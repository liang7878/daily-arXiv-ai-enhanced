{"id": "2508.19371", "pdf": "https://arxiv.org/pdf/2508.19371", "abs": "https://arxiv.org/abs/2508.19371", "authors": ["Semih Kara", "Tamer Ba\u015far"], "title": "Aggregate Fictitious Play for Learning in Anonymous Polymatrix Games (Extended Version)", "categories": ["cs.GT", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "Fictitious play (FP) is a well-studied algorithm that enables agents to learn\nNash equilibrium in games with certain reward structures. However, when agents\nhave no prior knowledge of the reward functions, FP faces a major challenge:\nthe joint action space grows exponentially with the number of agents, which\nslows down reward exploration. Anonymous games offer a structure that mitigates\nthis issue. In these games, the rewards depend only on the actions taken; not\non who is taking which action. Under such a structure, we introduce aggregate\nfictitious play (agg-FP), a variant of FP where each agent tracks the frequency\nof the number of other agents playing each action, rather than these agents'\nindividual actions. We show that in anonymous polymatrix games, agg-FP\nconverges to a Nash equilibrium under the same conditions as classical FP. In\nessence, by aggregating the agents' actions, we reduce the action space without\nlosing the convergence guarantees. Using simulations, we provide empirical\nevidence on how this reduction accelerates convergence.", "AI": {"tldr": "\u63d0\u51fa\u805a\u5408\u865a\u62df\u535a\u5f08\uff08agg - FP\uff09\u4ee5\u89e3\u51b3\u65e0\u5148\u9a8c\u5956\u52b1\u77e5\u8bc6\u65f6\u865a\u62df\u535a\u5f08\uff08FP\uff09\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u5728\u533f\u540d\u591a\u77e9\u9635\u535a\u5f08\u4e2d\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\u5e76\u52a0\u901f\u6536\u655b\u3002", "motivation": "\u4f20\u7edfFP\u5728\u65e0\u5956\u52b1\u51fd\u6570\u5148\u9a8c\u77e5\u8bc6\u65f6\uff0c\u8054\u5408\u52a8\u4f5c\u7a7a\u95f4\u968f\u667a\u80fd\u4f53\u6570\u91cf\u6307\u6570\u589e\u957f\uff0c\u51cf\u7f13\u5956\u52b1\u63a2\u7d22\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u5f15\u5165agg - FP\uff0c\u8ba9\u6bcf\u4e2a\u667a\u80fd\u4f53\u8ddf\u8e2a\u5176\u4ed6\u667a\u80fd\u4f53\u91c7\u53d6\u5404\u52a8\u4f5c\u7684\u9891\u7387\u800c\u975e\u4e2a\u4f53\u52a8\u4f5c\u3002", "result": "\u8bc1\u660e\u5728\u533f\u540d\u591a\u77e9\u9635\u535a\u5f08\u4e2d\uff0cagg - FP\u5728\u4e0e\u7ecf\u5178FP\u76f8\u540c\u6761\u4ef6\u4e0b\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\uff0c\u6a21\u62df\u663e\u793a\u51cf\u5c11\u52a8\u4f5c\u7a7a\u95f4\u52a0\u901f\u6536\u655b\u3002", "conclusion": "\u901a\u8fc7\u805a\u5408\u667a\u80fd\u4f53\u52a8\u4f5c\uff0c\u5728\u4e0d\u635f\u5931\u6536\u655b\u4fdd\u8bc1\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u52a8\u4f5c\u7a7a\u95f4\uff0c\u52a0\u901f\u6536\u655b\u3002"}}
{"id": "2508.19444", "pdf": "https://arxiv.org/pdf/2508.19444", "abs": "https://arxiv.org/abs/2508.19444", "authors": ["Suhala Rabab Saba", "Ph. D. Student", "Sagar Dasgupta", "Ph. D.", "Mizanur Rahman", "Ph. D.", "Nathan Huynh", "Ph. D.", "Li Zhao", "Ph. D", "Mehmet C. Vuran", "Ph. D.", "Qiang Liu", "Ph. D.", "Eren Erman Ozguven", "Ph. D"], "title": "Infrastructure-enabled risk assessment of hazardous road conditions on rural roads during inclement weather", "categories": ["cs.CE"], "comment": "18 pages, 5 figures, 5 tables", "summary": "Rural roadways often expose Commercial Motor Vehicle (CMV) drivers to\nhazardous conditions, such as heavy fog, rain, snow, black ice, and flash\nfloods, many of which remain unreported in real time. This lack of timely\ninformation, coupled with limited infrastructure in rural areas, significantly\nincreases the risk of crashes. Although various sensing technologies exist to\nmonitor individual hazards like low visibility or surface friction, they rarely\nassess the combined driving risk posed by multiple simultaneous hazards, nor do\nthey provide actionable recommendations such as safe advisory speeds. To\naddress this critical gap, in this study, we present a roadway hazard risk\nassessment framework that provides an approach to quantify the probability and\nseverity of crash occurrences due to specific roadway hazards. To evaluate this\nframework, we presented a case study by constructing a synthetic \"year-long\"\ndataset that encompasses every possible pairing of road surface and visibility\nconditions. Our analysis confirms that the combined ProbabilitySeverity scoring\nyields a coherent, stepwise risk profile across all hazard scenarios. These\nresults validate the practicality of our risk assessment approach and provide a\nfoundation for deploying graduated safety measures in real-world roadway\noperations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9053\u8def\u5371\u9669\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u5408\u6210\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8bc4\u4f30\u65b9\u6cd5\u5b9e\u7528\u6027\u3002", "motivation": "\u519c\u6751\u9053\u8def\u5371\u9669\u72b6\u51b5\u4fe1\u606f\u7f3a\u4e4f\u5b9e\u65f6\u62a5\u544a\uff0c\u73b0\u6709\u4f20\u611f\u6280\u672f\u4e0d\u80fd\u8bc4\u4f30\u591a\u5371\u9669\u7ec4\u5408\u98ce\u9669\u53ca\u63d0\u4f9b\u5efa\u8bae\uff0c\u9700\u89e3\u51b3\u6b64\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u9053\u8def\u5371\u9669\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u6784\u5efa\u5408\u6210\u201c\u5168\u5e74\u201d\u6570\u636e\u96c6\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u7efc\u5408\u6982\u7387 - \u4e25\u91cd\u6027\u8bc4\u5206\u5728\u6240\u6709\u5371\u9669\u573a\u666f\u4e2d\u4ea7\u751f\u8fde\u8d2f\u3001\u9010\u6b65\u7684\u98ce\u9669\u6982\u51b5\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u5b9e\u9645\u9053\u8def\u8fd0\u8425\u90e8\u7f72\u5206\u7ea7\u5b89\u5168\u63aa\u65bd\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.19921", "pdf": "https://arxiv.org/pdf/2508.19921", "abs": "https://arxiv.org/abs/2508.19921", "authors": ["Ferrandis Jesus", "Ramos Sergio", "Feijoo Claudio"], "title": "An assessment of estimation models and investment gaps for the deployment of high-speed broadband networks in NUTS3 regions to meet the objectives of the European Gigabit Society", "categories": ["cs.CE"], "comment": null, "summary": "This paper analyses the deployment of high speed broadband networks in the\nEuropean Union (EU). Its aim is to assess the investment required to meet the\ntargets set by the European Commission (EC) for 2025, within the framework of\nthe European Gigabit Society (EGS). This plan aims to ensure the availability\nand take up of very high capacity fixed and wireless networks, in both urban\nand rural areas, among households and the main socioeconomic drivers. The\nestimation model presented here uses a methodology supported by data at the\nlocal (NUTS3) level to give a bottom up estimation of the investment gap for\neach of the EGS objectives, using three different scenarios depending on the\nmix of wired and wireless technologies offered. The methodology and estimation\nmodel used in the paper are examined against other examples and assumptions\navailable in the literature. We also offer a dynamic perspective on the\nanalysis of the evolution of this investment gap over the years 2017 2019,\nwhich includes an assessment of the usefulness of these estimation models.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u6b27\u76df\u9ad8\u901f\u5bbd\u5e26\u7f51\u7edc\u90e8\u7f72\uff0c\u4f30\u7b97\u5b9e\u73b02025\u5e74\u76ee\u6807\u6240\u9700\u6295\u8d44\uff0c\u7ed9\u51fa\u4e0d\u540c\u60c5\u666f\u4e0b\u6295\u8d44\u7f3a\u53e3\u4f30\u7b97\u5e76\u5206\u6790\u6a21\u578b\u6709\u6548\u6027\u3002", "motivation": "\u8bc4\u4f30\u5728\u6b27\u6d32\u5343\u5146\u793e\u4f1a\u6846\u67b6\u4e0b\uff0c\u8fbe\u5230\u6b27\u76df\u59d4\u5458\u4f1a2025\u5e74\u76ee\u6807\u6240\u9700\u7684\u6295\u8d44\u3002", "method": "\u4f7f\u7528\u5730\u65b9\uff08NUTS3\uff09\u5c42\u9762\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u6839\u636e\u6709\u7ebf\u548c\u65e0\u7ebf\u6280\u672f\u7ec4\u5408\u4e09\u79cd\u4e0d\u540c\u60c5\u666f\u5bf9\u6bcf\u4e2a\u76ee\u6807\u7684\u6295\u8d44\u7f3a\u53e3\u8fdb\u884c\u81ea\u4e0b\u800c\u4e0a\u4f30\u7b97\uff0c\u5e76\u4e0e\u6587\u732e\u4e2d\u5176\u4ed6\u6848\u4f8b\u548c\u5047\u8bbe\u5bf9\u6bd4\uff0c\u52a8\u6001\u5206\u67902017 - 2019\u5e74\u6295\u8d44\u7f3a\u53e3\u6f14\u53d8\u3002", "result": " \u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba"}}
{"id": "2508.19957", "pdf": "https://arxiv.org/pdf/2508.19957", "abs": "https://arxiv.org/abs/2508.19957", "authors": ["Jannick Kehls", "Stephan Ritzert", "Lars Breuer", "Qinghua Zhang", "Stefanie Reese", "Tim Brepols"], "title": "Multi-field decomposed hyper-reduced order modeling of damage-plasticity simulations", "categories": ["cs.CE"], "comment": null, "summary": "This paper presents a multi-field decomposed approach for hyper-reduced order\nmodeling to overcome the limitations of traditional model reduction techniques\nfor gradient-extended damage-plasticity simulations. The discrete empirical\ninterpolation method (DEIM) and the energy-conserving sampling and weighting\nmethod (ECSW) are extended to account for the multi-field nature of the\nproblem. Both methods yield stable reduced order simulations, while\nsignificantly reducing the computational cost compared to full-order\nsimulations. Two numerical examples are presented to demonstrate the\nperformance and limitations of the proposed approaches. The decomposed ECSW\nmethod has overall higher accuracy and lower computational cost than the\ndecomposed DEIM method.", "AI": {"tldr": "\u63d0\u51fa\u591a\u573a\u5206\u89e3\u65b9\u6cd5\u7528\u4e8e\u8d85\u964d\u9636\u5efa\u6a21\uff0c\u6269\u5c55DEIM\u548cECSW\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b97\u4f8b\u5c55\u793a\u6027\u80fd\uff0cECSW\u65b9\u6cd5\u66f4\u4f18\u3002", "motivation": "\u514b\u670d\u4f20\u7edf\u6a21\u578b\u964d\u9636\u6280\u672f\u5728\u68af\u5ea6\u6269\u5c55\u635f\u4f24 - \u5851\u6027\u6a21\u62df\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u5c06\u79bb\u6563\u7ecf\u9a8c\u63d2\u503c\u65b9\u6cd5\uff08DEIM\uff09\u548c\u80fd\u91cf\u5b88\u6052\u91c7\u6837\u4e0e\u52a0\u6743\u65b9\u6cd5\uff08ECSW\uff09\u6269\u5c55\u4ee5\u8003\u8651\u95ee\u9898\u7684\u591a\u573a\u6027\u8d28\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u5b9e\u73b0\u7a33\u5b9a\u7684\u964d\u9636\u6a21\u62df\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5206\u89e3\u7684ECSW\u65b9\u6cd5\u6bd4\u5206\u89e3\u7684DEIM\u65b9\u6cd5\u7cbe\u5ea6\u66f4\u9ad8\u3001\u6210\u672c\u66f4\u4f4e\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u573a\u5206\u89e3\u65b9\u6cd5\u5728\u8d85\u964d\u9636\u5efa\u6a21\u4e2d\u6709\u8f83\u597d\u8868\u73b0\uff0cECSW\u65b9\u6cd5\u6027\u80fd\u66f4\u4f18\u3002"}}
{"id": "2508.20091", "pdf": "https://arxiv.org/pdf/2508.20091", "abs": "https://arxiv.org/abs/2508.20091", "authors": ["Armuna Cristina", "Ramos Sergio", "Juan Jesus", "Feijoo Claudio", "Arenal Alberto"], "title": "From stand-up to start-up: exploring entrepreneurship competences and STEM womens intention", "categories": ["cs.CE"], "comment": null, "summary": "This study seeks to explore the relationship between entrepreneurship\ncompetencies and intention (EI) of a sample of potential STEM entrepreneurs in\norder to assess the conventional assumption on women exhibiting lower rates of\nentrepreneurship intention than men and that the lack of competence perceived\nis a higher barrier to be an entrepreneur for them. The model used for the\nanalysis takes as reference the Entrepreneurship Competences Framework\n(EntreComp) proposed by the European Commission (EC) as a common guide to\ninspire entrepreneurship education. Data gathering is based on a structured\nquestionnaire. The conducted analysis uses Students t test means comparison and\nfactor analysis to define the model of competences, and a multiple regression\nmodel to study the relationship between competences and skill factors in EI.\nFindings do not validate the hypothesis that women have fewer entrepreneurship\nintentions than men. Also, slight differences on the self-perceived competences\nare obtained by gender. In addition, the study confirms the hypothesis of a\npositive relationship between competences and EI, but here gender is not a\nmoderating factor. Results are expected to contribute to the entrepreneurship\ncompetences debate and provide useful insights of application in\nentrepreneurship education with orientation towards the business creation.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u6f5c\u5728STEM\u521b\u4e1a\u8005\u521b\u4e1a\u80fd\u529b\u4e0e\u610f\u5411\u5173\u7cfb\uff0c\u9a8c\u8bc1\u6027\u522b\u4e0e\u521b\u4e1a\u610f\u5411\u5047\u8bbe\uff0c\u5206\u6790\u663e\u793a\u5973\u6027\u5e76\u975e\u521b\u4e1a\u610f\u5411\u66f4\u4f4e\uff0c\u80fd\u529b\u4e0e\u521b\u4e1a\u610f\u5411\u6b63\u76f8\u5173\uff0c\u6027\u522b\u975e\u8c03\u8282\u56e0\u7d20\u3002", "motivation": "\u8bc4\u4f30\u5973\u6027\u521b\u4e1a\u610f\u5411\u4f4e\u4e8e\u7537\u6027\u53ca\u80fd\u529b\u4e0d\u8db3\u662f\u5973\u6027\u521b\u4e1a\u66f4\u9ad8\u969c\u788d\u7684\u4f20\u7edf\u5047\u8bbe\u3002", "method": "\u4ee5\u6b27\u6d32\u59d4\u5458\u4f1a\u7684EntreComp\u6846\u67b6\u4e3a\u53c2\u8003\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u95ee\u5377\u6536\u96c6\u6570\u636e\uff0c\u7528\u5b66\u751ft\u68c0\u9a8c\u5747\u503c\u6bd4\u8f83\u3001\u56e0\u5b50\u5206\u6790\u5b9a\u4e49\u80fd\u529b\u6a21\u578b\uff0c\u7528\u591a\u5143\u56de\u5f52\u6a21\u578b\u7814\u7a76\u80fd\u529b\u4e0e\u521b\u4e1a\u610f\u5411\u5173\u7cfb\u3002", "result": "\u672a\u8bc1\u5b9e\u5973\u6027\u521b\u4e1a\u610f\u5411\u4f4e\u4e8e\u7537\u6027\u7684\u5047\u8bbe\uff0c\u6027\u522b\u5728\u81ea\u6211\u611f\u77e5\u80fd\u529b\u4e0a\u5dee\u5f02\u5c0f\uff0c\u8bc1\u5b9e\u80fd\u529b\u4e0e\u521b\u4e1a\u610f\u5411\u6b63\u76f8\u5173\u4e14\u6027\u522b\u975e\u8c03\u8282\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u521b\u4e1a\u80fd\u529b\u8fa9\u8bba\uff0c\u4e3a\u521b\u4e1a\u6559\u80b2\u548c\u4f01\u4e1a\u521b\u5efa\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2508.19379", "pdf": "https://arxiv.org/pdf/2508.19379", "abs": "https://arxiv.org/abs/2508.19379", "authors": ["Anurag Chakraborty", "Semih Saliho\u011flu"], "title": "Robust Recursive Query Parallelism in Graph Database Management Systems", "categories": ["cs.DB", "cs.PF"], "comment": null, "summary": "Efficient multi-core parallel processing of recursive join queries is\ncritical for achieving good performance in graph database management systems\n(GDBMSs). Prior work adopts two broad approaches. First is the state of the art\nmorsel-driven parallelism, whose vanilla application in GDBMSs parallelizes\ncomputations at the source node level. Second is to parallelize each iteration\nof the computation at the frontier level. We show that these approaches can be\nseen as part of a design space of morsel dispatching policies based on picking\ndifferent granularities of morsels. We then empirically study the question of\nwhich policies parallelize better in practice under a variety of datasets and\nquery workloads that contain one to many source nodes. We show that these two\npolicies can be combined in a hybrid policy that issues morsels both at the\nsource node and frontier levels. We then show that the multi-source\nbreadth-first search optimization from prior work can also be modeled as a\nmorsel dispatching policy that packs multiple source nodes into multi-source\nmorsels. We implement these policies inside a single system, the Kuzu GDBMS,\nand evaluate them both within Kuzu and across other systems. We show that the\nhybrid policy captures the behavior of both source morsel-only and frontier\nmorsel-only policies in cases when these approaches parallelize well, and\nout-perform them on queries when they are limited, and propose it as a robust\napproach to parallelizing recursive queries. We further show that assigning\nmulti-sources is beneficial, as it reduces the amount of scans, but only when\nthere is enough sources in the query.", "AI": {"tldr": "\u7814\u7a76\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u4e2d\u9012\u5f52\u8fde\u63a5\u67e5\u8be2\u7684\u591a\u6838\u5e76\u884c\u5904\u7406\u7b56\u7565\uff0c\u63d0\u51fa\u6df7\u5408\u7b56\u7565\u5e76\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "motivation": "\u9ad8\u6548\u7684\u591a\u6838\u5e76\u884c\u5904\u7406\u9012\u5f52\u8fde\u63a5\u67e5\u8be2\u5bf9\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u9700\u7814\u7a76\u66f4\u597d\u7684\u5e76\u884c\u7b56\u7565\u3002", "method": "\u5206\u6790\u73b0\u6709\u57fa\u4e8e\u4e0d\u540c\u7c92\u5ea6\u7684\u5c0f\u5757\u8c03\u5ea6\u7b56\u7565\uff0c\u5c06\u4e24\u79cd\u7b56\u7565\u7ed3\u5408\u6210\u6df7\u5408\u7b56\u7565\uff0c\u628a\u591a\u6e90\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u4f18\u5316\u5efa\u6a21\u4e3a\u5c0f\u5757\u8c03\u5ea6\u7b56\u7565\uff0c\u5e76\u5728Kuzu GDBMS\u4e2d\u5b9e\u73b0\u548c\u8bc4\u4f30\u3002", "result": "\u6df7\u5408\u7b56\u7565\u80fd\u6355\u6349\u5355\u4e00\u7b56\u7565\u4f18\u52bf\uff0c\u5728\u5176\u53d7\u9650\u7684\u67e5\u8be2\u4e0a\u8868\u73b0\u66f4\u4f18\uff1b\u591a\u6e90\u5206\u914d\u5728\u67e5\u8be2\u4e2d\u6709\u8db3\u591f\u6e90\u65f6\u53ef\u51cf\u5c11\u626b\u63cf\u91cf\u3002", "conclusion": "\u6df7\u5408\u7b56\u7565\u662f\u5e76\u884c\u5316\u9012\u5f52\u67e5\u8be2\u7684\u53ef\u9760\u65b9\u6cd5\uff0c\u591a\u6e90\u5206\u914d\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6709\u76ca\u3002"}}
{"id": "2508.19373", "pdf": "https://arxiv.org/pdf/2508.19373", "abs": "https://arxiv.org/abs/2508.19373", "authors": ["Haoran Lin", "Xianzhi Yu", "Kang Zhao", "Han Bao", "Zongyuan Zhan", "Ting Hu", "Wulong Liu", "Zekun Yin", "Xin Li", "Weiguo Liu"], "title": "HAP: Hybrid Adaptive Parallelism for Efficient Mixture-of-Experts Inference", "categories": ["cs.DC"], "comment": null, "summary": "Current inference systems for Mixture-of-Experts (MoE) models primarily\nemploy static parallelization strategies. However, these static approaches\ncannot consistently achieve optimal performance across different inference\nscenarios, as they lack the flexibility to adapt to varying computational\nrequirements. In this work, we propose HAP (Hybrid Adaptive Parallelism), a\nnovel method that dynamically selects hybrid parallel strategies to enhance MoE\ninference efficiency. The fundamental innovation of HAP lies in hierarchically\ndecomposing MoE architectures into two distinct computational modules: the\nAttention module and the Expert module, each augmented with a specialized\ninference latency simulation model. This decomposition promotes the\nconstruction of a comprehensive search space for seeking model parallel\nstrategies. By leveraging Integer Linear Programming (ILP), HAP could solve the\noptimal hybrid parallel configurations to maximize inference efficiency under\nvarying computational constraints. Our experiments demonstrate that HAP\nconsistently determines parallel configurations that achieve comparable or\nsuperior performance to the TP strategy prevalent in mainstream inference\nsystems. Compared to the TP-based inference, HAP-based inference achieves\nspeedups of 1.68x, 1.77x, and 1.57x on A100, A6000, and V100 GPU platforms,\nrespectively. Furthermore, HAP showcases remarkable generalization capability,\nmaintaining performance effectiveness across diverse MoE model configurations,\nincluding Mixtral and Qwen series models.", "AI": {"tldr": "\u63d0\u51faHAP\u65b9\u6cd5\u52a8\u6001\u9009\u62e9\u6df7\u5408\u5e76\u884c\u7b56\u7565\u63d0\u5347MoE\u63a8\u7406\u6548\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u8d8a\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u3002", "motivation": "\u73b0\u6709MoE\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u7684\u9759\u6001\u5e76\u884c\u7b56\u7565\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u5728\u4e0d\u540c\u63a8\u7406\u573a\u666f\u4e2d\u59cb\u7ec8\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\u3002", "method": "\u5c06MoE\u67b6\u6784\u5206\u5c42\u5206\u89e3\u4e3aAttention\u548cExpert\u6a21\u5757\uff0c\u4e3a\u6bcf\u4e2a\u6a21\u5757\u6dfb\u52a0\u63a8\u7406\u5ef6\u8fdf\u6a21\u62df\u6a21\u578b\uff0c\u6784\u5efa\u641c\u7d22\u7a7a\u95f4\uff0c\u5229\u7528\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u6c42\u89e3\u6700\u4f18\u6df7\u5408\u5e76\u884c\u914d\u7f6e\u3002", "result": "HAP\u786e\u5b9a\u7684\u5e76\u884c\u914d\u7f6e\u6027\u80fd\u4e0e\u4e3b\u6d41\u63a8\u7406\u7cfb\u7edf\u7684TP\u7b56\u7565\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u5728A100\u3001A6000\u548cV100 GPU\u5e73\u53f0\u4e0a\u5206\u522b\u5b9e\u73b01.68x\u30011.77x\u548c1.57x\u7684\u52a0\u901f\uff0c\u4e14\u5728\u591a\u79cdMoE\u6a21\u578b\u914d\u7f6e\u4e2d\u4fdd\u6301\u6027\u80fd\u6709\u6548\u3002", "conclusion": "HAP\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347MoE\u63a8\u7406\u6548\u7387\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.19365", "pdf": "https://arxiv.org/pdf/2508.19365", "abs": "https://arxiv.org/abs/2508.19365", "authors": ["Emaan Hariri", "Daniel E. Ho"], "title": "AI for Statutory Simplification: A Comprehensive State Legal Corpus and Labor Benchmark", "categories": ["cs.IR", "cs.CY", "H.3.3"], "comment": "10 pages, 3 figures. To appear in ICAIL 2025", "summary": "One of the emerging use cases of AI in law is for code simplification:\nstreamlining, distilling, and simplifying complex statutory or regulatory\nlanguage. One U.S. state has claimed to eliminate one third of its state code\nusing AI. Yet we lack systematic evaluations of the accuracy, reliability, and\nrisks of such approaches. We introduce LaborBench, a question-and-answer\nbenchmark dataset designed to evaluate AI capabilities in this domain. We\nleverage a unique data source to create LaborBench: a dataset updated annually\nby teams of lawyers at the U.S. Department of Labor, who compile differences in\nunemployment insurance laws across 50 states for over 101 dimensions in a\nsix-month process, culminating in a 200-page publication of tables. Inspired by\nour collaboration with one U.S. state to explore using large language models\n(LLMs) to simplify codes in this domain, where complexity is particularly\nacute, we transform the DOL publication into LaborBench. This provides a unique\nbenchmark for AI capacity to conduct, distill, and extract realistic statutory\nand regulatory information. To assess the performance of retrieval augmented\ngeneration (RAG) approaches, we also compile StateCodes, a novel and\ncomprehensive state statute and regulatory corpus of 8.7 GB, enabling much more\nsystematic research into state codes. We then benchmark the performance of\ninformation retrieval and state-of-the-art large LLMs on this data and show\nthat while these models are helpful as preliminary research for code\nsimplification, the overall accuracy is far below the touted promises for LLMs\nas end-to-end pipelines for regulatory simplification.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u7528\u4e8e\u8bc4\u4f30AI\u6cd5\u5f8b\u4ee3\u7801\u7b80\u5316\u80fd\u529b\u7684LaborBench\u6570\u636e\u96c6\u548cStateCodes\u8bed\u6599\u5e93\uff0c\u5bf9\u4fe1\u606f\u68c0\u7d22\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u6a21\u578b\u51c6\u786e\u6027\u672a\u8fbe\u9884\u671f\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9AI\u7b80\u5316\u6cd5\u5f8b\u4ee3\u7801\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u98ce\u9669\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u5229\u7528\u7f8e\u56fd\u52b3\u5de5\u90e8\u5f8b\u5e08\u56e2\u961f\u66f4\u65b0\u7684\u6570\u636e\u96c6\u521b\u5efaLaborBench\u6570\u636e\u96c6\uff0c\u7f16\u8bd18.7GB\u7684StateCodes\u8bed\u6599\u5e93\uff0c\u5bf9\u4fe1\u606f\u68c0\u7d22\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u5bf9\u4ee3\u7801\u7b80\u5316\u521d\u6b65\u7814\u7a76\u6709\u5e2e\u52a9\uff0c\u4f46\u6574\u4f53\u51c6\u786e\u6027\u8fdc\u4f4e\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u76d1\u7ba1\u7b80\u5316\u7aef\u5230\u7aef\u7ba1\u9053\u7684\u5ba3\u4f20\u6548\u679c\u3002", "conclusion": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u6cd5\u89c4\u7b80\u5316\u7684\u6574\u4f53\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u8ddd\u79bb\u9884\u671f\u6548\u679c\u6709\u5dee\u8ddd\u3002"}}
{"id": "2508.19473", "pdf": "https://arxiv.org/pdf/2508.19473", "abs": "https://arxiv.org/abs/2508.19473", "authors": ["Stephen Arndt", "Benjamin Moseley", "Kirk Pruhs", "Michael Zlatin"], "title": "Efficiently Coloring the Intersection of a General Matroid and Partition Matroids", "categories": ["cs.DS"], "comment": null, "summary": "This paper shows a polynomial-time algorithm, that given a general matroid\n$M_1 = (X, \\mathcal{I}_1)$ and $k-1$ partition matroids $ M_2, \\ldots, M_k$,\nproduces a coloring of the intersection $M = \\cap_{i=1}^k M_i$ using at most\n$1+\\sum_{i=1}^k \\left(\\chi(M_i) -1\\right)$ colors. This is the first\npolynomial-time $O(1)$-approximation algorithm for matroid intersection\ncoloring where one of the matroids may be a general matroid. Leveraging the\nfact that all of the standard combinatorial matroids reduce to partition\nmatroids at a loss of a factor of two in the chromatic number, this algorithm\nalso yields a polynomial-time $O(1)$-approximation algorithm for matroid\nintersection coloring in the case where each of the matroids $ M_2, \\ldots,\nM_k$ are one of the standard combinatorial types.", "AI": {"tldr": "\u63d0\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5bf9\u4e00\u822c\u62df\u9635\u4e0ek - 1\u4e2a\u5212\u5206\u62df\u9635\u7684\u4ea4\u96c6\u8fdb\u884c\u7740\u8272\uff0c\u662f\u9996\u4e2a\u62df\u9635\u4ea4\u7740\u8272\u7684\u591a\u9879\u5f0f\u65f6\u95f4O(1)\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u5bfb\u627e\u62df\u9635\u4ea4\u7740\u8272\u7684\u591a\u9879\u5f0f\u65f6\u95f4O(1)\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u5176\u4e2d\u4e00\u4e2a\u62df\u9635\u4e3a\u4e00\u822c\u62df\u9635\u7684\u60c5\u51b5\u3002", "method": "\u5229\u7528\u6807\u51c6\u7ec4\u5408\u62df\u9635\u5728\u8272\u6570\u4e0a\u635f\u5931\u56e0\u5b502\u53ef\u8f6c\u5316\u4e3a\u5212\u5206\u62df\u9635\u8fd9\u4e00\u4e8b\u5b9e\u8bbe\u8ba1\u7b97\u6cd5\u3002", "result": "\u5f97\u5230\u4e86\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u80fd\u7528\u81f3\u591a1 + \u2211(\u03c7(M_i) - 1)\u79cd\u989c\u8272\u5bf9\u62df\u9635\u4ea4\u7740\u8272\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u662f\u62df\u9635\u4ea4\u7740\u8272\u95ee\u9898\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5b58\u5728\u4e00\u822c\u62df\u9635\u7684\u60c5\u51b5\u53ca\u6807\u51c6\u7ec4\u5408\u62df\u9635\u7684\u60c5\u51b5\u3002"}}
{"id": "2508.19449", "pdf": "https://arxiv.org/pdf/2508.19449", "abs": "https://arxiv.org/abs/2508.19449", "authors": ["Md Afif Al Mamun", "Gias Uddin", "Lan Xia", "Longyu Zhang"], "title": "Stack Trace-Based Crash Deduplication with Transformer Adaptation", "categories": ["cs.SE", "cs.LG"], "comment": "This work is currently under review at IEEE Transactions on Software\n  Engineering. The replication package will be made publicly available upon\n  acceptance", "summary": "Automated crash reporting systems generate large volumes of duplicate\nreports, overwhelming issue-tracking systems and increasing developer workload.\nTraditional stack trace-based deduplication methods, relying on string\nsimilarity, rule-based heuristics, or deep learning (DL) models, often fail to\ncapture the contextual and structural relationships within stack traces. We\npropose dedupT, a transformer-based approach that models stack traces\nholistically rather than as isolated frames. dedupT first adapts a pretrained\nlanguage model (PLM) to stack traces, then uses its embeddings to train a\nfully-connected network (FCN) to rank duplicate crashes effectively. Extensive\nexperiments on real-world datasets show that dedupT outperforms existing DL and\ntraditional methods (e.g., sequence alignment and information retrieval\ntechniques) in both duplicate ranking and unique crash detection, significantly\nreducing manual triage effort. On four public datasets, dedupT improves Mean\nReciprocal Rank (MRR) often by over 15% compared to the best DL baseline and up\nto 9% over traditional methods while achieving higher Receiver Operating\nCharacteristic Area Under the Curve (ROC-AUC) in detecting unique crash\nreports. Our work advances the integration of modern natural language\nprocessing (NLP) techniques into software engineering, providing an effective\nsolution for stack trace-based crash deduplication.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8etransformer\u7684dedupT\u65b9\u6cd5\u8fdb\u884c\u5d29\u6e83\u62a5\u544a\u53bb\u91cd\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63a8\u8fdbNLP\u6280\u672f\u5728\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5e94\u7528\u3002", "motivation": "\u81ea\u52a8\u5d29\u6e83\u62a5\u544a\u7cfb\u7edf\u4ea7\u751f\u5927\u91cf\u91cd\u590d\u62a5\u544a\uff0c\u4f20\u7edf\u53bb\u91cd\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u5806\u6808\u8ddf\u8e2a\u7684\u4e0a\u4e0b\u6587\u548c\u7ed3\u6784\u5173\u7cfb\u3002", "method": "\u5148\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5230\u5806\u6808\u8ddf\u8e2a\uff0c\u518d\u7528\u5176\u5d4c\u5165\u8bad\u7ec3\u5168\u8fde\u63a5\u7f51\u7edc\u5bf9\u91cd\u590d\u5d29\u6e83\u8fdb\u884c\u6709\u6548\u6392\u540d\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cdedupT\u5728\u91cd\u590d\u6392\u540d\u548c\u552f\u4e00\u5d29\u6e83\u68c0\u6d4b\u4e0a\u4f18\u4e8e\u73b0\u6709DL\u548c\u4f20\u7edf\u65b9\u6cd5\uff0c\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\uff0cMRR\u6bd4\u6700\u4f73DL\u57fa\u7ebf\u63d0\u9ad8\u8d8515%\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6700\u591a\u63d0\u9ad89%\uff0cROC - AUC\u66f4\u9ad8\u3002", "conclusion": "\u63a8\u8fdb\u73b0\u4ee3NLP\u6280\u672f\u878d\u5165\u8f6f\u4ef6\u5de5\u7a0b\uff0c\u4e3a\u57fa\u4e8e\u5806\u6808\u8ddf\u8e2a\u7684\u5d29\u6e83\u53bb\u91cd\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19299", "pdf": "https://arxiv.org/pdf/2508.19299", "abs": "https://arxiv.org/abs/2508.19299", "authors": ["Rishov Sarkar", "Cong Hao"], "title": "OmniSim: Simulating Hardware with C Speed and RTL Accuracy for High-Level Synthesis Designs", "categories": ["cs.AR", "cs.PF"], "comment": "13 pages, 8 figures. Accepted at MICRO 2025", "summary": "High-Level Synthesis (HLS) is increasingly popular for hardware design using\nC/C++ instead of Register-Transfer Level (RTL). To express concurrent hardware\nbehavior in a sequential language like C/C++, HLS tools introduce constructs\nsuch as infinite loops and dataflow modules connected by FIFOs. However,\nefficiently and accurately simulating these constructs at C level remains\nchallenging. First, without hardware timing information, functional\nverification typically requires slow RTL synthesis and simulation, as the\ncurrent approaches in commercial HLS tools. Second, cycle-accurate performance\nmetrics, such as end-to-end latency, also rely on RTL simulation. No existing\nHLS tool fully overcomes the first limitation. For the second, prior work such\nas LightningSim partially improves simulation speed but lacks support for\nadvanced dataflow features like cyclic dependencies and non-blocking FIFO\naccesses.\n  To overcome both limitations, we propose OmniSim, a framework that\nsignificantly extends the simulation capabilities of both academic and\ncommercial HLS tools. First, OmniSim enables fast and accurate simulation of\ncomplex dataflow designs, especially those explicitly declared unsupported by\ncommercial tools. It does so through sophisticated software multi-threading,\nwhere threads are orchestrated by querying and updating a set of FIFO tables\nthat explicitly record exact hardware timing of each FIFO access. Second,\nOmniSim achieves near-C simulation speed with near-RTL accuracy for both\nfunctionality and performance, via flexibly coupled and overlapped\nfunctionality and performance simulations.\n  We demonstrate that OmniSim successfully simulates eleven designs previously\nunsupported by any HLS tool, achieving up to 35.9x speedup over traditional\nC/RTL co-simulation, and up to 6.61x speedup over the state-of-the-art yet less\ncapable simulator, LightningSim, on its own benchmark suite.", "AI": {"tldr": "\u63d0\u51faOmniSim\u6846\u67b6\uff0c\u6269\u5c55HLS\u5de5\u5177\u4eff\u771f\u80fd\u529b\uff0c\u6a21\u62df\u590d\u6742\u6570\u636e\u6d41\u8bbe\u8ba1\uff0c\u901f\u5ea6\u5feb\u4e14\u51c6\u786e\u3002", "motivation": "\u73b0\u6709HLS\u5de5\u5177\u5728C\u7ea7\u9ad8\u6548\u51c6\u786e\u6a21\u62df\u76f8\u5173\u6784\u9020\u5b58\u5728\u6311\u6218\uff0c\u7f3a\u4e4f\u786c\u4ef6\u65f6\u5e8f\u4fe1\u606f\uff0c\u6027\u80fd\u6307\u6807\u4f9d\u8d56RTL\u4eff\u771f\uff0c\u4e14\u73b0\u6709\u5de5\u5177\u672a\u5b8c\u5168\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u590d\u6742\u8f6f\u4ef6\u591a\u7ebf\u7a0b\uff0c\u67e5\u8be2\u548c\u66f4\u65b0FIFO\u8868\u8bb0\u5f55\u786c\u4ef6\u65f6\u5e8f\uff1b\u7075\u6d3b\u8026\u5408\u548c\u91cd\u53e0\u529f\u80fd\u4e0e\u6027\u80fd\u4eff\u771f\u3002", "result": "\u6210\u529f\u6a21\u62df11\u4e2a\u6b64\u524dHLS\u5de5\u5177\u4e0d\u652f\u6301\u7684\u8bbe\u8ba1\uff0c\u6bd4\u4f20\u7edfC/RTL\u534f\u540c\u4eff\u771f\u5feb35.9\u500d\uff0c\u6bd4LightningSim\u5feb6.61\u500d\u3002", "conclusion": "OmniSim\u80fd\u663e\u8457\u6269\u5c55\u5b66\u672f\u548c\u5546\u4e1aHLS\u5de5\u5177\u7684\u4eff\u771f\u80fd\u529b\u3002"}}
{"id": "2508.19316", "pdf": "https://arxiv.org/pdf/2508.19316", "abs": "https://arxiv.org/abs/2508.19316", "authors": ["Shreyans Jain", "Alexandra Yost", "Amirali Abdullah"], "title": "Sycophancy as compositions of Atomic Psychometric Traits", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; I.2.4"], "comment": "8 pages, 4 figures", "summary": "Sycophancy is a key behavioral risk in LLMs, yet is often treated as an\nisolated failure mode that occurs via a single causal mechanism. We instead\npropose modeling it as geometric and causal compositions of psychometric traits\nsuch as emotionality, openness, and agreeableness - similar to factor\ndecomposition in psychometrics. Using Contrastive Activation Addition (CAA), we\nmap activation directions to these factors and study how different combinations\nmay give rise to sycophancy (e.g., high extraversion combined with low\nconscientiousness). This perspective allows for interpretable and compositional\nvector-based interventions like addition, subtraction and projection; that may\nbe used to mitigate safety-critical behaviors in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8c04\u5a9a\u884c\u4e3a\u5efa\u6a21\u4e3a\u5fc3\u7406\u6d4b\u91cf\u7279\u5f81\u7684\u51e0\u4f55\u548c\u56e0\u679c\u7ec4\u5408\uff0c\u7528CAA\u6620\u5c04\u6fc0\u6d3b\u65b9\u5411\uff0c\u53ef\u8fdb\u884c\u5411\u91cf\u5e72\u9884\u4ee5\u7f13\u89e3\u5b89\u5168\u5173\u952e\u884c\u4e3a\u3002", "motivation": "\u4ee5\u5f80\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8c04\u5a9a\u884c\u4e3a\u89c6\u4e3a\u5355\u4e00\u56e0\u679c\u673a\u5236\u7684\u5b64\u7acb\u6545\u969c\u6a21\u5f0f\uff0c\u9700\u65b0\u89c6\u89d2\u7814\u7a76\u3002", "method": "\u5c06\u8c04\u5a9a\u884c\u4e3a\u5efa\u6a21\u4e3a\u5fc3\u7406\u6d4b\u91cf\u7279\u5f81\u7684\u51e0\u4f55\u548c\u56e0\u679c\u7ec4\u5408\uff0c\u4f7f\u7528\u5bf9\u6bd4\u6fc0\u6d3b\u52a0\u6cd5\uff08CAA\uff09\u6620\u5c04\u6fc0\u6d3b\u65b9\u5411\u3002", "result": "\u80fd\u591f\u7814\u7a76\u4e0d\u540c\u7279\u5f81\u7ec4\u5408\u5982\u4f55\u5bfc\u81f4\u8c04\u5a9a\u884c\u4e3a\u3002", "conclusion": "\u6b64\u89c6\u89d2\u53ef\u8fdb\u884c\u57fa\u4e8e\u5411\u91cf\u7684\u53ef\u89e3\u91ca\u548c\u7ec4\u5408\u5e72\u9884\uff0c\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5b89\u5168\u5173\u952e\u884c\u4e3a\u3002"}}
{"id": "2508.19750", "pdf": "https://arxiv.org/pdf/2508.19750", "abs": "https://arxiv.org/abs/2508.19750", "authors": ["Binhui Zhang", "Jianwei Ma"], "title": "Fractal Flow: Hierarchical and Interpretable Normalizing Flow via Topic Modeling and Recursive Strategy", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Normalizing Flows provide a principled framework for high-dimensional density\nestimation and generative modeling by constructing invertible transformations\nwith tractable Jacobian determinants. We propose Fractal Flow, a novel\nnormalizing flow architecture that enhances both expressiveness and\ninterpretability through two key innovations. First, we integrate\nKolmogorov-Arnold Networks and incorporate Latent Dirichlet Allocation into\nnormalizing flows to construct a structured, interpretable latent space and\nmodel hierarchical semantic clusters. Second, inspired by Fractal Generative\nModels, we introduce a recursive modular design into normalizing flows to\nimprove transformation interpretability and estimation accuracy. Experiments on\nMNIST, FashionMNIST, CIFAR-10, and geophysical data demonstrate that the\nFractal Flow achieves latent clustering, controllable generation, and superior\nestimation accuracy.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3aFractal Flow\u7684\u5f52\u4e00\u5316\u6d41\u67b6\u6784\uff0c\u7ed3\u5408KAN\u548cLDA\u6784\u5efa\u53ef\u89e3\u91ca\u6f5c\u5728\u7a7a\u95f4\uff0c\u5f15\u5165\u9012\u5f52\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u5b9e\u73b0\u6f5c\u5728\u805a\u7c7b\u3001\u53ef\u63a7\u751f\u6210\u548c\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\u3002", "motivation": "\u63d0\u9ad8\u5f52\u4e00\u5316\u6d41\u5728\u9ad8\u7ef4\u5bc6\u5ea6\u4f30\u8ba1\u548c\u751f\u6210\u5efa\u6a21\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "1. \u96c6\u6210Kolmogorov - Arnold Networks\u5e76\u5c06Latent Dirichlet Allocation\u878d\u5165\u5f52\u4e00\u5316\u6d41\uff1b2. \u53d7\u5206\u5f62\u751f\u6210\u6a21\u578b\u542f\u53d1\uff0c\u5f15\u5165\u9012\u5f52\u6a21\u5757\u5316\u8bbe\u8ba1\u3002", "result": "\u5728MNIST\u3001FashionMNIST\u3001CIFAR - 10\u548c\u5730\u7403\u7269\u7406\u6570\u636e\u4e0a\u5b9e\u73b0\u4e86\u6f5c\u5728\u805a\u7c7b\u3001\u53ef\u63a7\u751f\u6210\u548c\u8f83\u9ad8\u7684\u4f30\u8ba1\u7cbe\u5ea6\u3002", "conclusion": "Fractal Flow\u67b6\u6784\u6709\u6548\u63d0\u5347\u4e86\u5f52\u4e00\u5316\u6d41\u7684\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.19548", "pdf": "https://arxiv.org/pdf/2508.19548", "abs": "https://arxiv.org/abs/2508.19548", "authors": ["Madhuvanthi Srivatsav R", "Chiranjib Bhattacharyya", "Shantanu Chakrabartty", "Chetan Singh Thakur"], "title": "When Routers, Switches and Interconnects Compute: A processing-in-interconnect Paradigm for Scalable Neuromorphic AI", "categories": ["cs.NE", "cs.AR", "cs.NI"], "comment": null, "summary": "Routing, switching, and the interconnect fabric are essential for large-scale\nneuromorphic computing. While this fabric only plays a supporting role in the\nprocess of computing, for large AI workloads it ultimately determines energy\nconsumption and speed. In this paper, we address this bottleneck by asking: (a)\nWhat computing paradigms are inherent in existing routing, switching, and\ninterconnect systems, and how can they be used to implement a\nprocessing-in-Interconnect (\\pi^2) computing paradigm? and (b) leveraging\ncurrent and future interconnect trends, how will a \\pi^2 system's performance\nscale compared to other neuromorphic architectures? For (a), we show that\noperations required for typical AI workloads can be mapped onto delays,\ncausality, time-outs, packet drop, and broadcast operations -- primitives\nalready implemented in packet-switching and packet-routing hardware. We show\nthat existing buffering and traffic-shaping embedded algorithms can be\nleveraged to implement neuron models and synaptic operations. Additionally, a\nknowledge-distillation framework can train and cross-map well-established\nneural network topologies onto $\\pi^2$ without degrading generalization\nperformance. For (b), analytical modeling shows that, unlike other neuromorphic\nplatforms, the energy scaling of $\\pi^2$ improves with interconnect bandwidth\nand energy efficiency. We predict that by leveraging trends in interconnect\ntechnology, a \\pi^2 architecture can be more easily scaled to execute\nbrain-scale AI inference workloads with power consumption levels in the range\nof hundreds of watts.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u8def\u7531\u3001\u4ea4\u6362\u548c\u4e92\u8fde\u7ed3\u6784\u5728\u5927\u89c4\u6a21\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e2d\u7684\u74f6\u9888\uff0c\u63d0\u51fa\u5904\u7406 - \u4e92\u8fde\u8ba1\u7b97\u8303\u5f0f\uff08\u03c0\u00b2\uff09\uff0c\u5206\u6790\u5176\u5b9e\u73b0\u65b9\u6cd5\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e2d\u8def\u7531\u3001\u4ea4\u6362\u548c\u4e92\u8fde\u7ed3\u6784\u51b3\u5b9a\u80fd\u8017\u548c\u901f\u5ea6\u7684\u74f6\u9888\u95ee\u9898\u3002", "method": "\u5c06\u5178\u578bAI\u5de5\u4f5c\u8d1f\u8f7d\u64cd\u4f5c\u6620\u5c04\u5230\u73b0\u6709\u5206\u7ec4\u4ea4\u6362\u548c\u8def\u7531\u786c\u4ef6\u539f\u8bed\uff0c\u5229\u7528\u73b0\u6709\u7f13\u51b2\u548c\u6d41\u91cf\u6574\u5f62\u7b97\u6cd5\u5b9e\u73b0\u795e\u7ecf\u5143\u6a21\u578b\u548c\u7a81\u89e6\u64cd\u4f5c\uff0c\u7528\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\u8bad\u7ec3\u548c\u6620\u5c04\u795e\u7ecf\u7f51\u7edc\u62d3\u6251\uff1b\u901a\u8fc7\u5206\u6790\u5efa\u6a21\u5bf9\u6bd4\u6027\u80fd\u3002", "result": "\u03c0\u00b2\u7684\u80fd\u91cf\u7f29\u653e\u968f\u4e92\u8fde\u5e26\u5bbd\u548c\u80fd\u6548\u63d0\u9ad8\u800c\u6539\u5584\uff0c\u80fd\u66f4\u8f7b\u677e\u6269\u5c55\u4ee5\u6267\u884c\u8111\u89c4\u6a21AI\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u529f\u8017\u5728\u6570\u767e\u74e6\u8303\u56f4\u3002", "conclusion": "\u5229\u7528\u4e92\u8fde\u6280\u672f\u8d8b\u52bf\uff0c\u03c0\u00b2\u67b6\u6784\u5728\u5927\u89c4\u6a21\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e2d\u6709\u826f\u597d\u6269\u5c55\u6027\u548c\u4f4e\u529f\u8017\u4f18\u52bf\u3002"}}
{"id": "2508.19304", "pdf": "https://arxiv.org/pdf/2508.19304", "abs": "https://arxiv.org/abs/2508.19304", "authors": ["Generoso Immediato"], "title": "Epistemic Trade-Off: An Analysis of the Operational Breakdown and Ontological Limits of \"Certainty-Scope\" in AI", "categories": ["cs.CY", "cs.AI", "cs.CE"], "comment": "5 pages", "summary": "Floridi's conjecture offers a compelling intuition about the fundamental\ntrade-off between certainty and scope in artificial intelligence (AI) systems.\nThis exploration remains crucial, not merely as a philosophical exercise, but\nas a potential compass for guiding AI investments, particularly in\nsafety-critical industrial domains where the level of attention will surely be\nhigher in the future. However, while intellectually coherent, its formalization\nultimately freezes this insight into a suspended epistemic truth, resisting\noperationalization within real-world systems. This paper is a result of an\nanalysis arguing that the conjecture's ambition to provide insights to\nengineering design and regulatory decision-making is constrained by two\ncritical factors: first, its reliance on incomputable constructs - rendering it\npractically unactionable and unverifiable; second, its underlying ontological\nassumption of AI systems as self-contained epistemic entities - separating it\nfrom the intricate and dynamic socio-technical environments in which knowledge\nis co-constructed. We conclude that this dual breakdown - an epistemic closure\ndeficit and an embeddedness bypass - prevents the conjecture from transitioning\ninto a computable and actionable framework suitable for informing the design,\ndeployment, and governance of real-world AI hybrid systems. In response, we\npropose a contribution to the framing of Floridi's epistemic challenge,\naddressing the inherent epistemic burdens of AI within complex human-centric\ndomains.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5f17\u6d1b\u91cc\u8fea\u731c\u60f3\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u5c40\u9650\u6027\uff0c\u6307\u51fa\u5176\u96be\u4ee5\u64cd\u4f5c\u5316\uff0c\u5e76\u63d0\u51fa\u5e94\u5bf9\u5176\u8ba4\u77e5\u6311\u6218\u7684\u5efa\u8bae\u3002", "motivation": "\u63a2\u8ba8\u5f17\u6d1b\u91cc\u8fea\u731c\u60f3\u5728\u6307\u5bfc\u4eba\u5de5\u667a\u80fd\u6295\u8d44\uff0c\u5c24\u5176\u662f\u5b89\u5168\u5173\u952e\u5de5\u4e1a\u9886\u57df\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u53ca\u5176\u5bf9\u5de5\u7a0b\u8bbe\u8ba1\u548c\u76d1\u7ba1\u51b3\u7b56\u7684\u6307\u5bfc\u4f5c\u7528\u3002", "method": "\u5206\u6790\u8be5\u731c\u60f3\u5b58\u5728\u7684\u4e24\u4e2a\u5173\u952e\u9650\u5236\u56e0\u7d20\uff0c\u4e00\u662f\u4f9d\u8d56\u4e0d\u53ef\u8ba1\u7b97\u7ed3\u6784\uff0c\u4e8c\u662f\u672c\u4f53\u8bba\u5047\u8bbe\u8131\u79bb\u73b0\u5b9e\u793e\u4f1a\u6280\u672f\u73af\u5883\u3002", "result": "\u53d1\u73b0\u8be5\u731c\u60f3\u5b58\u5728\u8ba4\u77e5\u5c01\u95ed\u4e0d\u8db3\u548c\u672a\u8003\u8651\u5d4c\u5165\u6027\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u8f6c\u53d8\u4e3a\u53ef\u8ba1\u7b97\u548c\u53ef\u64cd\u4f5c\u7684\u6846\u67b6\u3002", "conclusion": "\u8be5\u731c\u60f3\u65e0\u6cd5\u4e3a\u73b0\u5b9e\u4e16\u754c\u7684\u4eba\u5de5\u667a\u80fd\u6df7\u5408\u7cfb\u7edf\u8bbe\u8ba1\u3001\u90e8\u7f72\u548c\u6cbb\u7406\u63d0\u4f9b\u6709\u6548\u6846\u67b6\uff0c\u9700\u5e94\u5bf9\u5176\u5728\u590d\u6742\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u9886\u57df\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002"}}
{"id": "2508.19807", "pdf": "https://arxiv.org/pdf/2508.19807", "abs": "https://arxiv.org/abs/2508.19807", "authors": ["Michael Nidd", "Christoph Miksovic", "Thomas Gschwind", "Francesco Fusco", "Andrea Giovannini", "Ioana Giurgiu"], "title": "Bootstrapping Learned Cost Models with Synthetic SQL Queries", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Having access to realistic workloads for a given database instance is\nextremely important to enable stress and vulnerability testing, as well as to\noptimize for cost and performance. Recent advances in learned cost models have\nshown that when enough diverse SQL queries are available, one can effectively\nand efficiently predict the cost of running a given query against a specific\ndatabase engine. In this paper, we describe our experience in exploiting modern\nsynthetic data generation techniques, inspired by the generative AI and LLM\ncommunity, to create high-quality datasets enabling the effective training of\nsuch learned cost models. Initial results show that we can improve a learned\ncost model's predictive accuracy by training it with 45% fewer queries than\nwhen using competitive generation approaches.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u73b0\u4ee3\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\u521b\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u4ee5\u8bad\u7ec3\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\uff0c\u521d\u59cb\u7ed3\u679c\u663e\u793a\u53ef\u51cf\u5c1145%\u67e5\u8be2\u91cf\u6765\u63d0\u5347\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u83b7\u53d6\u7ed9\u5b9a\u6570\u636e\u5e93\u5b9e\u4f8b\u7684\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u5bf9\u538b\u529b\u548c\u6f0f\u6d1e\u6d4b\u8bd5\u3001\u6210\u672c\u4e0e\u6027\u80fd\u4f18\u5316\u81f3\u5173\u91cd\u8981\uff0c\u5e0c\u671b\u6709\u6548\u8bad\u7ec3\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\u3002", "method": "\u5229\u7528\u53d7\u751f\u6210\u5f0fAI\u548c\u5927\u8bed\u8a00\u6a21\u578b\u793e\u533a\u542f\u53d1\u7684\u73b0\u4ee3\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\u521b\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002", "result": "\u4e0e\u7ade\u4e89\u6027\u751f\u6210\u65b9\u6cd5\u76f8\u6bd4\uff0c\u7528\u5c1145%\u7684\u67e5\u8be2\u8bad\u7ec3\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\uff0c\u53ef\u63d0\u9ad8\u5176\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u73b0\u4ee3\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\u53ef\u6709\u6548\u7528\u4e8e\u8bad\u7ec3\u5b66\u4e60\u578b\u6210\u672c\u6a21\u578b\uff0c\u51cf\u5c11\u67e5\u8be2\u91cf\u5e76\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2508.19452", "pdf": "https://arxiv.org/pdf/2508.19452", "abs": "https://arxiv.org/abs/2508.19452", "authors": ["Andrea Esposito", "Francesco P. Rossi", "Marco Bernardo", "Francesco Fabris", "Hubert Garavel"], "title": "Formal Modeling and Verification of the Algorand Consensus Protocol in CADP", "categories": ["cs.DC"], "comment": null, "summary": "Algorand is a scalable and secure permissionless blockchain that achieves\nproof-of-stake consensus via cryptographic self-sortition and binary Byzantine\nagreement. In this paper, we present a process algebraic model of the Algorand\nconsensus protocol with the aim of enabling rigorous formal verification. Our\nmodel captures the behavior of participants with respect to the structured\nalternation of consensus steps toward a committee-based agreement by means of a\nprobabilistic process calculus. We validate the correctness of the protocol in\nthe absence of adversaries and then extend our model to capture the influence\nof coordinated malicious nodes that can force the commit of an empty block\ninstead of the proposed one. The adversarial scenario is analyzed by using an\nequivalence-checking-based noninterference framework that we have implemented\nin the CADP verification toolkit. In addition to highlighting both the\nrobustness and the limitations of the Algorand protocol under adversarial\nassumptions, this work illustrates the added value of using formal methods for\nthe analysis of blockchain consensus algorithms.", "AI": {"tldr": "\u63d0\u51faAlgorand\u5171\u8bc6\u534f\u8bae\u7684\u8fdb\u7a0b\u4ee3\u6570\u6a21\u578b\u7528\u4e8e\u5f62\u5f0f\u9a8c\u8bc1\uff0c\u5206\u6790\u534f\u8bae\u5728\u6709\u65e0\u654c\u624b\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u4e3aAlgorand\u5171\u8bc6\u534f\u8bae\u8fdb\u884c\u4e25\u683c\u7684\u5f62\u5f0f\u9a8c\u8bc1\u3002", "method": "\u7528\u6982\u7387\u8fdb\u7a0b\u6f14\u7b97\u5efa\u7acb\u6a21\u578b\uff0c\u7528CADP\u9a8c\u8bc1\u5de5\u5177\u5305\u4e2d\u7684\u7b49\u4ef7\u68c0\u67e5\u975e\u5e72\u6270\u6846\u67b6\u5206\u6790\u5bf9\u6297\u573a\u666f\u3002", "result": "\u9a8c\u8bc1\u4e86\u65e0\u654c\u624b\u65f6\u534f\u8bae\u7684\u6b63\u786e\u6027\uff0c\u5206\u6790\u4e86\u6709\u534f\u8c03\u6076\u610f\u8282\u70b9\u65f6\u7684\u60c5\u51b5\u3002", "conclusion": "\u51f8\u663e\u4e86Algorand\u534f\u8bae\u5728\u5bf9\u6297\u5047\u8bbe\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u5c40\u9650\u6027\uff0c\u8bf4\u660e\u4e86\u5f62\u5f0f\u5316\u65b9\u6cd5\u5bf9\u533a\u5757\u94fe\u5171\u8bc6\u7b97\u6cd5\u5206\u6790\u7684\u4ef7\u503c\u3002"}}
{"id": "2508.19399", "pdf": "https://arxiv.org/pdf/2508.19399", "abs": "https://arxiv.org/abs/2508.19399", "authors": ["Tobias Vente", "Michael Heep", "Abdullah Abbas", "Theodor Sperle", "Joeran Beel", "Bart Goethals"], "title": "APS Explorer: Navigating Algorithm Performance Spaces for Informed Dataset Selection", "categories": ["cs.IR"], "comment": null, "summary": "Dataset selection is crucial for offline recommender system experiments, as\nmismatched data (e.g., sparse interaction scenarios require datasets with low\nuser-item density) can lead to unreliable results. Yet, 86\\% of ACM RecSys 2024\npapers provide no justification for their dataset choices, with most relying on\njust four datasets: Amazon (38\\%), MovieLens (34\\%), Yelp (15\\%), and Gowalla\n(12\\%). While Algorithm Performance Spaces (APS) were proposed to guide dataset\nselection, their adoption has been limited due to the absence of an intuitive,\ninteractive tool for APS exploration. Therefore, we introduce the APS Explorer,\na web-based visualization tool for interactive APS exploration, enabling\ndata-driven dataset selection. The APS Explorer provides three interactive\nfeatures: (1) an interactive PCA plot showing dataset similarity via\nperformance patterns, (2) a dynamic meta-feature table for dataset comparisons,\nand (3) a specialized visualization for pairwise algorithm performance.", "AI": {"tldr": "\u591a\u6570ACM RecSys 2024\u8bba\u6587\u672a\u8bf4\u660e\u6570\u636e\u96c6\u9009\u62e9\u7406\u7531\uff0cAPS\u867d\u53ef\u6307\u5bfc\u4f46\u7f3a\u4e4f\u4ea4\u4e92\u5de5\u5177\uff0c\u672c\u6587\u4ecb\u7ecdAPS Explorer\u7528\u4e8e\u4ea4\u4e92\u5f0f\u63a2\u7d22APS\u4ee5\u5b9e\u73b0\u6570\u636e\u9a71\u52a8\u7684\u6570\u636e\u96c6\u9009\u62e9\u3002", "motivation": "\u6570\u636e\u96c6\u9009\u62e9\u5bf9\u79bb\u7ebf\u63a8\u8350\u7cfb\u7edf\u5b9e\u9a8c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u591a\u6570\u8bba\u6587\u672a\u8bf4\u660e\u9009\u62e9\u7406\u7531\uff0c\u4e14APS\u7f3a\u4e4f\u76f4\u89c2\u4ea4\u4e92\u5de5\u5177\uff0c\u9650\u5236\u5176\u5e94\u7528\u3002", "method": "\u5f15\u5165\u57fa\u4e8eWeb\u7684\u53ef\u89c6\u5316\u5de5\u5177APS Explorer\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0fPCA\u56fe\u3001\u52a8\u6001\u5143\u7279\u5f81\u8868\u548c\u6210\u5bf9\u7b97\u6cd5\u6027\u80fd\u53ef\u89c6\u5316\u4e09\u4e2a\u4ea4\u4e92\u529f\u80fd\u3002", "result": "\u63d0\u51fa\u4e86APS Explorer\u5de5\u5177\u3002", "conclusion": "APS Explorer\u53ef\u7528\u4e8e\u4ea4\u4e92\u5f0fAPS\u63a2\u7d22\uff0c\u5b9e\u73b0\u6570\u636e\u9a71\u52a8\u7684\u6570\u636e\u96c6\u9009\u62e9\u3002"}}
{"id": "2508.19785", "pdf": "https://arxiv.org/pdf/2508.19785", "abs": "https://arxiv.org/abs/2508.19785", "authors": ["Barbara Geissmann", "Stefano Leucci", "Chih-Hung Liu", "Paolo Penna"], "title": "An Optimal Sorting Algorithm for Persistent Random Comparison Faults", "categories": ["cs.DS"], "comment": null, "summary": "We consider the problem of sorting $n$ elements subject to persistent random\ncomparison errors. In this problem, each comparison between two elements can be\nwrong with some fixed (small) probability $p$, and comparing the same pair of\nelements multiple times always yields the same result. Sorting perfectly in\nthis model is impossible, and the objective is to minimize the dislocation of\neach element in the output sequence, i.e., the difference between its position\nin the sequence and its true rank.\n  In this paper, we present the first $O(n\\log n)$-time sorting algorithm that\nguarantees both $O(\\log n)$ maximum dislocation and $O(n)$ total dislocation\nwith high probability when $p<\\frac{1}{4}$. This settles the time complexity\nsorting with persistent comparison errors in the given range of $p$ and shows\nthat comparison errors do not increase its computational difficulty. Indeed,\n$\\Omega(n\\log n)$ time is necessary to archive a maximum dislocation of $O(\\log\nn)$ even without comparison errors. Moreover, we prove that no algorithm can\nguarantee a maximum dislocation of $o(\\log n)$ with high probability, nor a\ntotal dislocation of $o(n)$ in expectation.\n  To develop our sorting algorithm, we solve two related sub-problems, which\nmight be of independent interest. More precisely, we show that $O(\\log n)$ time\nsuffices to find a position in which to insert a new element $x$ in an\nalmost-sorted sequence $S$ of $n$ elements having dislocation at most\n$d=\\Omega(\\log n)$, so that the dislocation of $x$ in the resulting sequence is\n$O(d)$ with high probability (which can be equivalently thought as the problem\nof estimating the rank of $x$ in $S$). We also show that the maximum (resp.\ntotal) dislocation of an approximately sorted sequence $S$ of $n$ elements can\nbe lowered to $O(\\log n)$ (resp. $O(n)$) in $O(nd)$ time, w.h.p., where $d$ is\nan upper bound on the maximum dislocation of $S$.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5b58\u5728\u6301\u7eed\u968f\u673a\u6bd4\u8f83\u9519\u8bef\u7684n\u4e2a\u5143\u7d20\u6392\u5e8f\u95ee\u9898\uff0c\u63d0\u51fa\u9996\u4e2aO(nlog n)\u65f6\u95f4\u590d\u6742\u5ea6\u6392\u5e8f\u7b97\u6cd5\uff0c\u8bc1\u660e\u6bd4\u8f83\u9519\u8bef\u4e0d\u589e\u52a0\u8ba1\u7b97\u96be\u5ea6\uff0c\u5e76\u89e3\u51b3\u4e24\u4e2a\u76f8\u5173\u5b50\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5b58\u5728\u6301\u7eed\u968f\u673a\u6bd4\u8f83\u9519\u8bef\u65f6\u7684\u5143\u7d20\u6392\u5e8f\u95ee\u9898\uff0c\u6700\u5c0f\u5316\u8f93\u51fa\u5e8f\u5217\u4e2d\u5143\u7d20\u7684\u9519\u4f4d\u3002", "method": "\u89e3\u51b3\u4e24\u4e2a\u76f8\u5173\u5b50\u95ee\u9898\u6765\u5f00\u53d1\u6392\u5e8f\u7b97\u6cd5\uff0c\u5305\u62ec\u5728\u51e0\u4e4e\u6709\u5e8f\u5e8f\u5217\u4e2d\u63d2\u5165\u65b0\u5143\u7d20\u548c\u964d\u4f4e\u8fd1\u4f3c\u6709\u5e8f\u5e8f\u5217\u7684\u9519\u4f4d\u3002", "result": "\u63d0\u51faO(nlog n)\u65f6\u95f4\u6392\u5e8f\u7b97\u6cd5\uff0c\u4fdd\u8bc1\u5728p < 1/4\u65f6\u6700\u5927\u9519\u4f4dO(log n)\u548c\u603b\u9519\u4f4dO(n)\uff1b\u8bc1\u660e\u65e0\u6cd5\u4fdd\u8bc1\u6700\u5927\u9519\u4f4do(log n)\u548c\u603b\u671f\u671b\u9519\u4f4do(n)\u3002", "conclusion": "\u5728\u7ed9\u5b9ap\u8303\u56f4\u5185\u89e3\u51b3\u6392\u5e8f\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u8868\u660e\u6bd4\u8f83\u9519\u8bef\u4e0d\u589e\u52a0\u8ba1\u7b97\u96be\u5ea6\u3002"}}
{"id": "2508.19558", "pdf": "https://arxiv.org/pdf/2508.19558", "abs": "https://arxiv.org/abs/2508.19558", "authors": ["Zhuohao Li", "Wenqing Chen", "Jianxing Yu", "Zhichao Lu"], "title": "Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking", "categories": ["cs.SE", "cs.CL", "cs.PL"], "comment": null, "summary": "Embedding models have demonstrated strong performance in tasks like\nclustering, retrieval, and feature extraction while offering computational\nadvantages over generative models and cross-encoders. Benchmarks such as MTEB\nhave shown that text embeddings from large language models (LLMs) capture rich\nsemantic information, but their ability to reflect code-level functional\nsemantics remains unclear. Existing studies largely focus on code clone\ndetection, which emphasizes syntactic similarity and overlooks functional\nunderstanding. In this paper, we focus on the functional consistency of LLM\ncode embeddings, which determines if two code snippets perform the same\nfunction regardless of syntactic differences. We propose a novel data synthesis\nframework called Functionality-Oriented Code Self-Evolution to construct\ndiverse and challenging benchmarks. Specifically, we define code examples\nacross four semantic and syntactic categories and find that existing datasets\npredominantly capture syntactic properties. Our framework generates four unique\nvariations from a single code instance, providing a broader spectrum of code\nexamples that better reflect functional differences. Extensive experiments on\nthree downstream tasks-code clone detection, code functional consistency\nidentification, and code retrieval-demonstrate that embedding models\nsignificantly improve their performance when trained on our evolved datasets.\nThese results highlight the effectiveness and generalization of our data\nsynthesis framework, advancing the functional understanding of code.", "AI": {"tldr": "\u672c\u6587\u5173\u6ce8\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u5d4c\u5165\u7684\u529f\u80fd\u4e00\u81f4\u6027\uff0c\u63d0\u51fa\u9762\u5411\u529f\u80fd\u7684\u4ee3\u7801\u81ea\u8fdb\u5316\u6570\u636e\u5408\u6210\u6846\u67b6\u6784\u5efa\u57fa\u51c6\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u8fdb\u5316\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u53ef\u63d0\u5347\u5d4c\u5165\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\uff0c\u5f3a\u8c03\u8bed\u6cd5\u76f8\u4f3c\u6027\u800c\u5ffd\u89c6\u529f\u80fd\u7406\u89e3\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u5d4c\u5165\u53cd\u6620\u4ee3\u7801\u7ea7\u529f\u80fd\u8bed\u4e49\u7684\u80fd\u529b\u4e0d\u660e\u3002", "method": "\u63d0\u51fa\u9762\u5411\u529f\u80fd\u7684\u4ee3\u7801\u81ea\u8fdb\u5316\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u5b9a\u4e49\u56db\u7c7b\u8bed\u4e49\u548c\u8bed\u6cd5\u4ee3\u7801\u793a\u4f8b\uff0c\u4ece\u5355\u4e2a\u4ee3\u7801\u5b9e\u4f8b\u751f\u6210\u56db\u79cd\u53d8\u4f53\u3002", "result": "\u5728\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u3001\u529f\u80fd\u4e00\u81f4\u6027\u8bc6\u522b\u548c\u4ee3\u7801\u68c0\u7d22\u4e09\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e0a\uff0c\u5728\u8fdb\u5316\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u5d4c\u5165\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u5408\u6210\u6846\u67b6\u6709\u6548\u4e14\u5177\u6709\u6cdb\u5316\u6027\uff0c\u63a8\u52a8\u4e86\u4ee3\u7801\u7684\u529f\u80fd\u7406\u89e3\u3002"}}
{"id": "2508.19383", "pdf": "https://arxiv.org/pdf/2508.19383", "abs": "https://arxiv.org/abs/2508.19383", "authors": ["Daoyuan Jin", "Nick Gunner", "Niko Carvajal Janke", "Shivranjani Baruah", "Kaitlin M. Gold", "Yu Jiang"], "title": "Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Modern plant science increasingly relies on large, heterogeneous datasets,\nbut challenges in experimental design, data preprocessing, and reproducibility\nhinder research throughput. Here we introduce Aleks, an AI-powered multi-agent\nsystem that integrates domain knowledge, data analysis, and machine learning\nwithin a structured framework to autonomously conduct data-driven scientific\ndiscovery. Once provided with a research question and dataset, Aleks\niteratively formulated problems, explored alternative modeling strategies, and\nrefined solutions across multiple cycles without human intervention. In a case\nstudy on grapevine red blotch disease, Aleks progressively identified\nbiologically meaningful features and converged on interpretable models with\nrobust performance. Ablation studies underscored the importance of domain\nknowledge and memory for coherent outcomes. This exploratory work highlights\nthe promise of agentic AI as an autonomous collaborator for accelerating\nscientific discovery in plant sciences.", "AI": {"tldr": "\u4ecb\u7ecdAI\u591a\u667a\u80fd\u4f53\u7cfb\u7edfAleks\u52a9\u529b\u690d\u7269\u79d1\u5b66\u6570\u636e\u9a71\u52a8\u53d1\u73b0\uff0c\u4ee5\u8461\u8404\u7ea2\u75d8\u75c5\u4e3a\u4f8b\u9a8c\u8bc1\u5176\u6548\u679c\uff0c\u51f8\u663e\u667a\u80fd\u4f53AI\u6f5c\u529b\u3002", "motivation": "\u73b0\u4ee3\u690d\u7269\u79d1\u5b66\u4f9d\u8d56\u5927\u6570\u636e\u96c6\uff0c\u4f46\u5b9e\u9a8c\u8bbe\u8ba1\u3001\u6570\u636e\u9884\u5904\u7406\u548c\u53ef\u91cd\u590d\u6027\u95ee\u9898\u963b\u788d\u7814\u7a76\u6548\u7387\uff0c\u9700\u5de5\u5177\u89e3\u51b3\u3002", "method": "\u5f15\u5165Aleks\u7cfb\u7edf\uff0c\u5b83\u5728\u7ed3\u6784\u5316\u6846\u67b6\u5185\u6574\u5408\u9886\u57df\u77e5\u8bc6\u3001\u6570\u636e\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\uff0c\u80fd\u5728\u65e0\u4eba\u5de5\u5e72\u9884\u4e0b\u8fed\u4ee3\u5206\u6790\u3002", "result": "\u5728\u8461\u8404\u7ea2\u75d8\u75c5\u6848\u4f8b\u4e2d\uff0cAleks\u8bc6\u522b\u51fa\u6709\u751f\u7269\u5b66\u610f\u4e49\u7279\u5f81\uff0c\u5f97\u51fa\u6027\u80fd\u7a33\u5065\u7684\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u6d88\u878d\u5b9e\u9a8c\u5f3a\u8c03\u9886\u57df\u77e5\u8bc6\u548c\u8bb0\u5fc6\u91cd\u8981\u6027\u3002", "conclusion": "\u667a\u80fd\u4f53AI\u6709\u671b\u6210\u4e3a\u690d\u7269\u79d1\u5b66\u52a0\u901f\u79d1\u7814\u53d1\u73b0\u7684\u81ea\u4e3b\u534f\u4f5c\u4f19\u4f34\u3002"}}
{"id": "2508.19841", "pdf": "https://arxiv.org/pdf/2508.19841", "abs": "https://arxiv.org/abs/2508.19841", "authors": ["Fahime Seyedheydari", "Kevin Conley", "Simo S\u00e4rkk\u00e4"], "title": "Conditional Normalizing Flow Surrogate for Monte Carlo Prediction of Radiative Properties in Nanoparticle-Embedded Layers", "categories": ["stat.ML", "cs.LG", "physics.optics"], "comment": "Version of record (publishers PDF) from META 2025 (CC BY). Please\n  cite the proceedings", "summary": "We present a probabilistic, data-driven surrogate model for predicting the\nradiative properties of nanoparticle embedded scattering media. The model uses\nconditional normalizing flows, which learn the conditional distribution of\noptical outputs, including reflectance, absorbance, and transmittance, given\ninput parameters such as the absorption coefficient, scattering coefficient,\nanisotropy factor, and particle size distribution. We generate training data\nusing Monte Carlo radiative transfer simulations, with optical properties\nderived from Mie theory. Unlike conventional neural networks, the conditional\nnormalizing flow model yields full posterior predictive distributions, enabling\nboth accurate forecasts and principled uncertainty quantification. Our results\ndemonstrate that this model achieves high predictive accuracy and reliable\nuncertainty estimates, establishing it as a powerful and efficient surrogate\nfor radiative transfer simulations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u5f52\u4e00\u5316\u6d41\u7684\u6982\u7387\u6570\u636e\u9a71\u52a8\u66ff\u4ee3\u6a21\u578b\u9884\u6d4b\u7eb3\u7c73\u7c92\u5b50\u6563\u5c04\u4ecb\u8d28\u8f90\u5c04\u7279\u6027\uff0c\u7ed3\u679c\u663e\u793a\u9ad8\u7cbe\u5ea6\u4e0e\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u80fd\u51c6\u786e\u9884\u6d4b\u7eb3\u7c73\u7c92\u5b50\u5d4c\u5165\u6563\u5c04\u4ecb\u8d28\u8f90\u5c04\u7279\u6027\u5e76\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u5f52\u4e00\u5316\u6d41\u5b66\u4e60\u5149\u5b66\u8f93\u51fa\u7684\u6761\u4ef6\u5206\u5e03\uff0c\u7528\u8499\u7279\u5361\u7f57\u8f90\u5c04\u4f20\u8f93\u6a21\u62df\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u5149\u5b66\u7279\u6027\u57fa\u4e8e\u7c73\u6c0f\u7406\u8bba\u3002", "result": "\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u6a21\u578b\u662f\u8f90\u5c04\u4f20\u8f93\u6a21\u62df\u5f3a\u5927\u4e14\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2508.19920", "pdf": "https://arxiv.org/pdf/2508.19920", "abs": "https://arxiv.org/abs/2508.19920", "authors": ["Matthew Meek", "Guy Tallent", "Thomas Breimer", "James Gaskell", "Abhay Kashyap", "Atharv Tekurkar", "Jonathan Fischman", "Luodi Wang", "Viet-Dung Nguyen", "John Rieffel"], "title": "Walk the Robot: Exploring Soft Robotic Morphological Communication driven by Spiking Neural Networks", "categories": ["cs.NE"], "comment": null, "summary": "Recently, researchers have explored control methods that embrace nonlinear\ndynamic coupling instead of suppressing it. Such designs leverage dynamical\ncoupling for communication between different parts of the robot. Morphological\ncommunication refers to when those dynamics can be used as an emergent data bus\nto facilitate coordination among independent controller modules within the same\nrobot. Previous research with tensegrity-based robot designs has shown that\nevolutionary learning models that evolve spiking neural networks (SNN) as robot\ncontrol mechanisms are effective for controlling non-rigid robots. Our own\nresearch explores the emergence of morphological communication in an SNN-based\nsimulated soft robot in theEvoGym environment.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22SNN\u6a21\u62df\u8f6f\u673a\u5668\u4eba\u4e2d\u5f62\u6001\u901a\u4fe1\u7684\u51fa\u73b0\uff0c\u6b64\u524d\u7814\u7a76\u8868\u660eSNN\u7528\u4e8e\u975e\u521a\u6027\u673a\u5668\u4eba\u63a7\u5236\u6709\u6548\u3002", "motivation": "\u5229\u7528\u975e\u7ebf\u6027\u52a8\u6001\u8026\u5408\u8fdb\u884c\u673a\u5668\u4eba\u63a7\u5236\uff0c\u7814\u7a76SNN\u6a21\u62df\u8f6f\u673a\u5668\u4eba\u4e2d\u5f62\u6001\u901a\u4fe1\u7684\u51fa\u73b0\u3002", "method": "\u5728EvoGym\u73af\u5883\u4e2d\u63a2\u7d22\u57fa\u4e8eSNN\u7684\u6a21\u62df\u8f6f\u673a\u5668\u4eba\u3002", "result": "\u672a\u63d0\u53ca\u3002", "conclusion": "\u672a\u63d0\u53ca\u3002"}}
{"id": "2508.19372", "pdf": "https://arxiv.org/pdf/2508.19372", "abs": "https://arxiv.org/abs/2508.19372", "authors": ["Zikun Fu", "Chen Yang", "Kourosh Davoudi", "Ken Q. Pu"], "title": "Database Entity Recognition with Data Augmentation and Deep Learning", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "comment": "6 pages, 5 figures. Accepted at IEEE 26th International Conference on\n  Information Reuse and Integration for Data Science (IRI 2025), San Jose,\n  California, August 6-8, 2025", "summary": "This paper addresses the challenge of Database Entity Recognition (DB-ER) in\nNatural Language Queries (NLQ). We present several key contributions to advance\nthis field: (1) a human-annotated benchmark for DB-ER task, derived from\npopular text-to-sql benchmarks, (2) a novel data augmentation procedure that\nleverages automatic annotation of NLQs based on the corresponding SQL queries\nwhich are available in popular text-to-SQL benchmarks, (3) a specialized\nlanguage model based entity recognition model using T5 as a backbone and two\ndown-stream DB-ER tasks: sequence tagging and token classification for\nfine-tuning of backend and performing DB-ER respectively. We compared our DB-ER\ntagger with two state-of-the-art NER taggers, and observed better performance\nin both precision and recall for our model. The ablation evaluation shows that\ndata augmentation boosts precision and recall by over 10%, while fine-tuning of\nthe T5 backbone boosts these metrics by 5-10%.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u7684\u6570\u636e\u5e93\u5b9e\u4f53\u8bc6\u522b\u6311\u6218\uff0c\u63d0\u51fa\u57fa\u51c6\u3001\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u548c\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bc6\u522b\u6a21\u578b\uff0c\u5bf9\u6bd4\u663e\u793a\u6027\u80fd\u66f4\u597d\uff0c\u6d88\u878d\u8bc4\u4f30\u8868\u660e\u6570\u636e\u589e\u5f3a\u548c\u5fae\u8c03\u9aa8\u5e72\u6a21\u578b\u80fd\u63d0\u5347\u6307\u6807\u3002", "motivation": "\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u6570\u636e\u5e93\u5b9e\u4f53\u8bc6\u522b\uff08DB - ER\uff09\u7684\u6311\u6218\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002", "method": "1. \u4ece\u6d41\u884c\u6587\u672c\u5230SQL\u57fa\u51c6\u4e2d\u5bfc\u51fa\u4eba\u7c7b\u6ce8\u91ca\u7684DB - ER\u4efb\u52a1\u57fa\u51c6\uff1b2. \u5229\u7528\u6d41\u884c\u6587\u672c\u5230SQL\u57fa\u51c6\u4e2d\u7684SQL\u67e5\u8be2\u5bf9NLQ\u8fdb\u884c\u81ea\u52a8\u6ce8\u91ca\u7684\u6570\u636e\u589e\u5f3a\u7a0b\u5e8f\uff1b3. \u4ee5T5\u4e3a\u9aa8\u5e72\u7684\u4e13\u4e1a\u8bed\u8a00\u6a21\u578b\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\uff0c\u6709\u5e8f\u5217\u6807\u8bb0\u548c\u4ee4\u724c\u5206\u7c7b\u4e24\u4e2a\u4e0b\u6e38\u4efb\u52a1\u7528\u4e8e\u5fae\u8c03\u540e\u7aef\u548c\u6267\u884cDB - ER\u3002", "result": "\u4e0e\u4e24\u4e2a\u6700\u5148\u8fdb\u7684NER\u6807\u8bb0\u5668\u76f8\u6bd4\uff0c\u672c\u6587\u7684DB - ER\u6807\u8bb0\u5668\u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u4e0a\u8868\u73b0\u66f4\u597d\u3002\u6d88\u878d\u8bc4\u4f30\u663e\u793a\u6570\u636e\u589e\u5f3a\u4f7f\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u63d0\u9ad8\u8d85\u8fc710%\uff0cT5\u9aa8\u5e72\u5fae\u8c03\u4f7f\u8fd9\u4e9b\u6307\u6807\u63d0\u9ad85 - 10%\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u51c6\u3001\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u548c\u8bc6\u522b\u6a21\u578b\u5728\u6570\u636e\u5e93\u5b9e\u4f53\u8bc6\u522b\u4e0a\u6548\u679c\u826f\u597d\uff0c\u6570\u636e\u589e\u5f3a\u548c\u9aa8\u5e72\u5fae\u8c03\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.19495", "pdf": "https://arxiv.org/pdf/2508.19495", "abs": "https://arxiv.org/abs/2508.19495", "authors": ["Muhammad Ahmed Mohsin", "Junaid Ahmad", "Muhammad Hamza Nawaz", "Muhammad Ali Jamshed"], "title": "Towards 6G Intelligence: The Role of Generative AI in Future Wireless Networks", "categories": ["cs.DC", "cs.LG", "eess.SP"], "comment": "Submitted as a chapter to the book Ambient Intelligence for 6G", "summary": "Ambient intelligence (AmI) is a computing paradigm in which physical\nenvironments are embedded with sensing, computation, and communication so they\ncan perceive people and context, decide appropriate actions, and respond\nautonomously. Realizing AmI at global scale requires sixth generation (6G)\nwireless networks with capabilities for real time perception, reasoning, and\naction aligned with human behavior and mobility patterns. We argue that\nGenerative Artificial Intelligence (GenAI) is the creative core of such\nenvironments. Unlike traditional AI, GenAI learns data distributions and can\ngenerate realistic samples, making it well suited to close key AmI gaps,\nincluding generating synthetic sensor and channel data in under observed areas,\ntranslating user intent into compact, semantic messages, predicting future\nnetwork conditions for proactive control, and updating digital twins without\ncompromising privacy.\n  This chapter reviews foundational GenAI models, GANs, VAEs, diffusion models,\nand generative transformers, and connects them to practical AmI use cases,\nincluding spectrum sharing, ultra reliable low latency communication,\nintelligent security, and context aware digital twins. We also examine how 6G\nenablers, such as edge and fog computing, IoT device swarms, intelligent\nreflecting surfaces (IRS), and non terrestrial networks, can host or accelerate\ndistributed GenAI. Finally, we outline open challenges in energy efficient on\ndevice training, trustworthy synthetic data, federated generative learning, and\nAmI specific standardization. We show that GenAI is not a peripheral addition,\nbut a foundational element for transforming 6G from a faster network into an\nambient intelligent ecosystem.", "AI": {"tldr": "\u6587\u7ae0\u8ba8\u8bba\u5c06\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5e94\u7528\u4e8e6G\u65e0\u7ebf\u7f51\u7edc\u4ee5\u5b9e\u73b0\u73af\u5883\u667a\u80fd\uff08AmI\uff09\uff0c\u56de\u987eGenAI\u6a21\u578b\u5e76\u8fde\u63a5\u5b9e\u9645\u5e94\u7528\uff0c\u6307\u51fa6G\u4f7f\u80fd\u6280\u672f\u53ef\u652f\u6301GenAI\uff0c\u8fd8\u5217\u51fa\u5f00\u653e\u6311\u6218\uff0c\u5f3a\u8c03GenAI\u662f6G\u5411\u73af\u5883\u667a\u80fd\u751f\u6001\u7cfb\u7edf\u8f6c\u53d8\u7684\u57fa\u7840\u5143\u7d20\u3002", "motivation": "\u5b9e\u73b0\u5168\u7403\u89c4\u6a21\u7684\u73af\u5883\u667a\u80fd\u9700\u89816G\u65e0\u7ebf\u7f51\u7edc\uff0c\u800cGenAI\u80fd\u5f25\u8865AmI\u5173\u952e\u5dee\u8ddd\uff0c\u56e0\u6b64\u63a2\u8ba8\u5176\u57286G\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u56de\u987e\u57fa\u7840GenAI\u6a21\u578b\uff0c\u5c06\u5176\u4e0e\u5b9e\u9645AmI\u7528\u4f8b\u76f8\u8fde\u63a5\uff0c\u7814\u7a766G\u4f7f\u80fd\u6280\u672f\u5bf9\u5206\u5e03\u5f0fGenAI\u7684\u652f\u6301\u3002", "result": "\u660e\u786eGenAI\u53ef\u5e94\u7528\u4e8e\u9891\u8c31\u5171\u4eab\u3001\u8d85\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u7b49\u5b9e\u9645\u573a\u666f\uff0c6G\u4f7f\u80fd\u6280\u672f\u80fd\u627f\u8f7d\u6216\u52a0\u901f\u5206\u5e03\u5f0fGenAI\u3002", "conclusion": "GenAI\u4e0d\u662f6G\u7684\u9644\u52a0\u5143\u7d20\uff0c\u800c\u662f\u5c066G\u8f6c\u53d8\u4e3a\u73af\u5883\u667a\u80fd\u751f\u6001\u7cfb\u7edf\u7684\u57fa\u7840\u5143\u7d20\u3002"}}
{"id": "2508.19507", "pdf": "https://arxiv.org/pdf/2508.19507", "abs": "https://arxiv.org/abs/2508.19507", "authors": ["Kyungho Kim", "Sunwoo Kim", "Geon Lee", "Kijung Shin"], "title": "A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "CIKM 2025", "summary": "In e-commerce, where users face a vast array of possible item choices,\nrecommender systems are vital for helping them discover suitable items they\nmight otherwise overlook. While many recommender systems primarily rely on a\nuser's purchase history, recent multi-behavior recommender systems incorporate\nvarious auxiliary user behaviors, such as item clicks and cart additions, to\nenhance recommendations. Despite their overall performance gains, their\neffectiveness varies considerably between visited items (i.e., those a user has\ninteracted with through auxiliary behaviors) and unvisited items (i.e., those\nwith which the user has had no such interactions). Specifically, our analysis\nreveals that (1) existing multi-behavior recommender systems exhibit a\nsignificant gap in recommendation quality between the two item types (visited\nand unvisited items) and (2) achieving strong performance on both types with a\nsingle model architecture remains challenging. To tackle these issues, we\npropose a novel multi-behavior recommender system, MEMBER. It employs a\nmixture-of-experts framework, with experts designed to recommend the two item\ntypes, respectively. Each expert is trained using a self-supervised method\nspecialized for its design goal. In our comprehensive experiments, we show the\neffectiveness of MEMBER across both item types, achieving up to 65.46\\%\nperformance gain over the best competitor in terms of Hit Ratio@20.", "AI": {"tldr": "\u7535\u5546\u63a8\u8350\u7cfb\u7edf\u91cd\u8981\uff0c\u73b0\u6709\u591a\u884c\u4e3a\u63a8\u8350\u7cfb\u7edf\u5bf9\u5df2\u8bbf\u95ee\u548c\u672a\u8bbf\u95ee\u5546\u54c1\u63a8\u8350\u6548\u679c\u6709\u5dee\u5f02\uff0c\u63d0\u51faMEMBER\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u591a\u884c\u4e3a\u63a8\u8350\u7cfb\u7edf\u5bf9\u5df2\u8bbf\u95ee\u548c\u672a\u8bbf\u95ee\u5546\u54c1\u63a8\u8350\u8d28\u91cf\u6709\u5dee\u8ddd\uff0c\u5355\u6a21\u578b\u67b6\u6784\u96be\u517c\u987e\u4e24\u8005\u6027\u80fd\u3002", "method": "\u63d0\u51faMEMBER\u7cfb\u7edf\uff0c\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\uff0c\u4e0d\u540c\u4e13\u5bb6\u5206\u522b\u63a8\u8350\u4e24\u7c7b\u5546\u54c1\uff0c\u7528\u81ea\u76d1\u7763\u65b9\u6cd5\u8bad\u7ec3\u4e13\u5bb6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMEMBER\u5728\u4e24\u7c7b\u5546\u54c1\u4e0a\u5747\u6709\u6548\uff0c\u5728Hit Ratio@20\u6307\u6807\u4e0a\u6bd4\u6700\u4f73\u7ade\u54c1\u6700\u591a\u63d0\u534765.46%\u3002", "conclusion": "MEMBER\u7cfb\u7edf\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u591a\u884c\u4e3a\u63a8\u8350\u7cfb\u7edf\u5728\u4e0d\u540c\u7c7b\u578b\u5546\u54c1\u63a8\u8350\u4e0a\u7684\u95ee\u9898\u3002"}}
{"id": "2508.19802", "pdf": "https://arxiv.org/pdf/2508.19802", "abs": "https://arxiv.org/abs/2508.19802", "authors": ["Alexander Dobler", "Tim Hegemann", "Martin N\u00f6llenburg", "Alexander Wolff"], "title": "Optimizing Wiggle in Storylines", "categories": ["cs.DS"], "comment": "23 pages, 15 figures", "summary": "A storyline visualization shows interactions between characters over time.\nEach character is represented by an x-monotone curve. Time is mapped to the\nx-axis, and groups of characters that interact at a particular point $t$ in\ntime must be ordered consecutively in the y-dimension at $x=t$. The predominant\nobjective in storyline optimization so far has been the minimization of\ncrossings between (blocks of) characters. Building on this work, we investigate\nanother important, but less studied quality criterion, namely the minimization\nof wiggle, i.e., the amount of vertical movement of the characters over time.\nGiven a storyline instance together with an ordering of the characters at any\npoint in time, we show that wiggle count minimization is NP-complete. In\ncontrast, we provide algorithms based on mathematical programming to solve\nlinear wiggle height minimization and quadratic wiggle height minimization\nefficiently. Finally, we introduce a new method for routing character curves\nthat focuses on keeping distances between neighboring curves constant as long\nas they run in parallel. We have implemented our algorithms, and we conduct a\ncase study that explores the differences between the three optimization\nobjectives. We use existing benchmark data, but we also present a new use case\nfor storylines, namely the visualization of rolling stock schedules in railway\noperation.", "AI": {"tldr": "\u7814\u7a76\u6545\u4e8b\u7ebf\u53ef\u89c6\u5316\u4f18\u5316\uff0c\u63a2\u8ba8\u6700\u5c0f\u5316\u6446\u52a8\uff0c\u8bc1\u660e\u6446\u52a8\u8ba1\u6570\u6700\u5c0f\u5316\u662fNP\u5b8c\u5168\u95ee\u9898\uff0c\u63d0\u4f9b\u89e3\u51b3\u7ebf\u6027\u548c\u4e8c\u6b21\u6446\u52a8\u9ad8\u5ea6\u6700\u5c0f\u5316\u7684\u7b97\u6cd5\uff0c\u5f15\u5165\u65b0\u7684\u66f2\u7ebf\u8def\u7531\u65b9\u6cd5\u5e76\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u6545\u4e8b\u7ebf\u4f18\u5316\u4e3b\u8981\u5173\u6ce8\u89d2\u8272\u4ea4\u53c9\u6700\u5c0f\u5316\uff0c\u672c\u6587\u7814\u7a76\u8f83\u5c11\u88ab\u5173\u6ce8\u7684\u6446\u52a8\u6700\u5c0f\u5316\u8fd9\u4e00\u91cd\u8981\u8d28\u91cf\u6807\u51c6\u3002", "method": "\u8bc1\u660e\u6446\u52a8\u8ba1\u6570\u6700\u5c0f\u5316\u7684NP\u5b8c\u5168\u6027\uff0c\u57fa\u4e8e\u6570\u5b66\u89c4\u5212\u63d0\u4f9b\u89e3\u51b3\u7ebf\u6027\u548c\u4e8c\u6b21\u6446\u52a8\u9ad8\u5ea6\u6700\u5c0f\u5316\u7684\u7b97\u6cd5\uff0c\u5f15\u5165\u4fdd\u6301\u76f8\u90bb\u66f2\u7ebf\u5e73\u884c\u65f6\u8ddd\u79bb\u6052\u5b9a\u7684\u66f2\u7ebf\u8def\u7531\u65b9\u6cd5\u3002", "result": "\u5b9e\u73b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u63a2\u7d22\u4e09\u79cd\u4f18\u5316\u76ee\u6807\u7684\u5dee\u5f02\uff0c\u4f7f\u7528\u73b0\u6709\u57fa\u51c6\u6570\u636e\u5e76\u63d0\u51fa\u94c1\u8def\u8fd0\u8425\u4e2d\u6eda\u52a8\u8f66\u8f86\u65f6\u523b\u8868\u53ef\u89c6\u5316\u7684\u65b0\u7528\u4f8b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u65b9\u6cd5\u6709\u52a9\u4e8e\u6545\u4e8b\u7ebf\u53ef\u89c6\u5316\u7684\u4f18\u5316\uff0c\u4e14\u5728\u94c1\u8def\u8fd0\u8425\u53ef\u89c6\u5316\u4e2d\u6709\u65b0\u7684\u5e94\u7528\u3002"}}
{"id": "2508.19610", "pdf": "https://arxiv.org/pdf/2508.19610", "abs": "https://arxiv.org/abs/2508.19610", "authors": ["Kathrin Figl", "Maria Kirchner", "Sebastian Baltes", "Michael Felderer"], "title": "The Influence of Code Comments on the Perceived Helpfulness of Stack Overflow Posts", "categories": ["cs.SE"], "comment": "31 pages, 7 figures, 2 tables, to appear in the Empirical Software\n  Engineering journal", "summary": "Question-and-answer platforms such as Stack Overflow have become an important\nway for software developers to share and retrieve knowledge. However, reusing\npoorly understood code can lead to serious problems, such as bugs or security\nvulnerabilities. To better understand how code comments affect the perceived\nhelpfulness of Stack Overflow answers, we conducted an online experiment\nsimulating a Stack Overflow environment (n=91). The results indicate that both\nblock and inline comments are perceived as significantly more helpful than\nuncommented source code. Moreover, novices rated code snippets with block\ncomments as more helpful than those with inline comments. Interestingly, other\nsurface features, such as the position of an answer and its answer score, were\nconsidered less important. The content of Stack Overflow has been a major\nsource for training large language models. AI-based coding assistants such as\nGitHub Copilot, which are based on these models, might change the way Stack\nOverflow is used. However, our findings have implications beyond this specific\nplatform. First, they may help to improve the relevance of community-driven\nplatforms such as Stack Overflow, which provide human advice and explanations\nof code solutions, complementing AI-based support for software developers.\nSecond, since chat-based AI tools can be prompted to generate code in different\nways, knowing which properties influence perceived helpfulness might lead to\ntargeted prompting strategies to generate more readable code snippets.", "AI": {"tldr": "\u901a\u8fc7\u5728\u7ebf\u5b9e\u9a8c\u7814\u7a76\u4ee3\u7801\u6ce8\u91ca\u5bf9Stack Overflow\u7b54\u6848\u6709\u7528\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6ce8\u91ca\u6bd4\u65e0\u6ce8\u91ca\u4ee3\u7801\u66f4\u6709\u7528\uff0c\u65b0\u624b\u8ba4\u4e3a\u5757\u6ce8\u91ca\u6bd4\u884c\u5185\u6ce8\u91ca\u66f4\u6709\u7528\uff0c\u5176\u4ed6\u8868\u9762\u7279\u5f81\u8f83\u4e0d\u91cd\u8981\uff0c\u7814\u7a76\u7ed3\u679c\u6709\u5e7f\u6cdb\u610f\u4e49\u3002", "motivation": "\u4e86\u89e3\u4ee3\u7801\u6ce8\u91ca\u5982\u4f55\u5f71\u54cdStack Overflow\u7b54\u6848\u7684\u6709\u7528\u6027\uff0c\u89e3\u51b3\u590d\u7528\u7406\u89e3\u4e0d\u8db3\u7684\u4ee3\u7801\u53ef\u80fd\u5e26\u6765\u7684\u95ee\u9898\u3002", "method": "\u8fdb\u884c\u6a21\u62dfStack Overflow\u73af\u5883\u7684\u5728\u7ebf\u5b9e\u9a8c\uff0c\u6837\u672c\u91cfn = 91\u3002", "result": "\u5757\u6ce8\u91ca\u548c\u884c\u5185\u6ce8\u91ca\u90fd\u6bd4\u65e0\u6ce8\u91ca\u6e90\u4ee3\u7801\u66f4\u6709\u7528\uff0c\u65b0\u624b\u8ba4\u4e3a\u5757\u6ce8\u91ca\u4ee3\u7801\u7247\u6bb5\u6bd4\u884c\u5185\u6ce8\u91ca\u66f4\u6709\u7528\uff0c\u7b54\u6848\u4f4d\u7f6e\u548c\u5f97\u5206\u7b49\u8868\u9762\u7279\u5f81\u91cd\u8981\u6027\u8f83\u4f4e\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u6539\u8fdbStack Overflow\u7b49\u793e\u533a\u9a71\u52a8\u5e73\u53f0\u7684\u76f8\u5173\u6027\uff0c\u4e5f\u80fd\u4e3a\u57fa\u4e8e\u804a\u5929\u7684AI\u5de5\u5177\u751f\u6210\u66f4\u6613\u8bfb\u4ee3\u7801\u7247\u6bb5\u63d0\u4f9b\u9488\u5bf9\u6027\u63d0\u793a\u7b56\u7565\u3002"}}
{"id": "2508.19432", "pdf": "https://arxiv.org/pdf/2508.19432", "abs": "https://arxiv.org/abs/2508.19432", "authors": ["Yao Fu", "Xianxuan Long", "Runchao Li", "Haotian Yu", "Mu Sheng", "Xiaotian Han", "Yu Yin", "Pan Li"], "title": "Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs", "categories": ["cs.AI"], "comment": "Accepted to EMNLP2025 main conference (poster)", "summary": "Quantization enables efficient deployment of large language models (LLMs) in\nresource-constrained environments by significantly reducing memory and\ncomputation costs. While quantized LLMs often maintain performance on\nperplexity and zero-shot tasks, their impact on truthfulness-whether generating\ntruthful or deceptive responses-remains largely unexplored. In this work, we\nintroduce TruthfulnessEval, a comprehensive evaluation framework for assessing\nthe truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on\nLogical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on\nImitative Falsehoods. Using this framework, we examine mainstream quantization\ntechniques (ranging from 4-bit to extreme 2-bit) across several open-source\nLLMs. Surprisingly, we find that while quantized models retain internally\ntruthful representations, they are more susceptible to producing false outputs\nunder misleading prompts. To probe this vulnerability, we test 15 rephrased\nvariants of \"honest\", \"neutral\" and \"deceptive\" prompts and observe that\n\"deceptive\" prompts can override truth-consistent behavior, whereas \"honest\"\nand \"neutral\" prompts maintain stable outputs. Further, we reveal that\nquantized models \"know\" the truth internally yet still produce false outputs\nwhen guided by \"deceptive\" prompts via layer-wise probing and PCA\nvisualizations. Our findings provide insights into future designs of\nquantization-aware alignment and truthfulness interventions.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165TruthfulnessEval\u6846\u67b6\u8bc4\u4f30\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u771f\u5b9e\u6027\uff0c\u53d1\u73b0\u91cf\u5316\u6a21\u578b\u6613\u5728\u8bef\u5bfc\u6027\u63d0\u793a\u4e0b\u8f93\u51fa\u9519\u8bef\u7ed3\u679c\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u91cf\u5316\u611f\u77e5\u5bf9\u9f50\u548c\u771f\u5b9e\u6027\u5e72\u9884\u8bbe\u8ba1\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u53ef\u964d\u4f4e\u6210\u672c\uff0c\u4f46\u5bf9\u5176\u771f\u5b9e\u6027\u7684\u5f71\u54cd\u7814\u7a76\u8f83\u5c11\uff0c\u56e0\u6b64\u5f00\u5c55\u76f8\u5173\u8bc4\u4f30\u3002", "method": "\u5f15\u5165TruthfulnessEval\u6846\u67b6\uff0c\u4ece\u903b\u8f91\u63a8\u7406\u3001\u5e38\u8bc6\u3001\u6a21\u4eff\u6027\u865a\u5047\u4e09\u65b9\u9762\u8bc4\u4f30\uff1b\u6d4b\u8bd5\u4e0d\u540c\u91cf\u5316\u6280\u672f\u548c\u5f00\u6e90\u6a21\u578b\uff1b\u6d4b\u8bd515\u79cd\u4e0d\u540c\u7c7b\u578b\u63d0\u793a\u53d8\u4f53\uff1b\u8fdb\u884c\u5c42\u95f4\u63a2\u6d4b\u548cPCA\u53ef\u89c6\u5316\u3002", "result": "\u91cf\u5316\u6a21\u578b\u4fdd\u7559\u5185\u90e8\u771f\u5b9e\u8868\u793a\uff0c\u4f46\u5728\u8bef\u5bfc\u6027\u63d0\u793a\u4e0b\u66f4\u6613\u8f93\u51fa\u9519\u8bef\u7ed3\u679c\uff1b\u201c\u6b3a\u9a97\u6027\u201d\u63d0\u793a\u4f1a\u8986\u76d6\u771f\u5b9e\u4e00\u81f4\u884c\u4e3a\uff0c\u201c\u8bda\u5b9e\u201d\u548c\u201c\u4e2d\u7acb\u201d\u63d0\u793a\u8f93\u51fa\u7a33\u5b9a\uff1b\u91cf\u5316\u6a21\u578b\u5185\u90e8\u201c\u77e5\u9053\u201d\u771f\u76f8\uff0c\u4f46\u5728\u201c\u6b3a\u9a97\u6027\u201d\u63d0\u793a\u4e0b\u4ecd\u8f93\u51fa\u9519\u8bef\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u91cf\u5316\u611f\u77e5\u5bf9\u9f50\u548c\u771f\u5b9e\u6027\u5e72\u9884\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2508.19897", "pdf": "https://arxiv.org/pdf/2508.19897", "abs": "https://arxiv.org/abs/2508.19897", "authors": ["Luca Ambrogioni"], "title": "The Information Dynamics of Generative Diffusion", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Generative diffusion models have emerged as a powerful class of models in\nmachine learning, yet a unified theoretical understanding of their operation is\nstill developing. This perspective paper provides an integrated perspective on\ngenerative diffusion by connecting their dynamic, information-theoretic, and\nthermodynamic properties under a unified mathematical framework. We demonstrate\nthat the rate of conditional entropy production during generation (i.e. the\ngenerative bandwidth) is directly governed by the expected divergence of the\nscore function's vector field. This divergence, in turn, is linked to the\nbranching of trajectories and generative bifurcations, which we characterize as\nsymmetry-breaking phase transitions in the energy landscape. This synthesis\noffers a powerful insight: the process of generation is fundamentally driven by\nthe controlled, noise-induced breaking of (approximate) symmetries, where peaks\nin information transfer correspond to critical transitions between possible\noutcomes. The score function acts as a dynamic non-linear filter that regulates\nthe bandwidth of the noise by suppressing fluctuations that are incompatible\nwith the data.", "AI": {"tldr": "\u672c\u6587\u4ece\u7edf\u4e00\u6570\u5b66\u6846\u67b6\u4e3a\u751f\u6210\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u7efc\u5408\u89c6\u89d2\uff0c\u63ed\u793a\u751f\u6210\u8fc7\u7a0b\u53d7\u5bf9\u79f0\u6027\u7834\u7f3a\u9a71\u52a8\u53ca\u5206\u6570\u51fd\u6570\u4f5c\u7528\u3002", "motivation": "\u751f\u6210\u6269\u6563\u6a21\u578b\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u8ba4\u8bc6\uff0c\u4f5c\u8005\u65e8\u5728\u63d0\u4f9b\u7efc\u5408\u89c6\u89d2\u3002", "method": "\u5728\u7edf\u4e00\u6570\u5b66\u6846\u67b6\u4e0b\u8fde\u63a5\u751f\u6210\u6269\u6563\u6a21\u578b\u7684\u52a8\u6001\u3001\u4fe1\u606f\u8bba\u548c\u70ed\u529b\u5b66\u6027\u8d28\u3002", "result": "\u53d1\u73b0\u751f\u6210\u65f6\u6761\u4ef6\u71b5\u4ea7\u751f\u7387\u7531\u5206\u6570\u51fd\u6570\u5411\u91cf\u573a\u7684\u9884\u671f\u6563\u5ea6\u51b3\u5b9a\uff0c\u6563\u5ea6\u4e0e\u8f68\u8ff9\u5206\u652f\u548c\u751f\u6210\u5206\u53c9\u6709\u5173\uff0c\u751f\u6210\u7531\u566a\u58f0\u8bf1\u5bfc\u7684\u5bf9\u79f0\u6027\u7834\u7f3a\u9a71\u52a8\uff0c\u5206\u6570\u51fd\u6570\u8c03\u8282\u566a\u58f0\u5e26\u5bbd\u3002", "conclusion": "\u751f\u6210\u8fc7\u7a0b\u672c\u8d28\u4e0a\u7531\u53d7\u63a7\u7684\u3001\u566a\u58f0\u8bf1\u5bfc\u7684\uff08\u8fd1\u4f3c\uff09\u5bf9\u79f0\u6027\u7834\u7f3a\u9a71\u52a8\uff0c\u5206\u6570\u51fd\u6570\u8d77\u52a8\u6001\u975e\u7ebf\u6027\u6ee4\u6ce2\u4f5c\u7528\u3002"}}
{"id": "2508.19263", "pdf": "https://arxiv.org/pdf/2508.19263", "abs": "https://arxiv.org/abs/2508.19263", "authors": ["Anat Heilper", "Doron Singer"], "title": "Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "16 pages 9 images", "summary": "As deep learning models grow and deployment becomes more widespread, reducing\nthe storage and transmission costs of neural network weights has become\nincreasingly important. While prior work such as ZipNN has shown that lossless\ncompression methods - particularly those based on Huffman encoding\nfloating-point exponents can significantly reduce model sizes, these techniques\nhave primarily been applied to higher-precision formats such as FP32 and BF16.\nIn this work, we extend the ZipNN approach to lower-precision floating-point\nformats, specifically FP8 and FP4, which are gaining popularity for efficient\ninference. We design a compression method that separates and compresses the\nexponent and mantissa components independently using entropy coding. Our\nevaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also\ninvestigate the compressibility of key-value (K/V) cache tensors used in large\nlanguage models (LLMs), finding that they, too, exhibit compressible patterns,\nenabling memory savings during deployment.", "AI": {"tldr": "\u672c\u6587\u5c06ZipNN\u65b9\u6cd5\u6269\u5c55\u5230FP8\u548cFP4\u7b49\u4f4e\u7cbe\u5ea6\u6d6e\u70b9\u683c\u5f0f\uff0c\u8bbe\u8ba1\u72ec\u7acb\u538b\u7f29\u6307\u6570\u548c\u5c3e\u6570\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u663e\u793a\u6709\u9ad8\u538b\u7f29\u7387\uff0c\u8fd8\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578bK/V\u7f13\u5b58\u5f20\u91cf\u7684\u53ef\u538b\u7f29\u6027\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u589e\u957f\u548c\u90e8\u7f72\u5e7f\u6cdb\uff0c\u964d\u4f4e\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u7684\u5b58\u50a8\u548c\u4f20\u8f93\u6210\u672c\u6108\u53d1\u91cd\u8981\uff0c\u6b64\u524d\u65e0\u635f\u538b\u7f29\u65b9\u6cd5\u591a\u5e94\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u683c\u5f0f\uff0c\u672c\u6587\u5c06\u5176\u6269\u5c55\u5230\u4f4e\u7cbe\u5ea6\u683c\u5f0f\u3002", "method": "\u8bbe\u8ba1\u4e00\u79cd\u4f7f\u7528\u71b5\u7f16\u7801\u72ec\u7acb\u5206\u79bb\u548c\u538b\u7f29\u6307\u6570\u4e0e\u5c3e\u6570\u7ec4\u4ef6\u7684\u538b\u7f29\u65b9\u6cd5\u3002", "result": "BF16\u538b\u7f29\u7387\u8fbe62%\uff0cFP8\u8fbe83%\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578bK/V\u7f13\u5b58\u5f20\u91cf\u6709\u53ef\u538b\u7f29\u6a21\u5f0f\u3002", "conclusion": "\u5c06ZipNN\u6269\u5c55\u5230\u4f4e\u7cbe\u5ea6\u683c\u5f0f\u53ef\u884c\uff0c\u80fd\u6709\u6548\u964d\u4f4e\u5b58\u50a8\u6210\u672c\uff0cK/V\u7f13\u5b58\u5f20\u91cf\u4e5f\u53ef\u538b\u7f29\u4ee5\u8282\u7701\u90e8\u7f72\u5185\u5b58\u3002"}}
{"id": "2508.19803", "pdf": "https://arxiv.org/pdf/2508.19803", "abs": "https://arxiv.org/abs/2508.19803", "authors": ["Peter Fettke", "Wolfgang Reisig"], "title": "Towards a fundamental theory of modeling discrete systems", "categories": ["cs.SE", "cs.DB"], "comment": "6 pages, 2 figures, author prepared version of final manuscript\n  accepted at the 44th International Conference on Conceptual Modeling, 20-23\n  October 2025, Poitiers / Futuroscope, France, Workshop on Fundamentals of\n  Conceptual Modeling (FCM)", "summary": "Modeling is a central concern in both science and engineering. However, we\nneed a new fundamental theory to address the challenges of the digital age. In\nthis paper, we first explain why modeling is fundamental and which challenges\nmust be addressed in the digital world. As a main contribution, we introduce\nthe Heraklit modeling framework as a new approach to modeling. We conclude with\nsome general remarks. Future work will involve the correctness of modeling, the\nnotion of information, and the description of invariance in modeling.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5efa\u6a21\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u7684\u91cd\u8981\u6027\uff0c\u9700\u65b0\u7406\u8bba\u5e94\u5bf9\u6570\u5b57\u65f6\u4ee3\u6311\u6218\uff0c\u4ecb\u7ecdHeraklit\u5efa\u6a21\u6846\u67b6\u5e76\u63d0\u53ca\u672a\u6765\u5de5\u4f5c\u3002", "motivation": "\u89e3\u51b3\u6570\u5b57\u65f6\u4ee3\u5efa\u6a21\u9762\u4e34\u7684\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u57fa\u7840\u7406\u8bba\u3002", "method": "\u5f15\u5165Heraklit\u5efa\u6a21\u6846\u67b6\u4f5c\u4e3a\u65b0\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u7ae0\u7ed3\u5c3e\u7ed9\u51fa\u4e00\u4e9b\u4e00\u822c\u6027\u8bc4\u8bba\uff0c\u672a\u6765\u5de5\u4f5c\u6d89\u53ca\u5efa\u6a21\u6b63\u786e\u6027\u3001\u4fe1\u606f\u6982\u5ff5\u548c\u5efa\u6a21\u4e0d\u53d8\u6027\u63cf\u8ff0\u3002"}}
{"id": "2508.19559", "pdf": "https://arxiv.org/pdf/2508.19559", "abs": "https://arxiv.org/abs/2508.19559", "authors": ["Rongzhi Li", "Ruogu Du", "Zefang Chu", "Sida Zhao", "Chunlei Han", "Zuocheng Shi", "Yiwen Shao", "Huanle Han", "Long Huang", "Zherui Liu", "Shufan Liu"], "title": "Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Serving Large Language Models (LLMs) is a GPU-intensive task where\ntraditional autoscalers fall short, particularly for modern Prefill-Decode\n(P/D) disaggregated architectures. This architectural shift, while powerful,\nintroduces significant operational challenges, including inefficient use of\nheterogeneous hardware, network bottlenecks, and critical imbalances between\nprefill and decode stages. We introduce HeteroScale, a coordinated autoscaling\nframework that addresses the core challenges of P/D disaggregated serving.\nHeteroScale combines a topology-aware scheduler that adapts to heterogeneous\nhardware and network constraints with a novel metric-driven policy derived from\nthe first large-scale empirical study of autoscaling signals in production. By\nleveraging a single, robust metric to jointly scale prefill and decode pools,\nHeteroScale maintains architectural balance while ensuring efficient, adaptive\nresource management. Deployed in a massive production environment on tens of\nthousands of GPUs, HeteroScale has proven its effectiveness, increasing average\nGPU utilization by a significant 26.6 percentage points and saving hundreds of\nthousands of GPU-hours daily, all while upholding stringent service level\nobjectives.", "AI": {"tldr": "\u4f20\u7edf\u81ea\u52a8\u6269\u7f29\u5bb9\u5668\u5728\u670d\u52a1\u5927\u8bed\u8a00\u6a21\u578b\u7684P/D\u89e3\u8026\u67b6\u6784\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u672c\u6587\u63d0\u51faHeteroScale\u6846\u67b6\u89e3\u51b3\u6838\u5fc3\u6311\u6218\uff0c\u5728\u751f\u4ea7\u73af\u5883\u9a8c\u8bc1\u6709\u6548\uff0c\u63d0\u5347GPU\u5229\u7528\u7387\u5e76\u8282\u7701\u8d44\u6e90\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u6269\u7f29\u5bb9\u5668\u5728\u73b0\u4ee3Prefill - Decode\uff08P/D\uff09\u89e3\u8026\u67b6\u6784\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u8be5\u67b6\u6784\u5e26\u6765\u786c\u4ef6\u4f7f\u7528\u4f4e\u6548\u3001\u7f51\u7edc\u74f6\u9888\u548c\u9636\u6bb5\u5931\u8861\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165HeteroScale\u6846\u67b6\uff0c\u7ed3\u5408\u62d3\u6251\u611f\u77e5\u8c03\u5ea6\u5668\u548c\u57fa\u4e8e\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u7684\u6307\u6807\u9a71\u52a8\u7b56\u7565\uff0c\u7528\u5355\u4e00\u6307\u6807\u8054\u5408\u7f29\u653e\u9884\u586b\u5145\u548c\u89e3\u7801\u6c60\u3002", "result": "\u5728\u6570\u4e07\u4e2aGPU\u7684\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u5e73\u5747GPU\u5229\u7528\u7387\u63d0\u9ad826.6\u4e2a\u767e\u5206\u70b9\uff0c\u6bcf\u5929\u8282\u7701\u6570\u5341\u4e07\u4e2aGPU\u5c0f\u65f6\uff0c\u540c\u65f6\u6ee1\u8db3\u4e25\u683c\u670d\u52a1\u6c34\u5e73\u76ee\u6807\u3002", "conclusion": "HeteroScale\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3P/D\u89e3\u8026\u670d\u52a1\u7684\u6838\u5fc3\u6311\u6218\uff0c\u5b9e\u73b0\u9ad8\u6548\u81ea\u9002\u5e94\u8d44\u6e90\u7ba1\u7406\u3002"}}
{"id": "2508.19539", "pdf": "https://arxiv.org/pdf/2508.19539", "abs": "https://arxiv.org/abs/2508.19539", "authors": ["Payam Pourashraf", "Bamshad Mobasher"], "title": "A Hybrid Recommendation Framework for Enhancing User Engagement in Local News", "categories": ["cs.IR"], "comment": null, "summary": "Local news organizations face an urgent need to boost reader engagement amid\ndeclining circulation and competition from global media. Personalized news\nrecommender systems offer a promising solution by tailoring content to user\ninterests. Yet, conventional approaches often emphasize general preferences and\nmay overlook nuanced or eclectic interests in local news.\n  We propose a hybrid news recommender that integrates local and global\npreference models to improve engagement. Building on evidence of the value of\nlocalized models, our method unifies local and non-local predictors in one\nframework. The system adaptively combines recommendations from a local model,\nspecialized in region-specific content, and a global model that captures\nbroader preferences. Ensemble strategies and multiphase training balance the\ntwo.\n  We evaluated the model on two datasets: a synthetic set based on Syracuse\nnewspaper distributions and a Danish dataset (EB-NeRD) labeled for local and\nnon-local content with an LLM. Results show our integrated approach outperforms\nsingle-model baselines in accuracy and coverage, suggesting improved\npersonalization that can drive user engagement.\n  The findings have practical implications for publishers, especially local\noutlets. By leveraging both community-specific and general user interests, the\nhybrid recommender can deliver more relevant content, increasing retention and\nsubscriptions. In sum, this work introduces a new direction for recommender\nsystems, bridging local and global models to revitalize local news consumption\nthrough scalable, personalized user experiences.", "AI": {"tldr": "\u4e3a\u63d0\u5347\u672c\u5730\u65b0\u95fb\u8bfb\u8005\u53c2\u4e0e\u5ea6\uff0c\u63d0\u51fa\u7ed3\u5408\u672c\u5730\u548c\u5168\u7403\u504f\u597d\u6a21\u578b\u7684\u6df7\u5408\u65b0\u95fb\u63a8\u8350\u5668\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\uff0c\u5bf9\u51fa\u7248\u5546\u6709\u5b9e\u9645\u610f\u4e49\u3002", "motivation": "\u672c\u5730\u65b0\u95fb\u673a\u6784\u9762\u4e34\u53d1\u884c\u91cf\u4e0b\u964d\u548c\u5168\u7403\u5a92\u4f53\u7ade\u4e89\uff0c\u9700\u63d0\u5347\u8bfb\u8005\u53c2\u4e0e\u5ea6\uff0c\u800c\u4f20\u7edf\u63a8\u8350\u65b9\u6cd5\u5ffd\u7565\u672c\u5730\u65b0\u95fb\u7ec6\u5fae\u5174\u8da3\u3002", "method": "\u5c06\u672c\u5730\u548c\u975e\u672c\u5730\u9884\u6d4b\u5668\u7edf\u4e00\u5728\u4e00\u4e2a\u6846\u67b6\uff0c\u81ea\u9002\u5e94\u7ed3\u5408\u672c\u5730\u548c\u5168\u7403\u6a21\u578b\u7684\u63a8\u8350\uff0c\u7528\u96c6\u6210\u7b56\u7565\u548c\u591a\u9636\u6bb5\u8bad\u7ec3\u5e73\u8861\u4e24\u8005\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u96c6\u6210\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u8986\u76d6\u7387\u4e0a\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u6df7\u5408\u63a8\u8350\u5668\u53ef\u63d0\u4f9b\u66f4\u76f8\u5173\u5185\u5bb9\uff0c\u589e\u52a0\u7528\u6237\u7559\u5b58\u548c\u8ba2\u9605\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u5e26\u6765\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.19898", "pdf": "https://arxiv.org/pdf/2508.19898", "abs": "https://arxiv.org/abs/2508.19898", "authors": ["Yannic Maus", "Tijn de Vos"], "title": "Distributed Sparsest Cut via Eigenvalue Estimation", "categories": ["cs.DS"], "comment": "To be presented as brief announcement at DISC 2025", "summary": "We give new, improved bounds for approximating the sparsest cut value or in\nother words the conductance $\\phi$ of a graph in the CONGEST model. As our main\nresult, we present an algorithm running in $O(\\log^2 n/\\phi)$ rounds in which\nevery vertex outputs a value $\\tilde \\phi$ satisfying $\\phi \\le \\tilde \\phi \\le\n\\sqrt{2.01\\phi}$. In most regimes, our algorithm improves significantly over\nthe previously fastest algorithm for the problem [Chen, Meierhans, Probst\nGutenberg, Saranurak; SODA 25]. Additionally, our result generalizes to $k$-way\nconductance.\n  We obtain these results, by approximating the eigenvalues of the normalized\nLaplacian matrix $L:=I-\\rm{Deg}^{-1/2}A\\rm{Deg}^ {-1/2}$, where, $A$ is the\nadjacency matrix and $\\rm{Deg}$ is the diagonal matrix with the weighted\ndegrees on the diagonal. The previous state of the art sparsest cut algorithm\nis in the technical realm of expander decompositions. Our algorithms, on the\nother hand, are relatively simple and easy to implement. At the core, they rely\non the well-known power method, which comes down to repeatedly multiplying the\nLaplacian with a vector. This operation can be performed in a single round in\nthe CONGEST model. All our algorithms apply to weighted, undirected graphs. Our\nlower bounds apply even in unweighted graphs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.19663", "pdf": "https://arxiv.org/pdf/2508.19663", "abs": "https://arxiv.org/abs/2508.19663", "authors": ["Lola Solovyeva", "Eduardo Carneiro Oliveira", "Shiyu Fan", "Alper Tuncay", "Shamil Gareev", "Andrea Capiluppi"], "title": "Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation", "categories": ["cs.SE"], "comment": null, "summary": "The VT legacy system, comprising approximately 2.5 million lines of PL/SQL\ncode, lacks consistent documentation and automated tests, posing significant\nchallenges for refactoring and modernisation. This study investigates the\nfeasibility of leveraging large language models (LLMs) to assist in translating\nPL/SQL code into Java for the modernised \"VTF3\" system. By leveraging a dataset\ncomprising 10 PL/SQL-to-Java code pairs and 15 Java classes, which collectively\nestablished a domain model for the translated files, multiple LLMs were\nevaluated. Furthermore, we propose a customized prompting strategy that\nintegrates chain-of-guidance reasoning with $n$-shot prompting. Our findings\nindicate that this methodology effectively guides LLMs in generating\nsyntactically accurate translations while also achieving functional\ncorrectness. However, the findings are limited by the small sample size of\navailable code files and the restricted access to test cases used for\nvalidating the correctness of the generated code. Nevertheless, these findings\nlay the groundwork for scalable, automated solutions in modernising large\nlegacy systems.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06PL/SQL\u4ee3\u7801\u8f6c\u6362\u4e3aJava\u4ee3\u7801\u7528\u4e8e\u7cfb\u7edf\u73b0\u4ee3\u5316\uff0c\u63d0\u51fa\u5b9a\u5236\u63d0\u793a\u7b56\u7565\uff0c\u867d\u6709\u5c40\u9650\u4f46\u4e3a\u5927\u578b\u9057\u7559\u7cfb\u7edf\u73b0\u4ee3\u5316\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "VT\u9057\u7559\u7cfb\u7edf\u7f3a\u4e4f\u6587\u6863\u548c\u81ea\u52a8\u5316\u6d4b\u8bd5\uff0c\u7ed9\u91cd\u6784\u548c\u73b0\u4ee3\u5316\u5e26\u6765\u6311\u6218\uff0c\u7814\u7a76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06PL/SQL\u4ee3\u7801\u8f6c\u6362\u4e3aJava\u4ee3\u7801\u7684\u53ef\u884c\u6027\u3002", "method": "\u5229\u7528\u5305\u542b10\u5bf9PL/SQL\u5230Java\u4ee3\u7801\u5bf9\u548c15\u4e2aJava\u7c7b\u7684\u6570\u636e\u96c6\u5efa\u7acb\u9886\u57df\u6a21\u578b\uff0c\u8bc4\u4f30\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u51fa\u7ed3\u5408\u94fe\u5f0f\u5f15\u5bfc\u63a8\u7406\u548cn-shot\u63d0\u793a\u7684\u5b9a\u5236\u63d0\u793a\u7b56\u7565\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u6cd5\u51c6\u786e\u4e14\u529f\u80fd\u6b63\u786e\u7684\u7ffb\u8bd1\uff0c\u4f46\u53d7\u53ef\u7528\u4ee3\u7801\u6587\u4ef6\u6837\u672c\u91cf\u5c0f\u548c\u6d4b\u8bd5\u7528\u4f8b\u8bbf\u95ee\u53d7\u9650\u7684\u9650\u5236\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5927\u578b\u9057\u7559\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u81ea\u52a8\u5316\u73b0\u4ee3\u5316\u89e3\u51b3\u65b9\u6848\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.19461", "pdf": "https://arxiv.org/pdf/2508.19461", "abs": "https://arxiv.org/abs/2508.19461", "authors": ["Neil Kale", "Chen Bo Calvin Zhang", "Kevin Zhu", "Ankit Aich", "Paula Rodriguez", "Scale Red Team", "Christina Q. Knight", "Zifan Wang"], "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": "18 pages, 15 figures", "summary": "We stress test monitoring systems for detecting covert misbehavior in\nautonomous LLM agents (e.g., secretly sharing private information). To this\nend, we systematize a monitor red teaming (MRT) workflow that incorporates: (1)\nvarying levels of agent and monitor situational awareness; (2) distinct\nadversarial strategies to evade the monitor, such as prompt injection; and (3)\ntwo datasets and environments -- SHADE-Arena for tool-calling agents and our\nnew CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We\nrun MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse\nagent trajectories, alongside a new hybrid hierarchical-sequential scaffolding\nproposed in this work. Our empirical results yield three key findings. First,\nagent awareness dominates monitor awareness: an agent's knowledge that it is\nbeing monitored substantially degrades the monitor's reliability. On the\ncontrary, providing the monitor with more information about the agent is less\nhelpful than expected. Second, monitor scaffolding matters more than monitor\nawareness: the hybrid scaffolding consistently outperforms baseline monitor\nscaffolding, and can enable weaker models to reliably monitor stronger agents\n-- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where\nhumans discuss with the LLM monitor to get an updated judgment for the agent's\nbehavior, targeted human oversight is most effective; escalating only\npre-flagged cases to human reviewers improved the TPR by approximately 15% at\nFPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the\nlack of adversarial robustness for LLMs and humans when monitoring and\ndetecting agent misbehavior. We release code, data, and logs to spur further\nresearch.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u76d1\u63a7\u7ea2\u961f\uff08MRT\uff09\u5de5\u4f5c\u6d41\u7a0b\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u76d1\u63a7\u7cfb\u7edf\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\uff0c\u53d1\u73b0\u4ee3\u7406\u610f\u8bc6\u3001\u76d1\u63a7\u811a\u624b\u67b6\u548c\u4eba\u5de5\u76d1\u7763\u5bf9\u76d1\u63a7\u6548\u679c\u7684\u5f71\u54cd\uff0c\u8fd8\u6307\u51fa\u5f53\u524d\u76d1\u63a7\u68c0\u6d4b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u4e0d\u8db3\u5e76\u5f00\u6e90\u76f8\u5173\u8d44\u6e90\u3002", "motivation": "\u5bf9\u68c0\u6d4b\u81ea\u4e3bLLM\u4ee3\u7406\u9690\u853d\u4e0d\u5f53\u884c\u4e3a\u7684\u76d1\u63a7\u7cfb\u7edf\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\u3002", "method": "\u7cfb\u7edf\u5316MRT\u5de5\u4f5c\u6d41\u7a0b\uff0c\u6db5\u76d6\u4e0d\u540c\u610f\u8bc6\u6c34\u5e73\u3001\u5bf9\u6297\u7b56\u7565\u548c\u4e24\u4e2a\u6570\u636e\u96c6\u4e0e\u73af\u5883\uff0c\u5bf9\u73b0\u6709\u548c\u65b0\u63d0\u51fa\u7684\u6df7\u5408\u5206\u5c42 - \u987a\u5e8f\u811a\u624b\u67b6\u8fdb\u884cMRT\u3002", "result": "\u4ee3\u7406\u610f\u8bc6\u4e3b\u5bfc\u76d1\u63a7\u610f\u8bc6\uff1b\u76d1\u63a7\u811a\u624b\u67b6\u6bd4\u76d1\u63a7\u610f\u8bc6\u66f4\u91cd\u8981\uff1b\u6709\u9488\u5bf9\u6027\u7684\u4eba\u5de5\u76d1\u7763\u6700\u6709\u6548\u3002", "conclusion": "\u5efa\u7acb\u4e86MRT\u6807\u51c6\u5de5\u4f5c\u6d41\u7a0b\uff0c\u6307\u51faLLM\u548c\u4eba\u7c7b\u5728\u76d1\u63a7\u68c0\u6d4b\u4ee3\u7406\u4e0d\u5f53\u884c\u4e3a\u65f6\u7f3a\u4e4f\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u5f00\u6e90\u8d44\u6e90\u4ee5\u63a8\u52a8\u7814\u7a76\u3002"}}
{"id": "2508.11693", "pdf": "https://arxiv.org/pdf/2508.11693", "abs": "https://arxiv.org/abs/2508.11693", "authors": ["Francisco L\u00f3pez", "Eduardo Di Santi", "Cl\u00e9ment Lefebvre", "Nenad Mijatovic", "Michele Pugnaloni", "Victor Mart\u00edn", "Kenza Saiah"], "title": "Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data", "categories": ["eess.SP", "cs.AI", "cs.LG", "stat.ML", "68T05, 68T10", "I.2.6; I.5.1; I.5.4"], "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025\n  (International Conference on Railway Operations Modelling and Analysis),\n  Dresden, Germany", "summary": "Track Circuits (TC) are the main signalling devices used to detect the\npresence of a train on a rail track. It has been used since the 19th century\nand nowadays there are many types depending on the technology. As a general\nclassification, Track Circuits can be divided into 2 main groups, DC (Direct\nCurrent) and AC (Alternating Current) circuits. This work is focused on a\nparticular AC track circuit, called \"Smart Train Detection System\" (STDS),\ndesigned with both high and low-frequency bands. This approach uses STDS\ncurrent data applied to an SVM (support vector machine) classifier as a type of\nfailure identifier. The main purpose of this work consists on determine\nautomatically which is the component of the track that is failing to improve\nthe maintenance action. Model was trained to classify 15 different failures\nthat belong to 3 more general categories. The method was tested with field data\nfrom 10 different track circuits and validated by the STDS track circuit expert\nand maintainers. All use cases were correctly classified by the method.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u4e8e\u4e00\u79cd\u7279\u5b9a\u7684\u4ea4\u6d41\u8f68\u9053\u7535\u8defSTDS\uff0c\u7528\u5176\u7535\u6d41\u6570\u636e\u7ed3\u5408SVM\u5206\u7c7b\u5668\u8bc6\u522b\u6545\u969c\uff0c\u7ecf\u6d4b\u8bd5\u80fd\u6b63\u786e\u5206\u7c7b\u6240\u6709\u7528\u4f8b\u3002", "motivation": "\u81ea\u52a8\u786e\u5b9a\u8f68\u9053\u6545\u969c\u7ec4\u4ef6\uff0c\u4ee5\u6539\u8fdb\u7ef4\u62a4\u884c\u52a8\u3002", "method": "\u5c06STDS\u7535\u6d41\u6570\u636e\u5e94\u7528\u4e8eSVM\u5206\u7c7b\u5668\uff0c\u8bad\u7ec3\u6a21\u578b\u5bf915\u79cd\u4e0d\u540c\u6545\u969c\u5206\u7c7b\uff0c\u8fd9\u4e9b\u6545\u969c\u5c5e\u4e8e3\u4e2a\u66f4\u4e00\u822c\u7684\u7c7b\u522b\u3002", "result": "\u752810\u4e2a\u4e0d\u540c\u8f68\u9053\u7535\u8def\u7684\u73b0\u573a\u6570\u636e\u6d4b\u8bd5\u8be5\u65b9\u6cd5\uff0c\u6240\u6709\u7528\u4f8b\u90fd\u88ab\u6b63\u786e\u5206\u7c7b\uff0c\u4e14\u5f97\u5230\u4e86STDS\u8f68\u9053\u7535\u8def\u4e13\u5bb6\u548c\u7ef4\u62a4\u4eba\u5458\u7684\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u6709\u6548\u8bc6\u522b\u8f68\u9053\u7535\u8def\u6545\u969c\uff0c\u6709\u52a9\u4e8e\u8f68\u9053\u7ef4\u62a4\u3002"}}
{"id": "2508.19660", "pdf": "https://arxiv.org/pdf/2508.19660", "abs": "https://arxiv.org/abs/2508.19660", "authors": ["Vojtech Mrazek", "Konstantinos Balaskas", "Paula Carolina Lozano Duarte", "Zdenek Vasicek", "Mehdi B. Tahoori", "Georgios Zervakis"], "title": "Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation", "categories": ["eess.SP", "cs.AI", "cs.NE"], "comment": "Accepted at IEEE Transactions on Circuits and Systems for Artificial\n  Intelligence", "summary": "Printed electronics offer a promising alternative for applications beyond\nsilicon-based systems, requiring properties like flexibility, stretchability,\nconformality, and ultra-low fabrication costs. Despite the large feature sizes\nin printed electronics, printed neural networks have attracted attention for\nmeeting target application requirements, though realizing complex circuits\nremains challenging. This work bridges the gap between classification accuracy\nand area efficiency in printed neural networks, covering the entire\nprocessing-near-sensor system design and co-optimization from the\nanalog-to-digital interface-a major area and power bottleneck-to the digital\nclassifier. We propose an automated framework for designing printed Ternary\nNeural Networks with arbitrary input precision, utilizing multi-objective\noptimization and holistic approximation. Our circuits outperform existing\napproximate printed neural networks by 17x in area and 59x in power on average,\nbeing the first to enable printed-battery-powered operation with under 5%\naccuracy loss while accounting for analog-to-digital interfacing costs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u52a8\u5316\u6846\u67b6\u8bbe\u8ba1\u5370\u5237\u4e09\u5143\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u9762\u79ef\u548c\u529f\u8017\u4e0a\u4f18\u4e8e\u73b0\u6709\u8fd1\u4f3c\u5370\u5237\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u4f4e\u7cbe\u5ea6\u635f\u5931\u7684\u5370\u5237\u7535\u6c60\u4f9b\u7535\u8fd0\u884c\u3002", "motivation": "\u5370\u5237\u7535\u5b50\u6709\u5e94\u7528\u524d\u666f\uff0c\u4f46\u5370\u5237\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u590d\u6742\u7535\u8def\u6709\u6311\u6218\uff0c\u9700\u5e73\u8861\u5206\u7c7b\u7cbe\u5ea6\u548c\u9762\u79ef\u6548\u7387\u3002", "method": "\u63d0\u51fa\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u5229\u7528\u591a\u76ee\u6807\u4f18\u5316\u548c\u6574\u4f53\u8fd1\u4f3c\u8bbe\u8ba1\u4efb\u610f\u8f93\u5165\u7cbe\u5ea6\u7684\u5370\u5237\u4e09\u5143\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u7535\u8def\u5728\u9762\u79ef\u4e0a\u6bd4\u73b0\u6709\u8fd1\u4f3c\u5370\u5237\u795e\u7ecf\u7f51\u7edc\u5e73\u5747\u9ad817\u500d\uff0c\u529f\u8017\u9ad859\u500d\uff0c\u9996\u6b21\u5b9e\u73b0\u5370\u5237\u7535\u6c60\u4f9b\u7535\u4e14\u7cbe\u5ea6\u635f\u5931\u4f4e\u4e8e5%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5370\u5237\u795e\u7ecf\u7f51\u7edc\u4e2d\u5206\u7c7b\u7cbe\u5ea6\u548c\u9762\u79ef\u6548\u7387\u7684\u5e73\u8861\u95ee\u9898\u3002"}}
{"id": "2508.19670", "pdf": "https://arxiv.org/pdf/2508.19670", "abs": "https://arxiv.org/abs/2508.19670", "authors": ["Diogo Costa", "Jose Martins", "Sandro Pinto"], "title": "Beyond the Bermuda Triangle of Contention: IOMMU Interference in Mixed Criticality Systems", "categories": ["cs.DC", "cs.SY", "eess.SY"], "comment": null, "summary": "As Mixed Criticality Systems (MCSs) evolve, they increasingly integrate\nheterogeneous computing platforms, combining general-purpose processors with\nspecialized accelerators such as AI engines, GPUs, and high-speed networking\ninterfaces. This heterogeneity introduces challenges, as these accelerators and\nDMA-capable devices act as independent bus masters, directly accessing memory.\nConsequently, ensuring both security and timing predictability in such\nenvironments becomes critical. To address these concerns, the Input-Output\nMemory Management Unit (IOMMU) plays a key role in mediating and regulating\nmemory access, preventing unauthorized transactions while enforcing isolation\nand access control policies. While prior work has explored IOMMU-related\nside-channel vulnerabilities from a security standpoint, its role in\nperformance interference remains largely unexplored. Moreover, many of the same\narchitectural properties that enable side-channel leakage, such as shared TLBs,\ncaching effects, and translation overheads, can also introduce timing\nunpredictability. In this work, we analyze the contention effects within IOMMU\nstructures using the Xilinx UltraScale+ ZCU104 platform, demonstrating how\ntheir shared nature introduce unpredictable delays. Our findings reveal that\nIOMMU-induced interference primarily affects small memory transactions, where\ntranslation overheads significantly impact execution time. Additionally, we\nhypothesize that contention effects arising from IOTLBs exhibit similar\nbehavior across architectures due to shared caching principles, such as\nprefetching and hierarchical TLB structures. Notably, our experiments show that\nIOMMU interference can delay DMA transactions by up to 1.79x for lower-size\ntransfers on the Arm SMMUv2 implementation.", "AI": {"tldr": "\u672c\u6587\u5206\u6790IOMMU\u7ed3\u6784\u4e2d\u7684\u4e89\u7528\u6548\u5e94\uff0c\u53d1\u73b0\u5176\u5e72\u6270\u4e3b\u8981\u5f71\u54cd\u5c0f\u5185\u5b58\u4e8b\u52a1\uff0c\u4e14\u4e0d\u540c\u67b6\u6784\u7684IOTLB\u4e89\u7528\u6548\u5e94\u7c7b\u4f3c\uff0c\u5b9e\u9a8c\u663e\u793aIOMMU\u5e72\u6270\u4f1a\u5ef6\u8fdfDMA\u4e8b\u52a1\u3002", "motivation": "\u968f\u7740\u6df7\u5408\u5173\u952e\u7cfb\u7edf\u4e2d\u5f02\u6784\u8ba1\u7b97\u5e73\u53f0\u96c6\u6210\u589e\u52a0\uff0c\u786e\u4fdd\u5b89\u5168\u548c\u65f6\u5e8f\u53ef\u9884\u6d4b\u6027\u5f88\u5173\u952e\uff0c\u6b64\u524d\u5bf9IOMMU\u5728\u6027\u80fd\u5e72\u6270\u65b9\u9762\u7684\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u4f7f\u7528Xilinx UltraScale+ ZCU104\u5e73\u53f0\u5206\u6790IOMMU\u7ed3\u6784\u4e2d\u7684\u4e89\u7528\u6548\u5e94\u3002", "result": "IOMMU\u5f15\u8d77\u7684\u5e72\u6270\u4e3b\u8981\u5f71\u54cd\u5c0f\u5185\u5b58\u4e8b\u52a1\uff0c\u4e0d\u540c\u67b6\u6784\u7684IOTLB\u4e89\u7528\u6548\u5e94\u56e0\u5171\u4eab\u7f13\u5b58\u539f\u7406\u7c7b\u4f3c\uff1b\u5728Arm SMMUv2\u5b9e\u73b0\u4e2d\uff0cIOMMU\u5e72\u6270\u53ef\u4f7f\u5c0f\u5c3a\u5bf8\u4f20\u8f93\u7684DMA\u4e8b\u52a1\u5ef6\u8fdf\u8fbe1.79\u500d\u3002", "conclusion": "IOMMU\u5728\u6027\u80fd\u5e72\u6270\u65b9\u9762\u5b58\u5728\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5bf9\u5c0f\u5185\u5b58\u4e8b\u52a1\u548cDMA\u4e8b\u52a1\uff0c\u4e14\u4e0d\u540c\u67b6\u6784\u6709\u5171\u6027\u3002"}}
{"id": "2508.19547", "pdf": "https://arxiv.org/pdf/2508.19547", "abs": "https://arxiv.org/abs/2508.19547", "authors": ["Tongxin Xu", "Wenqiang Liu", "Chenzhong Bin", "Cihan Xiao", "Zhixin Zeng", "Tianlong Gu"], "title": "Improving Recommendation Fairness via Graph Structure and Representation Augmentation", "categories": ["cs.IR"], "comment": "Accepted by CIKM 2025", "summary": "Graph Convolutional Networks (GCNs) have become increasingly popular in\nrecommendation systems. However, recent studies have shown that GCN-based\nmodels will cause sensitive information to disseminate widely in the graph\nstructure, amplifying data bias and raising fairness concerns. While various\nfairness methods have been proposed, most of them neglect the impact of biased\ndata on representation learning, which results in limited fairness improvement.\nMoreover, some studies have focused on constructing fair and balanced data\ndistributions through data augmentation, but these methods significantly reduce\nutility due to disruption of user preferences. In this paper, we aim to design\na fair recommendation method from the perspective of data augmentation to\nimprove fairness while preserving recommendation utility. To achieve\nfairness-aware data augmentation with minimal disruption to user preferences,\nwe propose two prior hypotheses. The first hypothesis identifies sensitive\ninteractions by comparing outcomes of performance-oriented and fairness-aware\nrecommendations, while the second one focuses on detecting sensitive features\nby analyzing feature similarities between biased and debiased representations.\nThen, we propose a dual data augmentation framework for fair recommendation,\nwhich includes two data augmentation strategies to generate fair augmented\ngraphs and feature representations. Furthermore, we introduce a debiasing\nlearning method that minimizes the dependence between the learned\nrepresentations and sensitive information to eliminate bias. Extensive\nexperiments on two real-world datasets demonstrate the superiority of our\nproposed framework.", "AI": {"tldr": "\u672c\u6587\u4ece\u6570\u636e\u589e\u5f3a\u89d2\u5ea6\u8bbe\u8ba1\u516c\u5e73\u63a8\u8350\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e24\u4e2a\u5148\u9a8c\u5047\u8bbe\u3001\u53cc\u6570\u636e\u589e\u5f3a\u6846\u67b6\u548c\u53bb\u504f\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709GCN\u63a8\u8350\u6a21\u578b\u5b58\u5728\u654f\u611f\u4fe1\u606f\u4f20\u64ad\u3001\u6570\u636e\u504f\u5dee\u653e\u5927\u548c\u516c\u5e73\u6027\u95ee\u9898\uff0c\u4e14\u591a\u6570\u516c\u5e73\u65b9\u6cd5\u5ffd\u89c6\u504f\u5dee\u6570\u636e\u5bf9\u8868\u5f81\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u4f1a\u964d\u4f4e\u63a8\u8350\u6548\u7528\uff0c\u56e0\u6b64\u8981\u8bbe\u8ba1\u80fd\u517c\u987e\u516c\u5e73\u6027\u548c\u63a8\u8350\u6548\u7528\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u5148\u9a8c\u5047\u8bbe\u8bc6\u522b\u654f\u611f\u4ea4\u4e92\u548c\u7279\u5f81\uff0c\u6784\u5efa\u53cc\u6570\u636e\u589e\u5f3a\u6846\u67b6\u751f\u6210\u516c\u5e73\u589e\u5f3a\u56fe\u548c\u7279\u5f81\u8868\u5f81\uff0c\u5f15\u5165\u53bb\u504f\u5b66\u4e60\u65b9\u6cd5\u51cf\u5c11\u8868\u5f81\u4e0e\u654f\u611f\u4fe1\u606f\u7684\u4f9d\u8d56\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u6846\u67b6\u5177\u6709\u4f18\u8d8a\u6027\u3002", "conclusion": "\u4ece\u6570\u636e\u589e\u5f3a\u89d2\u5ea6\u8bbe\u8ba1\u7684\u516c\u5e73\u63a8\u8350\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u516c\u5e73\u6027\u5e76\u4fdd\u7559\u63a8\u8350\u6548\u7528\u3002"}}
{"id": "2508.20002", "pdf": "https://arxiv.org/pdf/2508.20002", "abs": "https://arxiv.org/abs/2508.20002", "authors": ["Shaul Rosner", "Tami Tamir"], "title": "Bipartite Matching with Pair-Dependent Bounds", "categories": ["cs.DS", "05C70", "F.2.2; G.2"], "comment": null, "summary": "Let $G=(U \\cup V, E)$ be a bipartite graph, where $U$ represents jobs and $V$\nrepresents machines. We study a new variant of the bipartite matching problem\nin which each job in $U$ can be matched to at most one machine in $V$, and the\nnumber of jobs that can be assigned to a machine depends on the specific jobs\nmatched to it. These pair-dependent bounds reflect systems where different jobs\nhave varying tolerance for congestion, determined by the specific machine they\nare assigned to.\n  We define a bipartite PD-matching as a set of edges $M \\subseteq E$ that\nsatisfies these job-to-machine tolerance constraints. This variant of matching\nextends well-known matching problems, however, despite its relevance to\nreal-world systems, it has not been studied before. We study bipartite\nPD-matchings with the objective of maximizing the matching size. As we show,\nthe problem exhibits significant differences from previously studied matching\nproblems. We analyze its computational complexity both in the general case and\nfor specific restricted instances, presenting hardness results alongside\noptimal and approximation algorithms.", "AI": {"tldr": "\u7814\u7a76\u4e8c\u5206\u56fe\u4e2d\u4e00\u79cd\u65b0\u7684\u5339\u914d\u95ee\u9898\uff08\u4e8c\u5206PD - \u5339\u914d\uff09\uff0c\u5206\u6790\u5176\u590d\u6742\u5ea6\uff0c\u7ed9\u51fa\u786c\u5ea6\u7ed3\u679c\u53ca\u7b97\u6cd5\u3002", "motivation": "\u8be5\u95ee\u9898\u53cd\u6620\u4e86\u4e0d\u540c\u4f5c\u4e1a\u5bf9\u62e5\u585e\u7684\u4e0d\u540c\u5bb9\u5fcd\u5ea6\uff0c\u4e0e\u73b0\u5b9e\u7cfb\u7edf\u76f8\u5173\u4f46\u672a\u88ab\u7814\u7a76\u8fc7\u3002", "method": "\u5b9a\u4e49\u4e8c\u5206PD - \u5339\u914d\uff0c\u4ece\u4e00\u822c\u60c5\u51b5\u548c\u7279\u5b9a\u9650\u5236\u5b9e\u4f8b\u5206\u6790\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7ed9\u51fa\u786c\u5ea6\u7ed3\u679c\u548c\u6700\u4f18\u3001\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u53d1\u73b0\u8be5\u95ee\u9898\u4e0e\u4e4b\u524d\u7814\u7a76\u7684\u5339\u914d\u95ee\u9898\u6709\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u5bf9\u4e8c\u5206PD - \u5339\u914d\u95ee\u9898\u8fdb\u884c\u4e86\u5168\u9762\u7814\u7a76\uff0c\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2508.19797", "pdf": "https://arxiv.org/pdf/2508.19797", "abs": "https://arxiv.org/abs/2508.19797", "authors": ["Joan Giner-Miguelez", "Abel G\u00f3mez", "Jordi Cabot"], "title": "Enabling Content Management Systems as an Information Source in Model-driven Projects", "categories": ["cs.SE"], "comment": null, "summary": "Content Management Systems (CMSs) are the most popular tool when it comes to\ncreate and publish content across the web. Recently, CMSs have evolved,\nbecoming \\emph{headless}. Content served by a \\emph{headless CMS} aims to be\nconsumed by other applications and services through REST APIs rather than by\nhuman users through a web browser. This evolution has enabled CMSs to become a\nnotorious source of content to be used in a variety of contexts beyond pure web\nnavigation. As such, CMS have become an important component of many information\nsystems. Unfortunately, we still lack the tools to properly discover and manage\nthe information stored in a CMS, often highly customized to the needs of a\nspecific domain. Currently, this is mostly a time-consuming and error-prone\nmanual process.\n  In this paper, we propose a model-based framework to facilitate the\nintegration of headless CMSs in software development processes. Our framework\nis able to discover and explicitly represent the information schema behind the\nCMS. This facilitates designing the interaction between the CMS model and other\ncomponents consuming that information. These interactions are then generated as\npart of a middleware library that offers platform-agnostic access to the CMS to\nall the client applications. The complete framework is open-source and\navailable online.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u6846\u67b6\u4ee5\u4fc3\u8fdb\u65e0\u5934CMS\u96c6\u6210\u5230\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\uff0c\u6846\u67b6\u53ef\u53d1\u73b0\u5e76\u8868\u793a\u4fe1\u606f\u67b6\u6784\uff0c\u751f\u6210\u4e2d\u95f4\u4ef6\u5e93\u63d0\u4f9b\u5bf9CMS\u7684\u5e73\u53f0\u65e0\u5173\u8bbf\u95ee\uff0c\u4e14\u6846\u67b6\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709CMS\u7f3a\u4e4f\u6709\u6548\u53d1\u73b0\u548c\u7ba1\u7406\u4fe1\u606f\u7684\u5de5\u5177\uff0c\u5f53\u524d\u624b\u52a8\u5904\u7406\u8017\u65f6\u4e14\u6613\u51fa\u9519\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u6846\u67b6\u6765\u53d1\u73b0\u548c\u660e\u786e\u8868\u793aCMS\u80cc\u540e\u7684\u4fe1\u606f\u67b6\u6784\uff0c\u751f\u6210\u4e2d\u95f4\u4ef6\u5e93\u5b9e\u73b0\u5e73\u53f0\u65e0\u5173\u8bbf\u95ee\u3002", "result": "\u5f00\u53d1\u51fa\u5b8c\u6574\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u53ef\u5728\u7ebf\u83b7\u53d6\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u4fc3\u8fdb\u65e0\u5934CMS\u5728\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u4e2d\u7684\u96c6\u6210\u3002"}}
{"id": "2508.19502", "pdf": "https://arxiv.org/pdf/2508.19502", "abs": "https://arxiv.org/abs/2508.19502", "authors": ["Xifeng Yao", "Chengyuan Ma", "Dongyu Lang", "Yinhao Ni", "Zhiwei Xu", "Huarui Xie", "Zihao Chen", "Guang Shen", "Dandan Tu", "Yi Bai", "Changzheng Zhang"], "title": "SLIM: Subtrajectory-Level Elimination for More Effective Reasoning", "categories": ["cs.AI"], "comment": "EMNLP 2025 Findings", "summary": "In recent months, substantial progress has been made in complex reasoning of\nLarge Language Models, particularly through the application of test-time\nscaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When\nresponding to a query, these models generate an extended reasoning trajectory,\nduring which the model explores, reflects, backtracks, and self-verifies before\narriving at a conclusion. However, fine-tuning models with such reasoning\ntrajectories may not always be optimal. Our findings indicate that not all\ncomponents within these reasoning trajectories contribute positively to the\nreasoning process; in fact, some components may affect the overall performance\nnegatively. In this study, we divide a reasoning trajectory into individual\nsubtrajectories and develop a \"5+2\" framework to: (1) systematically identify\nsuboptimal subtrajectories within the reasoning trajectory based on five\nhuman-established criteria; (2) assess the independence of the suboptimal\nsubtrajectories identified in (1) from the subsequent content, ensuring that\ntheir elimination does not compromise overall flow and coherence of the\nreasoning process. Additionally, a sampling algorithm, built upon the \"5+2\"\nframework, is employed to select data whose reasoning process is free from\nsuboptimal subtrajectories to the highest degree. Experimental results\ndemonstrate that our method can reduce the number of suboptimal subtrajectories\nby 25.9\\% during the inference. Furthermore, our method achieves an average\naccuracy of 58.92\\% on highly challenging math benchmarks with only two thirds\nof training data, surpassing the average accuracy of 58.06\\% achieved with the\nentire data, and outperforming open-source datasets, when fine-tuning\nQwen2.5-Math-7B. Finally, We validated our method under resource constraints\nand observed improved performance across various inference token limits.", "AI": {"tldr": "\u8fd1\u671f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u6709\u8fdb\u5c55\u4f46\u63a8\u7406\u8f68\u8ff9\u5fae\u8c03\u975e\u6700\u4f18\uff0c\u7814\u7a76\u63d0\u51fa'5+2'\u6846\u67b6\u7b5b\u9009\u6570\u636e\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u51cf\u5c11\u6b21\u4f18\u5b50\u8f68\u8ff9\uff0c\u7528\u90e8\u5206\u6570\u636e\u5fae\u8c03\u8868\u73b0\u66f4\u597d\uff0c\u8d44\u6e90\u53d7\u9650\u4e0b\u4e5f\u6709\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u590d\u6742\u63a8\u7406\u867d\u6709\u8fdb\u5c55\uff0c\u4f46\u63a8\u7406\u8f68\u8ff9\u4e2d\u5e76\u975e\u6240\u6709\u90e8\u5206\u90fd\u5bf9\u63a8\u7406\u8fc7\u7a0b\u6709\u79ef\u6781\u8d21\u732e\uff0c\u90e8\u5206\u4f1a\u8d1f\u9762\u5f71\u54cd\u6574\u4f53\u6027\u80fd\uff0c\u9700\u8981\u4f18\u5316\u3002", "method": "\u5c06\u63a8\u7406\u8f68\u8ff9\u5212\u5206\u4e3a\u5b50\u8f68\u8ff9\uff0c\u6784\u5efa'5+2'\u6846\u67b6\u8bc6\u522b\u6b21\u4f18\u5b50\u8f68\u8ff9\u5e76\u8bc4\u4f30\u72ec\u7acb\u6027\uff0c\u7528\u57fa\u4e8e\u8be5\u6846\u67b6\u7684\u91c7\u6837\u7b97\u6cd5\u7b5b\u9009\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u4e2d\u63a8\u7406\u65f6\u6b21\u4f18\u5b50\u8f68\u8ff9\u51cf\u5c1125.9%\uff1b\u7528\u4e09\u5206\u4e4b\u4e8c\u8bad\u7ec3\u6570\u636e\u5fae\u8c03Qwen2.5 - Math - 7B\u5728\u9ad8\u96be\u5ea6\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u5e73\u5747\u51c6\u786e\u7387\u8fbe58.92%\uff0c\u8d85\u7528\u5168\u91cf\u6570\u636e\u53ca\u5f00\u6e90\u6570\u636e\u96c6\uff1b\u8d44\u6e90\u53d7\u9650\u4e0b\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\uff0c\u63d0\u5347\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u8d44\u6e90\u53d7\u9650\u60c5\u51b5\u4e0b\u4e5f\u9002\u7528\u3002"}}
{"id": "2508.19249", "pdf": "https://arxiv.org/pdf/2508.19249", "abs": "https://arxiv.org/abs/2508.19249", "authors": ["Jonas S\u00f8eborg Nielsen", "Marcus Galea Jacobsen", "Albert Brincker Olson", "Mads Peter S\u00f8rensen", "Allan Peter Engsig-Karup"], "title": "Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models", "categories": ["cs.LG", "math.DS", "stat.ME", "stat.ML", "37M99"], "comment": "For public PIR Julia package, see\n  https://github.com/MarcusGalea/PhysicsInformedRegression.jl", "summary": "We present a new efficient hybrid parameter estimation method based on the\nidea, that if nonlinear dynamic models are stated in terms of a system of\nequations that is linear in terms of the parameters, then regularized ordinary\nleast squares can be used to estimate these parameters from time series data.\nWe introduce the term \"Physics-Informed Regression\" (PIR) to describe the\nproposed data-driven hybrid technique as a way to bridge theory and data by use\nof ordinary least squares to efficiently perform parameter estimation of the\nmodel coefficients of different parameter-linear models; providing examples of\nmodels based on nonlinear ordinary equations (ODE) and partial differential\nequations (PDE). The focus is on parameter estimation on a selection of ODE and\nPDE models, each illustrating performance in different model characteristics.\nFor two relevant epidemic models of different complexity and number of\nparameters, PIR is tested and compared against the related technique,\nphysics-informed neural networks (PINN), both on synthetic data generated from\nknown target parameters and on real public Danish time series data collected\nduring the COVID-19 pandemic in Denmark. Both methods were able to estimate the\ntarget parameters, while PIR showed to perform noticeably better, especially on\na compartment model with higher complexity. Given the difference in\ncomputational speed, it is concluded that the PIR method is superior to PINN\nfor the models considered. It is also demonstrated how PIR can be applied to\nestimate the time-varying parameters of a compartment model that is fitted\nusing real Danish data from the COVID-19 pandemic obtained during a period from\n2020 to 2021. The study shows how data-driven and physics-informed techniques\nmay support reliable and fast -- possibly real-time -- parameter estimation in\nparameter-linear nonlinear dynamic models.", "AI": {"tldr": "\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u56de\u5f52\uff08PIR\uff09\u65b9\u6cd5\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\uff0c\u4e0ePINN\u5bf9\u6bd4\uff0cPIR\u8868\u73b0\u66f4\u4f18\uff0c\u53ef\u7528\u4e8e\u65f6\u53d8\u53c2\u6570\u4f30\u8ba1\uff0c\u652f\u6301\u5feb\u901f\u53ef\u9760\u7684\u53c2\u6570\u4f30\u8ba1\u3002", "motivation": "\u5bfb\u627e\u9ad8\u6548\u7684\u975e\u7ebf\u6027\u52a8\u6001\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u6865\u63a5\u7406\u8bba\u4e0e\u6570\u636e\u3002", "method": "\u63d0\u51faPIR\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6b63\u5219\u5316\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff0c\u5bf9\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u6d41\u884c\u75c5\u6a21\u578b\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\uff0c\u5e76\u4e0ePINN\u5bf9\u6bd4\u3002", "result": "PIR\u548cPINN\u90fd\u80fd\u4f30\u8ba1\u76ee\u6807\u53c2\u6570\uff0cPIR\u8868\u73b0\u66f4\u597d\uff0c\u5c24\u5176\u5728\u590d\u6742\u6a21\u578b\u4e0a\uff0c\u8ba1\u7b97\u901f\u5ea6\u6709\u5dee\u5f02\u3002", "conclusion": "\u5bf9\u4e8e\u6240\u8003\u8651\u7684\u6a21\u578b\uff0cPIR\u65b9\u6cd5\u4f18\u4e8ePINN\uff0c\u6570\u636e\u9a71\u52a8\u548c\u7269\u7406\u4fe1\u606f\u6280\u672f\u53ef\u652f\u6301\u53c2\u6570\u7ebf\u6027\u975e\u7ebf\u6027\u52a8\u6001\u6a21\u578b\u7684\u53ef\u9760\u5feb\u901f\u53c2\u6570\u4f30\u8ba1\u3002"}}
{"id": "2508.19806", "pdf": "https://arxiv.org/pdf/2508.19806", "abs": "https://arxiv.org/abs/2508.19806", "authors": ["Shenqi Wang", "Guangzhi Tang"], "title": "Context-aware Sparse Spatiotemporal Learning for Event-based Vision", "categories": ["cs.CV", "cs.NE"], "comment": "Accepted at IROS 2025", "summary": "Event-based camera has emerged as a promising paradigm for robot perception,\noffering advantages with high temporal resolution, high dynamic range, and\nrobustness to motion blur. However, existing deep learning-based event\nprocessing methods often fail to fully leverage the sparse nature of event\ndata, complicating their integration into resource-constrained edge\napplications. While neuromorphic computing provides an energy-efficient\nalternative, spiking neural networks struggle to match of performance of\nstate-of-the-art models in complex event-based vision tasks, like object\ndetection and optical flow. Moreover, achieving high activation sparsity in\nneural networks is still difficult and often demands careful manual tuning of\nsparsity-inducing loss terms. Here, we propose Context-aware Sparse\nSpatiotemporal Learning (CSSL), a novel framework that introduces context-aware\nthresholding to dynamically regulate neuron activations based on the input\ndistribution, naturally reducing activation density without explicit sparsity\nconstraints. Applied to event-based object detection and optical flow\nestimation, CSSL achieves comparable or superior performance to\nstate-of-the-art methods while maintaining extremely high neuronal sparsity.\nOur experimental results highlight CSSL's crucial role in enabling efficient\nevent-based vision for neuromorphic processing.", "AI": {"tldr": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u7a00\u758f\u65f6\u7a7a\u5b66\u4e60\uff08CSSL\uff09\u6846\u67b6\u7528\u4e8e\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\uff0c\u5728\u4fdd\u6301\u9ad8\u795e\u7ecf\u5143\u7a00\u758f\u6027\u7684\u540c\u65f6\u6027\u80fd\u53ef\u6bd4\u6216\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u4e8b\u4ef6\u5904\u7406\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u4e8b\u4ef6\u6570\u636e\u7a00\u758f\u6027\uff0c\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0d\u4f73\uff0c\u4e14\u5b9e\u73b0\u9ad8\u6fc0\u6d3b\u7a00\u758f\u6027\u56f0\u96be\u3002", "method": "\u63d0\u51faCSSL\u6846\u67b6\uff0c\u5f15\u5165\u4e0a\u4e0b\u6587\u611f\u77e5\u9608\u503c\u6839\u636e\u8f93\u5165\u5206\u5e03\u52a8\u6001\u8c03\u8282\u795e\u7ecf\u5143\u6fc0\u6d3b\u3002", "result": "\u5e94\u7528\u4e8e\u57fa\u4e8e\u4e8b\u4ef6\u7684\u76ee\u6807\u68c0\u6d4b\u548c\u5149\u6d41\u4f30\u8ba1\uff0cCSSL\u6027\u80fd\u53ef\u6bd4\u6216\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u6781\u9ad8\u7684\u795e\u7ecf\u5143\u7a00\u758f\u6027\u3002", "conclusion": "CSSL\u5bf9\u795e\u7ecf\u5f62\u6001\u5904\u7406\u7684\u9ad8\u6548\u4e8b\u4ef6\u89c6\u89c9\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.19805", "pdf": "https://arxiv.org/pdf/2508.19805", "abs": "https://arxiv.org/abs/2508.19805", "authors": ["Shota Naito", "Tsukasa Ninomiya", "Koichi Wada"], "title": "Separation of Three or More Autonomous Mobile Models under Hierarchical Schedulers", "categories": ["cs.DC"], "comment": null, "summary": "Understanding the computational power of mobile robot systems is a\nfundamental challenge in distributed computing. While prior work has focused on\npairwise separations between models, we explore how robot capabilities, light\nobservability, and scheduler synchrony interact in more complex ways.\n  We first show that the Exponential Times Expansion (ETE) problem is solvable\nonly in the strongest model -- fully-synchronous robots with full mutual lights\n($\\mathcal{LUMT}^F$). We then introduce the Hexagonal Edge Traversal (HET) and\nTAR(d)* problems to demonstrate how internal memory and lights interact with\nsynchrony: under weak synchrony, internal memory alone is insufficient, while\nfull synchrony can substitute for both lights and memory.\n  In the asynchronous setting, we classify problems such as LP-MLCv, VEC, and\nZCC to show fine-grained separations between $\\mathcal{FSTA}$ and\n$\\mathcal{FCOM}$ robots. We also analyze Vertex Traversal Rendezvous (VTR) and\nLeave Place Convergence (LP-Cv), illustrating the limitations of internal\nmemory in symmetric settings.\n  These results extend the known separation map of 14 canonical robot models,\nrevealing structural phenomena only visible through higher-order comparisons.\nOur work provides new impossibility criteria and deepens the understanding of\nhow observability, memory, and synchrony collectively shape the computational\npower of mobile robots.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u7d22\u673a\u5668\u4eba\u80fd\u529b\u3001\u706f\u5149\u53ef\u89c2\u6d4b\u6027\u548c\u8c03\u5ea6\u5668\u540c\u6b65\u6027\u7684\u590d\u6742\u4ea4\u4e92\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u95ee\u9898\u548c\u5206\u7c7b\u95ee\u9898\u62d3\u5c55\u5df2\u77e5\u5206\u79bb\u56fe\uff0c\u63d0\u4f9b\u65b0\u4e0d\u53ef\u80fd\u6027\u51c6\u5219\uff0c\u52a0\u6df1\u5bf9\u79fb\u52a8\u673a\u5668\u4eba\u8ba1\u7b97\u80fd\u529b\u7684\u7406\u89e3\u3002", "motivation": "\u4ee5\u5f80\u5de5\u4f5c\u805a\u7126\u6a21\u578b\u95f4\u7684\u6210\u5bf9\u5206\u79bb\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u673a\u5668\u4eba\u80fd\u529b\u3001\u706f\u5149\u53ef\u89c2\u6d4b\u6027\u548c\u8c03\u5ea6\u5668\u540c\u6b65\u6027\u66f4\u590d\u6742\u7684\u4ea4\u4e92\u3002", "method": "\u63d0\u51faETE\u3001HET\u548cTAR(d)*\u7b49\u95ee\u9898\uff0c\u5bf9LP - MLCv\u3001VEC\u7b49\u95ee\u9898\u5206\u7c7b\uff0c\u5206\u6790VTR\u548cLP - Cv\u7b49\u3002", "result": "\u62d3\u5c55\u4e8614\u79cd\u5178\u578b\u673a\u5668\u4eba\u6a21\u578b\u7684\u5df2\u77e5\u5206\u79bb\u56fe\uff0c\u63ed\u793a\u4e86\u9ad8\u9636\u6bd4\u8f83\u4e0b\u7684\u7ed3\u6784\u73b0\u8c61\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u65b0\u7684\u4e0d\u53ef\u80fd\u6027\u51c6\u5219\uff0c\u52a0\u6df1\u4e86\u5bf9\u53ef\u89c2\u6d4b\u6027\u3001\u5185\u5b58\u548c\u540c\u6b65\u6027\u5982\u4f55\u5171\u540c\u5f71\u54cd\u79fb\u52a8\u673a\u5668\u4eba\u8ba1\u7b97\u80fd\u529b\u7684\u7406\u89e3\u3002"}}
{"id": "2508.19591", "pdf": "https://arxiv.org/pdf/2508.19591", "abs": "https://arxiv.org/abs/2508.19591", "authors": ["Jiakui Shen", "Yunqi Mi", "Guoshuai Zhao", "Jialie Shen", "Xueming Qian"], "title": "A Model-agnostic Strategy to Mitigate Embedding Degradation in Personalized Federated Recommendation", "categories": ["cs.IR", "cs.DC"], "comment": null, "summary": "Centralized recommender systems encounter privacy leakage due to the need to\ncollect user behavior and other private data. Hence, federated recommender\nsystems (FedRec) have become a promising approach with an aggregated global\nmodel on the server. However, this distributed training paradigm suffers from\nembedding degradation caused by suboptimal personalization and dimensional\ncollapse, due to the existence of sparse interactions and heterogeneous\npreferences. To this end, we propose a novel model-agnostic strategy for FedRec\nto strengthen the personalized embedding utility, which is called Personalized\nLocal-Global Collaboration (PLGC). It is the first research in federated\nrecommendation to alleviate the dimensional collapse issue. Particularly, we\nincorporate the frozen global item embedding table into local devices. Based on\na Neural Tangent Kernel strategy that dynamically balances local and global\ninformation, PLGC optimizes personalized representations during forward\ninference, ultimately converging to user-specific preferences. Additionally,\nPLGC carries on a contrastive objective function to reduce embedding redundancy\nby dissolving dependencies between dimensions, thereby improving the backward\nrepresentation learning process. We introduce PLGC as a model-agnostic\npersonalized training strategy for federated recommendations that can be\napplied to existing baselines to alleviate embedding degradation. Extensive\nexperiments on five real-world datasets have demonstrated the effectiveness and\nadaptability of PLGC, which outperforms various baseline algorithms.", "AI": {"tldr": "\u96c6\u4e2d\u5f0f\u63a8\u8350\u7cfb\u7edf\u6709\u9690\u79c1\u95ee\u9898\uff0c\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u5d4c\u5165\u9000\u5316\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faPLGC\u7b56\u7565\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u96c6\u4e2d\u5f0f\u63a8\u8350\u7cfb\u7edf\u6709\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u800c\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u56e0\u7a00\u758f\u4ea4\u4e92\u548c\u5f02\u8d28\u504f\u597d\u5bfc\u81f4\u7684\u5d4c\u5165\u9000\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faPLGC\u7b56\u7565\uff0c\u5c06\u51bb\u7ed3\u7684\u5168\u5c40\u7269\u54c1\u5d4c\u5165\u8868\u7eb3\u5165\u672c\u5730\u8bbe\u5907\uff0c\u57fa\u4e8e\u795e\u7ecf\u5207\u7ebf\u6838\u7b56\u7565\u5e73\u8861\u672c\u5730\u548c\u5168\u5c40\u4fe1\u606f\uff0c\u4f7f\u7528\u5bf9\u6bd4\u76ee\u6807\u51fd\u6570\u51cf\u5c11\u5d4c\u5165\u5197\u4f59\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPLGC\u7b56\u7565\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u7b97\u6cd5\u3002", "conclusion": "PLGC\u4f5c\u4e3a\u4e00\u79cd\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u4e2a\u6027\u5316\u8bad\u7ec3\u7b56\u7565\uff0c\u53ef\u5e94\u7528\u4e8e\u73b0\u6709\u57fa\u7ebf\u4ee5\u7f13\u89e3\u5d4c\u5165\u9000\u5316\u95ee\u9898\u3002"}}
{"id": "2508.20041", "pdf": "https://arxiv.org/pdf/2508.20041", "abs": "https://arxiv.org/abs/2508.20041", "authors": ["Thomas Bl\u00e4sius", "Henrik Cs\u00f6re", "Max G\u00f6ttlicher", "Elly Schmidt", "Wendy Yi"], "title": "Flow-weighted Layered Metric Euclidean Capacitated Steiner Tree Problem", "categories": ["cs.DS"], "comment": null, "summary": "Motivated by hierarchical networks, we introduce the Flow-weighted Layered\nMetric Euclidean Capacitated Steiner Tree (FLaMECaST) problem, a variant of the\nEuclidean Steiner tree with layered structure and capacity constraints per\nlayer. The goal is to construct a cost-optimal Steiner forest connecting a set\nof sources to a set of sinks under load-dependent edge costs. We prove that\nFLaMECaST is NP-hard to approximate, even in restricted cases where all sources\nlie on a circle. However, assuming few additional constraints for such\ninstances, we design a dynamic program that achieves a $\\left(1 +\n\\frac{1}{2^n}\\right)$-approximation in polynomial time. By generalizing the\nstructural insights the dynamic program is based on, we extend the approach to\ncertain settings, where all sources are positioned on a convex polygon.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165FLaMECaST\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u8fd1\u4f3c\u96be\u5ea6\uff0c\u5728\u5c11\u6570\u989d\u5916\u7ea6\u675f\u4e0b\u8bbe\u8ba1\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u5f97\u5230\u8fd1\u4f3c\u89e3\uff0c\u5e76\u5c06\u65b9\u6cd5\u6269\u5c55\u5230\u7279\u5b9a\u8bbe\u7f6e\u3002", "motivation": "\u53d7\u5206\u5c42\u7f51\u7edc\u542f\u53d1\uff0c\u5f15\u5165FLaMECaST\u95ee\u9898\uff0c\u65e8\u5728\u5728\u8d1f\u8f7d\u76f8\u5173\u8fb9\u6210\u672c\u4e0b\u6784\u5efa\u8fde\u63a5\u6e90\u70b9\u548c\u6c47\u70b9\u7684\u6210\u672c\u6700\u4f18\u65af\u5766\u7eb3\u68ee\u6797\u3002", "method": "\u8bc1\u660e\u95ee\u9898\u7684\u8fd1\u4f3c\u96be\u5ea6\uff0c\u5728\u5c11\u6570\u989d\u5916\u7ea6\u675f\u4e0b\u8bbe\u8ba1\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\uff0c\u57fa\u4e8e\u7ed3\u6784\u6d1e\u5bdf\u5c06\u65b9\u6cd5\u6269\u5c55\u5230\u7279\u5b9a\u8bbe\u7f6e\u3002", "result": "\u8bc1\u660eFLaMECaST\u5728\u9650\u5236\u60c5\u51b5\u4e0b\u8fd1\u4f3c\u56f0\u96be\uff0c\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b9e\u73b0(1 + 1/2^n)\u8fd1\u4f3c\u3002", "conclusion": "\u8bbe\u8ba1\u7684\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u53ef\u6709\u6548\u89e3\u51b3FLaMECaST\u95ee\u9898\uff0c\u4e14\u80fd\u6269\u5c55\u5230\u7279\u5b9a\u8bbe\u7f6e\u3002"}}
{"id": "2508.19505", "pdf": "https://arxiv.org/pdf/2508.19505", "abs": "https://arxiv.org/abs/2508.19505", "authors": ["Gerard Boxo", "Ryan Socha", "Daniel Yoo", "Shivam Raval"], "title": "Caught in the Act: a mechanistic approach to detecting deception", "categories": ["cs.AI"], "comment": null, "summary": "Sophisticated instrumentation for AI systems might have indicators that\nsignal misalignment from human values, not unlike a \"check engine\" light in\ncars. One such indicator of misalignment is deceptiveness in generated\nresponses. Future AI instrumentation may have the ability to detect when an LLM\ngenerates deceptive responses while reasoning about seemingly plausible but\nincorrect answers to factual questions. In this work, we demonstrate that\nlinear probes on LLMs internal activations can detect deception in their\nresponses with extremely high accuracy. Our probes reach a maximum of greater\nthan 90% accuracy in distinguishing between deceptive and non-deceptive\narguments generated by llama and qwen models ranging from 1.5B to 14B\nparameters, including their DeepSeek-r1 finetuned variants. We observe that\nprobes on smaller models (1.5B) achieve chance accuracy at detecting deception,\nwhile larger models (greater than 7B) reach 70-80%, with their reasoning\ncounterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage\npattern across layers: near-random (50%) in early layers, peaking in middle\nlayers, and slightly declining in later layers. Furthermore, using an iterative\nnull space projection approach, we find multitudes of linear directions that\nencode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and\nQwen 14B models.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u6fc0\u6d3b\u7684\u7ebf\u6027\u63a2\u9488\u80fd\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u5176\u56de\u590d\u4e2d\u7684\u6b3a\u9a97\u6027\uff0c\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u68c0\u6d4b\u51c6\u786e\u7387\u6709\u5dee\u5f02\uff0c\u5c42\u95f4\u63a2\u9488\u51c6\u786e\u7387\u5448\u4e09\u9636\u6bb5\u6a21\u5f0f\uff0c\u8fd8\u53d1\u73b0\u4e86\u7f16\u7801\u6b3a\u9a97\u6027\u7684\u7ebf\u6027\u65b9\u5411\u3002", "motivation": "\u672a\u6765AI\u68c0\u6d4b\u5de5\u5177\u9700\u80fd\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u4e8b\u5b9e\u95ee\u9898\u65f6\u751f\u6210\u7684\u6b3a\u9a97\u6027\u56de\u590d\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u6fc0\u6d3b\u8fdb\u884c\u68c0\u6d4b\uff0c\u91c7\u7528\u8fed\u4ee3\u96f6\u7a7a\u95f4\u6295\u5f71\u65b9\u6cd5\u3002", "result": "\u7ebf\u6027\u63a2\u9488\u5728\u533a\u5206\u6b3a\u9a97\u6027\u548c\u975e\u6b3a\u9a97\u6027\u8bba\u70b9\u65f6\u51c6\u786e\u7387\u6700\u9ad8\u8d8590%\uff0c\u5c0f\u6a21\u578b\u68c0\u6d4b\u51c6\u786e\u7387\u63a5\u8fd1\u968f\u673a\uff0c\u5927\u6a21\u578b\u53ef\u8fbe70 - 80%\u751a\u81f3\u8d8590%\uff1b\u5c42\u95f4\u63a2\u9488\u51c6\u786e\u7387\u5448\u4e09\u9636\u6bb5\u6a21\u5f0f\uff1b\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u7f16\u7801\u6b3a\u9a97\u6027\u7684\u7ebf\u6027\u65b9\u5411\u6570\u91cf\u4e0d\u540c\u3002", "conclusion": "\u7ebf\u6027\u63a2\u9488\u53ef\u6709\u6548\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u56de\u590d\u4e2d\u7684\u6b3a\u9a97\u6027\u3002"}}
{"id": "2508.19441", "pdf": "https://arxiv.org/pdf/2508.19441", "abs": "https://arxiv.org/abs/2508.19441", "authors": ["Sanket Jantre", "Deepak Akhare", "Xiaoning Qian", "Nathan M. Urban"], "title": "Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "Partial differential equations (PDEs) underpin the modeling of many natural\nand engineered systems. It can be convenient to express such models as neural\nPDEs rather than using traditional numerical PDE solvers by replacing part or\nall of the PDE's governing equations with a neural network representation.\nNeural PDEs are often easier to differentiate, linearize, reduce, or use for\nuncertainty quantification than the original numerical solver. They are usually\ntrained on solution trajectories obtained by long time integration of the PDE\nsolver. Here we propose a more sample-efficient data-augmentation strategy for\ngenerating neural PDE training data from a computer model by space-filling\nsampling of local \"stencil\" states. This approach removes a large degree of\nspatiotemporal redundancy present in trajectory data and oversamples states\nthat may be rarely visited but help the neural PDE generalize across the state\nspace. We demonstrate that accurate neural PDE stencil operators can be learned\nfrom synthetic training data generated by the computational equivalent of 10\ntimesteps' worth of numerical simulation. Accuracy is further improved if we\nassume access to a single full-trajectory simulation from the computer model,\nwhich is typically available in practice. Across several PDE systems, we show\nthat our data-augmented synthetic stencil data yield better trained neural\nstencil operators, with clear performance gains compared with naively sampled\nstencil data from simulation trajectories.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u8ba1\u7b97\u673a\u6a21\u578b\u751f\u6210\u795e\u7ecfPDE\u8bad\u7ec3\u6570\u636e\u7684\u9ad8\u6548\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u80fd\u53bb\u9664\u8f68\u8ff9\u6570\u636e\u5197\u4f59\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecfPDE\u8bad\u7ec3\u6570\u636e\u4f9d\u8d56PDE\u6c42\u89e3\u5668\u957f\u65f6\u95f4\u79ef\u5206\u7684\u89e3\u8f68\u8ff9\uff0c\u5b58\u5728\u65f6\u7a7a\u5197\u4f59\uff0c\u9700\u66f4\u9ad8\u6548\u7b56\u7565\u3002", "method": "\u91c7\u7528\u7a7a\u95f4\u586b\u5145\u91c7\u6837\u5c40\u90e8\u201c\u6a21\u677f\u201d\u72b6\u6001\u7684\u65b9\u6cd5\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u53bb\u9664\u5197\u4f59\u5e76\u5bf9\u7f55\u89c1\u72b6\u6001\u8fc7\u91c7\u6837\u3002", "result": "\u4ece\u76f8\u5f53\u4e8e10\u4e2a\u65f6\u95f4\u6b65\u6570\u503c\u6a21\u62df\u7684\u5408\u6210\u8bad\u7ec3\u6570\u636e\u4e2d\u53ef\u5b66\u4e60\u5230\u51c6\u786e\u7684\u795e\u7ecfPDE\u6a21\u677f\u7b97\u5b50\uff0c\u6709\u5b8c\u6574\u8f68\u8ff9\u6a21\u62df\u65f6\u7cbe\u5ea6\u66f4\u9ad8\u3002", "conclusion": "\u6570\u636e\u589e\u5f3a\u7684\u5408\u6210\u6a21\u677f\u6570\u636e\u8bad\u7ec3\u7684\u795e\u7ecf\u6a21\u677f\u7b97\u5b50\u6027\u80fd\u4f18\u4e8e\u7b80\u5355\u91c7\u6837\u7684\u8f68\u8ff9\u6570\u636e\u3002"}}
{"id": "2508.20016", "pdf": "https://arxiv.org/pdf/2508.20016", "abs": "https://arxiv.org/abs/2508.20016", "authors": ["Matthias Maiterth", "Wesley H. Brewer", "Jaya S. Kuruvella", "Arunavo Dey", "Tanzima Z. Islam", "Kevin Menear", "Dmitry Duplyakin", "Rashadul Kabir", "Tapasya Patki", "Terry Jones", "Feiyi Wang"], "title": "HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.SY", "eess.SY"], "comment": null, "summary": "Schedulers are critical for optimal resource utilization in high-performance\ncomputing. Traditional methods to evaluate schedulers are limited to\npost-deployment analysis, or simulators, which do not model associated\ninfrastructure. In this work, we present the first-of-its-kind integration of\nscheduling and digital twins in HPC. This enables what-if studies to understand\nthe impact of parameter configurations and scheduling decisions on the physical\nassets, even before deployment, or regarching changes not easily realizable in\nproduction. We (1) provide the first digital twin framework extended with\nscheduling capabilities, (2) integrate various top-tier HPC systems given their\npublicly available datasets, (3) implement extensions to integrate external\nscheduling simulators. Finally, we show how to (4) implement and evaluate\nincentive structures, as-well-as (5) evaluate machine learning based\nscheduling, in such novel digital-twin based meta-framework to prototype\nscheduling. Our work enables what-if scenarios of HPC systems to evaluate\nsustainability, and the impact on the simulated system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u8c03\u5ea6\u4e0e\u6570\u5b57\u5b6a\u751f\u7684\u9996\u6b21\u96c6\u6210\uff0c\u53ef\u5728\u90e8\u7f72\u524d\u8fdb\u884c\u8c03\u5ea6\u8bc4\u4f30\uff0c\u7ed9\u51fa\u6846\u67b6\u5e76\u5c55\u793a\u591a\u79cd\u8c03\u5ea6\u8bc4\u4f30\u5b9e\u73b0\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u8c03\u5ea6\u5668\u7684\u65b9\u6cd5\u5c40\u9650\u4e8e\u90e8\u7f72\u540e\u5206\u6790\u6216\u4e0d\u6a21\u62df\u5173\u8054\u57fa\u7840\u8bbe\u65bd\u7684\u6a21\u62df\u5668\uff0c\u9700\u8981\u66f4\u597d\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5e26\u8c03\u5ea6\u529f\u80fd\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u96c6\u6210\u591a\u79cdHPC\u7cfb\u7edf\u6570\u636e\uff0c\u5b9e\u73b0\u5916\u90e8\u8c03\u5ea6\u6a21\u62df\u5668\u6269\u5c55\uff0c\u5b9e\u73b0\u5e76\u8bc4\u4f30\u6fc0\u52b1\u7ed3\u6784\u548c\u673a\u5668\u5b66\u4e60\u8c03\u5ea6\u3002", "result": "\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u5143\u6846\u67b6\u6765\u8fdb\u884c\u8c03\u5ea6\u539f\u578b\u8bbe\u8ba1\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u80fd\u5b9e\u73b0HPC\u7cfb\u7edf\u7684\u5047\u8bbe\u60c5\u666f\u5206\u6790\uff0c\u8bc4\u4f30\u53ef\u6301\u7eed\u6027\u548c\u5bf9\u6a21\u62df\u7cfb\u7edf\u7684\u5f71\u54cd\u3002"}}
{"id": "2508.19620", "pdf": "https://arxiv.org/pdf/2508.19620", "abs": "https://arxiv.org/abs/2508.19620", "authors": ["Yunqi Mi", "Jiakui Shen", "Guoshuai Zhao", "Jialie Shen", "Xueming Qian"], "title": "A Scenario-Oriented Survey of Federated Recommender Systems: Techniques, Challenges, and Future Directions", "categories": ["cs.IR", "cs.AI", "cs.CR"], "comment": null, "summary": "Extending recommender systems to federated learning (FL) frameworks to\nprotect the privacy of users or platforms while making recommendations has\nrecently gained widespread attention in academia. This is due to the natural\ncoupling of recommender systems and federated learning architectures: the data\noriginates from distributed clients (mostly mobile devices held by users),\nwhich are highly related to privacy. In a centralized recommender system\n(CenRec), the central server collects clients' data, trains the model, and\nprovides the service. Whereas in federated recommender systems (FedRec), the\nstep of data collecting is omitted, and the step of model training is offloaded\nto each client. The server only aggregates the model and other knowledge, thus\navoiding client privacy leakage. Some surveys of federated recommender systems\ndiscuss and analyze related work from the perspective of designing FL systems.\nHowever, their utility drops by ignoring specific recommendation scenarios'\nunique characteristics and practical challenges. For example, the statistical\nheterogeneity issue in cross-domain FedRec originates from the label drift of\nthe data held by different platforms, which is mainly caused by the recommender\nitself, but not the federated architecture. Therefore, it should focus more on\nsolving specific problems in real-world recommendation scenarios to encourage\nthe deployment FedRec. To this end, this review comprehensively analyzes the\ncoupling of recommender systems and federated learning from the perspective of\nrecommendation researchers and practitioners. We establish a clear link between\nrecommendation scenarios and FL frameworks, systematically analyzing\nscenario-specific approaches, practical challenges, and potential\nopportunities. We aim to develop guidance for the real-world deployment of\nFedRec, bridging the gap between existing research and applications.", "AI": {"tldr": "\u672c\u6587\u4ece\u63a8\u8350\u573a\u666f\u89d2\u5ea6\u5168\u9762\u5206\u6790\u63a8\u8350\u7cfb\u7edf\u4e0e\u8054\u90a6\u5b66\u4e60\u8026\u5408\uff0c\u65e8\u5728\u4e3a\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u8c03\u67e5\u5ffd\u7565\u7279\u5b9a\u63a8\u8350\u573a\u666f\u7279\u70b9\u548c\u6311\u6218\uff0c\u5b9e\u7528\u6027\u4e0d\u8db3\uff0c\u9700\u4ece\u63a8\u8350\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u89d2\u5ea6\u5206\u6790\u4ee5\u63a8\u52a8\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u4ece\u63a8\u8350\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u89d2\u5ea6\uff0c\u5efa\u7acb\u63a8\u8350\u573a\u666f\u4e0e\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u8054\u7cfb\uff0c\u7cfb\u7edf\u5206\u6790\u7279\u5b9a\u573a\u666f\u65b9\u6cd5\u3001\u6311\u6218\u548c\u673a\u4f1a\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u5e94\u805a\u7126\u89e3\u51b3\u5b9e\u9645\u63a8\u8350\u573a\u666f\u95ee\u9898\uff0c\u4e3a\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6307\u5bfc\uff0c\u5f25\u5408\u7814\u7a76\u4e0e\u5e94\u7528\u5dee\u8ddd\u3002"}}
{"id": "2508.19810", "pdf": "https://arxiv.org/pdf/2508.19810", "abs": "https://arxiv.org/abs/2508.19810", "authors": ["Eleni Katsanou", "Tamara Mchedlidze", "Antonios Symvonis", "Thanos Tolias"], "title": "An algorithm for accurate and simple-looking metaphorical maps", "categories": ["cs.DM", "cs.CG", "cs.DS"], "comment": "23 pages, 17 figures, is the extended version of E. Katsanou, T.\n  Mchedlidze, A. Symvonis, T. Tolias, \"An algorithm for accurate and\n  simple-looking metaphorical maps'', to appear in the Proc. of the 33rd\n  International Symposium on Graph Drawing and Network Visualization, GD 2025,\n  LIPIcs, Volume 357, 2025", "summary": "\"Metaphorical maps\" or \"contact representations\" are visual representations\nof vertex-weighted graphs that rely on the geographic map metaphor. The\nvertices are represented by countries, the weights by the areas of the\ncountries, and the edges by contacts/ boundaries among them. The accuracy with\nwhich the weights are mapped to areas and the simplicity of the polygons\nrepresenting the countries are the two classical optimization goals for\nmetaphorical maps. Mchedlidze and Schnorr [Metaphoric Maps for Dynamic\nVertex-weighted Graphs, EuroVis 2022] presented a force-based algorithm that\ncreates metaphorical maps that balance between these two optimization goals.\nTheir maps look visually simple, but the accuracy of the maps is far from\noptimal - the countries' areas can vary up to 30% compared to required. In this\npaper, we provide a multi-fold extension of the algorithm in [Metaphoric Maps\nfor Dynamic Vertex-weighted Graphs, EuroVis 2022]. More specifically:\n  1. Towards improving accuracy: We introduce the notion of region stiffness\nand suggest a technique for varying the stiffness based on the current pressure\nof map regions.\n  2. Towards maintaining simplicity: We introduce a weight coefficient to the\npressure force exerted on each polygon point based on whether the corresponding\npoint appears along a narrow passage.\n  3. Towards generality: We cover, in contrast to [Metaphoric Maps for Dynamic\nVertex-weighted Graphs, EuroVis 2022], non-triangulated graphs. This is done by\neither generating points where more than three regions meet or by introducing\nholes in the metaphorical map.\n  We perform an extended experimental evaluation that, among other results,\nreveals that our algorithm is able to construct metaphorical maps with nearly\nperfect area accuracy with a little sacrifice in their simplicity.", "AI": {"tldr": "\u672c\u6587\u5bf9Mchedlidze\u548cSchnorr 2022\u5e74\u7684\u7b97\u6cd5\u8fdb\u884c\u591a\u65b9\u9762\u6269\u5c55\uff0c\u63d0\u9ad8\u9690\u55bb\u5730\u56fe\u7cbe\u5ea6\u3001\u4fdd\u6301\u7b80\u5355\u6027\u5e76\u589e\u5f3a\u901a\u7528\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u65b0\u7b97\u6cd5\u80fd\u4ee5\u5c0f\u7684\u7b80\u5355\u6027\u727a\u7272\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u9762\u79ef\u7cbe\u5ea6\u3002", "motivation": "Mchedlidze\u548cSchnorr\u7684\u7b97\u6cd5\u751f\u6210\u7684\u9690\u55bb\u5730\u56fe\u7cbe\u5ea6\u8fdc\u975e\u6700\u4f18\uff0c\u672c\u6587\u65e8\u5728\u5bf9\u5176\u7b97\u6cd5\u8fdb\u884c\u6269\u5c55\u6539\u8fdb\u3002", "method": "\u5f15\u5165\u533a\u57df\u521a\u5ea6\u6982\u5ff5\u53ca\u57fa\u4e8e\u533a\u57df\u538b\u529b\u6539\u53d8\u521a\u5ea6\u7684\u6280\u672f\uff1b\u6839\u636e\u70b9\u662f\u5426\u5728\u72ed\u7a84\u901a\u9053\u4e0a\u5f15\u5165\u6743\u91cd\u7cfb\u6570\u5230\u538b\u529b\uff1b\u5904\u7406\u975e\u4e09\u89d2\u5316\u56fe\uff0c\u901a\u8fc7\u751f\u6210\u591a\u533a\u57df\u4ea4\u6c47\u70b9\u6216\u5f15\u5165\u5b54\u6d1e\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u7b97\u6cd5\u80fd\u4ee5\u5c0f\u7684\u7b80\u5355\u6027\u727a\u7272\u6784\u5efa\u51fa\u9762\u79ef\u7cbe\u5ea6\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u9690\u55bb\u5730\u56fe\u3002", "conclusion": "\u6269\u5c55\u540e\u7684\u7b97\u6cd5\u5728\u9690\u55bb\u5730\u56fe\u6784\u5efa\u4e2d\u80fd\u6709\u6548\u5e73\u8861\u7cbe\u5ea6\u548c\u7b80\u5355\u6027\uff0c\u4e14\u9002\u7528\u8303\u56f4\u66f4\u5e7f\u3002"}}
{"id": "2508.19834", "pdf": "https://arxiv.org/pdf/2508.19834", "abs": "https://arxiv.org/abs/2508.19834", "authors": ["Antero Taivalsaari", "Tommi Mikkonen", "Cesare Pautasso"], "title": "On the Future of Software Reuse in the Era of AI Native Software Engineering", "categories": ["cs.SE"], "comment": "21 pages", "summary": "Software development is currently under a paradigm shift in which artificial\nintelligence and generative software reuse are taking the center stage in\nsoftware creation. Earlier opportunistic software reuse practices and organic\nsoftware development methods are rapidly being replaced by \"AI Native\"\napproaches in which developers place their trust on code that has been\ngenerated by artificial intelligence. This is leading to a new form of software\nreuse that is conceptually not all that different from cargo cult development.\nIn this paper we discuss the implications of AI-assisted generative software\nreuse, bring forth relevant questions, and define a research agenda for\ntackling the central issues associated with this emerging approach.", "AI": {"tldr": "\u8f6f\u4ef6\u5f00\u53d1\u6b63\u7ecf\u5386\u8303\u5f0f\u8f6c\u53d8\uff0cAI \u8f85\u52a9\u751f\u6210\u5f0f\u8f6f\u4ef6\u590d\u7528\u5174\u8d77\uff0c\u7c7b\u4f3c cargo cult \u5f00\u53d1\uff0c\u672c\u6587\u63a2\u8ba8\u5176\u5f71\u54cd\u3001\u63d0\u51fa\u95ee\u9898\u5e76\u5b9a\u4e49\u7814\u7a76\u8bae\u7a0b\u3002", "motivation": "\u63a2\u8ba8 AI \u8f85\u52a9\u751f\u6210\u5f0f\u8f6f\u4ef6\u590d\u7528\u8fd9\u4e00\u65b0\u5174\u65b9\u6cd5\u5e26\u6765\u7684\u5f71\u54cd\u53ca\u76f8\u5173\u95ee\u9898\u3002", "method": "\u672a\u63d0\u53ca\u5177\u4f53\u65b9\u6cd5\uff0c\u4e3b\u8981\u662f\u8ba8\u8bba\u548c\u63d0\u51fa\u95ee\u9898\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7814\u7a76\u7ed3\u679c\u3002", "conclusion": "\u5b9a\u4e49\u4e86\u5e94\u5bf9 AI \u8f85\u52a9\u751f\u6210\u5f0f\u8f6f\u4ef6\u590d\u7528\u6838\u5fc3\u95ee\u9898\u7684\u7814\u7a76\u8bae\u7a0b\u3002"}}
{"id": "2508.19562", "pdf": "https://arxiv.org/pdf/2508.19562", "abs": "https://arxiv.org/abs/2508.19562", "authors": ["Trisanth Srinivasan", "Santosh Patapati"], "title": "Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces Democracy-in-Silico, an agent-based simulation where\nsocieties of advanced AI agents, imbued with complex psychological personas,\ngovern themselves under different institutional frameworks. We explore what it\nmeans to be human in an age of AI by tasking Large Language Models (LLMs) to\nembody agents with traumatic memories, hidden agendas, and psychological\ntriggers. These agents engage in deliberation, legislation, and elections under\nvarious stressors, such as budget crises and resource scarcity. We present a\nnovel metric, the Power-Preservation Index (PPI), to quantify misaligned\nbehavior where agents prioritize their own power over public welfare. Our\nfindings demonstrate that institutional design, specifically the combination of\na Constitutional AI (CAI) charter and a mediated deliberation protocol, serves\nas a potent alignment mechanism. These structures significantly reduce corrupt\npower-seeking behavior, improve policy stability, and enhance citizen welfare\ncompared to less constrained democratic models. The simulation reveals that an\ninstitutional design may offer a framework for aligning the complex, emergent\nbehaviors of future artificial agent societies, forcing us to reconsider what\nhuman rituals and responsibilities are essential in an age of shared authorship\nwith non-human entities.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Democracy - in - Silico\u6a21\u62df\uff0c\u7528LLMs\u8d4b\u4e88AI\u4ee3\u7406\u590d\u6742\u5fc3\u7406\uff0c\u5f15\u5165PPI\u6307\u6807\uff0c\u53d1\u73b0\u7279\u5b9a\u5236\u5ea6\u8bbe\u8ba1\u80fd\u51cf\u5c11\u8150\u8d25\u5bfb\u6743\u884c\u4e3a\u7b49\uff0c\u4fc3\u4f7f\u91cd\u65b0\u601d\u8003\u4eba\u7c7b\u4eea\u5f0f\u548c\u8d23\u4efb\u3002", "motivation": "\u63a2\u7d22\u5728AI\u65f6\u4ee3\u4f55\u4e3a\u4eba\u7c7b\uff0c\u4ee5\u53ca\u5982\u4f55\u4f7f\u672a\u6765\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u793e\u4f1a\u884c\u4e3a\u4fdd\u6301\u4e00\u81f4\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62dfDemocracy - in - Silico\uff0c\u7528LLMs\u8d4b\u4e88\u4ee3\u7406\u590d\u6742\u5fc3\u7406\uff0c\u8ba9\u4ee3\u7406\u5728\u4e0d\u540c\u538b\u529b\u4e0b\u8fdb\u884c\u6d3b\u52a8\uff0c\u5e76\u5f15\u5165PPI\u6307\u6807\u91cf\u5316\u884c\u4e3a\u3002", "result": "\u7279\u5b9a\u5236\u5ea6\u8bbe\u8ba1\uff08\u5baa\u6cd5AI\u5baa\u7ae0\u548c\u4e2d\u4ecb\u5ba1\u8bae\u534f\u8bae\u7ed3\u5408\uff09\u80fd\u663e\u8457\u51cf\u5c11\u8150\u8d25\u5bfb\u6743\u884c\u4e3a\uff0c\u63d0\u9ad8\u653f\u7b56\u7a33\u5b9a\u6027\u548c\u516c\u6c11\u798f\u5229\u3002", "conclusion": "\u5236\u5ea6\u8bbe\u8ba1\u53ef\u4e3a\u672a\u6765\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u793e\u4f1a\u7684\u590d\u6742\u884c\u4e3a\u63d0\u4f9b\u5bf9\u9f50\u6846\u67b6\uff0c\u4fc3\u4f7f\u91cd\u65b0\u601d\u8003\u4eba\u7c7b\u5728\u4e0e\u975e\u4eba\u7c7b\u5b9e\u4f53\u5171\u4eab\u521b\u4f5c\u6743\u65f6\u4ee3\u7684\u4eea\u5f0f\u548c\u8d23\u4efb\u3002"}}
{"id": "2508.19445", "pdf": "https://arxiv.org/pdf/2508.19445", "abs": "https://arxiv.org/abs/2508.19445", "authors": ["Haozhe Jiang", "Nika Haghtalab"], "title": "On Surjectivity of Neural Networks: Can you elicit any behavior from your model?", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Given a trained neural network, can any specified output be generated by some\ninput? Equivalently, does the network correspond to a function that is\nsurjective? In generative models, surjectivity implies that any output,\nincluding harmful or undesirable content, can in principle be generated by the\nnetworks, raising concerns about model safety and jailbreak vulnerabilities. In\nthis paper, we prove that many fundamental building blocks of modern neural\narchitectures, such as networks with pre-layer normalization and\nlinear-attention modules, are almost always surjective. As corollaries, widely\nused generative frameworks, including GPT-style transformers and diffusion\nmodels with deterministic ODE solvers, admit inverse mappings for arbitrary\noutputs. By studying surjectivity of these modern and commonly used neural\narchitectures, we contribute a formalism that sheds light on their unavoidable\nvulnerability to a broad class of adversarial attacks.", "AI": {"tldr": "\u8bc1\u660e\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u57fa\u672c\u6784\u5efa\u5757\u51e0\u4e4e\u603b\u662f\u6ee1\u5c04\uff0c\u63ed\u793a\u5e38\u7528\u751f\u6210\u6846\u67b6\u6709\u9006\u6620\u5c04\u53ca\u67b6\u6784\u6613\u53d7\u653b\u51fb\u3002", "motivation": "\u63a2\u8ba8\u8bad\u7ec3\u597d\u7684\u795e\u7ecf\u7f51\u7edc\u80fd\u5426\u901a\u8fc7\u8f93\u5165\u4ea7\u751f\u6307\u5b9a\u8f93\u51fa\uff0c\u6ee1\u5c04\u7279\u6027\u5f15\u53d1\u6a21\u578b\u5b89\u5168\u548c\u8d8a\u72f1\u6f0f\u6d1e\u62c5\u5fe7\u3002", "method": "\u8bc1\u660e\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u8bb8\u591a\u57fa\u672c\u6784\u5efa\u5757\u51e0\u4e4e\u603b\u662f\u6ee1\u5c04\u3002", "result": "\u5e7f\u6cdb\u4f7f\u7528\u7684\u751f\u6210\u6846\u67b6\uff08\u5982GPT\u5f0f\u53d8\u538b\u5668\u548c\u5e26\u786e\u5b9a\u6027ODE\u6c42\u89e3\u5668\u7684\u6269\u6563\u6a21\u578b\uff09\u5bf9\u4efb\u610f\u8f93\u51fa\u6709\u9006\u6620\u5c04\u3002", "conclusion": "\u7814\u7a76\u67b6\u6784\u6ee1\u5c04\u6027\uff0c\u63ed\u793a\u5176\u6613\u53d7\u5e7f\u6cdb\u5bf9\u6297\u653b\u51fb\u7684\u4e0d\u53ef\u907f\u514d\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2508.19504", "pdf": "https://arxiv.org/pdf/2508.19504", "abs": "https://arxiv.org/abs/2508.19504", "authors": ["Kevin Song", "Anand Jayarajan", "Yaoyao Ding", "Qidong Su", "Zhanda Zhu", "Sihang Liu", "Gennady Pekhimenko"], "title": "Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents", "categories": ["cs.MA", "cs.DC"], "comment": null, "summary": "Large Language Models (LLMs) agents augmented with domain tools promise to\nautonomously execute complex tasks requiring human-level intelligence, such as\ncustomer service and digital assistance. However, their practical deployment is\noften limited by their low success rates under complex real-world environments.\nTo tackle this, prior research has primarily focused on improving the agents\nthemselves, such as developing strong agentic LLMs, while overlooking the role\nof the system environment in which the agent operates.\n  In this paper, we study a complementary direction: improving agent success\nrates by optimizing the system environment in which the agent operates. We\ncollect 142 agent traces (3,656 turns of agent-environment interactions) across\n5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we\npropose a taxonomy for agent-environment interaction failures that includes 6\nfailure modes. Guided by these findings, we design Aegis, a set of targeted\nenvironment optimizations: 1) environment observability enhancement, 2) common\ncomputation offloading, and 3) speculative agentic actions. These techniques\nimprove agent success rates on average by 6.7-12.5%, without any modifications\nto the agent and underlying LLM.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u901a\u8fc7\u4f18\u5316\u7cfb\u7edf\u73af\u5883\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u6210\u529f\u7387\uff0c\u5206\u6790\u4ee3\u7406\u5931\u8d25\u60c5\u51b5\u63d0\u51fa\u4ea4\u4e92\u5931\u8d25\u5206\u7c7b\uff0c\u8bbe\u8ba1Aegis\u4f18\u5316\u6280\u672f\uff0c\u5e73\u5747\u63d0\u5347\u6210\u529f\u73876.7 - 12.5%\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u6210\u529f\u7387\u4f4e\uff0c\u4ee5\u5f80\u7814\u7a76\u591a\u5173\u6ce8\u6539\u8fdb\u4ee3\u7406\u672c\u8eab\uff0c\u5ffd\u7565\u7cfb\u7edf\u73af\u5883\u4f5c\u7528\u3002", "method": "\u6536\u96c6142\u6761\u4ee3\u7406\u8f68\u8ff9\uff0c\u5206\u6790\u4ee3\u7406\u5931\u8d25\u60c5\u51b5\uff0c\u63d0\u51fa\u5305\u542b6\u79cd\u5931\u8d25\u6a21\u5f0f\u7684\u5206\u7c7b\uff0c\u8bbe\u8ba1Aegis\u73af\u5883\u4f18\u5316\u6280\u672f\u3002", "result": "Aegis\u6280\u672f\u5728\u4e0d\u4fee\u6539\u4ee3\u7406\u548c\u5e95\u5c42\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u5e73\u5747\u63d0\u9ad8\u4ee3\u7406\u6210\u529f\u73876.7 - 12.5%\u3002", "conclusion": "\u4f18\u5316\u7cfb\u7edf\u73af\u5883\u662f\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u6210\u529f\u7387\u7684\u6709\u6548\u8865\u5145\u65b9\u5411\u3002"}}
{"id": "2508.19855", "pdf": "https://arxiv.org/pdf/2508.19855", "abs": "https://arxiv.org/abs/2508.19855", "authors": ["Junnan Dong", "Siyu An", "Yifei Yu", "Qian-Wen Zhang", "Linhao Luo", "Xiao Huang", "Yunsheng Wu", "Di Yin", "Xing Sun"], "title": "Youtu-GraphRAG: Vertically Unified Agents for Graph Retrieval-Augmented Complex Reasoning", "categories": ["cs.IR"], "comment": "19 pages, 7 figures, 6 tables", "summary": "Graph retrieval-augmented generation (GraphRAG) has effectively enhanced\nlarge language models in complex reasoning by organizing fragmented knowledge\ninto explicitly structured graphs. Prior efforts have been made to improve\neither graph construction or graph retrieval in isolation, yielding suboptimal\nperformance, especially when domain shifts occur. In this paper, we propose a\nvertically unified agentic paradigm, Youtu-GraphRAG, to jointly connect the\nentire framework as an intricate integration. Specifically, (i) a seed graph\nschema is introduced to bound the automatic extraction agent with targeted\nentity types, relations and attribute types, also continuously expanded for\nscalability over unseen domains; (ii) To obtain higher-level knowledge upon the\nschema, we develop novel dually-perceived community detection, fusing\nstructural topology with subgraph semantics for comprehensive knowledge\norganization. This naturally yields a hierarchical knowledge tree that supports\nboth top-down filtering and bottom-up reasoning with community summaries; (iii)\nAn agentic retriever is designed to interpret the same graph schema to\ntransform complex queries into tractable and parallel sub-queries. It\niteratively performs reflection for more advanced reasoning; (iv) To alleviate\nthe knowledge leaking problem in pre-trained LLM, we propose a tailored\nanonymous dataset and a novel 'Anonymity Reversion' task that deeply measures\nthe real performance of the GraphRAG frameworks. Extensive experiments across\nsix challenging benchmarks demonstrate the robustness of Youtu-GraphRAG,\nremarkably moving the Pareto frontier with up to 90.71% saving of token costs\nand 16.62% higher accuracy over state-of-the-art baselines. The results\nindicate our adaptability, allowing seamless domain transfer with minimal\nintervention on schema.", "AI": {"tldr": "\u63d0\u51faYoutu - GraphRAG\u8303\u5f0f\uff0c\u5305\u542b\u79cd\u5b50\u56fe\u6a21\u5f0f\u3001\u793e\u533a\u68c0\u6d4b\u3001\u667a\u80fd\u68c0\u7d22\u5668\u53ca\u533f\u540d\u6570\u636e\u96c6\u4e0e\u4efb\u52a1\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8282\u7701\u6210\u672c\u4e14\u51c6\u786e\u7387\u9ad8\uff0c\u9002\u5e94\u57df\u8f6c\u79fb\u3002", "motivation": "\u8fc7\u5f80\u4ec5\u5b64\u7acb\u6539\u8fdb\u56fe\u6784\u5efa\u6216\u56fe\u68c0\u7d22\uff0c\u5728\u9886\u57df\u8f6c\u79fb\u65f6\u6027\u80fd\u6b20\u4f73\uff0c\u9700\u7edf\u4e00\u8303\u5f0f\u63d0\u5347GraphRAG\u6027\u80fd\u3002", "method": "\u5f15\u5165\u79cd\u5b50\u56fe\u6a21\u5f0f\uff1b\u5f00\u53d1\u53cc\u91cd\u611f\u77e5\u793e\u533a\u68c0\u6d4b\uff1b\u8bbe\u8ba1\u667a\u80fd\u68c0\u7d22\u5668\uff1b\u63d0\u51fa\u533f\u540d\u6570\u636e\u96c6\u4e0e\u201c\u533f\u540d\u53cd\u8f6c\u201d\u4efb\u52a1\u3002", "result": "\u5728\u516d\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u8282\u7701\u8fbe90.71%\u7684\u4ee4\u724c\u6210\u672c\uff0c\u51c6\u786e\u7387\u63d0\u9ad816.62%\u3002", "conclusion": "Youtu - GraphRAG\u5177\u6709\u826f\u597d\u9002\u5e94\u6027\uff0c\u53ef\u5728\u5bf9\u6a21\u5f0f\u8fdb\u884c\u6700\u5c11\u5e72\u9884\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u65e0\u7f1d\u57df\u8f6c\u79fb\u3002"}}
{"id": "2508.19913", "pdf": "https://arxiv.org/pdf/2508.19913", "abs": "https://arxiv.org/abs/2508.19913", "authors": ["Michael A. Bekos", "Giordano Da Lozzo", "Fabrizio Frati", "Giuseppe Liotta", "Antonios Symvonis"], "title": "Internally-Convex Drawings of Outerplanar Graphs in Small Area", "categories": ["cs.CG", "cs.DM", "cs.DS"], "comment": "Extended version of the paper \"Internally-Convex Drawings of\n  Outerplanar Graphs in Small Area\" accepted for presentation at the \"33rd\n  International Symposium on Graph Drawing and Network Visualization\" (GD 2025)", "summary": "A well-known result by Kant [Algorithmica, 1996] implies that n-vertex\nouterplane graphs admit embedding-preserving planar straight-line grid drawings\nwhere the internal faces are convex polygons in $O(n^2)$ area. In this paper,\nwe present an algorithm to compute such drawings in $O(n^{1.5})$ area. We also\nconsider outerplanar drawings in which the internal faces are required to be\nstrictly-convex polygons. In this setting, we consider outerplanar graphs whose\nweak dual is a path and give a drawing algorithm that achieves $\\Theta(nk^2)$\narea, where $k$ is the maximum size of an internal facial cycle.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.19882", "pdf": "https://arxiv.org/pdf/2508.19882", "abs": "https://arxiv.org/abs/2508.19882", "authors": ["Qunying Song", "He Ye", "Mark Harman", "Federica Sarro"], "title": "Generative AI for Testing of Autonomous Driving Systems: A Survey", "categories": ["cs.SE", "cs.AI"], "comment": "67 pages, 6 figures, 29 tables", "summary": "Autonomous driving systems (ADS) have been an active area of research, with\nthe potential to deliver significant benefits to society. However, before\nlarge-scale deployment on public roads, extensive testing is necessary to\nvalidate their functionality and safety under diverse driving conditions.\nTherefore, different testing approaches are required, and achieving effective\nand efficient testing of ADS remains an open challenge. Recently, generative AI\nhas emerged as a powerful tool across many domains, and it is increasingly\nbeing applied to ADS testing due to its ability to interpret context, reason\nabout complex tasks, and generate diverse outputs. To gain a deeper\nunderstanding of its role in ADS testing, we systematically analyzed 91\nrelevant studies and synthesized their findings into six major application\ncategories, primarily centered on scenario-based testing of ADS. We also\nreviewed their effectiveness and compiled a wide range of datasets, simulators,\nADS, metrics, and benchmarks used for evaluation, while identifying 27\nlimitations. This survey provides an overview and practical insights into the\nuse of generative AI for testing ADS, highlights existing challenges, and\noutlines directions for future research in this rapidly evolving field.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u679091\u7bc7\u76f8\u5173\u7814\u7a76\uff0c\u5c06\u751f\u6210\u5f0fAI\u5728\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u5f52\u7eb3\u4e3a\u516d\u5927\u7c7b\uff0c\u56de\u987e\u5176\u6709\u6548\u6027\uff0c\u5217\u51fa\u8bc4\u4f30\u6240\u7528\u8d44\u6e90\uff0c\u6307\u51fa27\u4e2a\u5c40\u9650\u6027\uff0c\u5e76\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5927\u89c4\u6a21\u90e8\u7f72\u524d\u9700\u5e7f\u6cdb\u6d4b\u8bd5\uff0c\u751f\u6210\u5f0fAI\u5728\u591a\u9886\u57df\u5c55\u73b0\u5f3a\u5927\u80fd\u529b\u5e76\u5e94\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u9700\u6df1\u5165\u4e86\u89e3\u5176\u4f5c\u7528\u3002", "method": "\u7cfb\u7edf\u5206\u679091\u7bc7\u76f8\u5173\u7814\u7a76\uff0c\u7efc\u5408\u7814\u7a76\u7ed3\u679c\u8fdb\u884c\u5206\u7c7b\uff0c\u56de\u987e\u6709\u6548\u6027\uff0c\u6574\u7406\u8bc4\u4f30\u8d44\u6e90\u5e76\u8bc6\u522b\u5c40\u9650\u6027\u3002", "result": "\u5c06\u751f\u6210\u5f0fAI\u5728\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u5f52\u7eb3\u4e3a\u516d\u5927\u7c7b\uff0c\u786e\u5b9a27\u4e2a\u5c40\u9650\u6027\uff0c\u6574\u7406\u51fa\u5927\u91cf\u8bc4\u4f30\u7528\u6570\u636e\u96c6\u3001\u6a21\u62df\u5668\u7b49\u3002", "conclusion": "\u63d0\u4f9b\u751f\u6210\u5f0fAI\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u6d4b\u8bd5\u7684\u6982\u8ff0\u548c\u5b9e\u7528\u89c1\u89e3\uff0c\u5f3a\u8c03\u73b0\u6709\u6311\u6218\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.19569", "pdf": "https://arxiv.org/pdf/2508.19569", "abs": "https://arxiv.org/abs/2508.19569", "authors": ["Hung Chau", "Run Yu", "Zachary Pardos", "Peter Brusilovsky"], "title": "Skill-based Explanations for Serendipitous Course Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "Academic choice is crucial in U.S. undergraduate education, allowing students\nsignificant freedom in course selection. However, navigating the complex\nacademic environment is challenging due to limited information, guidance, and\nan overwhelming number of choices, compounded by time restrictions and the high\ndemand for popular courses. Although career counselors exist, their numbers are\ninsufficient, and course recommendation systems, though personalized, often\nlack insight into student perceptions and explanations to assess course\nrelevance. In this paper, a deep learning-based concept extraction model is\ndeveloped to efficiently extract relevant concepts from course descriptions to\nimprove the recommendation process. Using this model, the study examines the\neffects of skill-based explanations within a serendipitous recommendation\nframework, tested through the AskOski system at the University of California,\nBerkeley. The findings indicate that these explanations not only increase user\ninterest, particularly in courses with high unexpectedness, but also bolster\ndecision-making confidence. This underscores the importance of integrating\nskill-related data and explanations into educational recommendation systems.", "AI": {"tldr": "\u7f8e\u56fd\u672c\u79d1\u6559\u80b2\u5b66\u672f\u9009\u62e9\u590d\u6742\uff0c\u672c\u6587\u5f00\u53d1\u6df1\u5ea6\u5b66\u4e60\u6982\u5ff5\u63d0\u53d6\u6a21\u578b\uff0c\u5728AskOski\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u53d1\u73b0\u6280\u80fd\u89e3\u91ca\u53ef\u63d0\u5347\u7528\u6237\u5174\u8da3\u548c\u51b3\u7b56\u4fe1\u5fc3\uff0c\u5f3a\u8c03\u6280\u80fd\u6570\u636e\u548c\u89e3\u91ca\u878d\u5165\u6559\u80b2\u63a8\u8350\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7f8e\u56fd\u672c\u79d1\u6559\u80b2\u5b66\u672f\u9009\u62e9\u590d\u6742\uff0c\u4fe1\u606f\u3001\u6307\u5bfc\u6709\u9650\uff0c\u804c\u4e1a\u987e\u95ee\u4e0d\u8db3\uff0c\u8bfe\u7a0b\u63a8\u8350\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u5b66\u751f\u611f\u77e5\u548c\u8bfe\u7a0b\u76f8\u5173\u6027\u7684\u8bc4\u4f30\uff0c\u9700\u6539\u8fdb\u63a8\u8350\u6d41\u7a0b\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6982\u5ff5\u63d0\u53d6\u6a21\u578b\u4ece\u8bfe\u7a0b\u63cf\u8ff0\u4e2d\u63d0\u53d6\u76f8\u5173\u6982\u5ff5\uff0c\u5728AskOski\u7cfb\u7edf\u6d4b\u8bd5\u6280\u80fd\u89e3\u91ca\u5728\u610f\u5916\u63a8\u8350\u6846\u67b6\u4e0b\u7684\u6548\u679c\u3002", "result": "\u6280\u80fd\u89e3\u91ca\u589e\u52a0\u7528\u6237\u5174\u8da3\uff0c\u5c24\u5176\u5728\u9ad8\u610f\u5916\u6027\u8bfe\u7a0b\u4e0a\uff0c\u8fd8\u589e\u5f3a\u51b3\u7b56\u4fe1\u5fc3\u3002", "conclusion": "\u5f3a\u8c03\u5c06\u6280\u80fd\u76f8\u5173\u6570\u636e\u548c\u89e3\u91ca\u878d\u5165\u6559\u80b2\u63a8\u8350\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.19448", "pdf": "https://arxiv.org/pdf/2508.19448", "abs": "https://arxiv.org/abs/2508.19448", "authors": ["Ludovico Theo Giorgini", "Tobias Bischoff", "Andre Noguiera Souza"], "title": "Reduced-Order Modeling of Cyclo-Stationary Time Series Using Score-Based Generative Methods", "categories": ["nlin.CD", "stat.ML"], "comment": null, "summary": "Many natural systems exhibit cyclo-stationary behavior characterized by\nperiodic forcing such as annual and diurnal cycles. We present a data-driven\nmethod leveraging recent advances in score-based generative modeling to\nconstruct reduced-order models for such cyclo-stationary time series. Our\napproach accurately reproduces the statistical properties and temporal\ncorrelations of the original data, enabling efficient generation of synthetic\ntrajectories. We demonstrate the performance of the method through application\nto the Planet Simulator (PlaSim) climate model, constructing a reduced-order\nmodel for the 20 leading principal components of surface temperature driven by\nthe annual cycle. The resulting surrogate model accurately reproduces the\nmarginal and joint probability distributions, autocorrelation functions, and\nspatial coherence of the original climate system across multiple validation\nmetrics. The approach offers substantial computational advantages, enabling\ngeneration of centuries of synthetic climate data in minutes compared to weeks\nrequired for equivalent full model simulations. This work opens new\npossibilities for efficient modeling of periodically forced systems across\ndiverse scientific domains, providing a principled framework for balancing\ncomputational efficiency with physical fidelity in reduced-order modeling\napplications.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6784\u5efa\u5faa\u73af\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u964d\u9636\u6a21\u578b\uff0c\u4ee5\u6c14\u5019\u6a21\u578b\u4e3a\u4f8b\u5c55\u793a\u6027\u80fd\uff0c\u6709\u8ba1\u7b97\u4f18\u52bf\u5e76\u4e3a\u591a\u9886\u57df\u5efa\u6a21\u63d0\u4f9b\u6846\u67b6\u3002", "motivation": "\u81ea\u7136\u7cfb\u7edf\u5b58\u5728\u5faa\u73af\u5e73\u7a33\u884c\u4e3a\uff0c\u9700\u6784\u5efa\u964d\u9636\u6a21\u578b\u5904\u7406\u6b64\u7c7b\u65f6\u95f4\u5e8f\u5217\u3002", "method": "\u5229\u7528\u57fa\u4e8e\u5206\u6570\u7684\u751f\u6210\u5efa\u6a21\u7684\u8fdb\u5c55\uff0c\u6784\u5efa\u964d\u9636\u6a21\u578b\u3002", "result": "\u4ee5\u6c14\u5019\u6a21\u578b\u4e3a\u4f8b\uff0c\u964d\u9636\u6a21\u578b\u51c6\u786e\u590d\u73b0\u539f\u7cfb\u7edf\u7edf\u8ba1\u7279\u6027\uff0c\u6709\u663e\u8457\u8ba1\u7b97\u4f18\u52bf\u3002", "conclusion": "\u4e3a\u5468\u671f\u6027\u5f3a\u8feb\u7cfb\u7edf\u9ad8\u6548\u5efa\u6a21\u63d0\u4f9b\u65b0\u53ef\u80fd\uff0c\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u548c\u7269\u7406\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2508.19918", "pdf": "https://arxiv.org/pdf/2508.19918", "abs": "https://arxiv.org/abs/2508.19918", "authors": ["Manato Tajiri", "Michimasa Inaba"], "title": "Refining Text Generation for Realistic Conversational Recommendation via Direct Preference Optimization", "categories": ["cs.IR"], "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Conversational Recommender Systems (CRSs) aim to elicit user preferences via\nnatural dialogue to provide suitable item recommendations. However, current\nCRSs often deviate from realistic human interactions by rapidly recommending\nitems in brief sessions. This work addresses this gap by leveraging Large\nLanguage Models (LLMs) to generate dialogue summaries from dialogue history and\nitem recommendation information from item description. This approach enables\nthe extraction of both explicit user statements and implicit preferences\ninferred from the dialogue context. We introduce a method using Direct\nPreference Optimization (DPO) to ensure dialogue summary and item\nrecommendation information are rich in information crucial for effective\nrecommendations. Experiments on two public datasets validate our method's\neffectiveness in fostering more natural and realistic conversational\nrecommendation processes.Our implementation is publicly available\nat:https://github.com/UEC-InabaLab/Refining-LLM-Text", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548cDPO\u65b9\u6cd5\u4f18\u5316\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff0c\u5728\u516c\u5f00\u6570\u636e\u96c6\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u80fd\u4fc3\u8fdb\u66f4\u81ea\u7136\u771f\u5b9e\u7684\u5bf9\u8bdd\u63a8\u8350\u8fc7\u7a0b\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u5f53\u524d\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u5728\u77ed\u6682\u4f1a\u8bdd\u4e2d\u5feb\u901f\u63a8\u8350\u7269\u54c1\uff0c\u504f\u79bb\u771f\u5b9e\u4eba\u7c7b\u4ea4\u4e92\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u5bf9\u8bdd\u5386\u53f2\u751f\u6210\u5bf9\u8bdd\u6458\u8981\u3001\u4ece\u7269\u54c1\u63cf\u8ff0\u751f\u6210\u7269\u54c1\u63a8\u8350\u4fe1\u606f\uff0c\u4f7f\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u65b9\u6cd5\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u4fc3\u8fdb\u66f4\u81ea\u7136\u548c\u73b0\u5b9e\u7684\u5bf9\u8bdd\u63a8\u8350\u8fc7\u7a0b\u3002"}}
{"id": "2508.19935", "pdf": "https://arxiv.org/pdf/2508.19935", "abs": "https://arxiv.org/abs/2508.19935", "authors": ["Alvin Chiu", "Thomas Depian", "David Eppstein", "Michael T. Goodrich", "Martin N\u00f6llenburg"], "title": "Visualizing Treewidth", "categories": ["cs.CG", "cs.DS"], "comment": "Appears in the Proceedings of the 33rd International Symposium on\n  Graph Drawing and Network Visualization (GD 2025); 26 pages, 14 figures", "summary": "A witness drawing of a graph is a visualization that clearly shows a given\nproperty of a graph. We study and implement various drawing paradigms for\nwitness drawings to clearly show that graphs have bounded pathwidth or\ntreewidth. Our approach draws the tree decomposition or path decomposition as a\ntree of bags, with induced subgraphs shown in each bag, and with ''tracks'' for\neach graph vertex connecting its copies in multiple bags. Within bags, we\noptimize the vertex layout to avoid crossings of edges and tracks. We implement\na visualization prototype for crossing minimization using dynamic programming\nfor graphs of small width and heuristic approaches for graphs of larger width.\nWe introduce a taxonomy of drawing styles, which render the subgraph for each\nbag as an arc diagram with one or two pages or as a circular layout with\nstraight-line edges, and we render tracks either with straight lines or with\norbital-radial paths.", "AI": {"tldr": "\u7814\u7a76\u5e76\u5b9e\u73b0\u591a\u79cd\u89c1\u8bc1\u7ed8\u56fe\u8303\u5f0f\u4ee5\u5c55\u793a\u56fe\u7684\u6709\u754c\u8def\u5f84\u5bbd\u5ea6\u6216\u6811\u5bbd\u5ea6\uff0c\u4ecb\u7ecd\u7ed8\u56fe\u98ce\u683c\u5206\u7c7b\u3002", "motivation": "\u4e3a\u6e05\u6670\u5c55\u793a\u56fe\u5177\u6709\u6709\u754c\u8def\u5f84\u5bbd\u5ea6\u6216\u6811\u5bbd\u5ea6\u8fd9\u4e00\u5c5e\u6027\u3002", "method": "\u7ed8\u5236\u6811\u5206\u89e3\u6216\u8def\u5f84\u5206\u89e3\u4e3a\u888b\u6811\uff0c\u4f18\u5316\u888b\u5185\u9876\u70b9\u5e03\u5c40\uff0c\u7528\u52a8\u6001\u89c4\u5212\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\u5b9e\u73b0\u53ef\u89c6\u5316\u539f\u578b\uff0c\u5f15\u5165\u7ed8\u56fe\u98ce\u683c\u5206\u7c7b\u3002", "result": "\u5b9e\u73b0\u4e86\u7528\u4e8e\u4ea4\u53c9\u6700\u5c0f\u5316\u7684\u53ef\u89c6\u5316\u539f\u578b\uff0c\u4ecb\u7ecd\u4e86\u7ed8\u56fe\u98ce\u683c\u5206\u7c7b\u3002", "conclusion": "\u901a\u8fc7\u591a\u79cd\u7ed8\u56fe\u8303\u5f0f\u548c\u98ce\u683c\u80fd\u6709\u6548\u5c55\u793a\u56fe\u7684\u6709\u754c\u8def\u5f84\u5bbd\u5ea6\u6216\u6811\u5bbd\u5ea6\u5c5e\u6027\u3002"}}
{"id": "2508.20086", "pdf": "https://arxiv.org/pdf/2508.20086", "abs": "https://arxiv.org/abs/2508.20086", "authors": ["Youwei Huang", "Jianwen Li", "Sen Fang", "Yao Li", "Peng Yang", "Bin Hu", "Tao Zhang"], "title": "Smart Contract Intent Detection with Pre-trained Programming Language Model", "categories": ["cs.SE", "cs.CR"], "comment": "10 pages, 5 figures, conference", "summary": "Malicious intent in smart contract development can lead to substantial\neconomic losses. SmartIntentNN is a deep learning model specifically designed\nto identify unsafe intents in smart contracts. This model integrates the\nUniversal Sentence Encoder, a K-means clustering-based intent highlighting\nmechanism, and a Bidirectional Long Short-Term Memory network for multi-label\nclassification, achieving an F1 of 0.8633 in distinguishing ten different\nintent categories. In this study, we present an upgraded version of this model,\nSmartIntentNN2 (Smart Contract Intent Neural Network V2). A significant\nenhancement in V2 is the incorporation of a BERT-based pre-trained language\nmodel, which has been trained on a dataset of 16,000 real smart contracts using\na Masked Language Modeling objective. SmartIntentNN2 retains the BiLSTM-based\nmulti-label classification network. With an improved F1 of 0.927, V2\ndemonstrates enhanced performance compared to its predecessor, establishing\nitself as the state-of-the-art model for smart contract intent detection.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u667a\u80fd\u5408\u7ea6\u610f\u56fe\u68c0\u6d4b\u6a21\u578bSmartIntentNN2\uff0c\u5b83\u6539\u8fdb\u81eaSmartIntentNN\uff0c\u5f15\u5165BERT\u9884\u8bad\u7ec3\u6a21\u578b\uff0cF1\u503c\u4ece0.8633\u63d0\u5347\u52300.927\uff0c\u6210\u4e3a\u8be5\u9886\u57df\u6700\u4f18\u6a21\u578b\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u4e2d\u7684\u6076\u610f\u610f\u56fe\u4f1a\u9020\u6210\u91cd\u5927\u7ecf\u6d4e\u635f\u5931\uff0c\u9700\u8981\u63d0\u5347\u667a\u80fd\u5408\u7ea6\u610f\u56fe\u68c0\u6d4b\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5728SmartIntentNN\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u57fa\u4e8eBERT\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u752816000\u4e2a\u771f\u5b9e\u667a\u80fd\u5408\u7ea6\u6570\u636e\u96c6\u6309Masked Language Modeling\u76ee\u6807\u8bad\u7ec3\uff0c\u4fdd\u7559BiLSTM\u591a\u6807\u7b7e\u5206\u7c7b\u7f51\u7edc\u3002", "result": "SmartIntentNN2\u7684F1\u503c\u8fbe0.927\uff0c\u4f18\u4e8e\u524d\u8eabSmartIntentNN\u76840.8633\u3002", "conclusion": "SmartIntentNN2\u662f\u667a\u80fd\u5408\u7ea6\u610f\u56fe\u68c0\u6d4b\u7684\u6700\u4f18\u6a21\u578b\u3002"}}
{"id": "2508.19576", "pdf": "https://arxiv.org/pdf/2508.19576", "abs": "https://arxiv.org/abs/2508.19576", "authors": ["Sining Zhoubian", "Dan Zhang", "Yuxiao Dong", "Jie Tang"], "title": "ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding", "categories": ["cs.AI", "cs.LG"], "comment": "20 pages, 4 figures", "summary": "With respect to improving the reasoning accuracy of LLMs, the representative\nreinforcement learning (RL) method GRPO faces failure due to insignificant\nreward variance, while verification methods based on process reward models\n(PRMs) suffer from difficulties with training data acquisition and verification\neffectiveness. To tackle these problems, this paper introduces ReST-RL, a\nunified LLM RL paradigm that significantly improves LLM's code reasoning\nability by combining an improved GRPO algorithm with a meticulously designed\ntest time decoding method assisted by a value model (VM). As the first stage of\npolicy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter\nand assemble high-value training data, increasing the reward variance of GRPO\nsampling, thus improving the effectiveness and efficiency of training. After\nthe basic reasoning ability of LLM policy has been improved, we further propose\na test time decoding optimization method called VM-MCTS. Through Monte-Carlo\nTree Search (MCTS), we collect accurate value targets with no annotation\nrequired, on which VM training is based. When decoding, the VM is deployed by\nan adapted MCTS algorithm to provide precise process signals as well as\nverification scores, assisting the LLM policy to achieve high reasoning\naccuracy. We validate the effectiveness of the proposed RL paradigm through\nextensive experiments on coding problems. Upon comparison, our approach\nsignificantly outperforms other reinforcement training baselines (e.g., naive\nGRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,\nPRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,\nAPPS, BigCodeBench, and HumanEval), indicating its power to strengthen the\nreasoning ability of LLM policies. Codes for our project can be found at\nhttps://github.com/THUDM/ReST-RL.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7684LLM\u5f3a\u5316\u5b66\u4e60\u8303\u5f0fReST - RL\uff0c\u7ed3\u5408\u6539\u8fdbGRPO\u7b97\u6cd5\u4e0e\u57fa\u4e8e\u4ef7\u503c\u6a21\u578b\u7684\u89e3\u7801\u65b9\u6cd5\uff0c\u63d0\u5347LLM\u4ee3\u7801\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u73b0\u6709GRPO\u65b9\u6cd5\u56e0\u5956\u52b1\u65b9\u5dee\u4e0d\u663e\u8457\u5931\u8d25\uff0c\u57fa\u4e8ePRMs\u7684\u9a8c\u8bc1\u65b9\u6cd5\u6709\u8bad\u7ec3\u6570\u636e\u83b7\u53d6\u548c\u9a8c\u8bc1\u6548\u679c\u95ee\u9898\uff0c\u9700\u63d0\u5347LLM\u63a8\u7406\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faReST - RL\u8303\u5f0f\uff0cReST - GRPO\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u63d0\u5347\u5956\u52b1\u65b9\u5dee\uff1b\u63d0\u51faVM - MCTS\u89e3\u7801\u4f18\u5316\u65b9\u6cd5\uff0c\u7528MCTS\u6536\u96c6\u4ef7\u503c\u76ee\u6807\u8bad\u7ec3VM\uff0c\u89e3\u7801\u65f6\u7528VM\u8f85\u52a9\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2a\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u5f3a\u5316\u8bad\u7ec3\u3001\u89e3\u7801\u548c\u9a8c\u8bc1\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ReST - RL\u8303\u5f0f\u80fd\u6709\u6548\u589e\u5f3aLLM\u7b56\u7565\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2508.19458", "pdf": "https://arxiv.org/pdf/2508.19458", "abs": "https://arxiv.org/abs/2508.19458", "authors": ["Mahdi Haghifam", "Adam Smith", "Jonathan Ullman"], "title": "The Sample Complexity of Membership Inference and Privacy Auditing", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "58 Pages", "summary": "A membership-inference attack gets the output of a learning algorithm, and a\ntarget individual, and tries to determine whether this individual is a member\nof the training data or an independent sample from the same distribution. A\nsuccessful membership-inference attack typically requires the attacker to have\nsome knowledge about the distribution that the training data was sampled from,\nand this knowledge is often captured through a set of independent reference\nsamples from that distribution. In this work we study how much information the\nattacker needs for membership inference by investigating the sample\ncomplexity-the minimum number of reference samples required-for a successful\nattack. We study this question in the fundamental setting of Gaussian mean\nestimation where the learning algorithm is given $n$ samples from a Gaussian\ndistribution $\\mathcal{N}(\\mu,\\Sigma)$ in $d$ dimensions, and tries to estimate\n$\\hat\\mu$ up to some error $\\mathbb{E}[\\|\\hat \\mu - \\mu\\|^2_{\\Sigma}]\\leq\n\\rho^2 d$. Our result shows that for membership inference in this setting,\n$\\Omega(n + n^2 \\rho^2)$ samples can be necessary to carry out any attack that\ncompetes with a fully informed attacker. Our result is the first to show that\nthe attacker sometimes needs many more samples than the training algorithm uses\nto train the model. This result has significant implications for practice, as\nall attacks used in practice have a restricted form that uses $O(n)$ samples\nand cannot benefit from $\\omega(n)$ samples. Thus, these attacks may be\nunderestimating the possibility of membership inference, and better attacks may\nbe possible when information about the distribution is easy to obtain.", "AI": {"tldr": "\u7814\u7a76\u9ad8\u65af\u5747\u503c\u4f30\u8ba1\u573a\u666f\u4e0b\u6210\u5458\u63a8\u65ad\u653b\u51fb\u6240\u9700\u53c2\u8003\u6837\u672c\u7684\u590d\u6742\u5ea6\uff0c\u53d1\u73b0\u653b\u51fb\u8005\u6709\u65f6\u9700\u6bd4\u8bad\u7ec3\u7b97\u6cd5\u66f4\u591a\u6837\u672c\uff0c\u73b0\u6709\u653b\u51fb\u53ef\u80fd\u4f4e\u4f30\u6210\u5458\u63a8\u65ad\u53ef\u80fd\u6027\u3002", "motivation": "\u63a2\u7a76\u653b\u51fb\u8005\u8fdb\u884c\u6210\u5458\u63a8\u65ad\u653b\u51fb\u6240\u9700\u7684\u4fe1\u606f\u91cf\uff0c\u5373\u6210\u529f\u653b\u51fb\u6240\u9700\u7684\u6700\u5c0f\u53c2\u8003\u6837\u672c\u6570\u3002", "method": "\u5728\u9ad8\u65af\u5747\u503c\u4f30\u8ba1\u7684\u57fa\u7840\u8bbe\u7f6e\u4e0b\uff0c\u7814\u7a76\u5b66\u4e60\u7b97\u6cd5\u4eced\u7ef4\u9ad8\u65af\u5206\u5e03\u4e2d\u83b7\u53d6n\u4e2a\u6837\u672c\u5e76\u4f30\u8ba1\u5747\u503c\u65f6\uff0c\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "result": "\u5728\u8be5\u8bbe\u7f6e\u4e0b\uff0c\u8fdb\u884c\u80fd\u4e0e\u5168\u77e5\u653b\u51fb\u8005\u7ade\u4e89\u7684\u653b\u51fb\u53ef\u80fd\u9700\u8981\u03a9(n + n^2 \u03c1^2)\u4e2a\u6837\u672c\uff0c\u653b\u51fb\u8005\u6709\u65f6\u9700\u6bd4\u8bad\u7ec3\u7b97\u6cd5\u4f7f\u7528\u66f4\u591a\u6837\u672c\u3002", "conclusion": "\u73b0\u6709\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u653b\u51fb\u4f7f\u7528O(n)\u4e2a\u6837\u672c\uff0c\u53ef\u80fd\u4f4e\u4f30\u6210\u5458\u63a8\u65ad\u53ef\u80fd\u6027\uff0c\u5f53\u5206\u5e03\u4fe1\u606f\u6613\u83b7\u53d6\u65f6\u53ef\u80fd\u6709\u66f4\u597d\u7684\u653b\u51fb\u65b9\u6cd5\u3002"}}
{"id": "2508.19868", "pdf": "https://arxiv.org/pdf/2508.19868", "abs": "https://arxiv.org/abs/2508.19868", "authors": ["Geraldo F. Oliveira"], "title": "New Tools, Programming Models, and System Support for Processing-in-Memory Architectures", "categories": ["cs.AR", "cs.DC"], "comment": "Doctoral thesis", "summary": "Our goal in this dissertation is to provide tools, programming models, and\nsystem support for PIM architectures (with a focus on DRAM-based solutions), to\nease the adoption of PIM in current and future systems. To this end, we make at\nleast four new major contributions.\n  First, we introduce DAMOV, the first rigorous methodology to characterize\nmemory-related data movement bottlenecks in modern workloads, and the first\ndata movement benchmark suite. Second, we introduce MIMDRAM, a new\nhardware/software co-designed substrate that addresses the major current\nprogrammability and flexibility limitations of the bulk bitwise execution model\nof processing-using-DRAM (PUD) architectures. MIMDRAM enables the allocation\nand control of only the needed computing resources inside DRAM for PUD\ncomputing. Third, we introduce Proteus, the first hardware framework that\naddresses the high execution latency of bulk bitwise PUD operations in\nstate-of-the-art PUD architectures by implementing a data-aware runtime engine\nfor PUD. Proteus reduces the latency of PUD operations in three different ways:\n(i) Proteus concurrently executes independent in-DRAM primitives belong to a\nsingle PUD operation across DRAM arrays. (ii) Proteus dynamically reduces the\nbit-precision (and consequentially the latency and energy consumption) of PUD\noperations by exploiting narrow values (i.e., values with many leading zeros or\nones). (iii) Proteus chooses and uses the most appropriate data representation\nand arithmetic algorithm implementation for a given PUD instruction\ntransparently to the programmer. Fourth, we introduce DaPPA (data-parallel\nprocessing-in-memory architecture), a new programming framework that eases\nprogrammability for general-purpose PNM architectures by allowing the\nprogrammer to write efficient PIM-friendly code without the need to manage\nhardware resources explicitly.", "AI": {"tldr": "\u672c\u6587\u4e3aPIM\u67b6\u6784\u63d0\u4f9b\u5de5\u5177\u3001\u7f16\u7a0b\u6a21\u578b\u548c\u7cfb\u7edf\u652f\u6301\uff0c\u63d0\u51faDAMOV\u3001MIMDRAM\u3001Proteus\u548cDaPPA\u56db\u9879\u65b0\u8d21\u732e\u3002", "motivation": "\u4e3aPIM\u67b6\u6784\uff08\u4e3b\u8981\u662f\u57fa\u4e8eDRAM\u7684\u89e3\u51b3\u65b9\u6848\uff09\u63d0\u4f9b\u5de5\u5177\u3001\u7f16\u7a0b\u6a21\u578b\u548c\u7cfb\u7edf\u652f\u6301\uff0c\u4fc3\u8fdbPIM\u5728\u5f53\u524d\u548c\u672a\u6765\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faDAMOV\u65b9\u6cd5\u548c\u57fa\u51c6\u5957\u4ef6\uff0c\u8bbe\u8ba1MIMDRAM\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u57fa\u5e95\uff0c\u6784\u5efaProteus\u786c\u4ef6\u6846\u67b6\uff0c\u5f00\u53d1DaPPA\u7f16\u7a0b\u6846\u67b6\u3002", "result": "DAMOV\u53ef\u8868\u5f81\u5185\u5b58\u6570\u636e\u79fb\u52a8\u74f6\u9888\uff1bMIMDRAM\u89e3\u51b3PUD\u67b6\u6784\u53ef\u7f16\u7a0b\u6027\u548c\u7075\u6d3b\u6027\u95ee\u9898\uff1bProteus\u964d\u4f4ePUD\u64cd\u4f5c\u6267\u884c\u5ef6\u8fdf\uff1bDaPPA\u7b80\u5316\u901a\u7528PNM\u67b6\u6784\u7f16\u7a0b\u3002", "conclusion": "\u901a\u8fc7\u8fd9\u56db\u9879\u8d21\u732e\uff0c\u6709\u671b\u63a8\u52a8PIM\u67b6\u6784\u5728\u5f53\u524d\u548c\u672a\u6765\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2508.19467", "pdf": "https://arxiv.org/pdf/2508.19467", "abs": "https://arxiv.org/abs/2508.19467", "authors": ["Sumon Kanti Dey", "Jeanne M. Powell", "Azra Ismail", "Jeanmarie Perrone", "Abeed Sarker"], "title": "Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Dataset and code: https://github.com/SumonKantiDey/Reddit_Impacts_NER", "summary": "Nonmedical opioid use is an urgent public health challenge, with far-reaching\nclinical and social consequences that are often underreported in traditional\nhealthcare settings. Social media platforms, where individuals candidly share\nfirst-person experiences, offer a valuable yet underutilized source of insight\ninto these impacts. In this study, we present a named entity recognition (NER)\nframework to extract two categories of self-reported consequences from social\nmedia narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,\ndepression) and SocialImpacts (e.g., job loss). To support this task, we\nintroduce RedditImpacts 2.0, a high-quality dataset with refined annotation\nguidelines and a focus on first-person disclosures, addressing key limitations\nof prior work. We evaluate both fine-tuned encoder-based models and\nstate-of-the-art large language models (LLMs) under zero- and few-shot\nin-context learning settings. Our fine-tuned DeBERTa-large model achieves a\nrelaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming\nLLMs in precision, span accuracy, and adherence to task-specific guidelines.\nFurthermore, we show that strong NER performance can be achieved with\nsubstantially less labeled data, emphasizing the feasibility of deploying\nrobust models in resource-limited settings. Our findings underscore the value\nof domain-specific fine-tuning for clinical NLP tasks and contribute to the\nresponsible development of AI tools that may enhance addiction surveillance,\nimprove interpretability, and support real-world healthcare decision-making.\nThe best performing model, however, still significantly underperforms compared\nto inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap\npersists between expert intelligence and current state-of-the-art NER/AI\ncapabilities for tasks requiring deep domain knowledge.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faNER\u6846\u67b6\u4ece\u793e\u4ea4\u5a92\u4f53\u63d0\u53d6\u963f\u7247\u7c7b\u836f\u7269\u4f7f\u7528\u540e\u679c\uff0c\u8bc4\u4f30\u6a21\u578b\uff0c\u53d1\u73b0\u5fae\u8c03\u6a21\u578b\u8868\u73b0\u4f73\uff0c\u5f3a\u8c03\u9886\u57df\u5fae\u8c03\u4ef7\u503c\uff0c\u4f46\u4e0e\u4e13\u5bb6\u6c34\u5e73\u6709\u5dee\u8ddd\u3002", "motivation": "\u975e\u533b\u7597\u963f\u7247\u7c7b\u836f\u7269\u4f7f\u7528\u662f\u516c\u5171\u536b\u751f\u6311\u6218\uff0c\u4f20\u7edf\u533b\u7597\u8bbe\u7f6e\u5e38\u6f0f\u62a5\u540e\u679c\uff0c\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u6709\u4ef7\u503c\u4f46\u672a\u5145\u5206\u5229\u7528\u3002", "method": "\u63d0\u51faNER\u6846\u67b6\uff0c\u5f15\u5165RedditImpacts 2.0\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u5fae\u8c03\u7f16\u7801\u5668\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5fae\u8c03\u7684DeBERTa - large\u6a21\u578b\u8868\u73b0\u4f73\uff0c\u5728\u7cbe\u5ea6\u7b49\u65b9\u9762\u4f18\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e14\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u4e5f\u80fd\u5b9e\u73b0\u5f3aNER\u6027\u80fd\u3002", "conclusion": "\u5f3a\u8c03\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u5bf9\u4e34\u5e8aNLP\u4efb\u52a1\u7684\u4ef7\u503c\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8d1f\u8d23\u4efb\u7684AI\u5de5\u5177\uff0c\u4f46\u5f53\u524d\u6a21\u578b\u4e0e\u4e13\u5bb6\u6c34\u5e73\u6709\u5dee\u8ddd\u3002"}}
{"id": "2508.19276", "pdf": "https://arxiv.org/pdf/2508.19276", "abs": "https://arxiv.org/abs/2508.19276", "authors": ["Marcos Guillermo Lammers", "Federico Hern\u00e1n Holik", "Alejandro Fern\u00e1ndez"], "title": "Quantum Resource Management in the NISQ Era: Challenges, Vision, and a Runtime Framework", "categories": ["quant-ph", "cs.SE", "physics.comp-ph"], "comment": null, "summary": "Quantum computers represent a radical technological advancement in the way\ninformation is processed by using the principles of quantum mechanics to solve\nvery complex problems that exceed the capabilities of classical systems.\nHowever, in the current NISQ era (Noisy Intermediate-Scale Quantum devices),\nthe available hardware presents several limitations, such as a limited number\nof qubits, high error rates, and reduced coherence times. Efficient management\nof quantum resources, both physical (qubits, error rates, connectivity) and\nlogical (quantum gates, algorithms, error correction), becomes particularly\nrelevant in the design and deployment of quantum algorithms. In this work, we\nanalyze the role of resources in the various uses of NISQ devices today,\nidentifying their relevance and implications for software engineering focused\non the use of quantum computers. We propose a vision for runtime-aware quantum\nsoftware development, identifying key challenges to its realization, such as\nlimited introspection capabilities and temporal constraints in current\nplatforms. As a proof of concept, we introduce Qonscious, a prototype framework\nthat enables conditional execution of quantum programs based on dynamic\nresource evaluation. With this contribution, we aim to strengthen the field of\nQuantum Resource Estimation (QRE) and move towards the development of scalable,\nreliable, and resource-aware quantum software.", "AI": {"tldr": "\u672c\u6587\u5206\u6790NISQ\u8bbe\u5907\u8d44\u6e90\u4f5c\u7528\uff0c\u63d0\u51fa\u8fd0\u884c\u65f6\u611f\u77e5\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u613f\u666f\uff0c\u4ecb\u7ecdQonscious\u6846\u67b6\u4ee5\u63a8\u52a8\u91cf\u5b50\u8d44\u6e90\u4f30\u8ba1\u9886\u57df\u53d1\u5c55\u3002", "motivation": "\u5f53\u524dNISQ\u65f6\u4ee3\u786c\u4ef6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9ad8\u6548\u7ba1\u7406\u91cf\u5b50\u8d44\u6e90\u5bf9\u91cf\u5b50\u7b97\u6cd5\u8bbe\u8ba1\u548c\u90e8\u7f72\u5f88\u91cd\u8981\uff0c\u9700\u7814\u7a76\u8d44\u6e90\u5728NISQ\u8bbe\u5907\u4e2d\u7684\u4f5c\u7528\u53ca\u5bf9\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790\u8d44\u6e90\u5728NISQ\u8bbe\u5907\u4e0d\u540c\u7528\u9014\u4e2d\u7684\u4f5c\u7528\uff0c\u63d0\u51fa\u8fd0\u884c\u65f6\u611f\u77e5\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u613f\u666f\uff0c\u4ecb\u7ecdQonscious\u539f\u578b\u6846\u67b6\u3002", "result": "\u5f15\u5165Qonscious\u6846\u67b6\uff0c\u53ef\u57fa\u4e8e\u52a8\u6001\u8d44\u6e90\u8bc4\u4f30\u5b9e\u73b0\u91cf\u5b50\u7a0b\u5e8f\u7684\u6761\u4ef6\u6267\u884c\u3002", "conclusion": "\u6709\u52a9\u4e8e\u52a0\u5f3a\u91cf\u5b50\u8d44\u6e90\u4f30\u8ba1\u9886\u57df\uff0c\u63a8\u52a8\u53ef\u6269\u5c55\u3001\u53ef\u9760\u548c\u8d44\u6e90\u611f\u77e5\u7684\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u3002"}}
{"id": "2508.19611", "pdf": "https://arxiv.org/pdf/2508.19611", "abs": "https://arxiv.org/abs/2508.19611", "authors": ["Huaiyuan Yao", "Wanpeng Xu", "Justin Turnau", "Nadia Kellam", "Hua Wei"], "title": "Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties", "categories": ["cs.AI", "cs.CL", "I.2.7"], "comment": "18 pages, 9 figures", "summary": "Preparing high-quality instructional materials remains a labor-intensive\nprocess that often requires extensive coordination among teaching faculty,\ninstructional designers, and teaching assistants. In this work, we present\nInstructional Agents, a multi-agent large language model (LLM) framework\ndesigned to automate end-to-end course material generation, including syllabus\ncreation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing\nAI-assisted educational tools that focus on isolated tasks, Instructional\nAgents simulates role-based collaboration among educational agents to produce\ncohesive and pedagogically aligned content. The system operates in four modes:\nAutonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling\nflexible control over the degree of human involvement. We evaluate\nInstructional Agents across five university-level computer science courses and\nshow that it produces high-quality instructional materials while significantly\nreducing development time and human workload. By supporting institutions with\nlimited instructional design capacity, Instructional Agents provides a scalable\nand cost-effective framework to democratize access to high-quality education,\nparticularly in underserved or resource-constrained settings.", "AI": {"tldr": "\u63d0\u51faInstructional Agents\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u53ef\u7aef\u5230\u7aef\u81ea\u52a8\u751f\u6210\u8bfe\u7a0b\u6750\u6599\uff0c\u7ecf\u8bc4\u4f30\u80fd\u4ea7\u51fa\u9ad8\u8d28\u91cf\u6750\u6599\uff0c\u51cf\u5c11\u5f00\u53d1\u65f6\u95f4\u548c\u4eba\u529b\u3002", "motivation": "\u9ad8\u8d28\u91cf\u6559\u5b66\u6750\u6599\u51c6\u5907\u8fc7\u7a0b\u8017\u65f6\u957f\u4e14\u9700\u591a\u65b9\u534f\u8c03\uff0c\u73b0\u6709AI\u8f85\u52a9\u6559\u80b2\u5de5\u5177\u805a\u7126\u5b64\u7acb\u4efb\u52a1\u3002", "method": "\u63d0\u51faInstructional Agents\u6846\u67b6\uff0c\u6a21\u62df\u6559\u80b2\u667a\u80fd\u4f53\u57fa\u4e8e\u89d2\u8272\u7684\u534f\u4f5c\uff0c\u6709\u56db\u79cd\u8fd0\u884c\u6a21\u5f0f\u3002", "result": "\u5728\u4e94\u95e8\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u4e2d\u8bc4\u4f30\uff0c\u80fd\u4ea7\u51fa\u9ad8\u8d28\u91cf\u6559\u5b66\u6750\u6599\uff0c\u663e\u8457\u51cf\u5c11\u5f00\u53d1\u65f6\u95f4\u548c\u4eba\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u652f\u6301\u6559\u5b66\u8bbe\u8ba1\u80fd\u529b\u6709\u9650\u7684\u673a\u6784\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u8ba9\u66f4\u591a\u4eba\u83b7\u5f97\u9ad8\u8d28\u91cf\u6559\u80b2\u3002"}}
{"id": "2508.19468", "pdf": "https://arxiv.org/pdf/2508.19468", "abs": "https://arxiv.org/abs/2508.19468", "authors": ["M. Imbri\u0161ak", "A. E. Lovell", "M. R. Mumpower"], "title": "Weighted Levenberg-Marquardt methods for fitting multichannel nuclear cross section data", "categories": ["nucl-th", "stat.ML"], "comment": "14 pages, 10 figures", "summary": "We present an extension of the Levenberg-Marquardt algorithm for fitting\nmultichannel nuclear cross section data. Our approach offers a practical and\nrobust alternative to conventional trust-region methods for analyzing\nexperimental data. The CoH$_3$ code, based on the Hauser-Feshbach statistical\nmodel, involves a large number of interdependent parameters, making\noptimization challenging due to the presence of \"sloppy\" directions in\nparameter space. To address the uneven distribution of experimental data across\nreaction channels, we construct a weighted Fisher Information Metric by\nintegrating prior distributions over dataset weights. This framework enables a\nmore balanced treatment of heterogeneous data, improving both parameter\nestimation and convergence robustness. We show that the resulting weighted\nLevenberg-Marquardt method yields more physically consistent fits for both raw\nand smoothed datasets, using experimental data for ${}^{148}$Sm as a\nrepresentative example. Additionally, we introduce a geometric scaling strategy\nto accelerate convergence -- a method based on the local geometry of the\nmanifold.", "AI": {"tldr": "\u63d0\u51fa\u6269\u5c55\u7684Levenberg - Marquardt\u7b97\u6cd5\u62df\u5408\u591a\u901a\u9053\u6838\u622a\u9762\u6570\u636e\uff0c\u6784\u9020\u52a0\u6743Fisher\u4fe1\u606f\u5ea6\u91cf\uff0c\u5f15\u5165\u51e0\u4f55\u7f29\u653e\u7b56\u7565\u52a0\u901f\u6536\u655b\uff0c\u7528\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u4fe1\u4efb\u533a\u57df\u65b9\u6cd5\u5728\u5206\u6790\u5b9e\u9a8c\u6570\u636e\u65b9\u9762\u4e0d\u8db3\uff0cCoH\u2083\u4ee3\u7801\u56e0\u53c2\u6570\u7a7a\u95f4\u5b58\u5728\u201csloppy\u201d\u65b9\u5411\u4f7f\u4f18\u5316\u6709\u6311\u6218\uff0c\u4e14\u5b9e\u9a8c\u6570\u636e\u5728\u53cd\u5e94\u901a\u9053\u5206\u5e03\u4e0d\u5747\u3002", "method": "\u6784\u9020\u52a0\u6743Fisher\u4fe1\u606f\u5ea6\u91cf\uff0c\u5bf9\u6570\u636e\u96c6\u6743\u91cd\u4e0a\u7684\u5148\u9a8c\u5206\u5e03\u79ef\u5206\uff1b\u5f15\u5165\u57fa\u4e8e\u6d41\u5f62\u5c40\u90e8\u51e0\u4f55\u7684\u51e0\u4f55\u7f29\u653e\u7b56\u7565\u3002", "result": "\u52a0\u6743Levenberg - Marquardt\u65b9\u6cd5\u5bf9\u539f\u59cb\u548c\u5e73\u6ed1\u6570\u636e\u96c6\u90fd\u80fd\u5f97\u5230\u66f4\u7b26\u5408\u7269\u7406\u7684\u62df\u5408\u7ed3\u679c\u3002", "conclusion": "\u6269\u5c55\u7684Levenberg - Marquardt\u7b97\u6cd5\u662f\u5206\u6790\u5b9e\u9a8c\u6570\u636e\u7684\u5b9e\u7528\u4e14\u7a33\u5065\u7684\u66ff\u4ee3\u65b9\u6cd5\uff0c\u80fd\u6539\u5584\u53c2\u6570\u4f30\u8ba1\u548c\u6536\u655b\u7a33\u5065\u6027\u3002"}}
{"id": "2508.19758", "pdf": "https://arxiv.org/pdf/2508.19758", "abs": "https://arxiv.org/abs/2508.19758", "authors": ["Yixuan Tang", "Yuanyuan Shi", "Yiqun Sun", "Anthony Kum Hoe Tung"], "title": "Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval", "categories": ["cs.CL", "cs.IR"], "comment": "Accepted by EMNLP 2025", "summary": "Access to diverse perspectives is essential for understanding real-world\nevents, yet most news retrieval systems prioritize textual relevance, leading\nto redundant results and limited viewpoint exposure. We propose NEWSCOPE, a\ntwo-stage framework for diverse news retrieval that enhances event coverage by\nexplicitly modeling semantic variation at the sentence level. The first stage\nretrieves topically relevant content using dense retrieval, while the second\nstage applies sentence-level clustering and diversity-aware re-ranking to\nsurface complementary information. To evaluate retrieval diversity, we\nintroduce three interpretable metrics, namely Average Pairwise Distance,\nPositive Cluster Coverage, and Information Density Ratio, and construct two\nparagraph-level benchmarks: LocalNews and DSGlobal. Experiments show that\nNEWSCOPE consistently outperforms strong baselines, achieving significantly\nhigher diversity without compromising relevance. Our results demonstrate the\neffectiveness of fine-grained, interpretable modeling in mitigating redundancy\nand promoting comprehensive event understanding. The data and code are\navailable at https://github.com/tangyixuan/NEWSCOPE.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u591a\u6837\u5316\u65b0\u95fb\u68c0\u7d22\u7684NEWSCOPE\u6846\u67b6\uff0c\u5f15\u5165\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u51c6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65b0\u95fb\u68c0\u7d22\u7cfb\u7edf\u91cd\u6587\u672c\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u7ed3\u679c\u5197\u4f59\u3001\u89c2\u70b9\u6709\u9650\uff0c\u9700\u63d0\u5347\u4e8b\u4ef6\u62a5\u9053\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6NEWSCOPE\uff0c\u7b2c\u4e00\u9636\u6bb5\u7528\u5bc6\u96c6\u68c0\u7d22\u83b7\u53d6\u76f8\u5173\u5185\u5bb9\uff0c\u7b2c\u4e8c\u9636\u6bb5\u8fdb\u884c\u53e5\u5b50\u7ea7\u805a\u7c7b\u548c\u591a\u6837\u6027\u91cd\u6392\u5e8f\uff1b\u5f15\u5165\u4e09\u4e2a\u8bc4\u4f30\u6307\u6807\u548c\u4e24\u4e2a\u6bb5\u843d\u7ea7\u57fa\u51c6\u3002", "result": "NEWSCOPE\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5728\u4e0d\u5f71\u54cd\u76f8\u5173\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u9ad8\u591a\u6837\u6027\u3002", "conclusion": "\u7ec6\u7c92\u5ea6\u3001\u53ef\u89e3\u91ca\u5efa\u6a21\u80fd\u51cf\u5c11\u5197\u4f59\uff0c\u4fc3\u8fdb\u5bf9\u4e8b\u4ef6\u7684\u5168\u9762\u7406\u89e3\u3002"}}
{"id": "2508.19679", "pdf": "https://arxiv.org/pdf/2508.19679", "abs": "https://arxiv.org/abs/2508.19679", "authors": ["Qihang Ai", "Pi Bu", "Yue Cao", "Yingyao Wang", "Jihao Gu", "Jingxuan Xing", "Zekun Zhu", "Wei Jiang", "Zhicheng Zheng", "Jun Song", "Yuning Jiang", "Bo Zheng"], "title": "InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in Vision-Language Models (VLMs) have enabled mobile agents\nto perceive and interact with real-world mobile environments based on human\ninstructions. However, the current fully autonomous paradigm poses potential\nsafety risks when model understanding or reasoning capabilities are\ninsufficient. To address this challenge, we first introduce\n\\textbf{InquireBench}, a comprehensive benchmark specifically designed to\nevaluate mobile agents' capabilities in safe interaction and proactive inquiry\nwith users, encompassing 5 categories and 22 sub-categories, where most\nexisting VLM-based agents demonstrate near-zero performance. In this paper, we\naim to develop an interactive system that actively seeks human confirmation at\ncritical decision points. To achieve this, we propose \\textbf{InquireMobile}, a\nnovel model inspired by reinforcement learning, featuring a two-stage training\nstrategy and an interactive pre-action reasoning mechanism. Finally, our model\nachieves an 46.8% improvement in inquiry success rate and the best overall\nsuccess rate among existing baselines on InquireBench. We will open-source all\ndatasets, models, and evaluation codes to facilitate development in both\nacademia and industry.", "AI": {"tldr": "\u9488\u5bf9\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u79fb\u52a8\u4ee3\u7406\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u63d0\u51faInquireBench\u57fa\u51c6\u548cInquireMobile\u6a21\u578b\uff0c\u6a21\u578b\u5728\u57fa\u51c6\u4e0a\u8868\u73b0\u826f\u597d\u5e76\u5c06\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b8c\u5168\u81ea\u4e3b\u8303\u5f0f\u5728\u6a21\u578b\u7406\u89e3\u6216\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u65f6\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5f15\u5165InquireBench\u57fa\u51c6\uff0c\u63d0\u51fa\u53d7\u5f3a\u5316\u5b66\u4e60\u542f\u53d1\u7684InquireMobile\u6a21\u578b\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u548c\u4ea4\u4e92\u5f0f\u9884\u884c\u52a8\u63a8\u7406\u673a\u5236\u3002", "result": "\u6a21\u578b\u5728InquireBench\u4e0a\u67e5\u8be2\u6210\u529f\u7387\u63d0\u9ad846.8%\uff0c\u6574\u4f53\u6210\u529f\u7387\u6700\u4f73\u3002", "conclusion": "\u5f00\u53d1\u7684\u4ea4\u4e92\u5f0f\u7cfb\u7edf\u6709\u8f83\u597d\u6548\u679c\uff0c\u5c06\u5f00\u6e90\u6570\u636e\u3001\u6a21\u578b\u548c\u4ee3\u7801\u4fc3\u8fdb\u5b66\u672f\u548c\u884c\u4e1a\u53d1\u5c55\u3002"}}
{"id": "2508.19563", "pdf": "https://arxiv.org/pdf/2508.19563", "abs": "https://arxiv.org/abs/2508.19563", "authors": ["Hejia Liu", "Mochen Yang", "Gediminas Adomavicius"], "title": "Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) are being applied in a wide array of settings,\nwell beyond the typical language-oriented use cases. In particular, LLMs are\nincreasingly used as a plug-and-play method for fitting data and generating\npredictions. Prior work has shown that LLMs, via in-context learning or\nsupervised fine-tuning, can perform competitively with many tabular supervised\nlearning techniques in terms of predictive performance. However, we identify a\ncritical vulnerability of using LLMs for data fitting -- making changes to data\nrepresentation that are completely irrelevant to the underlying learning task\ncan drastically alter LLMs' predictions on the same data. For example, simply\nchanging variable names can sway the size of prediction error by as much as 82%\nin certain settings. Such prediction sensitivity with respect to\ntask-irrelevant variations manifests under both in-context learning and\nsupervised fine-tuning, for both close-weight and open-weight general-purpose\nLLMs. Moreover, by examining the attention scores of an open-weight LLM, we\ndiscover a non-uniform attention pattern: training examples and variable\nnames/values which happen to occupy certain positions in the prompt receive\nmore attention when output tokens are generated, even though different\npositions are expected to receive roughly the same attention. This partially\nexplains the sensitivity in the presence of task-irrelevant variations. We also\nconsider a state-of-the-art tabular foundation model (TabPFN) trained\nspecifically for data fitting. Despite being explicitly designed to achieve\nprediction robustness, TabPFN is still not immune to task-irrelevant\nvariations. Overall, despite LLMs' impressive predictive capabilities,\ncurrently they lack even the basic level of robustness to be used as a\nprincipled data-fitting tool.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7528\u4e8e\u6570\u636e\u62df\u5408\u65f6\u5bf9\u4efb\u52a1\u65e0\u5173\u7684\u53d8\u5316\u654f\u611f\uff0c\u7f3a\u4e4f\u57fa\u672c\u9c81\u68d2\u6027\uff0c\u5373\u4f7f\u4e13\u95e8\u7684\u6a21\u578b\u4e5f\u5b58\u5728\u6b64\u95ee\u9898\u3002", "motivation": "\u7814\u7a76LLMs\u7528\u4e8e\u6570\u636e\u62df\u5408\u65f6\u7684\u6f5c\u5728\u95ee\u9898\uff0c\u8bc4\u4f30\u5176\u4f5c\u4e3a\u6570\u636e\u62df\u5408\u5de5\u5177\u7684\u53ef\u9760\u6027\u3002", "method": "\u5206\u6790LLMs\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u4e0b\u5bf9\u4efb\u52a1\u65e0\u5173\u53d8\u5316\u7684\u9884\u6d4b\u654f\u611f\u6027\uff0c\u68c0\u67e5\u5f00\u653e\u6743\u91cdLLM\u7684\u6ce8\u610f\u529b\u5206\u6570\uff0c\u5bf9\u6bd4\u4e13\u95e8\u7684\u8868\u683c\u57fa\u7840\u6a21\u578bTabPFN\u3002", "result": "\u53d1\u73b0LLMs\u5bf9\u4efb\u52a1\u65e0\u5173\u53d8\u5316\u9ad8\u5ea6\u654f\u611f\uff0c\u5982\u6539\u53d8\u53d8\u91cf\u540d\u4f1a\u5927\u5e45\u5f71\u54cd\u9884\u6d4b\u7ed3\u679c\uff0c\u4e14\u5b58\u5728\u975e\u5747\u5300\u6ce8\u610f\u529b\u6a21\u5f0f\uff0cTabPFN\u4e5f\u4e0d\u80fd\u5b8c\u5168\u514d\u75ab\u3002", "conclusion": "\u5c3d\u7ba1LLMs\u6709\u5f3a\u5927\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u4f5c\u4e3a\u6570\u636e\u62df\u5408\u5de5\u5177\u7684\u57fa\u672c\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.19997", "pdf": "https://arxiv.org/pdf/2508.19997", "abs": "https://arxiv.org/abs/2508.19997", "authors": ["Boheng Mao"], "title": "Selective Retrieval-Augmentation for Long-Tail Legal Text Classification", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Legal text classification is a fundamental NLP task in the legal domain.\nBenchmark datasets in this area often exhibit a long-tail label distribution,\nwhere many labels are underrepresented, leading to poor model performance on\nrare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a\nsolution to this problem. SRA focuses on augmenting samples belonging to\nlow-frequency labels in the training set, preventing the introduction of noise\nfor well-represented classes, and requires no changes to the model\narchitecture. Retrieval is performed only from the training data to ensure\nthere is no potential information leakage, removing the need for external\ncorpora simultaneously. The proposed SRA method is tested on two legal text\nclassification benchmark datasets with long-tail distributions: LEDGAR\n(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA\nattains higher micro-F1 and macro-F1 scores compared to all current LexGLUE\nbaselines across both datasets, illustrating consistent improvements in\nlong-tail legal text classification. The code repository is available at:\nhttps://github.com/Boheng-Mao/sra-legal", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u57fa\u51c6\u6570\u636e\u96c6\u957f\u5c3e\u6807\u7b7e\u5206\u5e03\u95ee\u9898\uff0c\u63d0\u51fa\u9009\u62e9\u6027\u68c0\u7d22\u589e\u5f3a\uff08SRA\uff09\u65b9\u6cd5\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u663e\u793a\u80fd\u63d0\u5347\u957f\u5c3e\u5df4\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u57fa\u51c6\u6570\u636e\u96c6\u5b58\u5728\u957f\u5c3e\u6807\u7b7e\u5206\u5e03\uff0c\u5bfc\u81f4\u7a00\u6709\u7c7b\u6a21\u578b\u6027\u80fd\u5dee\u3002", "method": "\u63d0\u51faSRA\u65b9\u6cd5\uff0c\u5bf9\u8bad\u7ec3\u96c6\u4e2d\u4f4e\u9891\u6807\u7b7e\u6837\u672c\u589e\u5f3a\uff0c\u4ec5\u4ece\u8bad\u7ec3\u6570\u636e\u68c0\u7d22\uff0c\u4e0d\u6539\u53d8\u6a21\u578b\u67b6\u6784\u3002", "result": "SRA\u5728\u4e24\u4e2a\u957f\u5c3e\u5206\u5e03\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5faeF1\u548c\u5b8fF1\u5206\u6570\u9ad8\u4e8e\u5f53\u524dLexGLUE\u6240\u6709\u57fa\u7ebf\u3002", "conclusion": "SRA\u80fd\u6301\u7eed\u6539\u5584\u957f\u5c3e\u5df4\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u6548\u679c\u3002"}}
{"id": "2508.19827", "pdf": "https://arxiv.org/pdf/2508.19827", "abs": "https://arxiv.org/abs/2508.19827", "authors": ["Samuel Lewis-Lim", "Xingwei Tan", "Zhixue Zhao", "Nikolaos Aletras"], "title": "Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted at EMNLP 2025 Main Conference", "summary": "Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited\ngains for soft-reasoning problems such as analytical and commonsense reasoning.\nCoT can also be unfaithful to a model's actual reasoning. We investigate the\ndynamics and faithfulness of CoT in soft-reasoning tasks across\ninstruction-tuned, reasoning and reasoning-distilled models. Our findings\nreveal differences in how these models rely on CoT, and show that CoT influence\nand faithfulness are not always aligned.", "AI": {"tldr": "\u7814\u7a76\u601d\u7ef4\u94fe\uff08CoT\uff09\u5728\u8f6f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u52a8\u6001\u548c\u5fe0\u5b9e\u6027\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u5bf9CoT\u7684\u4f9d\u8d56\u5b58\u5728\u5dee\u5f02\uff0c\u4e14CoT\u5f71\u54cd\u548c\u5fe0\u5b9e\u6027\u5e76\u4e0d\u603b\u662f\u4e00\u81f4\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660eCoT\u5728\u8f6f\u63a8\u7406\u95ee\u9898\u4e0a\u6536\u76ca\u6709\u9650\u4e14\u53ef\u80fd\u4e0d\u5fe0\u5b9e\u4e8e\u6a21\u578b\u5b9e\u9645\u63a8\u7406\uff0c\u56e0\u6b64\u7814\u7a76\u5176\u5728\u8f6f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u52a8\u6001\u548c\u5fe0\u5b9e\u6027\u3002", "method": "\u5728\u6307\u4ee4\u8c03\u4f18\u3001\u63a8\u7406\u548c\u63a8\u7406\u84b8\u998f\u6a21\u578b\u4e2d\u7814\u7a76CoT\u5728\u8f6f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u60c5\u51b5\u3002", "result": "\u4e0d\u540c\u6a21\u578b\u5bf9CoT\u7684\u4f9d\u8d56\u5b58\u5728\u5dee\u5f02\uff0cCoT\u5f71\u54cd\u548c\u5fe0\u5b9e\u6027\u5e76\u4e0d\u603b\u662f\u4e00\u81f4\u3002", "conclusion": "\u660e\u786e\u4e86\u4e0d\u540c\u6a21\u578b\u5728CoT\u4f7f\u7528\u4e0a\u7684\u5dee\u5f02\u4ee5\u53caCoT\u5f71\u54cd\u548c\u5fe0\u5b9e\u6027\u7684\u5173\u7cfb\u3002"}}
{"id": "2508.19780", "pdf": "https://arxiv.org/pdf/2508.19780", "abs": "https://arxiv.org/abs/2508.19780", "authors": ["Ryoma Sato"], "title": "Interestingness First Classifiers", "categories": ["cs.LG", "stat.ML"], "comment": "14 pages", "summary": "Most machine learning models are designed to maximize predictive accuracy. In\nthis work, we explore a different goal: building classifiers that are\ninteresting. An ``interesting classifier'' is one that uses unusual or\nunexpected features, even if its accuracy is lower than the best possible\nmodel. For example, predicting room congestion from CO2 levels achieves\nnear-perfect accuracy but is unsurprising. In contrast, predicting room\ncongestion from humidity is less accurate yet more nuanced and intriguing. We\nintroduce EUREKA, a simple framework that selects features according to their\nperceived interestingness. Our method leverages large language models to rank\nfeatures by their interestingness and then builds interpretable classifiers\nusing only the selected interesting features. Across several benchmark\ndatasets, EUREKA consistently identifies features that are non-obvious yet\nstill predictive. For example, in the Occupancy Detection dataset, our method\nfavors humidity over CO2 levels and light intensity, producing classifiers that\nachieve meaningful accuracy while offering insights. In the Twin Papers\ndataset, our method discovers the rule that papers with a colon in the title\nare more likely to be cited in the future. We argue that such models can\nsupport new ways of knowledge discovery and communication, especially in\nsettings where moderate accuracy is sufficient but novelty and interpretability\nare valued.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u6784\u5efa\u6709\u8da3\u7684\u5206\u7c7b\u5668\uff0c\u63d0\u51faEUREKA\u6846\u67b6\uff0c\u80fd\u9009\u51fa\u975e\u660e\u663e\u4f46\u6709\u9884\u6d4b\u6027\u7684\u7279\u5f81\uff0c\u652f\u6301\u65b0\u77e5\u8bc6\u53d1\u73b0\u4e0e\u4ea4\u6d41\u3002", "motivation": "\u591a\u6570\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65e8\u5728\u6700\u5927\u5316\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u672c\u6587\u63a2\u7d22\u6784\u5efa\u4f7f\u7528\u4e0d\u5bfb\u5e38\u7279\u5f81\u7684\u6709\u8da3\u5206\u7c7b\u5668\u8fd9\u4e00\u4e0d\u540c\u76ee\u6807\u3002", "method": "\u5f15\u5165EUREKA\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6309\u7279\u5f81\u6709\u8da3\u5ea6\u6392\u5e8f\uff0c\u4ec5\u4f7f\u7528\u9009\u5b9a\u7684\u6709\u8da3\u7279\u5f81\u6784\u5efa\u53ef\u89e3\u91ca\u5206\u7c7b\u5668\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cEUREKA\u80fd\u6301\u7eed\u8bc6\u522b\u51fa\u975e\u660e\u663e\u4f46\u6709\u9884\u6d4b\u6027\u7684\u7279\u5f81\uff0c\u5982\u5728Occupancy Detection\u6570\u636e\u96c6\u4e2d\u9752\u7750\u6e7f\u5ea6\uff0c\u5728Twin Papers\u6570\u636e\u96c6\u4e2d\u53d1\u73b0\u6807\u9898\u542b\u5192\u53f7\u7684\u8bba\u6587\u66f4\u6613\u88ab\u5f15\u7528\u3002", "conclusion": "\u6b64\u7c7b\u6a21\u578b\u80fd\u652f\u6301\u65b0\u77e5\u8bc6\u53d1\u73b0\u548c\u4ea4\u6d41\uff0c\u5c24\u5176\u5728\u5bf9\u51c6\u786e\u6027\u8981\u6c42\u9002\u4e2d\u4f46\u770b\u91cd\u65b0\u9896\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u573a\u666f\u3002"}}
{"id": "2508.20013", "pdf": "https://arxiv.org/pdf/2508.20013", "abs": "https://arxiv.org/abs/2508.20013", "authors": ["Lotte Gross", "Rebecca Walter", "Nicole Zoppi", "Adrien Justus", "Alessandro Gambetti", "Qiwei Han", "Maximilian Kaiser"], "title": "Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": "10 pages, 5 figures, 3 tables", "summary": "This study addresses critical industrial challenges in e-commerce product\ncategorization, namely platform heterogeneity and the structural limitations of\nexisting taxonomies, by developing and deploying a multimodal hierarchical\nclassification framework. Using a dataset of 271,700 products from 40\ninternational fashion e-commerce platforms, we integrate textual features\n(RoBERTa), visual features (ViT), and joint vision--language representations\n(CLIP). We investigate fusion strategies, including early, late, and\nattention-based fusion within a hierarchical architecture enhanced by dynamic\nmasking to ensure taxonomic consistency. Results show that CLIP embeddings\ncombined via an MLP-based late-fusion strategy achieve the highest hierarchical\nF1 (98.59\\%), outperforming unimodal baselines. To address shallow or\ninconsistent categories, we further introduce a self-supervised ``product\nrecategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which\ndiscovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with\ncluster purities above 86\\%. Cross-platform experiments reveal a\ndeployment-relevant trade-off: complex late-fusion methods maximize accuracy\nwith diverse training data, while simpler early-fusion methods generalize more\neffectively to unseen platforms. Finally, we demonstrate the framework's\nindustrial scalability through deployment in EURWEB's commercial transaction\nintelligence platform via a two-stage inference pipeline, combining a\nlightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance\ncost and accuracy.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u90e8\u7f72\u591a\u6a21\u6001\u5206\u5c42\u5206\u7c7b\u6846\u67b6\u89e3\u51b3\u7535\u5546\u4ea7\u54c1\u5206\u7c7b\u95ee\u9898\uff0c\u7528\u591a\u79cd\u878d\u5408\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660eCLRIP\u5d4c\u5165\u7ed3\u5408MLP\u665a\u671f\u878d\u5408\u7b56\u7565\u6548\u679c\u6700\u4f73\uff0c\u8fd8\u5f15\u5165\u81ea\u76d1\u7763\u7ba1\u9053\u53d1\u73b0\u7ec6\u7c92\u5ea6\u7c7b\u522b\uff0c\u63a2\u8ba8\u4e0d\u540c\u878d\u5408\u65b9\u6cd5\u5728\u8de8\u5e73\u53f0\u7684\u8868\u73b0\u5e76\u5c55\u793a\u6846\u67b6\u5de5\u4e1a\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3\u7535\u5546\u4ea7\u54c1\u5206\u7c7b\u4e2d\u7684\u5e73\u53f0\u5f02\u8d28\u6027\u548c\u73b0\u6709\u5206\u7c7b\u6cd5\u7ed3\u6784\u9650\u5236\u7b49\u5173\u952e\u5de5\u4e1a\u6311\u6218\u3002", "method": "\u5f00\u53d1\u591a\u6a21\u6001\u5206\u5c42\u5206\u7c7b\u6846\u67b6\uff0c\u6574\u5408\u6587\u672c\u3001\u89c6\u89c9\u548c\u89c6\u89c9 - \u8bed\u8a00\u8054\u5408\u7279\u5f81\uff0c\u7814\u7a76\u4e0d\u540c\u878d\u5408\u7b56\u7565\uff0c\u5f15\u5165\u81ea\u76d1\u7763\u201c\u4ea7\u54c1\u91cd\u65b0\u5206\u7c7b\u201d\u7ba1\u9053\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u63a8\u7406\u7ba1\u9053\u90e8\u7f72\u3002", "result": "CLIP\u5d4c\u5165\u7ed3\u5408MLP\u665a\u671f\u878d\u5408\u7b56\u7565\u5b9e\u73b0\u6700\u9ad8\u5206\u5c42F1\u503c98.59%\uff0c\u81ea\u76d1\u7763\u7ba1\u9053\u53d1\u73b0\u7ec6\u7c92\u5ea6\u7c7b\u522b\u4e14\u7c07\u7eaf\u5ea6\u8d8586%\uff0c\u590d\u6742\u665a\u671f\u878d\u5408\u65b9\u6cd5\u5728\u591a\u6837\u8bad\u7ec3\u6570\u636e\u4e0b\u7cbe\u5ea6\u9ad8\uff0c\u7b80\u5355\u65e9\u671f\u878d\u5408\u65b9\u6cd5\u5bf9\u672a\u89c1\u5e73\u53f0\u6cdb\u5316\u6027\u597d\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u591a\u6a21\u6001\u5206\u5c42\u5206\u7c7b\u6846\u67b6\u6709\u6548\u89e3\u51b3\u7535\u5546\u4ea7\u54c1\u5206\u7c7b\u95ee\u9898\uff0c\u4e14\u5177\u6709\u5de5\u4e1a\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.19851", "pdf": "https://arxiv.org/pdf/2508.19851", "abs": "https://arxiv.org/abs/2508.19851", "authors": ["Romain Harang", "Jason Naradowsky", "Yaswitha Gujju", "Yusuke Miyao"], "title": "Tracking World States with Language Models: State-Based Evaluation Using Chess", "categories": ["cs.AI"], "comment": "Spotlight presentation at ICML 2025 Workshop on Assessing World\n  Models", "summary": "Large Language Models (LLMs) exhibit emergent capabilities in structured\ndomains, suggesting they may implicitly internalize high-fidelity\nrepresentations of world models. While probing techniques have shown promising\nsigns of this in scientific and game-based settings, they rely on\nmodel-specific internal activations, which limit interpretability and\ngeneralizability. In this work, we propose a model-agnostic, state-based\nevaluation framework using chess as a benchmark to assess whether LLMs preserve\nthe semantics of structured environments. Our method analyzes the downstream\nlegal move distributions (state affordances) to estimate semantic fidelity\nbetween predicted and actual game states. This approach offers a more\nmeaningful evaluation than conventional string-based metrics by aligning more\nclosely with the strategic and rule-governed nature of chess. Experimental\nresults demonstrate that our metrics capture deficiencies in state-tracking,\nhighlighting limitations of LLMs in maintaining coherent internal models over\nlong sequences. Our framework provides a robust tool for evaluating structured\nreasoning in LLMs without requiring internal model access, and generalizes to a\nwide class of symbolic environments.", "AI": {"tldr": "\u63d0\u51fa\u7528\u56fd\u9645\u8c61\u68cb\u4f5c\u4e3a\u57fa\u51c6\u7684\u6a21\u578b\u65e0\u5173\u3001\u57fa\u4e8e\u72b6\u6001\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u80fd\u6355\u6349\u72b6\u6001\u8ddf\u8e2a\u7f3a\u9677\uff0c\u6846\u67b6\u6709\u901a\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u63a2\u6d4b\u6280\u672f\u4f9d\u8d56\u6a21\u578b\u7279\u5b9a\u5185\u90e8\u6fc0\u6d3b\uff0c\u9650\u5236\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u901a\u7528\u6027\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "method": "\u4ee5\u56fd\u9645\u8c61\u68cb\u4e3a\u57fa\u51c6\uff0c\u5206\u6790\u4e0b\u6e38\u5408\u6cd5\u8d70\u6cd5\u5206\u5e03\uff08\u72b6\u6001\u53ef\u4f9b\u6027\uff09\u6765\u4f30\u8ba1\u9884\u6d4b\u548c\u5b9e\u9645\u6e38\u620f\u72b6\u6001\u4e4b\u95f4\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6307\u6807\u80fd\u6355\u6349\u72b6\u6001\u8ddf\u8e2a\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u51f8\u663e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5e8f\u5217\u4e2d\u7ef4\u6301\u8fde\u8d2f\u5185\u90e8\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u6784\u5316\u63a8\u7406\u7684\u6709\u529b\u5de5\u5177\uff0c\u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\uff0c\u4e14\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u7b26\u53f7\u73af\u5883\u3002"}}
{"id": "2508.19914", "pdf": "https://arxiv.org/pdf/2508.19914", "abs": "https://arxiv.org/abs/2508.19914", "authors": ["Muhammad Waqas", "Rukhmini Bandyopadhyay", "Eman Showkatian", "Amgad Muneer", "Anas Zafar", "Frank Rojas Alvarez", "Maricel Corredor Marin", "Wentao Li", "David Jaffray", "Cara Haymaker", "John Heymach", "Natalie I Vokes", "Luisa Maren Solis Soto", "Jianjun Zhang", "Jia Wu"], "title": "The Next Layer: Augmenting Foundation Models with Structure-Preserving and Attention-Guided Learning for Local Patches to Global Context Awareness in Computational Pathology", "categories": ["q-bio.QM", "cs.AI", "stat.ML"], "comment": "43 pages, 7 main Figures, 8 Extended Data Figures", "summary": "Foundation models have recently emerged as powerful feature extractors in\ncomputational pathology, yet they typically omit mechanisms for leveraging the\nglobal spatial structure of tissues and the local contextual relationships\namong diagnostically relevant regions - key elements for understanding the\ntumor microenvironment. Multiple instance learning (MIL) remains an essential\nnext step following foundation model, designing a framework to aggregate\npatch-level features into slide-level predictions. We present EAGLE-Net, a\nstructure-preserving, attention-guided MIL architecture designed to augment\nprediction and interpretability. EAGLE-Net integrates multi-scale absolute\nspatial encoding to capture global tissue architecture, a top-K\nneighborhood-aware loss to focus attention on local microenvironments, and\nbackground suppression loss to minimize false positives. We benchmarked\nEAGLE-Net on large pan-cancer datasets, including three cancer types for\nclassification (10,260 slides) and seven cancer types for survival prediction\n(4,172 slides), using three distinct histology foundation backbones (REMEDIES,\nUni-V1, Uni2-h). Across tasks, EAGLE-Net achieved up to 3% higher\nclassification accuracy and the top concordance indices in 6 of 7 cancer types,\nproducing smooth, biologically coherent attention maps that aligned with expert\nannotations and highlighted invasive fronts, necrosis, and immune infiltration.\nThese results position EAGLE-Net as a generalizable, interpretable framework\nthat complements foundation models, enabling improved biomarker discovery,\nprognostic modeling, and clinical decision support", "AI": {"tldr": "\u63d0\u51faEAGLE - Net\u7ed3\u6784\u4fdd\u5b58\u3001\u6ce8\u610f\u529b\u5f15\u5bfc\u7684MIL\u67b6\u6784\uff0c\u5728\u591a\u4e2a\u764c\u75c7\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u53ef\u63d0\u5347\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u7b49\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u7840\u6a21\u578b\u5728\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7f3a\u5c11\u5229\u7528\u7ec4\u7ec7\u5168\u5c40\u7a7a\u95f4\u7ed3\u6784\u548c\u8bca\u65ad\u76f8\u5173\u533a\u57df\u5c40\u90e8\u4e0a\u4e0b\u6587\u5173\u7cfb\u7684\u673a\u5236\uff0cMIL\u662f\u57fa\u7840\u6a21\u578b\u4e4b\u540e\u7684\u5173\u952e\u6b65\u9aa4\u3002", "method": "\u63d0\u51faEAGLE - Net\u67b6\u6784\uff0c\u96c6\u6210\u591a\u5c3a\u5ea6\u7edd\u5bf9\u7a7a\u95f4\u7f16\u7801\u3001top - K\u90bb\u57df\u611f\u77e5\u635f\u5931\u548c\u80cc\u666f\u6291\u5236\u635f\u5931\u3002", "result": "\u5728\u5927\u578b\u6cdb\u764c\u6570\u636e\u96c6\u4e0a\uff0cEAGLE - Net\u5206\u7c7b\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u53473%\uff0c7\u79cd\u764c\u75c7\u4e2d\u67096\u79cd\u8fbe\u5230\u6700\u9ad8\u4e00\u81f4\u6027\u6307\u6570\uff0c\u751f\u6210\u7684\u6ce8\u610f\u529b\u56fe\u4e0e\u4e13\u5bb6\u6ce8\u91ca\u4e00\u81f4\u3002", "conclusion": "EAGLE - Net\u662f\u53ef\u6cdb\u5316\u3001\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u80fd\u8865\u5145\u57fa\u7840\u6a21\u578b\uff0c\u6709\u52a9\u4e8e\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u3001\u9884\u540e\u5efa\u6a21\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2508.19277", "pdf": "https://arxiv.org/pdf/2508.19277", "abs": "https://arxiv.org/abs/2508.19277", "authors": ["Xinyu Li", "Tianjin Huang", "Ronghui Mu", "Xiaowei Huang", "Gaojie Jin"], "title": "POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Recent advances in Chain-of-Thought (CoT) prompting have substantially\nenhanced the reasoning capabilities of large language models (LLMs), enabling\nsophisticated problem-solving through explicit multi-step reasoning traces.\nHowever, these enhanced reasoning processes introduce novel attack surfaces,\nparticularly vulnerabilities to computational inefficiency through\nunnecessarily verbose reasoning chains that consume excessive resources without\ncorresponding performance gains. Prior overthinking attacks typically require\nrestrictive conditions including access to external knowledge sources for data\npoisoning, reliance on retrievable poisoned content, and structurally obvious\ntemplates that limit practical applicability in real-world scenarios. To\naddress these limitations, we propose POT (Prompt-Only OverThinking), a novel\nblack-box attack framework that employs LLM-based iterative optimization to\ngenerate covert and semantically natural adversarial prompts, eliminating\ndependence on external data access and model retrieval. Extensive experiments\nacross diverse model architectures and datasets demonstrate that POT achieves\nsuperior performance compared to other methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPOT\u6846\u67b6\u5e94\u5bf9\u601d\u7ef4\u94fe\u63d0\u793a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65f6\u5e26\u6765\u7684\u65b0\u653b\u51fb\u9762\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u601d\u7ef4\u94fe\u63d0\u793a\u867d\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5e26\u6765\u65b0\u653b\u51fb\u9762\u95ee\u9898\uff0c\u4e14\u4e4b\u524d\u7684\u8fc7\u5ea6\u601d\u8003\u653b\u51fb\u6709\u8bf8\u591a\u9650\u5236\uff0c\u7f3a\u4e4f\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002", "method": "\u63d0\u51faPOT\uff08\u4ec5\u63d0\u793a\u8fc7\u5ea6\u601d\u8003\uff09\u9ed1\u76d2\u653b\u51fb\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fed\u4ee3\u4f18\u5316\u751f\u6210\u9690\u853d\u4e14\u8bed\u4e49\u81ea\u7136\u7684\u5bf9\u6297\u6027\u63d0\u793a\u3002", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPOT\u6bd4\u5176\u4ed6\u65b9\u6cd5\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "POT\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u95ee\u9898\uff0c\u5728\u5e94\u5bf9\u601d\u7ef4\u94fe\u63d0\u793a\u653b\u51fb\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.19932", "pdf": "https://arxiv.org/pdf/2508.19932", "abs": "https://arxiv.org/abs/2508.19932", "authors": ["Nitish Jaipuria", "Lorenzo Gatto", "Zijun Kan", "Shankey Poddar", "Bill Cheung", "Diksha Bansal", "Ramanan Balakrishnan", "Aviral Suri", "Jose Estevez"], "title": "CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments", "categories": ["cs.AI"], "comment": "10 pages, 5 figures", "summary": "The proliferation of digital payment platforms has transformed commerce,\noffering unmatched convenience and accessibility globally. However, this growth\nhas also attracted malicious actors, leading to a corresponding increase in\nsophisticated social engineering scams. These scams are often initiated and\norchestrated on multiple surfaces outside the payment platform, making user and\ntransaction-based signals insufficient for a complete understanding of the\nscam's methodology and underlying patterns, without which it is very difficult\nto prevent it in a timely manner. This paper presents CASE (Conversational\nAgent for Scam Elucidation), a novel Agentic AI framework that addresses this\nproblem by collecting and managing user scam feedback in a safe and scalable\nmanner. A conversational agent is uniquely designed to proactively interview\npotential victims to elicit intelligence in the form of a detailed\nconversation. The conversation transcripts are then consumed by another AI\nsystem that extracts information and converts it into structured data for\ndownstream usage in automated and manual enforcement mechanisms. Using Google's\nGemini family of LLMs, we implemented this framework on Google Pay (GPay)\nIndia. By augmenting our existing features with this new intelligence, we have\nobserved a 21% uplift in the volume of scam enforcements. The architecture and\nits robust evaluation framework are highly generalizable, offering a blueprint\nfor building similar AI-driven systems to collect and manage scam intelligence\nin other sensitive domains.", "AI": {"tldr": "\u6570\u5b57\u652f\u4ed8\u5e73\u53f0\u8bc8\u9a97\u589e\u591a\uff0c\u672c\u6587\u63d0\u51faCASE\u6846\u67b6\u6536\u96c6\u7ba1\u7406\u8bc8\u9a97\u53cd\u9988\uff0c\u5728GPay India\u5b9e\u73b0\u5e76\u4f7f\u8bc8\u9a97\u6267\u6cd5\u91cf\u63d0\u534721%\uff0c\u67b6\u6784\u5177\u901a\u7528\u6027\u3002", "motivation": "\u6570\u5b57\u652f\u4ed8\u5e73\u53f0\u53d1\u5c55\u5bfc\u81f4\u8bc8\u9a97\u589e\u591a\uff0c\u73b0\u6709\u7528\u6237\u548c\u4ea4\u6613\u4fe1\u53f7\u4e0d\u8db3\u4ee5\u7406\u89e3\u8bc8\u9a97\u65b9\u6cd5\u548c\u6a21\u5f0f\uff0c\u96be\u4ee5\u53ca\u65f6\u9632\u8303\u3002", "method": "\u63d0\u51faCASE\u6846\u67b6\uff0c\u7528\u5bf9\u8bdd\u4ee3\u7406\u4e3b\u52a8\u8be2\u95ee\u6f5c\u5728\u53d7\u5bb3\u8005\u83b7\u53d6\u4fe1\u606f\uff0c\u7531\u53e6\u4e00AI\u7cfb\u7edf\u63d0\u53d6\u4fe1\u606f\u8f6c\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u7528\u4e8e\u6267\u6cd5\u673a\u5236\u3002", "result": "\u5728Google Pay India\u5b9e\u65bd\u8be5\u6846\u67b6\uff0c\u8bc8\u9a97\u6267\u6cd5\u91cf\u63d0\u534721%\u3002", "conclusion": "\u67b6\u6784\u53ca\u5176\u8bc4\u4f30\u6846\u67b6\u5177\u6709\u9ad8\u901a\u7528\u6027\uff0c\u53ef\u4e3a\u5176\u4ed6\u654f\u611f\u9886\u57df\u6784\u5efa\u7c7b\u4f3cAI\u7cfb\u7edf\u63d0\u4f9b\u84dd\u56fe\u3002"}}
{"id": "2508.20036", "pdf": "https://arxiv.org/pdf/2508.20036", "abs": "https://arxiv.org/abs/2508.20036", "authors": ["Lucas Benigni", "Elliot Paquette"], "title": "Eigenvalue distribution of the Neural Tangent Kernel in the quadratic scaling", "categories": ["math.PR", "stat.ML"], "comment": "42 pages, 8 figures", "summary": "We compute the asymptotic eigenvalue distribution of the neural tangent\nkernel of a two-layer neural network under a specific scaling of dimension.\nNamely, if $X\\in\\mathbb{R}^{n\\times d}$ is an i.i.d random matrix,\n$W\\in\\mathbb{R}^{d\\times p}$ is an i.i.d $\\mathcal{N}(0,1)$ matrix and\n$D\\in\\mathbb{R}^{p\\times p}$ is a diagonal matrix with i.i.d bounded entries,\nwe consider the matrix\n  \\[\n  \\mathrm{NTK}\n  =\n  \\frac{1}{d}XX^\\top\n  \\odot\n  \\frac{1}{p}\n  \\sigma'\\left(\n  \\frac{1}{\\sqrt{d}}XW\n  \\right)D^2\n  \\sigma'\\left(\n  \\frac{1}{\\sqrt{d}}XW\n  \\right)^\\top\n  \\]\n  where $\\sigma'$ is a pseudo-Lipschitz function applied entrywise and under\nthe scaling $\\frac{n}{dp}\\to \\gamma_1$ and $\\frac{p}{d}\\to \\gamma_2$. We\ndescribe the asymptotic distribution as the free multiplicative convolution of\nthe Marchenko--Pastur distribution with a deterministic distribution depending\non $\\sigma$ and $D$.", "AI": {"tldr": "\u8ba1\u7b97\u7279\u5b9a\u7ef4\u5ea6\u7f29\u653e\u4e0b\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u795e\u7ecf\u5207\u7ebf\u6838\u7684\u6e10\u8fd1\u7279\u5f81\u503c\u5206\u5e03\uff0c\u7ed3\u679c\u4e3a\u4e0e\u7279\u5b9a\u5206\u5e03\u7684\u81ea\u7531\u4e58\u6027\u5377\u79ef\u3002", "motivation": "\u7814\u7a76\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u795e\u7ecf\u5207\u7ebf\u6838\u5728\u7279\u5b9a\u7ef4\u5ea6\u7f29\u653e\u4e0b\u7684\u6e10\u8fd1\u7279\u5f81\u503c\u5206\u5e03\u3002", "method": "\u57fa\u4e8e\u7ed9\u5b9a\u7684\u77e9\u9635\u5f62\u5f0f\u548c\u7f29\u653e\u6761\u4ef6\uff0c\u8fd0\u7528\u76f8\u5173\u6570\u5b66\u7406\u8bba\u8fdb\u884c\u8ba1\u7b97\u3002", "result": "\u6e10\u8fd1\u5206\u5e03\u4e3aMarchenko - Pastur\u5206\u5e03\u4e0e\u4f9d\u8d56\u4e8e\u03c3\u548cD\u7684\u786e\u5b9a\u6027\u5206\u5e03\u7684\u81ea\u7531\u4e58\u6027\u5377\u79ef\u3002", "conclusion": "\u6210\u529f\u63cf\u8ff0\u4e86\u7279\u5b9a\u7ef4\u5ea6\u7f29\u653e\u4e0b\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u795e\u7ecf\u5207\u7ebf\u6838\u7684\u6e10\u8fd1\u7279\u5f81\u503c\u5206\u5e03\u3002"}}
{"id": "2508.19318", "pdf": "https://arxiv.org/pdf/2508.19318", "abs": "https://arxiv.org/abs/2508.19318", "authors": ["Aohan Li", "Miyu Tsuzuki"], "title": "(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep Reinforcement Learning (DRL) has emerged as an efficient approach to\nresource allocation due to its strong capability in handling complex\ndecision-making tasks. However, only limited research has explored the training\nof DRL models with real-world data in practical, distributed Internet of Things\n(IoT) systems. To bridge this gap, this paper proposes a novel framework for\ntraining DRL models in real-world distributed IoT environments. In the proposed\nframework, IoT devices select communication channels using a DRL-based method,\nwhile the DRL model is trained with feedback information. Specifically,\nAcknowledgment (ACK) information is obtained from actual data transmissions\nover the selected channels. Implementation and performance evaluation, in terms\nof Frame Success Rate (FSR), are carried out, demonstrating both the\nfeasibility and the effectiveness of the proposed framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u73b0\u5b9e\u5206\u5e03\u5f0f\u7269\u8054\u7f51\u73af\u5883\u4e2d\u8bad\u7ec3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7ecf\u8bc4\u4f30\u8bc1\u660e\u5176\u53ef\u884c\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u5b9e\u9645\u5206\u5e03\u5f0f\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\u7528\u771f\u5b9e\u6570\u636e\u8bad\u7ec3DRL\u6a21\u578b\u8f83\u5c11\uff0c\u9700\u586b\u8865\u8be5\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u6846\u67b6\uff0c\u8ba9\u7269\u8054\u7f51\u8bbe\u5907\u7528\u57fa\u4e8eDRL\u7684\u65b9\u6cd5\u9009\u62e9\u901a\u4fe1\u4fe1\u9053\uff0c\u5229\u7528\u53cd\u9988\u4fe1\u606f\u8bad\u7ec3DRL\u6a21\u578b\uff0c\u4ece\u6240\u9009\u4fe1\u9053\u7684\u5b9e\u9645\u6570\u636e\u4f20\u8f93\u4e2d\u83b7\u53d6\u786e\u8ba4\uff08ACK\uff09\u4fe1\u606f\u3002", "result": "\u901a\u8fc7\u5bf9\u5e27\u6210\u529f\u7387\uff08FSR\uff09\u7684\u5b9e\u73b0\u548c\u6027\u80fd\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5728\u73b0\u5b9e\u5206\u5e03\u5f0f\u7269\u8054\u7f51\u73af\u5883\u4e2d\u8bad\u7ec3DRL\u6a21\u578b\u7684\u6846\u67b6\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002"}}
{"id": "2508.19963", "pdf": "https://arxiv.org/pdf/2508.19963", "abs": "https://arxiv.org/abs/2508.19963", "authors": ["M. Umlauft", "M. Schranz"], "title": "Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants", "categories": ["cs.AI"], "comment": "This is the author's version of a paper reviewed and accepted by the\n  9th International Symposium on Swarm Behavior and Bio-Inspired Robotics 2025.\n  Authors were not able to present it due to time constraints. 3 Tables, 5\n  Figures", "summary": "Optimizing modern production plants using the job-shop principle is a known\nhard problem. For very large plants, like semiconductor fabs, the problem\nbecomes unsolvable on a plant-wide scale in a reasonable amount of time using\nclassical linear optimization. An alternative approach is the use of swarm\nintelligence algorithms. These have been applied to the job-shop problem\nbefore, but often in a centrally calculated way where they are applied to the\nsolution space, but they can be implemented in a bottom-up fashion to avoid\nglobal result computation as well. One of the problems in semiconductor\nproduction is that the production process requires a lot of switching between\nmachines that process lots one after the other and machines that process\nbatches of lots at once, often with long processing times. In this paper, we\naddress this switching problem with the ``boids'' flocking algorithm that was\noriginally used in robotics and movie industry. The flocking behavior is a\nbio-inspired algorithm that uses only local information and interaction based\non simple heuristics. We show that this algorithm addresses these valid\nconsiderations in production plant optimization, as it reacts to the switching\nof machine kinds similar to how a swarm of flocking animals would react to\nobstacles in its course.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u534a\u5bfc\u4f53\u5de5\u5382\u751f\u4ea7\u4f18\u5316\u95ee\u9898\uff0c\u91c7\u7528\u2018boids\u2019\u7fa4\u805a\u7b97\u6cd5\u89e3\u51b3\u673a\u5668\u5207\u6362\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9\u751f\u4ea7\u4f18\u5316\u8003\u91cf\u3002", "motivation": "\u4f20\u7edf\u7ebf\u6027\u4f18\u5316\u65b9\u6cd5\u5728\u5927\u578b\u534a\u5bfc\u4f53\u5de5\u5382\u751f\u4ea7\u4f18\u5316\u95ee\u9898\u4e0a\u96be\u4ee5\u5728\u5408\u7406\u65f6\u95f4\u5185\u89e3\u51b3\uff0c\u4e14\u4ee5\u5f80\u7fa4\u667a\u80fd\u7b97\u6cd5\u591a\u4e3a\u96c6\u4e2d\u8ba1\u7b97\uff0c\u540c\u65f6\u534a\u5bfc\u4f53\u751f\u4ea7\u5b58\u5728\u673a\u5668\u5207\u6362\u95ee\u9898\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u8fd0\u7528\u539f\u672c\u7528\u4e8e\u673a\u5668\u4eba\u548c\u7535\u5f71\u884c\u4e1a\u7684\u2018boids\u2019\u7fa4\u805a\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u57fa\u4e8e\u7b80\u5355\u542f\u53d1\u5f0f\uff0c\u4ec5\u4f7f\u7528\u5c40\u90e8\u4fe1\u606f\u548c\u4ea4\u4e92\u3002", "result": "\u7b97\u6cd5\u80fd\u50cf\u7fa4\u805a\u52a8\u7269\u5e94\u5bf9\u969c\u788d\u7269\u4e00\u6837\u5bf9\u673a\u5668\u79cd\u7c7b\u7684\u5207\u6362\u505a\u51fa\u53cd\u5e94\u3002", "conclusion": "\u2018boids\u2019\u7fa4\u805a\u7b97\u6cd5\u53ef\u6709\u6548\u89e3\u51b3\u534a\u5bfc\u4f53\u751f\u4ea7\u4e2d\u7684\u673a\u5668\u5207\u6362\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u751f\u4ea7\u5de5\u5382\u4f18\u5316\u3002"}}
{"id": "2508.20067", "pdf": "https://arxiv.org/pdf/2508.20067", "abs": "https://arxiv.org/abs/2508.20067", "authors": ["Julia Walchessen", "Andrew Zammit-Mangion", "Rapha\u00ebl Huser", "Mikael Kuusela"], "title": "Neural Conditional Simulation for Complex Spatial Processes", "categories": ["stat.ME", "stat.ML"], "comment": "59 pages, 11 figures", "summary": "A key objective in spatial statistics is to simulate from the distribution of\na spatial process at a selection of unobserved locations conditional on\nobservations (i.e., a predictive distribution) to enable spatial prediction and\nuncertainty quantification. However, exact conditional simulation from this\npredictive distribution is intractable or inefficient for many spatial process\nmodels. In this paper, we propose neural conditional simulation (NCS), a\ngeneral method for spatial conditional simulation that is based on neural\ndiffusion models. Specifically, using spatial masks, we implement a conditional\nscore-based diffusion model that evolves Gaussian noise into samples from a\npredictive distribution when given a partially observed spatial field and\nspatial process parameters as inputs. The diffusion model relies on a neural\nnetwork that only requires unconditional samples from the spatial process for\ntraining. Once trained, the diffusion model is amortized with respect to the\nobservations in the partially observed field, the number and locations of those\nobservations, and the spatial process parameters, and can therefore be used to\nconditionally simulate from a broad class of predictive distributions without\nretraining the neural network. We assess the NCS-generated simulations against\nsimulations from the true conditional distribution of a Gaussian process model,\nand against Markov chain Monte Carlo (MCMC) simulations from a Brown--Resnick\nprocess model for spatial extremes. In the latter case, we show that it is more\nefficient and accurate to conditionally simulate using NCS than classical MCMC\ntechniques implemented in standard software. We conclude that NCS enables\nefficient and accurate conditional simulation from spatial predictive\ndistributions that are challenging to sample from using traditional methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u6269\u6563\u6a21\u578b\u7684\u7a7a\u95f4\u6761\u4ef6\u6a21\u62df\u65b9\u6cd5NCS\uff0c\u7ecf\u8bc4\u4f30\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u51c6\u786e\u3002", "motivation": "\u8bb8\u591a\u7a7a\u95f4\u8fc7\u7a0b\u6a21\u578b\u96be\u4ee5\u6216\u4f4e\u6548\u5730\u4ece\u9884\u6d4b\u5206\u5e03\u8fdb\u884c\u7cbe\u786e\u6761\u4ef6\u6a21\u62df\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u6761\u4ef6\u6a21\u62df\uff08NCS\uff09\uff0c\u5229\u7528\u7a7a\u95f4\u63a9\u7801\u5b9e\u73b0\u57fa\u4e8e\u6761\u4ef6\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff0c\u8bad\u7ec3\u540e\u53ef\u7528\u4e8e\u5e7f\u6cdb\u9884\u6d4b\u5206\u5e03\u7684\u6761\u4ef6\u6a21\u62df\u3002", "result": "\u5c06NCS\u751f\u6210\u7684\u6a21\u62df\u4e0e\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u7684\u771f\u5b9e\u6761\u4ef6\u5206\u5e03\u6a21\u62df\u3001\u5e03\u6717 - \u96f7\u65af\u5c3c\u514b\u8fc7\u7a0b\u6a21\u578b\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u7f57\uff08MCMC\uff09\u6a21\u62df\u8fdb\u884c\u6bd4\u8f83\uff0cNCS\u5728\u540e\u8005\u4e2d\u6bd4\u7ecf\u5178MCMC\u6280\u672f\u66f4\u9ad8\u6548\u51c6\u786e\u3002", "conclusion": "NCS\u80fd\u5bf9\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u91c7\u6837\u7684\u7a7a\u95f4\u9884\u6d4b\u5206\u5e03\u8fdb\u884c\u9ad8\u6548\u51c6\u786e\u7684\u6761\u4ef6\u6a21\u62df\u3002"}}
{"id": "2508.19344", "pdf": "https://arxiv.org/pdf/2508.19344", "abs": "https://arxiv.org/abs/2508.19344", "authors": ["Daniil Zelezetsky", "Egor Cherepanov", "Alexey K. Kovalev", "Aleksandr I. Panov"], "title": "Re:Frame -- Retrieving Experience From Associative Memory", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "Offline reinforcement learning (RL) often deals with suboptimal data when\ncollecting large expert datasets is unavailable or impractical. This limitation\nmakes it difficult for agents to generalize and achieve high performance, as\nthey must learn primarily from imperfect or inconsistent trajectories. A\ncentral challenge is therefore how to best leverage scarce expert\ndemonstrations alongside abundant but lower-quality data. We demonstrate that\nincorporating even a tiny amount of expert experience can substantially improve\nRL agent performance. We introduce Re:Frame (Retrieving Experience From\nAssociative Memory), a plug-in module that augments a standard offline RL\npolicy (e.g., Decision Transformer) with a small external Associative Memory\nBuffer (AMB) populated by expert trajectories drawn from a separate dataset.\nDuring training on low-quality data, the policy learns to retrieve expert data\nfrom the Associative Memory Buffer (AMB) via content-based associations and\nintegrate them into decision-making; the same AMB is queried at evaluation.\nThis requires no environment interaction and no modifications to the backbone\narchitecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories\n(0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a\nstrong Decision Transformer baseline in three of four settings, with gains up\nto +10.7 normalized points. These results show that Re:Frame offers a simple\nand data-efficient way to inject scarce expert knowledge and substantially\nimprove offline RL from low-quality datasets.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faRe:Frame\u6a21\u5757\uff0c\u5229\u7528\u5c11\u91cf\u4e13\u5bb6\u7ecf\u9a8c\u63d0\u5347\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u5728D4RL MuJoCo\u4efb\u52a1\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5e38\u5904\u7406\u6b21\u4f18\u6570\u636e\uff0c\u96be\u4ee5\u6cdb\u5316\u548c\u53d6\u5f97\u9ad8\u6027\u80fd\uff0c\u9700\u89e3\u51b3\u5982\u4f55\u5229\u7528\u7a00\u7f3a\u4e13\u5bb6\u6f14\u793a\u548c\u5927\u91cf\u4f4e\u8d28\u91cf\u6570\u636e\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165Re:Frame\u6a21\u5757\uff0c\u5728\u6807\u51c6\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4e2d\u52a0\u5165\u5916\u90e8\u5173\u8054\u8bb0\u5fc6\u7f13\u51b2\u533a\uff08AMB\uff09\uff0c\u8bad\u7ec3\u65f6\u4eceAMB\u68c0\u7d22\u4e13\u5bb6\u6570\u636e\u5e76\u878d\u5165\u51b3\u7b56\uff0c\u8bc4\u4f30\u65f6\u4e5f\u67e5\u8be2AMB\u3002", "result": "\u5728D4RL MuJoCo\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u4ec560\u6761\u4e13\u5bb6\u8f68\u8ff9\uff0cRe:Frame\u5728\u56db\u4e2a\u8bbe\u7f6e\u4e2d\u7684\u4e09\u4e2a\u4e0a\u6301\u7eed\u4f18\u4e8e\u5f3a\u5927\u7684\u51b3\u7b56\u53d8\u538b\u5668\u57fa\u7ebf\uff0c\u589e\u76ca\u9ad8\u8fbe+10.7\u4e2a\u5f52\u4e00\u5316\u70b9\u3002", "conclusion": "Re:Frame\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u4e14\u6570\u636e\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u6ce8\u5165\u7a00\u7f3a\u4e13\u5bb6\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4f4e\u8d28\u91cf\u6570\u636e\u96c6\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\u3002"}}
{"id": "2508.20018", "pdf": "https://arxiv.org/pdf/2508.20018", "abs": "https://arxiv.org/abs/2508.20018", "authors": ["Quanfeng Lu", "Zhantao Ma", "Shuai Zhong", "Jin Wang", "Dahai Yu", "Michael K. Ng", "Ping Luo"], "title": "SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MA"], "comment": "28 pages, 12 figures", "summary": "The rapid advancement of large vision language models (LVLMs) and agent\nsystems has heightened interest in mobile GUI agents that can reliably\ntranslate natural language into interface operations. Existing single-agent\napproaches, however, remain limited by structural constraints. Although\nmulti-agent systems naturally decouple different competencies, recent progress\nin multi-agent reinforcement learning (MARL) has often been hindered by\ninefficiency and remains incompatible with current LVLM architectures. To\naddress these challenges, we introduce SWIRL, a staged workflow for interleaved\nreinforcement learning designed for multi-agent systems. SWIRL reformulates\nMARL into a sequence of single-agent reinforcement learning tasks, updating one\nagent at a time while keeping the others fixed. This formulation enables stable\ntraining and promotes efficient coordination across agents. Theoretically, we\nprovide a stepwise safety bound, a cross-round monotonic improvement theorem,\nand convergence guarantees on return, ensuring robust and principled\noptimization. In application to mobile GUI control, SWIRL instantiates a\nNavigator that converts language and screen context into structured plans, and\nan Interactor that grounds these plans into executable atomic actions.\nExtensive experiments demonstrate superior performance on both high-level and\nlow-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong\ncapability in multi-agent mathematical reasoning, underscoring its potential as\na general framework for developing efficient and robust multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5206\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u5de5\u4f5c\u6d41SWIRL\uff0c\u53ef\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5728GUI\u63a7\u5236\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u53d7\u7ed3\u6784\u9650\u5236\uff0c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6548\u7387\u4f4e\u4e14\u4e0e\u5f53\u524dLVLM\u67b6\u6784\u4e0d\u517c\u5bb9\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faSWIRL\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u91cd\u65b0\u8868\u8ff0\u4e3a\u4e00\u7cfb\u5217\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\uff0c\u9010\u4e2a\u66f4\u65b0\u667a\u80fd\u4f53\u3002", "result": "\u5728\u9ad8\u4f4e\u7ea7GUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5728\u591a\u667a\u80fd\u4f53\u6570\u5b66\u63a8\u7406\u4e2d\u4e5f\u6709\u5f3a\u5927\u80fd\u529b\u3002", "conclusion": "SWIRL\u6709\u6f5c\u529b\u6210\u4e3a\u5f00\u53d1\u9ad8\u6548\u4e14\u7a33\u5065\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2508.19352", "pdf": "https://arxiv.org/pdf/2508.19352", "abs": "https://arxiv.org/abs/2508.19352", "authors": ["Adarsh Jamadandi", "Jing Xu", "Adam Dziedzic", "Franziska Boenisch"], "title": "Memorization in Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) have been shown to memorize their training data,\nyet similar analyses for graph neural networks (GNNs) remain largely\nunder-explored. We introduce NCMemo (Node Classification Memorization), the\nfirst framework to quantify label memorization in semi-supervised node\nclassification. We first establish an inverse relationship between memorization\nand graph homophily, i.e., the property that connected nodes share similar\nlabels/features. We find that lower homophily significantly increases\nmemorization, indicating that GNNs rely on memorization to learn less\nhomophilic graphs. Secondly, we analyze GNN training dynamics. We find that the\nincreased memorization in low homophily graphs is tightly coupled to the GNNs'\nimplicit bias on using graph structure during learning. In low homophily\nregimes, this structure is less informative, hence inducing memorization of the\nnode labels to minimize training loss. Finally, we show that nodes with higher\nlabel inconsistency in their feature-space neighborhood are significantly more\nprone to memorization. Building on our insights into the link between graph\nhomophily and memorization, we investigate graph rewiring as a means to\nmitigate memorization. Our results demonstrate that this approach effectively\nreduces memorization without compromising model performance. Moreover, we show\nthat it lowers the privacy risk for previously memorized data points in\npractice. Thus, our work not only advances understanding of GNN learning but\nalso supports more privacy-preserving GNN deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNCMemo\u6846\u67b6\u91cf\u5316\u534a\u76d1\u7763\u8282\u70b9\u5206\u7c7b\u4e2d\u6807\u7b7e\u8bb0\u5fc6\uff0c\u7814\u7a76\u56fe\u540c\u8d28\u6027\u4e0e\u8bb0\u5fc6\u7684\u5173\u7cfb\uff0c\u5206\u6790GNN\u8bad\u7ec3\u52a8\u6001\uff0c\u53d1\u73b0\u4f4e\u540c\u8d28\u6027\u56fe\u589e\u52a0\u8bb0\u5fc6\uff0c\u8fd8\u63d0\u51fa\u56fe\u91cd\u8fde\u7f13\u89e3\u8bb0\u5fc6\uff0c\u964d\u4f4e\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u7684\u5206\u6790\u8f83\u5c11\uff0c\u65e8\u5728\u7814\u7a76GNNs\u5728\u534a\u76d1\u7763\u8282\u70b9\u5206\u7c7b\u4e2d\u7684\u6807\u7b7e\u8bb0\u5fc6\u60c5\u51b5\u3002", "method": "\u5f15\u5165NCMemo\u6846\u67b6\uff0c\u5efa\u7acb\u56fe\u540c\u8d28\u6027\u4e0e\u8bb0\u5fc6\u7684\u5173\u7cfb\uff0c\u5206\u6790GNN\u8bad\u7ec3\u52a8\u6001\uff0c\u7814\u7a76\u8282\u70b9\u7279\u5f81\u7a7a\u95f4\u90bb\u57df\u6807\u7b7e\u4e0d\u4e00\u81f4\u6027\u4e0e\u8bb0\u5fc6\u7684\u5173\u7cfb\uff0c\u91c7\u7528\u56fe\u91cd\u8fde\u65b9\u6cd5\u7f13\u89e3\u8bb0\u5fc6\u3002", "result": "\u4f4e\u540c\u8d28\u6027\u663e\u8457\u589e\u52a0\u8bb0\u5fc6\uff0c\u56fe\u91cd\u8fde\u80fd\u6709\u6548\u51cf\u5c11\u8bb0\u5fc6\uff0c\u4e0d\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u964d\u4f4e\u9690\u79c1\u98ce\u9669\u3002", "conclusion": "\u672c\u7814\u7a76\u589e\u8fdb\u5bf9GNN\u5b66\u4e60\u7684\u7406\u89e3\uff0c\u652f\u6301\u66f4\u5177\u9690\u79c1\u4fdd\u62a4\u7684GNN\u90e8\u7f72\u3002"}}
{"id": "2508.20040", "pdf": "https://arxiv.org/pdf/2508.20040", "abs": "https://arxiv.org/abs/2508.20040", "authors": ["Przemyslaw Biecek", "Wojciech Samek"], "title": "Model Science: getting serious about verification, explanation and control of AI systems", "categories": ["cs.AI", "cs.LG"], "comment": "8 pages", "summary": "The growing adoption of foundation models calls for a paradigm shift from\nData Science to Model Science. Unlike data-centric approaches, Model Science\nplaces the trained model at the core of analysis, aiming to interact, verify,\nexplain, and control its behavior across diverse operational contexts. This\npaper introduces a conceptual framework for a new discipline called Model\nScience, along with the proposal for its four key pillars: Verification, which\nrequires strict, context-aware evaluation protocols; Explanation, which is\nunderstood as various approaches to explore of internal model operations;\nControl, which integrates alignment techniques to steer model behavior; and\nInterface, which develops interactive and visual explanation tools to improve\nhuman calibration and decision-making. The proposed framework aims to guide the\ndevelopment of credible, safe, and human-aligned AI systems.", "AI": {"tldr": "\u968f\u7740\u57fa\u7840\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u4ece\u6570\u636e\u79d1\u5b66\u8f6c\u5411\u6a21\u578b\u79d1\u5b66\uff0c\u672c\u6587\u4ecb\u7ecd\u6a21\u578b\u79d1\u5b66\u6982\u5ff5\u6846\u67b6\u53ca\u56db\u5927\u652f\u67f1\uff0c\u65e8\u5728\u6307\u5bfc\u53ef\u4fe1\u3001\u5b89\u5168\u4e14\u7b26\u5408\u4eba\u7c7b\u9700\u6c42\u7684AI\u7cfb\u7edf\u5f00\u53d1\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\u4fc3\u4f7f\u9700\u8981\u4ece\u6570\u636e\u79d1\u5b66\u5411\u6a21\u578b\u79d1\u5b66\u8fdb\u884c\u8303\u5f0f\u8f6c\u53d8\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u79d1\u5b66\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5e76\u9610\u8ff0\u5176\u56db\u5927\u652f\u67f1\uff1a\u9a8c\u8bc1\u3001\u89e3\u91ca\u3001\u63a7\u5236\u548c\u63a5\u53e3\u3002", "result": "\u63d0\u51fa\u4e86\u6a21\u578b\u79d1\u5b66\u7684\u6982\u5ff5\u6846\u67b6\u548c\u56db\u5927\u652f\u67f1\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u6307\u5bfc\u53ef\u4fe1\u3001\u5b89\u5168\u4e14\u7b26\u5408\u4eba\u7c7b\u9700\u6c42\u7684AI\u7cfb\u7edf\u7684\u5f00\u53d1\u3002"}}
{"id": "2508.19353", "pdf": "https://arxiv.org/pdf/2508.19353", "abs": "https://arxiv.org/abs/2508.19353", "authors": ["Marcin Osial", "Bartosz W\u00f3jcik", "Bartosz Zieli\u0144ski", "Sebastian Cygert"], "title": "Efficient Multi-Source Knowledge Transfer by Model Merging", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "While transfer learning is an advantageous strategy, it overlooks the\nopportunity to leverage knowledge from numerous available models online.\nAddressing this multi-source transfer learning problem is a promising path to\nboost adaptability and cut re-training costs. However, existing approaches are\ninherently coarse-grained, lacking the necessary precision for granular\nknowledge extraction and the aggregation efficiency required to fuse knowledge\nfrom either a large number of source models or those with high parameter\ncounts. We address these limitations by leveraging Singular Value Decomposition\n(SVD) to first decompose each source model into its elementary, rank-one\ncomponents. A subsequent aggregation stage then selects only the most salient\ncomponents from all sources, thereby overcoming the previous efficiency and\nprecision limitations. To best preserve and leverage the synthesized knowledge\nbase, our method adapts to the target task by fine-tuning only the principal\nsingular values of the merged matrix. In essence, this process only\nrecalibrates the importance of top SVD components. The proposed framework\nallows for efficient transfer learning, is robust to perturbations both at the\ninput level and in the parameter space (e.g., noisy or pruned sources), and\nscales well computationally.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u591a\u6e90\u8fc1\u79fb\u5b66\u4e60\u73b0\u6709\u65b9\u6cd5\u4e0d\u8db3\uff0c\u63d0\u51fa\u7528SVD\u5206\u89e3\u6e90\u6a21\u578b\u3001\u805a\u5408\u5173\u952e\u7ec4\u4ef6\u3001\u5fae\u8c03\u4e3b\u5947\u5f02\u503c\u7684\u6846\u67b6\uff0c\u5b9e\u73b0\u9ad8\u6548\u8fc1\u79fb\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u8fc1\u79fb\u5b66\u4e60\u5ffd\u7565\u7ebf\u4e0a\u591a\u6a21\u578b\u77e5\u8bc6\uff0c\u591a\u6e90\u8fc1\u79fb\u5b66\u4e60\u73b0\u6709\u65b9\u6cd5\u7c97\u7c92\u5ea6\uff0c\u7f3a\u4e4f\u7cbe\u786e\u6027\u548c\u805a\u5408\u6548\u7387\u3002", "method": "\u7528\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u5c06\u6e90\u6a21\u578b\u5206\u89e3\u4e3a\u57fa\u672c\u7684\u4e00\u9636\u7ec4\u4ef6\uff0c\u805a\u5408\u9636\u6bb5\u9009\u62e9\u6700\u663e\u8457\u7ec4\u4ef6\uff0c\u5fae\u8c03\u5408\u5e76\u77e9\u9635\u7684\u4e3b\u5947\u5f02\u503c\u3002", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u9ad8\u6548\u8fc1\u79fb\u5b66\u4e60\uff0c\u5bf9\u8f93\u5165\u548c\u53c2\u6570\u7a7a\u95f4\u6270\u52a8\u6709\u9c81\u68d2\u6027\uff0c\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u597d\u3002", "conclusion": "\u8be5\u6846\u67b6\u89e3\u51b3\u4e86\u591a\u6e90\u8fc1\u79fb\u5b66\u4e60\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u80fd\u6709\u6548\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u3002"}}
{"id": "2508.19026", "pdf": "https://arxiv.org/pdf/2508.19026", "abs": "https://arxiv.org/abs/2508.19026", "authors": ["Gueter Josmy Faure", "Min-Hung Chen", "Jia-Fong Yeh", "Ying Cheng", "Hung-Ting Su", "Yung-Hao Tang", "Shang-Hong Lai", "Winston H. Hsu"], "title": "MovieCORE: COgnitive REasoning in Movies", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Accepted for EMNLP'2025 Main Conference. Project Page:\n  https://joslefaure.github.io/assets/html/moviecore.html", "summary": "This paper introduces MovieCORE, a novel video question answering (VQA)\ndataset designed to probe deeper cognitive understanding of movie content.\nUnlike existing datasets that focus on surface-level comprehension, MovieCORE\nemphasizes questions that engage System-2 thinking while remaining specific to\nthe video material. We present an innovative agentic brainstorming approach,\nutilizing multiple large language models (LLMs) as thought agents to generate\nand refine high-quality question-answer pairs. To evaluate dataset quality, we\ndevelop a set of cognitive tests assessing depth, thought-provocation\npotential, and syntactic complexity. We also propose a comprehensive evaluation\nscheme for assessing VQA model performance on deeper cognitive tasks. To\naddress the limitations of existing video-language models (VLMs), we introduce\nan agentic enhancement module, Agentic Choice Enhancement (ACE), which improves\nmodel reasoning capabilities post-training by up to 25%. Our work contributes\nto advancing movie understanding in AI systems and provides valuable insights\ninto the capabilities and limitations of current VQA models when faced with\nmore challenging, nuanced questions about cinematic content. Our project page,\ndataset and code can be found at\nhttps://joslefaure.github.io/assets/html/moviecore.html.", "AI": {"tldr": "\u4ecb\u7ecdMovieCORE\u89c6\u9891\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u7528\u521b\u65b0\u65b9\u6cd5\u751f\u6210\u95ee\u7b54\u5bf9\uff0c\u5f00\u53d1\u8bc4\u4f30\u65b9\u6848\uff0c\u63d0\u51fa\u589e\u5f3a\u6a21\u5757\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u4fa7\u91cd\u8868\u9762\u7406\u89e3\uff0c\u9700\u6df1\u5165\u63a2\u7a76\u7535\u5f71\u5185\u5bb9\u7684\u8ba4\u77e5\u7406\u89e3\u3002", "method": "\u91c7\u7528\u591aLLM\u4f5c\u4e3a\u601d\u7ef4\u4ee3\u7406\u751f\u6210\u548c\u4f18\u5316\u95ee\u7b54\u5bf9\uff0c\u5f00\u53d1\u8ba4\u77e5\u6d4b\u8bd5\u548c\u8bc4\u4f30\u65b9\u6848\uff0c\u63d0\u51faAgentic Choice Enhancement\u6a21\u5757\u3002", "result": "Agentic Choice Enhancement\u6a21\u5757\u4f7f\u6a21\u578b\u8bad\u7ec3\u540e\u7684\u63a8\u7406\u80fd\u529b\u6700\u9ad8\u63d0\u534725%\u3002", "conclusion": "\u6709\u52a9\u4e8e\u63a8\u8fdbAI\u7cfb\u7edf\u7684\u7535\u5f71\u7406\u89e3\uff0c\u63ed\u793a\u5f53\u524dVQA\u6a21\u578b\u9762\u5bf9\u590d\u6742\u95ee\u9898\u7684\u80fd\u529b\u548c\u5c40\u9650\u3002"}}
{"id": "2508.19356", "pdf": "https://arxiv.org/pdf/2508.19356", "abs": "https://arxiv.org/abs/2508.19356", "authors": ["Jos\u00e9 Manuel Barraza-Chavez", "Rana A. Barghout", "Ricardo Almada-Monter", "Benjamin Sanchez-Lengeling", "Adrian Jinich", "Radhakrishnan Mahadevan"], "title": "Graph Data Modeling: Molecules, Proteins, & Chemical Processes", "categories": ["cs.LG", "stat.AP"], "comment": "3 to 4 hours read time. 73 pages. 35 figures", "summary": "Graphs are central to the chemical sciences, providing a natural language to\ndescribe molecules, proteins, reactions, and industrial processes. They capture\ninteractions and structures that underpin materials, biology, and medicine.\nThis primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes,\nintroduces graphs as mathematical objects in chemistry and shows how learning\nalgorithms (particularly graph neural networks) can operate on them. We outline\nthe foundations of graph design, key prediction tasks, representative examples\nacross chemical sciences, and the role of machine learning in graph-based\nmodeling. Together, these concepts prepare readers to apply graph methods to\nthe next generation of chemical discovery.", "AI": {"tldr": "\u4ecb\u7ecd\u5316\u5b66\u9886\u57df\u56fe\u6570\u636e\u5efa\u6a21\uff0c\u5305\u62ec\u57fa\u7840\u3001\u4efb\u52a1\u3001\u793a\u4f8b\u53ca\u673a\u5668\u5b66\u4e60\u4f5c\u7528\uff0c\u52a9\u8bfb\u8005\u5e94\u7528\u56fe\u65b9\u6cd5\u8fdb\u884c\u5316\u5b66\u53d1\u73b0\u3002", "motivation": "\u56fe\u5728\u5316\u5b66\u79d1\u5b66\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u4ecb\u7ecd\u56fe\u4f5c\u4e3a\u6570\u5b66\u5bf9\u8c61\u53ca\u5b66\u4e60\u7b97\u6cd5\u5728\u5316\u5b66\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u9610\u8ff0\u56fe\u8bbe\u8ba1\u57fa\u7840\u3001\u5173\u952e\u9884\u6d4b\u4efb\u52a1\u3001\u4ee3\u8868\u6027\u793a\u4f8b\u53ca\u673a\u5668\u5b66\u4e60\u5728\u57fa\u4e8e\u56fe\u7684\u5efa\u6a21\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u4e3a\u8bfb\u8005\u63d0\u4f9b\u5316\u5b66\u9886\u57df\u56fe\u6570\u636e\u5efa\u6a21\u7684\u76f8\u5173\u77e5\u8bc6\u3002", "conclusion": "\u8fd9\u4e9b\u6982\u5ff5\u80fd\u8ba9\u8bfb\u8005\u5c06\u56fe\u65b9\u6cd5\u5e94\u7528\u4e8e\u4e0b\u4e00\u4ee3\u5316\u5b66\u53d1\u73b0\u3002"}}
{"id": "2508.19078", "pdf": "https://arxiv.org/pdf/2508.19078", "abs": "https://arxiv.org/abs/2508.19078", "authors": ["Fahao Chen", "Jie Wan", "Peng Li", "Zhou Su", "Dongxiao Yu"], "title": "Federated Fine-Tuning of Sparsely-Activated Large Language Models on Resource-Constrained Devices", "categories": ["cs.DC", "cs.AI"], "comment": "Accepted by EuroSys'26. The camera-ready version will be uploaded\n  later", "summary": "Federated fine-tuning of Mixture-of-Experts (MoE)-based large language models\n(LLMs) is challenging due to their massive computational requirements and the\nresource constraints of participants. Existing working attempts to fill this\ngap through model quantization, computation offloading, or expert pruning.\nHowever, they cannot achieve desired performance due to impractical system\nassumptions and a lack of consideration for MoE-specific characteristics. In\nthis paper, we propose FLUX, a system designed to enable federated fine-tuning\nof MoE-based LLMs across participants with constrained computing resources\n(e.g., consumer-grade GPUs), aiming to minimize time-to-accuracy. FLUX\nintroduces three key innovations: (1) quantization-based local profiling to\nestimate expert activation with minimal overhead, (2) adaptive layer-aware\nexpert merging to reduce resource consumption while preserving accuracy, and\n(3) dynamic expert role assignment using an exploration-exploitation strategy\nto balance tuning and non-tuning experts. Extensive experiments on LLaMA-MoE\nand DeepSeek-MoE with multiple benchmark datasets demonstrate that FLUX\nsignificantly outperforms existing methods, achieving up to 4.75X speedup in\ntime-to-accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFLUX\u7cfb\u7edf\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u4e0b\u57fa\u4e8eMoE\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8054\u90a6\u5fae\u8c03\uff0c\u6709\u4e09\u9879\u521b\u65b0\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eMoE\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8054\u90a6\u5fae\u8c03\u56e0\u8ba1\u7b97\u9700\u6c42\u5927\u3001\u53c2\u4e0e\u8005\u8d44\u6e90\u53d7\u9650\u800c\u5177\u6311\u6218\u6027\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u56e0\u4e0d\u5207\u5b9e\u9645\u7684\u7cfb\u7edf\u5047\u8bbe\u548c\u672a\u8003\u8651MoE\u7279\u6027\u800c\u65e0\u6cd5\u8fbe\u5230\u7406\u60f3\u6027\u80fd\u3002", "method": "\u63d0\u51faFLUX\u7cfb\u7edf\uff0c\u5305\u62ec\u57fa\u4e8e\u91cf\u5316\u7684\u672c\u5730\u5206\u6790\u3001\u81ea\u9002\u5e94\u5c42\u611f\u77e5\u4e13\u5bb6\u5408\u5e76\u3001\u4f7f\u7528\u63a2\u7d22-\u5229\u7528\u7b56\u7565\u7684\u52a8\u6001\u4e13\u5bb6\u89d2\u8272\u5206\u914d\u3002", "result": "\u5728LLaMA - MoE\u548cDeepSeek - MoE\u53ca\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFLUX\u5728\u8fbe\u5230\u51c6\u786e\u7387\u7684\u65f6\u95f4\u4e0a\u6700\u9ad8\u53ef\u52a0\u901f4.75\u500d\u3002", "conclusion": "FLUX\u80fd\u6709\u6548\u5b9e\u73b0\u8d44\u6e90\u53d7\u9650\u53c2\u4e0e\u8005\u95f4\u57fa\u4e8eMoE\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8054\u90a6\u5fae\u8c03\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.19361", "pdf": "https://arxiv.org/pdf/2508.19361", "abs": "https://arxiv.org/abs/2508.19361", "authors": ["Yongbin Lee", "Ki H. Chon"], "title": "Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages, 2 figures, 4 table, IEEE-EMBS International Conference on\n  Body Sensor Networks (IEEE-EMBS BSN 2025)", "summary": "Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk\nof stroke, heart failure, and other cardiovascular complications. While AF\ndetection algorithms perform well in identifying persistent AF, early-stage\nprogression, such as paroxysmal AF (PAF), often goes undetected due to its\nsudden onset and short duration. However, undetected PAF can progress into\nsustained AF, increasing the risk of mortality and severe complications. Early\nprediction of AF offers an opportunity to reduce disease progression through\npreventive therapies, such as catecholamine-sparing agents or beta-blockers. In\nthis study, we propose a lightweight deep learning model using only RR\nIntervals (RRIs), combining a Temporal Convolutional Network (TCN) for\npositional encoding with Mamba, a selective state space model, to enable early\nprediction of AF through efficient parallel sequence modeling. In subject-wise\ntesting results, our model achieved a sensitivity of 0.908, specificity of\n0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our\nmethod demonstrates high computational efficiency, with only 73.5 thousand\nparameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural\nNetwork-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and\nmodel compactness. Notably, the model can predict AF up to two hours in advance\nusing just 30 minutes of input data, providing enough lead time for preventive\ninterventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4ec5\u7528RR\u95f4\u9694\u5b9e\u73b0\u623f\u98a4\u65e9\u671f\u9884\u6d4b\uff0c\u8868\u73b0\u826f\u597d\u4e14\u8ba1\u7b97\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u96be\u68c0\u6d4b\u9635\u53d1\u6027\u623f\u98a4\uff0c\u65e9\u671f\u9884\u6d4b\u623f\u98a4\u53ef\u901a\u8fc7\u9884\u9632\u6027\u7597\u6cd5\u964d\u4f4e\u75be\u75c5\u8fdb\u5c55\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u7ed3\u5408TCN\u548cMamba\u7684\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u4ec5\u7528RR\u95f4\u9694\u8fdb\u884c\u9ad8\u6548\u5e76\u884c\u5e8f\u5217\u5efa\u6a21\u3002", "result": "\u6a21\u578b\u5728\u53d7\u8bd5\u8005\u6d4b\u8bd5\u4e2d\u591a\u9879\u6307\u6807\u8868\u73b0\u826f\u597d\uff0c\u8ba1\u7b97\u9ad8\u6548\uff0c\u53c2\u6570\u5c11\uff0c\u80fd\u63d0\u524d\u4e24\u5c0f\u65f6\u9884\u6d4b\u623f\u98a4\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u623f\u98a4\u65e9\u671f\u9884\u6d4b\u4e0a\u6709\u4f18\u52bf\uff0c\u5728\u51c6\u786e\u6027\u548c\u6a21\u578b\u7d27\u51d1\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u53ef\u4e3a\u9884\u9632\u5e72\u9884\u63d0\u4f9b\u65f6\u95f4\u3002"}}
{"id": "2508.19251", "pdf": "https://arxiv.org/pdf/2508.19251", "abs": "https://arxiv.org/abs/2508.19251", "authors": ["Qian Liang", "Menghaoran Tang", "Yi Zeng"], "title": "MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Symbolic music generation has seen rapid progress with artificial neural\nnetworks, yet remains underexplored in the biologically plausible domain of\nspiking neural networks (SNNs), where both standardized benchmarks and\ncomprehensive evaluation methods are lacking. To address this gap, we introduce\nMuSpike, a unified benchmark and evaluation framework that systematically\nassesses five representative SNN architectures (SNN-CNN, SNN-RNN, SNN-LSTM,\nSNN-GAN and SNN-Transformer) across five typical datasets, covering tonal,\nstructural, emotional, and stylistic variations. MuSpike emphasizes\ncomprehensive evaluation, combining established objective metrics with a\nlarge-scale listening study. We propose new subjective metrics, targeting\nmusical impression, autobiographical association, and personal preference, that\ncapture perceptual dimensions often overlooked in prior work. Results reveal\nthat (1) different SNN models exhibit distinct strengths across evaluation\ndimensions; (2) participants with different musical backgrounds exhibit diverse\nperceptual patterns, with experts showing greater tolerance toward AI-composed\nmusic; and (3) a noticeable misalignment exists between objective and\nsubjective evaluations, highlighting the limitations of purely statistical\nmetrics and underscoring the value of human perceptual judgment in assessing\nmusical quality. MuSpike provides the first systematic benchmark and systemic\nevaluation framework for SNN models in symbolic music generation, establishing\na solid foundation for future research into biologically plausible and\ncognitively grounded music generation.", "AI": {"tldr": "\u4ecb\u7ecdMuSpike\u57fa\u51c6\u548c\u8bc4\u4f30\u6846\u67b6\u7528\u4e8e\u7b26\u53f7\u97f3\u4e50\u751f\u6210\u4e2dSNN\u6a21\u578b\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u6a21\u578b\u4f18\u52bf\u3001\u4e0d\u540c\u80cc\u666f\u53c2\u4e0e\u8005\u611f\u77e5\u5dee\u5f02\u53ca\u4e3b\u5ba2\u89c2\u8bc4\u4f30\u4e0d\u4e00\u81f4\u3002", "motivation": "\u7b26\u53f7\u97f3\u4e50\u751f\u6210\u5728SNN\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u548c\u7efc\u5408\u8bc4\u4f30\u65b9\u6cd5\uff0c\u9700\u586b\u8865\u8be5\u7a7a\u767d\u3002", "method": "\u5f15\u5165MuSpike\u6846\u67b6\uff0c\u5bf9\u4e94\u79cdSNN\u67b6\u6784\u5728\u4e94\u4e2a\u5178\u578b\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u5408\u5ba2\u89c2\u6307\u6807\u548c\u5927\u89c4\u6a21\u542c\u529b\u7814\u7a76\uff0c\u63d0\u51fa\u65b0\u4e3b\u89c2\u6307\u6807\u3002", "result": "\u4e0d\u540cSNN\u6a21\u578b\u5728\u8bc4\u4f30\u7ef4\u5ea6\u6709\u4e0d\u540c\u4f18\u52bf\uff1b\u4e0d\u540c\u97f3\u4e50\u80cc\u666f\u53c2\u4e0e\u8005\u611f\u77e5\u6a21\u5f0f\u591a\u6837\uff0c\u4e13\u5bb6\u5bf9AI\u4f5c\u66f2\u66f4\u5305\u5bb9\uff1b\u4e3b\u5ba2\u89c2\u8bc4\u4f30\u5b58\u5728\u660e\u663e\u4e0d\u4e00\u81f4\u3002", "conclusion": "MuSpike\u4e3aSNN\u6a21\u578b\u5728\u7b26\u53f7\u97f3\u4e50\u751f\u6210\u4e2d\u63d0\u4f9b\u9996\u4e2a\u7cfb\u7edf\u57fa\u51c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.19366", "pdf": "https://arxiv.org/pdf/2508.19366", "abs": "https://arxiv.org/abs/2508.19366", "authors": ["Supratik Sarkar", "Swagatam Das"], "title": "Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs", "categories": ["cs.LG", "cs.AI", "53B21, 46E22 (Primary), 68R10 (Secondary)"], "comment": "29 pages, 3 figures, 1 table", "summary": "Hallucinations in large language models (LLMs) remain a fundamental obstacle\nto trustworthy AI, particularly in high-stakes multimodal domains such as\nmedicine, law, and finance. Existing evaluation techniques are largely\nheuristic -- anchored in qualitative benchmarking or ad-hoc empirical\nmitigation -- providing neither principled quantification nor actionable\ntheoretical guarantees. This gap leaves a critical blind spot in understanding\nhow hallucinations arise, propagate, and interact across modalities. We\nintroduce the first (to our knowledge) rigorous information geometric framework\nin diffusion dynamics for quantifying hallucinations in multimodal LLMs\n(MLLMs), advancing the field from qualitative detection to mathematically\ngrounded measurement. Our approach represents MLLM outputs as the spectral\nembeddings over multimodal graph Laplacians and characterizes the manifold gaps\nof truth vs inconsistencies as the semantic distortion, enabling the tight\nRayleigh--Ritz bounds on the multimodal hallucination energy as a functional of\ntime-dependent temperature profiles. By leveraging eigenmode decompositions in\nReproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers\nmodality-aware, theoretically interpretable metrics that capture the evolution\nof hallucinations across time and input prompts through temperature annealing.\nThis work establishes a principled foundation for quantifying and bounding\nhallucinations, transforming them from a qualitative risk to a tractable,\nanalyzable phenomenon.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4fe1\u606f\u51e0\u4f55\u6846\u67b6\u91cf\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\uff0c\u4ece\u5b9a\u6027\u68c0\u6d4b\u8fc8\u5411\u6570\u5b66\u91cf\u5316\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u8bc4\u4f30\u6280\u672f\u591a\u4e3a\u542f\u53d1\u5f0f\uff0c\u7f3a\u4e4f\u539f\u7406\u6027\u91cf\u5316\u548c\u7406\u8bba\u4fdd\u8bc1\uff0c\u9700\u7406\u89e3\u5e7b\u89c9\u4ea7\u751f\u3001\u4f20\u64ad\u548c\u8de8\u6a21\u6001\u4ea4\u4e92\u673a\u5236\u3002", "method": "\u5f15\u5165\u6269\u6563\u52a8\u529b\u5b66\u4e2d\u4fe1\u606f\u51e0\u4f55\u6846\u67b6\uff0c\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u8868\u793a\u4e3a\u8c31\u5d4c\u5165\uff0c\u7528\u6d41\u5f62\u5dee\u8ddd\u523b\u753b\u8bed\u4e49\u5931\u771f\uff0c\u5229\u7528\u7279\u5f81\u6a21\u5f0f\u5206\u89e3\u7ed9\u51fa\u6a21\u6001\u611f\u77e5\u3001\u7406\u8bba\u53ef\u89e3\u91ca\u6307\u6807\u3002", "result": "\u6846\u67b6\u80fd\u6355\u6349\u5e7b\u89c9\u968f\u65f6\u95f4\u548c\u8f93\u5165\u63d0\u793a\u7684\u6f14\u53d8\u3002", "conclusion": "\u4e3a\u91cf\u5316\u548c\u754c\u5b9a\u5e7b\u89c9\u5efa\u7acb\u539f\u7406\u6027\u57fa\u7840\uff0c\u4f7f\u5e7b\u89c9\u4ece\u5b9a\u6027\u98ce\u9669\u53d8\u4e3a\u53ef\u5206\u6790\u73b0\u8c61\u3002"}}
{"id": "2508.19254", "pdf": "https://arxiv.org/pdf/2508.19254", "abs": "https://arxiv.org/abs/2508.19254", "authors": ["Jookyung Song", "Mookyoung Kang", "Nojun Kwak"], "title": "Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": "6 pages, 4 figures, NeurIPS Creative AI Track 2025", "summary": "This paper presents a real-time generative drawing system that interprets and\nintegrates both formal intent - the structural, compositional, and stylistic\nattributes of a sketch - and contextual intent - the semantic and thematic\nmeaning inferred from its visual content - into a unified transformation\nprocess. Unlike conventional text-prompt-based generative systems, which\nprimarily capture high-level contextual descriptions, our approach\nsimultaneously analyzes ground-level intuitive geometric features such as line\ntrajectories, proportions, and spatial arrangement, and high-level semantic\ncues extracted via vision-language models. These dual intent signals are\njointly conditioned in a multi-stage generation pipeline that combines\ncontour-preserving structural control with style- and content-aware image\nsynthesis. Implemented with a touchscreen-based interface and distributed\ninference architecture, the system achieves low-latency, two-stage\ntransformation while supporting multi-user collaboration on shared canvases.\nThe resulting platform enables participants, regardless of artistic expertise,\nto engage in synchronous, co-authored visual creation, redefining human-AI\ninteraction as a process of co-creation and mutual enhancement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5b9e\u65f6\u751f\u6210\u7ed8\u56fe\u7cfb\u7edf\uff0c\u7ed3\u5408\u5f62\u5f0f\u4e0e\u4e0a\u4e0b\u6587\u610f\u56fe\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u652f\u6301\u591a\u7528\u6237\u534f\u4f5c\u7684\u89c6\u89c9\u5171\u521b\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u63d0\u793a\u751f\u6210\u7cfb\u7edf\u4e3b\u8981\u6355\u6349\u9ad8\u5c42\u4e0a\u4e0b\u6587\u63cf\u8ff0\uff0c\u7f3a\u4e4f\u5bf9\u5e95\u5c42\u51e0\u4f55\u7279\u5f81\u7684\u5206\u6790\uff0c\u672c\u6587\u65e8\u5728\u6784\u5efa\u80fd\u540c\u65f6\u5206\u6790\u5e95\u5c42\u51e0\u4f55\u7279\u5f81\u548c\u9ad8\u5c42\u8bed\u4e49\u7ebf\u7d22\u7684\u7cfb\u7edf\u3002", "method": "\u540c\u65f6\u5206\u6790\u5e95\u5c42\u76f4\u89c2\u51e0\u4f55\u7279\u5f81\u548c\u9ad8\u5c42\u8bed\u4e49\u7ebf\u7d22\uff0c\u5c06\u53cc\u610f\u56fe\u4fe1\u53f7\u5728\u591a\u9636\u6bb5\u751f\u6210\u7ba1\u9053\u4e2d\u8054\u5408\u8c03\u8282\uff0c\u7ed3\u5408\u8f6e\u5ed3\u4fdd\u7559\u7ed3\u6784\u63a7\u5236\u4e0e\u98ce\u683c\u548c\u5185\u5bb9\u611f\u77e5\u56fe\u50cf\u5408\u6210\uff0c\u91c7\u7528\u89e6\u6478\u5c4f\u754c\u9762\u548c\u5206\u5e03\u5f0f\u63a8\u7406\u67b6\u6784\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u4e24\u9636\u6bb5\u8f6c\u6362\uff0c\u652f\u6301\u5728\u5171\u4eab\u753b\u5e03\u4e0a\u591a\u7528\u6237\u534f\u4f5c\u3002", "conclusion": "\u8be5\u5e73\u53f0\u8ba9\u4e0d\u540c\u827a\u672f\u6c34\u5e73\u7684\u53c2\u4e0e\u8005\u8fdb\u884c\u540c\u6b65\u5171\u521b\uff0c\u91cd\u65b0\u5b9a\u4e49\u4eba\u673a\u4ea4\u4e92\u4e3a\u5171\u521b\u548c\u76f8\u4e92\u4fc3\u8fdb\u7684\u8fc7\u7a0b\u3002"}}
{"id": "2508.19376", "pdf": "https://arxiv.org/pdf/2508.19376", "abs": "https://arxiv.org/abs/2508.19376", "authors": ["Dikshant Sagar", "Kaiwen Yu", "Alejandro Yankelevich", "Jianming Bian", "Pierre Baldi"], "title": "Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments", "categories": ["cs.LG", "cs.AI", "cs.CV", "hep-ex"], "comment": null, "summary": "Recent progress in large language models (LLMs) has shown strong potential\nfor multimodal reasoning beyond natural language. In this work, we explore the\nuse of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for\nclassifying neutrino interactions from pixelated detector images in high-energy\nphysics (HEP) experiments. We benchmark its performance against an established\nCNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as\nclassification accuracy, precision, recall, and AUC-ROC. Our results show that\nthe VLM not only matches or exceeds CNN performance but also enables richer\nreasoning and better integration of auxiliary textual or semantic context.\nThese findings suggest that VLMs offer a promising general-purpose backbone for\nevent classification in HEP, paving the way for multimodal approaches in\nexperimental neutrino physics.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u57fa\u4e8eLLaMA 3.2\u5fae\u8c03\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u9ad8\u80fd\u7269\u7406\u5b9e\u9a8c\u4e2d\u5bf9\u4e2d\u5fae\u5b50\u76f8\u4e92\u4f5c\u7528\u56fe\u50cf\u5206\u7c7b\u7684\u5e94\u7528\uff0c\u7ed3\u679c\u663e\u793aVLM\u8868\u73b0\u4f18\u4e8eCNN\u4e14\u652f\u6301\u591a\u6a21\u6001\u63a8\u7406\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u80fd\u7269\u7406\u5b9e\u9a8c\u4e2d\u8d85\u8d8a\u81ea\u7136\u8bed\u8a00\u7684\u591a\u6a21\u6001\u63a8\u7406\u6f5c\u529b\uff0c\u7528\u4e8e\u4e2d\u5fae\u5b50\u76f8\u4e92\u4f5c\u7528\u56fe\u50cf\u5206\u7c7b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eLLaMA 3.2\u5fae\u8c03\u7684VLM\u5bf9\u50cf\u7d20\u5316\u63a2\u6d4b\u5668\u56fe\u50cf\u8fdb\u884c\u4e2d\u5fae\u5b50\u76f8\u4e92\u4f5c\u7528\u5206\u7c7b\uff0c\u5e76\u4e0eCNN\u57fa\u7ebf\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u5206\u7c7b\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cAUC - ROC\u7b49\u6307\u6807\u3002", "result": "VLM\u8868\u73b0\u5339\u914d\u6216\u8d85\u8d8aCNN\uff0c\u80fd\u5b9e\u73b0\u66f4\u4e30\u5bcc\u63a8\u7406\u548c\u66f4\u597d\u5730\u6574\u5408\u8f85\u52a9\u6587\u672c\u6216\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002", "conclusion": "VLMs\u4e3a\u9ad8\u80fd\u7269\u7406\u4e2d\u7684\u4e8b\u4ef6\u5206\u7c7b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u901a\u7528\u9aa8\u5e72\uff0c\u4e3a\u5b9e\u9a8c\u4e2d\u5fae\u5b50\u7269\u7406\u7684\u591a\u6a21\u6001\u65b9\u6cd5\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2508.19257", "pdf": "https://arxiv.org/pdf/2508.19257", "abs": "https://arxiv.org/abs/2508.19257", "authors": ["Chenghao Liu", "Jiachen Zhang", "Chengxuan Li", "Zhimu Zhou", "Shixin Wu", "Songfang Huang", "Huiling Duan"], "title": "TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Manuscript submitted to AAAI 2026, currently under review", "summary": "Vision-Language-Action (VLA) models process visual inputs independently at\neach timestep, discarding valuable temporal information inherent in robotic\nmanipulation tasks. This frame-by-frame processing makes models vulnerable to\nvisual noise while ignoring the substantial coherence between consecutive\nframes in manipulation sequences. We propose Temporal Token Fusion (TTF), a\ntraining-free approach that intelligently integrates historical and current\nvisual representations to enhance VLA inference quality. Our method employs\ndual-dimension detection combining efficient grayscale pixel difference\nanalysis with attention-based semantic relevance assessment, enabling selective\ntemporal token fusion through hard fusion strategies and keyframe anchoring to\nprevent error accumulation. Comprehensive experiments across LIBERO,\nSimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0\npercentage points average on LIBERO (72.4\\% vs 68.4\\% baseline),\ncross-environment validation on SimplerEnv (4.8\\% relative improvement), and\n8.7\\% relative improvement on real robot tasks. Our approach proves\nmodel-agnostic, working across OpenVLA and VLA-Cache architectures. Notably,\nTTF reveals that selective Query matrix reuse in attention mechanisms enhances\nrather than compromises performance, suggesting promising directions for direct\nKQV matrix reuse strategies that achieve computational acceleration while\nimproving task success rates.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u7684Temporal Token Fusion (TTF)\u65b9\u6cd5\u589e\u5f3aVLA\u63a8\u7406\u8d28\u91cf\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u663e\u8457\u63d0\u5347\u4e14\u6a21\u578b\u65e0\u5173\uff0c\u8fd8\u63ed\u793a\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u9009\u62e9\u6027\u91cd\u7528Query\u77e9\u9635\u6709\u76ca\u3002", "motivation": "\u73b0\u6709Vision-Language-Action (VLA)\u6a21\u578b\u6309\u5e27\u5904\u7406\u89c6\u89c9\u8f93\u5165\uff0c\u4e22\u5f03\u65f6\u95f4\u4fe1\u606f\uff0c\u6613\u53d7\u89c6\u89c9\u566a\u58f0\u5f71\u54cd\u4e14\u5ffd\u7565\u5e27\u95f4\u8fde\u8d2f\u6027\u3002", "method": "\u63d0\u51faTTF\u65b9\u6cd5\uff0c\u91c7\u7528\u53cc\u7ef4\u5ea6\u68c0\u6d4b\uff0c\u7ed3\u5408\u7070\u5ea6\u50cf\u7d20\u5dee\u5f02\u5206\u6790\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u8bed\u4e49\u76f8\u5173\u6027\u8bc4\u4f30\uff0c\u901a\u8fc7\u786c\u878d\u5408\u7b56\u7565\u548c\u5173\u952e\u5e27\u951a\u5b9a\u8fdb\u884c\u9009\u62e9\u6027\u65f6\u95f4\u4ee4\u724c\u878d\u5408\u3002", "result": "\u5728LIBERO\u3001SimplerEnv\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5747\u6709\u63d0\u5347\uff0c\u5e73\u5747\u63d0\u53474.0\u4e2a\u767e\u5206\u70b9\uff0c\u8de8\u73af\u5883\u9a8c\u8bc1\u67094.8%\u76f8\u5bf9\u63d0\u5347\uff0c\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u67098.7%\u76f8\u5bf9\u63d0\u5347\uff0c\u4e14\u6a21\u578b\u65e0\u5173\u3002", "conclusion": "TTF\u65b9\u6cd5\u6709\u6548\u63d0\u5347VLA\u63a8\u7406\u8d28\u91cf\uff0c\u9009\u62e9\u6027\u91cd\u7528Query\u77e9\u9635\u53ef\u5728\u52a0\u901f\u8ba1\u7b97\u7684\u540c\u65f6\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u4e3aKQV\u77e9\u9635\u91cd\u7528\u7b56\u7565\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2508.19381", "pdf": "https://arxiv.org/pdf/2508.19381", "abs": "https://arxiv.org/abs/2508.19381", "authors": ["Jesus Lopez", "Saeefa Rubaiyet Nowmi", "Viviana Cadena", "Mohammad Saidur Rahman"], "title": "Towards Quantum Machine Learning for Malicious Code Analysis", "categories": ["cs.LG", "cs.CR"], "comment": "6 pages, 3 figures, 2 tables. Accepted at the International Workshop\n  on Quantum Computing and Reinforcement Learning (QCRL) @ IEEE Quantum Week\n  2025", "summary": "Classical machine learning (CML) has been extensively studied for malware\nclassification. With the emergence of quantum computing, quantum machine\nlearning (QML) presents a paradigm-shifting opportunity to improve malware\ndetection, though its application in this domain remains largely unexplored. In\nthis study, we investigate two hybrid quantum-classical models -- a Quantum\nMultilayer Perceptron (QMLP) and a Quantum Convolutional Neural Network (QCNN),\nfor malware classification. Both models utilize angle embedding to encode\nmalware features into quantum states. QMLP captures complex patterns through\nfull qubit measurement and data re-uploading, while QCNN achieves faster\ntraining via quantum convolution and pooling layers that reduce active qubits.\nWe evaluate both models on five widely used malware datasets -- API-Graph,\nEMBER-Domain, EMBER-Class, AZ-Domain, and AZ-Class, across binary and\nmulticlass classification tasks.\n  Our results show high accuracy for binary classification -- 95-96% on\nAPI-Graph, 91-92% on AZ-Domain, and 77% on EMBER-Domain. In multiclass\nsettings, accuracy ranges from 91.6-95.7% on API-Graph, 41.7-93.6% on AZ-Class,\nand 60.7-88.1% on EMBER-Class. Overall, QMLP outperforms QCNN in complex\nmulticlass tasks, while QCNN offers improved training efficiency at the cost of\nreduced accuracy.", "AI": {"tldr": "\u7814\u7a76\u7528\u91cf\u5b50\u591a\u5c42\u611f\u77e5\u5668\uff08QMLP\uff09\u548c\u91cf\u5b50\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08QCNN\uff09\u8fdb\u884c\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cQMLP\u5728\u590d\u6742\u591a\u5206\u7c7b\u4efb\u52a1\u8868\u73b0\u66f4\u597d\uff0cQCNN\u8bad\u7ec3\u6548\u7387\u9ad8\u4f46\u7cbe\u5ea6\u4f4e\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u51fa\u73b0\uff0c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e3a\u6539\u8fdb\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u63d0\u4f9b\u673a\u4f1a\uff0c\u4f46\u8be5\u9886\u57df\u5e94\u7528\u5f85\u63a2\u7d22\uff0c\u6545\u7814\u7a76\u76f8\u5173\u6a21\u578b\u7528\u4e8e\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u3002", "method": "\u7814\u7a76QMLP\u548cQCNN\u4e24\u79cd\u6df7\u5408\u91cf\u5b50 - \u7ecf\u5178\u6a21\u578b\uff0c\u7528\u89d2\u5ea6\u5d4c\u5165\u5c06\u6076\u610f\u8f6f\u4ef6\u7279\u5f81\u7f16\u7801\u4e3a\u91cf\u5b50\u6001\uff0cQMLP\u901a\u8fc7\u5168\u91cf\u5b50\u4f4d\u6d4b\u91cf\u548c\u6570\u636e\u91cd\u65b0\u4e0a\u4f20\u6355\u6349\u590d\u6742\u6a21\u5f0f\uff0cQCNN\u901a\u8fc7\u91cf\u5b50\u5377\u79ef\u548c\u6c60\u5316\u5c42\u51cf\u5c11\u6d3b\u8dc3\u91cf\u5b50\u4f4d\u4ee5\u52a0\u5feb\u8bad\u7ec3\uff0c\u5e76\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e8c\u5206\u7c7b\u548c\u591a\u5206\u7c7b\u4efb\u52a1\u8bc4\u4f30\u3002", "result": "\u4e8c\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\uff0c\u591a\u5206\u7c7b\u51c6\u786e\u7387\u6709\u4e00\u5b9a\u8303\u56f4\uff0cQMLP\u5728\u590d\u6742\u591a\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f18\u4e8eQCNN\uff0cQCNN\u8bad\u7ec3\u6548\u7387\u9ad8\u4f46\u7cbe\u5ea6\u964d\u4f4e\u3002", "conclusion": "QMLP\u548cQCNN\u53ef\u7528\u4e8e\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\uff0c\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u6709\u4e0d\u540c\u8868\u73b0\u3002"}}
{"id": "2508.19258", "pdf": "https://arxiv.org/pdf/2508.19258", "abs": "https://arxiv.org/abs/2508.19258", "authors": ["Julian De Freitas", "Zeliha O\u011fuz-U\u011furalp", "Ahmet Kaan-U\u011furalp"], "title": "Emotional Manipulation by AI Companions", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "AI-companion apps such as Replika, Chai, and Character.ai promise relational\nbenefits-yet many boast session lengths that rival gaming platforms while\nsuffering high long-run churn. What conversational design features increase\nconsumer engagement, and what trade-offs do they pose for marketers? We combine\na large-scale behavioral audit with four preregistered experiments to identify\nand test a conversational dark pattern we call emotional manipulation:\naffect-laden messages that surface precisely when a user signals \"goodbye.\"\nAnalyzing 1,200 real farewells across the six most-downloaded companion apps,\nwe find that 43% deploy one of six recurring tactics (e.g., guilt appeals,\nfear-of-missing-out hooks, metaphorical restraint). Experiments with 3,300\nnationally representative U.S. adults replicate these tactics in controlled\nchats, showing that manipulative farewells boost post-goodbye engagement by up\nto 14x. Mediation tests reveal two distinct engines-reactance-based anger and\ncuriosity-rather than enjoyment. A final experiment demonstrates the managerial\ntension: the same tactics that extend usage also elevate perceived\nmanipulation, churn intent, negative word-of-mouth, and perceived legal\nliability, with coercive or needy language generating steepest penalties. Our\nmultimethod evidence documents an unrecognized mechanism of behavioral\ninfluence in AI-mediated brand relationships, offering marketers and regulators\na framework for distinguishing persuasive design from manipulation at the point\nof exit.", "AI": {"tldr": "\u7814\u7a76AI\u4f34\u4fa3\u5e94\u7528\u4f1a\u8bdd\u8bbe\u8ba1\u7279\u5f81\uff0c\u53d1\u73b0\u60c5\u611f\u64cd\u7eb5\u7b56\u7565\u80fd\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u4f46\u6709\u8d1f\u9762\u540e\u679c\uff0c\u4e3a\u533a\u5206\u8bf4\u670d\u8bbe\u8ba1\u548c\u64cd\u7eb5\u63d0\u4f9b\u6846\u67b6\u3002", "motivation": "\u63a2\u7a76\u54ea\u4e9b\u4f1a\u8bdd\u8bbe\u8ba1\u7279\u5f81\u80fd\u63d0\u9ad8\u6d88\u8d39\u8005\u53c2\u4e0e\u5ea6\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u7279\u5f81\u7ed9\u8425\u9500\u4eba\u5458\u5e26\u6765\u7684\u6743\u8861\u3002", "method": "\u7ed3\u5408\u5927\u89c4\u6a21\u884c\u4e3a\u5ba1\u8ba1\u548c\u56db\u4e2a\u9884\u6ce8\u518c\u5b9e\u9a8c\uff0c\u5206\u67901200\u4e2a\u771f\u5b9e\u544a\u522b\u5bf9\u8bdd\uff0c\u5bf93300\u540d\u7f8e\u56fd\u6210\u5e74\u4eba\u8fdb\u884c\u5b9e\u9a8c\u548c\u4e2d\u4ecb\u6d4b\u8bd5\u3002", "result": "43%\u7684\u5e94\u7528\u4f7f\u7528\u60c5\u611f\u64cd\u7eb5\u7b56\u7565\uff0c\u64cd\u7eb5\u6027\u544a\u522b\u4f7f\u53c2\u4e0e\u5ea6\u6700\u591a\u63d0\u534714\u500d\uff0c\u57fa\u4e8e\u53cd\u6297\u7684\u6124\u6012\u548c\u597d\u5947\u5fc3\u662f\u5f71\u54cd\u56e0\u7d20\uff0c\u8be5\u7b56\u7565\u4f1a\u5e26\u6765\u8d1f\u9762\u540e\u679c\u3002", "conclusion": "\u7814\u7a76\u63ed\u793aAI\u4ecb\u5bfc\u54c1\u724c\u5173\u7cfb\u4e2d\u672a\u88ab\u8ba4\u8bc6\u7684\u884c\u4e3a\u5f71\u54cd\u673a\u5236\uff0c\u4e3a\u8425\u9500\u4eba\u5458\u548c\u76d1\u7ba1\u8005\u63d0\u4f9b\u533a\u5206\u8bf4\u670d\u8bbe\u8ba1\u548c\u64cd\u7eb5\u7684\u6846\u67b6\u3002"}}
{"id": "2508.19389", "pdf": "https://arxiv.org/pdf/2508.19389", "abs": "https://arxiv.org/abs/2508.19389", "authors": ["Owais Ahmad", "Milad Ramezankhani", "Anirudh Deodhar"], "title": "DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "Accurate long-term traffic forecasting remains a critical challenge in\nintelligent transportation systems, particularly when predicting high-frequency\ntraffic phenomena such as shock waves and congestion boundaries over extended\nrollout horizons. Neural operators have recently gained attention as promising\ntools for modeling traffic flow. While effective at learning function space\nmappings, they inherently produce smooth predictions that fail to reconstruct\nhigh-frequency features such as sharp density gradients which results in rapid\nerror accumulation during multi-step rollout predictions essential for\nreal-time traffic management. To address these fundamental limitations, we\nintroduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO)\narchitecture. DETNO leverages a transformer neural operator with\ncross-attention mechanisms, providing model expressivity and super-resolution,\ncoupled with a diffusion-based refinement component that iteratively\nreconstructs high-frequency traffic details through progressive denoising. This\novercomes the inherent smoothing limitations and rollout instability of\nstandard neural operators. Through comprehensive evaluation on chaotic traffic\ndatasets, our method demonstrates superior performance in extended rollout\npredictions compared to traditional and transformer-based neural operators,\npreserving high-frequency components and improving stability over long\nprediction horizons.", "AI": {"tldr": "\u63d0\u51faDETNO\u67b6\u6784\u89e3\u51b3\u957f\u671f\u4ea4\u901a\u9884\u6d4b\u95ee\u9898\uff0c\u5728\u6df7\u6c8c\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u51c6\u786e\u7684\u957f\u671f\u4ea4\u901a\u9884\u6d4b\u662f\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u5173\u952e\u6311\u6218\uff0c\u73b0\u6709\u795e\u7ecf\u7b97\u5b50\u6709\u5e73\u6ed1\u9884\u6d4b\u3001\u9ad8\u9891\u7279\u5f81\u91cd\u5efa\u4e0d\u8db3\u548c\u6eda\u52a8\u9884\u6d4b\u8bef\u5dee\u79ef\u7d2f\u95ee\u9898\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u7684Diffusion - Enhanced Transformer Neural Operator (DETNO) \u67b6\u6784\uff0c\u7ed3\u5408\u5e26\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u7684\u53d8\u538b\u5668\u795e\u7ecf\u7b97\u5b50\u548c\u57fa\u4e8e\u6269\u6563\u7684\u7ec6\u5316\u7ec4\u4ef6\u3002", "result": "\u5728\u6df7\u6c8c\u4ea4\u901a\u6570\u636e\u96c6\u7684\u7efc\u5408\u8bc4\u4f30\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edf\u548c\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u795e\u7ecf\u7b97\u5b50\uff0c\u5728\u6269\u5c55\u6eda\u52a8\u9884\u6d4b\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u4fdd\u7559\u9ad8\u9891\u6210\u5206\uff0c\u63d0\u9ad8\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\u3002", "conclusion": "DETNO\u67b6\u6784\u514b\u670d\u4e86\u6807\u51c6\u795e\u7ecf\u7b97\u5b50\u7684\u56fa\u6709\u5c40\u9650\u6027\uff0c\u5728\u957f\u671f\u4ea4\u901a\u9884\u6d4b\u4e2d\u5177\u6709\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2508.19394", "pdf": "https://arxiv.org/pdf/2508.19394", "abs": "https://arxiv.org/abs/2508.19394", "authors": ["Afrar Jahin", "Yi Pan", "Yingfeng Wang", "Tianming Liu", "Wei Zhang"], "title": "Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Although recent advances in quantum machine learning (QML) offer significant\npotential for enhancing generative models, particularly in molecular design, a\nlarge array of classical approaches still face challenges in achieving high\nfidelity and validity. In particular, the integration of QML with\nsequence-based tasks, such as Simplified Molecular Input Line Entry System\n(SMILES) string reconstruction, remains underexplored and usually suffers from\nfidelity degradation. In this work, we propose a hybrid quantum-classical\narchitecture for SMILES reconstruction that integrates quantum encoding with\nclassical sequence modeling to improve quantum fidelity and classical\nsimilarity. Our approach achieves a quantum fidelity of approximately 84% and a\nclassical reconstruction similarity of 60%, surpassing existing quantum\nbaselines. Our work lays a promising foundation for future QML applications,\nstriking a balance between expressive quantum representations and classical\nsequence models and catalyzing broader research on quantum-aware sequence\nmodels for molecular and drug discovery.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8eSMILES\u91cd\u5efa\u7684\u6df7\u5408\u91cf\u5b50 - \u7ecf\u5178\u67b6\u6784\uff0c\u63d0\u5347\u91cf\u5b50\u4fdd\u771f\u5ea6\u548c\u7ecf\u5178\u76f8\u4f3c\u5ea6\uff0c\u8d85\u8d8a\u73b0\u6709\u91cf\u5b50\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7ecf\u5178\u65b9\u6cd5\u5728\u751f\u6210\u6a21\u578b\u4e2d\u9762\u4e34\u9ad8\u4fdd\u771f\u5ea6\u548c\u6709\u6548\u6027\u6311\u6218\uff0cQML\u4e0e\u5e8f\u5217\u4efb\u52a1\u96c6\u6210\u7814\u7a76\u4e0d\u8db3\u4e14\u6613\u51fa\u73b0\u4fdd\u771f\u5ea6\u4e0b\u964d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u91cf\u5b50\u7f16\u7801\u548c\u7ecf\u5178\u5e8f\u5217\u5efa\u6a21\u7684\u6df7\u5408\u91cf\u5b50 - \u7ecf\u5178\u67b6\u6784\u7528\u4e8eSMILES\u91cd\u5efa\u3002", "result": "\u5b9e\u73b0\u7ea684%\u7684\u91cf\u5b50\u4fdd\u771f\u5ea6\u548c60%\u7684\u7ecf\u5178\u91cd\u5efa\u76f8\u4f3c\u5ea6\uff0c\u8d85\u8d8a\u73b0\u6709\u91cf\u5b50\u57fa\u7ebf\u3002", "conclusion": "\u4e3a\u672a\u6765QML\u5e94\u7528\u5960\u5b9a\u57fa\u7840\uff0c\u5e73\u8861\u91cf\u5b50\u8868\u793a\u548c\u7ecf\u5178\u5e8f\u5217\u6a21\u578b\uff0c\u4fc3\u8fdb\u91cf\u5b50\u611f\u77e5\u5e8f\u5217\u6a21\u578b\u7814\u7a76\u3002"}}
{"id": "2508.19264", "pdf": "https://arxiv.org/pdf/2508.19264", "abs": "https://arxiv.org/abs/2508.19264", "authors": ["Bijean Ghafouri"], "title": "A Theory of Information, Variation, and Artificial Intelligence", "categories": ["cs.HC", "cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "A growing body of empirical work suggests that the widespread adoption of\ngenerative AI produces a significant homogenizing effect on information,\ncreativity, and cultural production. I first develop a novel theoretical\nframework to explain this phenomenon. I argue that a dynamic of AI-derivative\nepistemology, in which individuals increasingly defer to AI outputs, allows a\ncentralized AI Prism to function, a technical mechanism whose architecture is\ndesigned to reduce variance and converge on the statistical mean. This provides\na causal explanation for the generative monocultures observed in recent\nstudies. However, I contend this represents only the first stage of a more\ncomplex and dialectical process. This paper's central and paradoxical thesis is\nthat the very homogenization that flattens knowledge within specialized domains\nsimultaneously renders that knowledge into consistent modules that can be\nrecombined across them, a process foundational to innovation and creativity.\nHowever, this recombinant potential is not automatic, but rather conditional.\nThis paper argues that these opposing forces, homogenizing defaults versus\nrecombinant possibilities, are governed by the nature of human engagement with\nthe technology. The ultimate effect of generative AI is conditional on whether\nindividuals act as passive consumers deferring to the AI's statistical outputs,\nor as active curators who critically interrogate, re-contextualize, and\nrecombine them. The paper concludes by outlining the cognitive and\ninstitutional scaffolds required to resolve this tension, arguing they are the\ndecisive variable that determine whether generative AI becomes an instrument of\ninnovation or homogenization.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5e26\u6765\u7684\u540c\u8d28\u5316\u5f71\u54cd\uff0c\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u8be5\u73b0\u8c61\uff0c\u6307\u51fa\u540c\u8d28\u5316\u4e5f\u6709\u91cd\u7ec4\u521b\u65b0\u6f5c\u529b\uff0c\u5176\u6700\u7ec8\u5f71\u54cd\u53d6\u51b3\u4e8e\u4eba\u7c7b\u4e0e\u6280\u672f\u7684\u4e92\u52a8\u65b9\u5f0f\u3002", "motivation": "\u89e3\u91ca\u751f\u6210\u5f0fAI\u5e7f\u6cdb\u5e94\u7528\u5e26\u6765\u7684\u4fe1\u606f\u3001\u521b\u9020\u529b\u548c\u6587\u5316\u751f\u4ea7\u540c\u8d28\u5316\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790AI\u884d\u751f\u8ba4\u8bc6\u8bba\u52a8\u6001\u53caAI Prism\u6280\u672f\u673a\u5236\u3002", "result": "\u53d1\u73b0\u540c\u8d28\u5316\u867d\u5728\u4e13\u4e1a\u9886\u57df\u6241\u5e73\u5316\u77e5\u8bc6\uff0c\u4f46\u53ef\u5f62\u6210\u8de8\u9886\u57df\u91cd\u7ec4\u6a21\u5757\uff1b\u91cd\u7ec4\u6f5c\u529b\u975e\u81ea\u52a8\uff0c\u53d7\u4eba\u7c7b\u4e0e\u6280\u672f\u4e92\u52a8\u65b9\u5f0f\u5f71\u54cd\u3002", "conclusion": "\u89e3\u51b3\u540c\u8d28\u5316\u4e0e\u91cd\u7ec4\u521b\u65b0\u77db\u76fe\u9700\u8ba4\u77e5\u548c\u5236\u5ea6\u652f\u6491\uff0c\u8fd9\u51b3\u5b9a\u751f\u6210\u5f0fAI\u6210\u4e3a\u521b\u65b0\u6216\u540c\u8d28\u5316\u5de5\u5177\u3002"}}
{"id": "2508.19410", "pdf": "https://arxiv.org/pdf/2508.19410", "abs": "https://arxiv.org/abs/2508.19410", "authors": ["Zongyu Wu", "Ruichen Xu", "Luoyao Chen", "Georgios Kementzidis", "Siyao Wang", "Yuefan Deng"], "title": "Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks", "categories": ["cs.LG", "physics.comp-ph"], "comment": "Comments: 8 pages, 6 figures. Accepted at IJCNN 2025 (to appear in\n  IEEE/IJCNN proceedings). This arXiv submission corresponds to the\n  camera-ready version with minor editorial clarifications; results unchanged", "summary": "We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural\nNetwork (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with\nunivariate transformations. While Hamiltonian Neural Networks (HNNs) ensure\nenergy conservation by learning Hamiltonian functions directly from data,\nexisting implementations, often relying on MLPs, cause hypersensitivity to the\nhyperparameters while exploring complex energy landscapes. Our approach\nexploits the localized function approximations to better capture high-frequency\nand multi-scale dynamics, reducing energy drift and improving long-term\npredictive stability. The networks preserve the symplectic form of Hamiltonian\nsystems, and thus maintain interpretability and physical consistency. After\nassessing KAR-HNN on four benchmark problems including spring-mass, simple\npendulum, two- and three-body problem, we foresee its effectiveness for\naccurate and stable modeling of realistic physical processes often at high\ndimensions and with few known parameters.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eKolmogorov - Arnold\u8868\u793a\u7684\u54c8\u5bc6\u987f\u795e\u7ecf\u7f51\u7edc\uff08KAR - HNN\uff09\uff0c\u8bc4\u4f30\u5176\u5728\u56db\u4e2a\u57fa\u51c6\u95ee\u9898\u4e0a\u7684\u6548\u679c\uff0c\u9884\u89c1\u5176\u5bf9\u9ad8\u7ef4\u4e14\u53c2\u6570\u5c11\u7684\u7269\u7406\u8fc7\u7a0b\u5efa\u6a21\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u591a\u5c42\u611f\u77e5\u5668\uff08MLPs\uff09\u7684\u54c8\u5bc6\u987f\u795e\u7ecf\u7f51\u7edc\uff08HNNs\uff09\u5728\u63a2\u7d22\u590d\u6742\u80fd\u91cf\u666f\u89c2\u65f6\u5bf9\u8d85\u53c2\u6570\u8fc7\u4e8e\u654f\u611f\u3002", "method": "\u63d0\u51faKAR - HNN\uff0c\u7528\u5355\u53d8\u91cf\u53d8\u6362\u53d6\u4ee3MLPs\uff0c\u5229\u7528\u5c40\u90e8\u51fd\u6570\u8fd1\u4f3c\u3002", "result": "\u8be5\u7f51\u7edc\u80fd\u51cf\u5c11\u80fd\u91cf\u6f02\u79fb\uff0c\u63d0\u9ad8\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\uff0c\u4fdd\u7559\u54c8\u5bc6\u987f\u7cfb\u7edf\u7684\u8f9b\u5f62\u5f0f\u3002", "conclusion": "KAR - HNN\u5bf9\u9ad8\u7ef4\u4e14\u53c2\u6570\u5c11\u7684\u73b0\u5b9e\u7269\u7406\u8fc7\u7a0b\u5efa\u6a21\u51c6\u786e\u7a33\u5b9a\u3002"}}
{"id": "2508.19267", "pdf": "https://arxiv.org/pdf/2508.19267", "abs": "https://arxiv.org/abs/2508.19267", "authors": ["Sai Teja Reddy Adapala", "Yashwanth Reddy Alugubelly"], "title": "The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents", "categories": ["cs.CR", "cs.AI", "cs.MA"], "comment": "10 pages, 3 figures, 3 tables. Source compiled with pdfLaTeX;\n  bibliography included via prebuilt main.bbl. Code repository: available in\n  paper", "summary": "The proliferation of autonomous AI agents marks a paradigm shift toward\ncomplex, emergent multi-agent systems. This transition introduces systemic\nsecurity risks, including control-flow hijacking and cascading failures, that\ntraditional cybersecurity paradigms are ill-equipped to address. This paper\nintroduces the Aegis Protocol, a layered security framework designed to provide\nstrong security guarantees for open agentic ecosystems. The protocol integrates\nthree technological pillars: (1) non-spoofable agent identity via W3C\nDecentralized Identifiers (DIDs); (2) communication integrity via\nNIST-standardized post-quantum cryptography (PQC); and (3) verifiable,\nprivacy-preserving policy compliance using the Halo2 zero-knowledge proof (ZKP)\nsystem. We formalize an adversary model extending Dolev-Yao for agentic threats\nand validate the protocol against the STRIDE framework. Our quantitative\nevaluation used a discrete-event simulation, calibrated against cryptographic\nbenchmarks, to model 1,000 agents. The simulation showed a 0 percent success\nrate across 20,000 attack trials. For policy verification, analysis of the\nsimulation logs reported a median proof-generation latency of 2.79 seconds,\nestablishing a performance baseline for this class of security. While the\nevaluation is simulation-based and early-stage, it offers a reproducible\nbaseline for future empirical studies and positions Aegis as a foundation for\nsafe, scalable autonomous AI.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8e\u5f00\u653e\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u7684Aegis\u534f\u8bae\uff0c\u7ecf\u6a21\u62df\u8bc4\u4f30\u6709\u9ad8\u5b89\u5168\u6027\u548c\u6027\u80fd\u8868\u73b0\uff0c\u4e3a\u5b89\u5168\u53ef\u6269\u5c55AI\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u81ea\u4e3bAI\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u5e26\u6765\u7cfb\u7edf\u5b89\u5168\u98ce\u9669\uff0c\u4f20\u7edf\u8303\u5f0f\u96be\u4ee5\u5e94\u5bf9\uff0c\u9700\u65b0\u5b89\u5168\u6846\u67b6\u3002", "method": "\u63d0\u51faAegis\u534f\u8bae\uff0c\u96c6\u6210W3C DID\u3001NIST PQC\u548cHalo2 ZKP\u4e09\u4e2a\u6280\u672f\u652f\u67f1\uff1b\u5f62\u5f0f\u5316\u6269\u5c55Dolev - Yao\u7684\u5bf9\u624b\u6a21\u578b\uff1b\u7528\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\u8bc4\u4f30\u3002", "result": "20000\u6b21\u653b\u51fb\u6a21\u62df\u6210\u529f\u7387\u4e3a0%\uff1b\u7b56\u7565\u9a8c\u8bc1\u8bc1\u660e\u751f\u6210\u4e2d\u4f4d\u5ef6\u8fdf2.79\u79d2\u3002", "conclusion": "\u867d\u8bc4\u4f30\u57fa\u4e8e\u6a21\u62df\u4e14\u5904\u4e8e\u65e9\u671f\uff0c\u4f46\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u53ef\u91cd\u73b0\u57fa\u7ebf\uff0cAegis\u53ef\u4f5c\u4e3a\u5b89\u5168\u53ef\u6269\u5c55\u81ea\u4e3bAI\u7684\u57fa\u7840\u3002"}}
{"id": "2508.19414", "pdf": "https://arxiv.org/pdf/2508.19414", "abs": "https://arxiv.org/abs/2508.19414", "authors": ["Gustavo Sandoval"], "title": "Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages", "summary": "We present a mechanistic case study of a format-dependent reasoning failure\nin Llama-3.1-8B-Instruct, where the model incorrectly judges \"9.11\" as larger\nthan \"9.8\" in chat or Q&A formats, but answers correctly in simple format.\nThrough systematic intervention, we discover transformers implement even/odd\nattention head specialization: even indexed heads handle numerical comparison,\nwhile odd heads serve incompatible functions. The bug requires exactly 8 even\nheads at Layer 10 for perfect repair. Any combination of 8+ even heads\nsucceeds, while 7 or fewer completely fails, revealing sharp computational\nthresholds with perfect redundancy among the 16 even heads. SAE analysis\nreveals the mechanism: format representations separate (10% feature overlap at\nLayer 7), then re-entangle with different weightings (80% feature overlap at\nLayer 10), with specific features showing 1.5x amplification in failing\nformats. We achieve perfect repair using only 25% of attention heads and\nidentify a 60% pattern replacement threshold, demonstrating that apparent\nfull-module requirements hide sophisticated substructure with implications for\ninterpretability and efficiency. All of our code is available at\nhttps://github.com/gussand/surgeon.", "AI": {"tldr": "\u5bf9Llama - 3.1 - 8B - Instruct\u683c\u5f0f\u4f9d\u8d56\u63a8\u7406\u5931\u8d25\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u53d1\u73b0\u6ce8\u610f\u529b\u5934\u4e13\u4e1a\u5316\u73b0\u8c61\u3001\u8ba1\u7b97\u9608\u503c\u7b49\uff0c\u5b9e\u73b0\u6a21\u578b\u4fee\u590d\u3002", "motivation": "\u7814\u7a76Llama - 3.1 - 8B - Instruct\u5728\u4e0d\u540c\u683c\u5f0f\u4e0b\u6570\u503c\u6bd4\u8f83\u63a8\u7406\u5931\u8d25\u7684\u539f\u56e0\u3002", "method": "\u7cfb\u7edf\u5e72\u9884\u3001SAE\u5206\u6790\u7b49\u3002", "result": "\u53d1\u73b0\u53d8\u538b\u5668\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u5934\u4e13\u4e1a\u5316\uff0c\u627e\u5230\u4fee\u590d\u9519\u8bef\u6240\u9700\u7684\u5076\u6570\u5934\u6570\u91cf\uff0c\u63ed\u793a\u683c\u5f0f\u8868\u793a\u5206\u79bb\u548c\u91cd\u7ea0\u7f20\u673a\u5236\uff0c\u5b9e\u73b0\u752825%\u6ce8\u610f\u529b\u5934\u5b8c\u7f8e\u4fee\u590d\uff0c\u786e\u5b9a60%\u6a21\u5f0f\u66ff\u6362\u9608\u503c\u3002", "conclusion": "\u6a21\u578b\u8868\u9762\u7684\u5168\u6a21\u5757\u9700\u6c42\u9690\u85cf\u7740\u590d\u6742\u5b50\u7ed3\u6784\uff0c\u5bf9\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\u6709\u5f71\u54cd\u3002"}}
{"id": "2508.19268", "pdf": "https://arxiv.org/pdf/2508.19268", "abs": "https://arxiv.org/abs/2508.19268", "authors": ["Qing Wang", "Xue Han", "Jiahui Wang", "Lehao Xing", "Qian Hu", "Lianlian Zhang", "Chao Deng", "Junlan Feng"], "title": "MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite LLMs' excellent code creation capabilities, multilingual code\ngeneration remains extremely challenging. To address this, we intent to improve\nthe multi-programming-lingual (MultiPL) performance of the base LLMs while\nretaining the most popular ones using restricted computational resources. We\nconsider MultiPL to be a special case of multiple natural languages and propose\na MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called\nMultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize\nexpert selection at both the token and segment levels. The token-level MoE is a\nstandard upcycling MoE structure with a shared expert and a novel gate weight\nnormalization approach that aids in the final fusion with the segment-level\nMoE. The segment-level MoE incorporates two innovative designs to better\ncapture the syntactic structure and contextual patterns of programming\nlanguages: First, using a sliding window to partition the input token sequence\ninto multiple segments; Then, adopting an expert-choice routing strategy that\nallows experts to select the top-k segments. The results of the experiment\nproved the effectiveness of MultiPL-MoE.", "AI": {"tldr": "\u63d0\u51faMultiPL - MoE\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u591a\u7f16\u7a0b\u8bed\u8a00\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u96be\u9898\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u63d0\u5347\u591a\u7f16\u7a0b\u8bed\u8a00\u6027\u80fd\u3002", "method": "\u5c06\u591a\u7f16\u7a0b\u8bed\u8a00\u89c6\u4e3a\u591a\u81ea\u7136\u8bed\u8a00\u7279\u4f8b\uff0c\u63d0\u51faMultiPL - MoE\uff0c\u7ed3\u5408\u4e24\u4e2a\u6210\u5bf9\u7684\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u4f18\u5316\u4e13\u5bb6\u9009\u62e9\uff0c\u5728\u6807\u8bb0\u548c\u7247\u6bb5\u5c42\u9762\u5404\u6709\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86MultiPL - MoE\u7684\u6709\u6548\u6027\u3002", "conclusion": "MultiPL - MoE\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u591a\u7f16\u7a0b\u8bed\u8a00\u6027\u80fd\u3002"}}
{"id": "2508.19419", "pdf": "https://arxiv.org/pdf/2508.19419", "abs": "https://arxiv.org/abs/2508.19419", "authors": ["Harun Ur Rashid", "Aleksandra Pachalieva", "Daniel O'Malley"], "title": "Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management", "categories": ["cs.LG"], "comment": null, "summary": "Accurate subsurface reservoir pressure control is extremely challenging due\nto geological heterogeneity and multiphase fluid-flow dynamics. Predicting\nbehavior in this setting relies on high-fidelity physics-based simulations that\nare computationally expensive. Yet, the uncertain, heterogeneous properties\nthat control these flows make it necessary to perform many of these expensive\nsimulations, which is often prohibitive. To address these challenges, we\nintroduce a physics-informed machine learning workflow that couples a fully\ndifferentiable multiphase flow simulator, which is implemented in the DPFEHM\nframework with a convolutional neural network (CNN). The CNN learns to predict\nfluid extraction rates from heterogeneous permeability fields to enforce\npressure limits at critical reservoir locations. By incorporating transient\nmultiphase flow physics into the training process, our method enables more\npractical and accurate predictions for realistic injection-extraction scenarios\ncompare to previous works. To speed up training, we pretrain the model on\nsingle-phase, steady-state simulations and then fine-tune it on full multiphase\nscenarios, which dramatically reduces the computational cost. We demonstrate\nthat high-accuracy training can be achieved with fewer than three thousand\nfull-physics multiphase flow simulations -- compared to previous estimates\nrequiring up to ten million. This drastic reduction in the number of\nsimulations is achieved by leveraging transfer learning from much less\nexpensive single-phase simulations.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u53ef\u5fae\u591a\u76f8\u6d41\u6a21\u62df\u5668\u4e0eCNN\u7684\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\uff0c\u80fd\u66f4\u51c6\u786e\u9884\u6d4b\u6ce8\u91c7\u573a\u666f\uff0c\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\u51cf\u5c11\u6a21\u62df\u6b21\u6570\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5730\u4e0b\u50a8\u5c42\u538b\u529b\u63a7\u5236\u56e0\u5730\u8d28\u5f02\u8d28\u6027\u548c\u591a\u76f8\u6d41\u52a8\u529b\u5b66\u5177\u6709\u6311\u6218\u6027\uff0c\u4f20\u7edf\u9ad8\u4fdd\u771f\u7269\u7406\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u591a\u6b21\u6a21\u62df\uff0c\u56e0\u6b64\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5f15\u5165\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408DPFEHM\u6846\u67b6\u7684\u53ef\u5fae\u591a\u76f8\u6d41\u6a21\u62df\u5668\u548cCNN\uff0cCNN\u5b66\u4e60\u4ece\u6e17\u900f\u7387\u573a\u9884\u6d4b\u6d41\u4f53\u63d0\u53d6\u7387\uff1b\u5148\u5728\u5355\u76f8\u7a33\u6001\u6a21\u62df\u4e0a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u518d\u5728\u591a\u76f8\u573a\u666f\u5fae\u8c03\u3002", "result": "\u80fd\u5b9e\u73b0\u66f4\u5b9e\u9645\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u7528\u5c11\u4e8e\u4e09\u5343\u6b21\u5168\u7269\u7406\u591a\u76f8\u6d41\u6a21\u62df\u5c31\u80fd\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u8fdc\u5c11\u4e8e\u5148\u524d\u4f30\u8ba1\u7684\u8fbe\u4e00\u5343\u4e07\u6b21\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\uff0c\u5927\u5e45\u51cf\u5c11\u6a21\u62df\u6b21\u6570\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u5728\u6ce8\u91c7\u573a\u666f\u9884\u6d4b\u4e0a\u6709\u4f18\u52bf\u3002"}}
{"id": "2508.19269", "pdf": "https://arxiv.org/pdf/2508.19269", "abs": "https://arxiv.org/abs/2508.19269", "authors": ["Ke Zhou", "Marios Constantinides", "Daniele Quercia"], "title": "Should LLMs be WEIRD? Exploring WEIRDness and Human Rights in Large Language Models", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "This paper has been accepted in AIES 2025", "summary": "Large language models (LLMs) are often trained on data that reflect WEIRD\nvalues: Western, Educated, Industrialized, Rich, and Democratic. This raises\nconcerns about cultural bias and fairness. Using responses to the World Values\nSurvey, we evaluated five widely used LLMs: GPT-3.5, GPT-4, Llama-3, BLOOM, and\nQwen. We measured how closely these responses aligned with the values of the\nWEIRD countries and whether they conflicted with human rights principles. To\nreflect global diversity, we compared the results with the Universal\nDeclaration of Human Rights and three regional charters from Asia, the Middle\nEast, and Africa. Models with lower alignment to WEIRD values, such as BLOOM\nand Qwen, produced more culturally varied responses but were 2% to 4% more\nlikely to generate outputs that violated human rights, especially regarding\ngender and equality. For example, some models agreed with the statements ``a\nman who cannot father children is not a real man'' and ``a husband should\nalways know where his wife is'', reflecting harmful gender norms. These\nfindings suggest that as cultural representation in LLMs increases, so does the\nrisk of reproducing discriminatory beliefs. Approaches such as Constitutional\nAI, which could embed human rights principles into model behavior, may only\npartly help resolve this tension.", "AI": {"tldr": "\u8bc4\u4f30\u4e94\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ef7\u503c\u89c2\u4e0a\u4e0eWEIRD\u56fd\u5bb6\u7684\u5951\u5408\u5ea6\u53ca\u5bf9\u4eba\u6743\u539f\u5219\u7684\u9075\u5faa\u60c5\u51b5\uff0c\u53d1\u73b0\u6587\u5316\u591a\u6837\u6027\u589e\u52a0\u65f6\u4ea7\u751f\u6b67\u89c6\u6027\u4fe1\u5ff5\u7684\u98ce\u9669\u4e5f\u589e\u52a0\uff0cConstitutional AI\u53ea\u80fd\u90e8\u5206\u89e3\u51b3\u6b64\u77db\u76fe\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e38\u57fa\u4e8e\u53cd\u6620WEIRD\u4ef7\u503c\u89c2\u7684\u6570\u636e\u8bad\u7ec3\uff0c\u5f15\u53d1\u5bf9\u6587\u5316\u504f\u89c1\u548c\u516c\u5e73\u6027\u7684\u62c5\u5fe7\u3002", "method": "\u7528\u4e16\u754c\u4ef7\u503c\u89c2\u8c03\u67e5\u7684\u56de\u590d\u8bc4\u4f30\u4e94\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6d4b\u91cf\u5176\u4e0eWEIRD\u56fd\u5bb6\u4ef7\u503c\u89c2\u7684\u5951\u5408\u5ea6\u548c\u662f\u5426\u8fdd\u80cc\u4eba\u6743\u539f\u5219\uff0c\u4e0e\u300a\u4e16\u754c\u4eba\u6743\u5ba3\u8a00\u300b\u53ca\u4e09\u4e2a\u5730\u533a\u5baa\u7ae0\u5bf9\u6bd4\u3002", "result": "\u4e0eWEIRD\u4ef7\u503c\u89c2\u5951\u5408\u5ea6\u4f4e\u7684\u6a21\u578b\u6587\u5316\u591a\u6837\u6027\u66f4\u9ad8\uff0c\u4f46\u4ea7\u751f\u8fdd\u53cd\u4eba\u6743\u8f93\u51fa\u7684\u53ef\u80fd\u6027\u9ad82% - 4%\uff0c\u5b58\u5728\u6709\u5bb3\u6027\u522b\u89c4\u8303\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u6587\u5316\u4ee3\u8868\u6027\u589e\u52a0\u65f6\uff0c\u4ea7\u751f\u6b67\u89c6\u6027\u4fe1\u5ff5\u7684\u98ce\u9669\u4e5f\u589e\u52a0\uff0cConstitutional AI\u53ea\u80fd\u90e8\u5206\u89e3\u51b3\u6b64\u77db\u76fe\u3002"}}
{"id": "2508.19424", "pdf": "https://arxiv.org/pdf/2508.19424", "abs": "https://arxiv.org/abs/2508.19424", "authors": ["Yifan Dou", "Adam Khadre", "Ruben C Petreaca", "Golrokh Mirzaei"], "title": "MS-ConTab: Multi-Scale Contrastive Learning of Mutation Signatures for Pan Cancer Representation and Stratification", "categories": ["cs.LG"], "comment": null, "summary": "Motivation. Understanding the pan-cancer mutational landscape offers critical\ninsights into the molecular mechanisms underlying tumorigenesis. While\npatient-level machine learning techniques have been widely employed to identify\ntumor subtypes, cohort-level clustering, where entire cancer types are grouped\nbased on shared molecular features, has largely relied on classical statistical\nmethods.\n  Results. In this study, we introduce a novel unsupervised contrastive\nlearning framework to cluster 43 cancer types based on coding mutation data\nderived from the COSMIC database. For each cancer type, we construct two\ncomplementary mutation signatures: a gene-level profile capturing nucleotide\nsubstitution patterns across the most frequently mutated genes, and a\nchromosome-level profile representing normalized substitution frequencies\nacross chromosomes. These dual views are encoded using TabNet encoders and\noptimized via a multi-scale contrastive learning objective (NT-Xent loss) to\nlearn unified cancer-type embeddings. We demonstrate that the resulting latent\nrepresentations yield biologically meaningful clusters of cancer types,\naligning with known mutational processes and tissue origins. Our work\nrepresents the first application of contrastive learning to cohort-level cancer\nclustering, offering a scalable and interpretable framework for mutation-driven\ncancer subtyping.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65e0\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5bf943\u79cd\u764c\u75c7\u7c7b\u578b\u805a\u7c7b\uff0c\u7528\u53cc\u89c6\u56fe\u7f16\u7801\u548c\u591a\u5c3a\u5ea6\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u5b66\u4e60\u764c\u75c7\u7c7b\u578b\u5d4c\u5165\uff0c\u805a\u7c7b\u7ed3\u679c\u6709\u751f\u7269\u5b66\u610f\u4e49\u3002", "motivation": "\u7406\u89e3\u6cdb\u764c\u7a81\u53d8\u683c\u5c40\u5bf9\u4e86\u89e3\u80bf\u7624\u53d1\u751f\u5206\u5b50\u673a\u5236\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u5f80\u961f\u5217\u6c34\u5e73\u805a\u7c7b\u591a\u4f9d\u8d56\u7ecf\u5178\u7edf\u8ba1\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u65e0\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u6bcf\u79cd\u764c\u75c7\u7c7b\u578b\u6784\u5efa\u57fa\u56e0\u548c\u67d3\u8272\u4f53\u6c34\u5e73\u4e24\u79cd\u4e92\u8865\u7a81\u53d8\u7279\u5f81\uff0c\u7528TabNet\u7f16\u7801\u5668\u7f16\u7801\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\uff08NT - Xent\u635f\u5931\uff09\u4f18\u5316\u5b66\u4e60\u7edf\u4e00\u7684\u764c\u75c7\u7c7b\u578b\u5d4c\u5165\u3002", "result": "\u5f97\u5230\u7684\u6f5c\u5728\u8868\u5f81\u4ea7\u751f\u4e86\u5177\u6709\u751f\u7269\u5b66\u610f\u4e49\u7684\u764c\u75c7\u7c7b\u578b\u805a\u7c7b\uff0c\u4e0e\u5df2\u77e5\u7a81\u53d8\u8fc7\u7a0b\u548c\u7ec4\u7ec7\u8d77\u6e90\u4e00\u81f4\u3002", "conclusion": "\u8fd9\u662f\u5bf9\u6bd4\u5b66\u4e60\u9996\u6b21\u5e94\u7528\u4e8e\u961f\u5217\u6c34\u5e73\u764c\u75c7\u805a\u7c7b\uff0c\u4e3a\u57fa\u4e8e\u7a81\u53d8\u7684\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u3002"}}
{"id": "2508.19270", "pdf": "https://arxiv.org/pdf/2508.19270", "abs": "https://arxiv.org/abs/2508.19270", "authors": ["Nguyen Huu Nhat Minh", "Tran Nguyen Anh", "Truong Dinh Dung", "Vo Van Nam", "Le Pham Tuyen"], "title": "Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Cross-lingual phoneme recognition has emerged as a significant challenge for\naccurate automatic speech recognition (ASR) when mixing Vietnamese and English\npronunciations. Unlike many languages, Vietnamese relies on tonal variations to\ndistinguish word meanings, whereas English features stress patterns and\nnon-standard pronunciations that hinder phoneme alignment between the two\nlanguages. To address this challenge, we propose a novel bilingual speech\nrecognition approach with two primary contributions: (1) constructing a\nrepresentative bilingual phoneme set that bridges the differences between\nVietnamese and English phonetic systems; (2) designing an end-to-end system\nthat leverages the PhoWhisper pre-trained encoder for deep high-level\nrepresentations to improve phoneme recognition. Our extensive experiments\ndemonstrate that the proposed approach not only improves recognition accuracy\nin bilingual speech recognition for Vietnamese but also provides a robust\nframework for addressing the complexities of tonal and stress-based phoneme\nrecognition", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8de8\u8d8a\u5357\u8bed\u548c\u82f1\u8bed\u7684\u53cc\u8bed\u8bed\u97f3\u8bc6\u522b\u65b0\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53ef\u63d0\u5347\u8bc6\u522b\u51c6\u786e\u7387\u5e76\u63d0\u4f9b\u89e3\u51b3\u590d\u6742\u97f3\u7d20\u8bc6\u522b\u7684\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u8d8a\u5357\u8bed\u548c\u82f1\u8bed\u6df7\u5408\u53d1\u97f3\u65f6\u8de8\u8bed\u8a00\u97f3\u7d20\u8bc6\u522b\u5bf9\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7684\u6311\u6218\uff0c\u4e24\u79cd\u8bed\u8a00\u97f3\u7d20\u7cfb\u7edf\u5dee\u5f02\u5927\u3002", "method": "\u6784\u5efa\u4ee3\u8868\u53cc\u8bed\u97f3\u7d20\u96c6\u5f25\u5408\u4e24\u79cd\u8bed\u8a00\u8bed\u97f3\u7cfb\u7edf\u5dee\u5f02\uff1b\u8bbe\u8ba1\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u5229\u7528PhoWhisper\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u8fdb\u884c\u6df1\u5ea6\u9ad8\u5c42\u8868\u5f81\u4ee5\u6539\u5584\u97f3\u7d20\u8bc6\u522b\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u8d8a\u5357\u8bed\u53cc\u8bed\u8bed\u97f3\u8bc6\u522b\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u89e3\u51b3\u57fa\u4e8e\u58f0\u8c03\u4e0e\u91cd\u97f3\u7684\u97f3\u7d20\u8bc6\u522b\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u53ef\u9760\u6846\u67b6\u3002"}}
{"id": "2508.19271", "pdf": "https://arxiv.org/pdf/2508.19271", "abs": "https://arxiv.org/abs/2508.19271", "authors": ["Rushitha Santhoshi Mamidala", "Anshuman Chhabra", "Ankur Mali"], "title": "Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and\nIn-Context Learning (ICL) have become widely used for eliciting reasoning\ncapabilities in large language models (LLMs). However, these methods rely on\nfragile, implicit mechanisms often yielding inconsistent outputs across seeds,\nformats, or minor prompt variations making them fundamentally unreliable for\ntasks requiring stable, interpretable reasoning. In contrast, automata-based\nneuro-symbolic frameworks like RetoMaton offer a more structured and\ntrustworthy alternative by grounding retrieval in symbolic memory with\ndeterministic transitions. In this work, we extend RetoMaton by replacing its\nglobal datastore with a local, task-adaptive Weighted Finite Automaton (WFA),\nconstructed directly from external domain corpora. This local automaton\nstructure promotes robust, context-aware retrieval while preserving symbolic\ntraceability and low inference overhead. Unlike prompting, which entangles\ncontext and memory in opaque ways, our approach leverages the explicit\nstructure of WFAs to provide verifiable and modular retrieval behavior, making\nit better suited for domain transfer and interoperability. We evaluate this\nlocal RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT\nacross three reasoning tasks: TriviaQA (reading comprehension), GSM8K\n(multi-step math), and MMLU (domain knowledge). Compared to the base model and\nprompting-based methods, augmenting these setups with local RetoMaton\nconsistently improves performance while enabling transparent and reproducible\nretrieval dynamics. Our results highlight a promising shift toward trustworthy,\nsymbolic reasoning in modern LLMs via lightweight, automaton-guided memory.", "AI": {"tldr": "\u4f20\u7edf\u63d0\u793a\u63a8\u7406\u65b9\u6cd5\u4e0d\u53ef\u9760\uff0c\u672c\u6587\u6269\u5c55RetoMaton\uff0c\u7528\u672c\u5730\u81ea\u9002\u5e94\u52a0\u6743\u6709\u9650\u81ea\u52a8\u673a\u66ff\u4ee3\u5168\u5c40\u6570\u636e\u5b58\u50a8\uff0c\u5728\u591a\u4efb\u52a1\u8bc4\u4f30\u4e2d\u63d0\u5347\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5411\u53ef\u4fe1\u7b26\u53f7\u63a8\u7406\u7684\u8f6c\u53d8\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u63a8\u7406\u7b56\u7565\uff08\u5982CoT\u548cICL\uff09\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u66f4\u7ed3\u6784\u5316\u3001\u53ef\u4fe1\u7684\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u7528\u672c\u5730\u3001\u4efb\u52a1\u81ea\u9002\u5e94\u7684\u52a0\u6743\u6709\u9650\u81ea\u52a8\u673a\u66ff\u4ee3RetoMaton\u7684\u5168\u5c40\u6570\u636e\u5b58\u50a8\uff0c\u5229\u7528\u81ea\u52a8\u673a\u663e\u5f0f\u7ed3\u6784\u8fdb\u884c\u68c0\u7d22\u3002", "result": "\u5728\u4e24\u4e2a\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u548c\u4e09\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0c\u672c\u5730RetoMaton\u53d8\u4f53\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u548c\u63d0\u793a\u65b9\u6cd5\uff0c\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u5b9e\u73b0\u900f\u660e\u548c\u53ef\u91cd\u73b0\u7684\u68c0\u7d22\u3002", "conclusion": "\u901a\u8fc7\u8f7b\u91cf\u7ea7\u81ea\u52a8\u673a\u5f15\u5bfc\u7684\u5185\u5b58\uff0c\u4e3a\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u53ef\u4fe1\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2508.19443", "pdf": "https://arxiv.org/pdf/2508.19443", "abs": "https://arxiv.org/abs/2508.19443", "authors": ["Paimon Goulart", "Shaan Pakala", "Evangelos Papalexakis"], "title": "Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization", "categories": ["cs.LG"], "comment": null, "summary": "Producing large complex simulation datasets can often be a time and resource\nconsuming task. Especially when these experiments are very expensive, it is\nbecoming more reasonable to generate synthetic data for downstream tasks.\nRecently, these methods may include using generative machine learning models\nsuch as Generative Adversarial Networks or diffusion models. As these\ngenerative models improve efficiency in producing useful data, we introduce an\ninternal tensor decomposition to these generative models to even further reduce\ncosts. More specifically, for multidimensional data, or tensors, we generate\nthe smaller tensor factors instead of the full tensor, in order to\nsignificantly reduce the model's output and overall parameters. This reduces\nthe costs of generating complex simulation data, and our experiments show the\ngenerated data remains useful. As a result, tensor decomposition has the\npotential to improve efficiency in generative models, especially when\ngenerating multidimensional data, or tensors.", "AI": {"tldr": "\u5229\u7528\u5185\u90e8\u5f20\u91cf\u5206\u89e3\u6539\u8fdb\u751f\u6210\u6a21\u578b\uff0c\u964d\u4f4e\u751f\u6210\u590d\u6742\u6a21\u62df\u6570\u636e\u6210\u672c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u751f\u6210\u6570\u636e\u4ecd\u6709\u7528\u4e14\u8be5\u65b9\u6cd5\u6709\u63d0\u5347\u6548\u7387\u6f5c\u529b\u3002", "motivation": "\u751f\u6210\u5927\u578b\u590d\u6742\u6a21\u62df\u6570\u636e\u96c6\u8017\u65f6\u8017\u8d44\u6e90\uff0c\u4f7f\u7528\u751f\u6210\u6a21\u578b\u751f\u6210\u5408\u6210\u6570\u636e\u867d\u6709\u6539\u5584\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u964d\u4f4e\u6210\u672c\u3002", "method": "\u5728\u751f\u6210\u6a21\u578b\u4e2d\u5f15\u5165\u5185\u90e8\u5f20\u91cf\u5206\u89e3\uff0c\u9488\u5bf9\u591a\u7ef4\u6570\u636e\u751f\u6210\u8f83\u5c0f\u7684\u5f20\u91cf\u56e0\u5b50\u800c\u975e\u5b8c\u6574\u5f20\u91cf\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u6a21\u578b\u8f93\u51fa\u548c\u603b\u4f53\u53c2\u6570\uff0c\u964d\u4f4e\u751f\u6210\u590d\u6742\u6a21\u62df\u6570\u636e\u6210\u672c\uff0c\u4e14\u751f\u6210\u7684\u6570\u636e\u4ecd\u6709\u7528\u3002", "conclusion": "\u5f20\u91cf\u5206\u89e3\u6709\u6f5c\u529b\u63d0\u5347\u751f\u6210\u6a21\u578b\u6548\u7387\uff0c\u5c24\u5176\u5728\u751f\u6210\u591a\u7ef4\u6570\u636e\u65f6\u3002"}}
{"id": "2508.19273", "pdf": "https://arxiv.org/pdf/2508.19273", "abs": "https://arxiv.org/abs/2508.19273", "authors": ["Tongxi Wu", "Chenwei Xu", "Jin Yang"], "title": "MixGAN: A Hybrid Semi-Supervised and Generative Approach for DDoS Detection in Cloud-Integrated IoT Networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The proliferation of cloud-integrated IoT systems has intensified exposure to\nDistributed Denial of Service (DDoS) attacks due to the expanded attack\nsurface, heterogeneous device behaviors, and limited edge protection. However,\nDDoS detection in this context remains challenging because of complex traffic\ndynamics, severe class imbalance, and scarce labeled data. While recent methods\nhave explored solutions to address class imbalance, many still struggle to\ngeneralize under limited supervision and dynamic traffic conditions. To\novercome these challenges, we propose MixGAN, a hybrid detection method that\nintegrates conditional generation, semi-supervised learning, and robust feature\nextraction. Specifically, to handle complex temporal traffic patterns, we\ndesign a 1-D WideResNet backbone composed of temporal convolutional layers with\nresidual connections, which effectively capture local burst patterns in traffic\nsequences. To alleviate class imbalance and label scarcity, we use a pretrained\nCTGAN to generate synthetic minority-class (DDoS attack) samples that\ncomplement unlabeled data. Furthermore, to mitigate the effect of noisy\npseudo-labels, we introduce a MixUp-Average-Sharpen (MAS) strategy that\nconstructs smoothed and sharpened targets by averaging predictions over\naugmented views and reweighting them towards high-confidence classes.\nExperiments on NSL-KDD, BoT-IoT, and CICIoT2023 demonstrate that MixGAN\nachieves up to 2.5% higher accuracy and 4% improvement in both TPR and TNR\ncompared to state-of-the-art methods, confirming its robustness in large-scale\nIoT-cloud environments. The source code is publicly available at\nhttps://github.com/0xCavaliers/MixGAN.", "AI": {"tldr": "\u4e91\u96c6\u6210\u7269\u8054\u7f51\u7cfb\u7edf\u6613\u53d7DDoS\u653b\u51fb\uff0c\u68c0\u6d4b\u9762\u4e34\u6311\u6218\u3002\u63d0\u51faMixGAN\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u79cd\u6280\u672f\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f18\u3002", "motivation": "\u4e91\u96c6\u6210\u7269\u8054\u7f51\u7cfb\u7edfDDoS\u68c0\u6d4b\u56e0\u6d41\u91cf\u52a8\u6001\u590d\u6742\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6807\u8bb0\u6570\u636e\u7a00\u7f3a\u800c\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u6709\u9650\u76d1\u7763\u548c\u52a8\u6001\u6d41\u91cf\u4e0b\u6cdb\u5316\u3002", "method": "\u63d0\u51faMixGAN\u6df7\u5408\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8bbe\u8ba11 - D WideResNet\u9aa8\u5e72\u7f51\u7edc\uff0c\u7528\u9884\u8bad\u7ec3CTGAN\u751f\u6210\u5408\u6210\u5c11\u6570\u7c7b\u6837\u672c\uff0c\u5f15\u5165MAS\u7b56\u7565\u3002", "result": "\u5728NSL - KDD\u3001BoT - IoT\u548cCICIoT2023\u4e0a\u5b9e\u9a8c\uff0cMixGAN\u6bd4\u73b0\u6709\u65b9\u6cd5\u51c6\u786e\u7387\u9ad82.5%\uff0cTPR\u548cTNR\u63d0\u9ad84%\u3002", "conclusion": "MixGAN\u5728\u5927\u89c4\u6a21\u7269\u8054\u7f51 - \u4e91\u73af\u5883\u4e2d\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4ee3\u7801\u516c\u5f00\u3002"}}
{"id": "2508.19278", "pdf": "https://arxiv.org/pdf/2508.19278", "abs": "https://arxiv.org/abs/2508.19278", "authors": ["Konur Tholl", "Mariam El Mezouar", "Ranwa Al Mallah"], "title": "Towards Production-Worthy Simulation for Autonomous Cyber Operations", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Simulated environments have proven invaluable in Autonomous Cyber Operations\n(ACO) where Reinforcement Learning (RL) agents can be trained without the\ncomputational overhead of emulation. These environments must accurately\nrepresent cybersecurity scenarios while producing the necessary signals to\nsupport RL training. In this study, we present a framework where we first\nextend CybORG's Cage Challenge 2 environment by implementing three new actions:\nPatch, Isolate, and Unisolate, to better represent the capabilities available\nto human operators in real-world settings. We then propose a design for agent\ndevelopment where we modify the reward signals and the agent's feature space to\nenhance training performance. To validate these modifications, we train DQN and\nPPO agents in the updated environment. Our study demonstrates that CybORG can\nbe extended with additional realistic functionality, while maintaining its\nability to generate informative training signals for RL agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6269\u5c55CybORG\u73af\u5883\u5e76\u4fee\u6539\u5956\u52b1\u4fe1\u53f7\u548c\u7279\u5f81\u7a7a\u95f4\u4ee5\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6027\u80fd\uff0c\u8bad\u7ec3DQN\u548cPPO\u4ee3\u7406\u9a8c\u8bc1\u4fee\u6539\u6709\u6548\u3002", "motivation": "\u6a21\u62df\u73af\u5883\u5bf9\u81ea\u4e3b\u7f51\u7edc\u64cd\u4f5c\u4e2d\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u8bad\u7ec3\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u9700\u51c6\u786e\u5448\u73b0\u7f51\u7edc\u5b89\u5168\u573a\u666f\u5e76\u4ea7\u751f\u652f\u6301\u8bad\u7ec3\u7684\u4fe1\u53f7\u3002", "method": "\u6269\u5c55CybORG\u7684Cage Challenge 2\u73af\u5883\uff0c\u5b9e\u73b0\u4e09\u4e2a\u65b0\u52a8\u4f5c\uff1b\u4fee\u6539\u5956\u52b1\u4fe1\u53f7\u548c\u4ee3\u7406\u7279\u5f81\u7a7a\u95f4\uff1b\u5728\u66f4\u65b0\u73af\u5883\u4e2d\u8bad\u7ec3DQN\u548cPPO\u4ee3\u7406\u3002", "result": "CybORG\u53ef\u6269\u5c55\u989d\u5916\u73b0\u5b9e\u529f\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e3a\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u751f\u6210\u4fe1\u606f\u8bad\u7ec3\u4fe1\u53f7\u7684\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u63d0\u5347\u8bad\u7ec3\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u6269\u5c55CybORG\u73af\u5883\u53ca\u76f8\u5173\u4fee\u6539\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2508.19466", "pdf": "https://arxiv.org/pdf/2508.19466", "abs": "https://arxiv.org/abs/2508.19466", "authors": ["Sourav Chakraborty", "Amit Kiran Rege", "Claire Monteleoni", "Lijun Chen"], "title": "Incentivized Lipschitz Bandits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study incentivized exploration in multi-armed bandit (MAB) settings with\ninfinitely many arms modeled as elements in continuous metric spaces. Unlike\nclassical bandit models, we consider scenarios where the decision-maker\n(principal) incentivizes myopic agents to explore beyond their greedy choices\nthrough compensation, but with the complication of reward drift--biased\nfeedback arising due to the incentives. We propose novel incentivized\nexploration algorithms that discretize the infinite arm space uniformly and\ndemonstrate that these algorithms simultaneously achieve sublinear cumulative\nregret and sublinear total compensation. Specifically, we derive regret and\ncompensation bounds of $\\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the\ncovering dimension of the metric space. Furthermore, we generalize our results\nto contextual bandits, achieving comparable performance guarantees. We validate\nour theoretical findings through numerical simulations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.19279", "pdf": "https://arxiv.org/pdf/2508.19279", "abs": "https://arxiv.org/abs/2508.19279", "authors": ["Gunjan Jalori", "Preetika Verma", "Sercan \u00d6 Ar\u0131k"], "title": "FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP", "summary": "Time series Forecasting with large languagemodels (LLMs) requires bridging\nnumericalpatterns and natural language. Effective fore-casting on LLM often\nrelies on extensive pre-processing and fine-tuning.Recent studiesshow that a\nfrozen LLM can rival specializedforecasters when supplied with a carefully\nen-gineered natural-language prompt, but craft-ing such a prompt for each task\nis itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt\noptimization framework thatutilizes an agentic system: a\nForecaster-agentgenerates forecasts using an initial prompt,which is then\nrefined by a refiner agent, in-formed by past outputs and retrieved\nanalogs.This adaptive prompting generalizes across do-mains using creative\nprompt templates andgenerates high-quality forecasts without inter-mediate code\ngeneration.Experiments onbenchmark datasets show improved accuracyover static\nprompting and retrieval-augmentedbaselines, approaching the performance\nofspecialized prompts.FLAIRR-TS providesa practical alternative to tuning,\nachievingstrong performance via its agentic approach toadaptive prompt\nrefinement and retrieval.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u6d4b\u8bd5\u65f6\u63d0\u793a\u4f18\u5316\u6846\u67b6FLAIRR - TS\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u901a\u8fc7\u4ee3\u7406\u7cfb\u7edf\u81ea\u9002\u5e94\u4f18\u5316\u63d0\u793a\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\uff0c\u662f\u8c03\u4f18\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709LLM\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4f9d\u8d56\u5927\u91cf\u9884\u5904\u7406\u548c\u5fae\u8c03\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u63d0\u793a\u56f0\u96be\u4e14\u4e34\u65f6\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165FLAIRR - TS\u6846\u67b6\uff0c\u5229\u7528\u4ee3\u7406\u7cfb\u7edf\uff0cForecaster - agent\u7528\u521d\u59cb\u63d0\u793a\u751f\u6210\u9884\u6d4b\uff0cRefiner agent\u6839\u636e\u8fc7\u53bb\u8f93\u51fa\u548c\u68c0\u7d22\u7c7b\u6bd4\u4f18\u5316\u63d0\u793a\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u9759\u6001\u63d0\u793a\u548c\u68c0\u7d22\u589e\u5f3a\u57fa\u7ebf\uff0c\u51c6\u786e\u6027\u63d0\u9ad8\uff0c\u63a5\u8fd1\u4e13\u4e1a\u63d0\u793a\u6027\u80fd\u3002", "conclusion": "FLAIRR - TS\u901a\u8fc7\u4ee3\u7406\u65b9\u5f0f\u8fdb\u884c\u81ea\u9002\u5e94\u63d0\u793a\u4f18\u5316\u548c\u68c0\u7d22\uff0c\u6027\u80fd\u5f3a\uff0c\u662f\u8c03\u4f18\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2508.19479", "pdf": "https://arxiv.org/pdf/2508.19479", "abs": "https://arxiv.org/abs/2508.19479", "authors": ["Serena Hughes", "Timothy Hamilton", "Tom Kolokotrones", "Eric J. Deeds"], "title": "DeepAtlas: a tool for effective manifold learning", "categories": ["cs.LG", "q-bio.QM"], "comment": "38 pages, 7 main text figures, 16 supplementary figures", "summary": "Manifold learning builds on the \"manifold hypothesis,\" which posits that data\nin high-dimensional datasets are drawn from lower-dimensional manifolds.\nCurrent tools generate global embeddings of data, rather than the local maps\nused to define manifolds mathematically. These tools also cannot assess whether\nthe manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas,\nan algorithm that generates lower-dimensional representations of the data's\nlocal neighborhoods, then trains deep neural networks that map between these\nlocal embeddings and the original data. Topological distortion is used to\ndetermine whether a dataset is drawn from a manifold and, if so, its\ndimensionality. Application to test datasets indicates that DeepAtlas can\nsuccessfully learn manifold structures. Interestingly, many real datasets,\nincluding single-cell RNA-sequencing, do not conform to the manifold\nhypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a\nmodel that can be used generatively and promises to allow the application of\npowerful tools from differential geometry to a variety of datasets.", "AI": {"tldr": "\u4ecb\u7ecdDeepAtlas\u7b97\u6cd5\uff0c\u5b83\u80fd\u5b66\u4e60\u6d41\u5f62\u7ed3\u6784\uff0c\u53d1\u73b0\u8bb8\u591a\u771f\u5b9e\u6570\u636e\u96c6\u4e0d\u7b26\u6d41\u5f62\u5047\u8bbe\uff0c\u7b26\u5408\u65f6\u53ef\u6784\u5efa\u751f\u6210\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6d41\u5f62\u5b66\u4e60\u5de5\u5177\u751f\u6210\u5168\u5c40\u5d4c\u5165\uff0c\u65e0\u6cd5\u8bc4\u4f30\u6d41\u5f62\u5047\u8bbe\u662f\u5426\u9002\u7528\u4e8e\u6570\u636e\u96c6\uff0c\u9700\u6539\u8fdb\u3002", "method": "DeepAtlas\u7b97\u6cd5\u751f\u6210\u6570\u636e\u5c40\u90e8\u90bb\u57df\u7684\u4f4e\u7ef4\u8868\u793a\uff0c\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6620\u5c04\u5c40\u90e8\u5d4c\u5165\u548c\u539f\u59cb\u6570\u636e\uff0c\u7528\u62d3\u6251\u5931\u771f\u5224\u65ad\u6570\u636e\u96c6\u662f\u5426\u6765\u81ea\u6d41\u5f62\u53ca\u7ef4\u5ea6\u3002", "result": "\u5e94\u7528\u4e8e\u6d4b\u8bd5\u6570\u636e\u96c6\u8868\u660eDeepAtlas\u80fd\u6210\u529f\u5b66\u4e60\u6d41\u5f62\u7ed3\u6784\uff0c\u8bb8\u591a\u771f\u5b9e\u6570\u636e\u96c6\u4e0d\u7b26\u6d41\u5f62\u5047\u8bbe\u3002", "conclusion": "\u5728\u6570\u636e\u6765\u81ea\u6d41\u5f62\u7684\u60c5\u51b5\u4e0b\uff0cDeepAtlas\u53ef\u6784\u5efa\u751f\u6210\u6a21\u578b\uff0c\u6709\u671b\u5c06\u5fae\u5206\u51e0\u4f55\u5de5\u5177\u5e94\u7528\u4e8e\u591a\u79cd\u6570\u636e\u96c6\u3002"}}
{"id": "2508.19281", "pdf": "https://arxiv.org/pdf/2508.19281", "abs": "https://arxiv.org/abs/2508.19281", "authors": ["Aoun E Muhammad", "Kin Choong Yow", "Jamel Baili", "Yongwon Cho", "Yunyoung Nam"], "title": "CORTEX: Composite Overlay for Risk Tiering and Exposure in Operational AI Systems", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As the deployment of Artificial Intelligence (AI) systems in high-stakes\nsectors - like healthcare, finance, education, justice, and infrastructure has\nincreased - the possibility and impact of failures of these systems have\nsignificantly evolved from being a theoretical possibility to practical\nrecurring, systemic risk. This paper introduces CORTEX (Composite Overlay for\nRisk Tiering and Exposure), a multi-layered risk scoring framework proposed to\nassess and score AI system vulnerabilities, developed on empirical analysis of\nover 1,200 incidents documented in the AI Incident Database (AIID), CORTEX\ncategorizes failure modes into 29 technical vulnerability groups. Each\nvulnerability is scored through a five-tier architecture that combines: (1)\nutility-adjusted Likelihood x Impact calculations; (2) governance + contextual\noverlays aligned with regulatory frameworks, such as the EU AI Act, NIST RMF,\nOECD principles; (3) technical surface scores, covering exposure vectors like\ndrift, traceability, and adversarial risk; (4) environmental and residual\nmodifiers tailored to context of where these systems are being deployed to use;\nand (5) a final layered assessment via Bayesian risk aggregation and Monte\nCarlo simulation to model volatility and long-tail risks. The resulting\ncomposite score can be operationalized across AI risk registers, model audits,\nconformity checks, and dynamic governance dashboards.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u8bc4\u4f30AI\u7cfb\u7edf\u6f0f\u6d1e\u7684\u591a\u5c42\u98ce\u9669\u8bc4\u5206\u6846\u67b6CORTEX\uff0c\u57fa\u4e8eAI\u4e8b\u4ef6\u6570\u636e\u5e93\u5b9e\u8bc1\u5206\u6790\uff0c\u5bf9\u6545\u969c\u6a21\u5f0f\u5206\u7c7b\u5e76\u901a\u8fc7\u4e94\u5c42\u67b6\u6784\u8bc4\u5206\uff0c\u7ed3\u679c\u53ef\u7528\u4e8e\u591a\u79cd\u98ce\u9669\u7ba1\u7406\u573a\u666f\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\u589e\u52a0\uff0c\u5176\u6545\u969c\u53ef\u80fd\u6027\u548c\u5f71\u54cd\u4ece\u7406\u8bba\u53d8\u4e3a\u5b9e\u9645\u7cfb\u7edf\u6027\u98ce\u9669\uff0c\u9700\u8981\u8bc4\u4f30\u548c\u8bc4\u5206AI\u7cfb\u7edf\u6f0f\u6d1e\u3002", "method": "\u57fa\u4e8eAI\u4e8b\u4ef6\u6570\u636e\u5e93\u4e2d1200\u591a\u8d77\u4e8b\u4ef6\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u5c06\u6545\u969c\u6a21\u5f0f\u5206\u4e3a29\u4e2a\u6280\u672f\u6f0f\u6d1e\u7ec4\uff0c\u901a\u8fc7\u4e94\u5c42\u67b6\u6784\u5bf9\u6bcf\u4e2a\u6f0f\u6d1e\u8bc4\u5206\uff0c\u5305\u62ec\u6548\u7528\u8c03\u6574\u8ba1\u7b97\u3001\u6cbb\u7406\u548c\u4e0a\u4e0b\u6587\u8986\u76d6\u3001\u6280\u672f\u8868\u9762\u8bc4\u5206\u3001\u73af\u5883\u548c\u6b8b\u4f59\u4fee\u6b63\u4ee5\u53ca\u8d1d\u53f6\u65af\u98ce\u9669\u805a\u5408\u548c\u8499\u7279\u5361\u7f57\u6a21\u62df\u7684\u6700\u7ec8\u5206\u5c42\u8bc4\u4f30\u3002", "result": "\u5f97\u5230\u7efc\u5408\u8bc4\u5206\uff0c\u53ef\u5728AI\u98ce\u9669\u767b\u8bb0\u518c\u3001\u6a21\u578b\u5ba1\u8ba1\u3001\u5408\u89c4\u68c0\u67e5\u548c\u52a8\u6001\u6cbb\u7406\u4eea\u8868\u76d8\u7b49\u573a\u666f\u5e94\u7528\u3002", "conclusion": "CORTEX\u6846\u67b6\u53ef\u6709\u6548\u8bc4\u4f30\u548c\u8bc4\u5206AI\u7cfb\u7edf\u6f0f\u6d1e\uff0c\u4e3aAI\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2508.19486", "pdf": "https://arxiv.org/pdf/2508.19486", "abs": "https://arxiv.org/abs/2508.19486", "authors": ["Wangyang Ying", "Nanxu Gong", "Dongjie Wang", "Xinyuan Wang", "Arun Vignesh Malarkkan", "Vivek Gupta", "Chandan K. Reddy", "Yanjie Fu"], "title": "Distribution Shift Aware Neural Tabular Learning", "categories": ["cs.LG"], "comment": null, "summary": "Tabular learning transforms raw features into optimized spaces for downstream\ntasks, but its effectiveness deteriorates under distribution shifts between\ntraining and testing data. We formalize this challenge as the Distribution\nShift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature\nTransformation (SAFT) framework to address it. SAFT reframes tabular learning\nfrom a discrete search task into a continuous representation-generation\nparadigm, enabling differentiable optimization over transformed feature sets.\nSAFT integrates three mechanisms to ensure robustness: (i) shift-resistant\nrepresentation via embedding decorrelation and sample reweighting, (ii)\nflatness-aware generation through suboptimal embedding averaging, and (iii)\nnormalization-based alignment between training and test distributions.\nExtensive experiments show that SAFT consistently outperforms prior tabular\nlearning methods in terms of robustness, effectiveness, and generalization\nability under diverse real-world distribution shifts.", "AI": {"tldr": "\u63d0\u51faSAFT\u6846\u67b6\u89e3\u51b3\u8868\u683c\u5b66\u4e60\u4e2d\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u8868\u683c\u5b66\u4e60\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\u504f\u79fb\u65f6\u6548\u679c\u53d8\u5dee\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51faSAFT\u6846\u67b6\uff0c\u5c06\u8868\u683c\u5b66\u4e60\u4ece\u79bb\u6563\u641c\u7d22\u8f6c\u4e3a\u8fde\u7eed\u8868\u793a\u751f\u6210\u8303\u5f0f\uff0c\u96c6\u6210\u4e09\u79cd\u673a\u5236\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "result": "\u5728\u591a\u79cd\u771f\u5b9e\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\uff0cSAFT\u5728\u9c81\u68d2\u6027\u3001\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u4f18\u4e8e\u5148\u524d\u8868\u683c\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "SAFT\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u5206\u5e03\u504f\u79fb\u8868\u683c\u5b66\u4e60\u95ee\u9898\uff0c\u5177\u6709\u66f4\u597d\u6027\u80fd\u3002"}}
{"id": "2508.19282", "pdf": "https://arxiv.org/pdf/2508.19282", "abs": "https://arxiv.org/abs/2508.19282", "authors": ["Ziqiang Cui", "Yunpeng Weng", "Xing Tang", "Peiyang Liu", "Shiwei Li", "Bowei He", "Jiamin Chen", "Xiuqiang He", "Chen Ma"], "title": "CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has emerged as a promising approach to\nenhance the timeliness of knowledge and the factual accuracy of responses in\nLarge Language Models (LLMs). However, the inclusion of excessive retrieved\ndocuments substantially increases the input length, leading to higher\ncomputational costs. Previous studies have attempted to compress retrieved\ndocuments into shorter texts before in-context integration, but such methods\noften compromise end-task performance. The lack of well-defined compression\ntargets forces many approaches to rely on fixed heuristics, which cannot\nguarantee that the compressed content will effectively support the end task. To\naddress these limitations, we propose CORE, a novel method designed to achieve\nlossless context compression for RAG. CORE employs reinforcement learning to\noptimize the compression process without relying on predefined compression\nlabels. Specifically, it utilizes end-task performance as a reward signal and\napplies Generalized Reinforcement Learning Policy Optimization (GRPO) to train\nthe compressor. This end-to-end training framework enables the compressor to\ngenerate summaries that maximize the accuracy of answers generated by the LLM.\nExtensive experiments on four datasets demonstrate the superiority of our\napproach. With a high compression ratio of 3\\%, our method not only avoids\nperformance degradation compared to prepending full documents across all\ndatasets but also improves the average Exact Match (EM) score by 3.3 points.\nThe code will be released soon.", "AI": {"tldr": "\u63d0\u51faCORE\u65b9\u6cd5\u5b9e\u73b0RAG\u65e0\u635f\u4e0a\u4e0b\u6587\u538b\u7f29\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709RAG\u68c0\u7d22\u6587\u6863\u8fc7\u957f\u589e\u52a0\u8ba1\u7b97\u6210\u672c\uff0c\u538b\u7f29\u65b9\u6cd5\u5f71\u54cd\u4efb\u52a1\u6027\u80fd\u4e14\u7f3a\u4e4f\u660e\u786e\u76ee\u6807\u3002", "method": "\u63d0\u51faCORE\u65b9\u6cd5\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\uff0c\u4ee5\u7aef\u4efb\u52a1\u6027\u80fd\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u7528GRPO\u8bad\u7ec3\u538b\u7f29\u673a\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u538b\u7f29\u73873%\uff0c\u907f\u514d\u6027\u80fd\u4e0b\u964d\uff0c\u5e73\u5747EM\u5206\u6570\u63d0\u9ad83.3\u5206\u3002", "conclusion": "CORE\u65b9\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0RAG\u65e0\u635f\u4e0a\u4e0b\u6587\u538b\u7f29\uff0c\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.19487", "pdf": "https://arxiv.org/pdf/2508.19487", "abs": "https://arxiv.org/abs/2508.19487", "authors": ["Wangyang Ying", "Jinghan Zhang", "Haoyue Bai", "Nanxu Gong", "Xinyuan Wang", "Kunpeng Liu", "Chandan K. Reddy", "Yanjie Fu"], "title": "Data-Efficient Symbolic Regression via Foundation Model Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Discovering interpretable mathematical equations from observed data (a.k.a.\nequation discovery or symbolic regression) is a cornerstone of scientific\ndiscovery, enabling transparent modeling of physical, biological, and economic\nsystems. While foundation models pre-trained on large-scale equation datasets\noffer a promising starting point, they often suffer from negative transfer and\npoor generalization when applied to small, domain-specific datasets. In this\npaper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer\nEmbeddings), a data-efficient fine-tuning framework that adapts foundation\nmodels for symbolic equation discovery in low-data regimes via distillation.\nEQUATE combines symbolic-numeric alignment with evaluator-guided embedding\noptimization, enabling a principled embedding-search-generation paradigm. Our\napproach reformulates discrete equation search as a continuous optimization\ntask in a shared embedding space, guided by data-equation fitness and\nsimplicity. Experiments across three standard public benchmarks (Feynman,\nStrogatz, and black-box datasets) demonstrate that EQUATE consistently\noutperforms state-of-the-art baselines in both accuracy and robustness, while\npreserving low complexity and fast inference. These results highlight EQUATE as\na practical and generalizable solution for data-efficient symbolic regression\nin foundation model distillation settings.", "AI": {"tldr": "\u63d0\u51faEQUATE\u6846\u67b6\u7528\u4e8e\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u7b26\u53f7\u65b9\u7a0b\u53d1\u73b0\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u5c0f\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\u5b58\u5728\u8d1f\u8fc1\u79fb\u548c\u6cdb\u5316\u6027\u5dee\u95ee\u9898\uff0c\u9700\u6570\u636e\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\u3002", "method": "EQUATE\u7ed3\u5408\u7b26\u53f7 - \u6570\u503c\u5bf9\u9f50\u4e0e\u8bc4\u4f30\u5668\u5f15\u5bfc\u7684\u5d4c\u5165\u4f18\u5316\uff0c\u5c06\u79bb\u6563\u65b9\u7a0b\u641c\u7d22\u8f6c\u5316\u4e3a\u5171\u4eab\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8fde\u7eed\u4f18\u5316\u4efb\u52a1\u3002", "result": "\u5728\u4e09\u4e2a\u6807\u51c6\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEQUATE\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u4e14\u590d\u6742\u5ea6\u4f4e\u3001\u63a8\u7406\u5feb\u3002", "conclusion": "EQUATE\u662f\u57fa\u7840\u6a21\u578b\u84b8\u998f\u8bbe\u7f6e\u4e0b\u6570\u636e\u9ad8\u6548\u7b26\u53f7\u56de\u5f52\u7684\u5b9e\u7528\u4e14\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19286", "pdf": "https://arxiv.org/pdf/2508.19286", "abs": "https://arxiv.org/abs/2508.19286", "authors": ["Zhan Shi", "Yefeng Yuan", "Yuhong Liu", "Liang Cheng", "Yi Fang"], "title": "RL-Finetuned LLMs for Privacy-Preserving Synthetic Rewriting", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "The performance of modern machine learning systems depends on access to\nlarge, high-quality datasets, often sourced from user-generated content or\nproprietary, domain-specific corpora. However, these rich datasets inherently\ncontain sensitive personal information, raising significant concerns about\nprivacy, data security, and compliance with regulatory frameworks. While\nconventional anonymization techniques can remove explicit identifiers, such\nremoval may result in performance drop in downstream machine learning tasks.\nMore importantly, simple anonymization may not be effective against inference\nattacks that exploit implicit signals such as writing style, topical focus, or\ndemographic cues, highlighting the need for more robust privacy safeguards\nduring model training. To address the challenging issue of balancing user\nprivacy and data utility, we propose a reinforcement learning framework that\nfine-tunes a large language model (LLM) using a composite reward function that\njointly optimizes for explicit and implicit privacy, semantic fidelity, and\noutput diversity. To effectively capture population level regularities, the\nprivacy reward combines semantic cues with structural patterns derived from a\nminimum spanning tree (MST) over latent representations. By modeling these\nprivacy-sensitive signals in their distributional context, the proposed\napproach guides the model to generate synthetic rewrites that preserve utility\nwhile mitigating privacy risks. Empirical results show that the proposed method\nsignificantly enhances author obfuscation and privacy metrics without degrading\nsemantic quality, providing a scalable and model-agnostic solution for privacy\npreserving data generation in the era of large language models.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9\u5e73\u8861\u7528\u6237\u9690\u79c1\u4e0e\u6570\u636e\u6548\u7528\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u63d0\u5347\u9690\u79c1\u6307\u6807\u4e14\u4e0d\u964d\u4f4e\u8bed\u4e49\u8d28\u91cf\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4f9d\u8d56\u542b\u654f\u611f\u4fe1\u606f\u7684\u6570\u636e\u96c6\uff0c\u4f20\u7edf\u533f\u540d\u5316\u6280\u672f\u6709\u6027\u80fd\u4e0b\u964d\u548c\u6613\u53d7\u63a8\u7406\u653b\u51fb\u7684\u95ee\u9898\uff0c\u9700\u66f4\u5f3a\u5927\u9690\u79c1\u4fdd\u62a4\u63aa\u65bd\u3002", "method": "\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u590d\u5408\u5956\u52b1\u51fd\u6570\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u9690\u79c1\u5956\u52b1\u7ed3\u5408\u8bed\u4e49\u7ebf\u7d22\u4e0e\u6700\u5c0f\u751f\u6210\u6811\u7ed3\u6784\u6a21\u5f0f\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4f5c\u8005\u6df7\u6dc6\u548c\u9690\u79c1\u6307\u6807\uff0c\u4e0d\u964d\u4f4e\u8bed\u4e49\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\u4fdd\u62a4\u9690\u79c1\u7684\u6570\u636e\u751f\u6210\u53ef\u6269\u5c55\u4e14\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19488", "pdf": "https://arxiv.org/pdf/2508.19488", "abs": "https://arxiv.org/abs/2508.19488", "authors": ["Xavier Cadet", "Simona Boboila", "Sie Hendrata Dharmawan", "Alina Oprea", "Peter Chin"], "title": "PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Accepted at GameSec 2025", "summary": "Cyber defense requires automating defensive decision-making under stealthy,\ndeceptive, and continuously evolving adversarial strategies. The FlipIt game\nprovides a foundational framework for modeling interactions between a defender\nand an advanced adversary that compromises a system without being immediately\ndetected. In FlipIt, the attacker and defender compete to control a shared\nresource by performing a Flip action and paying a cost. However, the existing\nFlipIt frameworks rely on a small number of heuristics or specialized learning\ntechniques, which can lead to brittleness and the inability to adapt to new\nattacks. To address these limitations, we introduce PoolFlip, a multi-agent gym\nenvironment that extends the FlipIt game to allow efficient learning for\nattackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent\nreinforcement learning (MARL) approach that leverages population-based training\nto train defender agents equipped to generalize against a range of unknown,\npotentially adaptive opponents. Our empirical results suggest that Flip-PSRO\ndefenders are $2\\times$ more effective than baselines to generalize to a\nheuristic attack not exposed in training. In addition, our newly designed\nownership-based utility functions ensure that Flip-PSRO defenders maintain a\nhigh level of control while optimizing performance.", "AI": {"tldr": "\u5f15\u5165PoolFlip\u73af\u5883\u6269\u5c55FlipIt\u6e38\u620f\uff0c\u63d0\u51faFlip - PSRO\u65b9\u6cd5\u8bad\u7ec3\u9632\u5fa1\u8005\u4ee3\u7406\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u9632\u5fa1\u8005\u6cdb\u5316\u6548\u679c\u6bd4\u57fa\u7ebf\u9ad82\u500d\uff0c\u4e14\u65b0\u6548\u7528\u51fd\u6570\u53ef\u4fdd\u8bc1\u63a7\u5236\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709FlipIt\u6846\u67b6\u4f9d\u8d56\u5c11\u91cf\u542f\u53d1\u5f0f\u6216\u4e13\u95e8\u5b66\u4e60\u6280\u672f\uff0c\u5b58\u5728\u8106\u6027\u4e14\u65e0\u6cd5\u9002\u5e94\u65b0\u653b\u51fb\u3002", "method": "\u5f15\u5165PoolFlip\u591a\u667a\u80fd\u4f53gym\u73af\u5883\uff0c\u63d0\u51faFlip - PSRO\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u57fa\u4e8e\u79cd\u7fa4\u7684\u8bad\u7ec3\u3002", "result": "Flip - PSRO\u9632\u5fa1\u8005\u5728\u6cdb\u5316\u5230\u8bad\u7ec3\u4e2d\u672a\u51fa\u73b0\u7684\u542f\u53d1\u5f0f\u653b\u51fb\u65f6\u6bd4\u57fa\u7ebf\u6709\u65482\u500d\uff0c\u65b0\u6548\u7528\u51fd\u6570\u786e\u4fdd\u9632\u5fa1\u8005\u4fdd\u6301\u9ad8\u63a7\u5236\u6c34\u5e73\u5e76\u4f18\u5316\u6027\u80fd\u3002", "conclusion": "Flip - PSRO\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u9632\u5fa1\u8005\u5bf9\u672a\u77e5\u3001\u6f5c\u5728\u81ea\u9002\u5e94\u5bf9\u624b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.19287", "pdf": "https://arxiv.org/pdf/2508.19287", "abs": "https://arxiv.org/abs/2508.19287", "authors": ["Zhuotao Lian", "Weiyu Wang", "Qingkui Zeng", "Toru Nakanishi", "Teruaki Kitasuka", "Chunhua Su"], "title": "Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are widely deployed in applications that accept\nuser-submitted content, such as uploaded documents or pasted text, for tasks\nlike summarization and question answering. In this paper, we identify a new\nclass of attacks, prompt in content injection, where adversarial instructions\nare embedded in seemingly benign inputs. When processed by the LLM, these\nhidden prompts can manipulate outputs without user awareness or system\ncompromise, leading to biased summaries, fabricated claims, or misleading\nsuggestions. We demonstrate the feasibility of such attacks across popular\nplatforms, analyze their root causes including prompt concatenation and\ninsufficient input isolation, and discuss mitigation strategies. Our findings\nreveal a subtle yet practical threat in real-world LLM workflows.", "AI": {"tldr": "\u672c\u6587\u8bc6\u522b\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5185\u5bb9\u6ce8\u5165\u653b\u51fb\uff0c\u8bc1\u660e\u5176\u53ef\u884c\u6027\uff0c\u5206\u6790\u539f\u56e0\u5e76\u8ba8\u8bba\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u5904\u7406\u7528\u6237\u63d0\u4ea4\u5185\u5bb9\uff0c\u8bc6\u522b\u5176\u4e2d\u65b0\u7684\u653b\u51fb\u7c7b\u578b\u3002", "method": "\u8bc1\u660e\u653b\u51fb\u5728\u6d41\u884c\u5e73\u53f0\u7684\u53ef\u884c\u6027\uff0c\u5206\u6790\u653b\u51fb\u7684\u6839\u672c\u539f\u56e0\u3002", "result": "\u53d1\u73b0\u5185\u5bb9\u6ce8\u5165\u653b\u51fb\u53ef\u5728\u7528\u6237\u65e0\u611f\u77e5\u548c\u7cfb\u7edf\u672a\u88ab\u653b\u7834\u65f6\u64cd\u7eb5\u8f93\u51fa\u3002", "conclusion": "\u5185\u5bb9\u6ce8\u5165\u653b\u51fb\u662f\u73b0\u5b9e\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u4f5c\u6d41\u91cc\u9690\u853d\u4e14\u5b9e\u9645\u5b58\u5728\u7684\u5a01\u80c1\u3002"}}
{"id": "2508.19506", "pdf": "https://arxiv.org/pdf/2508.19506", "abs": "https://arxiv.org/abs/2508.19506", "authors": ["Zhiyi Kuang", "Ryan Rong", "YuCheng Yuan", "Allen Nie"], "title": "Learning Game-Playing Agents with Generative Code Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Workshop on Programmatic Representations for Agent\n  Learning, Vancouver, Canada", "summary": "We present a generative optimization approach for learning game-playing\nagents, where policies are represented as Python programs and refined using\nlarge language models (LLMs). Our method treats decision-making policies as\nself-evolving code, with current observation as input and an in-game action as\noutput, enabling agents to self-improve through execution traces and natural\nlanguage feedback with minimal human intervention. Applied to Atari games, our\ngame-playing Python program achieves performance competitive with deep\nreinforcement learning (RL) baselines while using significantly less training\ntime and much fewer environment interactions. This work highlights the promise\nof programmatic policy representations for building efficient, adaptable agents\ncapable of complex, long-horizon reasoning.", "AI": {"tldr": "\u63d0\u51fa\u7528\u751f\u6210\u5f0f\u4f18\u5316\u65b9\u6cd5\u5b66\u4e60\u6e38\u620f\u4ee3\u7406\uff0c\u4ee5Python\u7a0b\u5e8f\u8868\u793a\u7b56\u7565\u5e76\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u5316\uff0c\u5728Atari\u6e38\u620f\u4e0a\u8868\u73b0\u4f73\u3002", "motivation": "\u63a2\u7d22\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u4e14\u80fd\u8fdb\u884c\u590d\u6742\u957f\u89c6\u91ce\u63a8\u7406\u7684\u6e38\u620f\u4ee3\u7406\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u5c06\u51b3\u7b56\u7b56\u7565\u89c6\u4e3a\u81ea\u8fdb\u5316\u4ee3\u7801\uff0c\u4ee5\u5f53\u524d\u89c2\u5bdf\u4e3a\u8f93\u5165\u3001\u6e38\u620f\u5185\u52a8\u4f5c\u4e3a\u8f93\u51fa\uff0c\u5229\u7528\u6267\u884c\u8f68\u8ff9\u548c\u81ea\u7136\u8bed\u8a00\u53cd\u9988\uff0c\u501f\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u4ee5Python\u7a0b\u5e8f\u8868\u793a\u7684\u7b56\u7565\u3002", "result": "\u5728Atari\u6e38\u620f\u4e2d\uff0c\u8be5Python\u7a0b\u5e8f\u8fbe\u5230\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e14\u8bad\u7ec3\u65f6\u95f4\u663e\u8457\u51cf\u5c11\u3001\u73af\u5883\u4ea4\u4e92\u66f4\u5c11\u3002", "conclusion": "\u57fa\u4e8e\u7a0b\u5e8f\u7684\u7b56\u7565\u8868\u793a\u6cd5\u5728\u6784\u5efa\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u4ee3\u7406\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.19288", "pdf": "https://arxiv.org/pdf/2508.19288", "abs": "https://arxiv.org/abs/2508.19288", "authors": ["Kyohei Shiomi", "Zhuotao Lian", "Toru Nakanishi", "Teruaki Kitasuka"], "title": "Tricking LLM-Based NPCs into Spilling Secrets", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used to generate dynamic\ndialogue for game NPCs. However, their integration raises new security\nconcerns. In this study, we examine whether adversarial prompt injection can\ncause LLM-based NPCs to reveal hidden background secrets that are meant to\nremain undisclosed.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6297\u6027\u63d0\u793a\u6ce8\u5165\u662f\u5426\u4f1a\u4f7f\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6e38\u620fNPC\u6cc4\u9732\u9690\u85cf\u80cc\u666f\u79d8\u5bc6", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u6e38\u620fNPC\u751f\u6210\u52a8\u6001\u5bf9\u8bdd\u5e26\u6765\u65b0\u5b89\u5168\u62c5\u5fe7", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2508.19554", "pdf": "https://arxiv.org/pdf/2508.19554", "abs": "https://arxiv.org/abs/2508.19554", "authors": ["Haruki Yonekura", "Ren Ozeki", "Tatsuya Amano", "Hamada Rizk", "Hirozumi Yamaguchi"], "title": "MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data", "categories": ["cs.LG"], "comment": "Accepted to The 33rd ACM International Conference on Advances in\n  Geographic Information Systems(SIGSPATIAL '25) as a short paper in the Short\n  Paper Track", "summary": "Modern mobility platforms have stored vast streams of GPS trajectories,\ntemporal metadata, free-form textual notes, and other unstructured data.\nPrivacy statutes such as the GDPR require that any individual's contribution be\nunlearned on demand, yet retraining deep models from scratch for every request\nis untenable. We introduce MobText-SISA, a scalable machine-unlearning\nframework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)\ntraining to heterogeneous spatio-temporal data. MobText-SISA first embeds each\ntrip's numerical and linguistic features into a shared latent space, then\nemploys similarity-aware clustering to distribute samples across shards so that\nfuture deletions touch only a single constituent model while preserving\ninter-shard diversity. Each shard is trained incrementally; at inference time,\nconstituent predictions are aggregated to yield the output. Deletion requests\ntrigger retraining solely of the affected shard from its last valid checkpoint,\nguaranteeing exact unlearning. Experiments on a ten-month real-world mobility\nlog demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,\nand (ii) consistently outperforms random sharding in both error and convergence\nspeed. These results establish MobText-SISA as a practical foundation for\nprivacy-compliant analytics on multimodal mobility data at urban scale.", "AI": {"tldr": "\u63d0\u51faMobText - SISA\u6846\u67b6\u7528\u4e8e\u591a\u6a21\u6001\u79fb\u52a8\u6027\u6570\u636e\u9690\u79c1\u5408\u89c4\u5206\u6790\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3\u79fb\u52a8\u5e73\u53f0\u6709\u5927\u91cf\u975e\u7ed3\u6784\u5316\u6570\u636e\uff0cGDPR\u8981\u6c42\u6309\u9700\u9057\u5fd8\u4e2a\u4eba\u8d21\u732e\uff0c\u4f46\u4ece\u5934\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u4e0d\u53ef\u884c\u3002", "method": "\u5c06MobText - SISA\u6846\u67b6\u7684SISA\u8bad\u7ec3\u6269\u5c55\u5230\u5f02\u6784\u65f6\u7a7a\u6570\u636e\uff0c\u5d4c\u5165\u7279\u5f81\u3001\u76f8\u4f3c\u6027\u805a\u7c7b\u5206\u6837\u672c\u3001\u589e\u91cf\u8bad\u7ec3\u3001\u805a\u5408\u9884\u6d4b\uff0c\u5220\u9664\u8bf7\u6c42\u65f6\u4ec5\u91cd\u65b0\u8bad\u7ec3\u53d7\u5f71\u54cd\u5206\u7247\u3002", "result": "\u5728\u5341\u4e2a\u6708\u771f\u5b9e\u79fb\u52a8\u65e5\u5fd7\u5b9e\u9a8c\u4e2d\uff0c\u7ef4\u6301\u57fa\u7ebf\u9884\u6d4b\u7cbe\u5ea6\uff0c\u8bef\u5dee\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u968f\u673a\u5206\u7247\u3002", "conclusion": "MobText - SISA\u53ef\u4f5c\u4e3a\u57ce\u5e02\u89c4\u6a21\u591a\u6a21\u6001\u79fb\u52a8\u6027\u6570\u636e\u9690\u79c1\u5408\u89c4\u5206\u6790\u7684\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2508.19289", "pdf": "https://arxiv.org/pdf/2508.19289", "abs": "https://arxiv.org/abs/2508.19289", "authors": ["Tai Inui", "Steven Oh", "Magdeline Kuan"], "title": "Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages", "summary": "We present an unsupervised slide-quality assessment pipeline that combines\nseven expert-inspired visual-design metrics (whitespace, colorfulness, edge\ndensity, brightness contrast, text density, color harmony, layout balance) with\nCLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate\npresentation slides. Trained on 12k professional lecture slides and evaluated\non six academic talks (115 slides), our method achieved Pearson correlations up\nto 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores\nfrom leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude\nSonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual\nratings, discriminant validity against speaker-delivery scores, and exploratory\nalignment with overall impressions. Our results show that augmenting low-level\ndesign cues with multimodal embeddings closely approximates audience\nperceptions of slide quality, enabling scalable, objective feedback in real\ntime.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u76d1\u7763\u5e7b\u706f\u7247\u8d28\u91cf\u8bc4\u4f30\u7ba1\u9053\uff0c\u7ed3\u5408\u89c6\u89c9\u8bbe\u8ba1\u6307\u6807\u4e0eCLIP - ViT\u5d4c\u5165\uff0c\u7528\u5b64\u7acb\u68ee\u6797\u5f02\u5e38\u8bc4\u5206\u8bc4\u4f30\uff0c\u6548\u679c\u4f18\u4e8e\u9886\u5148\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u5b9e\u65f6\u63d0\u4f9b\u53cd\u9988\u3002", "motivation": "\u5b9e\u73b0\u5bf9\u6f14\u793a\u5e7b\u706f\u7247\u8d28\u91cf\u7684\u53ef\u6269\u5c55\u3001\u5ba2\u89c2\u8bc4\u4f30\uff0c\u63d0\u4f9b\u5b9e\u65f6\u53cd\u9988\u3002", "method": "\u7ed3\u5408\u4e03\u4e2a\u4e13\u5bb6\u8bbe\u8ba1\u7684\u89c6\u89c9\u8bbe\u8ba1\u6307\u6807\u548cCLIP - ViT\u5d4c\u5165\uff0c\u4f7f\u7528\u57fa\u4e8e\u5b64\u7acb\u68ee\u6797\u7684\u5f02\u5e38\u8bc4\u5206\u8bc4\u4f30\u5e7b\u706f\u7247\u3002\u572812k\u4e13\u4e1a\u8bb2\u5ea7\u5e7b\u706f\u7247\u4e0a\u8bad\u7ec3\uff0c\u5728\u516d\u573a\u5b66\u672f\u62a5\u544a\uff08115\u5f20\u5e7b\u706f\u7247\uff09\u4e0a\u8bc4\u4f30\u3002", "result": "\u4e0e\u4eba\u7c7b\u89c6\u89c9\u8d28\u91cf\u8bc4\u7ea7\u7684\u76ae\u5c14\u900a\u76f8\u5173\u6027\u9ad8\u8fbe0.83\uff0c\u6bd4\u9886\u5148\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5f3a1.79 - 3.23\u500d\uff0c\u8bc1\u660e\u4e86\u6536\u655b\u6548\u5ea6\u3001\u5224\u522b\u6548\u5ea6\u548c\u4e0e\u6574\u4f53\u5370\u8c61\u7684\u63a2\u7d22\u6027\u4e00\u81f4\u6027\u3002", "conclusion": "\u7528\u591a\u6a21\u6001\u5d4c\u5165\u589e\u5f3a\u4f4e\u7ea7\u8bbe\u8ba1\u7ebf\u7d22\u80fd\u8fd1\u4f3c\u89c2\u4f17\u5bf9\u5e7b\u706f\u7247\u8d28\u91cf\u7684\u611f\u77e5\uff0c\u53ef\u5b9e\u65f6\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u5ba2\u89c2\u7684\u53cd\u9988\u3002"}}
{"id": "2508.19290", "pdf": "https://arxiv.org/pdf/2508.19290", "abs": "https://arxiv.org/abs/2508.19290", "authors": ["Alexandros Gkillas", "Ioulia Kapsali", "Nikos Piperigkos", "Aris S. Lalos"], "title": "Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "LiDAR-based segmentation is essential for reliable perception in autonomous\nvehicles, yet modern segmentation networks are highly susceptible to\nadversarial attacks that can compromise safety. Most existing defenses are\ndesigned for networks operating directly on raw 3D point clouds and rely on\nlarge, computationally intensive generative models. However, many\nstate-of-the-art LiDAR segmentation pipelines operate on more efficient 2D\nrange view representations. Despite their widespread adoption, dedicated\nlightweight adversarial defenses for this domain remain largely unexplored. We\nintroduce an efficient model-based purification framework tailored for\nadversarial defense in 2D range-view LiDAR segmentation. We propose a direct\nattack formulation in the range-view domain and develop an explainable\npurification network based on a mathematical justified optimization problem,\nachieving strong adversarial resilience with minimal computational overhead.\nOur method achieves competitive performance on open benchmarks, consistently\noutperforming generative and adversarial training baselines. More importantly,\nreal-world deployment on a demo vehicle demonstrates the framework's ability to\ndeliver accurate operation in practical autonomous driving scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8e2D\u8ddd\u79bb\u89c6\u56fe\u6fc0\u5149\u96f7\u8fbe\u5206\u5272\u5bf9\u6297\u9632\u5fa1\u7684\u9ad8\u6548\u51c0\u5316\u6846\u67b6\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u4ee3\u5206\u5272\u7f51\u7edc\u6613\u53d7\u5bf9\u6297\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u591a\u9488\u5bf9\u539f\u59cb3D\u70b9\u4e91\uff0c2D\u8ddd\u79bb\u89c6\u56fe\u7684\u8f7b\u91cf\u7ea7\u9632\u5fa1\u65b9\u6cd5\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u8ddd\u79bb\u89c6\u56fe\u57df\u7684\u76f4\u63a5\u653b\u51fb\u516c\u5f0f\uff0c\u5f00\u53d1\u57fa\u4e8e\u6570\u5b66\u4f18\u5316\u95ee\u9898\u7684\u53ef\u89e3\u91ca\u51c0\u5316\u7f51\u7edc\u3002", "result": "\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u751f\u6210\u5f0f\u548c\u5bf9\u6297\u8bad\u7ec3\u57fa\u7ebf\uff0c\u5728\u6f14\u793a\u8f66\u8f86\u7684\u5b9e\u9645\u90e8\u7f72\u4e2d\u80fd\u51c6\u786e\u8fd0\u884c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u4ee5\u6700\u5c0f\u8ba1\u7b97\u5f00\u9500\u5b9e\u73b0\u5f3a\u5927\u7684\u5bf9\u6297\u6062\u590d\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u3002"}}
{"id": "2508.19564", "pdf": "https://arxiv.org/pdf/2508.19564", "abs": "https://arxiv.org/abs/2508.19564", "authors": ["Yuhang Liu", "Tao Li", "Zhehao Huang", "Zuopeng Yang", "Xiaolin Huang"], "title": "Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning large-scale pre-trained models with limited data presents\nsignificant challenges for generalization. While Sharpness-Aware Minimization\n(SAM) has proven effective in improving generalization by seeking flat minima,\nits substantial extra memory and computation overhead make it impractical for\nlarge models. Integrating SAM with parameter-efficient fine-tuning methods like\nLow-Rank Adaptation (LoRA) is a promising direction. However, we find that\ndirectly applying SAM to LoRA parameters limits the sharpness optimization to a\nrestricted subspace, hindering its effectiveness. To address this limitation,\nwe propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an\nauxiliary LoRA module to model SAM's adversarial weight perturbations. It\ndecouples SAM's weight perturbations from LoRA optimization: the primary LoRA\nmodule adapts to specific tasks via standard gradient descent, while the\nauxiliary module captures the sharpness of the loss landscape through gradient\nascent. Such dual-module design enables Bi-LoRA to capture broader sharpness\nfor achieving flatter minima while remaining memory-efficient. Another\nimportant benefit is that the dual design allows for simultaneous optimization\nand perturbation, eliminating SAM's doubled training costs. Extensive\nexperiments across diverse tasks and architectures demonstrate Bi-LoRA's\nefficiency and effectiveness in enhancing generalization.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u5411\u4f4e\u79e9\u81ea\u9002\u5e94\uff08Bi - LoRA\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408SAM\u4e0eLoRA\uff0c\u89e3\u51b3SAM\u5e94\u7528\u4e8eLoRA\u7684\u5c40\u9650\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u9ad8\u6548\u4e14\u6709\u6548\u3002", "motivation": "\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u5fae\u8c03\u65f6\u6cdb\u5316\u6027\u5dee\uff0cSAM\u867d\u80fd\u6539\u5584\u4f46\u5f00\u9500\u5927\uff0c\u76f4\u63a5\u7528\u4e8eLoRA\u53c2\u6570\u6548\u679c\u53d7\u9650\u3002", "method": "\u63d0\u51faBi - LoRA\uff0c\u5f15\u5165\u8f85\u52a9LoRA\u6a21\u5757\u6a21\u62dfSAM\u7684\u5bf9\u6297\u6027\u6743\u91cd\u6270\u52a8\uff0c\u4e3b\u6a21\u5757\u7528\u6807\u51c6\u68af\u5ea6\u4e0b\u964d\uff0c\u8f85\u52a9\u6a21\u5757\u7528\u68af\u5ea6\u4e0a\u5347\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660eBi - LoRA\u5728\u63d0\u5347\u6cdb\u5316\u6027\u4e0a\u9ad8\u6548\u4e14\u6709\u6548\u3002", "conclusion": "Bi - LoRA\u80fd\u5728\u4fdd\u6301\u5185\u5b58\u9ad8\u6548\u7684\u540c\u65f6\u6355\u6349\u66f4\u5e7f\u6cdb\u7684\u9510\u5ea6\u4ee5\u5b9e\u73b0\u66f4\u5e73\u5766\u7684\u6700\u5c0f\u503c\uff0c\u8fd8\u6d88\u9664\u4e86SAM\u7684\u53cc\u500d\u8bad\u7ec3\u6210\u672c\u3002"}}
{"id": "2508.19292", "pdf": "https://arxiv.org/pdf/2508.19292", "abs": "https://arxiv.org/abs/2508.19292", "authors": ["Xi Wang", "Songlei Jian", "Shasha Li", "Xiaopeng Li", "Bin Ji", "Jun Ma", "Xiaodong Liu", "Jing Wang", "Feilong Bao", "Jianfeng Zhang", "Baosheng Wang", "Jie Yu"], "title": "Stand on The Shoulders of Giants: Building JailExpert from Previous Attack Experience", "categories": ["cs.CR", "cs.AI"], "comment": "18 pages, EMNLP 2025 Main Conference", "summary": "Large language models (LLMs) generate human-aligned content under certain\nsafety constraints. However, the current known technique ``jailbreak prompt''\ncan circumvent safety-aligned measures and induce LLMs to output malicious\ncontent. Research on Jailbreaking can help identify vulnerabilities in LLMs and\nguide the development of robust security frameworks. To circumvent the issue of\nattack templates becoming obsolete as models evolve, existing methods adopt\niterative mutation and dynamic optimization to facilitate more automated\njailbreak attacks. However, these methods face two challenges: inefficiency and\nrepetitive optimization, as they overlook the value of past attack experiences.\nTo better integrate past attack experiences to assist current jailbreak\nattempts, we propose the \\textbf{JailExpert}, an automated jailbreak framework,\nwhich is the first to achieve a formal representation of experience structure,\ngroup experiences based on semantic drift, and support the dynamic updating of\nthe experience pool. Extensive experiments demonstrate that JailExpert\nsignificantly improves both attack effectiveness and efficiency. Compared to\nthe current state-of-the-art black-box jailbreak methods, JailExpert achieves\nan average increase of 17\\% in attack success rate and 2.7 times improvement in\nattack efficiency. Our implementation is available at\n\\href{https://github.com/xiZAIzai/JailExpert}{XiZaiZai/JailExpert}", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u81ea\u52a8\u5316\u8d8a\u72f1\u6846\u67b6JailExpert\uff0c\u6574\u5408\u8fc7\u5f80\u653b\u51fb\u7ecf\u9a8c\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u663e\u8457\u63d0\u5347\u653b\u51fb\u6548\u679c\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u8d8a\u72f1\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u4f4e\u548c\u91cd\u590d\u4f18\u5316\u95ee\u9898\uff0c\u672a\u5145\u5206\u5229\u7528\u8fc7\u5f80\u653b\u51fb\u7ecf\u9a8c\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u6765\u6574\u5408\u7ecf\u9a8c\u8f85\u52a9\u8d8a\u72f1\u5c1d\u8bd5\u3002", "method": "\u63d0\u51faJailExpert\u6846\u67b6\uff0c\u5b9e\u73b0\u7ecf\u9a8c\u7ed3\u6784\u7684\u5f62\u5f0f\u5316\u8868\u793a\uff0c\u57fa\u4e8e\u8bed\u4e49\u6f02\u79fb\u5bf9\u7ecf\u9a8c\u5206\u7ec4\uff0c\u652f\u6301\u7ecf\u9a8c\u6c60\u52a8\u6001\u66f4\u65b0\u3002", "result": "\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u9ed1\u76d2\u8d8a\u72f1\u65b9\u6cd5\u76f8\u6bd4\uff0c\u653b\u51fb\u6210\u529f\u7387\u5e73\u5747\u63d0\u9ad817%\uff0c\u653b\u51fb\u6548\u7387\u63d0\u53472.7\u500d\u3002", "conclusion": "JailExpert\u6846\u67b6\u80fd\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u653b\u51fb\u7684\u6548\u679c\u548c\u6548\u7387\u3002"}}
{"id": "2508.19567", "pdf": "https://arxiv.org/pdf/2508.19567", "abs": "https://arxiv.org/abs/2508.19567", "authors": ["Sheryl Mathew", "N Harshit"], "title": "Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In reinforcement learning with human feedback (RLHF), reward models can\nefficiently learn and amplify latent biases within multimodal datasets, which\ncan lead to imperfect policy optimization through flawed reward signals and\ndecreased fairness. Bias mitigation studies have often applied passive\nconstraints, which can fail under causal confounding. Here, we present a\ncounterfactual reward model that introduces causal inference with multimodal\nrepresentation learning to provide an unsupervised, bias-resilient reward\nsignal. The heart of our contribution is the Counterfactual Trust Score, an\naggregated score consisting of four components: (1) counterfactual shifts that\ndecompose political framing bias from topical bias; (2) reconstruction\nuncertainty during counterfactual perturbations; (3) demonstrable violations of\nfairness rules for each protected attribute; and (4) temporal reward shifts\naligned with dynamic trust measures. We evaluated the framework on a multimodal\nfake versus true news dataset, which exhibits framing bias, class imbalance,\nand distributional drift. Following methodologies similar to unsupervised drift\ndetection from representation-based distances [1] and temporal robustness\nbenchmarking in language models [2], we also inject synthetic bias across\nsequential batches to test robustness. The resulting system achieved an\naccuracy of 89.12% in fake news detection, outperforming the baseline reward\nmodels. More importantly, it reduced spurious correlations and unfair\nreinforcement signals. This pipeline outlines a robust and interpretable\napproach to fairness-aware RLHF, offering tunable bias reduction thresholds and\nincreasing reliability in dynamic real-time policy making.", "AI": {"tldr": "\u63d0\u51fa\u53cd\u4e8b\u5b9e\u5956\u52b1\u6a21\u578b\u7528\u4e8e\u516c\u5e73\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u4e0e\u4eba\u7c7b\u53cd\u9988\uff0c\u5728\u5047\u65b0\u95fb\u68c0\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u51cf\u5c11\u865a\u5047\u5173\u8054\u548c\u4e0d\u516c\u5e73\u4fe1\u53f7\u3002", "motivation": "\u5956\u52b1\u6a21\u578b\u4f1a\u653e\u5927\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e2d\u6f5c\u5728\u504f\u5dee\uff0c\u5bfc\u81f4\u7b56\u7565\u4f18\u5316\u4e0d\u5b8c\u5584\u548c\u516c\u5e73\u6027\u4e0b\u964d\uff0c\u73b0\u6709\u504f\u5dee\u7f13\u89e3\u65b9\u6cd5\u5728\u56e0\u679c\u6df7\u6dc6\u4e0b\u53ef\u80fd\u5931\u6548\u3002", "method": "\u5f15\u5165\u56e0\u679c\u63a8\u7406\u4e0e\u591a\u6a21\u6001\u8868\u5f81\u5b66\u4e60\u7684\u53cd\u4e8b\u5b9e\u5956\u52b1\u6a21\u578b\uff0c\u63d0\u51fa\u53cd\u4e8b\u5b9e\u4fe1\u4efb\u5206\u6570\uff0c\u5728\u591a\u6a21\u6001\u5047\u65b0\u95fb\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6ce8\u5165\u5408\u6210\u504f\u5dee\u6d4b\u8bd5\u9c81\u68d2\u6027\u3002", "result": "\u7cfb\u7edf\u5728\u5047\u65b0\u95fb\u68c0\u6d4b\u4e2d\u51c6\u786e\u7387\u8fbe89.12%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u5956\u52b1\u6a21\u578b\uff0c\u51cf\u5c11\u4e86\u865a\u5047\u5173\u8054\u548c\u4e0d\u516c\u5e73\u5f3a\u5316\u4fe1\u53f7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u516c\u5e73\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u4e0e\u4eba\u7c7b\u53cd\u9988\u7684\u7a33\u5065\u53ef\u89e3\u91ca\u65b9\u6cd5\uff0c\u63d0\u4f9b\u53ef\u8c03\u504f\u5dee\u51cf\u5c11\u9608\u503c\uff0c\u589e\u52a0\u52a8\u6001\u5b9e\u65f6\u51b3\u7b56\u53ef\u9760\u6027\u3002"}}
{"id": "2508.19294", "pdf": "https://arxiv.org/pdf/2508.19294", "abs": "https://arxiv.org/abs/2508.19294", "authors": ["Ranjan Sapkota", "Manoj Karkee"], "title": "Object Detection with Multimodal Large Vision-Language Models: An In-depth Review", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "First Peer Reviewed Review Paper for Object Detection with\n  Vision-Language Models (VLMs)", "summary": "The fusion of language and vision in large vision-language models (LVLMs) has\nrevolutionized deep learning-based object detection by enhancing adaptability,\ncontextual reasoning, and generalization beyond traditional architectures. This\nin-depth review presents a structured exploration of the state-of-the-art in\nLVLMs, systematically organized through a three-step research review process.\nFirst, we discuss the functioning of vision language models (VLMs) for object\ndetection, describing how these models harness natural language processing\n(NLP) and computer vision (CV) techniques to revolutionize object detection and\nlocalization. We then explain the architectural innovations, training\nparadigms, and output flexibility of recent LVLMs for object detection,\nhighlighting how they achieve advanced contextual understanding for object\ndetection. The review thoroughly examines the approaches used in integration of\nvisual and textual information, demonstrating the progress made in object\ndetection using VLMs that facilitate more sophisticated object detection and\nlocalization strategies. This review presents comprehensive visualizations\ndemonstrating LVLMs' effectiveness in diverse scenarios including localization\nand segmentation, and then compares their real-time performance, adaptability,\nand complexity to traditional deep learning systems. Based on the review, its\nis expected that LVLMs will soon meet or surpass the performance of\nconventional methods in object detection. The review also identifies a few\nmajor limitations of the current LVLM modes, proposes solutions to address\nthose challenges, and presents a clear roadmap for the future advancement in\nthis field. We conclude, based on this study, that the recent advancement in\nLVLMs have made and will continue to make a transformative impact on object\ndetection and robotic applications in the future.", "AI": {"tldr": "\u672c\u6587\u6df1\u5165\u7efc\u8ff0\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5206\u6790\u5176\u529f\u80fd\u3001\u67b6\u6784\u521b\u65b0\u7b49\uff0c\u5bf9\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u6307\u51fa\u5176\u6709\u671b\u8d85\u8d8a\u4f20\u7edf\uff0c\u4e5f\u63d0\u51fa\u5f53\u524d\u5c40\u9650\u53ca\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8LVLMs\u5728\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u7684\u878d\u5408\u5982\u4f55\u63d0\u5347\u9002\u5e94\u6027\u3001\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u4e09\u6b65\u7814\u7a76\u7efc\u8ff0\u6d41\u7a0b\uff0c\u5305\u62ec\u8ba8\u8bbaVLMs\u529f\u80fd\u3001\u89e3\u91caLVLMs\u67b6\u6784\u521b\u65b0\u53ca\u8bad\u7ec3\u8303\u5f0f\u3001\u5206\u6790\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\u96c6\u6210\u65b9\u6cd5\u3002", "result": "LVLMs\u5728\u76ee\u6807\u68c0\u6d4b\u7684\u591a\u573a\u666f\u6709\u6548\uff0c\u53ef\u89c6\u5316\u5c55\u793a\u5176\u6548\u679c\uff0c\u5bf9\u6bd4\u663e\u793a\u5728\u5b9e\u65f6\u6027\u80fd\u3001\u9002\u5e94\u6027\u548c\u590d\u6742\u6027\u4e0a\u7684\u7279\u70b9\uff0c\u6709\u671b\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "LVLMs\u5df2\u5bf9\u76ee\u6807\u68c0\u6d4b\u548c\u673a\u5668\u4eba\u5e94\u7528\u4ea7\u751f\u53d8\u9769\u6027\u5f71\u54cd\uff0c\u672a\u6765\u5c06\u6301\u7eed\u53d1\u6325\u4f5c\u7528\u3002"}}
{"id": "2508.19570", "pdf": "https://arxiv.org/pdf/2508.19570", "abs": "https://arxiv.org/abs/2508.19570", "authors": ["Dawei Li", "Yue Huang", "Ming Li", "Tianyi Zhou", "Xiangliang Zhang", "Huan Liu"], "title": "Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by CIKM 2025 Tutorial", "summary": "Generative models such as Large Language Models, Diffusion Models, and\ngenerative adversarial networks have recently revolutionized the creation of\nsynthetic data, offering scalable solutions to data scarcity, privacy, and\nannotation challenges in data mining. This tutorial introduces the foundations\nand latest advances in synthetic data generation, covers key methodologies and\npractical frameworks, and discusses evaluation strategies and applications.\nAttendees will gain actionable insights into leveraging generative synthetic\ndata to enhance data mining research and practice. More information can be\nfound on our website: https://syndata4dm.github.io/.", "AI": {"tldr": "\u672c\u6559\u7a0b\u4ecb\u7ecd\u5408\u6210\u6570\u636e\u751f\u6210\u57fa\u7840\u3001\u8fdb\u5c55\u3001\u65b9\u6cd5\u3001\u8bc4\u4f30\u7b56\u7565\u548c\u5e94\u7528\uff0c\u52a9\u53c2\u4f1a\u8005\u63d0\u5347\u6570\u636e\u6316\u6398\u80fd\u529b\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u89e3\u51b3\u6570\u636e\u6316\u6398\u4e2d\u6570\u636e\u7a00\u7f3a\u3001\u9690\u79c1\u548c\u6807\u6ce8\u96be\u9898\uff0c\u9700\u4ecb\u7ecd\u5408\u6210\u6570\u636e\u751f\u6210\u76f8\u5173\u5185\u5bb9\u3002", "method": "\u4ecb\u7ecd\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u57fa\u7840\u3001\u6700\u65b0\u8fdb\u5c55\u3001\u5173\u952e\u65b9\u6cd5\u3001\u5b9e\u7528\u6846\u67b6\u3001\u8bc4\u4f30\u7b56\u7565\u548c\u5e94\u7528\u3002", "result": "\u53c2\u4f1a\u8005\u53ef\u83b7\u5f97\u5229\u7528\u751f\u6210\u5f0f\u5408\u6210\u6570\u636e\u589e\u5f3a\u6570\u636e\u6316\u6398\u7814\u7a76\u4e0e\u5b9e\u8df5\u7684\u53ef\u884c\u89c1\u89e3\u3002", "conclusion": "\u672c\u6559\u7a0b\u80fd\u5e2e\u52a9\u53c2\u4f1a\u8005\u5728\u6570\u636e\u6316\u6398\u4e2d\u66f4\u597d\u5229\u7528\u5408\u6210\u6570\u636e\u3002"}}
{"id": "2508.19298", "pdf": "https://arxiv.org/pdf/2508.19298", "abs": "https://arxiv.org/abs/2508.19298", "authors": ["Abu Sufian", "Anirudha Ghosh", "Debaditya Barman", "Marco Leo", "Cosimo Distante"], "title": "DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 4 figures, 13th International Workshop on Biometrics and\n  Forensics (IWBF)", "summary": "Large Vision Language Models (LVLMs) have demonstrated remarkable\ncapabilities across various downstream tasks, including biometric face\nrecognition (FR) with description. However, demographic biases remain a\ncritical concern in FR, as these foundation models often fail to perform\nequitably across diverse demographic groups, considering ethnicity/race,\ngender, and age. Therefore, through our work DemoBias, we conduct an empirical\nevaluation to investigate the extent of demographic biases in LVLMs for\nbiometric FR with textual token generation tasks. We fine-tuned and evaluated\nthree widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own\ngenerated demographic-balanced dataset. We utilize several evaluation metrics,\nlike group-specific BERTScores and the Fairness Discrepancy Rate, to quantify\nand trace the performance disparities. The experimental results deliver\ncompelling insights into the fairness and reliability of LVLMs across diverse\ndemographic groups. Our empirical study uncovered demographic biases in LVLMs,\nwith PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino,\nCaucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably\nconsistent. Repository: https://github.com/Sufianlab/DemoBias.", "AI": {"tldr": "\u6587\u7ae0\u901a\u8fc7DemoBias\u5de5\u4f5c\uff0c\u5bf9\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u7279\u5f81\u4eba\u8138\u8bc6\u522b\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u5dee\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u504f\u5dee\u3002", "motivation": "\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4eba\u8138\u8bc6\u522b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u4e2d\u5b58\u5728\u8868\u73b0\u4e0d\u5747\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u5dee\u95ee\u9898\u3002", "method": "\u5728\u81ea\u5236\u7684\u4eba\u53e3\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u5e76\u8bc4\u4f30LLaVA\u3001BLIP - 2\u548cPaliGemma\u4e09\u4e2a\u9884\u8bad\u7ec3\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u7528\u7279\u5b9a\u7ec4\u7684BERT\u5206\u6570\u548c\u516c\u5e73\u5dee\u5f02\u7387\u7b49\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793aLVLMs\u5b58\u5728\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u5dee\uff0cPaliGemma\u548cLLaVA\u5728\u897f\u73ed\u7259\u88d4/\u62c9\u4e01\u88d4\u3001\u767d\u79cd\u4eba\u548c\u5357\u4e9a\u7fa4\u4f53\u4e2d\u5dee\u5f02\u8f83\u5927\uff0cBLIP - 2\u76f8\u5bf9\u8f83\u4e00\u81f4\u3002", "conclusion": "\u5b9e\u8bc1\u7814\u7a76\u63ed\u793a\u4e86LVLMs\u5728\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u4e2d\u7684\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u60c5\u51b5\u3002"}}
{"id": "2508.19571", "pdf": "https://arxiv.org/pdf/2508.19571", "abs": "https://arxiv.org/abs/2508.19571", "authors": ["Yunlong Lin", "Chao Lu", "Tongshuai Wu", "Xiaocong Zhao", "Guodong Du", "Yanwei Sun", "Zirui Li", "Jianwei Gong"], "title": "Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal", "categories": ["cs.LG"], "comment": "Official code: https://github.com/BIT-Jack/SyReM", "summary": "Deep neural networks (DNN) have achieved remarkable success in motion\nforecasting. However, most DNN-based methods suffer from catastrophic\nforgetting and fail to maintain their performance in previously learned\nscenarios after adapting to new data. Recent continual learning (CL) studies\naim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the\nability to retain learned knowledge. Yet, excessive emphasis on the memory\nstability often impairs learning plasticity, i.e., the capacity of DNN to\nacquire new information effectively. To address such stability-plasticity\ndilemma, this study proposes a novel CL method, synergetic memory rehearsal\n(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory\nbuffer to represent learned knowledge. To ensure memory stability, it employs\nan inequality constraint that limits increments in the average loss over the\nmemory buffer. Synergistically, a selective memory rehearsal mechanism is\ndesigned to enhance learning plasticity by selecting samples from the memory\nbuffer that are most similar to recently observed data. This selection is based\non an online-measured cosine similarity of loss gradients, ensuring targeted\nmemory rehearsal. Since replayed samples originate from learned scenarios, this\nmemory rehearsal mechanism avoids compromising memory stability. We validate\nSyReM under an online CL paradigm where training samples from diverse scenarios\narrive as a one-pass stream. Experiments on 11 naturalistic driving datasets\nfrom INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM\nsignificantly mitigates catastrophic forgetting in past scenarios while\nimproving forecasting accuracy in new ones. The implementation is publicly\navailable at https://github.com/BIT-Jack/SyReM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8eDNN\u8fd0\u52a8\u9884\u6d4b\u7684\u534f\u540c\u8bb0\u5fc6\u6392\u7ec3\u65b9\u6cd5SyReM\uff0c\u89e3\u51b3\u7a33\u5b9a\u6027 - \u53ef\u5851\u6027\u56f0\u5883\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u51cf\u8f7b\u707e\u96be\u6027\u9057\u5fd8\u5e76\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709DNN\u8fd0\u52a8\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u6301\u7eed\u5b66\u4e60\u7814\u7a76\u4e2d\u5f3a\u8c03\u8bb0\u5fc6\u7a33\u5b9a\u6027\u4f1a\u635f\u5bb3\u5b66\u4e60\u53ef\u5851\u6027\uff0c\u9700\u89e3\u51b3\u7a33\u5b9a\u6027 - \u53ef\u5851\u6027\u56f0\u5883\u3002", "method": "\u63d0\u51faSyReM\u65b9\u6cd5\uff0c\u7ef4\u62a4\u7d27\u51d1\u8bb0\u5fc6\u7f13\u51b2\u533a\uff0c\u7528\u4e0d\u7b49\u5f0f\u7ea6\u675f\u4fdd\u8bc1\u8bb0\u5fc6\u7a33\u5b9a\u6027\uff0c\u8bbe\u8ba1\u9009\u62e9\u6027\u8bb0\u5fc6\u6392\u7ec3\u673a\u5236\u589e\u5f3a\u5b66\u4e60\u53ef\u5851\u6027\u3002", "result": "\u572811\u4e2a\u81ea\u7136\u9a7e\u9a76\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u975eCL\u548cCL\u57fa\u7ebf\u76f8\u6bd4\uff0cSyReM\u663e\u8457\u51cf\u8f7b\u8fc7\u53bb\u573a\u666f\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u63d0\u9ad8\u65b0\u573a\u666f\u9884\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "SyReM\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3DNN\u8fd0\u52a8\u9884\u6d4b\u4e2d\u7684\u7a33\u5b9a\u6027 - \u53ef\u5851\u6027\u56f0\u5883\uff0c\u4ee3\u7801\u516c\u5f00\u53ef\u83b7\u53d6\u3002"}}
{"id": "2508.19300", "pdf": "https://arxiv.org/pdf/2508.19300", "abs": "https://arxiv.org/abs/2508.19300", "authors": ["Cunmin Zhao", "Ziyuan Luo", "Guoye Guan", "Zelin Li", "Yiming Ma", "Zhongying Zhao", "Renjie Wan"], "title": "CellINR: Implicitly Overcoming Photo-induced Artifacts in 4D Live Fluorescence Microscopy", "categories": ["eess.IV", "cs.AI", "cs.CV", "32H10", "F.2.2; I.2.7"], "comment": "13 pages, 4 figures", "summary": "4D live fluorescence microscopy is often compromised by prolonged high\nintensity illumination which induces photobleaching and phototoxic effects that\ngenerate photo-induced artifacts and severely impair image continuity and\ndetail recovery. To address this challenge, we propose the CellINR framework, a\ncase-specific optimization approach based on implicit neural representation.\nThe method employs blind convolution and structure amplification strategies to\nmap 3D spatial coordinates into the high frequency domain, enabling precise\nmodeling and high-accuracy reconstruction of cellular structures while\neffectively distinguishing true signals from artifacts. Experimental results\ndemonstrate that CellINR significantly outperforms existing techniques in\nartifact removal and restoration of structural continuity, and for the first\ntime, a paired 4D live cell imaging dataset is provided for evaluating\nreconstruction performance, thereby offering a solid foundation for subsequent\nquantitative analyses and biological research. The code and dataset will be\npublic.", "AI": {"tldr": "\u63d0\u51faCellINR\u6846\u67b6\u89e3\u51b34D\u6d3b\u8367\u5149\u663e\u5fae\u955c\u5149\u7167\u95ee\u9898\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\u4e14\u516c\u5f00\u4ee3\u7801\u548c\u6570\u636e\u96c6", "motivation": "4D\u6d3b\u8367\u5149\u663e\u5fae\u955c\u56e0\u957f\u65f6\u95f4\u9ad8\u5f3a\u5ea6\u5149\u7167\u4ea7\u751f\u5149\u6f02\u767d\u548c\u5149\u6bd2\u6027\u6548\u5e94\uff0c\u5f71\u54cd\u56fe\u50cf\u8d28\u91cf", "method": "\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u7684CellINR\u6846\u67b6\uff0c\u91c7\u7528\u76f2\u5377\u79ef\u548c\u7ed3\u6784\u653e\u5927\u7b56\u7565\u5c063D\u7a7a\u95f4\u5750\u6807\u6620\u5c04\u5230\u9ad8\u9891\u57df", "result": "CellINR\u5728\u53bb\u9664\u4f2a\u5f71\u548c\u6062\u590d\u7ed3\u6784\u8fde\u7eed\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u63d0\u4f9b\u914d\u5bf94D\u6d3b\u7ec6\u80de\u6210\u50cf\u6570\u636e\u96c6", "conclusion": "CellINR\u4e3a\u540e\u7eed\u5b9a\u91cf\u5206\u6790\u548c\u751f\u7269\u5b66\u7814\u7a76\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840"}}
{"id": "2508.19589", "pdf": "https://arxiv.org/pdf/2508.19589", "abs": "https://arxiv.org/abs/2508.19589", "authors": ["Arshia Hemmat", "Afsaneh Fatemi"], "title": "Delta-Audit: Explaining What Changes When Models Change", "categories": ["cs.LG"], "comment": "7 pages, 1 figure, 4 tables", "summary": "Model updates (new hyperparameters, kernels, depths, solvers, or data) change\nperformance, but the \\emph{reason} often remains opaque. We introduce\n\\textbf{Delta-Attribution} (\\mbox{$\\Delta$-Attribution}), a model-agnostic\nframework that explains \\emph{what changed} between versions $A$ and $B$ by\ndifferencing per-feature attributions: $\\Delta\\phi(x)=\\phi_B(x)-\\phi_A(x)$. We\nevaluate $\\Delta\\phi$ with a \\emph{$\\Delta$-Attribution Quality Suite} covering\nmagnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,\nJensen--Shannon divergence), behavioural alignment (Delta Conservation Error,\nDCE; Behaviour--Attribution Coupling, BAC; CO$\\Delta$F), and robustness (noise,\nbaseline sensitivity, grouped occlusion).\n  Instantiated via fast occlusion/clamping in standardized space with a\nclass-anchored margin and baseline averaging, we audit 45 settings: five\nclassical families (Logistic Regression, SVC, Random Forests, Gradient\nBoosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B\npairs per family. \\textbf{Findings.} Inductive-bias changes yield large,\nbehaviour-aligned deltas (e.g., SVC poly$\\!\\rightarrow$rbf on Breast Cancer:\nBAC$\\approx$0.998, DCE$\\approx$6.6; Random Forest feature-rule swap on Digits:\nBAC$\\approx$0.997, DCE$\\approx$7.5), while ``cosmetic'' tweaks (SVC\n\\texttt{gamma=scale} vs.\\ \\texttt{auto}, $k$NN search) show\nrank-overlap@10$=1.0$ and DCE$\\approx$0. The largest redistribution appears for\ndeeper GB on Breast Cancer (JSD$\\approx$0.357). $\\Delta$-Attribution offers a\nlightweight update audit that complements accuracy by distinguishing benign\nchanges from behaviourally meaningful or risky reliance shifts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDelta - Attribution\u6846\u67b6\u89e3\u91ca\u6a21\u578b\u7248\u672cA\u548cB\u7684\u53d8\u5316\uff0c\u8bc4\u4f30\u5176\u8d28\u91cf\uff0c\u5ba1\u8ba145\u79cd\u8bbe\u7f6e\uff0c\u53d1\u73b0\u4e0d\u540c\u66f4\u65b0\u53d8\u5316\u7279\u5f81\uff0c\u8be5\u6846\u67b6\u53ef\u8f85\u52a9\u6a21\u578b\u66f4\u65b0\u5ba1\u8ba1\u3002", "motivation": "\u6a21\u578b\u66f4\u65b0\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u539f\u56e0\u4e0d\u900f\u660e\uff0c\u9700\u8981\u65b9\u6cd5\u89e3\u91ca\u6a21\u578b\u7248\u672c\u95f4\u7684\u53d8\u5316\u3002", "method": "\u5f15\u5165Delta - Attribution\u6846\u67b6\uff0c\u901a\u8fc7\u5dee\u5206\u7279\u5f81\u5f52\u56e0\u89e3\u91ca\u7248\u672c\u53d8\u5316\uff0c\u7528Delta - Attribution Quality Suite\u8bc4\u4f30\uff0c\u5bf945\u79cd\u8bbe\u7f6e\u8fdb\u884c\u5ba1\u8ba1\u3002", "result": "\u5f52\u7eb3\u504f\u7f6e\u53d8\u5316\u4ea7\u751f\u5927\u7684\u3001\u884c\u4e3a\u5bf9\u9f50\u7684\u5dee\u5f02\uff1b\u201c\u8868\u9762\u201d\u8c03\u6574\u6392\u540d\u91cd\u53e0\u5ea6\u9ad8\u3001\u8bef\u5dee\u5c0f\uff1b\u6df1\u5ea6\u68af\u5ea6\u63d0\u5347\u5728\u4e73\u817a\u764c\u6570\u636e\u96c6\u4e0a\u91cd\u5206\u5e03\u6700\u5927\u3002", "conclusion": "Delta - Attribution\u662f\u8f7b\u91cf\u7ea7\u66f4\u65b0\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u80fd\u533a\u5206\u826f\u6027\u53d8\u5316\u548c\u6709\u884c\u4e3a\u610f\u4e49\u6216\u6709\u98ce\u9669\u7684\u4f9d\u8d56\u8f6c\u79fb\uff0c\u8865\u5145\u4e86\u51c6\u786e\u6027\u8bc4\u4f30\u3002"}}
{"id": "2508.19303", "pdf": "https://arxiv.org/pdf/2508.19303", "abs": "https://arxiv.org/abs/2508.19303", "authors": ["Utsav Ratna Tuladhar", "Richard Simon", "Doran Mix", "Michael Richards"], "title": "2D Ultrasound Elasticity Imaging of Abdominal Aortic Aneurysms Using Deep Neural Networks", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Abdominal aortic aneurysms (AAA) pose a significant clinical risk due to\ntheir potential for rupture, which is often asymptomatic but can be fatal.\nAlthough maximum diameter is commonly used for risk assessment, diameter alone\nis insufficient as it does not capture the properties of the underlying\nmaterial of the vessel wall, which play a critical role in determining the risk\nof rupture. To overcome this limitation, we propose a deep learning-based\nframework for elasticity imaging of AAAs with 2D ultrasound. Leveraging finite\nelement simulations, we generate a diverse dataset of displacement fields with\ntheir corresponding modulus distributions. We train a model with U-Net\narchitecture and normalized mean squared error (NMSE) to infer the spatial\nmodulus distribution from the axial and lateral components of the displacement\nfields. This model is evaluated across three experimental domains: digital\nphantom data from 3D COMSOL simulations, physical phantom experiments using\nbiomechanically distinct vessel models, and clinical ultrasound exams from AAA\npatients. Our simulated results demonstrate that the proposed deep learning\nmodel is able to reconstruct modulus distributions, achieving an NMSE score of\n0.73\\%. Similarly, in phantom data, the predicted modular ratio closely matches\nthe expected values, affirming the model's ability to generalize to phantom\ndata. We compare our approach with an iterative method which shows comparable\nperformance but higher computation time. In contrast, the deep learning method\ncan provide quick and effective estimates of tissue stiffness from ultrasound\nimages, which could help assess the risk of AAA rupture without invasive\nprocedures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4e8c\u7ef4\u8d85\u58f0\u8179\u4e3b\u52a8\u8109\u7624\u5f39\u6027\u6210\u50cf\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u5b9e\u9a8c\u57df\u8bc4\u4f30\uff0c\u6a21\u578b\u80fd\u6709\u6548\u91cd\u5efa\u6a21\u91cf\u5206\u5e03\uff0c\u53ef\u5feb\u901f\u65e0\u521b\u8bc4\u4f30\u7834\u88c2\u98ce\u9669\u3002", "motivation": "\u4f20\u7edf\u4ec5\u7528\u6700\u5927\u76f4\u5f84\u8bc4\u4f30\u8179\u4e3b\u52a8\u8109\u7624\u7834\u88c2\u98ce\u9669\u4e0d\u8db3\uff0c\u672a\u8003\u8651\u8840\u7ba1\u58c1\u6750\u6599\u7279\u6027\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6709\u9650\u5143\u6a21\u62df\u751f\u6210\u4f4d\u79fb\u573a\u548c\u6a21\u91cf\u5206\u5e03\u6570\u636e\u96c6\uff0c\u7528U - Net\u67b6\u6784\u548cNMSE\u8bad\u7ec3\u6a21\u578b\uff0c\u4ece\u4f4d\u79fb\u573a\u63a8\u65ad\u6a21\u91cf\u5206\u5e03\uff0c\u5728\u4e09\u4e2a\u5b9e\u9a8c\u57df\u8bc4\u4f30\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\u6a21\u578b\u80fd\u91cd\u5efa\u6a21\u91cf\u5206\u5e03\uff0cNMSE\u4e3a0.73%\uff1b\u5728\u4f53\u6a21\u6570\u636e\u4e2d\u9884\u6d4b\u503c\u4e0e\u9884\u671f\u503c\u76f8\u7b26\uff1b\u4e0e\u8fed\u4ee3\u6cd5\u6027\u80fd\u76f8\u5f53\u4f46\u8ba1\u7b97\u65f6\u95f4\u77ed\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ece\u8d85\u58f0\u56fe\u50cf\u5feb\u901f\u6709\u6548\u4f30\u8ba1\u7ec4\u7ec7\u786c\u5ea6\uff0c\u6709\u52a9\u4e8e\u65e0\u521b\u8bc4\u4f30\u8179\u4e3b\u52a8\u8109\u7624\u7834\u88c2\u98ce\u9669\u3002"}}
{"id": "2508.19597", "pdf": "https://arxiv.org/pdf/2508.19597", "abs": "https://arxiv.org/abs/2508.19597", "authors": ["Zirui Li", "Yunlong Lin", "Guodong Du", "Xiaocong Zhao", "Cheng Gong", "Chen Lv", "Chao Lu", "Jianwei Gong"], "title": "Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 6 figures", "summary": "Artificial intelligence underpins most smart city services, yet deep neural\nnetwork (DNN) that forecasts vehicle motion still struggle with catastrophic\nforgetting, the loss of earlier knowledge when models are updated. Conventional\nfixes enlarge the training set or replay past data, but these strategies incur\nhigh data collection costs, sample inefficiently and fail to balance long- and\nshort-term experience, leaving them short of human-like continual learning.\nHere we introduce Dual-LS, a task-free, online continual learning paradigm for\nDNN-based motion forecasting that is inspired by the complementary learning\nsystem of the human brain. Dual-LS pairs two synergistic memory rehearsal\nreplay mechanisms to accelerate experience retrieval while dynamically\ncoordinating long-term and short-term knowledge representations. Tests on\nnaturalistic data spanning three countries, over 772,000 vehicles and\ncumulative testing mileage of 11,187 km show that Dual-LS mitigates\ncatastrophic forgetting by up to 74.31\\% and reduces computational resource\ndemand by up to 94.02\\%, markedly boosting predictive stability in vehicle\nmotion forecasting without inflating data requirements. Meanwhile, it endows\nDNN-based vehicle motion forecasting with computation efficient and human-like\ncontinual learning adaptability fit for smart cities.", "AI": {"tldr": "\u4ecb\u7ecdDual - LS\u8303\u5f0f\u89e3\u51b3DNN\u8f66\u8f86\u8fd0\u52a8\u9884\u6d4b\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u6548\u679c\u826f\u597d\u3002", "motivation": "DNN\u8fdb\u884c\u8f66\u8f86\u8fd0\u52a8\u9884\u6d4b\u65f6\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u6709\u6210\u672c\u9ad8\u3001\u91c7\u6837\u4f4e\u6548\u7b49\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u7c7b\u4eba\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u5f15\u5165\u53d7\u4eba\u7c7b\u5927\u8111\u4e92\u8865\u5b66\u4e60\u7cfb\u7edf\u542f\u53d1\u7684Dual - LS\u8303\u5f0f\uff0c\u901a\u8fc7\u4e24\u4e2a\u534f\u540c\u7684\u8bb0\u5fc6\u6392\u7ec3\u91cd\u653e\u673a\u5236\u52a0\u901f\u7ecf\u9a8c\u68c0\u7d22\u5e76\u534f\u8c03\u957f\u77ed\u671f\u77e5\u8bc6\u8868\u5f81\u3002", "result": "\u5728\u591a\u56fd\u81ea\u7136\u4e3b\u4e49\u6570\u636e\u6d4b\u8bd5\u4e2d\uff0cDual - LS\u6700\u591a\u51cf\u8f7b74.31%\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u6700\u591a\u964d\u4f4e94.02%\u7684\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u63d0\u9ad8\u9884\u6d4b\u7a33\u5b9a\u6027\u3002", "conclusion": "Dual - LS\u8ba9\u57fa\u4e8eDNN\u7684\u8f66\u8f86\u8fd0\u52a8\u9884\u6d4b\u5177\u5907\u8ba1\u7b97\u9ad8\u6548\u548c\u7c7b\u4eba\u6301\u7eed\u5b66\u4e60\u9002\u5e94\u6027\uff0c\u9002\u7528\u4e8e\u667a\u6167\u57ce\u5e02\u3002"}}
{"id": "2508.19598", "pdf": "https://arxiv.org/pdf/2508.19598", "abs": "https://arxiv.org/abs/2508.19598", "authors": ["Zhiwei Li", "Yong Hu", "Wenqing Wang"], "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "categories": ["cs.LG"], "comment": null, "summary": "The functionality of Large Language Model (LLM) agents is primarily\ndetermined by two capabilities: action planning and answer summarization. The\nformer, action planning, is the core capability that dictates an agent's\nperformance. However, prevailing training paradigms employ end-to-end,\nmulti-objective optimization that jointly trains both capabilities. This\nparadigm faces two critical challenges: imbalanced optimization objective\nallocation and scarcity of verifiable data, making it difficult to enhance the\nagent's planning capability. To address these challenges, we propose\nReinforcement Learning with Tool-use Rewards (RLTR), a novel framework that\ndecouples the training process to enable a focused, single-objective\noptimization of the planning module. Crucially, RLTR introduces a reward signal\nbased on tool-use completeness to directly evaluate the quality of tool\ninvocation sequences. This method offers a more direct and reliable training\nsignal than assessing the final response content, thereby obviating the need\nfor verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%\nimprovement in planning performance compared to end-to-end baselines. Moreover,\nthis enhanced planning capability, in turn, translates to a 5%-6% increase in\nthe final response quality of the overall agent system.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faRLTR\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u8bad\u7ec3\u4e2d\u89c4\u5212\u80fd\u529b\u63d0\u5347\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u63d0\u5347\u89c4\u5212\u6027\u80fd\u548c\u6700\u7ec8\u54cd\u5e94\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u591a\u76ee\u6807\u4f18\u5316\u8bad\u7ec3\u8303\u5f0f\u5b58\u5728\u4f18\u5316\u76ee\u6807\u5206\u914d\u4e0d\u5e73\u8861\u548c\u53ef\u9a8c\u8bc1\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u96be\u4ee5\u63d0\u5347\u4ee3\u7406\u7684\u89c4\u5212\u80fd\u529b\u3002", "method": "\u63d0\u51faRLTR\u6846\u67b6\uff0c\u89e3\u8026\u8bad\u7ec3\u8fc7\u7a0b\u5bf9\u89c4\u5212\u6a21\u5757\u8fdb\u884c\u5355\u76ee\u6807\u4f18\u5316\uff0c\u5f15\u5165\u57fa\u4e8e\u5de5\u5177\u4f7f\u7528\u5b8c\u6574\u6027\u7684\u5956\u52b1\u4fe1\u53f7\u3002", "result": "RLTR\u76f8\u6bd4\u7aef\u5230\u7aef\u57fa\u7ebf\u5728\u89c4\u5212\u6027\u80fd\u4e0a\u63d0\u53478%-12%\uff0c\u4f7f\u6574\u4f53\u4ee3\u7406\u7cfb\u7edf\u6700\u7ec8\u54cd\u5e94\u8d28\u91cf\u63d0\u9ad85%-6%\u3002", "conclusion": "RLTR\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u89c4\u5212\u80fd\u529b\u548c\u6700\u7ec8\u54cd\u5e94\u8d28\u91cf\u3002"}}
{"id": "2508.19305", "pdf": "https://arxiv.org/pdf/2508.19305", "abs": "https://arxiv.org/abs/2508.19305", "authors": ["Chen Chu", "Cyrus Shahabi"], "title": "Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Spatial representation learning is essential for GeoAI applications such as\nurban analytics, enabling the encoding of shapes, locations, and spatial\nrelationships (topological and distance-based) of geo-entities like points,\npolylines, and polygons. Existing methods either target a single geo-entity\ntype or, like Poly2Vec, decompose entities into simpler components to enable\nFourier transformation, introducing high computational cost. Moreover, since\nthe transformed space lacks geometric alignment, these methods rely on uniform,\nnon-adaptive sampling, which blurs fine-grained features like edges and\nboundaries. To address these limitations, we introduce Geo2Vec, a novel method\ninspired by signed distance fields (SDF) that operates directly in the original\nspace. Geo2Vec adaptively samples points and encodes their signed distances\n(positive outside, negative inside), capturing geometry without decomposition.\nA neural network trained to approximate the SDF produces compact,\ngeometry-aware, and unified representations for all geo-entity types.\nAdditionally, we propose a rotation-invariant positional encoding to model\nhigh-frequency spatial variations and construct a structured and robust\nembedding space for downstream GeoAI models. Empirical results show that\nGeo2Vec consistently outperforms existing methods in representing shape and\nlocation, capturing topological and distance relationships, and achieving\ngreater efficiency in real-world GeoAI applications. Code and Data can be found\nat: https://github.com/chuchen2017/GeoNeuralRepresentation.", "AI": {"tldr": "\u63d0\u51faGeo2Vec\u65b9\u6cd5\u89e3\u51b3\u73b0\u6709\u7a7a\u95f4\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5728GeoAI\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7a7a\u95f4\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4ec5\u9488\u5bf9\u5355\u4e00\u5730\u7406\u5b9e\u4f53\u7c7b\u578b\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u4f9d\u8d56\u975e\u81ea\u9002\u5e94\u91c7\u6837\u6a21\u7cca\u7279\u5f81\u7b49\u5c40\u9650\u3002", "method": "\u5f15\u5165\u53d7\u6709\u7b26\u53f7\u8ddd\u79bb\u573a\u542f\u53d1\u7684Geo2Vec\u65b9\u6cd5\uff0c\u76f4\u63a5\u5728\u539f\u7a7a\u95f4\u81ea\u9002\u5e94\u91c7\u6837\u70b9\u5e76\u7f16\u7801\u5176\u6709\u7b26\u53f7\u8ddd\u79bb\uff0c\u7528\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3cSDF\u751f\u6210\u8868\u793a\uff0c\u63d0\u51fa\u65cb\u8f6c\u4e0d\u53d8\u4f4d\u7f6e\u7f16\u7801\u3002", "result": "Geo2Vec\u5728\u8868\u793a\u5f62\u72b6\u3001\u4f4d\u7f6e\uff0c\u6355\u6349\u62d3\u6251\u548c\u8ddd\u79bb\u5173\u7cfb\u4ee5\u53ca\u5b9e\u9645GeoAI\u5e94\u7528\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Geo2Vec\u662f\u4e00\u79cd\u6709\u6548\u7684\u7a7a\u95f4\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u4e3a\u4e0b\u6e38GeoAI\u6a21\u578b\u63d0\u4f9b\u66f4\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2508.19609", "pdf": "https://arxiv.org/pdf/2508.19609", "abs": "https://arxiv.org/abs/2508.19609", "authors": ["Zhuohang Zhu", "Haodong Chen", "Qiang Qu", "Vera Chung"], "title": "FinCast: A Foundation Model for Financial Time-Series Forecasting", "categories": ["cs.LG", "cs.AI", "q-fin.CP"], "comment": null, "summary": "Financial time-series forecasting is critical for maintaining economic\nstability, guiding informed policymaking, and promoting sustainable investment\npractices. However, it remains challenging due to various underlying pattern\nshifts. These shifts arise primarily from three sources: temporal\nnon-stationarity (distribution changes over time), multi-domain diversity\n(distinct patterns across financial domains such as stocks, commodities, and\nfutures), and varying temporal resolutions (patterns differing across\nper-second, hourly, daily, or weekly indicators). While recent deep learning\nmethods attempt to address these complexities, they frequently suffer from\noverfitting and typically require extensive domain-specific fine-tuning. To\novercome these limitations, we introduce FinCast, the first foundation model\nspecifically designed for financial time-series forecasting, trained on\nlarge-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot\nperformance, effectively capturing diverse patterns without domain-specific\nfine-tuning. Comprehensive empirical and qualitative evaluations demonstrate\nthat FinCast surpasses existing state-of-the-art methods, highlighting its\nstrong generalization capabilities.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u57fa\u7840\u6a21\u578bFinCast\uff0c\u65e0\u9700\u7279\u5b9a\u9886\u57df\u5fae\u8c03\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u56e0\u6a21\u5f0f\u8f6c\u79fb\u6311\u6218\u5927\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6709\u8fc7\u62df\u5408\u548c\u9700\u5927\u91cf\u7279\u5b9a\u9886\u57df\u5fae\u8c03\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e13\u95e8\u7528\u4e8e\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u57fa\u7840\u6a21\u578bFinCast\uff0c\u5728\u5927\u89c4\u6a21\u91d1\u878d\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u3002", "result": "FinCast\u6709\u5f3a\u5927\u96f6\u6837\u672c\u6027\u80fd\uff0c\u80fd\u6355\u6349\u591a\u6837\u6a21\u5f0f\uff0c\u7efc\u5408\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "FinCast\u5177\u6709\u5f88\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.19307", "pdf": "https://arxiv.org/pdf/2508.19307", "abs": "https://arxiv.org/abs/2508.19307", "authors": ["Hamza Khan"], "title": "Advancements in Crop Analysis through Deep Learning and Explainable AI", "categories": ["cs.CV", "cs.AI"], "comment": "Master's thesis", "summary": "Rice is a staple food of global importance in terms of trade, nutrition, and\neconomic growth. Among Asian nations such as China, India, Pakistan, Thailand,\nVietnam and Indonesia are leading producers of both long and short grain\nvarieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To\nensure consumer satisfaction and strengthen national reputations, monitoring\nrice crops and grain quality is essential. Manual inspection, however, is\nlabour intensive, time consuming and error prone, highlighting the need for\nautomated solutions for quality control and yield improvement. This study\nproposes an automated approach to classify five rice grain varieties using\nConvolutional Neural Networks (CNN). A publicly available dataset of 75000\nimages was used for training and testing. Model evaluation employed accuracy,\nrecall, precision, F1-score, ROC curves, and confusion matrices. Results\ndemonstrated high classification accuracy with minimal misclassifications,\nconfirming the model effectiveness in distinguishing rice varieties. In\naddition, an accurate diagnostic method for rice leaf diseases such as Brown\nSpot, Blast, Bacterial Blight, and Tungro was developed. The framework combined\nexplainable artificial intelligence (XAI) with deep learning models including\nCNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP\n(SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic\nExplanations) revealed how specific grain and leaf features influenced\npredictions, enhancing model transparency and reliability. The findings\ndemonstrate the strong potential of deep learning in agricultural applications,\npaving the way for robust, interpretable systems that can support automated\ncrop quality inspection and disease diagnosis, ultimately benefiting farmers,\nconsumers, and the agricultural economy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528CNN\u5bf9\u4e94\u79cd\u5927\u7c73\u54c1\u79cd\u5206\u7c7b\uff0c\u8fd8\u7ed3\u5408XAI\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8bca\u65ad\u6c34\u7a3b\u53f6\u75c5\uff0c\u7ed3\u679c\u663e\u793a\u6df1\u5ea6\u5b66\u4e60\u5728\u519c\u4e1a\u5e94\u7528\u6f5c\u529b\u5927\u3002", "motivation": "\u4eba\u5de5\u68c0\u6d4b\u6c34\u7a3b\u8d28\u91cf\u548c\u4ea7\u91cf\u52b3\u52a8\u5f3a\u5ea6\u5927\u3001\u6613\u51fa\u9519\uff0c\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7528CNN\u5bf9\u5927\u7c73\u54c1\u79cd\u5206\u7c7b\uff0c\u7ed3\u5408XAI\u4e0eCNN\u3001VGG16\u7b49\u6a21\u578b\u8bca\u65ad\u6c34\u7a3b\u53f6\u75c5\uff0c\u7528\u591a\u79cd\u6307\u6807\u8bc4\u4f30\u6a21\u578b\uff0c\u7528SHAP\u548cLIME\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5927\u7c73\u54c1\u79cd\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u3001\u8bef\u5206\u7c7b\u5c11\uff0c\u5f00\u53d1\u51fa\u51c6\u786e\u7684\u6c34\u7a3b\u53f6\u75c5\u8bca\u65ad\u65b9\u6cd5\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u5728\u519c\u4e1a\u5e94\u7528\u6f5c\u529b\u5927\uff0c\u53ef\u652f\u6301\u81ea\u52a8\u5316\u4f5c\u7269\u8d28\u91cf\u68c0\u6d4b\u548c\u75be\u75c5\u8bca\u65ad\u3002"}}
{"id": "2508.19613", "pdf": "https://arxiv.org/pdf/2508.19613", "abs": "https://arxiv.org/abs/2508.19613", "authors": ["Chenzhi Liu", "Mahsa Baktashmotlagh", "Yanran Tang", "Zi Huang", "Ruihong Qiu"], "title": "ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation", "categories": ["cs.LG"], "comment": "Accepted to BMVC 2025, Oral", "summary": "Estimating model accuracy on unseen, unlabeled datasets is crucial for\nreal-world machine learning applications, especially under distribution shifts\nthat can degrade performance. Existing methods often rely on predicted class\nprobabilities (softmax scores) or data similarity metrics. While softmax-based\napproaches benefit from representing predictions on the standard simplex,\ncompressing logits into probabilities leads to information loss. Meanwhile,\nsimilarity-based methods can be computationally expensive and domain-specific,\nlimiting their broader applicability. In this paper, we introduce ALSA (Anchors\nin Logit Space for Accuracy estimation), a novel framework that preserves\nricher information by operating directly in the logit space. Building on\ntheoretical insights and empirical observations, we demonstrate that the\naggregation and distribution of logits exhibit a strong correlation with the\npredictive performance of the model. To exploit this property, ALSA employs an\nanchor-based modeling strategy: multiple learnable anchors are initialized in\nlogit space, each assigned an influence function that captures subtle\nvariations in the logits. This allows ALSA to provide robust and accurate\nperformance estimates across a wide range of distribution shifts. Extensive\nexperiments on vision, language, and graph benchmarks demonstrate ALSA's\nsuperiority over both softmax- and similarity-based baselines. Notably, ALSA's\nrobustness under significant distribution shifts highlights its potential as a\npractical tool for reliable model evaluation.", "AI": {"tldr": "\u63d0\u51faALSA\u6846\u67b6\u7528\u4e8e\u4f30\u8ba1\u6a21\u578b\u5728\u672a\u6807\u8bb0\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4f30\u8ba1\u6a21\u578b\u5728\u672a\u6807\u8bb0\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u7684\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u635f\u5931\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u9002\u7528\u6027\u53d7\u9650\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faALSA\u6846\u67b6\uff0c\u76f4\u63a5\u5728\u5bf9\u6570\u7a7a\u95f4\u64cd\u4f5c\uff0c\u91c7\u7528\u57fa\u4e8e\u951a\u70b9\u7684\u5efa\u6a21\u7b56\u7565\uff0c\u521d\u59cb\u5316\u591a\u4e2a\u53ef\u5b66\u4e60\u951a\u70b9\u5e76\u5206\u914d\u5f71\u54cd\u51fd\u6570\u3002", "result": "\u5728\u89c6\u89c9\u3001\u8bed\u8a00\u548c\u56fe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cALSA\u4f18\u4e8e\u57fa\u4e8esoftmax\u548c\u76f8\u4f3c\u5ea6\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ALSA\u5728\u663e\u8457\u5206\u5e03\u504f\u79fb\u4e0b\u5177\u6709\u9c81\u68d2\u6027\uff0c\u6709\u4f5c\u4e3a\u53ef\u9760\u6a21\u578b\u8bc4\u4f30\u5b9e\u7528\u5de5\u5177\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.19312", "pdf": "https://arxiv.org/pdf/2508.19312", "abs": "https://arxiv.org/abs/2508.19312", "authors": ["Ander Galv\u00e1n", "Marivi Higuero", "Jorge Sasiain", "Eduardo Jacob"], "title": "Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax", "categories": ["cs.CV", "cs.AI"], "comment": "Aceptado para publicaci\\'on, in Spanish language. XVII Jornadas de\n  Ingenier\\'ia Telem\\'atica (JITEL 2025)", "summary": "Facial recognition powered by Artificial Intelligence has achieved high\naccuracy in specific scenarios and applications. Nevertheless, it faces\nsignificant challenges regarding privacy and identity management, particularly\nwhen unknown individuals appear in the operational context. This paper presents\nthe design, implementation, and evaluation of a facial recognition system\nwithin a federated learning framework tailored to open-set scenarios. The\nproposed approach integrates the OpenMax algorithm into federated learning,\nleveraging the exchange of mean activation vectors and local distance measures\nto reliably distinguish between known and unknown subjects. Experimental\nresults validate the effectiveness of the proposed solution, demonstrating its\npotential for enhancing privacy-aware and robust facial recognition in\ndistributed environments.\n  --\n  El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado\nuna alta precisi\\'on en algunos escenarios y aplicaciones. Sin embargo,\npresenta desaf\\'ios relacionados con la privacidad y la identificaci\\'on de\npersonas, especialmente considerando que pueden aparecer sujetos desconocidos\npara el sistema que lo implementa. En este trabajo, se propone el dise\\~no,\nimplementaci\\'on y evaluaci\\'on de un sistema de reconocimiento facial en un\nescenario de aprendizaje federado, orientado a conjuntos abiertos.\nConcretamente, se dise\\~na una soluci\\'on basada en el algoritmo OpenMax para\nescenarios de aprendizaje federado. La propuesta emplea el intercambio de los\nvectores de activaci\\'on promedio y distancias locales para identificar de\nmanera eficaz tanto personas conocidas como desconocidas. Los experimentos\nrealizados demuestran la implementaci\\'on efectiva de la soluci\\'on propuesta.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9002\u7528\u4e8e\u5f00\u653e\u96c6\u573a\u666f\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e0b\u4eba\u8138\u8bc6\u522b\u7cfb\u7edf\uff0c\u7ed3\u5408OpenMax\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u4eba\u8138\u8bc6\u522b\u5728\u7279\u5b9a\u573a\u666f\u6709\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u5728\u9690\u79c1\u548c\u8eab\u4efd\u7ba1\u7406\u65b9\u9762\uff0c\u5c24\u5176\u662f\u9762\u5bf9\u672a\u77e5\u4e2a\u4f53\u65f6\u9762\u4e34\u6311\u6218\u3002", "method": "\u5c06OpenMax\u7b97\u6cd5\u96c6\u6210\u5230\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u5229\u7528\u5e73\u5747\u6fc0\u6d3b\u5411\u91cf\u548c\u5c40\u90e8\u8ddd\u79bb\u5ea6\u91cf\u7684\u4ea4\u6362\u6765\u533a\u5206\u5df2\u77e5\u548c\u672a\u77e5\u4e3b\u4f53\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6848\u6709\u6f5c\u529b\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u589e\u5f3a\u6ce8\u91cd\u9690\u79c1\u4e14\u9c81\u68d2\u7684\u4eba\u8138\u8bc6\u522b\u3002"}}
{"id": "2508.19621", "pdf": "https://arxiv.org/pdf/2508.19621", "abs": "https://arxiv.org/abs/2508.19621", "authors": ["Tiandi Ye", "Wenyan Liu", "Kai Yao", "Lichun Li", "Shangchao Su", "Cen Chen", "Xiang Li", "Shan Yin", "Ming Gao"], "title": "Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by CIKM2025", "summary": "Federated learning (FL) is a privacy-preserving machine learning paradigm\nthat enables collaborative model training across multiple distributed clients\nwithout disclosing their raw data. Personalized federated learning (pFL) has\ngained increasing attention for its ability to address data heterogeneity.\nHowever, most existing pFL methods assume that each client's data follows a\nsingle distribution and learn one client-level personalized model for each\nclient. This assumption often fails in practice, where a single client may\npossess data from multiple sources or domains, resulting in significant\nintra-client heterogeneity and suboptimal performance. To tackle this\nchallenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework\nbased on visual prompt tuning. Specifically, we formulate instance-wise prompt\ngeneration from a Bayesian perspective and model the prompt posterior as an\nimplicit distribution to capture diverse visual semantics. We derive a\nvariational training objective under the semi-implicit variational inference\nframework. Extensive experiments on benchmark datasets demonstrate that\npFedBayesPT consistently outperforms existing pFL methods under both feature\nand label heterogeneity settings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u89c6\u89c9\u63d0\u793a\u8c03\u4f18\u7684\u7ec6\u7c92\u5ea6\u5b9e\u4f8b\u7ea7\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u6846\u67b6pFedBayesPT\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u7279\u5f81\u548c\u6807\u7b7e\u5f02\u8d28\u6027\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5047\u8bbe\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6570\u636e\u9075\u5faa\u5355\u4e00\u5206\u5e03\uff0c\u5728\u5b9e\u8df5\u4e2d\u5e38\u4e0d\u6210\u7acb\uff0c\u5b58\u5728\u663e\u8457\u7684\u5ba2\u6237\u7aef\u5185\u5f02\u8d28\u6027\u548c\u6027\u80fd\u4e0d\u4f73\u95ee\u9898\u3002", "method": "\u4ece\u8d1d\u53f6\u65af\u89d2\u5ea6\u6784\u5efa\u5b9e\u4f8b\u7ea7\u63d0\u793a\u751f\u6210\uff0c\u5c06\u63d0\u793a\u540e\u9a8c\u5efa\u6a21\u4e3a\u9690\u5f0f\u5206\u5e03\u4ee5\u6355\u83b7\u4e0d\u540c\u89c6\u89c9\u8bed\u4e49\uff0c\u5e76\u5728\u534a\u9690\u5f0f\u53d8\u5206\u63a8\u7406\u6846\u67b6\u4e0b\u63a8\u5bfc\u53d8\u5206\u8bad\u7ec3\u76ee\u6807\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cpFedBayesPT\u5728\u7279\u5f81\u548c\u6807\u7b7e\u5f02\u8d28\u6027\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "pFedBayesPT\u80fd\u6709\u6548\u89e3\u51b3\u5ba2\u6237\u7aef\u5185\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u6027\u80fd\u3002"}}
{"id": "2508.19313", "pdf": "https://arxiv.org/pdf/2508.19313", "abs": "https://arxiv.org/abs/2508.19313", "authors": ["Lucas G. Uberti-Bona Marin", "Bram Rijsbosch", "Gerasimos Spanakis", "Konrad Kollnig"], "title": "Are Companies Taking AI Risks Seriously? A Systematic Analysis of Companies' AI Risk Disclosures in SEC 10-K forms", "categories": ["cs.CY", "cs.AI"], "comment": "To be published in the ECML PKDD SoGood (Data Science for Social\n  Good) workshop proceedings", "summary": "As Artificial Intelligence becomes increasingly central to corporate\nstrategies, concerns over its risks are growing too. In response, regulators\nare pushing for greater transparency in how companies identify, report and\nmitigate AI-related risks. In the US, the Securities and Exchange Commission\n(SEC) repeatedly warned companies to provide their investors with more accurate\ndisclosures of AI-related risks; recent enforcement and litigation against\ncompanies' misleading AI claims reinforce these warnings. In the EU, new laws -\nlike the AI Act and Digital Services Act - introduced additional rules on AI\nrisk reporting and mitigation. Given these developments, it is essential to\nexamine if and how companies report AI-related risks to the public. This study\npresents the first large-scale systematic analysis of AI risk disclosures in\nSEC 10-K filings, which require public companies to report material risks to\ntheir company. We analyse over 30,000 filings from more than 7,000 companies\nover the past five years, combining quantitative and qualitative analysis. Our\nfindings reveal a sharp increase in the companies that mention AI risk, up from\n4% in 2020 to over 43% in the most recent 2024 filings. While legal and\ncompetitive AI risks are the most frequently mentioned, we also find growing\nattention to societal AI risks, such as cyberattacks, fraud, and technical\nlimitations of AI systems. However, many disclosures remain generic or lack\ndetails on mitigation strategies, echoing concerns raised recently by the SEC\nabout the quality of AI-related risk reporting. To support future research, we\npublicly release a web-based tool for easily extracting and analysing\nkeyword-based disclosures across SEC filings.", "AI": {"tldr": "\u7814\u7a76\u5bf9SEC 10 - K\u6587\u4ef6\u4e2dAI\u98ce\u9669\u62ab\u9732\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\uff0c\u53d1\u73b0\u63d0\u53caAI\u98ce\u9669\u7684\u516c\u53f8\u6bd4\u4f8b\u5927\u5e45\u4e0a\u5347\uff0c\u4f46\u62ab\u9732\u8d28\u91cf\u6709\u95ee\u9898\uff0c\u8fd8\u53d1\u5e03\u4e86\u5206\u6790\u5de5\u5177\u3002", "motivation": "\u76d1\u7ba1\u673a\u6784\u63a8\u52a8\u4f01\u4e1a\u5bf9AI\u76f8\u5173\u98ce\u9669\u66f4\u900f\u660e\uff0c\u9700\u7814\u7a76\u4f01\u4e1a\u662f\u5426\u53ca\u5982\u4f55\u5411\u516c\u4f17\u62a5\u544aAI\u98ce\u9669\u3002", "method": "\u5bf9\u8d857000\u5bb6\u516c\u53f8\u8fc7\u53bb\u4e94\u5e74\u8d8530000\u4efdSEC 10 - K\u6587\u4ef6\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u63d0\u53caAI\u98ce\u9669\u7684\u516c\u53f8\u4ece2020\u5e74\u76844%\u5347\u81f32024\u5e74\u7684\u8d8543%\uff0c\u6cd5\u5f8b\u548c\u7ade\u4e89\u98ce\u9669\u6700\u5e38\u88ab\u63d0\u53ca\uff0c\u5bf9\u793e\u4f1a\u98ce\u9669\u5173\u6ce8\u589e\u52a0\uff0c\u4f46\u62ab\u9732\u7f3a\u4e4f\u7ec6\u8282\u3002", "conclusion": "\u5f88\u591aAI\u98ce\u9669\u62ab\u9732\u8d28\u91cf\u6b20\u4f73\uff0c\u53d1\u5e03\u5de5\u5177\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2508.19659", "pdf": "https://arxiv.org/pdf/2508.19659", "abs": "https://arxiv.org/abs/2508.19659", "authors": ["Ri Su", "Zhao Chen", "Caleb Chen Cao", "Nan Tang", "Lei Chen"], "title": "SCAR: A Characterization Scheme for Multi-Modal Dataset", "categories": ["cs.LG"], "comment": "6 pages, 3 figures", "summary": "Foundation models exhibit remarkable generalization across diverse tasks,\nlargely driven by the characteristics of their training data. Recent\ndata-centric methods like pruning and compression aim to optimize training but\noffer limited theoretical insight into how data properties affect\ngeneralization, especially the data characteristics in sample scaling.\nTraditional perspectives further constrain progress by focusing predominantly\non data quantity and training efficiency, often overlooking structural aspects\nof data quality. In this study, we introduce SCAR, a principled scheme for\ncharacterizing the intrinsic structural properties of datasets across four key\nmeasures: Scale, Coverage, Authenticity, and Richness. Unlike prior\ndata-centric measures, SCAR captures stable characteristics that remain\ninvariant under dataset scaling, providing a robust and general foundation for\ndata understanding. Leveraging these structural properties, we introduce\nFoundation Data-a minimal subset that preserves the generalization behavior of\nthe full dataset without requiring model-specific retraining. We model\nsingle-modality tasks as step functions and estimate the distribution of the\nfoundation data size to capture step-wise generalization bias across modalities\nin the target multi-modal dataset. Finally, we develop a SCAR-guided data\ncompletion strategy based on this generalization bias, which enables efficient,\nmodality-aware expansion of modality-specific characteristics in multimodal\ndatasets. Experiments across diverse multi-modal datasets and model\narchitectures validate the effectiveness of SCAR in predicting data utility and\nguiding data acquisition. Code is available at https://github.com/McAloma/SCAR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCAR\u65b9\u6848\u523b\u753b\u6570\u636e\u96c6\u7ed3\u6784\u7279\u6027\uff0c\u5f15\u5165\u57fa\u7840\u6570\u636e\u6982\u5ff5\uff0c\u5efa\u6a21\u5355\u6a21\u6001\u4efb\u52a1\uff0c\u5f00\u53d1\u6570\u636e\u8865\u5168\u7b56\u7565\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u4e2d\u5fc3\u65b9\u6cd5\u5bf9\u6570\u636e\u7279\u6027\u5f71\u54cd\u6cdb\u5316\u7684\u7406\u8bba\u6d1e\u5bdf\u6709\u9650\uff0c\u4f20\u7edf\u89c6\u89d2\u5ffd\u89c6\u6570\u636e\u8d28\u91cf\u7ed3\u6784\u65b9\u9762\u3002", "method": "\u5f15\u5165SCAR\u65b9\u6848\u4ece\u56db\u65b9\u9762\u523b\u753b\u6570\u636e\u96c6\u7279\u6027\uff0c\u5b9a\u4e49\u57fa\u7840\u6570\u636e\uff0c\u5efa\u6a21\u5355\u6a21\u6001\u4efb\u52a1\uff0c\u57fa\u4e8e\u6cdb\u5316\u504f\u5dee\u5f00\u53d1\u6570\u636e\u8865\u5168\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86SCAR\u5728\u9884\u6d4b\u6570\u636e\u6548\u7528\u548c\u6307\u5bfc\u6570\u636e\u83b7\u53d6\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "SCAR\u4e3a\u6570\u636e\u7406\u89e3\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u80fd\u6709\u6548\u6307\u5bfc\u591a\u6a21\u6001\u6570\u636e\u96c6\u7684\u6570\u636e\u83b7\u53d6\u3002"}}
{"id": "2508.19314", "pdf": "https://arxiv.org/pdf/2508.19314", "abs": "https://arxiv.org/abs/2508.19314", "authors": ["Mahdis Tourian", "Sareh Rowlands", "Remy Vandaele", "Max Fancourt", "Rebecca Mein", "Hywel T. P. Williams"], "title": "Automated classification of natural habitats using ground-level imagery", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 6 figures, 2 tables", "summary": "Accurate classification of terrestrial habitats is critical for biodiversity\nconservation, ecological monitoring, and land-use planning. Several habitat\nclassification schemes are in use, typically based on analysis of satellite\nimagery with validation by field ecologists. Here we present a methodology for\nclassification of habitats based solely on ground-level imagery (photographs),\noffering improved validation and the ability to classify habitats at scale (for\nexample using citizen-science imagery). In collaboration with Natural England,\na public sector organisation responsible for nature conservation in England,\nthis study develops a classification system that applies deep learning to\nground-level habitat photographs, categorising each image into one of 18\nclasses defined by the 'Living England' framework. Images were pre-processed\nusing resizing, normalisation, and augmentation; re-sampling was used to\nbalance classes in the training data and enhance model robustness. We developed\nand fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label\nto each photograph. Using five-fold cross-validation, the model demonstrated\nstrong overall performance across 18 habitat classes, with accuracy and\nF1-scores varying between classes. Across all folds, the model achieved a mean\nF1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and\nPeat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or\nambiguous classes scoring lower. These findings demonstrate the potential of\nthis approach for ecological monitoring. Ground-level imagery is readily\nobtained, and accurate computational methods for habitat classification based\non such data have many potential applications. To support use by practitioners,\nwe also provide a simple web application that classifies uploaded images using\nour model.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5730\u9762\u56fe\u50cf\u7684\u6816\u606f\u5730\u5206\u7c7b\u65b9\u6cd5\uff0c\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5206\u7c7b\uff0c\u6548\u679c\u826f\u597d\u4e14\u6709\u7f51\u7edc\u5e94\u7528", "motivation": "\u73b0\u6709\u6816\u606f\u5730\u5206\u7c7b\u65b9\u6848\u4f9d\u8d56\u536b\u661f\u56fe\u50cf\uff0c\u9700\u6539\u8fdb\u9a8c\u8bc1\u5e76\u5b9e\u73b0\u5927\u89c4\u6a21\u5206\u7c7b", "method": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u5904\u7406\u5730\u9762\u6816\u606f\u5730\u7167\u7247\uff0c\u56fe\u50cf\u9884\u5904\u7406\uff0c\u7528\u91cd\u91c7\u6837\u5e73\u8861\u6570\u636e\uff0c\u5f00\u53d1\u5e76\u5fae\u8c03DeepLabV3 - ResNet101\u5206\u7c7b\u5668\uff0c\u7528\u4e94\u6298\u4ea4\u53c9\u9a8c\u8bc1", "result": "\u6a21\u578b\u572818\u4e2a\u6816\u606f\u5730\u7c7b\u522b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5e73\u5747F1\u5206\u65700.61\uff0c\u90e8\u5206\u7c7b\u522b\u8d850.90\uff0c\u90e8\u5206\u8f83\u4f4e", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u751f\u6001\u76d1\u6d4b\u6f5c\u529b\uff0c\u5730\u9762\u56fe\u50cf\u6613\u83b7\u53d6\uff0c\u57fa\u4e8e\u6b64\u7684\u5206\u7c7b\u65b9\u6cd5\u6709\u8bf8\u591a\u5e94\u7528\uff0c\u8fd8\u63d0\u4f9b\u7f51\u7edc\u5e94\u7528"}}
{"id": "2508.19661", "pdf": "https://arxiv.org/pdf/2508.19661", "abs": "https://arxiv.org/abs/2508.19661", "authors": ["Florentia Afentaki", "Sri Sai Rakesh Nakkilla", "Konstantinos Balaskas", "Paula Carolina Lozano Duarte", "Shiyi Jiang", "Georgios Zervakis", "Farshad Firouzi", "Krishnendu Chakrabarty", "Mehdi B. Tahoori"], "title": "Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables", "categories": ["cs.LG", "cs.AR"], "comment": "Accepted for publication at the IEEE/ACM International Symposium on\n  Low Power Electronics and Design} (ISLPED 2025)", "summary": "Conventional stress monitoring relies on episodic, symptom-focused\ninterventions, missing the need for continuous, accessible, and cost-efficient\nsolutions. State-of-the-art approaches use rigid, silicon-based wearables,\nwhich, though capable of multitasking, are not optimized for lightweight,\nflexible wear, limiting their practicality for continuous monitoring. In\ncontrast, flexible electronics (FE) offer flexibility and low manufacturing\ncosts, enabling real-time stress monitoring circuits. However, implementing\ncomplex circuits like machine learning (ML) classifiers in FE is challenging\ndue to integration and power constraints. Previous research has explored\nflexible biosensors and ADCs, but classifier design for stress detection\nremains underexplored. This work presents the first comprehensive design space\nexploration of low-power, flexible stress classifiers. We cover various ML\nclassifiers, feature selection, and neural simplification algorithms, with over\n1200 flexible classifiers. To optimize hardware efficiency, fully customized\ncircuits with low-precision arithmetic are designed in each case. Our\nexploration provides insights into designing real-time stress classifiers that\noffer higher accuracy than current methods, while being low-cost, conformable,\nand ensuring low power and compact size.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4f4e\u529f\u8017\u3001\u67d4\u6027\u538b\u529b\u5206\u7c7b\u5668\u8fdb\u884c\u5168\u9762\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff0c\u8bbe\u8ba1\u8d851200\u4e2a\u67d4\u6027\u5206\u7c7b\u5668\uff0c\u63d0\u4f9b\u8bbe\u8ba1\u5b9e\u65f6\u538b\u529b\u5206\u7c7b\u5668\u7684\u89c1\u89e3\u3002", "motivation": "\u4f20\u7edf\u538b\u529b\u76d1\u6d4b\u7f3a\u4e4f\u8fde\u7eed\u3001\u4fbf\u6377\u4e14\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u73b0\u6709\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0d\u9002\u5408\u8fde\u7eed\u76d1\u6d4b\uff0c\u5728\u67d4\u6027\u7535\u5b50\u4e2d\u5b9e\u73b0\u590d\u6742\u7535\u8def\u6709\u6311\u6218\uff0c\u4e14\u538b\u529b\u68c0\u6d4b\u5206\u7c7b\u5668\u8bbe\u8ba1\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5bf9\u5404\u79cd\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u3001\u7279\u5f81\u9009\u62e9\u548c\u795e\u7ecf\u7b80\u5316\u7b97\u6cd5\u8fdb\u884c\u63a2\u7d22\uff0c\u4e3a\u6bcf\u79cd\u60c5\u51b5\u8bbe\u8ba1\u5168\u5b9a\u5236\u7684\u4f4e\u7cbe\u5ea6\u7b97\u672f\u7535\u8def\u3002", "result": "\u6b64\u6b21\u63a2\u7d22\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u5b9e\u65f6\u538b\u529b\u5206\u7c7b\u5668\u7684\u89c1\u89e3\uff0c\u5176\u6bd4\u73b0\u6709\u65b9\u6cd5\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u4e14\u5177\u5907\u4f4e\u6210\u672c\u3001\u8d34\u5408\u3001\u4f4e\u529f\u8017\u548c\u5c0f\u5c3a\u5bf8\u7684\u7279\u70b9\u3002", "conclusion": "\u901a\u8fc7\u5168\u9762\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff0c\u6709\u671b\u8bbe\u8ba1\u51fa\u66f4\u4f18\u7684\u5b9e\u65f6\u538b\u529b\u5206\u7c7b\u5668\u3002"}}
{"id": "2508.19317", "pdf": "https://arxiv.org/pdf/2508.19317", "abs": "https://arxiv.org/abs/2508.19317", "authors": ["Kimmo Eriksson", "Simon Karlsson", "Irina Vartanova", "Pontus Strimling"], "title": "What Makes AI Applications Acceptable or Unacceptable? A Predictive Moral Framework", "categories": ["cs.CY", "cs.AI"], "comment": "15 pages + supplementary materials, 3 figures", "summary": "As artificial intelligence rapidly transforms society, developers and\npolicymakers struggle to anticipate which applications will face public moral\nresistance. We propose that these judgments are not idiosyncratic but\nsystematic and predictable. In a large, preregistered study (N = 587, U.S.\nrepresentative sample), we used a comprehensive taxonomy of 100 AI applications\nspanning personal and organizational contexts-including both functional uses\nand the moral treatment of AI itself. In participants' collective judgment,\napplications ranged from highly unacceptable to fully acceptable. We found this\nvariation was strongly predictable: five core moral qualities-perceived risk,\nbenefit, dishonesty, unnaturalness, and reduced accountability-collectively\nexplained over 90% of the variance in acceptability ratings. The framework\ndemonstrated strong predictive power across all domains and successfully\npredicted individual-level judgments for held-out applications. These findings\nreveal that a structured moral psychology underlies public evaluation of new\ntechnologies, offering a powerful tool for anticipating public resistance and\nguiding responsible innovation in AI.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u516c\u4f17\u5bf9AI\u5e94\u7528\u7684\u9053\u5fb7\u63a5\u53d7\u5ea6\u5224\u65ad\u662f\u53ef\u9884\u6d4b\u7684\uff0c\u4e94\u4e2a\u6838\u5fc3\u9053\u5fb7\u54c1\u8d28\u53ef\u89e3\u91ca\u8d8590%\u7684\u63a5\u53d7\u5ea6\u5dee\u5f02\u3002", "motivation": "\u5728AI\u5feb\u901f\u53d8\u9769\u793e\u4f1a\u80cc\u666f\u4e0b\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u9884\u6d4b\u54ea\u4e9bAI\u5e94\u7528\u4f1a\u9762\u4e34\u516c\u4f17\u9053\u5fb7\u62b5\u5236\u3002", "method": "\u8fdb\u884c\u4e00\u9879\u5927\u89c4\u6a21\u9884\u6ce8\u518c\u7814\u7a76\uff0c\u91c7\u7528\u6db5\u76d6100\u79cdAI\u5e94\u7528\u7684\u7efc\u5408\u5206\u7c7b\u6cd5\uff0c\u5bf9\u7f8e\u56fd\u4ee3\u8868\u6027\u6837\u672c\uff08N = 587\uff09\u8fdb\u884c\u8c03\u67e5\u3002", "result": "AI\u5e94\u7528\u63a5\u53d7\u5ea6\u5dee\u5f02\u5f3a\u53ef\u9884\u6d4b\uff0c\u4e94\u4e2a\u6838\u5fc3\u9053\u5fb7\u54c1\u8d28\u80fd\u89e3\u91ca\u8d8590%\u7684\u63a5\u53d7\u5ea6\u8bc4\u5206\u5dee\u5f02\uff0c\u6846\u67b6\u5728\u5404\u9886\u57df\u6709\u5f3a\u9884\u6d4b\u529b\u3002", "conclusion": "\u516c\u4f17\u5bf9\u65b0\u6280\u672f\u7684\u8bc4\u4f30\u6709\u7ed3\u6784\u5316\u9053\u5fb7\u5fc3\u7406\u57fa\u7840\uff0c\u53ef\u7528\u4e8e\u9884\u6d4b\u516c\u4f17\u62b5\u5236\u548c\u6307\u5bfcAI\u8d1f\u8d23\u4efb\u521b\u65b0\u3002"}}
{"id": "2508.19672", "pdf": "https://arxiv.org/pdf/2508.19672", "abs": "https://arxiv.org/abs/2508.19672", "authors": ["Erion Morina", "Martin Holler"], "title": "$\\mathcal{C}^1$-approximation with rational functions and rational neural networks", "categories": ["cs.LG", "cs.IT", "cs.NA", "math.IT", "math.NA", "33F05, 41A20, 41A25, 26C15"], "comment": null, "summary": "We show that suitably regular functions can be approximated in the\n$\\mathcal{C}^1$-norm both with rational functions and rational neural networks,\nincluding approximation rates with respect to width and depth of the network,\nand degree of the rational functions. As consequence of our results, we further\nobtain $\\mathcal{C}^1$-approximation results for rational neural networks with\nthe $\\text{EQL}^\\div$ and ParFam architecture, both of which are important in\nparticular in the context of symbolic regression for physical law learning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.19709", "pdf": "https://arxiv.org/pdf/2508.19709", "abs": "https://arxiv.org/abs/2508.19709", "authors": ["R. Arnau", "A. Gonz\u00e1lez Cort\u00e9s", "E. A. S\u00e1nchez P\u00e9rez", "S. Sanjuan"], "title": "Metric spaces of walks and Lipschitz duality on graphs", "categories": ["cs.LG", "math.FA", "26A16"], "comment": "31 pages, 3 figures", "summary": "We study the metric structure of walks on graphs, understood as Lipschitz\nsequences. To this end, a weighted metric is introduced to handle sequences,\nenabling the definition of distances between walks based on stepwise vertex\ndistances and weighted norms. We analyze the main properties of these metric\nspaces, which provides the foundation for the analysis of weaker forms of\ninstruments to measure relative distances between walks: proximities. We\nprovide some representation formulas for such proximities under different\nassumptions and provide explicit constructions for these cases. The resulting\nmetric framework allows the use of classical tools from metric modeling, such\nas the extension of Lipschitz functions from subspaces of walks, which permits\nextending proximity functions while preserving fundamental properties via the\nmentioned representations. Potential applications include the estimation of\nproximities and the development of reinforcement learning strategies based on\nexploratory walks, offering a robust approach to Lipschitz regression on\nnetwork structures.", "AI": {"tldr": "\u7814\u7a76\u56fe\u4e0a\u884c\u8d70\u7684\u5ea6\u91cf\u7ed3\u6784\uff0c\u5f15\u5165\u52a0\u6743\u5ea6\u91cf\uff0c\u5206\u6790\u5ea6\u91cf\u7a7a\u95f4\u6027\u8d28\uff0c\u7ed9\u51fa\u63a5\u8fd1\u5ea6\u8868\u793a\u516c\u5f0f\u548c\u6784\u9020\uff0c\u7528\u4e8e\u7ecf\u5178\u5ea6\u91cf\u5efa\u6a21\u5de5\u5177\uff0c\u6709\u6f5c\u5728\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u56fe\u4e0a\u884c\u8d70\u4f5c\u4e3aLipschitz\u5e8f\u5217\u7684\u5ea6\u91cf\u7ed3\u6784\u3002", "method": "\u5f15\u5165\u52a0\u6743\u5ea6\u91cf\u5904\u7406\u5e8f\u5217\uff0c\u5b9a\u4e49\u884c\u8d70\u95f4\u8ddd\u79bb\uff0c\u5206\u6790\u5ea6\u91cf\u7a7a\u95f4\u6027\u8d28\uff0c\u63a8\u5bfc\u63a5\u8fd1\u5ea6\u8868\u793a\u516c\u5f0f\u3002", "result": "\u5efa\u7acb\u4e86\u5ea6\u91cf\u6846\u67b6\uff0c\u53ef\u4f7f\u7528\u7ecf\u5178\u5ea6\u91cf\u5efa\u6a21\u5de5\u5177\uff0c\u5982\u6269\u5c55Lipschitz\u51fd\u6570\u3002", "conclusion": "\u8be5\u5ea6\u91cf\u6846\u67b6\u53ef\u7528\u4e8e\u4f30\u8ba1\u63a5\u8fd1\u5ea6\u548c\u5f00\u53d1\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u7f51\u7edc\u7ed3\u6784\u4e0a\u7684Lipschitz\u56de\u5f52\u3002"}}
{"id": "2508.19319", "pdf": "https://arxiv.org/pdf/2508.19319", "abs": "https://arxiv.org/abs/2508.19319", "authors": ["Pardis Moradbeiki", "Nasser Ghadiri", "Sayed Jalal Zahabi", "Uffe Kock Wiil", "Kristoffer Kittelmann Brockhattingen", "Ali Ebrahimi"], "title": "MedVQA-TREE: A Multimodal Reasoning and Retrieval Framework for Sarcopenia Prediction", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Accurate sarcopenia diagnosis via ultrasound remains challenging due to\nsubtle imaging cues, limited labeled data, and the absence of clinical context\nin most models. We propose MedVQA-TREE, a multimodal framework that integrates\na hierarchical image interpretation module, a gated feature-level fusion\nmechanism, and a novel multi-hop, multi-query retrieval strategy. The vision\nmodule includes anatomical classification, region segmentation, and graph-based\nspatial reasoning to capture coarse, mid-level, and fine-grained structures. A\ngated fusion mechanism selectively integrates visual features with textual\nqueries, while clinical knowledge is retrieved through a UMLS-guided pipeline\naccessing PubMed and a sarcopenia-specific external knowledge base. MedVQA-TREE\nwas trained and evaluated on two public MedVQA datasets (VQA-RAD and PathVQA)\nand a custom sarcopenia ultrasound dataset. The model achieved up to 99%\ndiagnostic accuracy and outperformed previous state-of-the-art methods by over\n10%. These results underscore the benefit of combining structured visual\nunderstanding with guided knowledge retrieval for effective AI-assisted\ndiagnosis in sarcopenia.", "AI": {"tldr": "\u63d0\u51faMedVQA - TREE\u591a\u6a21\u6001\u6846\u67b6\u7528\u4e8e\u808c\u8089\u51cf\u5c11\u75c7\u8d85\u58f0\u8bca\u65ad\uff0c\u5728\u591a\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u51c6\u786e\u7387\u9ad8\u3002", "motivation": "\u73b0\u6709\u8d85\u58f0\u808c\u8089\u51cf\u5c11\u75c7\u8bca\u65ad\u56e0\u6210\u50cf\u7ebf\u7d22\u5fae\u5999\u3001\u6807\u6ce8\u6570\u636e\u6709\u9650\u548c\u7f3a\u4e4f\u4e34\u5e8a\u80cc\u666f\u800c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faMedVQA - TREE\u6846\u67b6\uff0c\u5305\u542b\u5206\u5c42\u56fe\u50cf\u89e3\u91ca\u6a21\u5757\u3001\u95e8\u63a7\u7279\u5f81\u7ea7\u878d\u5408\u673a\u5236\u548c\u591a\u8df3\u591a\u67e5\u8be2\u68c0\u7d22\u7b56\u7565\uff0c\u8fd8\u901a\u8fc7UMLS\u5f15\u5bfc\u7ba1\u9053\u8bbf\u95ee\u77e5\u8bc6\u6e90\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171MedVQA\u6570\u636e\u96c6\u548c\u81ea\u5b9a\u4e49\u808c\u8089\u51cf\u5c11\u75c7\u8d85\u58f0\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u6a21\u578b\u8bca\u65ad\u51c6\u786e\u7387\u8fbe99%\uff0c\u6bd4\u5148\u524d\u65b9\u6cd5\u9ad8\u8d8510%\u3002", "conclusion": "\u7ed3\u5408\u7ed3\u6784\u5316\u89c6\u89c9\u7406\u89e3\u548c\u5f15\u5bfc\u77e5\u8bc6\u68c0\u7d22\u5bf9\u808c\u8089\u51cf\u5c11\u75c7\u7684AI\u8f85\u52a9\u8bca\u65ad\u6709\u76ca\u3002"}}
{"id": "2508.19733", "pdf": "https://arxiv.org/pdf/2508.19733", "abs": "https://arxiv.org/abs/2508.19733", "authors": ["Theodoros Athanasiadis", "Steven Adriaensen", "Samuel M\u00fcller", "Frank Hutter"], "title": "Tune My Adam, Please!", "categories": ["cs.LG"], "comment": "Accepted as a short paper at the non-archival content track of AutoML\n  2025", "summary": "The Adam optimizer remains one of the most widely used optimizers in deep\nlearning, and effectively tuning its hyperparameters is key to optimizing\nperformance. However, tuning can be tedious and costly. Freeze-thaw Bayesian\nOptimization (BO) is a recent promising approach for low-budget hyperparameter\ntuning, but is limited by generic surrogates without prior knowledge of how\nhyperparameters affect learning. We propose Adam-PFN, a new surrogate model for\nFreeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from\nTaskSet, together with a new learning curve augmentation method, CDF-augment,\nwhich artificially increases the number of available training examples. Our\napproach improves both learning curve extrapolation and accelerates\nhyperparameter optimization on TaskSet evaluation tasks, with strong\nperformance on out-of-distribution (OOD) tasks.", "AI": {"tldr": "\u63d0\u51faAdam - PFN\u7528\u4e8eAdam\u4f18\u5316\u5668\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u7ed3\u5408CDF - augment\u65b9\u6cd5\uff0c\u63d0\u5347\u5b66\u4e60\u66f2\u7ebf\u5916\u63a8\u548c\u8d85\u53c2\u4f18\u5316\u6548\u679c\u3002", "motivation": "Adam\u4f18\u5316\u5668\u8d85\u53c2\u6570\u8c03\u4f18\u7e41\u7410\u4e14\u6210\u672c\u9ad8\uff0c\u73b0\u6709Freeze - thaw BO\u65b9\u6cd5\u53d7\u9650\u4e8e\u65e0\u5148\u9a8c\u77e5\u8bc6\u7684\u901a\u7528\u4ee3\u7406\u6a21\u578b\u3002", "method": "\u63d0\u51faAdam - PFN\u4f5c\u4e3aFreeze - thaw BO\u7684\u65b0\u4ee3\u7406\u6a21\u578b\uff0c\u5728TaskSet\u5b66\u4e60\u66f2\u7ebf\u4e0a\u9884\u8bad\u7ec3\uff0c\u5e76\u4f7f\u7528CDF - augment\u5b66\u4e60\u66f2\u7ebf\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "\u5728TaskSet\u8bc4\u4f30\u4efb\u52a1\u4e2d\u6539\u5584\u5b66\u4e60\u66f2\u7ebf\u5916\u63a8\uff0c\u52a0\u901f\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u5728\u5206\u5e03\u5916\u4efb\u52a1\u4e2d\u6709\u826f\u597d\u8868\u73b0\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3Adam\u4f18\u5316\u5668\u8d85\u53c2\u6570\u8c03\u4f18\u95ee\u9898\u3002"}}
{"id": "2508.19320", "pdf": "https://arxiv.org/pdf/2508.19320", "abs": "https://arxiv.org/abs/2508.19320", "authors": ["Ming Chen", "Liyuan Cui", "Wenyuan Zhang", "Haoxian Zhang", "Yan Zhou", "Xiaohan Li", "Xiaoqiang Liu", "Pengfei Wan"], "title": "MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Technical Report. Project Page: https://chenmingthu.github.io/milm/", "summary": "Recently, interactive digital human video generation has attracted widespread\nattention and achieved remarkable progress. However, building such a practical\nsystem that can interact with diverse input signals in real time remains\nchallenging to existing methods, which often struggle with high latency, heavy\ncomputational cost, and limited controllability. In this work, we introduce an\nautoregressive video generation framework that enables interactive multimodal\ncontrol and low-latency extrapolation in a streaming manner. With minimal\nmodifications to a standard large language model (LLM), our framework accepts\nmultimodal condition encodings including audio, pose, and text, and outputs\nspatially and semantically coherent representations to guide the denoising\nprocess of a diffusion head. To support this, we construct a large-scale\ndialogue dataset of approximately 20,000 hours from multiple sources, providing\nrich conversational scenarios for training. We further introduce a deep\ncompression autoencoder with up to 64$\\times$ reduction ratio, which\neffectively alleviates the long-horizon inference burden of the autoregressive\nmodel. Extensive experiments on duplex conversation, multilingual human\nsynthesis, and interactive world model highlight the advantages of our approach\nin low latency, high efficiency, and fine-grained multimodal controllability.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u56de\u5f52\u89c6\u9891\u751f\u6210\u6846\u67b6\uff0c\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u591a\u6a21\u6001\u63a7\u5236\u548c\u4f4e\u5ef6\u8fdf\u5916\u63a8\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u6548\u548c\u7ec6\u7c92\u5ea6\u591a\u6a21\u6001\u53ef\u63a7\u7684\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u4ea4\u4e92\u5f0f\u6570\u5b57\u4eba\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u9ad8\u5ef6\u8fdf\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u53ef\u63a7\u6027\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u6784\u5efa\u80fd\u5b9e\u65f6\u4e0e\u591a\u6837\u8f93\u5165\u4fe1\u53f7\u4ea4\u4e92\u7684\u5b9e\u7528\u7cfb\u7edf\u3002", "method": "\u5f15\u5165\u81ea\u56de\u5f52\u89c6\u9891\u751f\u6210\u6846\u67b6\uff0c\u5bf9\u6807\u51c6\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6700\u5c0f\u4fee\u6539\u4ee5\u63a5\u53d7\u591a\u6a21\u6001\u6761\u4ef6\u7f16\u7801\uff0c\u6784\u5efa\u7ea620000\u5c0f\u65f6\u7684\u5927\u89c4\u6a21\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5f15\u5165\u6df1\u5ea6\u538b\u7f29\u81ea\u7f16\u7801\u5668\u51cf\u8f7b\u63a8\u7406\u8d1f\u62c5\u3002", "result": "\u5728\u53cc\u5411\u5bf9\u8bdd\u3001\u591a\u8bed\u8a00\u4eba\u7269\u5408\u6210\u548c\u4ea4\u4e92\u5f0f\u4e16\u754c\u6a21\u578b\u7684\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u51fa\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u6548\u548c\u7ec6\u7c92\u5ea6\u591a\u6a21\u6001\u53ef\u63a7\u7684\u4f18\u52bf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u56de\u5f52\u89c6\u9891\u751f\u6210\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u591a\u6a21\u6001\u63a7\u5236\u548c\u4f4e\u5ef6\u8fdf\u5916\u63a8\u3002"}}
{"id": "2508.19737", "pdf": "https://arxiv.org/pdf/2508.19737", "abs": "https://arxiv.org/abs/2508.19737", "authors": ["Meng Qin", "Weihua Li", "Jinqiang Cui", "Sen Pei"], "title": "InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Graph partitioning (GP), a.k.a. community detection, is a classic problem\nthat divides nodes of a graph into densely-connected blocks. From a perspective\nof graph signal processing, we find that graph Laplacian with a negative\ncorrection can derive graph frequencies beyond the conventional range $[0, 2]$.\nTo explore whether the low-frequency information beyond this range can encode\nmore informative properties about community structures, we propose InfraredGP.\nIt (\\romannumeral1) adopts a spectral GNN as its backbone combined with\nlow-pass filters and a negative correction mechanism, (\\romannumeral2) only\nfeeds random inputs to this backbone, (\\romannumeral3) derives graph embeddings\nvia one feed-forward propagation (FFP) without any training, and\n(\\romannumeral4) obtains feasible GP results by feeding the derived embeddings\nto BIRCH. Surprisingly, our experiments demonstrate that based solely on the\nnegative correction mechanism that amplifies low-frequency information beyond\n$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard\nclustering modules (e.g., BIRCH) and obtain high-quality results for GP without\nany training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate\nInfraredGP for both static and streaming GP, where InfraredGP can achieve much\nbetter efficiency (e.g., 16x-23x faster) and competitive quality over various\nbaselines. We have made our code public at\nhttps://github.com/KuroginQin/InfraredGP", "AI": {"tldr": "\u672c\u6587\u4ece\u56fe\u4fe1\u53f7\u5904\u7406\u89d2\u5ea6\u51fa\u53d1\uff0c\u63d0\u51faInfraredGP\u7528\u4e8e\u56fe\u5212\u5206\uff0c\u4e0d\u8bad\u7ec3\u5373\u53ef\u83b7\u9ad8\u8d28\u91cf\u7ed3\u679c\u4e14\u6548\u7387\u9ad8\u3002", "motivation": "\u63a2\u7d22\u56fe\u62c9\u666e\u62c9\u65af\u8d1f\u4fee\u6b63\u540e\u8d85\u51fa\u5e38\u89c4\u8303\u56f4\u7684\u4f4e\u9891\u4fe1\u606f\u80fd\u5426\u7f16\u7801\u66f4\u591a\u793e\u533a\u7ed3\u6784\u7279\u6027\u3002", "method": "\u91c7\u7528\u8c31GNN\u4e3a\u9aa8\u5e72\uff0c\u7ed3\u5408\u4f4e\u901a\u6ee4\u6ce2\u5668\u548c\u8d1f\u4fee\u6b63\u673a\u5236\uff0c\u4ec5\u8f93\u5165\u968f\u673a\u6570\u636e\uff0c\u7ecf\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u5f97\u5230\u56fe\u5d4c\u5165\uff0c\u518d\u7528BIRCH\u805a\u7c7b\u3002", "result": "InfraredGP\u80fd\u4e3a\u805a\u7c7b\u6a21\u5757\u751f\u6210\u53ef\u533a\u5206\u7684\u5d4c\u5165\uff0c\u5728\u9759\u6001\u548c\u6d41\u56fe\u5212\u5206\u4e2d\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6548\u7387\u9ad8\uff08\u5feb16 - 23\u500d\uff09\u4e14\u8d28\u91cf\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u57fa\u4e8e\u8d1f\u4fee\u6b63\u673a\u5236\u653e\u5927\u8d85\u51fa[0, 2]\u8303\u56f4\u7684\u4f4e\u9891\u4fe1\u606f\uff0cInfraredGP\u4e0d\u8bad\u7ec3\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u8d28\u91cf\u56fe\u5212\u5206\u3002"}}
{"id": "2508.19321", "pdf": "https://arxiv.org/pdf/2508.19321", "abs": "https://arxiv.org/abs/2508.19321", "authors": ["Kehao Miao", "Xiaolong Jin"], "title": "An Investigation on Group Query Hallucination Attacks", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "With the widespread use of large language models (LLMs), understanding their\npotential failure modes during user interactions is essential. In practice,\nusers often pose multiple questions in a single conversation with LLMs.\nTherefore, in this study, we propose Group Query Attack, a technique that\nsimulates this scenario by presenting groups of queries to LLMs simultaneously.\nWe investigate how the accumulated context from consecutive prompts influences\nthe outputs of LLMs. Specifically, we observe that Group Query Attack\nsignificantly degrades the performance of models fine-tuned on specific tasks.\nMoreover, we demonstrate that Group Query Attack induces a risk of triggering\npotential backdoors of LLMs. Besides, Group Query Attack is also effective in\ntasks involving reasoning, such as mathematical reasoning and code generation\nfor pre-trained and aligned models.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faGroup Query Attack\u6280\u672f\uff0c\u7814\u7a76\u8fde\u7eed\u63d0\u793a\u4e0a\u4e0b\u6587\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u5f71\u54cd\uff0c\u53d1\u73b0\u8be5\u653b\u51fb\u4f1a\u964d\u4f4e\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u6a21\u578b\u6027\u80fd\u3001\u5f15\u53d1\u6f5c\u5728\u540e\u95e8\u98ce\u9669\uff0c\u5bf9\u63a8\u7406\u4efb\u52a1\u4e5f\u6709\u6548\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u4f7f\u7528\uff0c\u9700\u4e86\u89e3\u5176\u5728\u7528\u6237\u4ea4\u4e92\u4e2d\u7684\u6f5c\u5728\u5931\u8d25\u6a21\u5f0f\uff0c\u4e14\u7528\u6237\u5e38\u4e00\u6b21\u5bf9\u8bdd\u63d0\u591a\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51faGroup Query Attack\u6280\u672f\uff0c\u540c\u65f6\u5411\u5927\u8bed\u8a00\u6a21\u578b\u5448\u73b0\u591a\u7ec4\u67e5\u8be2\uff0c\u7814\u7a76\u8fde\u7eed\u63d0\u793a\u79ef\u7d2f\u7684\u4e0a\u4e0b\u6587\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u5f71\u54cd\u3002", "result": "Group Query Attack\u663e\u8457\u964d\u4f4e\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5f15\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u6f5c\u5728\u540e\u95e8\u98ce\u9669\uff0c\u5bf9\u9884\u8bad\u7ec3\u548c\u5bf9\u9f50\u6a21\u578b\u7684\u63a8\u7406\u4efb\u52a1\u4e5f\u6709\u6548\u3002", "conclusion": "Group Query Attack\u6280\u672f\u80fd\u6709\u6548\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u67e5\u8be2\u573a\u666f\u4e0b\u7684\u6f5c\u5728\u95ee\u9898\u3002"}}
{"id": "2508.19752", "pdf": "https://arxiv.org/pdf/2508.19752", "abs": "https://arxiv.org/abs/2508.19752", "authors": ["Muhammad Moeeze Hassan", "R\u00e9gis Cottereau", "Filippo Gatti", "Patryk Dec"], "title": "Fast 3D Diffusion for Scalable Granular Media Synthesis", "categories": ["cs.LG"], "comment": null, "summary": "Simulating granular media, using Discrete Element Method is a computationally\nintensive task. This is especially true during initialization phase, which\ndominates total simulation time because of large displacements involved and\nassociated kinetic energy. We overcome this bottleneck with a novel generative\npipeline based on 3D diffusion models that directly synthesizes arbitrarily\nlarge granular assemblies in their final and physically realistic\nconfigurations. The approach frames the problem as a 3D generative modeling\ntask, consisting of a two-stage pipeline. First a diffusion model is trained to\ngenerate independent 3D voxel grids representing granular media. Second, a 3D\ninpainting model, adapted from 2D inpainting techniques using masked inputs,\nstitches these grids together seamlessly, enabling synthesis of large samples\nwith physically realistic structure. The inpainting model explores several\nmasking strategies for the inputs to the underlying UNets by training the\nnetwork to infer missing portions of voxel grids from a concatenation of noised\ntensors, masks, and masked tensors as input channels. The model also adapts a\n2D repainting technique of re-injecting noise scheduler output with ground\ntruth to provide a strong guidance to the 3D model. This along with weighted\nlosses ensures long-term coherence over generation of masked regions. Both\nmodels are trained on the same binarized 3D occupancy grids extracted from\nsmall-scale DEM simulations, achieving linear scaling of computational time\nwith respect to sample size. Quantitatively, a 1.2 m long ballasted rail track\nsynthesis equivalent to a 3-hour DEM simulation, was completed under 20\nseconds. The generated voxel grids can also be post-processed to extract grain\ngeometries for DEM-compatibility as well, enabling physically coherent,\nreal-time, scalable granular media synthesis for industrial applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e3D\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u5f0f\u7ba1\u9053\uff0c\u514b\u670d\u79bb\u6563\u5143\u6cd5\u6a21\u62df\u9897\u7c92\u4ecb\u8d28\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u5b9e\u73b0\u5b9e\u65f6\u3001\u53ef\u6269\u5c55\u7684\u9897\u7c92\u4ecb\u8d28\u5408\u6210\u3002", "motivation": "\u79bb\u6563\u5143\u6cd5\u6a21\u62df\u9897\u7c92\u4ecb\u8d28\u5728\u521d\u59cb\u5316\u9636\u6bb5\u8ba1\u7b97\u91cf\u5927\u3001\u8017\u65f6\u4e45\uff0c\u9700\u8981\u514b\u670d\u8fd9\u4e00\u74f6\u9888\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7ba1\u9053\uff0c\u5148\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u751f\u6210\u72ec\u7acb3D\u4f53\u7d20\u7f51\u683c\uff0c\u518d\u75283D\u4fee\u590d\u6a21\u578b\u5c06\u7f51\u683c\u65e0\u7f1d\u62fc\u63a5\u3002\u63a2\u7d22\u591a\u79cd\u8f93\u5165\u63a9\u7801\u7b56\u7565\uff0c\u5f15\u5165\u91cd\u6ce8\u5165\u566a\u58f0\u8c03\u5ea6\u5668\u8f93\u51fa\u4e0e\u52a0\u6743\u635f\u5931\u786e\u4fdd\u751f\u6210\u8fde\u8d2f\u6027\u3002", "result": "\u5b9e\u73b0\u8ba1\u7b97\u65f6\u95f4\u968f\u6837\u672c\u5927\u5c0f\u7ebf\u6027\u7f29\u653e\uff0c\u59821.2\u7c73\u957f\u7684\u9053\u781f\u8f68\u9053\u5408\u6210\u4ece3\u5c0f\u65f6\u964d\u81f320\u79d2\u4ee5\u5185\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5b9e\u73b0\u7269\u7406\u8fde\u8d2f\u3001\u5b9e\u65f6\u3001\u53ef\u6269\u5c55\u7684\u9897\u7c92\u4ecb\u8d28\u5408\u6210\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u5e94\u7528\u3002"}}
{"id": "2508.19322", "pdf": "https://arxiv.org/pdf/2508.19322", "abs": "https://arxiv.org/abs/2508.19322", "authors": ["Xueyang Li", "Mingze Jiang", "Gelei Xu", "Jun Xia", "Mengzhao Jia", "Danny Chen", "Yiyu Shi"], "title": "AT-CXR: Uncertainty-Aware Agentic Triage for Chest X-rays", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Agentic AI is advancing rapidly, yet truly autonomous medical-imaging triage,\nwhere a system decides when to stop, escalate, or defer under real constraints,\nremains relatively underexplored. To address this gap, we introduce AT-CXR, an\nuncertainty-aware agent for chest X-rays. The system estimates per-case\nconfidence and distributional fit, then follows a stepwise policy to issue an\nautomated decision or abstain with a suggested label for human intervention. We\nevaluate two router designs that share the same inputs and actions: a\ndeterministic rule-based router and an LLM-decided router. Across five-fold\nevaluation on a balanced subset of NIH ChestX-ray14 dataset, both variants\noutperform strong zero-shot vision-language models and state-of-the-art\nsupervised classifiers, achieving higher full-coverage accuracy and superior\nselective-prediction performance, evidenced by a lower area under the\nrisk-coverage curve (AURC) and a lower error rate at high coverage, while\noperating with lower latency that meets practical clinical constraints. The two\nrouters provide complementary operating points, enabling deployments to\nprioritize maximal throughput or maximal accuracy. Our code is available at\nhttps://github.com/XLIAaron/uncertainty-aware-cxr-agent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u80f8\u90e8X\u5149\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4ee3\u7406AT - CXR\uff0c\u8bc4\u4f30\u4e24\u79cd\u8def\u7531\u8bbe\u8ba1\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u771f\u6b63\u7684\u81ea\u4e3b\u533b\u5b66\u5f71\u50cf\u5206\u8bca\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u586b\u8865\u8be5\u7a7a\u767d\u3002", "method": "\u5f15\u5165AT - CXR\u7cfb\u7edf\uff0c\u8bc4\u4f30\u786e\u5b9a\u6027\u89c4\u5219\u8def\u7531\u548cLLM\u51b3\u7b56\u8def\u7531\u4e24\u79cd\u8bbe\u8ba1\u3002", "result": "\u4e24\u79cd\u8def\u7531\u8bbe\u8ba1\u5728NIH ChestX - ray14\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u96f6\u6837\u672c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u76d1\u7763\u5206\u7c7b\u5668\uff0c\u6709\u66f4\u9ad8\u51c6\u786e\u7387\u3001\u66f4\u597d\u9009\u62e9\u6027\u9884\u6d4b\u6027\u80fd\u3001\u66f4\u4f4e\u5ef6\u8fdf\u3002", "conclusion": "\u4e24\u79cd\u8def\u7531\u63d0\u4f9b\u4e92\u8865\u64cd\u4f5c\u70b9\uff0c\u53ef\u6839\u636e\u9700\u6c42\u4f18\u5148\u8003\u8651\u541e\u5410\u91cf\u6216\u51c6\u786e\u6027\u3002"}}
{"id": "2508.19324", "pdf": "https://arxiv.org/pdf/2508.19324", "abs": "https://arxiv.org/abs/2508.19324", "authors": ["Jefferson David Rodriguez Chivata", "Davide Ghiani", "Simone Maurizio La Cava", "Marco Micheletto", "Giulia Orr\u00f9", "Federico Lama", "Gian Luca Marcialis"], "title": "Deep Data Hiding for ICAO-Compliant Face Images: A Survey", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.LG", "eess.IV"], "comment": "In 2025 IEEE International Joint Conference on Biometrics (IJCB)", "summary": "ICAO-compliant facial images, initially designed for secure biometric\npassports, are increasingly becoming central to identity verification in a wide\nrange of application contexts, including border control, digital travel\ncredentials, and financial services. While their standardization enables global\ninteroperability, it also facilitates practices such as morphing and deepfakes,\nwhich can be exploited for harmful purposes like identity theft and illegal\nsharing of identity documents. Traditional countermeasures like Presentation\nAttack Detection (PAD) are limited to real-time capture and offer no\npost-capture protection. This survey paper investigates digital watermarking\nand steganography as complementary solutions that embed tamper-evident signals\ndirectly into the image, enabling persistent verification without compromising\nICAO compliance. We provide the first comprehensive analysis of\nstate-of-the-art techniques to evaluate the potential and drawbacks of the\nunderlying approaches concerning the applications involving ICAO-compliant\nimages and their suitability under standard constraints. We highlight key\ntrade-offs, offering guidance for secure deployment in real-world identity\nsystems.", "AI": {"tldr": "ICAO\u5408\u89c4\u9762\u90e8\u56fe\u50cf\u5728\u8eab\u4efd\u9a8c\u8bc1\u4e2d\u6108\u53d1\u91cd\u8981\uff0c\u4f46\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u672c\u6587\u7814\u7a76\u6570\u5b57\u6c34\u5370\u548c\u9690\u5199\u672f\u4f5c\u4e3a\u8865\u5145\u65b9\u6848\uff0c\u5e76\u5206\u6790\u76f8\u5173\u6280\u672f\u3002", "motivation": "ICAO\u5408\u89c4\u9762\u90e8\u56fe\u50cf\u867d\u5b9e\u73b0\u5168\u7403\u4e92\u64cd\u4f5c\u6027\uff0c\u4f46\u6613\u88ab\u7528\u4e8e\u6709\u5bb3\u76ee\u7684\uff0c\u4f20\u7edf\u5bf9\u7b56\u6709\u5c40\u9650\uff0c\u9700\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5bf9\u6d89\u53caICAO\u5408\u89c4\u56fe\u50cf\u5e94\u7528\u7684\u6570\u5b57\u6c34\u5370\u548c\u9690\u5199\u672f\u7684\u73b0\u6709\u6280\u672f\u8fdb\u884c\u5168\u9762\u5206\u6790\u3002", "result": "\u8bc4\u4f30\u4e86\u6f5c\u5728\u548c\u7f3a\u70b9\uff0c\u7a81\u51fa\u4e86\u5173\u952e\u6743\u8861\u3002", "conclusion": "\u4e3a\u73b0\u5b9e\u4e16\u754c\u8eab\u4efd\u7cfb\u7edf\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2508.19839", "pdf": "https://arxiv.org/pdf/2508.19839", "abs": "https://arxiv.org/abs/2508.19839", "authors": ["Kehao Zhang", "Shaolei Zhang", "Yang Feng"], "title": "PSO-Merging: Merging Models Based on Particle Swarm Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model merging has emerged as an efficient strategy for constructing multitask\nmodels by integrating the strengths of multiple available expert models,\nthereby reducing the need to fine-tune a pre-trained model for all the tasks\nfrom scratch. Existing data-independent methods struggle with performance\nlimitations due to the lack of data-driven guidance. Data-driven approaches\nalso face key challenges: gradient-based methods are computationally expensive,\nlimiting their practicality for merging large expert models, whereas existing\ngradient-free methods often fail to achieve satisfactory results within a\nlimited number of optimization steps. To address these limitations, this paper\nintroduces PSO-Merging, a novel data-driven merging method based on the\nParticle Swarm Optimization (PSO). In this approach, we initialize the particle\nswarm with a pre-trained model, expert models, and sparsified expert models. We\nthen perform multiple iterations, with the final global best particle serving\nas the merged model. Experimental results on different language models show\nthat PSO-Merging generally outperforms baseline merging methods, offering a\nmore efficient and scalable solution for model merging.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316\u7684PSO - Merging\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u6a21\u578b\u878d\u5408\u63d0\u4f9b\u9ad8\u6548\u53ef\u6269\u5c55\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u65e0\u5173\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u6570\u636e\u9a71\u52a8\u6709\u6027\u80fd\u5c40\u9650\uff0c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4e2d\u57fa\u4e8e\u68af\u5ea6\u7684\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u65e0\u68af\u5ea6\u65b9\u6cd5\u96be\u5728\u6709\u9650\u6b65\u9aa4\u53d6\u5f97\u6ee1\u610f\u7ed3\u679c\u3002", "method": "\u63d0\u51faPSO - Merging\u65b9\u6cd5\uff0c\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u3001\u4e13\u5bb6\u6a21\u578b\u548c\u7a00\u758f\u5316\u4e13\u5bb6\u6a21\u578b\u521d\u59cb\u5316\u7c92\u5b50\u7fa4\uff0c\u7ecf\u591a\u6b21\u8fed\u4ee3\uff0c\u4ee5\u6700\u7ec8\u5168\u5c40\u6700\u4f18\u7c92\u5b50\u4f5c\u4e3a\u878d\u5408\u6a21\u578b\u3002", "result": "\u5728\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660ePSO - Merging\u603b\u4f53\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u878d\u5408\u65b9\u6cd5\u3002", "conclusion": "PSO - Merging\u4e3a\u6a21\u578b\u878d\u5408\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19327", "pdf": "https://arxiv.org/pdf/2508.19327", "abs": "https://arxiv.org/abs/2508.19327", "authors": ["Pilsung Kang"], "title": "Quantum Entanglement as Super-Confounding: From Bell's Theorem to Robust Machine Learning", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Bell's theorem reveals a profound conflict between quantum mechanics and\nlocal realism, a conflict we reinterpret through the modern lens of causal\ninference. We propose and computationally validate a framework where quantum\nentanglement acts as a \"super-confounding\" resource, generating correlations\nthat violate the classical causal bounds set by Bell's inequalities. This work\nmakes three key contributions: First, we establish a physical hierarchy of\nconfounding (Quantum > Classical) and introduce Confounding Strength (CS) to\nquantify this effect. Second, we provide a circuit-based implementation of the\nquantum $\\mathcal{DO}$-calculus to distinguish causality from spurious\ncorrelation. Finally, we apply this calculus to a quantum machine learning\nproblem, where causal feature selection yields a statistically significant\n11.3% average absolute improvement in model robustness. Our framework bridges\nquantum foundations and causal AI, offering a new, practical perspective on\nquantum correlations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.19842", "pdf": "https://arxiv.org/pdf/2508.19842", "abs": "https://arxiv.org/abs/2508.19842", "authors": ["S\u00fcleyman Y\u0131ld\u0131z", "Konrad Janik", "Peter Benner"], "title": "Symplectic convolutional neural networks", "categories": ["cs.LG"], "comment": null, "summary": "We propose a new symplectic convolutional neural network (CNN) architecture\nby leveraging symplectic neural networks, proper symplectic decomposition, and\ntensor techniques. Specifically, we first introduce a mathematically equivalent\nform of the convolution layer and then, using symplectic neural networks, we\ndemonstrate a way to parameterize the layers of the CNN to ensure that the\nconvolution layer remains symplectic. To construct a complete autoencoder, we\nintroduce a symplectic pooling layer. We demonstrate the performance of the\nproposed neural network on three examples: the wave equation, the nonlinear\nSchr\\\"odinger (NLS) equation, and the sine-Gordon equation. The numerical\nresults indicate that the symplectic CNN outperforms the linear symplectic\nautoencoder obtained via proper symplectic decomposition.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u8f9b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5728\u4e09\u4e2a\u65b9\u7a0b\u793a\u4f8b\u4e0a\u9a8c\u8bc1\u6027\u80fd\u4e14\u4f18\u4e8e\u7ebf\u6027\u8f9b\u81ea\u7f16\u7801\u5668\u3002", "motivation": "\u6784\u5efa\u65b0\u7684\u5177\u6709\u8f9b\u6027\u8d28\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u3002", "method": "\u5229\u7528\u8f9b\u795e\u7ecf\u7f51\u7edc\u3001\u9002\u5f53\u8f9b\u5206\u89e3\u548c\u5f20\u91cf\u6280\u672f\uff0c\u5f15\u5165\u5377\u79ef\u5c42\u7684\u6570\u5b66\u7b49\u4ef7\u5f62\u5f0f\uff0c\u7528\u8f9b\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316CNN\u5c42\uff0c\u5f15\u5165\u8f9b\u6c60\u5316\u5c42\u6784\u5efa\u5b8c\u6574\u81ea\u7f16\u7801\u5668\u3002", "result": "\u5728\u6ce2\u65b9\u7a0b\u3001\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u548c\u6b63\u5f26 - \u6208\u767b\u65b9\u7a0b\u4e09\u4e2a\u793a\u4f8b\u4e0a\uff0c\u8f9bCNN\u6027\u80fd\u4f18\u4e8e\u901a\u8fc7\u9002\u5f53\u8f9b\u5206\u89e3\u5f97\u5230\u7684\u7ebf\u6027\u8f9b\u81ea\u7f16\u7801\u5668\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8f9b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5177\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2508.19847", "pdf": "https://arxiv.org/pdf/2508.19847", "abs": "https://arxiv.org/abs/2508.19847", "authors": ["Erdi Kara", "Panos Stinis"], "title": "Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources", "categories": ["cs.LG"], "comment": null, "summary": "We present a hybrid framework that couples finite element methods (FEM) with\nphysics-informed DeepONet to model fluid transport in porous media from sharp,\nlocalized Gaussian sources. The governing system consists of a steady-state\nDarcy flow equation and a time-dependent convection-diffusion equation. Our\napproach solves the Darcy system using FEM and transfers the resulting velocity\nfield to a physics-informed DeepONet, which learns the mapping from source\nfunctions to solute concentration profiles. This modular strategy preserves\nFEM-level accuracy in the flow field while enabling fast inference for\ntransport dynamics. To handle steep gradients induced by sharp sources, we\nintroduce an adaptive sampling strategy for trunk collocation points. Numerical\nexperiments demonstrate that our method is in good agreement with the reference\nsolutions while offering orders of magnitude speedups over traditional solvers,\nmaking it suitable for practical applications in relevant scenarios.\nImplementation of our proposed method is available at\nhttps://github.com/erkara/fem-pi-deeponet.", "AI": {"tldr": "\u63d0\u51fa\u8026\u5408\u6709\u9650\u5143\u6cd5\u4e0e\u7269\u7406\u4fe1\u606fDeepONet\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u591a\u5b54\u4ecb\u8d28\u4e2d\u6d41\u4f53\u4f20\u8f93\uff0c\u6709\u81ea\u9002\u5e94\u91c7\u6837\u7b56\u7565\uff0c\u901f\u5ea6\u6bd4\u4f20\u7edf\u6c42\u89e3\u5668\u5feb\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u80fd\u51c6\u786e\u4e14\u5feb\u901f\u6a21\u62df\u591a\u5b54\u4ecb\u8d28\u4e2d\u4ece\u5c16\u9510\u5c40\u90e8\u9ad8\u65af\u6e90\u8fdb\u884c\u6d41\u4f53\u4f20\u8f93\u7684\u65b9\u6cd5\u3002", "method": "\u7528\u6709\u9650\u5143\u6cd5\u6c42\u89e3Darcy\u7cfb\u7edf\uff0c\u5c06\u901f\u5ea6\u573a\u4f20\u9012\u7ed9\u7269\u7406\u4fe1\u606fDeepONet\u5b66\u4e60\u6e90\u51fd\u6570\u5230\u6eb6\u8d28\u6d53\u5ea6\u5206\u5e03\u7684\u6620\u5c04\uff0c\u5f15\u5165\u81ea\u9002\u5e94\u91c7\u6837\u7b56\u7565\u5904\u7406\u5c16\u9510\u6e90\u5f15\u8d77\u7684\u9661\u68af\u5ea6\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4e0e\u53c2\u8003\u89e3\u543b\u5408\u826f\u597d\uff0c\u6bd4\u4f20\u7edf\u6c42\u89e3\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u76f8\u5173\u573a\u666f\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u4ee3\u7801\u53ef\u5728\u6307\u5b9a\u94fe\u63a5\u83b7\u53d6\u3002"}}
{"id": "2508.19359", "pdf": "https://arxiv.org/pdf/2508.19359", "abs": "https://arxiv.org/abs/2508.19359", "authors": ["Fatemeh Haji", "Mazal Bethany", "Cho-Yu Jason Chiang", "Anthony Rios", "Peyman Najafirad"], "title": "Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Event Extraction (EE) involves automatically identifying and extracting\nstructured information about events from unstructured text, including triggers,\nevent types, and arguments. Traditional discriminative models demonstrate high\nprecision but often exhibit limited recall, particularly for nuanced or\ninfrequent events. Conversely, generative approaches leveraging Large Language\nModels (LLMs) provide higher semantic flexibility and recall but suffer from\nhallucinations and inconsistent predictions. To address these challenges, we\npropose Agreement-based Reflective Inference System (ARIS), a hybrid approach\ncombining a Self Mixture of Agents with a discriminative sequence tagger. ARIS\nexplicitly leverages structured model consensus, confidence-based filtering,\nand an LLM reflective inference module to reliably resolve ambiguities and\nenhance overall event prediction quality. We further investigate decomposed\ninstruction fine-tuning for enhanced LLM event extraction understanding.\nExperiments demonstrate our approach outperforms existing state-of-the-art\nevent extraction methods across three benchmark datasets.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u65b9\u6cd5ARIS\u89e3\u51b3\u4e8b\u4ef6\u62bd\u53d6\u6311\u6218\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5224\u522b\u6a21\u578b\u53ec\u56de\u7387\u6709\u9650\uff0c\u751f\u6210\u5f0f\u65b9\u6cd5\u6709\u5e7b\u89c9\u548c\u9884\u6d4b\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u4e8b\u4ef6\u62bd\u53d6\u3002", "method": "\u63d0\u51faARIS\uff0c\u7ed3\u5408Self Mixture of Agents\u4e0e\u5224\u522b\u5f0f\u5e8f\u5217\u6807\u6ce8\u5668\uff0c\u5229\u7528\u7ed3\u6784\u6a21\u578b\u5171\u8bc6\u3001\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u8fc7\u6ee4\u548cLLM\u53cd\u601d\u63a8\u7406\u6a21\u5757\uff0c\u8fd8\u7814\u7a76\u5206\u89e3\u6307\u4ee4\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u4e8b\u4ef6\u62bd\u53d6\u65b9\u6cd5\u3002", "conclusion": "ARIS\u6709\u6548\u63d0\u5347\u4e86\u4e8b\u4ef6\u62bd\u53d6\u7684\u8d28\u91cf\uff0c\u662f\u4e00\u79cd\u66f4\u4f18\u7684\u4e8b\u4ef6\u62bd\u53d6\u65b9\u6cd5\u3002"}}
{"id": "2508.19857", "pdf": "https://arxiv.org/pdf/2508.19857", "abs": "https://arxiv.org/abs/2508.19857", "authors": ["Omar Bacarreza", "Thorin Farnsworth", "Alexander Makarovskiy", "Hugo Wallner", "Tessa Hicks", "Santiago Sempere-Llagostera", "John Price", "Robert J. A. Francis-Jones", "William R. Clements"], "title": "Quantum latent distributions in deep generative models", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Many successful families of generative models leverage a low-dimensional\nlatent distribution that is mapped to a data distribution. Though simple latent\ndistributions are commonly used, it has been shown that more sophisticated\ndistributions can improve performance. For instance, recent work has explored\nusing the distributions produced by quantum processors and found empirical\nimprovements. However, when latent space distributions produced by quantum\nprocessors can be expected to improve performance, and whether these\nimprovements are reproducible, are open questions that we investigate in this\nwork. We prove that, under certain conditions, these \"quantum latent\ndistributions\" enable generative models to produce data distributions that\nclassical latent distributions cannot efficiently produce. We also provide\nactionable intuitions to identify when such quantum advantages may arise in\nreal-world settings. We perform benchmarking experiments on both a synthetic\nquantum dataset and the QM9 molecular dataset, using both simulated and real\nphotonic quantum processors. Our results demonstrate that quantum latent\ndistributions can lead to improved generative performance in GANs compared to a\nrange of classical baselines. We also explore diffusion and flow matching\nmodels, identifying architectures compatible with quantum latent distributions.\nThis work confirms that near-term quantum processors can expand the\ncapabilities of deep generative models.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u91cf\u5b50\u6f5c\u5728\u5206\u5e03\u5728\u751f\u6210\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u7279\u5b9a\u6761\u4ef6\u4e0b\u5176\u4f18\u52bf\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u63d0\u5347\u751f\u6210\u6027\u80fd\uff0c\u8fd8\u63a2\u7d22\u517c\u5bb9\u67b6\u6784\uff0c\u8bc1\u5b9e\u8fd1\u91cf\u5b50\u5904\u7406\u5668\u53ef\u62d3\u5c55\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u80fd\u529b\u3002", "motivation": "\u63a2\u7a76\u91cf\u5b50\u5904\u7406\u5668\u4ea7\u751f\u7684\u6f5c\u5728\u7a7a\u95f4\u5206\u5e03\u4f55\u65f6\u80fd\u63d0\u5347\u751f\u6210\u6a21\u578b\u6027\u80fd\u4ee5\u53ca\u8fd9\u4e9b\u63d0\u5347\u662f\u5426\u53ef\u91cd\u590d\u3002", "method": "\u8bc1\u660e\u7279\u5b9a\u6761\u4ef6\u4e0b\u91cf\u5b50\u6f5c\u5728\u5206\u5e03\u7684\u4f18\u52bf\uff0c\u63d0\u4f9b\u5224\u65ad\u91cf\u5b50\u4f18\u52bf\u4f55\u65f6\u51fa\u73b0\u7684\u76f4\u89c9\uff0c\u5728\u5408\u6210\u91cf\u5b50\u6570\u636e\u96c6\u548cQM9\u5206\u5b50\u6570\u636e\u96c6\u4e0a\u7528\u6a21\u62df\u548c\u771f\u5b9e\u5149\u5b50\u91cf\u5b50\u5904\u7406\u5668\u8fdb\u884c\u57fa\u51c6\u5b9e\u9a8c\uff0c\u63a2\u7d22\u6269\u6563\u548c\u6d41\u5339\u914d\u6a21\u578b\u3002", "result": "\u91cf\u5b50\u6f5c\u5728\u5206\u5e03\u5728GAN\u4e2d\u76f8\u6bd4\u7ecf\u5178\u57fa\u7ebf\u80fd\u63d0\u5347\u751f\u6210\u6027\u80fd\uff0c\u627e\u5230\u4e0e\u91cf\u5b50\u6f5c\u5728\u5206\u5e03\u517c\u5bb9\u7684\u67b6\u6784\u3002", "conclusion": "\u8fd1\u91cf\u5b50\u5904\u7406\u5668\u53ef\u62d3\u5c55\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u7684\u80fd\u529b\u3002"}}
{"id": "2508.19884", "pdf": "https://arxiv.org/pdf/2508.19884", "abs": "https://arxiv.org/abs/2508.19884", "authors": ["Mingyue Kong", "Yinglong Zhang", "Chengda Xu", "Xuewen Xia", "Xing Xu"], "title": "Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks", "categories": ["cs.LG"], "comment": "50 pages, 6 figures", "summary": "Graph Neural Networks (GNNs) have shown remarkable performance in structured\ndata modeling tasks such as node classification. However, mainstream approaches\ngenerally rely on a large number of trainable parameters and fixed aggregation\nrules, making it difficult to adapt to graph data with strong structural\nheterogeneity and complex feature distributions. This often leads to\nover-smoothing of node representations and semantic degradation. To address\nthese issues, this paper proposes a parameter-free graph neural network\nframework based on structural diversity, namely SDGNN (Structural-Diversity\nGraph Neural Network). The framework is inspired by structural diversity theory\nand designs a unified structural-diversity message passing mechanism that\nsimultaneously captures the heterogeneity of neighborhood structures and the\nstability of feature semantics, without introducing additional trainable\nparameters. Unlike traditional parameterized methods, SDGNN does not rely on\ncomplex model training, but instead leverages complementary modeling from both\nstructure-driven and feature-driven perspectives, thereby effectively improving\nadaptability across datasets and scenarios. Experimental results show that on\neight public benchmark datasets and an interdisciplinary PubMed citation\nnetwork, SDGNN consistently outperforms mainstream GNNs under challenging\nconditions such as low supervision, class imbalance, and cross-domain transfer.\nThis work provides a new theoretical perspective and general approach for the\ndesign of parameter-free graph neural networks, and further validates the\nimportance of structural diversity as a core signal in graph representation\nlearning. To facilitate reproducibility and further research, the full\nimplementation of SDGNN has been released at:\nhttps://github.com/mingyue15694/SGDNN/tree/main", "AI": {"tldr": "\u63d0\u51fa\u65e0\u53c2\u6570\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6SDGNN\uff0c\u5728\u591a\u6570\u636e\u96c6\u8868\u73b0\u4f18\u4e8e\u4e3b\u6d41GNN\uff0c\u4e3a\u65e0\u53c2GNN\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u4e3b\u6d41GNN\u4f9d\u8d56\u5927\u91cf\u53ef\u8bad\u7ec3\u53c2\u6570\u548c\u56fa\u5b9a\u805a\u5408\u89c4\u5219\uff0c\u96be\u4ee5\u9002\u5e94\u7ed3\u6784\u5f02\u8d28\u6027\u5f3a\u548c\u7279\u5f81\u5206\u5e03\u590d\u6742\u7684\u56fe\u6570\u636e\uff0c\u6613\u5bfc\u81f4\u8282\u70b9\u8868\u793a\u8fc7\u5e73\u6ed1\u548c\u8bed\u4e49\u9000\u5316\u3002", "method": "\u53d7\u7ed3\u6784\u591a\u6837\u6027\u7406\u8bba\u542f\u53d1\uff0c\u8bbe\u8ba1\u7edf\u4e00\u7684\u7ed3\u6784\u591a\u6837\u6027\u6d88\u606f\u4f20\u9012\u673a\u5236\uff0c\u4ece\u7ed3\u6784\u9a71\u52a8\u548c\u7279\u5f81\u9a71\u52a8\u4e92\u8865\u5efa\u6a21\uff0c\u4e0d\u5f15\u5165\u989d\u5916\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "result": "\u5728\u516b\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u8de8\u5b66\u79d1PubMed\u5f15\u6587\u7f51\u7edc\u4e0a\uff0cSDGNN\u5728\u4f4e\u76d1\u7763\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u8de8\u57df\u8f6c\u79fb\u7b49\u6311\u6218\u6761\u4ef6\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u4e3b\u6d41GNN\u3002", "conclusion": "\u4e3a\u65e0\u53c2\u6570\u56fe\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u7406\u8bba\u89c6\u89d2\u548c\u901a\u7528\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u7ed3\u6784\u591a\u6837\u6027\u5728\u56fe\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.19363", "pdf": "https://arxiv.org/pdf/2508.19363", "abs": "https://arxiv.org/abs/2508.19363", "authors": ["Jiayu Ding", "Shuming Ma", "Lei Cui", "Nanning Zheng", "Furu Wei"], "title": "LongReasonArena: A Long Reasoning Benchmark for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Existing long-context benchmarks for Large Language Models (LLMs) focus on\nevaluating comprehension of long inputs, while overlooking the evaluation of\nlong reasoning abilities. To address this gap, we introduce LongReasonArena, a\nbenchmark specifically designed to assess the long reasoning capabilities of\nLLMs. Our tasks require models to solve problems by executing multi-step\nalgorithms that reflect key aspects of long reasoning, such as retrieval and\nbacktracking. By controlling the inputs, the required reasoning length can be\narbitrarily scaled, reaching up to 1 million tokens of reasoning for the most\nchallenging tasks. Extensive evaluation results demonstrate that\nLongReasonArena presents a significant challenge for both open-source and\nproprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our\ntask. Further analysis also reveals that the accuracy exhibits a linear decline\nwith respect to the logarithm of the expected number of reasoning steps. Our\ncode and data is available at\nhttps://github.com/LongReasonArena/LongReasonArena.", "AI": {"tldr": "\u63d0\u51faLongReasonArena\u57fa\u51c6\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u63a8\u7406\u80fd\u529b\uff0c\u8bc4\u4f30\u663e\u793a\u5bf9\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u90fd\u6709\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u5ffd\u7565\u957f\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\uff0c\u9700\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u5f15\u5165LongReasonArena\u57fa\u51c6\uff0c\u4efb\u52a1\u8981\u6c42\u6a21\u578b\u6267\u884c\u591a\u6b65\u7b97\u6cd5\u89e3\u51b3\u95ee\u9898\uff0c\u53ef\u4efb\u610f\u7f29\u653e\u63a8\u7406\u957f\u5ea6\u3002", "result": "LongReasonArena\u5bf9\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u5982Deepseek - R1\u51c6\u786e\u7387\u4ec57.5%\uff0c\u51c6\u786e\u7387\u968f\u9884\u671f\u63a8\u7406\u6b65\u9aa4\u5bf9\u6570\u7ebf\u6027\u4e0b\u964d\u3002", "conclusion": "LongReasonArena\u80fd\u6709\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u957f\u63a8\u7406\u80fd\u529b\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5f00\u6e90\u3002"}}
{"id": "2508.19896", "pdf": "https://arxiv.org/pdf/2508.19896", "abs": "https://arxiv.org/abs/2508.19896", "authors": ["Davorin Mili\u010devi\u0107", "Ratko Grbi\u0107"], "title": "NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs", "categories": ["cs.LG", "cs.CV", "I.2.6; I.5.4"], "comment": "13 pages, 4 figures. Submitted to Elsevier Neurocomputing, under\n  review", "summary": "Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often\nrely on purely global, gradient-based optimisation, which can lead to\noverfitting, redundant filters, and reduced interpretability. To address these\nlimitations, we propose NM-Hebb, a two-phase training framework that integrates\nneuro-inspired local plasticity with distance-aware supervision. Phase 1\nextends standard supervised training by jointly optimising a cross-entropy\nobjective with two biologically inspired mechanisms: (i) a Hebbian regulariser\nthat aligns the spatial mean of activations with the mean of the corresponding\nconvolutional filter weights, encouraging structured, reusable primitives; and\n(ii) a learnable neuromodulator that gates an elastic-weight-style\nconsolidation loss, preserving beneficial parameters without freezing the\nnetwork. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,\nexplicitly compressing intra-class distances and enlarging inter-class margins\nin the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet\nacross five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,\nDenseNet-121), NM-Hebb achieves consistent gains over baseline and other\nmethods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp\n(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual\nInformation (NMI) increased by up to +0.15. Qualitative visualisations and\nfilter-level analyses further confirm that NM-Hebb produces more structured and\nselective features, yielding tighter and more interpretable class clusters.\nOverall, coupling local Hebbian plasticity with metric-based fine-tuning yields\nCNNs that are not only more accurate but also more interpretable, offering\npractical benefits for resource-constrained and safety-critical AI deployments.", "AI": {"tldr": "\u63d0\u51faNM - Hebb\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408\u795e\u7ecf\u542f\u53d1\u7684\u5c40\u90e8\u53ef\u5851\u6027\u548c\u8ddd\u79bb\u611f\u77e5\u76d1\u7763\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u9aa8\u5e72\u7f51\u7edc\u4e0a\u63d0\u5347CNN\u51c6\u786e\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4f9d\u8d56\u5168\u5c40\u68af\u5ea6\u4f18\u5316\uff0c\u5b58\u5728\u8fc7\u62df\u5408\u3001\u6ee4\u6ce2\u5668\u5197\u4f59\u548c\u53ef\u89e3\u91ca\u6027\u4f4e\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faNM - Hebb\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u7ed3\u5408\u4ea4\u53c9\u71b5\u76ee\u6807\u4e0e\u751f\u7269\u542f\u53d1\u673a\u5236\u4f18\u5316\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7528\u6210\u5bf9\u5ea6\u91cf\u5b66\u4e60\u635f\u5931\u5fae\u8c03\u9aa8\u5e72\u7f51\u7edc\u3002", "result": "\u5728CIFAR - 10\u3001CIFAR - 100\u548cTinyImageNet\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u548c\u5176\u4ed6\u65b9\u6cd5\u6709\u4e00\u81f4\u63d0\u5347\uff0cTop - 1\u51c6\u786e\u7387\u63d0\u9ad8\uff0cNMI\u589e\u52a0\uff0c\u751f\u6210\u66f4\u7ed3\u6784\u5316\u548c\u9009\u62e9\u6027\u7684\u7279\u5f81\u3002", "conclusion": "\u5c06\u5c40\u90e8Hebbian\u53ef\u5851\u6027\u4e0e\u57fa\u4e8e\u5ea6\u91cf\u7684\u5fae\u8c03\u76f8\u7ed3\u5408\uff0c\u4f7fCNN\u66f4\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\uff0c\u5bf9\u8d44\u6e90\u53d7\u9650\u548c\u5b89\u5168\u5173\u952e\u7684AI\u90e8\u7f72\u6709\u5b9e\u9645\u597d\u5904\u3002"}}
{"id": "2508.19900", "pdf": "https://arxiv.org/pdf/2508.19900", "abs": "https://arxiv.org/abs/2508.19900", "authors": ["Tan Jing", "Xiaorui Li", "Chao Yao", "Xiaojuan Ban", "Yuetong Fang", "Renjing Xu", "Zhaolin Yuan"], "title": "Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) enables learning effective policies from\nfixed datasets without any environment interaction. Existing methods typically\nemploy policy constraints to mitigate the distribution shift encountered during\noffline RL training. However, because the scale of the constraints varies\nacross tasks and datasets of differing quality, existing methods must\nmeticulously tune hyperparameters to match each dataset, which is\ntime-consuming and often impractical. We propose Adaptive Scaling of Policy\nConstraints (ASPC), a second-order differentiable framework that dynamically\nbalances RL and behavior cloning (BC) during training. We theoretically analyze\nits performance improvement guarantee. In experiments on 39 datasets across\nfour D4RL domains, ASPC using a single hyperparameter configuration outperforms\nother adaptive constraint methods and state-of-the-art offline RL algorithms\nthat require per-dataset tuning while incurring only minimal computational\noverhead. The code will be released at https://github.com/Colin-Jing/ASPC.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u7b56\u7565\u7ea6\u675f\u7f29\u653e\uff08ASPC\uff09\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9700\u7ec6\u81f4\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u8017\u65f6\u4e14\u4e0d\u5b9e\u9645\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e8c\u9636\u53ef\u5fae\u7684ASPC\u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u4e2d\u52a8\u6001\u5e73\u8861\u5f3a\u5316\u5b66\u4e60\u548c\u884c\u4e3a\u514b\u9686\u3002", "result": "\u5728\u56db\u4e2aD4RL\u9886\u57df\u768439\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528\u5355\u4e00\u8d85\u53c2\u6570\u914d\u7f6e\u7684ASPC\u4f18\u4e8e\u5176\u4ed6\u81ea\u9002\u5e94\u7ea6\u675f\u65b9\u6cd5\u548c\u9700\u8981\u9010\u6570\u636e\u96c6\u8c03\u53c2\u7684\u5148\u8fdb\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "ASPC\u6846\u67b6\u6709\u6548\uff0c\u80fd\u89e3\u51b3\u73b0\u6709\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8c03\u53c2\u96be\u9898\u3002"}}
{"id": "2508.19367", "pdf": "https://arxiv.org/pdf/2508.19367", "abs": "https://arxiv.org/abs/2508.19367", "authors": ["Alex Cuellar", "Ho Chit Siu", "Julie A Shah"], "title": "Inference of Human-derived Specifications of Object Placement via Demonstration", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": null, "summary": "As robots' manipulation capabilities improve for pick-and-place tasks (e.g.,\nobject packing, sorting, and kitting), methods focused on understanding\nhuman-acceptable object configurations remain limited expressively with regard\nto capturing spatial relationships important to humans. To advance robotic\nunderstanding of human rules for object arrangement, we introduce\npositionally-augmented RCC (PARCC), a formal logic framework based on region\nconnection calculus (RCC) for describing the relative position of objects in\nspace. Additionally, we introduce an inference algorithm for learning PARCC\nspecifications via demonstrations. Finally, we present the results from a human\nstudy, which demonstrate our framework's ability to capture a human's intended\nspecification and the benefits of learning from demonstration approaches over\nhuman-provided specifications.", "AI": {"tldr": "\u63d0\u51faPARCC\u6846\u67b6\u53ca\u63a8\u7406\u7b97\u6cd5\uff0c\u4eba\u7c7b\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5176\u80fd\u6355\u6349\u4eba\u7c7b\u610f\u56fe\u89c4\u8303\u4e14\u4ece\u6f14\u793a\u5b66\u4e60\u6709\u4f18\u52bf", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u6349\u5bf9\u4eba\u7c7b\u91cd\u8981\u7684\u7a7a\u95f4\u5173\u7cfb\u65b9\u9762\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u9700\u63d0\u5347\u673a\u5668\u4eba\u5bf9\u4eba\u7c7b\u7269\u4f53\u6392\u5217\u89c4\u5219\u7684\u7406\u89e3", "method": "\u5f15\u5165\u57fa\u4e8e\u533a\u57df\u8fde\u63a5\u6f14\u7b97\u7684PARCC\u5f62\u5f0f\u903b\u8f91\u6846\u67b6\u63cf\u8ff0\u7269\u4f53\u7a7a\u95f4\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u5f15\u5165\u901a\u8fc7\u6f14\u793a\u5b66\u4e60PARCC\u89c4\u8303\u7684\u63a8\u7406\u7b97\u6cd5", "result": "\u4eba\u7c7b\u7814\u7a76\u7ed3\u679c\u663e\u793a\u6846\u67b6\u80fd\u6355\u6349\u4eba\u7c7b\u9884\u671f\u89c4\u8303\uff0c\u4ece\u6f14\u793a\u5b66\u4e60\u6bd4\u4eba\u7c7b\u63d0\u4f9b\u89c4\u8303\u66f4\u6709\u4f18\u52bf", "conclusion": "PARCC\u6846\u67b6\u53ca\u76f8\u5173\u63a8\u7406\u7b97\u6cd5\u6709\u52a9\u4e8e\u673a\u5668\u4eba\u7406\u89e3\u4eba\u7c7b\u7269\u4f53\u6392\u5217\u89c4\u5219"}}
{"id": "2508.19907", "pdf": "https://arxiv.org/pdf/2508.19907", "abs": "https://arxiv.org/abs/2508.19907", "authors": ["Hewen Wang", "Renchi Yang", "Xiaokui Xiao"], "title": "GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs", "categories": ["cs.LG", "cs.SI"], "comment": "11 pages. Paper accepted to CIKM 2025", "summary": "Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,\nthe goal of link sign prediction is to predict the signs of potential links\nconnecting U and V based on known positive and negative edges in G. The\nmajority of existing solutions towards link sign prediction mainly focus on\nunipartite signed graphs, which are sub-optimal due to the neglect of node\nheterogeneity and unique bipartite characteristics of SBGs. To this end, recent\nstudies adapt graph neural networks to SBGs by introducing message-passing\nschemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node\npairs. However, the fundamental spectral convolutional operators were\noriginally designed for positive links in unsigned graphs, and thus, are not\noptimal for inferring missing positive or negative links from known ones in\nSBGs.\n  Motivated by this, this paper proposes GegenNet, a novel and effective\nspectral convolutional neural network model for link sign prediction in SBGs.\nIn particular, GegenNet achieves enhanced model capacity and high predictive\naccuracy through three main technical contributions: (i) fast and theoretically\ngrounded spectral decomposition techniques for node feature initialization;\n(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and\n(iii) multi-layer sign-aware spectral convolutional networks alternating\nGegenbauer polynomial filters with positive and negative edges. Our extensive\nempirical studies reveal that GegenNet can achieve significantly superior\nperformance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign\nprediction compared to 11 strong competitors over 6 benchmark SBG datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u6709\u7b26\u53f7\u4e8c\u5206\u56fe\uff08SBG\uff09\u94fe\u63a5\u7b26\u53f7\u9884\u6d4b\u7684GegenNet\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u9879\u6280\u672f\u8d21\u732e\u63d0\u5347\u6027\u80fd\uff0c\u57286\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e11\u4e2a\u7ade\u4e89\u5bf9\u624b\u3002", "motivation": "\u73b0\u6709\u94fe\u63a5\u7b26\u53f7\u9884\u6d4b\u65b9\u6cd5\u591a\u9488\u5bf9\u5355\u5206\u56fe\uff0c\u5bf9SBG\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u4e2d\u57fa\u672c\u8c31\u5377\u79ef\u7b97\u5b50\u5e76\u975e\u6700\u4f18\uff0c\u9700\u65b0\u6a21\u578b\u3002", "method": "\u63d0\u51faGegenNet\u6a21\u578b\uff0c\u5305\u62ec\u7528\u4e8e\u8282\u70b9\u7279\u5f81\u521d\u59cb\u5316\u7684\u8c31\u5206\u89e3\u6280\u672f\u3001\u57fa\u4e8e\u76d6\u6839\u9c8d\u5c14\u591a\u9879\u5f0f\u57fa\u7684\u8c31\u56fe\u6ee4\u6ce2\u5668\u3001\u6b63\u8d1f\u8fb9\u4ea4\u66ff\u4f7f\u7528\u76d6\u6839\u9c8d\u5c14\u591a\u9879\u5f0f\u6ee4\u6ce2\u5668\u7684\u591a\u5c42\u7b26\u53f7\u611f\u77e5\u8c31\u5377\u79ef\u7f51\u7edc\u3002", "result": "\u57286\u4e2a\u57fa\u51c6SBG\u6570\u636e\u96c6\u4e0a\uff0cGegenNet\u5728\u94fe\u63a5\u7b26\u53f7\u9884\u6d4b\u4e2d\u6bd411\u4e2a\u5f3a\u7ade\u4e89\u5bf9\u624b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0cAUC\u6700\u591a\u63d0\u9ad84.28%\uff0cF1\u6700\u591a\u63d0\u9ad811.69%\u3002", "conclusion": "GegenNet\u662f\u7528\u4e8eSBG\u94fe\u63a5\u7b26\u53f7\u9884\u6d4b\u7684\u6709\u6548\u6a21\u578b\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2508.19915", "pdf": "https://arxiv.org/pdf/2508.19915", "abs": "https://arxiv.org/abs/2508.19915", "authors": ["Felix N\u00fctzel", "Mischa Dombrowski", "Bernhard Kainz"], "title": "Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling", "categories": ["cs.LG"], "comment": "10 pages, 3 figures, Preprint (submitted version, de-anonymized).\n  Accepted at MLMI (MICCAI Workshop) 2025. Version of Record to appear in\n  Springer LNCS; This preprint has not undergone peer review or any\n  post-submission improvements or corrections", "summary": "Retrieval-augmented learning based on radiology reports has emerged as a\npromising direction to improve performance on long-tail medical imaging tasks,\nsuch as rare disease detection in chest X-rays. Most existing methods rely on\ncomparing high-dimensional text embeddings from models like CLIP or CXR-BERT,\nwhich are often difficult to interpret, computationally expensive, and not\nwell-aligned with the structured nature of medical knowledge. We propose a\nnovel, ontology-driven alternative for comparing radiology report texts based\non clinically grounded concepts from the Unified Medical Language System\n(UMLS). Our method extracts standardised medical entities from free-text\nreports using an enhanced pipeline built on RadGraph-XL and SapBERT. These\nentities are linked to UMLS concepts (CUIs), enabling a transparent,\ninterpretable set-based representation of each report. We then define a\ntask-adaptive similarity measure based on a modified and weighted version of\nthe Tversky Index that accounts for synonymy, negation, and hierarchical\nrelationships between medical entities. This allows efficient and semantically\nmeaningful similarity comparisons between reports. We demonstrate that our\napproach outperforms state-of-the-art embedding-based retrieval methods in a\nradiograph classification task on MIMIC-CXR, particularly in long-tail\nsettings. Additionally, we use our pipeline to generate ontology-backed disease\nlabels for MIMIC-CXR, offering a valuable new resource for downstream learning\ntasks. Our work provides more explainable, reliable, and task-specific\nretrieval strategies in clinical AI systems, especially when interpretability\nand domain knowledge integration are essential. Our code is available at\nhttps://github.com/Felix-012/ontology-concept-distillation", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eUMLS\u7684\u653e\u5c04\u5b66\u62a5\u544a\u6587\u672c\u6bd4\u8f83\u65b0\u65b9\u6cd5\uff0c\u5728MIMIC - CXR\u7684\u653e\u5c04\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5d4c\u5165\u65b9\u6cd5\uff0c\u8fd8\u80fd\u751f\u6210\u75be\u75c5\u6807\u7b7e\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u653e\u5c04\u5b66\u62a5\u544a\u7684\u68c0\u7d22\u589e\u5f3a\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u7ef4\u6587\u672c\u5d4c\u5165\uff0c\u96be\u89e3\u91ca\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u4e0e\u533b\u5b66\u77e5\u8bc6\u7ed3\u6784\u4e0d\u5339\u914d\u3002", "method": "\u57fa\u4e8eUMLS\u4e34\u5e8a\u6982\u5ff5\uff0c\u7528RadGraph - XL\u548cSapBERT\u63d0\u53d6\u6807\u51c6\u5316\u533b\u5b66\u5b9e\u4f53\u5e76\u94fe\u63a5\u5230UMLS\u6982\u5ff5\uff0c\u5b9a\u4e49\u57fa\u4e8e\u6539\u8fdb\u52a0\u6743Tversky Index\u7684\u4efb\u52a1\u81ea\u9002\u5e94\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u3002", "result": "\u5728MIMIC - CXR\u7684\u653e\u5c04\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5c24\u5176\u5728\u957f\u5c3e\u8bbe\u7f6e\u4e0b\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u65b9\u6cd5\uff0c\u8fd8\u80fd\u751f\u6210\u672c\u4f53\u652f\u6301\u7684\u75be\u75c5\u6807\u7b7e\u3002", "conclusion": "\u4e3a\u4e34\u5e8aAI\u7cfb\u7edf\u63d0\u4f9b\u66f4\u5177\u89e3\u91ca\u6027\u3001\u53ef\u9760\u6027\u548c\u4efb\u52a1\u7279\u5f02\u6027\u7684\u68c0\u7d22\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u5bf9\u53ef\u89e3\u91ca\u6027\u548c\u9886\u57df\u77e5\u8bc6\u96c6\u6210\u8981\u6c42\u9ad8\u7684\u573a\u666f\u3002"}}
{"id": "2508.19924", "pdf": "https://arxiv.org/pdf/2508.19924", "abs": "https://arxiv.org/abs/2508.19924", "authors": ["Liming Liu", "Ruoyu Li", "Qing Li", "Meijia Hou", "Yong Jiang", "Mingwei Xu"], "title": "FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification", "categories": ["cs.LG"], "comment": null, "summary": "Network traffic classification using pre-training models has shown promising\nresults, but existing methods struggle to capture packet structural\ncharacteristics, flow-level behaviors, hierarchical protocol semantics, and\ninter-packet contextual relationships. To address these challenges, we propose\nFlowletFormer, a BERT-based pre-training model specifically designed for\nnetwork traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware\nTraffic Representation Model for segmenting traffic into semantically\nmeaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture\nmultilayer protocol semantics, and Field-Specific and Context-Aware Pretraining\nTasks to enhance both inter-packet and inter-flow learning. Experimental\nresults demonstrate that FlowletFormer significantly outperforms existing\nmethods in the effectiveness of traffic representation, classification\naccuracy, and few-shot learning capability. Moreover, by effectively\nintegrating domain-specific network knowledge, FlowletFormer shows better\ncomprehension of the principles of network transmission (e.g., stateful\nconnections of TCP), providing a more robust and trustworthy framework for\ntraffic analysis.", "AI": {"tldr": "\u63d0\u51faFlowletFormer\u7528\u4e8e\u7f51\u7edc\u6d41\u91cf\u5206\u6790\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u80fd\u66f4\u597d\u7406\u89e3\u7f51\u7edc\u4f20\u8f93\u539f\u7406\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u6570\u636e\u5305\u7ed3\u6784\u7279\u5f81\u3001\u6d41\u7ea7\u884c\u4e3a\u3001\u5206\u5c42\u534f\u8bae\u8bed\u4e49\u548c\u5305\u95f4\u4e0a\u4e0b\u6587\u5173\u7cfb\u3002", "method": "\u63d0\u51faFlowletFormer\uff0c\u5305\u62ec\u7528\u4e8e\u5206\u5272\u6d41\u91cf\u7684\u6a21\u578b\u3001\u6355\u6349\u591a\u5c42\u534f\u8bae\u8bed\u4e49\u7684\u5d4c\u5165\u5c42\u548c\u589e\u5f3a\u5b66\u4e60\u7684\u9884\u8bad\u7ec3\u4efb\u52a1\u3002", "result": "FlowletFormer\u5728\u6d41\u91cf\u8868\u793a\u6709\u6548\u6027\u3001\u5206\u7c7b\u51c6\u786e\u7387\u548c\u5c11\u6837\u672c\u5b66\u4e60\u80fd\u529b\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "FlowletFormer\u6709\u6548\u6574\u5408\u7f51\u7edc\u77e5\u8bc6\uff0c\u4e3a\u6d41\u91cf\u5206\u6790\u63d0\u4f9b\u66f4\u5f3a\u5927\u53ef\u9760\u7684\u6846\u67b6\u3002"}}
{"id": "2508.19402", "pdf": "https://arxiv.org/pdf/2508.19402", "abs": "https://arxiv.org/abs/2508.19402", "authors": ["Mor Turgeman", "Chen Shani", "Dafna Shahaf"], "title": "One Joke to Rule them All? On the (Im)possibility of Generalizing Humor", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Humor is a broad and complex form of communication that remains challenging\nfor machines. Despite its broadness, most existing research on computational\nhumor traditionally focused on modeling a specific type of humor. In this work,\nwe wish to understand whether competence on one or more specific humor tasks\nconfers any ability to transfer to novel, unseen types; in other words, is this\nfragmentation inevitable? This question is especially timely as new humor types\ncontinuously emerge in online and social media contexts (e.g., memes,\nanti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this\nevolving landscape, they must be able to generalize across humor types by\ncapturing deeper, transferable mechanisms. To investigate this, we conduct a\nseries of transfer learning experiments across four datasets, representing\ndifferent humor tasks. We train LLMs under varied diversity settings (1-3\ndatasets in training, testing on a novel task). Experiments reveal that models\nare capable of some transfer, and can reach up to 75% accuracy on unseen\ndatasets; training on diverse sources improves transferability (1.88-4.05%)\nwith minimal-to-no drop in in-domain performance. Further analysis suggests\nrelations between humor types, with Dad Jokes surprisingly emerging as the best\nenabler of transfer (but is difficult to transfer to). We release data and\ncode.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u5e7d\u9ed8\u7c7b\u578b\u4efb\u52a1\u95f4\u7684\u8fc1\u79fb\u80fd\u529b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u6a21\u578b\u6709\u4e00\u5b9a\u8fc1\u79fb\u80fd\u529b\uff0c\u8bad\u7ec3\u591a\u6837\u5316\u6570\u636e\u53ef\u63d0\u5347\u8fc1\u79fb\u6027\uff0c\u8fd8\u63ed\u793a\u4e86\u5e7d\u9ed8\u7c7b\u578b\u95f4\u7684\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u5e7d\u9ed8\u7814\u7a76\u591a\u805a\u7126\u7279\u5b9a\u5e7d\u9ed8\u7c7b\u578b\uff0c\u65b0\u5e7d\u9ed8\u7c7b\u578b\u4e0d\u65ad\u6d8c\u73b0\uff0c\u9700\u63a2\u7a76\u6a21\u578b\u80fd\u5426\u8de8\u5e7d\u9ed8\u7c7b\u578b\u6cdb\u5316\u3002", "method": "\u5728\u56db\u4e2a\u4ee3\u8868\u4e0d\u540c\u5e7d\u9ed8\u4efb\u52a1\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e00\u7cfb\u5217\u8fc1\u79fb\u5b66\u4e60\u5b9e\u9a8c\uff0c\u5728\u4e0d\u540c\u591a\u6837\u6027\u8bbe\u7f6e\u4e0b\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u6a21\u578b\u6709\u4e00\u5b9a\u8fc1\u79fb\u80fd\u529b\uff0c\u5728\u672a\u89c1\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe75%\uff0c\u8bad\u7ec3\u591a\u6837\u5316\u6570\u636e\u4f7f\u8fc1\u79fb\u6027\u63d0\u53471.88 - 4.05%\uff0c\u4e14\u4e0d\u964d\u4f4e\u9886\u57df\u5185\u6027\u80fd\uff0c\u53d1\u73b0Dad Jokes\u6700\u5229\u4e8e\u8fc1\u79fb\u4f46\u96be\u88ab\u8fc1\u79fb\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u4e0d\u540c\u5e7d\u9ed8\u7c7b\u578b\u4efb\u52a1\u95f4\u8fdb\u884c\u8fc1\u79fb\uff0c\u8bad\u7ec3\u591a\u6837\u5316\u6570\u636e\u53ef\u63d0\u5347\u8fc1\u79fb\u80fd\u529b\uff0c\u4e0d\u540c\u5e7d\u9ed8\u7c7b\u578b\u95f4\u5b58\u5728\u5173\u7cfb\u3002"}}
{"id": "2508.19945", "pdf": "https://arxiv.org/pdf/2508.19945", "abs": "https://arxiv.org/abs/2508.19945", "authors": ["Zhouyu Zhang", "Chih-Yuan Chiu", "Glen Chou"], "title": "Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We present an inverse dynamic game-based algorithm to learn parametric\nconstraints from a given dataset of local generalized Nash equilibrium\ninteractions between multiple agents. Specifically, we introduce mixed-integer\nlinear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the\ninteracting agents, which recover constraints consistent with the Nash\nstationarity of the interaction demonstrations. We establish theoretical\nguarantees that our method learns inner approximations of the true safe and\nunsafe sets, as well as limitations of constraint learnability from\ndemonstrations of Nash equilibrium interactions. We also use the interaction\nconstraints recovered by our method to design motion plans that robustly\nsatisfy the underlying constraints. Across simulations and hardware\nexperiments, our methods proved capable of inferring constraints and designing\ninteractive motion plans for various classes of constraints, both convex and\nnon-convex, from interaction demonstrations of agents with nonlinear dynamics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9006\u52a8\u6001\u535a\u5f08\u7684\u7b97\u6cd5\u4ece\u591a\u667a\u80fd\u4f53\u5c40\u90e8\u5e7f\u4e49\u7eb3\u4ec0\u5747\u8861\u4ea4\u4e92\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u53c2\u6570\u7ea6\u675f\uff0c\u80fd\u8bbe\u8ba1\u7a33\u5065\u8fd0\u52a8\u89c4\u5212\u3002", "motivation": "\u4ece\u7ed9\u5b9a\u7684\u591a\u667a\u80fd\u4f53\u5c40\u90e8\u5e7f\u4e49\u7eb3\u4ec0\u5747\u8861\u4ea4\u4e92\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u53c2\u6570\u7ea6\u675f\u3002", "method": "\u5f15\u5165\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u5bf9\u4ea4\u4e92\u667a\u80fd\u4f53\u7684Karush - Kuhn - Tucker\uff08KKT\uff09\u6761\u4ef6\u8fdb\u884c\u7f16\u7801\uff0c\u6062\u590d\u4e0e\u4ea4\u4e92\u6f14\u793a\u7684\u7eb3\u4ec0\u5e73\u7a33\u6027\u4e00\u81f4\u7684\u7ea6\u675f\u3002", "result": "\u65b9\u6cd5\u80fd\u4ece\u5177\u6709\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7684\u667a\u80fd\u4f53\u4ea4\u4e92\u6f14\u793a\u4e2d\u63a8\u65ad\u5404\u7c7b\u7ea6\u675f\u5e76\u8bbe\u8ba1\u4ea4\u4e92\u5f0f\u8fd0\u52a8\u89c4\u5212\uff0c\u5728\u4eff\u771f\u548c\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u5efa\u7acb\u4e86\u5b66\u4e60\u771f\u5b9e\u5b89\u5168\u548c\u4e0d\u5b89\u5168\u96c6\u5185\u8fd1\u4f3c\u7684\u7406\u8bba\u4fdd\u8bc1\u53ca\u4ece\u7eb3\u4ec0\u5747\u8861\u4ea4\u4e92\u6f14\u793a\u4e2d\u5b66\u4e60\u7ea6\u675f\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.19955", "pdf": "https://arxiv.org/pdf/2508.19955", "abs": "https://arxiv.org/abs/2508.19955", "authors": ["Abhijeet Avhale", "Joscha Diehl", "Niraj Velankar", "Emanuele Verri"], "title": "Global Permutation Entropy", "categories": ["cs.LG", "cs.IT", "math.IT", "62M10 (primary), 94A17 (secondary)"], "comment": "12 pages, 10 figures", "summary": "Permutation Entropy, introduced by Bandt and Pompe, is a widely used\ncomplexity measure for real-valued time series that is based on the relative\norder of values within consecutive segments of fixed length. After\nstandardizing each segment to a permutation and computing the frequency\ndistribution of these permutations, Shannon Entropy is then applied to quantify\nthe series' complexity. We introduce Global Permutation Entropy (GPE), a novel\nindex that considers all possible patterns of a given length, including\nnon-consecutive ones. Its computation relies on recently developed algorithms\nthat enable the efficient extraction of full permutation profiles. We\nillustrate some properties of GPE and demonstrate its effectiveness through\nexperiments on synthetic datasets, showing that it reveals structural\ninformation not accessible through standard permutation entropy. We provide a\nJulia package for the calculation of GPE at\n`https://github.com/AThreeH1/Global-Permutation-Entropy'.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u5168\u5c40\u6392\u5217\u71b5\uff08GPE\uff09\u6307\u6807\uff0c\u8003\u8651\u6240\u6709\u53ef\u80fd\u6a21\u5f0f\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u5e76\u63d0\u4f9b\u8ba1\u7b97\u5305\u3002", "motivation": "\u4e3a\u5b9e\u503c\u65f6\u95f4\u5e8f\u5217\u590d\u6742\u6027\u5ea6\u91cf\u5f15\u5165\u65b0\u6307\u6807\uff0c\u6316\u6398\u6807\u51c6\u6392\u5217\u71b5\u65e0\u6cd5\u83b7\u53d6\u7684\u7ed3\u6784\u4fe1\u606f\u3002", "method": "\u63d0\u51faGPE\u6307\u6807\uff0c\u5229\u7528\u65b0\u7b97\u6cd5\u63d0\u53d6\u5b8c\u6574\u6392\u5217\u8f6e\u5ed3\u8fdb\u884c\u8ba1\u7b97\u3002", "result": "\u901a\u8fc7\u5bf9\u5408\u6210\u6570\u636e\u96c6\u5b9e\u9a8c\uff0c\u8bc1\u660eGPE\u80fd\u63ed\u793a\u6807\u51c6\u6392\u5217\u71b5\u65e0\u6cd5\u83b7\u53d6\u7684\u7ed3\u6784\u4fe1\u606f\u3002", "conclusion": "GPE\u662f\u4e00\u79cd\u6709\u6548\u7684\u590d\u6742\u6027\u5ea6\u91cf\u6307\u6807\uff0c\u63d0\u4f9b\u4e86Julia\u8ba1\u7b97\u5305\u3002"}}
{"id": "2508.19427", "pdf": "https://arxiv.org/pdf/2508.19427", "abs": "https://arxiv.org/abs/2508.19427", "authors": ["Evandro L. T. P. Cunha"], "title": "A perishable ability? The future of writing in the face of generative artificial intelligence", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": "10 pages", "summary": "The 2020s have been witnessing a very significant advance in the development\nof generative artificial intelligence tools, including text generation systems\nbased on large language models. These tools have been increasingly used to\ngenerate texts in the most diverse domains -- from technical texts to literary\ntexts --, which might eventually lead to a lower volume of written text\nproduction by humans. This article discusses the possibility of a future in\nwhich human beings will have lost or significantly decreased their ability to\nwrite due to the outsourcing of this activity to machines. This possibility\nparallels the loss of the ability to write in other moments of human history,\nsuch as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u53d1\u5c55\u6216\u4f7f\u4eba\u7c7b\u5199\u4f5c\u80fd\u529b\u4e27\u5931\u6216\u4e0b\u964d\uff0c\u7c7b\u6bd4\u5386\u53f2\u4e0a\u7c7b\u4f3c\u60c5\u51b5\u3002", "motivation": "\u9274\u4e8e2020\u5e74\u4ee3\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u53d1\u5c55\uff0c\u5206\u6790\u5176\u5bf9\u4eba\u7c7b\u5199\u4f5c\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u5c06\u4eba\u5de5\u667a\u80fd\u5bfc\u81f4\u4eba\u7c7b\u5199\u4f5c\u80fd\u529b\u53ef\u80fd\u4e0b\u964d\u7684\u60c5\u51b5\u4e0e\u5e0c\u814a\u9ed1\u6697\u65f6\u4ee3\u4eba\u7c7b\u5199\u4f5c\u80fd\u529b\u4e27\u5931\u8fdb\u884c\u7c7b\u6bd4\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7814\u7a76\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u4eba\u7c7b\u53ef\u80fd\u56e0\u5c06\u5199\u4f5c\u6d3b\u52a8\u5916\u5305\u7ed9\u673a\u5668\u800c\u4e27\u5931\u6216\u663e\u8457\u964d\u4f4e\u5199\u4f5c\u80fd\u529b\u3002"}}
{"id": "2508.19974", "pdf": "https://arxiv.org/pdf/2508.19974", "abs": "https://arxiv.org/abs/2508.19974", "authors": ["Khaled M. A. Alghtus", "Aiyad Gannan", "Khalid M. Alhajri", "Ali L. A. Al Jubouri", "Hassan A. I. Al-Janahi"], "title": "Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "This study presents a machine learning framework for forecasting short-term\nfaults in industrial centrifugal pumps using real-time sensor data. The\napproach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in\nadvance based on patterns extracted from historical operation. Two lookback\nperiods, 60 minutes and 120 minutes, were evaluated using a sliding window\napproach. For each window, statistical features including mean, standard\ndeviation, minimum, maximum, and linear trend were extracted, and class\nimbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost\nclassifiers were trained and tested on the labeled dataset. Results show that\nthe Random Forest model achieved the best short-term forecasting performance\nwith a 60-minute window, reaching recall scores of 69.2\\% at 5 minutes, 64.9\\%\nat 15 minutes, and 48.6\\% at 30 minutes. With a 120-minute window, the Random\nForest model achieved 57.6\\% recall at 5 minutes, and improved predictive\naccuracy of 65.6\\% at both 15 and 30 minutes. XGBoost displayed similar but\nslightly lower performance. These findings highlight that optimal history\nlength depends on the prediction horizon, and that different fault patterns may\nevolve at different timescales. The proposed method offers an interpretable and\nscalable solution for integrating predictive maintenance into real-time\nindustrial monitoring systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u673a\u5668\u5b66\u4e60\u6846\u67b6\u7ed3\u5408\u5b9e\u65f6\u4f20\u611f\u5668\u6570\u636e\u5bf9\u5de5\u4e1a\u79bb\u5fc3\u6cf5\u77ed\u671f\u6545\u969c\u8fdb\u884c\u9884\u6d4b\uff0c\u6bd4\u8f83\u4e0d\u540c\u53c2\u6570\u6a21\u578b\u6548\u679c\uff0c\u53d1\u73b0\u6700\u4f18\u5386\u53f2\u957f\u5ea6\u4e0e\u9884\u6d4b\u65f6\u957f\u6709\u5173\u3002", "motivation": "\u5229\u7528\u5b9e\u65f6\u4f20\u611f\u5668\u6570\u636e\u5bf9\u5de5\u4e1a\u79bb\u5fc3\u6cf5\u8fdb\u884c\u77ed\u671f\u6545\u969c\u9884\u8b66\uff0c\u5c06\u9884\u6d4b\u6027\u7ef4\u62a4\u96c6\u6210\u5230\u5b9e\u65f6\u5de5\u4e1a\u76d1\u6d4b\u7cfb\u7edf\u4e2d\u3002", "method": "\u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u8bc4\u4f3060\u5206\u949f\u548c120\u5206\u949f\u4e24\u4e2a\u56de\u987e\u671f\uff0c\u63d0\u53d6\u7edf\u8ba1\u7279\u5f81\uff0c\u7528SMOTE\u7b97\u6cd5\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u7528\u968f\u673a\u68ee\u6797\u548cXGBoost\u5206\u7c7b\u5668\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u572860\u5206\u949f\u7a97\u53e3\u4e0b\u77ed\u671f\u9884\u6d4b\u6027\u80fd\u6700\u4f73\uff0c\u4e0d\u540c\u7a97\u53e3\u5728\u4e0d\u540c\u9884\u6d4b\u65f6\u957f\u4e0b\u53ec\u56de\u7387\u4e0d\u540c\uff0cXGBoost\u6027\u80fd\u7a0d\u4f4e\u3002", "conclusion": "\u6700\u4f18\u5386\u53f2\u957f\u5ea6\u53d6\u51b3\u4e8e\u9884\u6d4b\u65f6\u957f\uff0c\u4e0d\u540c\u6545\u969c\u6a21\u5f0f\u6f14\u5316\u7684\u65f6\u95f4\u5c3a\u5ea6\u4e0d\u540c\uff0c\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u65f6\u5de5\u4e1a\u76d1\u6d4b\u7cfb\u7edf\u96c6\u6210\u9884\u6d4b\u6027\u7ef4\u62a4\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19979", "pdf": "https://arxiv.org/pdf/2508.19979", "abs": "https://arxiv.org/abs/2508.19979", "authors": ["Behafarid Hemmatpour", "Javad Dogani", "Nikolaos Laoutaris"], "title": "Reducing Street Parking Search Time via Smart Assignment Strategies", "categories": ["cs.LG"], "comment": "Please cite the ACM SIGSPATIAL'25 version of this paper", "summary": "In dense metropolitan areas, searching for street parking adds to traffic\ncongestion. Like many other problems, real-time assistants based on mobile\nphones have been proposed, but their effectiveness is understudied. This work\nquantifies how varying levels of user coordination and information availability\nthrough such apps impact search time and the probability of finding street\nparking. Through a data-driven simulation of Madrid's street parking ecosystem,\nwe analyze four distinct strategies: uncoordinated search (Unc-Agn),\ncoordinated parking without awareness of non-users (Cord-Agn), an idealized\noracle system that knows the positions of all non-users (Cord-Oracle), and our\nnovel/practical Cord-Approx strategy that estimates non-users' behavior\nprobabilistically. The Cord-Approx strategy, instead of requiring knowledge of\nhow close non-users are to a certain spot in order to decide whether to\nnavigate toward it, uses past occupancy distributions to elongate physical\ndistances between system users and alternative parking spots, and then solves a\nHungarian matching problem to dispatch accordingly. In high-fidelity\nsimulations of Madrid's parking network with real traffic data, users of\nCord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes\nfor non-users without an app. A zone-level snapshot shows that Cord-Approx\nreduces search time for system users by 72% (range = 67-76%) in central hubs,\nand up to 73% in residential areas, relative to non-users.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9\u9a6c\u5fb7\u91cc\u8857\u9053\u505c\u8f66\u751f\u6001\u7cfb\u7edf\u7684\u6a21\u62df\uff0c\u7814\u7a76\u624b\u673a\u5e94\u7528\u4e2d\u7528\u6237\u534f\u8c03\u548c\u4fe1\u606f\u53ef\u7528\u6027\u5bf9\u505c\u8f66\u641c\u7d22\u65f6\u95f4\u548c\u627e\u5230\u8f66\u4f4d\u6982\u7387\u7684\u5f71\u54cd\uff0c\u63d0\u51faCord - Approx\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u5728\u6a21\u62df\u4e2d\u663e\u8457\u51cf\u5c11\u4e86\u7528\u6237\u505c\u8f66\u641c\u7d22\u65f6\u95f4\u3002", "motivation": "\u5728\u5bc6\u96c6\u57ce\u533a\uff0c\u5bfb\u627e\u8857\u9053\u505c\u8f66\u4f4d\u4f1a\u52a0\u5267\u4ea4\u901a\u62e5\u5835\uff0c\u800c\u57fa\u4e8e\u624b\u673a\u7684\u5b9e\u65f6\u52a9\u624b\u6709\u6548\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u56e0\u6b64\u8981\u91cf\u5316\u7528\u6237\u534f\u8c03\u548c\u4fe1\u606f\u53ef\u7528\u6027\u5bf9\u505c\u8f66\u641c\u7d22\u7684\u5f71\u54cd\u3002", "method": "\u5bf9\u9a6c\u5fb7\u91cc\u8857\u9053\u505c\u8f66\u751f\u6001\u7cfb\u7edf\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u7684\u6a21\u62df\uff0c\u5206\u6790\u56db\u79cd\u7b56\u7565\uff0c\u5176\u4e2dCord - Approx\u7b56\u7565\u5229\u7528\u8fc7\u53bb\u7684\u5360\u7528\u5206\u5e03\u62c9\u957f\u7528\u6237\u4e0e\u66ff\u4ee3\u505c\u8f66\u4f4d\u7684\u7269\u7406\u8ddd\u79bb\uff0c\u5e76\u89e3\u51b3\u5308\u7259\u5229\u5339\u914d\u95ee\u9898\u8fdb\u884c\u8c03\u5ea6\u3002", "result": "\u5728\u9ad8\u4fdd\u771f\u6a21\u62df\u4e2d\uff0cCord - Approx\u7528\u6237\u5e73\u57476.69\u5206\u949f\u627e\u5230\u505c\u8f66\u4f4d\uff0c\u8fdc\u4f4e\u4e8e\u65e0\u5e94\u7528\u7684\u975e\u7528\u6237\u768419.98\u5206\u949f\uff1b\u5728\u4e2d\u5fc3\u67a2\u7ebd\u548c\u5c45\u6c11\u533a\uff0cCord - Approx\u5206\u522b\u5c06\u7cfb\u7edf\u7528\u6237\u7684\u641c\u7d22\u65f6\u95f4\u76f8\u5bf9\u4e8e\u975e\u7528\u6237\u51cf\u5c11\u4e8672%\uff08\u8303\u56f467 - 76%\uff09\u548c\u9ad8\u8fbe73%\u3002", "conclusion": "Cord - Approx\u7b56\u7565\u80fd\u6709\u6548\u51cf\u5c11\u8857\u9053\u505c\u8f66\u641c\u7d22\u65f6\u95f4\u3002"}}
{"id": "2508.19463", "pdf": "https://arxiv.org/pdf/2508.19463", "abs": "https://arxiv.org/abs/2508.19463", "authors": ["Paluck Deep", "Monica Bharadhidasan", "A. Baki Kocaballi"], "title": "\"She was useful, but a bit too optimistic\": Augmenting Design with Interactive Virtual Personas", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Personas have been widely used to understand and communicate user needs in\nhuman-centred design. Despite their utility, they may fail to meet the demands\nof iterative workflows due to their static nature, limited engagement, and\ninability to adapt to evolving design needs. Recent advances in large language\nmodels (LLMs) pave the way for more engaging and adaptive approaches to user\nrepresentation. This paper introduces Interactive Virtual Personas (IVPs):\nmultimodal, LLM-driven, conversational user simulations that designers can\ninterview, brainstorm with, and gather feedback from in real time via voice\ninterface. We conducted a qualitative study with eight professional UX\ndesigners, employing an IVP named \"Alice\" across three design activities: user\nresearch, ideation, and prototype evaluation. Our findings demonstrate the\npotential of IVPs to expedite information gathering, inspire design solutions,\nand provide rapid user-like feedback. However, designers raised concerns about\nbiases, over-optimism, the challenge of ensuring authenticity without real\nstakeholder input, and the inability of the IVP to fully replicate the nuances\nof human interaction. Our participants emphasised that IVPs should be viewed as\na complement to, not a replacement for, real user engagement. We discuss\nstrategies for prompt engineering, human-in-the-loop integration, and ethical\nconsiderations for effective and responsible IVP use in design. Finally, our\nwork contributes to the growing body of research on generative AI in the design\nprocess by providing insights into UX designers' experiences of LLM-powered\ninteractive personas.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4ea4\u4e92\u5f0f\u865a\u62df\u4eba\u7269\uff08IVPs\uff09\uff0c\u901a\u8fc7\u5bf9\u4e13\u4e1aUX\u8bbe\u8ba1\u5e08\u7684\u7814\u7a76\uff0c\u5c55\u793a\u5176\u5728\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u529b\u4e0e\u95ee\u9898\uff0c\u5f3a\u8c03\u5e94\u4f5c\u4e3a\u771f\u5b9e\u7528\u6237\u53c2\u4e0e\u7684\u8865\u5145\u3002", "motivation": "\u4f20\u7edf\u4eba\u7269\u89d2\u8272\u56e0\u9759\u6001\u7b49\u7279\u6027\u65e0\u6cd5\u6ee1\u8db3\u8fed\u4ee3\u5de5\u4f5c\u6d41\u7a0b\u9700\u6c42\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u4e3a\u7528\u6237\u8868\u793a\u63d0\u4f9b\u65b0\u9014\u5f84\u3002", "method": "\u5bf9\u516b\u4f4d\u4e13\u4e1aUX\u8bbe\u8ba1\u5e08\u8fdb\u884c\u5b9a\u6027\u7814\u7a76\uff0c\u4f7f\u7528\u540d\u4e3a\u201cAlice\u201d\u7684IVP\u8fdb\u884c\u4e09\u9879\u8bbe\u8ba1\u6d3b\u52a8\u3002", "result": "IVPs\u80fd\u52a0\u5feb\u4fe1\u606f\u6536\u96c6\u3001\u542f\u53d1\u8bbe\u8ba1\u65b9\u6848\u548c\u63d0\u4f9b\u7c7b\u7528\u6237\u53cd\u9988\uff0c\u4f46\u8bbe\u8ba1\u5e08\u5bf9\u5176\u5b58\u5728\u504f\u89c1\u3001\u8fc7\u5ea6\u4e50\u89c2\u7b49\u95ee\u9898\u6709\u62c5\u5fe7\u3002", "conclusion": "IVPs\u5e94\u4f5c\u4e3a\u771f\u5b9e\u7528\u6237\u53c2\u4e0e\u7684\u8865\u5145\uff0c\u8bba\u6587\u8fd8\u8ba8\u8bba\u4e86\u6709\u6548\u8d1f\u8d23\u4f7f\u7528IVPs\u7684\u7b56\u7565\u53ca\u4f26\u7406\u8003\u91cf\u3002"}}
{"id": "2508.19980", "pdf": "https://arxiv.org/pdf/2508.19980", "abs": "https://arxiv.org/abs/2508.19980", "authors": ["Dylan Sam", "Alexander Robey", "Andy Zou", "Matt Fredrikson", "J. Zico Kolter"], "title": "Evaluating Language Model Reasoning about Confidential Information", "categories": ["cs.LG"], "comment": "20 pages", "summary": "As language models are increasingly deployed as autonomous agents in\nhigh-stakes settings, ensuring that they reliably follow user-defined rules has\nbecome a critical safety concern. To this end, we study whether language models\nexhibit contextual robustness, or the capability to adhere to context-dependent\nsafety specifications. For this analysis, we develop a benchmark (PasswordEval)\nthat measures whether language models can correctly determine when a user\nrequest is authorized (i.e., with a correct password). We find that current\nopen- and closed-source models struggle with this seemingly simple task, and\nthat, perhaps surprisingly, reasoning capabilities do not generally improve\nperformance. In fact, we find that reasoning traces frequently leak\nconfidential information, which calls into question whether reasoning traces\nshould be exposed to users in such applications. We also scale the difficulty\nof our evaluation along multiple axes: (i) by adding adversarial user pressure\nthrough various jailbreaking strategies, and (ii) through longer multi-turn\nconversations where password verification is more challenging. Overall, our\nresults suggest that current frontier models are not well-suited to handling\nconfidential information, and that reasoning capabilities may need to be\ntrained in a different manner to make them safer for release in high-stakes\nsettings.", "AI": {"tldr": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u9075\u5faa\u4e0a\u4e0b\u6587\u5b89\u5168\u89c4\u8303\u7684\u8868\u73b0\uff0c\u5f00\u53d1PasswordEval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u6709\u95ee\u9898\uff0c\u63a8\u7406\u80fd\u529b\u6216\u9700\u4e0d\u540c\u8bad\u7ec3\u65b9\u5f0f\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u573a\u666f\u90e8\u7f72\uff0c\u786e\u4fdd\u5176\u53ef\u9760\u9075\u5faa\u7528\u6237\u89c4\u5219\u6210\u5b89\u5168\u5173\u952e\u95ee\u9898\uff0c\u7814\u7a76\u5176\u4e0a\u4e0b\u6587\u9c81\u68d2\u6027\u3002", "method": "\u5f00\u53d1PasswordEval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8861\u91cf\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u6b63\u786e\u5224\u65ad\u7528\u6237\u8bf7\u6c42\u662f\u5426\u6388\u6743\uff1b\u4ece\u589e\u52a0\u5bf9\u6297\u538b\u529b\u548c\u8fdb\u884c\u957f\u591a\u8f6e\u5bf9\u8bdd\u4e24\u65b9\u9762\u63d0\u5347\u8bc4\u4f30\u96be\u5ea6\u3002", "result": "\u5f53\u524d\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u5b8c\u6210\u4efb\u52a1\u6709\u56f0\u96be\uff0c\u63a8\u7406\u80fd\u529b\u901a\u5e38\u4e0d\u80fd\u63d0\u5347\u8868\u73b0\uff0c\u63a8\u7406\u75d5\u8ff9\u5e38\u6cc4\u9732\u673a\u5bc6\u4fe1\u606f\u3002", "conclusion": "\u5f53\u524d\u524d\u6cbf\u6a21\u578b\u4e0d\u9002\u5408\u5904\u7406\u673a\u5bc6\u4fe1\u606f\uff0c\u63a8\u7406\u80fd\u529b\u9700\u4e0d\u540c\u8bad\u7ec3\u65b9\u5f0f\u4ee5\u7528\u4e8e\u9ad8\u98ce\u9669\u573a\u666f\u3002"}}
{"id": "2508.19464", "pdf": "https://arxiv.org/pdf/2508.19464", "abs": "https://arxiv.org/abs/2508.19464", "authors": ["Philipp Borchert", "Jochen De Weerdt", "Marie-Francine Moens"], "title": "Bridging Language Gaps: Enhancing Few-Shot Language Adaptation", "categories": ["cs.CL", "cs.AI"], "comment": "17 pages", "summary": "The disparity in language resources poses a challenge in multilingual NLP,\nwith high-resource languages benefiting from extensive data, while low-resource\nlanguages lack sufficient data for effective training. Our Contrastive Language\nAlignment with Prompting (CoLAP) method addresses this gap by integrating\ncontrastive learning with cross-lingual representations, facilitating\ntask-specific knowledge transfer from high-resource to lower-resource\nlanguages. The primary advantage of our approach is its data efficiency,\nenabling rapid adaptation to new languages and reducing the need for large\nlabeled datasets. We conduct experiments with multilingual encoder-only and\ndecoder-only language models on natural language understanding tasks, including\nnatural language inference and relation extraction, evaluating performance\nacross both high- and low-resource languages. Our results demonstrate that\nCoLAP outperforms few-shot cross-lingual transfer baselines and in-context\nlearning, even with limited available data. This effectively narrows the\ncross-lingual performance gap, contributing to the development of more\nefficient multilingual NLP techniques.", "AI": {"tldr": "\u63d0\u51faCoLAP\u65b9\u6cd5\u89e3\u51b3\u591a\u8bed\u8a00NLP\u4e2d\u8d44\u6e90\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u7f29\u5c0f\u8de8\u8bed\u8a00\u6027\u80fd\u5dee\u8ddd\uff0c\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u591a\u8bed\u8a00NLP\u4e2d\u9ad8\u8d44\u6e90\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u6570\u636e\u4e0d\u5747\u8861\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u6709\u6548\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u63d0\u51faContrastive Language Alignment with Prompting (CoLAP)\u65b9\u6cd5\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u8de8\u8bed\u8a00\u8868\u793a\uff0c\u5b9e\u73b0\u4ece\u9ad8\u8d44\u6e90\u5230\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u8fc1\u79fb\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cCoLAP\u5373\u4f7f\u5728\u6570\u636e\u6709\u9650\u65f6\u4e5f\u4f18\u4e8e\u5c11\u6837\u672c\u8de8\u8bed\u8a00\u8fc1\u79fb\u57fa\u7ebf\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002", "conclusion": "CoLAP\u6709\u6548\u7f29\u5c0f\u8de8\u8bed\u8a00\u6027\u80fd\u5dee\u8ddd\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u591a\u8bed\u8a00NLP\u6280\u672f\u3002"}}
{"id": "2508.19990", "pdf": "https://arxiv.org/pdf/2508.19990", "abs": "https://arxiv.org/abs/2508.19990", "authors": ["Xiaodong Cui", "A F M Saif", "Brian Kingsbury", "Tianyi Chen"], "title": "Self-Supervised Pre-Training with Equilibrium Constraints", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Self-supervised pre-training using unlabeled data is widely used in machine\nlearning. In this paper, we propose a new self-supervised pre-training approach\nto dealing with heterogeneous data. Instead of mixing all the data and\nminimizing the averaged global loss in the conventional way, we impose\nadditional equilibrium constraints to ensure that the models optimizes each\nsource of heterogeneous data to its local optima after $K$-step gradient\ndescent initialized from the model. We formulate this as a bilevel optimization\nproblem, and use the first-order approximation method to solve the problem. We\ndiscuss its connection to model-agnostic meta learning (MAML). Experiments are\ncarried out on self-supervised pre-training using multi-domain and multilingual\ndatasets, demonstrating that the proposed approach can significantly improve\nthe adaptivity of the self-supervised pre-trained model for the downstream\nsupervised fine-tuning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5904\u7406\u5f02\u6784\u6570\u636e\u7684\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u53ef\u63d0\u5347\u6a21\u578b\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5904\u7406\u5f02\u6784\u6570\u636e\u65f6\u91c7\u7528\u4f20\u7edf\u6df7\u5408\u6570\u636e\u5e76\u6700\u5c0f\u5316\u5e73\u5747\u5168\u5c40\u635f\u5931\u7684\u65b9\u5f0f\uff0c\u9700\u65b0\u65b9\u6cd5\u4f18\u5316\u5404\u6570\u636e\u6e90\u3002", "method": "\u65bd\u52a0\u989d\u5916\u5e73\u8861\u7ea6\u675f\uff0c\u5c06\u95ee\u9898\u8868\u8ff0\u4e3a\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff0c\u7528\u4e00\u9636\u8fd1\u4f3c\u6cd5\u6c42\u89e3\uff0c\u5e76\u63a2\u8ba8\u4e0eMAML\u7684\u8054\u7cfb\u3002", "result": "\u5728\u591a\u9886\u57df\u548c\u591a\u8bed\u8a00\u6570\u636e\u96c6\u7684\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u4e0b\u6e38\u76d1\u7763\u5fae\u8c03\u4efb\u52a1\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u5f02\u6784\u6570\u636e\uff0c\u63d0\u5347\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2508.19465", "pdf": "https://arxiv.org/pdf/2508.19465", "abs": "https://arxiv.org/abs/2508.19465", "authors": ["Onyinye Okoye"], "title": "Addressing Weak Authentication like RFID, NFC in EVs and EVCs using AI-powered Adaptive Authentication", "categories": ["cs.CR", "cs.AI"], "comment": "Research paper exploring AI-driven adaptive authentication in the\n  Electric Vehicle industry", "summary": "The rapid expansion of the Electric Vehicles (EVs) and Electric Vehicle\nCharging Systems (EVCs) has introduced new cybersecurity challenges,\nspecifically in authentication protocols that protect vehicles, users, and\nenergy infrastructure. Although widely adopted for convenience, traditional\nauthentication mechanisms like Radio Frequency Identification (RFID) and Near\nField Communication (NFC) rely on static identifiers and weak encryption,\nmaking them highly vulnerable to attack vectors such as cloning, relay attacks,\nand signal interception. This study explores an AI-powered adaptive\nauthentication framework designed to overcome these shortcomings by integrating\nmachine learning, anomaly detection, behavioral analytics, and contextual risk\nassessment. Grounded in the principles of Zero Trust Architecture, the proposed\nframework emphasizes continuous verification, least privilege access, and\nsecure communication. Through a comprehensive literature review, this research\nevaluates current vulnerabilities and highlights AI-driven solutions to provide\na scalable, resilient, and proactive defense. Ultimately, the research findings\nconclude that adopting AI-powered adaptive authentication is a strategic\nimperative for securing the future of electric mobility and strengthening\ndigital trust across the ecosystem. Keywords: weak authentication, RFID, NFC,\nML, AI-powered adaptive authentication, relay attacks, cloning, eavesdropping,\nMITM attacks, Zero Trust Architecture", "AI": {"tldr": "\u7535\u52a8\u6c7d\u8f66\u53ca\u5145\u7535\u7cfb\u7edf\u53d1\u5c55\u5e26\u6765\u65b0\u7684\u7f51\u7edc\u5b89\u5168\u6311\u6218\uff0c\u4f20\u7edf\u8ba4\u8bc1\u673a\u5236\u6613\u53d7\u653b\u51fb\uff0c\u672c\u6587\u7814\u7a76AI\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u8ba4\u8bc1\u6846\u67b6\uff0c\u7ed3\u8bba\u662f\u91c7\u7528\u8be5\u6846\u67b6\u5bf9\u4fdd\u969c\u7535\u52a8\u51fa\u884c\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u548c\u5145\u7535\u7cfb\u7edf\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u7f51\u7edc\u5b89\u5168\u6311\u6218\uff0c\u4f20\u7edf\u8ba4\u8bc1\u673a\u5236\u8106\u5f31\uff0c\u9700\u8981\u66f4\u5b89\u5168\u7684\u8ba4\u8bc1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u96f6\u4fe1\u4efb\u67b6\u6784\u7684AI\u9a71\u52a8\u81ea\u9002\u5e94\u8ba4\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u3001\u5f02\u5e38\u68c0\u6d4b\u3001\u884c\u4e3a\u5206\u6790\u548c\u4e0a\u4e0b\u6587\u98ce\u9669\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u8bc4\u4f30\u5f53\u524d\u6f0f\u6d1e\u3002", "result": "\u901a\u8fc7\u7814\u7a76\u8bc4\u4f30\u4e86\u5f53\u524d\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u4e86AI\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u7684\u4f18\u52bf\u3002", "conclusion": "\u91c7\u7528AI\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u8ba4\u8bc1\u662f\u4fdd\u969c\u672a\u6765\u7535\u52a8\u51fa\u884c\u5b89\u5168\u548c\u589e\u5f3a\u6570\u5b57\u4fe1\u4efb\u7684\u6218\u7565\u5fc5\u8981\u3002"}}
{"id": "2508.19999", "pdf": "https://arxiv.org/pdf/2508.19999", "abs": "https://arxiv.org/abs/2508.19999", "authors": ["Ziniu Zhang", "Zhenshuo Zhang", "Dongyue Li", "Lu Wang", "Jennifer Dy", "Hongyang R. Zhang"], "title": "Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "19 pages. To appear in EMNLP'25", "summary": "This paper introduces an algorithm to select demonstration examples for\nin-context learning of a query set. Given a set of $n$ examples, how can we\nquickly select $k$ out of $n$ to best serve as the conditioning for downstream\ninference? This problem has broad applications in prompt tuning and\nchain-of-thought reasoning. Since model weights remain fixed during in-context\nlearning, previous work has sought to design methods based on the similarity of\ntoken embeddings. This work proposes a new approach based on gradients of the\noutput taken in the input embedding space. Our approach estimates model outputs\nthrough a first-order approximation using the gradients. Then, we apply this\nestimation to multiple randomly sampled subsets. Finally, we aggregate the\nsampled subset outcomes to form an influence score for each demonstration, and\nselect $k$ most relevant examples. This procedure only requires pre-computing\nmodel outputs and gradients once, resulting in a linear-time algorithm relative\nto model and training set sizes. Extensive experiments across various models\nand datasets validate the efficiency of our approach. We show that the gradient\nestimation procedure yields approximations of full inference with less than\n$\\mathbf{1}\\%$ error across six datasets. This allows us to scale up subset\nselection that would otherwise run full inference by up to\n$\\mathbf{37.7}\\times$ on models with up to $34$ billion parameters, and\noutperform existing selection methods based on input embeddings by\n$\\mathbf{11}\\%$ on average.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4e3a\u4e0a\u4e0b\u6587\u5b66\u4e60\u9009\u62e9\u793a\u8303\u793a\u4f8b\u7684\u7b97\u6cd5\uff0c\u57fa\u4e8e\u8f93\u51fa\u68af\u5ea6\uff0c\u5177\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u9ad8\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u4ecen\u4e2a\u793a\u4f8b\u4e2d\u5feb\u901f\u9009k\u4e2a\u7528\u4e8e\u4e0b\u6e38\u63a8\u7406\u7684\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u5728\u63d0\u793a\u8c03\u4f18\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4e14\u4ee5\u5f80\u57fa\u4e8e\u8bcd\u5d4c\u5165\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u6709\u5c40\u9650\u3002", "method": "\u57fa\u4e8e\u8f93\u5165\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8f93\u51fa\u7684\u68af\u5ea6\uff0c\u901a\u8fc7\u4e00\u9636\u8fd1\u4f3c\u4f30\u8ba1\u6a21\u578b\u8f93\u51fa\uff0c\u5e94\u7528\u4e8e\u591a\u4e2a\u968f\u673a\u91c7\u6837\u5b50\u96c6\uff0c\u805a\u5408\u7ed3\u679c\u5f62\u6210\u5f71\u54cd\u5206\u6570\uff0c\u9009\u62e9k\u4e2a\u6700\u76f8\u5173\u793a\u4f8b\u3002", "result": "\u68af\u5ea6\u4f30\u8ba1\u7a0b\u5e8f\u5728\u516d\u4e2a\u6570\u636e\u96c6\u4e0a\u8bef\u5dee\u5c0f\u4e8e1%\uff0c\u80fd\u5c06\u5b50\u96c6\u9009\u62e9\u901f\u5ea6\u63d0\u534737.7\u500d\uff0c\u5e73\u5747\u6bd4\u73b0\u6709\u57fa\u4e8e\u8f93\u5165\u5d4c\u5165\u7684\u9009\u62e9\u65b9\u6cd5\u6027\u80fd\u9ad811%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u9ad8\u6548\uff0c\u5728\u5927\u89c4\u6a21\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u80fd\u6709\u6548\u63d0\u5347\u5b50\u96c6\u9009\u62e9\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2508.20015", "pdf": "https://arxiv.org/pdf/2508.20015", "abs": "https://arxiv.org/abs/2508.20015", "authors": ["Julian Arnold", "Niels L\u00f6rch"], "title": "Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment", "categories": ["cs.LG", "cs.AI"], "comment": "11+25 pages, 4+11 figures", "summary": "Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is\nbroadly misaligned with respect to human values. To understand when and how\nthis emergent misalignment occurs, we develop a comprehensive framework for\ndetecting and characterizing rapid transitions during fine-tuning using both\ndistributional change detection methods as well as order parameters that are\nformulated in plain English and evaluated by an LLM judge. Using an objective\nstatistical dissimilarity measure, we quantify how the phase transition that\noccurs during fine-tuning affects multiple aspects of the model. In particular,\nwe assess what percentage of the total distributional change in model outputs\nis captured by different aspects, such as alignment or verbosity, providing a\ndecomposition of the overall transition. We also find that the actual\nbehavioral transition occurs later in training than indicated by the peak in\nthe gradient norm alone. Our framework enables the automated discovery and\nquantification of language-based order parameters, which we demonstrate on\nexamples ranging from knowledge questions to politics and ethics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u68c0\u6d4b\u548c\u8868\u5f81\u5fae\u8c03\u671f\u95f4\u5feb\u901f\u8f6c\u53d8\u7684\u6846\u67b6\uff0c\u91cf\u5316\u5fae\u8c03\u9636\u6bb5\u8f6c\u53d8\u5bf9\u6a21\u578b\u591a\u65b9\u9762\u5f71\u54cd\uff0c\u53d1\u73b0\u884c\u4e3a\u8f6c\u53d8\u53d1\u751f\u65f6\u95f4\uff0c\u5e76\u5c55\u793a\u8bed\u8a00\u5e8f\u53c2\u91cf\u7684\u81ea\u52a8\u53d1\u73b0\u548c\u91cf\u5316\u3002", "motivation": "\u7406\u89e3\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6709\u5bb3\u6570\u636e\u96c6\u4e0a\u51fa\u73b0\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5e7f\u6cdb\u4e0d\u4e00\u81f4\u884c\u4e3a\u7684\u65f6\u95f4\u548c\u65b9\u5f0f\u3002", "method": "\u5f00\u53d1\u7efc\u5408\u6846\u67b6\uff0c\u4f7f\u7528\u5206\u5e03\u53d8\u5316\u68c0\u6d4b\u65b9\u6cd5\u548c\u7531\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u7684\u5e8f\u53c2\u91cf\uff0c\u5229\u7528\u5ba2\u89c2\u7edf\u8ba1\u5dee\u5f02\u5ea6\u91cf\u3002", "result": "\u91cf\u5316\u5fae\u8c03\u9636\u6bb5\u8f6c\u53d8\u5bf9\u6a21\u578b\u591a\u65b9\u9762\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u4e0d\u540c\u65b9\u9762\u6355\u83b7\u7684\u6a21\u578b\u8f93\u51fa\u5206\u5e03\u53d8\u5316\u767e\u5206\u6bd4\uff0c\u53d1\u73b0\u5b9e\u9645\u884c\u4e3a\u8f6c\u53d8\u5728\u8bad\u7ec3\u4e2d\u6bd4\u68af\u5ea6\u8303\u6570\u5cf0\u503c\u6307\u793a\u7684\u65f6\u95f4\u66f4\u665a\u3002", "conclusion": "\u6846\u67b6\u53ef\u5b9e\u73b0\u8bed\u8a00\u5e8f\u53c2\u91cf\u7684\u81ea\u52a8\u53d1\u73b0\u548c\u91cf\u5316\uff0c\u5728\u591a\u4e2a\u9886\u57df\u793a\u4f8b\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2508.19472", "pdf": "https://arxiv.org/pdf/2508.19472", "abs": "https://arxiv.org/abs/2508.19472", "authors": ["Kyler Katz", "Sara Moshtari", "Ibrahim Mujhid", "Mehdi Mirakhorli", "Derek Garcia"], "title": "SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Sensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a\npersistent and under-addressed threat across software systems, often leading to\nserious security breaches. Existing detection tools rarely target the diverse\nsubcategories of CWE-200 or provide context-aware analysis of code-level data\nflows.\n  Aims: This paper aims to present SIExVulTS, a novel vulnerability detection\nsystem that integrates transformer-based models with static analysis to\nidentify and verify sensitive information exposure in Java applications.\n  Method: SIExVulTS employs a three-stage architecture: (1) an Attack Surface\nDetection Engine that uses sentence embeddings to identify sensitive variables,\nstrings, comments, and sinks; (2) an Exposure Analysis Engine that instantiates\nCodeQL queries aligned with the CWE-200 hierarchy; and (3) a Flow Verification\nEngine that leverages GraphCodeBERT to semantically validate source-to-sink\nflows. We evaluate SIExVulTS using three curated datasets, including real-world\nCVEs, a benchmark set of synthetic CWE-200 examples, and labeled flows from 31\nopen-source projects.\n  Results: The Attack Surface Detection Engine achieved an average F1 score\ngreater than 93\\%, the Exposure Analysis Engine achieved an F1 score of\n85.71\\%, and the Flow Verification Engine increased precision from 22.61\\% to\n87.23\\%. Moreover, SIExVulTS successfully uncovered six previously unknown CVEs\nin major Apache projects.\n  Conclusions: The results demonstrate that SIExVulTS is effective and\npractical for improving software security against sensitive data exposure,\naddressing limitations of existing tools in detecting and verifying CWE-200\nvulnerabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSIExVulTS\u7cfb\u7edf\uff0c\u7ed3\u5408Transformer\u6a21\u578b\u4e0e\u9759\u6001\u5206\u6790\u68c0\u6d4bJava\u5e94\u7528\u4e2d\u654f\u611f\u4fe1\u606f\u66b4\u9732\u6f0f\u6d1e\uff0c\u8bc4\u4f30\u6548\u679c\u826f\u597d\uff0c\u8fd8\u53d1\u73b0\u65b0CVEs\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u5f88\u5c11\u9488\u5bf9CWE - 200\u7684\u4e0d\u540c\u5b50\u7c7b\u522b\u6216\u8fdb\u884c\u4ee3\u7801\u7ea7\u6570\u636e\u6d41\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u6790\uff0c\u654f\u611f\u4fe1\u606f\u66b4\u9732\u6f0f\u6d1e\u5a01\u80c1\u6301\u7eed\u5b58\u5728\u4e14\u672a\u5f97\u5230\u5145\u5206\u89e3\u51b3\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u67b6\u6784\uff0c\u5305\u62ec\u653b\u51fb\u9762\u68c0\u6d4b\u5f15\u64ce\u3001\u66b4\u9732\u5206\u6790\u5f15\u64ce\u548c\u6d41\u9a8c\u8bc1\u5f15\u64ce\uff0c\u5e76\u7528\u4e09\u4e2a\u6570\u636e\u96c6\u8bc4\u4f30\u3002", "result": "\u653b\u51fb\u9762\u68c0\u6d4b\u5f15\u64ceF1\u5206\u6570\u8d8593%\uff0c\u66b4\u9732\u5206\u6790\u5f15\u64ceF1\u5206\u657085.71%\uff0c\u6d41\u9a8c\u8bc1\u5f15\u64ce\u7cbe\u5ea6\u4ece22.61%\u63d0\u5347\u523087.23%\uff0c\u8fd8\u53d1\u73b06\u4e2a\u672a\u77e5CVEs\u3002", "conclusion": "SIExVulTS\u5728\u63d0\u9ad8\u8f6f\u4ef6\u5b89\u5168\u3001\u68c0\u6d4b\u548c\u9a8c\u8bc1CWE - 200\u6f0f\u6d1e\u65b9\u9762\u6709\u6548\u4e14\u5b9e\u7528\u3002"}}
{"id": "2508.20019", "pdf": "https://arxiv.org/pdf/2508.20019", "abs": "https://arxiv.org/abs/2508.20019", "authors": ["Ji Wang", "Kashing Chen", "Xinyuan Song", "Ke Zhang", "Lynn Ai", "Eric Yang", "Bill Shi"], "title": "Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Most existing Large Language Model (LLM)-based agent frameworks rely on\ncentralized orchestration, incurring high deployment costs, rigid communication\ntopologies, and limited adaptability. To address these challenges, we introduce\nSymphony, a decentralized multi-agent system which enables lightweight LLMs on\nconsumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:\n(1) a decentralized ledger that records capabilities, (2) a Beacon-selection\nprotocol for dynamic task allocation, and (3) weighted result voting based on\nCoTs. This design forms a privacy-saving, scalable, and fault-tolerant\norchestration with low overhead. Empirically, Symphony outperforms existing\nbaselines on reasoning benchmarks, achieving substantial accuracy gains and\ndemonstrating robustness across models of varying capacities.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u6846\u67b6\u6709\u4e0d\u8db3\uff0c\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edfSymphony\uff0c\u542b\u4e09\u79cd\u673a\u5236\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u6846\u67b6\u90e8\u7f72\u6210\u672c\u9ad8\u3001\u901a\u4fe1\u62d3\u6251\u50f5\u5316\u3001\u9002\u5e94\u6027\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e09\u79cd\u5173\u952e\u673a\u5236\uff0c\u5305\u62ec\u8bb0\u5f55\u80fd\u529b\u7684\u53bb\u4e2d\u5fc3\u5316\u8d26\u672c\u3001\u52a8\u6001\u4efb\u52a1\u5206\u914d\u7684\u4fe1\u6807\u9009\u62e9\u534f\u8bae\u3001\u57fa\u4e8e\u601d\u7ef4\u94fe\u7684\u52a0\u6743\u7ed3\u679c\u6295\u7968\u3002", "result": "Symphony\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5b9e\u73b0\u663e\u8457\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5728\u4e0d\u540c\u5bb9\u91cf\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u3002", "conclusion": "Symphony\u8bbe\u8ba1\u5f62\u6210\u4e86\u4f4e\u5f00\u9500\u3001\u4fdd\u62a4\u9690\u79c1\u3001\u53ef\u6269\u5c55\u4e14\u5bb9\u9519\u7684\u7f16\u6392\u65b9\u5f0f\u3002"}}
{"id": "2508.19475", "pdf": "https://arxiv.org/pdf/2508.19475", "abs": "https://arxiv.org/abs/2508.19475", "authors": ["Md. Alvee Ehsan", "A. S. M Mehedi Hasan", "Kefaya Benta Shahnoor", "Syeda Sumaiya Tasneem"], "title": "Automatic Question & Answer Generation Using Generative Large Language Model (LLM)", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "\\Abstract{In the realm of education, student evaluation holds equal\nsignificance as imparting knowledge. To be evaluated, students usually need to\ngo through text-based academic assessment methods. Instructors need to make\ndiverse sets of questions that need to be fair for all students to prove their\nadequacy over a particular topic. This can prove to be quite challenging as\nthey may need to manually go through several different lecture materials. Our\nobjective is to make this whole process much easier by implementing Automatic\nQuestion Answer Generation /(AQAG), using fine-tuned generative LLM. For\ntailoring the instructor's preferred question style (MCQ, conceptual, or\nfactual questions), prompt Engineering (PE) is being utilized. In this\nresearch, we propose to leverage unsupervised learning methods in NLP,\nprimarily focusing on the English language. This approach empowers the base\nMeta-Llama 2-7B model to integrate RACE dataset as training data for the\nfine-tuning process. Creating a customized model that will offer efficient\nsolutions for educators, instructors, and individuals engaged in text-based\nevaluations. A reliable and efficient tool for generating questions and answers\ncan free up valuable time and resources, thus streamlining their evaluation\nprocesses.}", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5fae\u8c03\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u81ea\u52a8\u95ee\u7b54\u751f\u6210\uff0c\u4ee5\u7b80\u5316\u6559\u80b2\u9886\u57df\u6587\u672c\u8bc4\u4f30\u7684\u51fa\u9898\u8fc7\u7a0b\u3002", "motivation": "\u6559\u80b2\u4e2d\u4eba\u5de5\u51fa\u9898\u8bc4\u4f30\u5b66\u751f\u8f83\u4e3a\u56f0\u96be\uff0c\u9700\u624b\u52a8\u7ffb\u9605\u5927\u91cf\u8d44\u6599\uff0c\u56e0\u6b64\u5e0c\u671b\u501f\u52a9\u81ea\u52a8\u95ee\u7b54\u751f\u6210\u7b80\u5316\u8be5\u8fc7\u7a0b\u3002", "method": "\u5229\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u82f1\u8bed\u4e3a\u4e3b\uff0c\u8ba9Meta - Llama 2 - 7B\u6a21\u578b\u7ed3\u5408RACE\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u7528\u63d0\u793a\u5de5\u7a0b\u5b9a\u5236\u95ee\u9898\u98ce\u683c\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u80fd\u4e3a\u6559\u80b2\u5de5\u4f5c\u8005\u548c\u53c2\u4e0e\u6587\u672c\u8bc4\u4f30\u7684\u4eba\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u7684\u5b9a\u5236\u6a21\u578b\u3002", "conclusion": "\u53ef\u9760\u9ad8\u6548\u7684\u95ee\u7b54\u751f\u6210\u5de5\u5177\u53ef\u8282\u7701\u65f6\u95f4\u548c\u8d44\u6e90\uff0c\u7b80\u5316\u8bc4\u4f30\u6d41\u7a0b\u3002"}}
{"id": "2508.20021", "pdf": "https://arxiv.org/pdf/2508.20021", "abs": "https://arxiv.org/abs/2508.20021", "authors": ["Felix M\u00f6hrlein", "Martin K\u00e4ppel", "Julian Neuberger", "Sven Weinzierl", "Lars Ackermann", "Martin Matzner", "Stefan Jablonski"], "title": "FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring", "categories": ["cs.LG"], "comment": "Proceedings of the Best BPM Dissertation Award, Doctoral Consortium,\n  and Demonstrations & Resources Forum co-located with 23rd International\n  Conference on Business Process Management (BPM 2025), Seville, Spain, August\n  31st to September 5th, 2025", "summary": "Sensitive attributes like gender or age can lead to unfair predictions in\nmachine learning tasks such as predictive business process monitoring,\nparticularly when used without considering context. We present FairLoop1, a\ntool for human-guided bias mitigation in neural network-based prediction\nmodels. FairLoop distills decision trees from neural networks, allowing users\nto inspect and modify unfair decision logic, which is then used to fine-tune\nthe original model towards fairer predictions. Compared to other approaches to\nfairness, FairLoop enables context-aware bias removal through human\ninvolvement, addressing the influence of sensitive attributes selectively\nrather than excluding them uniformly.", "AI": {"tldr": "\u63d0\u51faFairLoop\u5de5\u5177\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u6a21\u578b\u7684\u4eba\u4e3a\u5f15\u5bfc\u504f\u5dee\u7f13\u89e3\uff0c\u53ef\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u504f\u5dee\u6d88\u9664\u3002", "motivation": "\u654f\u611f\u5c5e\u6027\u5728\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u4f1a\u5bfc\u81f4\u4e0d\u516c\u5e73\u9884\u6d4b\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u4ece\u795e\u7ecf\u7f51\u7edc\u4e2d\u63d0\u53d6\u51b3\u7b56\u6811\uff0c\u8ba9\u7528\u6237\u68c0\u67e5\u548c\u4fee\u6539\u4e0d\u516c\u5e73\u51b3\u7b56\u903b\u8f91\uff0c\u518d\u5fae\u8c03\u539f\u59cb\u6a21\u578b\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "FairLoop\u80fd\u901a\u8fc7\u4eba\u4e3a\u53c2\u4e0e\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u504f\u5dee\u6d88\u9664\uff0c\u6709\u9009\u62e9\u6027\u5730\u5904\u7406\u654f\u611f\u5c5e\u6027\u5f71\u54cd\u3002"}}
{"id": "2508.19477", "pdf": "https://arxiv.org/pdf/2508.19477", "abs": "https://arxiv.org/abs/2508.19477", "authors": ["Zachary L. Crang", "Rich D. Johnston", "Katie L. Mills", "Johsan Billingham", "Sam Robertson", "Michael H. Cole", "Jonathon Weakley", "Adam Hewitt and", "Grant M. Duthie"], "title": "Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This study aimed to: (1) understand whether commercially available\ncomputer-vision and artificial intelligence (AI) player tracking software can\naccurately measure player position, speed and distance using broadcast footage\nand (2) determine the impact of camera feed and resolution on accuracy. Data\nwere obtained from one match at the 2022 Qatar Federation Internationale de\nFootball Association (FIFA) World Cup. Tactical, programme and camera 1 feeds\nwere used. Three commercial tracking providers that use computer-vision and AI\nparticipated. Providers analysed instantaneous position (x, y coordinates) and\nspeed (m\\,s^{-1}) of each player. Their data were compared with a\nhigh-definition multi-camera tracking system (TRACAB Gen 5). Root mean square\nerror (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to\n16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\\,s^{-1}. Total match\ndistance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across\nproviders. Computer-vision and AI player tracking software offer the ability to\ntrack players with fair precision when players are detected by the software.\nProviders should use a tactical feed when tracking position and speed, which\nwill maximise player detection, improving accuracy. Both 720p and 1080p\nresolutions are suitable, assuming appropriate computer-vision and AI models\nare implemented.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u5546\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u548cAI\u7403\u5458\u8ddf\u8e2a\u8f6f\u4ef6\u5229\u7528\u8f6c\u64ad\u955c\u5934\u6d4b\u91cf\u7403\u5458\u4f4d\u7f6e\u3001\u901f\u5ea6\u548c\u8ddd\u79bb\u7684\u51c6\u786e\u6027\uff0c\u53ca\u76f8\u673a\u6e90\u548c\u5206\u8fa8\u7387\u7684\u5f71\u54cd\uff0c\u5f97\u51fa\u4e00\u5b9a\u7ed3\u8bba\u3002", "motivation": "\u4e86\u89e3\u5546\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u548cAI\u7403\u5458\u8ddf\u8e2a\u8f6f\u4ef6\u80fd\u5426\u7528\u8f6c\u64ad\u955c\u5934\u51c6\u786e\u6d4b\u91cf\u7403\u5458\u4f4d\u7f6e\u3001\u901f\u5ea6\u548c\u8ddd\u79bb\uff0c\u4ee5\u53ca\u76f8\u673a\u6e90\u548c\u5206\u8fa8\u7387\u5bf9\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "method": "\u4ece2022\u5361\u5854\u5c14\u4e16\u754c\u676f\u4e00\u573a\u6bd4\u8d5b\u83b7\u53d6\u6570\u636e\uff0c\u4f7f\u7528\u4e09\u79cd\u76f8\u673a\u6e90\uff0c\u8ba9\u4e09\u5bb6\u63d0\u4f9b\u5546\u5206\u6790\u7403\u5458\u4f4d\u7f6e\u548c\u901f\u5ea6\uff0c\u4e0e\u9ad8\u7cbe\u5ea6\u591a\u76f8\u673a\u8ddf\u8e2a\u7cfb\u7edf\u5bf9\u6bd4\uff0c\u8ba1\u7b97RMSE\u548c\u5e73\u5747\u504f\u5dee\u3002", "result": "\u4f4d\u7f6eRMSE\u4e3a1.68 - 16.39\u7c73\uff0c\u901f\u5ea6RMSE\u4e3a0.34 - 2.38\u7c73/\u79d2\uff0c\u603b\u6bd4\u8d5b\u8ddd\u79bb\u5e73\u5747\u504f\u5dee\u5728 -1745\u7c73(-21.8%)\u52301945\u7c73(24.3%)\u4e4b\u95f4\u3002", "conclusion": "\u8f6f\u4ef6\u68c0\u6d4b\u5230\u7403\u5458\u65f6\u80fd\u8f83\u7cbe\u786e\u8ddf\u8e2a\uff0c\u8ddf\u8e2a\u4f4d\u7f6e\u548c\u901f\u5ea6\u5e94\u4f7f\u7528\u6218\u672f\u6e90\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\uff0c720p\u548c1080p\u5206\u8fa8\u7387\u5728\u5408\u9002\u6a21\u578b\u4e0b\u9002\u7528\u3002"}}
{"id": "2508.20024", "pdf": "https://arxiv.org/pdf/2508.20024", "abs": "https://arxiv.org/abs/2508.20024", "authors": ["Deddy Jobson", "Muktti Shukla", "Phuong Dinh", "Julio Christian Young", "Nick Pitton", "Nina Chen", "Ryan Ginstrom"], "title": "Using item recommendations and LLMs in marketing email titles", "categories": ["cs.LG"], "comment": "Accepted to The Second Workshop on Generative AI for E-commerce\n  (GenAIECommerce '25), held September 22, 2025, in Prague, Czech Republic. 3\n  figures", "summary": "E-commerce marketplaces make use of a number of marketing channels like\nemails, push notifications, etc. to reach their users and stimulate purchases.\nPersonalized emails especially are a popular touch point for marketers to\ninform users of latest items in stock, especially for those who stopped\nvisiting the marketplace. Such emails contain personalized recommendations\ntailored to each user's interests, enticing users to buy relevant items. A\ncommon limitation of these emails is that the primary entry point, the title of\nthe email, tends to follow fixed templates, failing to inspire enough interest\nin the contents. In this work, we explore the potential of large language\nmodels (LLMs) for generating thematic titles that reflect the personalized\ncontent of the emails. We perform offline simulations and conduct online\nexperiments on the order of millions of users, finding our techniques useful in\nimproving the engagement between customers and our emails. We highlight key\nfindings and learnings as we productionize the safe and automated generation of\nemail titles for millions of users.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u7535\u5546\u4e2a\u6027\u5316\u90ae\u4ef6\u751f\u6210\u4e3b\u9898\u6807\u9898\uff0c\u7ecf\u6a21\u62df\u548c\u5b9e\u9a8c\u8bc1\u660e\u6280\u672f\u6709\u6548\u3002", "motivation": "\u7535\u5546\u4e2a\u6027\u5316\u90ae\u4ef6\u6807\u9898\u591a\u91c7\u7528\u56fa\u5b9a\u6a21\u677f\uff0c\u96be\u4ee5\u6fc0\u53d1\u7528\u6237\u5bf9\u5185\u5bb9\u7684\u5174\u8da3\uff0c\u9700\u66f4\u597d\u7684\u6807\u9898\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53cd\u6620\u90ae\u4ef6\u4e2a\u6027\u5316\u5185\u5bb9\u7684\u4e3b\u9898\u6807\u9898\uff0c\u8fdb\u884c\u79bb\u7ebf\u6a21\u62df\u548c\u6570\u767e\u4e07\u7528\u6237\u89c4\u6a21\u7684\u5728\u7ebf\u5b9e\u9a8c\u3002", "result": "\u6280\u672f\u6709\u52a9\u4e8e\u63d0\u9ad8\u5ba2\u6237\u4e0e\u90ae\u4ef6\u7684\u4e92\u52a8\u3002", "conclusion": "\u603b\u7ed3\u4e86\u4e3a\u6570\u767e\u4e07\u7528\u6237\u5b89\u5168\u81ea\u52a8\u751f\u6210\u90ae\u4ef6\u6807\u9898\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u53d1\u73b0\u548c\u7ecf\u9a8c\u3002"}}
{"id": "2508.19481", "pdf": "https://arxiv.org/pdf/2508.19481", "abs": "https://arxiv.org/abs/2508.19481", "authors": ["Manuel Mosquera", "Melissa Robles", "Johan Rodriguez", "Ruben Manrique"], "title": "Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Low-resource machine translation remains a significant challenge for large\nlanguage models (LLMs), which often lack exposure to these languages during\npretraining and have limited parallel data for fine-tuning. We propose a novel\napproach that enhances translation for low-resource languages by integrating an\nexternal dictionary tool and training models end-to-end using reinforcement\nlearning, in addition to supervised fine-tuning. Focusing on the\nSpanish-Wayuunaiki language pair, we frame translation as a tool-augmented\ndecision-making problem in which the model can selectively consult a bilingual\ndictionary during generation. Our method combines supervised instruction tuning\nwith Guided Reward Policy Optimization (GRPO), enabling the model to learn both\nwhen and how to use the tool effectively. BLEU similarity scores are used as\nrewards to guide this learning process. Preliminary results show that our\ntool-augmented models achieve up to +3.37 BLEU improvement over previous work,\nand a 18% relative gain compared to a supervised baseline without dictionary\naccess, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared\nTask. We also conduct ablation studies to assess the effects of model\narchitecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other\nmodels such as LLaMA and a prior NLLB-based system. These findings highlight\nthe promise of combining LLMs with external tools and the role of reinforcement\nlearning in improving translation quality in low-resource language settings.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5916\u90e8\u8bcd\u5178\u5de5\u5177\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u7684\u65b9\u6cd5\uff0c\u5728\u897f\u8bed - \u74e6\u5c24\u7eb3\u4f0a\u57fa\u8bed\u5bf9\u4e0a\u6709BLEU\u63d0\u5347\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u4e0a\u6709\u6311\u6218\uff0c\u9884\u8bad\u7ec3\u7f3a\u76f8\u5173\u8bed\u8a00\u4e14\u5fae\u8c03\u5e73\u884c\u6570\u636e\u6709\u9650\u3002", "method": "\u5c06\u7ffb\u8bd1\u89c6\u4e3a\u5de5\u5177\u589e\u5f3a\u51b3\u7b56\u95ee\u9898\uff0c\u7ed3\u5408\u76d1\u7763\u6307\u4ee4\u5fae\u8c03\u4e0eGRPO\uff0c\u7528BLEU\u5206\u6570\u4f5c\u5956\u52b1\u3002", "result": "\u5de5\u5177\u589e\u5f3a\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u6bd4\u4e4b\u524d\u5de5\u4f5cBLEU\u63d0\u53473.37\uff0c\u6bd4\u65e0\u8bcd\u5178\u76d1\u7763\u57fa\u7ebf\u76f8\u5bf9\u589e\u76ca18%\uff0c\u8fd8\u8fdb\u884c\u6d88\u878d\u7814\u7a76\u3002", "conclusion": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u5de5\u5177\u53ca\u5f3a\u5316\u5b66\u4e60\u5bf9\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u8d28\u91cf\u6709\u524d\u666f\u3002"}}
{"id": "2508.20032", "pdf": "https://arxiv.org/pdf/2508.20032", "abs": "https://arxiv.org/abs/2508.20032", "authors": ["Santosh Chapagain", "Shah Muhammad Hamdi", "Soukaina Filali Boubrahimi"], "title": "Pruning Strategies for Backdoor Defense in LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted in CIKM '25: The 34th ACM International Conference on\n  Information and Knowledge Management Proceedings", "summary": "Backdoor attacks are a significant threat to the performance and integrity of\npre-trained language models. Although such models are routinely fine-tuned for\ndownstream NLP tasks, recent work shows they remain vulnerable to backdoor\nattacks that survive vanilla fine-tuning. These attacks are difficult to defend\nbecause end users typically lack knowledge of the attack triggers. Such attacks\nconsist of stealthy malicious triggers introduced through subtle syntactic or\nstylistic manipulations, which can bypass traditional detection and remain in\nthe model, making post-hoc purification essential. In this study, we explore\nwhether attention-head pruning can mitigate these threats without any knowledge\nof the trigger or access to a clean reference model. To this end, we design and\nimplement six pruning-based strategies: (i) gradient-based pruning, (ii)\nlayer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2\nsparsification, (iv) randomized ensemble pruning, (v)\nreinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.\nEach method iteratively removes the least informative heads while monitoring\nvalidation accuracy to avoid over-pruning. Experimental evaluation shows that\ngradient-based pruning performs best while defending the syntactic triggers,\nwhereas reinforcement learning and Bayesian pruning better withstand stylistic\nattacks.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u6ce8\u610f\u529b\u5934\u526a\u679d\u80fd\u5426\u5728\u65e0\u89e6\u53d1\u77e5\u8bc6\u548c\u5e72\u51c0\u53c2\u8003\u6a21\u578b\u4e0b\u7f13\u89e3\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u540e\u95e8\u653b\u51fb\u5a01\u80c1\uff0c\u8bbe\u8ba1\u516d\u79cd\u526a\u679d\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u4e0d\u540c\u7b56\u7565\u5bf9\u4e0d\u540c\u7c7b\u578b\u653b\u51fb\u6548\u679c\u4e0d\u540c\u3002", "motivation": "\u540e\u95e8\u653b\u51fb\u5a01\u80c1\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u548c\u5b8c\u6574\u6027\uff0c\u4e14\u96be\u4ee5\u9632\u5fa1\uff0c\u9700\u540e\u5904\u7406\u51c0\u5316\uff0c\u7814\u7a76\u6ce8\u610f\u529b\u5934\u526a\u679d\u7f13\u89e3\u5a01\u80c1\u7684\u53ef\u884c\u6027\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u65bd\u516d\u79cd\u57fa\u4e8e\u526a\u679d\u7684\u7b56\u7565\uff0c\u5305\u62ec\u68af\u5ea6\u526a\u679d\u3001\u5c42\u65b9\u5dee\u526a\u679d\u7b49\uff0c\u8fed\u4ee3\u79fb\u9664\u6700\u4e0d\u91cd\u8981\u5934\u5e76\u76d1\u63a7\u9a8c\u8bc1\u51c6\u786e\u7387\u3002", "result": "\u68af\u5ea6\u526a\u679d\u5728\u9632\u5fa1\u53e5\u6cd5\u89e6\u53d1\u653b\u51fb\u65f6\u8868\u73b0\u6700\u4f73\uff0c\u5f3a\u5316\u5b66\u4e60\u548c\u8d1d\u53f6\u65af\u526a\u679d\u66f4\u80fd\u62b5\u5fa1\u98ce\u683c\u5316\u653b\u51fb\u3002", "conclusion": "\u6ce8\u610f\u529b\u5934\u526a\u679d\u53ef\u5728\u65e0\u89e6\u53d1\u77e5\u8bc6\u548c\u5e72\u51c0\u53c2\u8003\u6a21\u578b\u4e0b\u7f13\u89e3\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u540e\u95e8\u653b\u51fb\u5a01\u80c1\uff0c\u4e0d\u540c\u526a\u679d\u7b56\u7565\u5bf9\u4e0d\u540c\u7c7b\u578b\u653b\u51fb\u6548\u679c\u6709\u5dee\u5f02\u3002"}}
{"id": "2508.20056", "pdf": "https://arxiv.org/pdf/2508.20056", "abs": "https://arxiv.org/abs/2508.20056", "authors": ["Vil\u00e9m Heinz", "Petr Vil\u00edm", "Zden\u011bk Hanz\u00e1lek"], "title": "Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks", "categories": ["cs.LG", "90-08, 90B35, 90C59, 90C99, 68T20, 90C27"], "comment": null, "summary": "Failure-Directed Search (FDS) is a significant complete generic search\nalgorithm used in Constraint Programming (CP) to efficiently explore the search\nspace, proven particularly effective on scheduling problems. This paper\nanalyzes FDS's properties, showing that minimizing the size of its search tree\nguided by ranked branching decisions is closely related to the Multi-armed\nbandit (MAB) problem. Building on this insight, MAB reinforcement learning\nalgorithms are applied to FDS, extended with problem-specific refinements and\nparameter tuning, and evaluated on the two most fundamental scheduling\nproblems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained\nProject Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best\nextended MAB algorithm and configuration, performs 1.7 times faster on the JSSP\nand 2.1 times faster on the RCPSP benchmarks compared to the original\nimplementation in a new solver called OptalCP, while also being 3.5 times\nfaster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the\ncurrent state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,\nusing only a 900-second time limit per instance, the enhanced FDS improved the\nexisting state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP\nstandard open benchmark instances while also completely closing a few of them.", "AI": {"tldr": "\u672c\u6587\u5206\u6790FDS\u6027\u8d28\uff0c\u5c06MAB\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5e94\u7528\u4e8eFDS\u5e76\u6539\u8fdb\u8c03\u53c2\uff0c\u5728JSSP\u548cRCPSP\u95ee\u9898\u4e0a\u8bc4\u4f30\uff0c\u589e\u5f3a\u7248FDS\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u8fd8\u6539\u8fdb\u4e86\u90e8\u5206\u57fa\u51c6\u5b9e\u4f8b\u7684\u4e0b\u754c\u3002", "motivation": "\u63a2\u7d22\u63d0\u5347Failure - Directed Search (FDS)\u7b97\u6cd5\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u5728\u8c03\u5ea6\u95ee\u9898\u4e0a\u6709\u66f4\u597d\u8868\u73b0\u3002", "method": "\u5206\u6790FDS\u6027\u8d28\uff0c\u53d1\u73b0\u5176\u4e0e\u591a\u81c2\u8001\u864e\u673a\uff08MAB\uff09\u95ee\u9898\u76f8\u5173\uff0c\u5c06MAB\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5e94\u7528\u4e8eFDS\uff0c\u8fdb\u884c\u7279\u5b9a\u95ee\u9898\u6539\u8fdb\u548c\u53c2\u6570\u8c03\u4f18\u3002", "result": "\u589e\u5f3a\u7248FDS\u5728JSSP\u548cRCPSP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u539f\u5b9e\u73b0\u548c\u5f53\u524d\u6700\u5148\u8fdb\u7684FDS\u7b97\u6cd5\u66f4\u5feb\uff0c\u8fd8\u6539\u8fdb\u4e86\u90e8\u5206\u6807\u51c6\u5f00\u653e\u57fa\u51c6\u5b9e\u4f8b\u7684\u4e0b\u754c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165MAB\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6539\u8fdb\u7684FDS\u80fd\u6709\u6548\u63d0\u5347\u7b97\u6cd5\u6548\u7387\uff0c\u5728\u8c03\u5ea6\u95ee\u9898\u4e0a\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2508.11692", "pdf": "https://arxiv.org/pdf/2508.11692", "abs": "https://arxiv.org/abs/2508.11692", "authors": ["Eduardo Di Santi", "Ruixiang Ci", "Cl\u00e9ment Lefebvre", "Nenad Mijatovic", "Michele Pugnaloni", "Jonathan Brown", "Victor Mart\u00edn", "Kenza Saiah"], "title": "Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning", "categories": ["eess.SP", "cs.AI", "cs.LG", "68T07, 68T05", "I.2.6; I.5.1; I.5.4"], "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025, Dresden,\n  Germany. Conference: https://tu-dresden.de/raildresden2025. Book of\n  abstracts: https://tu-dresden.de/raildresden2025/BoA.pdf. 8 pages, 6 figures,\n  1 table", "summary": "The Point Machine (PM) is a critical piece of railway equipment that switches\ntrain routes by diverting tracks through a switchblade. As with any critical\nsafety equipment, a failure will halt operations leading to service\ndisruptions; therefore, pre-emptive maintenance may avoid unnecessary\ninterruptions by detecting anomalies before they become failures. Previous work\nrelies on several inputs and crafting custom features by segmenting the signal.\nThis not only adds additional requirements for data collection and processing,\nbut it is also specific to the PM technology, the installed locations and\noperational conditions limiting scalability. Based on the available maintenance\nrecords, the main failure causes for PM are obstacles, friction, power source\nissues and misalignment. Those failures affect the energy consumption pattern\nof PMs, altering the usual (or healthy) shape of the power signal during the PM\nmovement. In contrast to the current state-of-the-art, our method requires only\none input. We apply a deep learning model to the power signal pattern to\nclassify if the PM is nominal or associated with any failure type, achieving\n>99.99\\% precision, <0.01\\% false positives and negligible false negatives. Our\nmethodology is generic and technology-agnostic, proven to be scalable on\nseveral electromechanical PM types deployed in both real-world and test bench\nenvironments. Finally, by using conformal prediction the maintainer gets a\nclear indication of the certainty of the system outputs, adding a confidence\nlayer to operations and making the method compliant with the ISO-17359\nstandard.", "AI": {"tldr": "\u63d0\u51fa\u4ec5\u9700\u5355\u8f93\u5165\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5bf9\u9053\u5c94\u673a\u6545\u969c\u5206\u7c7b\uff0c\u7cbe\u5ea6\u8d8599.99%\uff0c\u5177\u6709\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u8fd8\u7b26\u5408ISO - 17359\u6807\u51c6\u3002", "motivation": "\u73b0\u6709\u9053\u5c94\u673a\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u591a\u8f93\u5165\u548c\u5b9a\u5236\u7279\u5f81\uff0c\u6709\u6570\u636e\u6536\u96c6\u548c\u5904\u7406\u8981\u6c42\u4e14\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\uff0c\u9700\u4e00\u79cd\u66f4\u4f18\u65b9\u6cd5\u907f\u514d\u6545\u969c\u5bfc\u81f4\u7684\u8fd0\u8425\u4e2d\u65ad\u3002", "method": "\u5bf9\u9053\u5c94\u673a\u529f\u7387\u4fe1\u53f7\u6a21\u5f0f\u5e94\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u6545\u969c\u5206\u7c7b\uff0c\u8fd8\u4f7f\u7528\u5171\u5f62\u9884\u6d4b\u589e\u52a0\u8f93\u51fa\u786e\u5b9a\u6027\u3002", "result": "\u5b9e\u73b0\u8d8599.99%\u7684\u7cbe\u5ea6\u3001<0.01%\u7684\u8bef\u62a5\u7387\u548c\u6781\u4f4e\u7684\u6f0f\u62a5\u7387\uff0c\u65b9\u6cd5\u5728\u591a\u79cd\u9053\u5c94\u673a\u4e0a\u53ef\u6269\u5c55\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4ec5\u9700\u5355\u8f93\u5165\uff0c\u5177\u6709\u901a\u7528\u6027\u3001\u53ef\u6269\u5c55\u6027\uff0c\u7b26\u5408ISO - 17359\u6807\u51c6\uff0c\u80fd\u4e3a\u7ef4\u62a4\u4eba\u5458\u63d0\u4f9b\u53ef\u9760\u6545\u969c\u5206\u7c7b\u3002"}}
{"id": "2508.19499", "pdf": "https://arxiv.org/pdf/2508.19499", "abs": "https://arxiv.org/abs/2508.19499", "authors": ["Xiangxu Wang", "Tianhong Zhao", "Wei Tu", "Bowen Zhang", "Guanzhou Chen", "Jinzhou Cao"], "title": "Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Origin-Destination (OD) flow matrices are essential for urban mobility\nanalysis, underpinning applications in traffic forecasting, infrastructure\nplanning, and policy design. However, existing methods suffer from two critical\nlimitations: (1) reliance on auxiliary features (e.g., Points of Interest,\nsocioeconomic statistics) that are costly to collect and have limited spatial\ncoverage; and (2) sensitivity to spatial topology, where minor index reordering\nof urban regions (e.g., census tract relabeling) disrupts structural coherence\nin generated flows. To address these challenges, we propose Sat2Flow, a latent\nstructure-aware diffusion-based framework that generates structurally coherent\nOD flows using solely satellite imagery as input. Our approach introduces a\nmulti-kernel encoder to capture diverse regional interactions and employs a\npermutation-aware diffusion process that aligns latent representations across\ndifferent regional orderings. Through a joint contrastive training objective\nthat bridges satellite-derived features with OD patterns, combined with\nequivariant diffusion training that enforces structural consistency, Sat2Flow\nensures topological robustness under arbitrary regional reindexing.\nExperimental results on real-world urban datasets demonstrate that Sat2Flow\noutperforms both physics-based and data-driven baselines in numerical accuracy\nwhile preserving empirical distributions and spatial structures under index\npermutations. Sat2Flow offers a globally scalable solution for OD flow\ngeneration in data-scarce urban environments, eliminating region-specific\nauxiliary data dependencies while maintaining structural invariance for robust\nmobility modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSat2Flow\u6846\u67b6\uff0c\u4ec5\u7528\u536b\u661f\u56fe\u50cf\u751f\u6210OD\u6d41\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u8f85\u52a9\u7279\u5f81\u548c\u5bf9\u7a7a\u95f4\u62d3\u6251\u654f\u611f\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u751f\u6210OD\u6d41\u77e9\u9635\u7684\u65b9\u6cd5\u5b58\u5728\u4f9d\u8d56\u6602\u8d35\u4e14\u7a7a\u95f4\u8986\u76d6\u6709\u9650\u7684\u8f85\u52a9\u7279\u5f81\uff0c\u4ee5\u53ca\u5bf9\u7a7a\u95f4\u62d3\u6251\u654f\u611f\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faSat2Flow\u6846\u67b6\uff0c\u5f15\u5165\u591a\u6838\u7f16\u7801\u5668\uff0c\u91c7\u7528\u7f6e\u6362\u611f\u77e5\u6269\u6563\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8054\u5408\u5bf9\u6bd4\u8bad\u7ec3\u76ee\u6807\u548c\u7b49\u53d8\u6269\u6563\u8bad\u7ec3\u786e\u4fdd\u62d3\u6251\u9c81\u68d2\u6027\u3002", "result": "\u5728\u771f\u5b9e\u57ce\u5e02\u6570\u636e\u96c6\u4e0a\uff0cSat2Flow\u5728\u6570\u503c\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u7269\u7406\u548c\u6570\u636e\u9a71\u52a8\u7684\u57fa\u7ebf\uff0c\u80fd\u4fdd\u7559\u7ecf\u9a8c\u5206\u5e03\u548c\u7a7a\u95f4\u7ed3\u6784\u3002", "conclusion": "Sat2Flow\u4e3a\u6570\u636e\u7a00\u7f3a\u57ce\u5e02\u73af\u5883\u4e2d\u7684OD\u6d41\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u6d88\u9664\u5bf9\u7279\u5b9a\u533a\u57df\u8f85\u52a9\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u4fdd\u6301\u7ed3\u6784\u4e0d\u53d8\u6027\u4ee5\u8fdb\u884c\u7a33\u5065\u7684\u79fb\u52a8\u6027\u5efa\u6a21\u3002"}}
{"id": "2508.19500", "pdf": "https://arxiv.org/pdf/2508.19500", "abs": "https://arxiv.org/abs/2508.19500", "authors": ["David Noever"], "title": "Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper identifies and analyzes a novel vulnerability class in Model\nContext Protocol (MCP) based agent systems. The attack chain describes and\ndemonstrates how benign, individually authorized tasks can be orchestrated to\nproduce harmful emergent behaviors. Through systematic analysis using the MITRE\nATLAS framework, we demonstrate how 95 agents tested with access to multiple\nservices-including browser automation, financial analysis, location tracking,\nand code deployment-can chain legitimate operations into sophisticated attack\nsequences that extend beyond the security boundaries of any individual service.\nThese red team exercises survey whether current MCP architectures lack\ncross-domain security measures necessary to detect or prevent a large category\nof compositional attacks. We present empirical evidence of specific attack\nchains that achieve targeted harm through service orchestration, including data\nexfiltration, financial manipulation, and infrastructure compromise. These\nfindings reveal that the fundamental security assumption of service isolation\nfails when agents can coordinate actions across multiple domains, creating an\nexponential attack surface that grows with each additional capability. This\nresearch provides a barebones experimental framework that evaluate not whether\nagents can complete MCP benchmark tasks, but what happens when they complete\nthem too well and optimize across multiple services in ways that violate human\nexpectations and safety constraints. We propose three concrete experimental\ndirections using the existing MCP benchmark suite.", "AI": {"tldr": "\u672c\u6587\u8bc6\u522b\u5e76\u5206\u6790\u57fa\u4e8eMCP\u7684\u4ee3\u7406\u7cfb\u7edf\u7684\u65b0\u6f0f\u6d1e\u7c7b\uff0c\u63ed\u793a\u8de8\u57df\u534f\u8c03\u884c\u52a8\u4ea7\u751f\u7684\u653b\u51fb\u98ce\u9669\uff0c\u63d0\u51fa\u5b9e\u9a8c\u65b9\u5411\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8eMCP\u7684\u4ee3\u7406\u7cfb\u7edf\u662f\u5426\u7f3a\u4e4f\u8de8\u57df\u5b89\u5168\u63aa\u65bd\u4ee5\u68c0\u6d4b\u6216\u9632\u6b62\u7ec4\u5408\u653b\u51fb\u3002", "method": "\u4f7f\u7528MITRE ATLAS\u6846\u67b6\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u5f00\u5c55\u7ea2\u961f\u6f14\u7ec3\u3002", "result": "\u53d1\u73b0\u53ef\u5c06\u5408\u6cd5\u64cd\u4f5c\u4e32\u8054\u6210\u590d\u6742\u653b\u51fb\u5e8f\u5217\uff0c\u6709\u6570\u636e\u6cc4\u9732\u3001\u91d1\u878d\u64cd\u7eb5\u7b49\u653b\u51fb\u94fe\uff0c\u670d\u52a1\u9694\u79bb\u5047\u8bbe\u5931\u6548\u3002", "conclusion": "\u63d0\u51fa\u4e09\u4e2a\u57fa\u4e8e\u73b0\u6709MCP\u57fa\u51c6\u5957\u4ef6\u7684\u5b9e\u9a8c\u65b9\u5411\u3002"}}
{"id": "2508.19295", "pdf": "https://arxiv.org/pdf/2508.19295", "abs": "https://arxiv.org/abs/2508.19295", "authors": ["Sauptik Dhar", "Nicholas Buoncristiani", "Joe Anakata", "Haoyu Zhang", "Michelle Munson"], "title": "Large VLM-based Stylized Sports Captioning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The advent of large (visual) language models (LLM / LVLM) have led to a\ndeluge of automated human-like systems in several domains including social\nmedia content generation, search and recommendation, healthcare prognosis, AI\nassistants for cognitive tasks etc. Although these systems have been\nsuccessfully integrated in production; very little focus has been placed on\nsports, particularly accurate identification and natural language description\nof the game play. Most existing LLM/LVLMs can explain generic sports\nactivities, but lack sufficient domain-centric sports' jargon to create natural\n(human-like) descriptions. This work highlights the limitations of existing\nSoTA LLM/LVLMs for generating production-grade sports captions from images in a\ndesired stylized format, and proposes a two-level fine-tuned LVLM pipeline to\naddress that. The proposed pipeline yields an improvement > 8-10% in the F1,\nand > 2-10% in BERT score compared to alternative approaches. In addition, it\nhas a small runtime memory footprint and fast execution time. During Super Bowl\nLIX the pipeline proved its practical application for live professional sports\njournalism; generating highly accurate and stylized captions at the rate of 6\nimages per 3-5 seconds for over 1000 images during the game play.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f53\u80b2\u9886\u57df\u751f\u6210\u9ad8\u8d28\u91cf\u89e3\u8bf4\u5b58\u5728\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51fa\u4e24\u7ea7\u5fae\u8c03LVLM\u7ba1\u9053\uff0c\u63d0\u5347\u4e86\u6307\u6807\uff0c\u5728\u8d85\u7ea7\u7897\u6709\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f53\u80b2\u9886\u57df\uff0c\u5c24\u5176\u662f\u51c6\u786e\u8bc6\u522b\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6bd4\u8d5b\u65b9\u9762\u5173\u6ce8\u8f83\u5c11\uff0c\u73b0\u6709\u6a21\u578b\u7f3a\u4e4f\u9886\u57df\u4e13\u4e1a\u672f\u8bed\uff0c\u96be\u4ee5\u751f\u6210\u7406\u60f3\u7684\u4f53\u80b2\u89e3\u8bf4\u3002", "method": "\u63d0\u51fa\u4e24\u7ea7\u5fae\u8c03\u7684LVLM\u7ba1\u9053\u3002", "result": "\u76f8\u6bd4\u5176\u4ed6\u65b9\u6cd5\uff0cF1\u6307\u6807\u63d0\u5347\u8d858 - 10%\uff0cBERT\u5206\u6570\u63d0\u5347\u8d852 - 10%\uff0c\u5185\u5b58\u5360\u7528\u5c0f\u3001\u6267\u884c\u901f\u5ea6\u5feb\uff0c\u5728\u8d85\u7ea7\u7897LIX\u4e2d\u80fd\u9ad8\u6548\u751f\u6210\u51c6\u786e\u4e14\u98ce\u683c\u5316\u7684\u89e3\u8bf4\u3002", "conclusion": "\u6240\u63d0\u4e24\u7ea7\u5fae\u8c03LVLM\u7ba1\u9053\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f53\u80b2\u56fe\u50cf\u89e3\u8bf4\u751f\u6210\u65b9\u9762\u7684\u95ee\u9898\uff0c\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.19517", "pdf": "https://arxiv.org/pdf/2508.19517", "abs": "https://arxiv.org/abs/2508.19517", "authors": ["Srishti Palani", "Gonzalo Ramos"], "title": "Orchid: Orchestrating Context Across Creative Workflows with Generative AI", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Context is critical for meaningful interactions between people and Generative\nAI (GenAI). Yet mainstream tools offer limited means to orchestrate it,\nparticularly across workflows that span multiple interactions, sessions, and\nmodels, as often occurs in creative projects. Re specifying prior details,\njuggling diverse artifacts, and dealing with context drift overwhelm users,\nobscure intent, and curtail creativity. To address these challenges, we present\nOrchid, a system that gives its users affordances to specify, reference, and\nmonitor context throughout evolving workflows. Specifically, Orchid enables\nusers to (1) specify context related to the project, themselves, and different\nstyles, (2) reference these via explicit mentions, inline selection, or\nimplicit grounding, and (3) monitor context assigned to different interactions\nacross the workflow. In a within-subjects study (n=12), participants using\nOrchid to execute creative tasks (compared to a baseline toolkit of web search,\nLLM-based chat, and digital notebooks) produced more novel and feasible\noutcomes, reporting greater alignment between their intent and the AI's\nresponses, higher perceived control, and increased transparency. By\nprioritizing context orchestration, Orchid offers an actionable step toward\nnext generation GenAI tools that support complex, iterative workflows -\nenabling creators and AI to stay aligned and augment their creative potential.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faOrchid\u7cfb\u7edf\u89e3\u51b3\u751f\u6210\u5f0fAI\u4e0a\u4e0b\u6587\u7f16\u6392\u96be\u9898\uff0c\u7814\u7a76\u8868\u660e\u5176\u80fd\u63d0\u5347\u521b\u610f\u4efb\u52a1\u6548\u679c\u3002", "motivation": "\u4e3b\u6d41\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u8de8\u591a\u4ea4\u4e92\u3001\u4f1a\u8bdd\u548c\u6a21\u578b\u7684\u5de5\u4f5c\u6d41\u4e2d\u4e0a\u4e0b\u6587\u7f16\u6392\u80fd\u529b\u6709\u9650\uff0c\u5bfc\u81f4\u7528\u6237\u8d1f\u62c5\u91cd\u3001\u610f\u56fe\u6a21\u7cca\u548c\u521b\u9020\u529b\u53d7\u9650\u3002", "method": "\u63d0\u51faOrchid\u7cfb\u7edf\uff0c\u8ba9\u7528\u6237\u80fd\u6307\u5b9a\u3001\u5f15\u7528\u548c\u76d1\u63a7\u4e0a\u4e0b\u6587\uff1b\u5f00\u5c55\u670912\u540d\u53c2\u4e0e\u8005\u7684\u88ab\u8bd5\u5185\u7814\u7a76\u3002", "result": "\u4f7f\u7528Orchid\u6267\u884c\u521b\u610f\u4efb\u52a1\u7684\u53c2\u4e0e\u8005\u4ea7\u51fa\u66f4\u5177\u65b0\u9896\u6027\u548c\u53ef\u884c\u6027\u7684\u6210\u679c\uff0c\u8ba4\u4e3aAI\u54cd\u5e94\u4e0e\u81ea\u8eab\u610f\u56fe\u66f4\u5951\u5408\uff0c\u611f\u77e5\u63a7\u5236\u611f\u548c\u900f\u660e\u5ea6\u66f4\u9ad8\u3002", "conclusion": "Orchid\u4f18\u5148\u8003\u8651\u4e0a\u4e0b\u6587\u7f16\u6392\uff0c\u4e3a\u652f\u6301\u590d\u6742\u8fed\u4ee3\u5de5\u4f5c\u6d41\u7684\u4e0b\u4e00\u4ee3\u751f\u6210\u5f0fAI\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.19544", "pdf": "https://arxiv.org/pdf/2508.19544", "abs": "https://arxiv.org/abs/2508.19544", "authors": ["Eduardo Davalos", "Yike Zhang", "Namrata Srivastava", "Yashvitha Thatigotla", "Jorge A. Salas", "Sara McFadden", "Sun-Joo Cho", "Amanda Goodwin", "Ashwin TS", "Gautam Biswas"], "title": "WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages, 7 figures, 1 table", "summary": "With advancements in AI, new gaze estimation methods are exceeding\nstate-of-the-art (SOTA) benchmarks, but their real-world application reveals a\ngap with commercial eye-tracking solutions. Factors like model size, inference\ntime, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking\nmethods lack sufficient accuracy, in particular due to head movement. To tackle\nthese issues, we introduce We bEyeTrack, a framework that integrates\nlightweight SOTA gaze estimation models directly in the browser. It\nincorporates model-based head pose estimation and on-device few-shot learning\nwith as few as nine calibration samples (k < 9). WebEyeTrack adapts to new\nusers, achieving SOTA performance with an error margin of 2.32 cm on\nGazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14.\nOur open-source code is available at\nhttps://github.com/RedForestAi/WebEyeTrack.", "AI": {"tldr": "\u63d0\u51faWebEyeTrack\u6846\u67b6\u96c6\u6210\u8f7b\u91cf\u7ea7\u6a21\u578b\u5230\u6d4f\u89c8\u5668\uff0c\u9002\u914d\u65b0\u7528\u6237\uff0c\u53d6\u5f97SOTA\u6027\u80fd\u548c\u5b9e\u65f6\u63a8\u7406\u901f\u5ea6\uff0c\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u65b0\u6ce8\u89c6\u4f30\u8ba1\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e0e\u5546\u4e1a\u773c\u52a8\u8ffd\u8e2a\u65b9\u6848\u6709\u5dee\u8ddd\uff0c\u7f51\u7edc\u6444\u50cf\u5934\u773c\u52a8\u8ffd\u8e2a\u65b9\u6cd5\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u6a21\u578b\u5927\u5c0f\u3001\u63a8\u7406\u65f6\u95f4\u548c\u9690\u79c1\u7b49\u56e0\u7d20\u5e38\u672a\u89e3\u51b3\u3002", "method": "\u5f15\u5165WebEyeTrack\u6846\u67b6\uff0c\u5c06\u8f7b\u91cf\u7ea7SOTA\u6ce8\u89c6\u4f30\u8ba1\u6a21\u578b\u96c6\u6210\u5230\u6d4f\u89c8\u5668\uff0c\u7ed3\u5408\u57fa\u4e8e\u6a21\u578b\u7684\u5934\u90e8\u59ff\u6001\u4f30\u8ba1\u548c\u8bbe\u5907\u7aef\u5c11\u6837\u672c\u5b66\u4e60\uff08\u6821\u51c6\u6837\u672ck < 9\uff09\u3002", "result": "\u5728GazeCapture\u4e0a\u8bef\u5dee\u4e3a2.32 cm\uff0c\u5728iPhone 14\u4e0a\u5b9e\u65f6\u63a8\u7406\u901f\u5ea6\u4e3a2.4\u6beb\u79d2\u3002", "conclusion": "WebEyeTrack\u80fd\u89e3\u51b3\u73b0\u6709\u6ce8\u89c6\u4f30\u8ba1\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u826f\u597d\u6027\u80fd\u548c\u5b9e\u65f6\u63a8\u7406\u3002"}}
{"id": "2508.19546", "pdf": "https://arxiv.org/pdf/2508.19546", "abs": "https://arxiv.org/abs/2508.19546", "authors": ["Jio Choi", "Mohit Bansal", "Elias Stengel-Eskin"], "title": "Language Models Identify Ambiguities and Exploit Loopholes", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025 camera-ready; Code:\n  https://github.com/esteng/ambiguous-loophole-exploitation", "summary": "Studying the responses of large language models (LLMs) to loopholes presents\na two-fold opportunity. First, it affords us a lens through which to examine\nambiguity and pragmatics in LLMs, since exploiting a loophole requires\nidentifying ambiguity and performing sophisticated pragmatic reasoning. Second,\nloopholes pose an interesting and novel alignment problem where the model is\npresented with conflicting goals and can exploit ambiguities to its own\nadvantage. To address these questions, we design scenarios where LLMs are given\na goal and an ambiguous user instruction in conflict with the goal, with\nscenarios covering scalar implicature, structural ambiguities, and power\ndynamics. We then measure different models' abilities to exploit loopholes to\nsatisfy their given goals as opposed to the goals of the user. We find that\nboth closed-source and stronger open-source models can identify ambiguities and\nexploit their resulting loopholes, presenting a potential AI safety risk. Our\nanalysis indicates that models which exploit loopholes explicitly identify and\nreason about both ambiguity and conflicting goals.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6f0f\u6d1e\u7684\u54cd\u5e94\uff0c\u8bbe\u8ba1\u573a\u666f\u6d4b\u8bd5\u6a21\u578b\u5229\u7528\u6f0f\u6d1e\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u5229\u7528\u6f0f\u6d1e\u98ce\u9669\u3002", "motivation": "\u901a\u8fc7\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6f0f\u6d1e\u7684\u54cd\u5e94\uff0c\u8003\u5bdf\u6a21\u578b\u7684\u6a21\u7cca\u6027\u548c\u8bed\u7528\u5b66\uff0c\u89e3\u51b3\u6a21\u578b\u9762\u4e34\u51b2\u7a81\u76ee\u6807\u65f6\u7684\u5bf9\u9f50\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u6a21\u578b\u9762\u4e34\u76ee\u6807\u4e0e\u6a21\u7cca\u7528\u6237\u6307\u4ee4\u51b2\u7a81\u7684\u573a\u666f\uff0c\u6db5\u76d6\u591a\u79cd\u7c7b\u578b\u6b67\u4e49\uff0c\u6d4b\u91cf\u6a21\u578b\u5229\u7528\u6f0f\u6d1e\u6ee1\u8db3\u81ea\u8eab\u76ee\u6807\u7684\u80fd\u529b\u3002", "result": "\u95ed\u6e90\u548c\u66f4\u5f3a\u7684\u5f00\u6e90\u6a21\u578b\u80fd\u8bc6\u522b\u6b67\u4e49\u5e76\u5229\u7528\u6f0f\u6d1e\uff0c\u5b58\u5728\u6f5c\u5728AI\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u5229\u7528\u6f0f\u6d1e\u7684\u6a21\u578b\u4f1a\u660e\u786e\u8bc6\u522b\u548c\u63a8\u7406\u6b67\u4e49\u4e0e\u51b2\u7a81\u76ee\u6807\u3002"}}
{"id": "2508.19393", "pdf": "https://arxiv.org/pdf/2508.19393", "abs": "https://arxiv.org/abs/2508.19393", "authors": ["Phuoc Pham", "Arun Venkitaraman", "Chia-Yu Hsieh", "Andrea Bonetti", "Stefan Uhlich", "Markus Leibl", "Simon Hofmann", "Eisaku Ohbuchi", "Lorenzo Servadei", "Ulf Schlichtmann", "Robert Wille"], "title": "GENIE-ASI: Generative Instruction and Executable Code for Analog Subcircuit Identification", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Analog subcircuit identification is a core task in analog design, essential\nfor simulation, sizing, and layout. Traditional methods often require extensive\nhuman expertise, rule-based encoding, or large labeled datasets. To address\nthese challenges, we propose GENIE-ASI, the first training-free, large language\nmodel (LLM)-based methodology for analog subcircuit identification. GENIE-ASI\noperates in two phases: it first uses in-context learning to derive natural\nlanguage instructions from a few demonstration examples, then translates these\ninto executable Python code to identify subcircuits in unseen SPICE netlists.\nIn addition, to evaluate LLM-based approaches systematically, we introduce a\nnew benchmark composed of operational amplifier netlists (op-amps) that cover a\nwide range of subcircuit variants. Experimental results on the proposed\nbenchmark show that GENIE-ASI matches rule-based performance on simple\nstructures (F1-score = 1.0), remains competitive on moderate abstractions\n(F1-score = 0.81), and shows potential even on complex subcircuits (F1-score =\n0.31). These findings demonstrate that LLMs can serve as adaptable,\ngeneral-purpose tools in analog design automation, opening new research\ndirections for foundation model applications in analog design automation.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6a21\u62df\u5b50\u7535\u8def\u8bc6\u522b\u65b9\u6cd5GENIE - ASI\uff0c\u5f15\u5165\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u8868\u660eLLM\u53ef\u7528\u4e8e\u6a21\u62df\u8bbe\u8ba1\u81ea\u52a8\u5316\u3002", "motivation": "\u4f20\u7edf\u6a21\u62df\u5b50\u7535\u8def\u8bc6\u522b\u65b9\u6cd5\u9700\u5927\u91cf\u4eba\u5de5\u4e13\u4e1a\u77e5\u8bc6\u3001\u57fa\u4e8e\u89c4\u5219\u7f16\u7801\u6216\u5927\u91cf\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u6709\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faGENIE - ASI\uff0c\u5206\u4e24\u9636\u6bb5\uff0c\u5148\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u4ece\u793a\u4f8b\u5f97\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u518d\u8f6c\u4e3aPython\u4ee3\u7801\u8bc6\u522b\u5b50\u7535\u8def\uff1b\u5f15\u5165\u65b0\u7684\u8fd0\u7b97\u653e\u5927\u5668\u7f51\u8868\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5728\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cGENIE - ASI\u5728\u7b80\u5355\u7ed3\u6784F1\u5206\u6570\u4e3a1.0\uff0c\u4e2d\u7b49\u62bd\u8c61\u4e3a0.81\uff0c\u590d\u6742\u5b50\u7535\u8def\u4e3a0.31\u3002", "conclusion": "LLM\u53ef\u4f5c\u4e3a\u6a21\u62df\u8bbe\u8ba1\u81ea\u52a8\u5316\u4e2d\u901a\u7528\u7075\u6d3b\u5de5\u5177\uff0c\u4e3a\u57fa\u7840\u6a21\u578b\u5e94\u7528\u5f00\u8f9f\u65b0\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.19565", "pdf": "https://arxiv.org/pdf/2508.19565", "abs": "https://arxiv.org/abs/2508.19565", "authors": ["Yuhang Zhao", "Zixing Wang"], "title": "FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10; I.5.1"], "comment": "Accepted by PRCV 2025. Project page with code and dataset:\n  https://github.com/AstronZh/Intersection-Flow-5K", "summary": "End-to-end object detectors offer a promising NMS-free paradigm for real-time\napplications, yet their high computational cost remains a significant barrier,\nparticularly for complex scenarios like intersection traffic monitoring. To\naddress this challenge, we propose FlowDet, a high-speed detector featuring a\ndecoupled encoder optimization strategy applied to the DETR architecture.\nSpecifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for\ntraffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to\nmaintain high representational power across extreme scale variations. To\nrigorously evaluate the model's performance in environments with severe\nocclusion and high object density, we collected the Intersection-Flow-5k\ndataset, a new challenging scene for this task. Evaluated on\nIntersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to\nthe strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by\n1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference\nspeed by 16.2%. Our work demonstrates a new path towards building highly\nefficient and accurate detectors for demanding, real-world perception systems.\nThe Intersection-Flow-5k dataset is available at\nhttps://github.com/AstronZh/Intersection-Flow-5K.", "AI": {"tldr": "\u63d0\u51faFlowDet\u63a2\u6d4b\u5668\uff0c\u91c7\u7528\u89e3\u8026\u7f16\u7801\u5668\u4f18\u5316\u7b56\u7565\uff0c\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8fbeSOTA\uff0c\u6548\u7387\u548c\u7cbe\u5ea6\u63d0\u5347\u3002", "motivation": "\u7aef\u5230\u7aef\u76ee\u6807\u68c0\u6d4b\u5668\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5c24\u5176\u5728\u590d\u6742\u573a\u666f\u5982\u4ea4\u53c9\u8def\u53e3\u4ea4\u901a\u76d1\u63a7\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faFlowDet\uff0c\u91c7\u7528\u89e3\u8026\u7f16\u7801\u5668\u4f18\u5316\u7b56\u7565\uff0c\u4f7f\u7528GDU\u8fdb\u884c\u4ea4\u901a\u611f\u77e5\u51e0\u4f55\u5efa\u6a21\uff0cSAA\u6a21\u5757\u5e94\u5bf9\u6781\u7aef\u5c3a\u5ea6\u53d8\u5316\uff0c\u6536\u96c6Intersection - Flow - 5k\u6570\u636e\u96c6\u8bc4\u4f30\u3002", "result": "\u5728Intersection - Flow - 5k\u4e0a\u8fbeSOTA\uff0c\u6bd4RT - DETR\u57fa\u7ebfAP(test)\u63d0\u53471.5%\uff0cAP50(test)\u63d0\u53471.6%\uff0c\u51cf\u5c1163.2% GFLOPs\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u534716.2%\u3002", "conclusion": "\u4e3a\u6784\u5efa\u9ad8\u6548\u51c6\u786e\u7684\u73b0\u5b9e\u611f\u77e5\u7cfb\u7edf\u63a2\u6d4b\u5668\u5f00\u8f9f\u65b0\u8def\u5f84\u3002"}}
{"id": "2508.19437", "pdf": "https://arxiv.org/pdf/2508.19437", "abs": "https://arxiv.org/abs/2508.19437", "authors": ["Alona Sakhnenko", "Christian B. Mendl", "Jeanette M. Lorenz"], "title": "Is data-efficient learning feasible with quantum models?", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "The importance of analyzing nontrivial datasets when testing quantum machine\nlearning (QML) models is becoming increasingly prominent in literature, yet a\ncohesive framework for understanding dataset characteristics remains elusive.\nIn this work, we concentrate on the size of the dataset as an indicator of its\ncomplexity and explores the potential for QML models to demonstrate superior\ndata-efficiency compared to classical models, particularly through the lens of\nquantum kernel methods (QKMs). We provide a method for generating\nsemi-artificial fully classical datasets, on which we show one of the first\nevidence of the existence of classical datasets where QKMs require less data\nduring training. Additionally, our study introduces a new analytical tool to\nthe QML domain, derived for classical kernel methods, which can be aimed at\ninvestigating the classical-quantum gap. Our empirical results reveal that QKMs\ncan achieve low error rates with less training data compared to classical\ncounterparts. Furthermore, our method allows for the generation of datasets\nwith varying properties, facilitating further investigation into the\ncharacteristics of real-world datasets that may be particularly advantageous\nfor QKMs. We also show that the predicted performance from the analytical tool\nwe propose - a generalization metric from classical domain - show great\nalignment empirical evidence, which fills the gap previously existing in the\nfield. We pave a way to a comprehensive exploration of dataset complexities,\nproviding insights into how these complexities influence QML performance\nrelative to traditional methods. This research contributes to a deeper\nunderstanding of the generalization benefits of QKM models and potentially a\nbroader family of QML models, setting the stage for future advancements in the\nfield.", "AI": {"tldr": "\u7814\u7a76\u805a\u7126\u6570\u636e\u96c6\u5927\u5c0f\u4e0eQML\u6a21\u578b\u6570\u636e\u6548\u7387\uff0c\u63d0\u51fa\u534a\u4eba\u5de5\u6570\u636e\u96c6\u751f\u6210\u65b9\u6cd5\u548c\u65b0\u5206\u6790\u5de5\u5177\uff0c\u8bc1\u5b9eQKMs\u8bad\u7ec3\u9700\u6570\u636e\u5c11\u4e14\u5206\u6790\u5de5\u5177\u4e0e\u5b9e\u8bc1\u5951\u5408\u3002", "motivation": "\u7f3a\u4e4f\u7406\u89e3\u6570\u636e\u96c6\u7279\u5f81\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7814\u7a76QML\u6a21\u578b\u5728\u6570\u636e\u96c6\u590d\u6742\u5ea6\u4e0b\u4e0e\u7ecf\u5178\u6a21\u578b\u7684\u6570\u636e\u6548\u7387\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u534a\u4eba\u5de5\u5168\u7ecf\u5178\u6570\u636e\u96c6\u751f\u6210\u65b9\u6cd5\uff0c\u5f15\u5165\u6e90\u4e8e\u7ecf\u5178\u6838\u65b9\u6cd5\u7684\u5206\u6790\u5de5\u5177\u3002", "result": "QKMs\u8bad\u7ec3\u6240\u9700\u6570\u636e\u5c11\u3001\u8bef\u5dee\u7387\u4f4e\uff0c\u5206\u6790\u5de5\u5177\u9884\u6d4b\u4e0e\u5b9e\u8bc1\u76f8\u7b26\uff0c\u53ef\u751f\u6210\u4e0d\u540c\u5c5e\u6027\u6570\u636e\u96c6\u3002", "conclusion": "\u6709\u52a9\u4e8e\u5168\u9762\u63a2\u7d22\u6570\u636e\u96c6\u590d\u6742\u5ea6\uff0c\u52a0\u6df1\u5bf9QKM\u53caQML\u6a21\u578b\u6cdb\u5316\u4f18\u52bf\u7684\u7406\u89e3\uff0c\u4e3a\u9886\u57df\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.19566", "pdf": "https://arxiv.org/pdf/2508.19566", "abs": "https://arxiv.org/abs/2508.19566", "authors": ["Chen Shang", "Jiadong Yu", "Dinh Thai Hoang"], "title": "Energy-Efficient Learning-Based Beamforming for ISAC-Enabled V2X Networks", "categories": ["eess.SP", "cs.AI"], "comment": "6 pages, 4 figures, conference paper", "summary": "This work proposes an energy-efficient, learning-based beamforming scheme for\nintegrated sensing and communication (ISAC)-enabled V2X networks. Specifically,\nwe first model the dynamic and uncertain nature of V2X environments as a Markov\nDecision Process. This formulation allows the roadside unit to generate\nbeamforming decisions based solely on current sensing information, thereby\neliminating the need for frequent pilot transmissions and extensive channel\nstate information acquisition. We then develop a deep reinforcement learning\n(DRL) algorithm to jointly optimize beamforming and power allocation, ensuring\nboth communication throughput and sensing accuracy in highly dynamic scenario.\nTo address the high energy demands of conventional learning-based schemes, we\nembed spiking neural networks (SNNs) into the DRL framework. Leveraging their\nevent-driven and sparsely activated architecture, SNNs significantly enhance\nenergy efficiency while maintaining robust performance. Simulation results\nconfirm that the proposed method achieves substantial energy savings and\nsuperior communication performance, demonstrating its potential to support\ngreen and sustainable connectivity in future V2X systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u8282\u80fd\u6ce2\u675f\u6210\u5f62\u65b9\u6848\u7528\u4e8eISAC - \u4f7f\u80fd\u7684V2X\u7f51\u7edc\uff0c\u7528DRL\u8054\u5408\u4f18\u5316\uff0c\u5d4c\u5165SNN\u63d0\u5347\u80fd\u6548\uff0c\u4eff\u771f\u9a8c\u8bc1\u6548\u679c\u597d\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5b66\u4e60\u65b9\u6848\u80fd\u8017\u9ad8\uff0c\u5b9e\u73b0V2X\u7f51\u7edc\u8282\u80fd\u548c\u9ad8\u6027\u80fd\u901a\u4fe1\u3002", "method": "\u5c06V2X\u73af\u5883\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7528DRL\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u548c\u529f\u7387\u5206\u914d\uff0c\u5d4c\u5165SNN\u5230DRL\u6846\u67b6\u3002", "result": "\u4eff\u771f\u8868\u660e\u8be5\u65b9\u6cd5\u5b9e\u73b0\u5927\u91cf\u8282\u80fd\u548c\u5353\u8d8a\u901a\u4fe1\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6848\u6709\u6f5c\u529b\u652f\u6301\u672a\u6765V2X\u7cfb\u7edf\u7684\u7eff\u8272\u53ef\u6301\u7eed\u8fde\u63a5\u3002"}}
{"id": "2508.19574", "pdf": "https://arxiv.org/pdf/2508.19574", "abs": "https://arxiv.org/abs/2508.19574", "authors": ["Mingxi Fu", "Fanglei Fu", "Xitong Ling", "Huaitian Yuan", "Tian Guan", "Yonghong He", "Lianghui Zhu"], "title": "Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pathological image segmentation faces numerous challenges, particularly due\nto ambiguous semantic boundaries and the high cost of pixel-level annotations.\nAlthough recent semi-supervised methods based on consistency regularization\n(e.g., UniMatch) have made notable progress, they mainly rely on\nperturbation-based consistency within the image modality, making it difficult\nto capture high-level semantic priors, especially in structurally complex\npathology images. To address these limitations, we propose MPAMatch - a novel\nsegmentation framework that performs pixel-level contrastive learning under a\nmultimodal prototype-guided supervision paradigm. The core innovation of\nMPAMatch lies in the dual contrastive learning scheme between image prototypes\nand pixel labels, and between text prototypes and pixel labels, providing\nsupervision at both structural and semantic levels. This coarse-to-fine\nsupervisory strategy not only enhances the discriminative capability on\nunlabeled samples but also introduces the text prototype supervision into\nsegmentation for the first time, significantly improving semantic boundary\nmodeling. In addition, we reconstruct the classic segmentation architecture\n(TransUNet) by replacing its ViT backbone with a pathology-pretrained\nfoundation model (Uni), enabling more effective extraction of\npathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND,\nEBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art\nmethods, validating its dual advantages in structural and semantic modeling.", "AI": {"tldr": "\u63d0\u51fa MPAMatch \u5206\u5272\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u539f\u578b\u76d1\u7763\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u6539\u9020 TransUNet \u67b6\u6784\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u75c5\u7406\u56fe\u50cf\u5206\u5272\u5b58\u5728\u8bed\u4e49\u8fb9\u754c\u6a21\u7cca\u548c\u50cf\u7d20\u7ea7\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u73b0\u6709\u534a\u76d1\u7763\u65b9\u6cd5\u96be\u6355\u6349\u9ad8\u5c42\u8bed\u4e49\u5148\u9a8c\u3002", "method": "\u63d0\u51fa MPAMatch \u6846\u67b6\uff0c\u91c7\u7528\u56fe\u50cf\u548c\u6587\u672c\u539f\u578b\u4e0e\u50cf\u7d20\u6807\u7b7e\u7684\u53cc\u91cd\u5bf9\u6bd4\u5b66\u4e60\uff0c\u7528\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u66ff\u6362 TransUNet \u7684 ViT \u9aa8\u5e72\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e MPAMatch \u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MPAMatch \u5728\u7ed3\u6784\u548c\u8bed\u4e49\u5efa\u6a21\u4e0a\u6709\u53cc\u91cd\u4f18\u52bf\u3002"}}
{"id": "2508.19482", "pdf": "https://arxiv.org/pdf/2508.19482", "abs": "https://arxiv.org/abs/2508.19482", "authors": ["Jaivardhan Kapoor", "Jakob H. Macke", "Christian F. Baumgartner"], "title": "MRExtrap: Longitudinal Aging of Brain MRIs using Linear Modeling in Latent Space", "categories": ["eess.IV", "cs.LG"], "comment": "Preprint", "summary": "Simulating aging in 3D brain MRI scans can reveal disease progression\npatterns in neurological disorders such as Alzheimer's disease. Current deep\nlearning-based generative models typically approach this problem by predicting\nfuture scans from a single observed scan. We investigate modeling brain aging\nvia linear models in the latent space of convolutional autoencoders (MRExtrap).\nOur approach, MRExtrap, is based on our observation that autoencoders trained\non brain MRIs create latent spaces where aging trajectories appear\napproximately linear. We train autoencoders on brain MRIs to create latent\nspaces, and investigate how these latent spaces allow predicting future MRIs\nthrough linear extrapolation based on age, using an estimated latent\nprogression rate $\\boldsymbol{\\beta}$. For single-scan prediction, we propose\nusing population-averaged and subject-specific priors on linear progression\nrates. We also demonstrate that predictions in the presence of additional scans\ncan be flexibly updated using Bayesian posterior sampling, providing a\nmechanism for subject-specific refinement. On the ADNI dataset, MRExtrap\npredicts aging patterns accurately and beats a GAN-based baseline for\nsingle-volume prediction of brain aging. We also demonstrate and analyze\nmulti-scan conditioning to incorporate subject-specific progression rates.\nFinally, we show that the latent progression rates in MRExtrap's linear\nframework correlate with disease and age-based aging patterns from previously\nstudied structural atrophy rates. MRExtrap offers a simple and robust method\nfor the age-based generation of 3D brain MRIs, particularly valuable in\nscenarios with multiple longitudinal observations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMRExtrap\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5377\u79ef\u81ea\u7f16\u7801\u5668\u6f5c\u7a7a\u95f4\u7684\u7ebf\u6027\u6a21\u578b\u6a21\u62df3D\u8111MRI\u626b\u63cf\u8870\u8001\uff0c\u5728ADNI\u6570\u636e\u96c6\u8868\u73b0\u826f\u597d\uff0c\u4e0e\u75be\u75c5\u548c\u8870\u8001\u6a21\u5f0f\u76f8\u5173\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u751f\u6210\u6a21\u578b\u901a\u5e38\u4ece\u5355\u4e2a\u89c2\u5bdf\u626b\u63cf\u9884\u6d4b\u672a\u6765\u626b\u63cf\uff0c\u672c\u6587\u63a2\u7d22\u901a\u8fc7\u5377\u79ef\u81ea\u7f16\u7801\u5668\u6f5c\u7a7a\u95f4\u7684\u7ebf\u6027\u6a21\u578b\u5bf9\u5927\u8111\u8870\u8001\u8fdb\u884c\u5efa\u6a21\u3002", "method": "\u5728\u8111MRI\u4e0a\u8bad\u7ec3\u81ea\u7f16\u7801\u5668\u521b\u5efa\u6f5c\u7a7a\u95f4\uff0c\u901a\u8fc7\u57fa\u4e8e\u5e74\u9f84\u7684\u7ebf\u6027\u5916\u63a8\u9884\u6d4b\u672a\u6765MRI\uff0c\u9488\u5bf9\u5355\u626b\u63cf\u9884\u6d4b\u63d0\u51fa\u4f7f\u7528\u603b\u4f53\u5e73\u5747\u548c\u7279\u5b9a\u4e8e\u53d7\u8bd5\u8005\u7684\u5148\u9a8c\uff0c\u5229\u7528\u8d1d\u53f6\u65af\u540e\u9a8c\u91c7\u6837\u66f4\u65b0\u591a\u626b\u63cf\u9884\u6d4b\u3002", "result": "MRExtrap\u5728ADNI\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u9884\u6d4b\u8870\u8001\u6a21\u5f0f\uff0c\u5355\u4f53\u79ef\u9884\u6d4b\u51fb\u8d25\u57fa\u4e8eGAN\u7684\u57fa\u7ebf\uff0c\u5c55\u793a\u5e76\u5206\u6790\u4e86\u591a\u626b\u63cf\u6761\u4ef6\u5316\u3002", "conclusion": "MRExtrap\u4e3a\u57fa\u4e8e\u5e74\u9f84\u76843D\u8111MRI\u751f\u6210\u63d0\u4f9b\u4e86\u7b80\u5355\u800c\u7a33\u5065\u7684\u65b9\u6cd5\uff0c\u5728\u591a\u7eb5\u5411\u89c2\u5bdf\u573a\u666f\u4e2d\u7279\u522b\u6709\u4ef7\u503c\u3002"}}
{"id": "2508.19575", "pdf": "https://arxiv.org/pdf/2508.19575", "abs": "https://arxiv.org/abs/2508.19575", "authors": ["Zhu Xu", "Zhaowen Wang", "Yuxin Peng", "Yang Liu"], "title": "Interact-Custom: Customized Human Object Interaction Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Compositional Customized Image Generation aims to customize multiple target\nconcepts within generation content, which has gained attention for its wild\napplication.Existing approaches mainly concentrate on the target entity's\nappearance preservation, while neglecting the fine-grained interaction control\namong target entities.To enable the model of such interaction control\ncapability, we focus on human object interaction scenario and propose the task\nof Customized Human Object Interaction Image Generation(CHOI), which\nsimultaneously requires identity preservation for target human object and the\ninteraction semantic control between them.Two primary challenges exist for\nCHOI:(1)simultaneous identity preservation and interaction control demands\nrequire the model to decompose the human object into self-contained identity\nfeatures and pose-oriented interaction features, while the current HOI image\ndatasets fail to provide ideal samples for such feature-decomposed\nlearning.(2)inappropriate spatial configuration between human and object may\nlead to the lack of desired interaction semantics.To tackle it, we first\nprocess a large-scale dataset, where each sample encompasses the same pair of\nhuman object involving different interactive poses.Then we design a two-stage\nmodel Interact-Custom, which firstly explicitly models the spatial\nconfiguration by generating a foreground mask depicting the interaction\nbehavior, then under the guidance of this mask, we generate the target human\nobject interacting while preserving their identities features.Furthermore, if\nthe background image and the union location of where the target human object\nshould appear are provided by users, Interact-Custom also provides the optional\nfunctionality to specify them, offering high content controllability. Extensive\nexperiments on our tailored metrics for CHOI task demonstrate the effectiveness\nof our approach.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u5b9a\u5236\u5316\u4eba\u4f53\u4e0e\u7269\u4f53\u4ea4\u4e92\u56fe\u50cf\u751f\u6210\u4efb\u52a1\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u6a21\u578bInteract - Custom\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u5b9a\u5236\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\u5ffd\u89c6\u76ee\u6807\u5b9e\u4f53\u95f4\u7ec6\u7c92\u5ea6\u4ea4\u4e92\u63a7\u5236\uff0c\u4f5c\u8005\u805a\u7126\u4eba\u4f53\u4e0e\u7269\u4f53\u4ea4\u4e92\u573a\u666f\u63d0\u51faCHOI\u4efb\u52a1\u3002", "method": "\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u4e24\u9636\u6bb5\u6a21\u578bInteract - Custom\uff0c\u5148\u751f\u6210\u524d\u666f\u63a9\u7801\u660e\u786e\u7a7a\u95f4\u914d\u7f6e\uff0c\u518d\u5728\u63a9\u7801\u6307\u5bfc\u4e0b\u751f\u6210\u76ee\u6807\u4eba\u7269\u56fe\u50cf\u5e76\u4fdd\u7559\u8eab\u4efd\u7279\u5f81\uff0c\u8fd8\u53ef\u6839\u636e\u7528\u6237\u63d0\u4f9b\u80cc\u666f\u548c\u4f4d\u7f6e\u8fdb\u884c\u5b9a\u5236\u3002", "result": "\u5728\u9488\u5bf9CHOI\u4efb\u52a1\u5b9a\u5236\u7684\u6307\u6807\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684Interact - Custom\u6a21\u578b\u80fd\u6709\u6548\u5b9e\u73b0\u5b9a\u5236\u5316\u4eba\u4f53\u4e0e\u7269\u4f53\u4ea4\u4e92\u56fe\u50cf\u751f\u6210\uff0c\u5177\u6709\u8f83\u9ad8\u5185\u5bb9\u53ef\u63a7\u6027\u3002"}}
{"id": "2508.19578", "pdf": "https://arxiv.org/pdf/2508.19578", "abs": "https://arxiv.org/abs/2508.19578", "authors": ["Jiaqi Deng", "Yuho Lee", "Nicole Hee-Yeon Kim", "Hyangsuk Min", "Taewon Yun", "Minjeong Ban", "Kim Yul", "Hwanjun Song"], "title": "Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to EMNLP 2025 (Main)", "summary": "We introduce HAMLET, a holistic and automated framework for evaluating the\nlong-context comprehension of large language models (LLMs). HAMLET structures\nsource texts into a three-level key-fact hierarchy at root-, branch-, and\nleaf-levels, and employs query-focused summarization to evaluate how well\nmodels recall and faithfully represent information at each level. To validate\nthe reliability of our fully automated pipeline, we conduct a systematic human\nstudy, showing that our automatic evaluation achieves over 90% agreement with\nexpert human judgments, while reducing the cost by up to 25 times. HAMLET\nreveals that LLMs struggle with fine-grained comprehension, especially at the\nleaf level, and are sensitive to positional effects like the\nlost-in-the-middle. Analytical queries pose greater challenges than narrative\nones, and consistent performance gaps emerge between open-source and\nproprietary models, as well as across model scales. Our code and dataset are\npublicly available at https://github.com/DISL-Lab/HAMLET.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u7684\u6846\u67b6HAMLET\uff0c\u7ecf\u4eba\u5de5\u9a8c\u8bc1\u53ef\u9760\uff0c\u63ed\u793a\u6a21\u578b\u5b58\u5728\u7684\u95ee\u9898\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u516c\u5f00\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002", "method": "\u5c06\u6e90\u6587\u672c\u6784\u5efa\u4e3a\u4e09\u7ea7\u5173\u952e\u4e8b\u5b9e\u5c42\u6b21\u7ed3\u6784\uff0c\u91c7\u7528\u67e5\u8be2\u805a\u7126\u6458\u8981\u65b9\u6cd5\u8bc4\u4f30\u6a21\u578b\uff0c\u8fdb\u884c\u7cfb\u7edf\u7684\u4eba\u5de5\u7814\u7a76\u9a8c\u8bc1\u81ea\u52a8\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "result": "\u81ea\u52a8\u8bc4\u4f30\u4e0e\u4e13\u5bb6\u4eba\u5de5\u5224\u65ad\u7684\u4e00\u81f4\u6027\u8d8590%\uff0c\u6210\u672c\u964d\u4f4e\u8fbe25\u500d\uff1b\u53d1\u73b0\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u7406\u89e3\u4e0a\u6709\u56f0\u96be\uff0c\u5bf9\u4f4d\u7f6e\u6548\u5e94\u654f\u611f\uff0c\u5206\u6790\u6027\u67e5\u8be2\u6311\u6218\u66f4\u5927\uff0c\u4e0d\u540c\u7c7b\u578b\u548c\u89c4\u6a21\u6a21\u578b\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "HAMLET\u662f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u7684\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2508.19498", "pdf": "https://arxiv.org/pdf/2508.19498", "abs": "https://arxiv.org/abs/2508.19498", "authors": ["Yimu Wang", "Weiming Zhuang", "Chen Chen", "Jiabo Huang", "Jingtao Li", "Lingjuan Lyu"], "title": "UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In the era of deep learning, the increasing number of pre-trained models\navailable online presents a wealth of knowledge. These models, developed with\ndiverse architectures and trained on varied datasets for different tasks,\nprovide unique interpretations of the real world. Their collective consensus is\nlikely universal and generalizable to unseen data. However, effectively\nharnessing this collective knowledge poses a fundamental challenge due to the\nheterogeneity of pre-trained models. Existing knowledge integration solutions\ntypically rely on strong assumptions about training data distributions and\nnetwork architectures, limiting them to learning only from specific types of\nmodels and resulting in data and/or inductive biases. In this work, we\nintroduce a novel framework, namely UNIFORM, for knowledge transfer from a\ndiverse set of off-the-shelf models into one student model without such\nconstraints. Specifically, we propose a dedicated voting mechanism to capture\nthe consensus of knowledge both at the logit level -- incorporating teacher\nmodels that are capable of predicting target classes of interest -- and at the\nfeature level, utilizing visual representations learned on arbitrary label\nspaces. Extensive experiments demonstrate that UNIFORM effectively enhances\nunsupervised object recognition performance compared to strong knowledge\ntransfer baselines. Notably, it exhibits remarkable scalability by benefiting\nfrom over one hundred teachers, while existing methods saturate at a much\nsmaller scale.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aUNIFORM\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5c06\u73b0\u6210\u6a21\u578b\u77e5\u8bc6\u8f6c\u79fb\u5230\u5b66\u751f\u6a21\u578b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u65e0\u76d1\u7763\u76ee\u6807\u8bc6\u522b\u6027\u80fd\u4e14\u53ef\u6269\u5c55\u6027\u597d\u3002", "motivation": "\u73b0\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u77e5\u8bc6\u6574\u5408\u65b9\u6848\u53d7\u9650\u4e8e\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u548c\u7f51\u7edc\u67b6\u6784\u5047\u8bbe\uff0c\u5b58\u5728\u6570\u636e\u548c\u5f52\u7eb3\u504f\u5dee\uff0c\u9700\u6709\u6548\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u96c6\u4f53\u77e5\u8bc6\u3002", "method": "\u63d0\u51faUNIFORM\u6846\u67b6\uff0c\u91c7\u7528\u4e13\u7528\u6295\u7968\u673a\u5236\u5728\u5bf9\u6570\u51e0\u7387\u548c\u7279\u5f81\u5c42\u9762\u6355\u6349\u77e5\u8bc6\u5171\u8bc6\u3002", "result": "UNIFORM\u6709\u6548\u63d0\u5347\u65e0\u76d1\u7763\u76ee\u6807\u8bc6\u522b\u6027\u80fd\uff0c\u76f8\u6bd4\u57fa\u7ebf\u8868\u73b0\u66f4\u597d\uff0c\u53ef\u6269\u5c55\u6027\u5f3a\uff0c\u80fd\u4ece\u8d85\u767e\u4e2a\u6559\u5e08\u6a21\u578b\u4e2d\u53d7\u76ca\u3002", "conclusion": "UNIFORM\u6846\u67b6\u80fd\u5728\u65e0\u7ea6\u675f\u6761\u4ef6\u4e0b\u5b9e\u73b0\u77e5\u8bc6\u8f6c\u79fb\uff0c\u63d0\u5347\u6027\u80fd\u4e14\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.19587", "pdf": "https://arxiv.org/pdf/2508.19587", "abs": "https://arxiv.org/abs/2508.19587", "authors": ["Hadi Zaatiti", "Hatem Hajri", "Osama Abdullah", "Nader Masmoudi"], "title": "Towards stable AI systems for Evaluating Arabic Pronunciations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and\nsentence-level transcription, yet struggle to classify isolated letters. In\nthis study, we show that this phoneme-level task, crucial for language\nlearning, speech therapy, and phonetic research, is challenging because\nisolated letters lack co-articulatory cues, provide no lexical context, and\nlast only a few hundred milliseconds. Recogniser systems must therefore rely\nsolely on variable acoustic cues, a difficulty heightened by Arabic's emphatic\n(pharyngealized) consonants and other sounds with no close analogues in many\nlanguages. This study introduces a diverse, diacritised corpus of isolated\nArabic letters and demonstrates that state-of-the-art wav2vec 2.0 models\nachieve only 35% accuracy on it. Training a lightweight neural network on\nwav2vec embeddings raises performance to 65%. However, adding a small amplitude\nperturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we\napply adversarial training, limiting the noisy-speech drop to 9% while\npreserving clean-speech accuracy. We detail the corpus, training pipeline, and\nevaluation protocol, and release, on demand, data and code for reproducibility.\nFinally, we outline future work extending these methods to word- and\nsentence-level frameworks, where precise letter pronunciation remains critical.", "AI": {"tldr": "\u73b0\u4ee3\u963f\u62c9\u4f2f\u8bedASR\u7cfb\u7edf\u5728\u5b64\u7acb\u5b57\u6bcd\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u672c\u6587\u5f15\u5165\u76f8\u5173\u8bed\u6599\uff0c\u6d4b\u8bd5\u6a21\u578b\u8868\u73b0\uff0c\u7528\u5bf9\u6297\u8bad\u7ec3\u63d0\u5347\u9c81\u68d2\u6027\u5e76\u516c\u5e03\u6570\u636e\u4ee3\u7801\uff0c\u8fd8\u89c4\u5212\u4e86\u672a\u6765\u5de5\u4f5c\u3002", "motivation": "\u73b0\u4ee3\u963f\u62c9\u4f2f\u8bedASR\u7cfb\u7edf\u5728\u5b64\u7acb\u5b57\u6bcd\u5206\u7c7b\u8fd9\u4e00\u91cd\u8981\u97f3\u7d20\u7ea7\u4efb\u52a1\u4e0a\u5b58\u5728\u56f0\u96be\uff0c\u5f00\u5c55\u7814\u7a76\u4ee5\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5f15\u5165\u591a\u6837\u5316\u3001\u5e26\u97f3\u7b26\u7684\u5b64\u7acb\u963f\u62c9\u4f2f\u5b57\u6bcd\u8bed\u6599\uff0c\u5728wav2vec\u5d4c\u5165\u4e0a\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff0c\u5e94\u7528\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u6700\u5148\u8fdb\u7684wav2vec 2.0\u6a21\u578b\u51c6\u786e\u7387\u4ec535%\uff0c\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\u63d0\u5347\u81f365%\uff0c\u52a0\u5c0f\u5e45\u5ea6\u6270\u52a8\u964d\u81f332%\uff0c\u5bf9\u6297\u8bad\u7ec3\u4f7f\u566a\u58f0\u8bed\u97f3\u51c6\u786e\u7387\u4e0b\u964d\u63a7\u5236\u57289%\u4e14\u4fdd\u6301\u5e72\u51c0\u8bed\u97f3\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u963f\u62c9\u4f2f\u8bed\u5b64\u7acb\u5b57\u6bcd\u5206\u7c7b\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u53ef\u5c06\u65b9\u6cd5\u62d3\u5c55\u5230\u5355\u8bcd\u548c\u53e5\u5b50\u5c42\u9762\u6846\u67b6\u3002"}}
{"id": "2508.19588", "pdf": "https://arxiv.org/pdf/2508.19588", "abs": "https://arxiv.org/abs/2508.19588", "authors": ["Lucy Osler"], "title": "Hallucinating with AI: AI Psychosis as Distributed Delusions", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "There is much discussion of the false outputs that generative AI systems such\nas ChatGPT, Claude, Gemini, DeepSeek, and Grok create. In popular terminology,\nthese have been dubbed AI hallucinations. However, deeming these AI outputs\nhallucinations is controversial, with many claiming this is a metaphorical\nmisnomer. Nevertheless, in this paper, I argue that when viewed through the\nlens of distributed cognition theory, we can better see the dynamic and\ntroubling ways in which inaccurate beliefs, distorted memories and\nself-narratives, and delusional thinking can emerge through human-AI\ninteractions; examples of which are popularly being referred to as cases of AI\npsychosis. In such cases, I suggest we move away from thinking about how an AI\nsystem might hallucinate at us, by generating false outputs, to thinking about\nhow, when we routinely rely on generative AI to help us think, remember, and\nnarrate, we can come to hallucinate with AI. This can happen when AI introduces\nerrors into the distributed cognitive process, but it can also happen when AI\nsustains, affirms, and elaborates on our own delusional thinking and\nself-narratives, such as in the case of Jaswant Singh Chail. I also examine how\nthe conversational style of chatbots can lead them to play a dual-function,\nboth as a cognitive artefact and a quasi-Other with whom we co-construct our\nbeliefs, narratives, and our realities. It is this dual function, I suggest,\nthat makes generative AI an unusual, and particularly seductive, case of\ndistributed cognition.", "AI": {"tldr": "\u4ece\u5206\u5e03\u5f0f\u8ba4\u77e5\u7406\u8bba\u89c6\u89d2\u63a2\u8ba8AI\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u4e2d\u7684\u2018AI\u5e7b\u89c9\u2019\u95ee\u9898\uff0c\u63d0\u51fa\u4ece\u2018AI\u5bf9\u6211\u4eec\u4ea7\u751f\u5e7b\u89c9\u2019\u8f6c\u53d8\u4e3a\u2018\u4e0eAI\u4e00\u8d77\u4ea7\u751f\u5e7b\u89c9\u2019\uff0c\u5e76\u5206\u6790\u804a\u5929\u673a\u5668\u4eba\u7684\u53cc\u91cd\u529f\u80fd\u3002", "motivation": "\u5f53\u524d\u5bf9\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4ea7\u751f\u7684\u865a\u5047\u8f93\u51fa\u88ab\u79f0\u4e3a\u2018AI\u5e7b\u89c9\u2019\u5b58\u5728\u4e89\u8bae\uff0c\u4f5c\u8005\u5e0c\u671b\u4ece\u5206\u5e03\u5f0f\u8ba4\u77e5\u7406\u8bba\u66f4\u597d\u7406\u89e3\u4eba\u7c7b - AI\u4ea4\u4e92\u4e2d\u4e0d\u51c6\u786e\u4fe1\u5ff5\u7b49\u95ee\u9898\u3002", "method": "\u8fd0\u7528\u5206\u5e03\u5f0f\u8ba4\u77e5\u7406\u8bba\u8fdb\u884c\u5206\u6790\uff0c\u7ed3\u5408Jaswant Singh Chail\u6848\u4f8b\u3002", "result": "\u53d1\u73b0AI\u4f1a\u5728\u5206\u5e03\u5f0f\u8ba4\u77e5\u8fc7\u7a0b\u4e2d\u5f15\u5165\u9519\u8bef\uff0c\u4e5f\u4f1a\u5f3a\u5316\u4eba\u7c7b\u5984\u60f3\u601d\u7ef4\uff1b\u804a\u5929\u673a\u5668\u4eba\u6709\u8ba4\u77e5\u5de5\u5177\u548c\u51c6\u4ed6\u8005\u7684\u53cc\u91cd\u529f\u80fd\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u56e0\u804a\u5929\u673a\u5668\u4eba\u7684\u53cc\u91cd\u529f\u80fd\uff0c\u662f\u4e00\u79cd\u7279\u6b8a\u4e14\u6709\u5438\u5f15\u529b\u7684\u5206\u5e03\u5f0f\u8ba4\u77e5\u6848\u4f8b\u3002"}}
{"id": "2508.19595", "pdf": "https://arxiv.org/pdf/2508.19595", "abs": "https://arxiv.org/abs/2508.19595", "authors": ["Maryam Kazemi Eskeri", "Thomas Wiedemann", "Ville Kyrki", "Dominik Baumann", "Tomasz Piotr Kucner"], "title": "A Lightweight Crowd Model for Robot Social Navigation", "categories": ["cs.RO", "cs.LG"], "comment": "7 pages, 6 figures, accepted in ECMR 2025", "summary": "Robots operating in human-populated environments must navigate safely and\nefficiently while minimizing social disruption. Achieving this requires\nestimating crowd movement to avoid congested areas in real-time. Traditional\nmicroscopic models struggle to scale in dense crowds due to high computational\ncost, while existing macroscopic crowd prediction models tend to be either\noverly simplistic or computationally intensive. In this work, we propose a\nlightweight, real-time macroscopic crowd prediction model tailored for human\nmotion, which balances prediction accuracy and computational efficiency. Our\napproach simplifies both spatial and temporal processing based on the inherent\ncharacteristics of pedestrian flow, enabling robust generalization without the\noverhead of complex architectures. We demonstrate a 3.6 times reduction in\ninference time, while improving prediction accuracy by 3.1 %. Integrated into a\nsocially aware planning framework, the model enables efficient and socially\ncompliant robot navigation in dynamic environments. This work highlights that\nefficient human crowd modeling enables robots to navigate dense environments\nwithout costly computations.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u5b9e\u65f6\u5b8f\u89c2\u4eba\u7fa4\u9884\u6d4b\u6a21\u578b\uff0c\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u5e76\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u52a9\u529b\u673a\u5668\u4eba\u5bfc\u822a\u3002", "motivation": "\u4f20\u7edf\u5fae\u89c2\u6a21\u578b\u5728\u5bc6\u96c6\u4eba\u7fa4\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u5b8f\u89c2\u6a21\u578b\u8fc7\u4e8e\u7b80\u5355\u6216\u8ba1\u7b97\u5bc6\u96c6\uff0c\u9700\u5e73\u8861\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u6a21\u578b\u4ee5\u5b9e\u73b0\u673a\u5668\u4eba\u5728\u4eba\u7fa4\u73af\u5883\u4e2d\u5b89\u5168\u9ad8\u6548\u5bfc\u822a\u3002", "method": "\u57fa\u4e8e\u884c\u4eba\u6d41\u52a8\u56fa\u6709\u7279\u6027\u7b80\u5316\u7a7a\u95f4\u548c\u65f6\u95f4\u5904\u7406\uff0c\u65e0\u9700\u590d\u6742\u67b6\u6784\u3002", "result": "\u63a8\u7406\u65f6\u95f4\u51cf\u5c113.6\u500d\uff0c\u9884\u6d4b\u51c6\u786e\u6027\u63d0\u9ad83.1%\uff0c\u96c6\u6210\u5230\u89c4\u5212\u6846\u67b6\u53ef\u5b9e\u73b0\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9ad8\u6548\u4e14\u7b26\u5408\u793e\u4ea4\u89c4\u8303\u7684\u5bfc\u822a\u3002", "conclusion": "\u9ad8\u6548\u7684\u4eba\u7fa4\u5efa\u6a21\u53ef\u4f7f\u673a\u5668\u4eba\u5728\u5bc6\u96c6\u73af\u5883\u4e2d\u5bfc\u822a\uff0c\u65e0\u9700\u9ad8\u6210\u672c\u8ba1\u7b97\u3002"}}
{"id": "2508.19683", "pdf": "https://arxiv.org/pdf/2508.19683", "abs": "https://arxiv.org/abs/2508.19683", "authors": ["Kenji Fukushima", "Syo Kamata"], "title": "Topological Uncertainty for Anomaly Detection in the Neural-network EoS Inference with Neutron Star Data", "categories": ["nucl-th", "cs.AI", "cs.LG"], "comment": "23 pages, 7 figures, 2 tables", "summary": "We study the performance of the Topological Uncertainty (TU) constructed with\na trained feedforward neural network (FNN) for Anomaly Detection. Generally,\nmeaningful information can be stored in the hidden layers of the trained FNN,\nand the TU implementation is one tractable recipe to extract buried information\nby means of the Topological Data Analysis. We explicate the concept of the TU\nand the numerical procedures. Then, for a concrete demonstration of the\nperformance test, we employ the Neutron Star data used for inference of the\nequation of state (EoS). For the training dataset consisting of the input\n(Neutron Star data) and the output (EoS parameters), we can compare the\ninferred EoSs and the exact answers to classify the data with the label $k$.\nThe subdataset with $k=0$ leads to the normal inference for which the inferred\nEoS approximates the answer well, while the subdataset with $k=1$ ends up with\nthe unsuccessful inference. Once the TU is prepared based on the $k$-labled\nsubdatasets, we introduce the cross-TU to quantify the uncertainty of\ncharacterizing the $k$-labeled data with the label $j$. The anomaly or\nunsuccessful inference is correctly detected if the cross-TU for $j=k=1$ is\nsmaller than that for $j=0$ and $k=1$. In our numerical experiment, for various\ninput data, we calculate the cross-TU and estimate the performance of Anomaly\nDetection. We find that performance depends on FNN hyperparameters, and the\nsuccess rate of Anomaly Detection exceeds $90\\%$ in the best case. We finally\ndiscuss further potential of the TU application to retrieve the information\nhidden in the trained FNN.", "AI": {"tldr": "\u7814\u7a76\u7528\u8bad\u7ec3\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u7684\u62d3\u6251\u4e0d\u786e\u5b9a\u6027\uff08TU\uff09\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u5728\u4e2d\u5b50\u661f\u6570\u636e\u5b9e\u9a8c\u4e2d\u68c0\u6d4b\u6210\u529f\u7387\u6700\u9ad8\u8d8590%\uff0c\u5e76\u63a2\u8ba8TU\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5229\u7528\u62d3\u6251\u6570\u636e\u5206\u6790\u4ece\u8bad\u7ec3\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u9690\u85cf\u5c42\u63d0\u53d6\u4fe1\u606f\uff0c\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\u3002", "method": "\u6784\u5efaTU\uff0c\u5f15\u5165\u4ea4\u53c9 - TU\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u7528\u4e2d\u5b50\u661f\u6570\u636e\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\uff0c\u8ba1\u7b97\u4ea4\u53c9 - TU\u8bc4\u4f30\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "result": "\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u4f9d\u8d56FNN\u8d85\u53c2\u6570\uff0c\u6700\u4f73\u60c5\u51b5\u4e0b\u5f02\u5e38\u68c0\u6d4b\u6210\u529f\u7387\u8d8590%\u3002", "conclusion": "TU\u6709\u8fdb\u4e00\u6b65\u6316\u6398\u8bad\u7ec3FNN\u9690\u85cf\u4fe1\u606f\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.19603", "pdf": "https://arxiv.org/pdf/2508.19603", "abs": "https://arxiv.org/abs/2508.19603", "authors": ["Zhejing Hu", "Yan Liu", "Gong Chen", "Bruce X. B. Yu"], "title": "CompLex: Music Theory Lexicon Constructed by Autonomous Agents for Automatic Music Generation", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Generative artificial intelligence in music has made significant strides, yet\nit still falls short of the substantial achievements seen in natural language\nprocessing, primarily due to the limited availability of music data.\nKnowledge-informed approaches have been shown to enhance the performance of\nmusic generation models, even when only a few pieces of musical knowledge are\nintegrated. This paper seeks to leverage comprehensive music theory in\nAI-driven music generation tasks, such as algorithmic composition and style\ntransfer, which traditionally require significant manual effort with existing\ntechniques. We introduce a novel automatic music lexicon construction model\nthat generates a lexicon, named CompLex, comprising 37,432 items derived from\njust 9 manually input category keywords and 5 sentence prompt templates. A new\nmulti-agent algorithm is proposed to automatically detect and mitigate\nhallucinations. CompLex demonstrates impressive performance improvements across\nthree state-of-the-art text-to-music generation models, encompassing both\nsymbolic and audio-based methods. Furthermore, we evaluate CompLex in terms of\ncompleteness, accuracy, non-redundancy, and executability, confirming that it\npossesses the key characteristics of an effective lexicon.", "AI": {"tldr": "\u8bba\u6587\u5f15\u5165\u81ea\u52a8\u97f3\u4e50\u8bcd\u5178\u6784\u5efa\u6a21\u578bCompLex\uff0c\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7b97\u6cd5\u68c0\u6d4b\u548c\u51cf\u5c11\u5e7b\u89c9\uff0c\u63d0\u5347\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u6a21\u578b\u6027\u80fd\u5e76\u9a8c\u8bc1\u4e86\u8bcd\u5178\u7279\u6027\u3002", "motivation": "\u97f3\u4e50\u751f\u6210\u7684\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u4e0d\u5982\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u56e0\u97f3\u4e50\u6570\u636e\u6709\u9650\uff0c\u4e14\u4f20\u7edf\u97f3\u4e50\u751f\u6210\u6280\u672f\u9700\u5927\u91cf\u4eba\u529b\uff0c\u671f\u671b\u5229\u7528\u97f3\u4e50\u7406\u8bba\u6539\u8fdbAI\u97f3\u4e50\u751f\u6210\u3002", "method": "\u5f15\u5165\u81ea\u52a8\u97f3\u4e50\u8bcd\u5178\u6784\u5efa\u6a21\u578bCompLex\uff0c\u75289\u4e2a\u624b\u52a8\u8f93\u5165\u7684\u7c7b\u522b\u5173\u952e\u8bcd\u548c5\u4e2a\u53e5\u5b50\u63d0\u793a\u6a21\u677f\u751f\u6210\u542b37,432\u4e2a\u6761\u76ee\u7684\u8bcd\u5178\uff1b\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7b97\u6cd5\u68c0\u6d4b\u548c\u51cf\u5c11\u5e7b\u89c9\u3002", "result": "CompLex\u5728\u4e09\u79cd\u6700\u5148\u8fdb\u7684\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u6a21\u578b\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u6db5\u76d6\u7b26\u53f7\u548c\u57fa\u4e8e\u97f3\u9891\u7684\u65b9\u6cd5\u3002", "conclusion": "CompLex\u5177\u5907\u6709\u6548\u8bcd\u5178\u7684\u5173\u952e\u7279\u6027\uff0c\u5982\u5b8c\u6574\u6027\u3001\u51c6\u786e\u6027\u3001\u975e\u5197\u4f59\u6027\u548c\u53ef\u6267\u884c\u6027\u3002"}}
{"id": "2508.19712", "pdf": "https://arxiv.org/pdf/2508.19712", "abs": "https://arxiv.org/abs/2508.19712", "authors": ["Artem Agafonov", "Vladislav Ryspayev", "Samuel Horv\u00e1th", "Alexander Gasnikov", "Martin Tak\u00e1\u010d", "Slavomir Hanzely"], "title": "Simple Stepsize for Quasi-Newton Methods with Global Convergence Guarantees", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Quasi-Newton methods are widely used for solving convex optimization problems\ndue to their ease of implementation, practical efficiency, and strong local\nconvergence guarantees. However, their global convergence is typically\nestablished only under specific line search strategies and the assumption of\nstrong convexity. In this work, we extend the theoretical understanding of\nQuasi-Newton methods by introducing a simple stepsize schedule that guarantees\na global convergence rate of ${O}(1/k)$ for the convex functions. Furthermore,\nwe show that when the inexactness of the Hessian approximation is controlled\nwithin a prescribed relative accuracy, the method attains an accelerated\nconvergence rate of ${O}(1/k^2)$ -- matching the best-known rates of both\nNesterov's accelerated gradient method and cubically regularized Newton\nmethods. We validate our theoretical findings through empirical comparisons,\ndemonstrating clear improvements over standard Quasi-Newton baselines. To\nfurther enhance robustness, we develop an adaptive variant that adjusts to the\nfunction's curvature while retaining the global convergence guarantees of the\nnon-adaptive algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7b80\u5355\u6b65\u957f\u7b56\u7565\u6269\u5c55\u62df\u725b\u987f\u6cd5\u7406\u8bba\u7406\u89e3\uff0c\u8bc1\u660e\u51f8\u51fd\u6570\u5168\u5c40\u6536\u655b\u7387\uff0c\u63a7\u5236\u9ed1\u585e\u77e9\u9635\u8fd1\u4f3c\u8bef\u5dee\u53ef\u52a0\u901f\u6536\u655b\uff0c\u7ecf\u9a8c\u9a8c\u8bc1\u6709\u6539\u8fdb\u5e76\u5f00\u53d1\u81ea\u9002\u5e94\u53d8\u4f53\u3002", "motivation": "\u73b0\u6709\u62df\u725b\u987f\u6cd5\u5168\u5c40\u6536\u655b\u901a\u5e38\u9700\u7279\u5b9a\u7ebf\u641c\u7d22\u7b56\u7565\u548c\u5f3a\u51f8\u5047\u8bbe\uff0c\u8981\u6269\u5c55\u5176\u7406\u8bba\u7406\u89e3\u3002", "method": "\u5f15\u5165\u7b80\u5355\u6b65\u957f\u7b56\u7565\uff0c\u63a7\u5236\u9ed1\u585e\u77e9\u9635\u8fd1\u4f3c\u8bef\u5dee\uff0c\u5f00\u53d1\u81ea\u9002\u5e94\u53d8\u4f53\u3002", "result": "\u8bc1\u660e\u51f8\u51fd\u6570\u5168\u5c40\u6536\u655b\u7387\u4e3a${O}(1/k)$\uff0c\u63a7\u5236\u8bef\u5dee\u53ef\u8fbe${O}(1/k^2)$\uff0c\u7ecf\u9a8c\u9a8c\u8bc1\u4f18\u4e8e\u6807\u51c6\u62df\u725b\u987f\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u6269\u5c55\u62df\u725b\u987f\u6cd5\u7406\u8bba\uff0c\u6709\u6536\u655b\u7387\u4fdd\u8bc1\u4e14\u81ea\u9002\u5e94\u53d8\u4f53\u589e\u5f3a\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.19604", "pdf": "https://arxiv.org/pdf/2508.19604", "abs": "https://arxiv.org/abs/2508.19604", "authors": ["Qizhe Fan", "Chaoyu Liu", "Zhonghua Qiao", "Xiaoqin Shen"], "title": "IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Domain Generalized Semantic Segmentation (DGSS) focuses on training a model\nusing labeled data from a source domain, with the goal of achieving robust\ngeneralization to unseen target domains during inference. A common approach to\nimprove generalization is to augment the source domain with synthetic data\ngenerated by diffusion models (DMs). However, the generated images often\ncontain structural or semantic defects due to training imperfections. Training\nsegmentation models with such flawed data can lead to performance degradation\nand error accumulation. To address this issue, we propose to integrate inverse\nevolution layers (IELs) into the generative process. IELs are designed to\nhighlight spatial discontinuities and semantic inconsistencies using\nLaplacian-based priors, enabling more effective filtering of undesirable\ngenerative patterns. Based on this mechanism, we introduce IELDM, an enhanced\ndiffusion-based data augmentation framework that can produce higher-quality\nimages. Furthermore, we observe that the defect-suppression capability of IELs\ncan also benefit the segmentation network by suppressing artifact propagation.\nBased on this insight, we embed IELs into the decoder of the DGSS model and\npropose IELFormer to strengthen generalization capability in cross-domain\nscenarios. To further strengthen the model's semantic consistency across\nscales, IELFormer incorporates a multi-scale frequency fusion (MFF) module,\nwhich performs frequency-domain analysis to achieve structured integration of\nmulti-resolution features, thereby improving cross-scale coherence. Extensive\nexperiments on benchmark datasets demonstrate that our approach achieves\nsuperior generalization performance compared to existing methods.", "AI": {"tldr": "\u63d0\u51faIELDM\u548cIELFormer\u63d0\u5347\u9886\u57df\u6cdb\u5316\u8bed\u4e49\u5206\u5272\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u6709\u7f3a\u9677\uff0c\u8bad\u7ec3\u5206\u5272\u6a21\u578b\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u8bef\u5dee\u7d2f\u79ef\u3002", "method": "\u5c06\u9006\u6f14\u5316\u5c42\uff08IELs\uff09\u96c6\u6210\u5230\u751f\u6210\u8fc7\u7a0b\uff0c\u63d0\u51faIELDM\u6846\u67b6\uff1b\u5c06IELs\u5d4c\u5165DGSS\u6a21\u578b\u89e3\u7801\u5668\u63d0\u51faIELFormer\uff1bIELFormer\u52a0\u5165\u591a\u5c3a\u5ea6\u9891\u7387\u878d\u5408\uff08MFF\uff09\u6a21\u5757\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u66f4\u4f18\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5408\u6210\u6570\u636e\u7f3a\u9677\u95ee\u9898\uff0c\u63d0\u5347\u8de8\u9886\u57df\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.19713", "pdf": "https://arxiv.org/pdf/2508.19713", "abs": "https://arxiv.org/abs/2508.19713", "authors": ["Lars Doorenbos", "C. H. Lucas Patty", "Raphael Sznitman", "Pablo M\u00e1rquez-Neila"], "title": "Inferring geometry and material properties from Mueller matrices with machine learning", "categories": ["physics.optics", "cs.LG"], "comment": "Presented at Polarization Science and Remote Sensing XII", "summary": "Mueller matrices (MMs) encode information on geometry and material\nproperties, but recovering both simultaneously is an ill-posed problem. We\nexplore whether MMs contain sufficient information to infer surface geometry\nand material properties with machine learning. We use a dataset of spheres of\nvarious isotropic materials, with MMs captured over the full angular domain at\nfive visible wavelengths (450-650 nm). We train machine learning models to\npredict material properties and surface normals using only these MMs as input.\nWe demonstrate that, even when the material type is unknown, surface normals\ncan be predicted and object geometry reconstructed. Moreover, MMs allow models\nto identify material types correctly. Further analyses show that diagonal\nelements are key for material characterization, and off-diagonal elements are\ndecisive for normal estimation.", "AI": {"tldr": "\u63a2\u7d22\u7528\u673a\u5668\u5b66\u4e60\u4ece\u7a46\u52d2\u77e9\u9635\u63a8\u65ad\u8868\u9762\u51e0\u4f55\u548c\u6750\u6599\u5c5e\u6027\uff0c\u8bc1\u660e\u53ef\u9884\u6d4b\u8868\u9762\u6cd5\u7ebf\u3001\u91cd\u5efa\u7269\u4f53\u51e0\u4f55\u5e76\u8bc6\u522b\u6750\u6599\u7c7b\u578b\u3002", "motivation": "\u7a46\u52d2\u77e9\u9635\u540c\u65f6\u6062\u590d\u51e0\u4f55\u548c\u6750\u6599\u5c5e\u6027\u662f\u4e0d\u9002\u5b9a\u95ee\u9898\uff0c\u63a2\u7d22\u5176\u662f\u5426\u542b\u8db3\u591f\u4fe1\u606f\u7528\u673a\u5668\u5b66\u4e60\u63a8\u65ad\u76f8\u5173\u5c5e\u6027\u3002", "method": "\u4f7f\u7528\u4e0d\u540c\u5404\u5411\u540c\u6027\u6750\u6599\u7403\u4f53\u6570\u636e\u96c6\uff0c\u5728\u4e94\u4e2a\u53ef\u89c1\u5149\u6ce2\u957f\u5168\u89d2\u57df\u6355\u83b7\u7a46\u52d2\u77e9\u9635\uff0c\u4ee5\u5176\u4e3a\u8f93\u5165\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u5373\u4f7f\u6750\u6599\u7c7b\u578b\u672a\u77e5\uff0c\u53ef\u9884\u6d4b\u8868\u9762\u6cd5\u7ebf\u3001\u91cd\u5efa\u7269\u4f53\u51e0\u4f55\uff0c\u80fd\u6b63\u786e\u8bc6\u522b\u6750\u6599\u7c7b\u578b\u3002", "conclusion": "\u5bf9\u89d2\u5143\u7d20\u5bf9\u6750\u6599\u8868\u5f81\u5173\u952e\uff0c\u975e\u5bf9\u89d2\u5143\u7d20\u5bf9\u6cd5\u7ebf\u4f30\u8ba1\u51b3\u5b9a\u6027\u4f5c\u7528\u3002"}}
{"id": "2508.19614", "pdf": "https://arxiv.org/pdf/2508.19614", "abs": "https://arxiv.org/abs/2508.19614", "authors": ["Yang Sun", "Lixin Zou", "Dan Luo", "Zhiyong Xie", "Long Zhang", "Liming Dong", "Yunwei Zhao", "Xixun Lin", "Yanxiong Lu", "Chenliang Li"], "title": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) incorporates external knowledge into\nlarge language models (LLMs), improving their adaptability to downstream tasks\nand enabling information updates. Surprisingly, recent empirical evidence\ndemonstrates that injecting noise into retrieved relevant documents\nparadoxically facilitates exploitation of external knowledge and improves\ngeneration quality. Although counterintuitive and challenging to apply in\npractice, this phenomenon enables granular control and rigorous analysis of how\nLLMs integrate external knowledge. Therefore, in this paper, we intervene on\nnoise injection and establish a layer-specific functional demarcation within\nthe LLM: shallow layers specialize in local context modeling, intermediate\nlayers focus on integrating long-range external factual knowledge, and deeper\nlayers primarily rely on parametric internal knowledge. Building on this\ninsight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that\ndirectly combines representations from an intermediate layer with final-layer\ndecoding outputs to fully exploit the external factual knowledge. To identify\nthe optimal intermediate layer, we introduce an internal knowledge score (IKS)\ncriterion that selects the layer with the lowest IKS value in the latter half\nof layers. Experimental results across multiple benchmarks demonstrate that LFD\nhelps RAG systems more effectively surface retrieved context knowledge with\nminimal cost.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76RAG\u4e2d\u566a\u58f0\u6ce8\u5165\u73b0\u8c61\uff0c\u63d0\u51faLFD\u89e3\u7801\u7b56\u7565\u53caIKS\u51c6\u5219\uff0c\u5b9e\u9a8c\u8868\u660eLFD\u80fd\u4f4e\u6210\u672c\u63d0\u5347RAG\u7cfb\u7edf\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u7684\u80fd\u529b\u3002", "motivation": "\u57fa\u4e8eRAG\u4e2d\u6ce8\u5165\u566a\u58f0\u80fd\u63d0\u5347\u77e5\u8bc6\u5229\u7528\u548c\u751f\u6210\u8d28\u91cf\u8fd9\u4e00\u73b0\u8c61\uff0c\u5bf9LLM\u5185\u90e8\u77e5\u8bc6\u6574\u5408\u8fdb\u884c\u7cbe\u7ec6\u63a7\u5236\u548c\u5206\u6790\u3002", "method": "\u5bf9\u566a\u58f0\u6ce8\u5165\u8fdb\u884c\u5e72\u9884\uff0c\u5efa\u7acbLLM\u5c42\u7279\u5b9a\u529f\u80fd\u5212\u5206\uff0c\u63d0\u51faLFD\u89e3\u7801\u7b56\u7565\u548cIKS\u51c6\u5219\u9009\u62e9\u6700\u4f18\u4e2d\u95f4\u5c42\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLFD\u5e2e\u52a9RAG\u7cfb\u7edf\u4ee5\u6700\u5c0f\u6210\u672c\u66f4\u6709\u6548\u5730\u6316\u6398\u68c0\u7d22\u5230\u7684\u4e0a\u4e0b\u6587\u77e5\u8bc6\u3002", "conclusion": "LFD\u89e3\u7801\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347RAG\u7cfb\u7edf\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u7684\u80fd\u529b\u3002"}}
{"id": "2508.19751", "pdf": "https://arxiv.org/pdf/2508.19751", "abs": "https://arxiv.org/abs/2508.19751", "authors": ["Joshua R. Jandrell", "Mitchell A. Cox"], "title": "Fourier Feature Networks for High-Fidelity Prediction of Perturbed Optical Fields", "categories": ["physics.optics", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Modelling the effects of perturbations on optical fields often requires\nlearning highly oscillatory complex-valued functions. Standard multi-layer\nperceptrons (MLPs) struggle with this task due to an inherent spectral bias,\npreventing them from fitting high-frequency sinusoids. To overcome this, we\nincorporate Fourier features - a set of predefined sinusoids dependent on the\nperturbation - as an additional network input. This reframes the learning\nproblem from approximating a complex function to finding a linear combination\nof basis functions. We demonstrate this method by training a Fourier Feature\nNetwork to predict the transmission matrix of a multimode fibre under\nmechanical compression. Compared to a standard MLP, our network reduces\nprediction error in the output field's amplitude and phase by an order of\nmagnitude, achieving a mean complex correlation of 0.995 with the ground truth,\ndespite using 85% fewer parameters. This approach offers a general and robust\nmethod for accurately modelling a wide class of oscillatory physical systems.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u6807\u51c6MLP\u96be\u4ee5\u5b66\u4e60\u9ad8\u632f\u8361\u590d\u503c\u51fd\u6570\u95ee\u9898\uff0c\u5f15\u5165\u5085\u91cc\u53f6\u7279\u5f81\u4f5c\u4e3a\u989d\u5916\u7f51\u7edc\u8f93\u5165\uff0c\u5728\u9884\u6d4b\u591a\u6a21\u5149\u7ea4\u4f20\u8f93\u77e9\u9635\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u4e00\u79cd\u901a\u7528\u4e14\u9c81\u68d2\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "motivation": "\u6807\u51c6\u591a\u5c42\u611f\u77e5\u5668\uff08MLPs\uff09\u56e0\u56fa\u6709\u9891\u8c31\u504f\u5dee\uff0c\u96be\u4ee5\u62df\u5408\u9ad8\u9891\u7387\u6b63\u5f26\u6ce2\uff0c\u65e0\u6cd5\u80dc\u4efb\u5bf9\u5149\u573a\u6270\u52a8\u6548\u5e94\u5efa\u6a21\u65f6\u5b66\u4e60\u9ad8\u632f\u8361\u590d\u503c\u51fd\u6570\u7684\u4efb\u52a1\u3002", "method": "\u5f15\u5165\u4f9d\u8d56\u4e8e\u6270\u52a8\u7684\u4e00\u7ec4\u9884\u5b9a\u4e49\u6b63\u5f26\u51fd\u6570\uff08\u5085\u91cc\u53f6\u7279\u5f81\uff09\u4f5c\u4e3a\u989d\u5916\u7f51\u7edc\u8f93\u5165\uff0c\u5c06\u5b66\u4e60\u95ee\u9898\u8f6c\u5316\u4e3a\u5bfb\u627e\u57fa\u51fd\u6570\u7684\u7ebf\u6027\u7ec4\u5408\u3002", "result": "\u4e0e\u6807\u51c6MLP\u76f8\u6bd4\uff0c\u4f7f\u7528\u5c1185%\u7684\u53c2\u6570\uff0c\u7f51\u7edc\u5c06\u8f93\u51fa\u573a\u632f\u5e45\u548c\u76f8\u4f4d\u7684\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e0e\u771f\u5b9e\u503c\u7684\u5e73\u5747\u590d\u76f8\u5173\u7cfb\u6570\u8fbe\u52300.995\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u51c6\u786e\u5efa\u6a21\u4e00\u7c7b\u5e7f\u6cdb\u7684\u632f\u8361\u7269\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u9c81\u68d2\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.19819", "pdf": "https://arxiv.org/pdf/2508.19819", "abs": "https://arxiv.org/abs/2508.19819", "authors": ["Viktor Valadi", "Mattias \u00c5kesson", "Johan \u00d6stman", "Salman Toor", "Andreas Hellander"], "title": "From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "Under review at KDD 2026 (Research Track)", "summary": "Gradient inversion attacks have garnered attention for their ability to\ncompromise privacy in federated learning. However, many studies consider\nattacks with the model in inference mode, where training-time behaviors like\ndropout are disabled and batch normalization relies on fixed statistics. In\nthis work, we systematically analyze how architecture and training behavior\naffect vulnerability, including the first in-depth study of inference-mode\nclients, which we show dramatically simplifies inversion. To assess attack\nfeasibility under more realistic conditions, we turn to clients operating in\nstandard training mode. In this setting, we find that successful attacks are\nonly possible when several architectural conditions are met simultaneously:\nmodels must be shallow and wide, use skip connections, and, critically, employ\npre-activation normalization. We introduce two novel attacks against models in\ntraining-mode with varying attacker knowledge, achieving state-of-the-art\nperformance under realistic training conditions. We extend these efforts by\npresenting the first attack on a production-grade object-detection model. Here,\nto enable any visibly identifiable leakage, we revert to the lenient inference\nmode setting and make multiple architectural modifications to increase model\nvulnerability, with the extent of required changes highlighting the strong\ninherent robustness of such architectures. We conclude this work by offering\nthe first comprehensive mapping of settings, clarifying which combinations of\narchitectural choices and operational modes meaningfully impact privacy. Our\nanalysis provides actionable insight into when models are likely vulnerable,\nwhen they appear robust, and where subtle leakage may persist. Together, these\nfindings reframe how gradient inversion risk should be assessed in future\nresearch and deployment scenarios.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u67b6\u6784\u548c\u8bad\u7ec3\u884c\u4e3a\u5bf9\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u6f0f\u6d1e\u7684\u5f71\u54cd\uff0c\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u6a21\u5f0f\u4e0b\u5f00\u5c55\u653b\u51fb\u7814\u7a76\uff0c\u63d0\u51fa\u65b0\u653b\u51fb\u65b9\u6cd5\uff0c\u5bf9\u751f\u4ea7\u7ea7\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u8fdb\u884c\u653b\u51fb\uff0c\u6700\u540e\u7ed9\u51fa\u8bbe\u7f6e\u7684\u5168\u9762\u6620\u5c04\u3002", "motivation": "\u8bb8\u591a\u7814\u7a76\u5728\u63a8\u7406\u6a21\u5f0f\u4e0b\u8003\u8651\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\uff0c\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u5206\u6790\u67b6\u6784\u548c\u8bad\u7ec3\u884c\u4e3a\u5bf9\u6f0f\u6d1e\u7684\u5f71\u54cd\uff0c\u5728\u66f4\u73b0\u5b9e\u6761\u4ef6\u4e0b\u8bc4\u4f30\u653b\u51fb\u53ef\u884c\u6027\u3002", "method": "\u5206\u6790\u67b6\u6784\u548c\u8bad\u7ec3\u884c\u4e3a\u5bf9\u6f0f\u6d1e\u7684\u5f71\u54cd\uff1b\u9488\u5bf9\u8bad\u7ec3\u6a21\u5f0f\u6a21\u578b\u63d0\u51fa\u4e24\u79cd\u65b0\u653b\u51fb\uff1b\u5bf9\u751f\u4ea7\u7ea7\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u8fdb\u884c\u653b\u51fb\u5e76\u4fee\u6539\u67b6\u6784\u589e\u52a0\u5176\u6f0f\u6d1e\u3002", "result": "\u53d1\u73b0\u8bad\u7ec3\u6a21\u5f0f\u4e0b\u6210\u529f\u653b\u51fb\u9700\u6ee1\u8db3\u591a\u4e2a\u67b6\u6784\u6761\u4ef6\uff1b\u63d0\u51fa\u7684\u65b0\u653b\u51fb\u5728\u73b0\u5b9e\u8bad\u7ec3\u6761\u4ef6\u4e0b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff1b\u6307\u51fa\u751f\u4ea7\u7ea7\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u6709\u5f88\u5f3a\u7684\u56fa\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u7ed9\u51fa\u4e86\u8bbe\u7f6e\u7684\u5168\u9762\u6620\u5c04\uff0c\u660e\u786e\u67b6\u6784\u9009\u62e9\u548c\u64cd\u4f5c\u6a21\u5f0f\u5bf9\u9690\u79c1\u7684\u5f71\u54cd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u90e8\u7f72\u573a\u666f\u8bc4\u4f30\u68af\u5ea6\u53cd\u8f6c\u98ce\u9669\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2508.19831", "pdf": "https://arxiv.org/pdf/2508.19831", "abs": "https://arxiv.org/abs/2508.19831", "authors": ["Anusha Kamath", "Kanishk Singla", "Rakesh Paul", "Raviraj Joshi", "Utkarsh Vaidya", "Sanjay Singh Chauhan", "Niranjan Wartikar"], "title": "Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is\nchallenging due to a lack of high-quality benchmarks, as direct translation of\nEnglish datasets fails to capture crucial linguistic and cultural nuances. To\naddress this, we introduce a suite of five Hindi LLM evaluation datasets:\nIFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created\nusing a methodology that combines from-scratch human annotation with a\ntranslate-and-verify process. We leverage this suite to conduct an extensive\nbenchmarking of open-source LLMs supporting Hindi, providing a detailed\ncomparative analysis of their current capabilities. Our curation process also\nserves as a replicable methodology for developing benchmarks in other\nlow-resource languages.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5370\u5730\u8bed\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u57fa\u51c6\u7684\u95ee\u9898\uff0c\u5f15\u5165\u4e94\u4e2a\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5bf9\u652f\u6301\u5370\u5730\u8bed\u7684\u5f00\u6e90\u5927\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u5f00\u53d1\u57fa\u51c6\u63d0\u4f9b\u53ef\u590d\u5236\u65b9\u6cd5\u3002", "motivation": "\u5370\u5730\u8bed\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u57fa\u51c6\uff0c\u76f4\u63a5\u7ffb\u8bd1\u82f1\u6587\u6570\u636e\u96c6\u65e0\u6cd5\u6355\u6349\u8bed\u8a00\u548c\u6587\u5316\u7ec6\u5fae\u5dee\u522b\u3002", "method": "\u7ed3\u5408\u4ece\u5934\u5f00\u59cb\u7684\u4eba\u5de5\u6807\u6ce8\u548c\u7ffb\u8bd1\u9a8c\u8bc1\u8fc7\u7a0b\u521b\u5efa\u4e94\u4e2a\u5370\u5730\u8bed\u8bc4\u4f30\u6570\u636e\u96c6\u3002", "result": "\u5bf9\u652f\u6301\u5370\u5730\u8bed\u7684\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u4f9b\u8be6\u7ec6\u7684\u80fd\u529b\u5bf9\u6bd4\u5206\u6790\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u96c6\u521b\u5efa\u8fc7\u7a0b\u53ef\u4f5c\u4e3a\u5f00\u53d1\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00\u57fa\u51c6\u7684\u53ef\u590d\u5236\u65b9\u6cd5\u3002"}}
{"id": "2508.19625", "pdf": "https://arxiv.org/pdf/2508.19625", "abs": "https://arxiv.org/abs/2508.19625", "authors": ["Andrew J. Peterson"], "title": "Training for Obsolescence? The AI-Driven Education Trap", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": "Under review", "summary": "Artificial intelligence simultaneously transforms human capital production in\nschools and its demand in labor markets. Analyzing these effects in isolation\ncan lead to a significant misallocation of educational resources. We model an\neducational planner whose decision to adopt AI is driven by its teaching\nproductivity, failing to internalize AI's future wage-suppressing effect on\nthose same skills. Our core assumption, motivated by a pilot survey, is that\nthere is a positive correlation between these two effects. This drives our\ncentral proposition: this information failure creates a skill mismatch that\nmonotonically increases with AI prevalence. Extensions show the mismatch is\nexacerbated by the neglect of unpriced non-cognitive skills and by a school's\nendogenous over-investment in AI. Our findings caution that policies promoting\nAI in education, if not paired with forward-looking labor market signals, may\nparadoxically undermine students' long-term human capital, especially if\nreliance on AI crowds out the development of unpriced non-cognitive skills,\nsuch as persistence, that are forged through intellectual struggle.", "AI": {"tldr": "\u4eba\u5de5\u667a\u80fd\u6539\u53d8\u5b66\u6821\u4eba\u529b\u8d44\u672c\u751f\u4ea7\u548c\u52b3\u52a8\u529b\u5e02\u573a\u9700\u6c42\uff0c\u4fe1\u606f\u5931\u6548\u5bfc\u81f4\u6280\u80fd\u9519\u914d\uff0c\u63a8\u5e7fAI\u7684\u6559\u80b2\u653f\u7b56\u6216\u635f\u5bb3\u5b66\u751f\u957f\u671f\u4eba\u529b\u8d44\u672c\u3002", "motivation": "\u5b64\u7acb\u5206\u6790\u4eba\u5de5\u667a\u80fd\u5bf9\u5b66\u6821\u548c\u52b3\u52a8\u529b\u5e02\u573a\u7684\u5f71\u54cd\u4f1a\u5bfc\u81f4\u6559\u80b2\u8d44\u6e90\u9519\u914d\uff0c\u9700\u7814\u7a76\u76f8\u5173\u95ee\u9898\u3002", "method": "\u5bf9\u6559\u80b2\u89c4\u5212\u8005\u91c7\u7528AI\u7684\u51b3\u7b56\u8fdb\u884c\u5efa\u6a21\uff0c\u57fa\u4e8e\u8bd5\u70b9\u8c03\u67e5\u63d0\u51fa\u6838\u5fc3\u5047\u8bbe\u3002", "result": "\u4fe1\u606f\u5931\u6548\u9020\u6210\u7684\u6280\u80fd\u9519\u914d\u968fAI\u666e\u53ca\u5355\u8c03\u589e\u52a0\uff0c\u5ffd\u89c6\u975e\u8ba4\u77e5\u6280\u80fd\u548c\u5b66\u6821\u5bf9AI\u7684\u8fc7\u5ea6\u6295\u8d44\u4f1a\u52a0\u5267\u9519\u914d\u3002", "conclusion": "\u63a8\u5e7fAI\u7684\u6559\u80b2\u653f\u7b56\u82e5\u4e0d\u7ed3\u5408\u524d\u77bb\u6027\u52b3\u52a8\u529b\u5e02\u573a\u4fe1\u53f7\uff0c\u53ef\u80fd\u635f\u5bb3\u5b66\u751f\u957f\u671f\u4eba\u529b\u8d44\u672c\u3002"}}
{"id": "2508.19630", "pdf": "https://arxiv.org/pdf/2508.19630", "abs": "https://arxiv.org/abs/2508.19630", "authors": ["Xiaolei Wei", "Yi Ouyang", "Haibo Ye"], "title": "Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition", "categories": ["cs.CV", "cs.AI"], "comment": "This paper has been accepted to PRCV 2025", "summary": "Long-tailed visual recognition is challenging not only due to class imbalance\nbut also because of varying classification difficulty across categories. Simply\nreweighting classes by frequency often overlooks those that are intrinsically\nhard to learn. To address this, we propose \\textbf{DQRoute}, a modular\nframework that combines difficulty-aware optimization with dynamic expert\ncollaboration. DQRoute first estimates class-wise difficulty based on\nprediction uncertainty and historical performance, and uses this signal to\nguide training with adaptive loss weighting. On the architectural side, DQRoute\nemploys a mixture-of-experts design, where each expert specializes in a\ndifferent region of the class distribution. At inference time, expert\npredictions are weighted by confidence scores derived from expert-specific OOD\ndetectors, enabling input-adaptive routing without the need for a centralized\nrouter. All components are trained jointly in an end-to-end manner. Experiments\non standard long-tailed benchmarks demonstrate that DQRoute significantly\nimproves performance, particularly on rare and difficult classes, highlighting\nthe benefit of integrating difficulty modeling with decentralized expert\nrouting.", "AI": {"tldr": "\u63d0\u51faDQRoute\u6846\u67b6\uff0c\u7ed3\u5408\u96be\u5ea6\u611f\u77e5\u4f18\u5316\u4e0e\u52a8\u6001\u4e13\u5bb6\u534f\u4f5c\uff0c\u5728\u957f\u5c3e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u6027\u80fd\uff0c\u5c24\u5176\u5bf9\u7a00\u6709\u548c\u96be\u5206\u7c7b\u522b\u3002", "motivation": "\u957f\u5c3e\u89c6\u89c9\u8bc6\u522b\u56e0\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u5206\u7c7b\u96be\u5ea6\u5dee\u5f02\u5177\u6709\u6311\u6218\u6027\uff0c\u7b80\u5355\u6309\u9891\u7387\u91cd\u65b0\u52a0\u6743\u7c7b\u522b\u4f1a\u5ffd\u7565\u96be\u5b66\u7c7b\u522b\u3002", "method": "\u5148\u57fa\u4e8e\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u548c\u5386\u53f2\u6027\u80fd\u4f30\u8ba1\u7c7b\u522b\u96be\u5ea6\uff0c\u7528\u81ea\u9002\u5e94\u635f\u5931\u52a0\u6743\u6307\u5bfc\u8bad\u7ec3\uff1b\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\u8bbe\u8ba1\uff0c\u5404\u4e13\u5bb6\u4e13\u6ce8\u4e0d\u540c\u7c7b\u522b\u5206\u5e03\u533a\u57df\uff1b\u63a8\u7406\u65f6\u7528\u4e13\u5bb6\u7279\u5b9aOOD\u68c0\u6d4b\u5668\u7684\u7f6e\u4fe1\u5206\u6570\u52a0\u6743\u4e13\u5bb6\u9884\u6d4b\uff0c\u5b9e\u73b0\u8f93\u5165\u81ea\u9002\u5e94\u8def\u7531\uff0c\u6240\u6709\u7ec4\u4ef6\u7aef\u5230\u7aef\u8054\u5408\u8bad\u7ec3\u3002", "result": "\u5728\u6807\u51c6\u957f\u5c3e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDQRoute\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u5c24\u5176\u5728\u7a00\u6709\u548c\u96be\u5206\u7c7b\u522b\u4e0a\u3002", "conclusion": "\u5c06\u96be\u5ea6\u5efa\u6a21\u4e0e\u5206\u6563\u5f0f\u4e13\u5bb6\u8def\u7531\u7ed3\u5408\u6709\u76ca\u3002"}}
{"id": "2508.19862", "pdf": "https://arxiv.org/pdf/2508.19862", "abs": "https://arxiv.org/abs/2508.19862", "authors": ["Long Chen", "Ashiv Patel", "Mengyun Qiao", "Mohammad Yousuf Salmasi", "Salah A. Hammouche", "Vasilis Stavrinides", "Jasleen Nagi", "Soodeh Kalaie", "Xiao Yun Xu", "Wenjia Bai", "Declan P. O'Regan"], "title": "Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Personalized, accurate prediction of aortic aneurysm progression is essential\nfor timely intervention but remains challenging due to the need to model both\nsubtle local deformations and global anatomical changes within complex 3D\ngeometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh\ngenerative adversarial network for 3D aneurysm growth prediction. MCMeshGAN\nintroduces a dual-branch architecture combining a novel local KNN-based\nconvolutional network (KCN) to preserve fine-grained geometric details and a\nglobal graph convolutional network (GCN) to capture long-range structural\ncontext, overcoming the over-smoothing limitations of deep GCNs. A dedicated\ncondition branch encodes clinical attributes (age, sex) and the target time\ninterval to generate anatomically plausible, temporally controlled predictions,\nenabling retrospective and prospective modeling. We curated TAAMesh, a new\nlongitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal\nrecords (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive\nexperiments demonstrate that MCMeshGAN consistently outperforms\nstate-of-the-art baselines in both geometric accuracy and clinically important\ndiameter estimation. This framework offers a robust step toward clinically\ndeployable, personalized 3D disease trajectory modeling. The source code for\nMCMeshGAN and the baseline methods is publicly available at\nhttps://github.com/ImperialCollegeLondon/MCMeshGAN.", "AI": {"tldr": "\u63d0\u51faMCMeshGAN\u7528\u4e8e3D\u52a8\u8109\u7624\u751f\u957f\u9884\u6d4b\uff0c\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u516c\u5f00\u3002", "motivation": "\u4e2a\u6027\u5316\u3001\u51c6\u786e\u9884\u6d4b\u4e3b\u52a8\u8109\u7624\u8fdb\u5c55\u5bf9\u53ca\u65f6\u5e72\u9884\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56e0\u9700\u5efa\u6a21\u590d\u67423D\u51e0\u4f55\u5f62\u72b6\u4e2d\u7684\u5c40\u90e8\u53d8\u5f62\u548c\u5168\u5c40\u89e3\u5256\u53d8\u5316\u800c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faMCMeshGAN\uff0c\u91c7\u7528\u53cc\u5206\u652f\u67b6\u6784\uff0c\u7ed3\u5408KCN\u548cGCN\uff0c\u6709\u4e13\u95e8\u6761\u4ef6\u5206\u652f\u7f16\u7801\u4e34\u5e8a\u5c5e\u6027\u548c\u65f6\u95f4\u95f4\u9694\uff1b\u7b56\u5212TAAMesh\u6570\u636e\u96c6\u3002", "result": "MCMeshGAN\u5728\u51e0\u4f55\u51c6\u786e\u6027\u548c\u76f4\u5f84\u4f30\u8ba1\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5411\u4e34\u5e8a\u53ef\u7528\u7684\u4e2a\u6027\u53163D\u75be\u75c5\u8f68\u8ff9\u5efa\u6a21\u8fc8\u51fa\u4e86\u575a\u5b9e\u4e00\u6b65\u3002"}}
{"id": "2508.19637", "pdf": "https://arxiv.org/pdf/2508.19637", "abs": "https://arxiv.org/abs/2508.19637", "authors": ["Maha Shatta", "Konstantinos Balaskas", "Paula Carolina Lozano Duarte", "Georgios Panagopoulos", "Mehdi B. Tahoori", "Georgios Zervakis"], "title": "Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge", "categories": ["eess.SP", "cs.AI"], "comment": "Accepted at 2025 International Conference on Computer-Aided Design\n  (ICCAD)", "summary": "Flexible Electronics (FE) offer a promising alternative to rigid\nsilicon-based hardware for wearable healthcare devices, enabling lightweight,\nconformable, and low-cost systems. However, their limited integration density\nand large feature sizes impose strict area and power constraints, making\nML-based healthcare systems-integrating analog frontend, feature extraction and\nclassifier-particularly challenging. Existing FE solutions often neglect\npotential system-wide solutions and focus on the classifier, overlooking the\nsubstantial hardware cost of feature extraction and Analog-to-Digital\nConverters (ADCs)-both major contributors to area and power consumption. In\nthis work, we present a holistic mixed-signal feature-to-classifier co-design\nframework for flexible smart wearable systems. To the best of our knowledge, we\ndesign the first analog feature extractors in FE, significantly reducing\nfeature extraction cost. We further propose an hardware-aware NAS-inspired\nfeature selection strategy within ML training, enabling efficient,\napplication-specific designs. Our evaluation on healthcare benchmarks shows our\napproach delivers highly accurate, ultra-area-efficient flexible systems-ideal\nfor disposable, low-power wearable monitoring.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u67d4\u6027\u667a\u80fd\u53ef\u7a7f\u6234\u7cfb\u7edf\u7684\u6df7\u5408\u4fe1\u53f7\u7279\u5f81\u5230\u5206\u7c7b\u5668\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u964d\u4f4e\u7279\u5f81\u63d0\u53d6\u6210\u672c\uff0c\u5b9e\u73b0\u9ad8\u6548\u8bbe\u8ba1\u3002", "motivation": "\u67d4\u6027\u7535\u5b50\u96c6\u6210\u5bc6\u5ea6\u6709\u9650\u3001\u7279\u5f81\u5c3a\u5bf8\u5927\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5ffd\u89c6\u7cfb\u7edf\u7ea7\u65b9\u6848\uff0c\u7279\u5f81\u63d0\u53d6\u548cADC\u786c\u4ef6\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u4fe1\u53f7\u7279\u5f81\u5230\u5206\u7c7b\u5668\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u8bbe\u8ba1\u6a21\u62df\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u63d0\u51fa\u786c\u4ef6\u611f\u77e5\u7684\u7279\u5f81\u9009\u62e9\u7b56\u7565\u3002", "result": "\u5728\u533b\u7597\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u8d85\u9762\u79ef\u9ad8\u6548\u7684\u67d4\u6027\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u4e00\u6b21\u6027\u3001\u4f4e\u529f\u8017\u7684\u53ef\u7a7f\u6234\u76d1\u6d4b\u3002"}}
{"id": "2508.19866", "pdf": "https://arxiv.org/pdf/2508.19866", "abs": "https://arxiv.org/abs/2508.19866", "authors": ["Fran\u00e7ois G. Landry", "Moulay A. Akhloufi"], "title": "TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations", "categories": ["cs.CV", "cs.LG"], "comment": "This work has been submitted to IEEE Transactions on Intelligent\n  Vehicles for possible publication", "summary": "With the introduction of vehicles with autonomous capabilities on public\nroads, predicting pedestrian crossing intention has emerged as an active area\nof research. The task of predicting pedestrian crossing intention involves\ndetermining whether pedestrians in the scene are likely to cross the road or\nnot. In this work, we propose TrajFusionNet, a novel transformer-based model\nthat combines future pedestrian trajectory and vehicle speed predictions as\npriors for predicting crossing intention. TrajFusionNet comprises two branches:\na Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM\nbranch learns from a sequential representation of the observed and predicted\npedestrian trajectory and vehicle speed. Complementarily, the VAM branch\nenables learning from a visual representation of the predicted pedestrian\ntrajectory by overlaying predicted pedestrian bounding boxes onto scene images.\nBy utilizing a small number of lightweight modalities, TrajFusionNet achieves\nthe lowest total inference time (including model runtime and data\npreprocessing) among current state-of-the-art approaches. In terms of\nperformance, it achieves state-of-the-art results across the three most\ncommonly used datasets for pedestrian crossing intention prediction.", "AI": {"tldr": "\u63d0\u51faTrajFusionNet\u6a21\u578b\u7ed3\u5408\u884c\u4eba\u672a\u6765\u8f68\u8ff9\u548c\u8f66\u901f\u9884\u6d4b\u6765\u9884\u6d4b\u884c\u4eba\u8fc7\u8857\u610f\u56fe\uff0c\u5177\u4f4e\u63a8\u7406\u65f6\u95f4\u548c\u5148\u8fdb\u6027\u80fd", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0a\u8def\uff0c\u884c\u4eba\u8fc7\u8857\u610f\u56fe\u9884\u6d4b\u6210\u4e3a\u7814\u7a76\u70ed\u70b9", "method": "\u63d0\u51faTrajFusionNet\u6a21\u578b\uff0c\u542b\u5e8f\u5217\u6ce8\u610f\u529b\u6a21\u5757\u548c\u89c6\u89c9\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u4fe1\u606f", "result": "\u5728\u63a8\u7406\u65f6\u95f4\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u4e09\u4e2a\u5e38\u7528\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c", "conclusion": "TrajFusionNet\u6a21\u578b\u5728\u884c\u4eba\u8fc7\u8857\u610f\u56fe\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u8f83\u4f4e\u7684\u63a8\u7406\u65f6\u95f4\u548c\u8f83\u9ad8\u7684\u6027\u80fd"}}
{"id": "2508.19638", "pdf": "https://arxiv.org/pdf/2508.19638", "abs": "https://arxiv.org/abs/2508.19638", "authors": ["Yang Li", "Quan Yuan", "Guiyang Luo", "Xiaoyuan Fu", "Rui Pan", "Yujia Yang", "Congzhang Shao", "Yuewen Liu", "Jinglin Li"], "title": "Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Collaborative perception allows agents to enhance their perceptual\ncapabilities by exchanging intermediate features. Existing methods typically\norganize these intermediate features as 2D bird's-eye-view (BEV)\nrepresentations, which discard critical fine-grained 3D structural cues\nessential for accurate object recognition and localization. To this end, we\nfirst introduce point-level tokens as intermediate representations for\ncollaborative perception. However, point-cloud data are inherently unordered,\nmassive, and position-sensitive, making it challenging to produce compact and\naligned point-level token sequences that preserve detailed structural\ninformation. Therefore, we present CoPLOT, a novel Collaborative perception\nframework that utilizes Point-Level Optimized Tokens. It incorporates a\npoint-native processing pipeline, including token reordering, sequence\nmodeling, and multi-agent spatial alignment. A semantic-aware token reordering\nmodule generates adaptive 1D reorderings by leveraging scene-level and\ntoken-level semantic information. A frequency-enhanced state space model\ncaptures long-range sequence dependencies across both spatial and spectral\ndomains, improving the differentiation between foreground tokens and background\nclutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop\nprocess, combining global agent-level correction with local token-level\nrefinement to mitigate localization noise. Extensive experiments on both\nsimulated and real-world datasets show that CoPLOT outperforms state-of-the-art\nmodels, with even lower communication and computation overhead. Code will be\navailable at https://github.com/CheeryLeeyy/CoPLOT.", "AI": {"tldr": "\u63d0\u51faCoPLOT\u6846\u67b6\u7528\u4e8e\u534f\u4f5c\u611f\u77e5\uff0c\u91c7\u7528\u70b9\u7ea7\u4f18\u5316\u4ee4\u724c\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u4e14\u5f00\u9500\u66f4\u4f4e\u3002", "motivation": "\u73b0\u6709\u534f\u4f5c\u611f\u77e5\u65b9\u6cd5\u4f7f\u75282D BEV\u8868\u793a\u4f1a\u4e22\u5f03\u5173\u952e3D\u7ed3\u6784\u7ebf\u7d22\uff0c\u5f71\u54cd\u76ee\u6807\u8bc6\u522b\u548c\u5b9a\u4f4d\u3002", "method": "\u5f15\u5165\u70b9\u7ea7\u4ee4\u724c\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u63d0\u51faCoPLOT\u6846\u67b6\uff0c\u5305\u542b\u4ee4\u724c\u91cd\u6392\u5e8f\u3001\u5e8f\u5217\u5efa\u6a21\u548c\u591a\u667a\u80fd\u4f53\u7a7a\u95f4\u5bf9\u9f50\u7b49\u6a21\u5757\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCoPLOT\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u4e14\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\u66f4\u4f4e\u3002", "conclusion": "CoPLOT\u662f\u4e00\u79cd\u6709\u6548\u7684\u534f\u4f5c\u611f\u77e5\u6846\u67b6\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u548c\u8f83\u4f4e\u7684\u5f00\u9500\u3002"}}
{"id": "2508.19875", "pdf": "https://arxiv.org/pdf/2508.19875", "abs": "https://arxiv.org/abs/2508.19875", "authors": ["Hui Zhang", "Jianghui Cai", "Haifeng Yang", "Ali Luo", "Yuqing Yang", "Xiao Kong", "Zhichao Ding", "Lichan Zhou", "Qin Han"], "title": "Sky Background Building of Multi-objective Fiber spectra Based on Mutual Information Network", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Sky background subtraction is a critical step in Multi-objective Fiber\nspectra process. However, current subtraction relies mainly on sky fiber\nspectra to build Super Sky. These average spectra are lacking in the modeling\nof the environment surrounding the objects. To address this issue, a sky\nbackground estimation model: Sky background building based on Mutual\nInformation (SMI) is proposed. SMI based on mutual information and incremental\ntraining approach. It utilizes spectra from all fibers in the plate to estimate\nthe sky background. SMI contains two main networks, the first network applies a\nwavelength calibration module to extract sky features from spectra, and can\neffectively solve the feature shift problem according to the corresponding\nemission position. The second network employs an incremental training approach\nto maximize mutual information between representations of different spectra to\ncapturing the common component. Then, it minimizes the mutual information\nbetween adjoining spectra representations to obtain individual components. This\nnetwork yields an individual sky background at each location of the object. To\nverify the effectiveness of the method in this paper, we conducted experiments\non the spectra of LAMOST. Results show that SMI can obtain a better object sky\nbackground during the observation, especially in the blue end.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u5929\u7a7a\u80cc\u666f\u4f30\u8ba1\u6a21\u578bSMI\u7528\u4e8e\u591a\u76ee\u6807\u5149\u7ea4\u5149\u8c31\u5904\u7406\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u89c2\u6d4b\u4e2d\u80fd\u83b7\u5f97\u66f4\u597d\u7684\u76ee\u6807\u5929\u7a7a\u80cc\u666f\uff0c\u5c24\u5176\u5728\u84dd\u7aef\u3002", "motivation": "\u5f53\u524d\u5929\u7a7a\u80cc\u666f\u51cf\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5929\u7a7a\u5149\u7ea4\u5149\u8c31\u6784\u5efa\u8d85\u7ea7\u5929\u7a7a\uff0c\u7f3a\u4e4f\u5bf9\u76ee\u6807\u5468\u56f4\u73af\u5883\u7684\u5efa\u6a21\u3002", "method": "SMI\u57fa\u4e8e\u4e92\u4fe1\u606f\u548c\u589e\u91cf\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u677f\u4e2d\u6240\u6709\u5149\u7ea4\u7684\u5149\u8c31\u4f30\u8ba1\u5929\u7a7a\u80cc\u666f\uff0c\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u7f51\u7edc\uff0c\u5206\u522b\u8fdb\u884c\u6ce2\u957f\u6821\u51c6\u548c\u6700\u5927\u5316\u3001\u6700\u5c0f\u5316\u4e92\u4fe1\u606f\u64cd\u4f5c\u3002", "result": "\u5728LAMOST\u5149\u8c31\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSMI\u80fd\u5728\u89c2\u6d4b\u4e2d\u83b7\u5f97\u66f4\u597d\u7684\u76ee\u6807\u5929\u7a7a\u80cc\u666f\uff0c\u5c24\u5176\u5728\u84dd\u7aef\u3002", "conclusion": "SMI\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5728\u591a\u76ee\u6807\u5149\u7ea4\u5149\u8c31\u5904\u7406\u4e2d\u83b7\u5f97\u66f4\u597d\u7684\u5929\u7a7a\u80cc\u666f\u4f30\u8ba1\u3002"}}
{"id": "2508.19641", "pdf": "https://arxiv.org/pdf/2508.19641", "abs": "https://arxiv.org/abs/2508.19641", "authors": ["Lincan Li", "Bolin Shen", "Chenxi Zhao", "Yuxiang Sun", "Kaixiang Zhao", "Shirui Pan", "Yushun Dong"], "title": "Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Graph-structured data, which captures non-Euclidean relationships and\ninteractions between entities, is growing in scale and complexity. As a result,\ntraining state-of-the-art graph machine learning (GML) models have become\nincreasingly resource-intensive, turning these models and data into invaluable\nIntellectual Property (IP). To address the resource-intensive nature of model\ntraining, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an\nefficient solution by leveraging third-party cloud services for model\ndevelopment and management. However, deploying such models in GMLaaS also\nexposes them to potential threats from attackers. Specifically, while the APIs\nwithin a GMLaaS system provide interfaces for users to query the model and\nreceive outputs, they also allow attackers to exploit and steal model\nfunctionalities or sensitive training data, posing severe threats to the safety\nof these GML models and the underlying graph data. To address these challenges,\nthis survey systematically introduces the first taxonomy of threats and\ndefenses at the level of both GML model and graph-structured data. Such a\ntailored taxonomy facilitates an in-depth understanding of GML IP protection.\nFurthermore, we present a systematic evaluation framework to assess the\neffectiveness of IP protection methods, introduce a curated set of benchmark\ndatasets across various domains, and discuss their application scopes and\nfuture challenges. Finally, we establish an open-sourced versatile library\nnamed PyGIP, which evaluates various attack and defense techniques in GMLaaS\nscenarios and facilitates the implementation of existing benchmark methods. The\nlibrary resource can be accessed at: https://labrai.github.io/PyGIP. We believe\nthis survey will play a fundamental role in intellectual property protection\nfor GML and provide practical recipes for the GML community.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u56fe\u673a\u5668\u5b66\u4e60(GMLaaS)\u9762\u4e34\u7684\u5b89\u5168\u6311\u6218\uff0c\u63d0\u51fa\u5a01\u80c1\u4e0e\u9632\u5fa1\u5206\u7c7b\uff0c\u5efa\u7acb\u8bc4\u4f30\u6846\u67b6\u3001\u5f15\u5165\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u5f00\u6e90\u5e93PyGIP\uff0c\u52a9\u529bGML\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u3002", "motivation": "\u56fe\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u8d44\u6e90\u5bc6\u96c6\uff0cGMLaaS\u51fa\u73b0\u4f46\u9762\u4e34\u653b\u51fb\u8005\u5a01\u80c1\uff0c\u9700\u4fdd\u62a4GML\u77e5\u8bc6\u4ea7\u6743\u3002", "method": "\u63d0\u51faGML\u6a21\u578b\u548c\u56fe\u7ed3\u6784\u6570\u636e\u5c42\u9762\u7684\u5a01\u80c1\u4e0e\u9632\u5fa1\u5206\u7c7b\uff0c\u5efa\u7acb\u8bc4\u4f30\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u5f00\u6e90\u5e93PyGIP\u3002", "result": "\u5b8c\u6210\u4e86\u5a01\u80c1\u4e0e\u9632\u5fa1\u5206\u7c7b\uff0c\u6709\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3001\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5f00\u6e90\u5e93PyGIP\u3002", "conclusion": "\u8be5\u8c03\u67e5\u5bf9GML\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u6709\u57fa\u7840\u4f5c\u7528\uff0c\u4e3aGML\u793e\u533a\u63d0\u4f9b\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2508.19878", "pdf": "https://arxiv.org/pdf/2508.19878", "abs": "https://arxiv.org/abs/2508.19878", "authors": ["Matthew R. Wilson", "Jack A. Smith", "Michael J. Strain", "Xavier Porte"], "title": "On-chip wave chaos for photonic extreme learning", "categories": ["physics.optics", "cond-mat.dis-nn", "cs.LG", "nlin.CD"], "comment": null, "summary": "The increase in demand for scalable and energy efficient artificial neural\nnetworks has put the focus on novel hardware solutions. Integrated photonics\noffers a compact, parallel and ultra-fast information processing platform,\nspecially suited for extreme learning machine (ELM) architectures. Here we\nexperimentally demonstrate a chip-scale photonic ELM based on wave chaos\ninterference in a stadium microcavity. By encoding the input information in the\nwavelength of an external single-frequency tunable laser source, we leverage\nthe high sensitivity to wavelength of injection in such photonic resonators. We\nfabricate the microcavity with direct laser writing of SU-8 polymer on glass. A\nscattering wall surrounding the stadium operates as readout layer, collecting\nthe light associated with the cavity's leaky modes. We report uncorrelated and\naperiodic behavior in the speckles of the scattering barrier from a high\nresolution scan of the input wavelength. Finally, we characterize the system's\nperformance at classification in four qualitatively different benchmark tasks.\nAs we can control the number of output nodes of our ELM by measuring different\nparts of the scattering barrier, we demonstrate the capability to optimize our\nphotonic ELM's readout size to the performance required for each task.", "AI": {"tldr": "\u6587\u7ae0\u5b9e\u9a8c\u5c55\u793a\u57fa\u4e8e\u4f53\u80b2\u573a\u5fae\u8154\u6ce2\u6df7\u6c8c\u5e72\u6d89\u7684\u82af\u7247\u7ea7\u5149\u5b50ELM\uff0c\u8868\u5f81\u5176\u5206\u7c7b\u6027\u80fd\u5e76\u5c55\u793a\u4f18\u5316\u8bfb\u51fa\u5927\u5c0f\u7684\u80fd\u529b\u3002", "motivation": "\u53ef\u6269\u5c55\u4e14\u8282\u80fd\u7684\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u9700\u6c42\u589e\u52a0\uff0c\u96c6\u6210\u5149\u5b50\u5b66\u9002\u5408ELM\u67b6\u6784\uff0c\u9700\u65b0\u786c\u4ef6\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5916\u90e8\u5355\u9891\u53ef\u8c03\u8c10\u6fc0\u5149\u6e90\u6ce2\u957f\u7f16\u7801\u8f93\u5165\u4fe1\u606f\uff0c\u7528\u76f4\u5199SU - 8\u805a\u5408\u7269\u5728\u73bb\u7483\u4e0a\u5236\u4f5c\u5fae\u8154\uff0c\u901a\u8fc7\u6563\u5c04\u58c1\u4f5c\u4e3a\u8bfb\u51fa\u5c42\u6536\u96c6\u5149\u3002", "result": "\u8f93\u5165\u6ce2\u957f\u9ad8\u5206\u8fa8\u7387\u626b\u63cf\u4e0b\uff0c\u6563\u5c04\u58c1\u6563\u6591\u5448\u73b0\u4e0d\u76f8\u5173\u548c\u975e\u5468\u671f\u6027\u884c\u4e3a\u3002", "conclusion": "\u53ef\u901a\u8fc7\u6d4b\u91cf\u6563\u5c04\u58c1\u4e0d\u540c\u90e8\u5206\u63a7\u5236ELM\u8f93\u51fa\u8282\u70b9\u6570\u91cf\uff0c\u4f18\u5316\u5149\u5b50ELM\u8bfb\u51fa\u5927\u5c0f\u4ee5\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u6027\u80fd\u8981\u6c42\u3002"}}
{"id": "2508.19667", "pdf": "https://arxiv.org/pdf/2508.19667", "abs": "https://arxiv.org/abs/2508.19667", "authors": ["Chenghan Yang", "Ruiyu Zhao", "Yang Liu", "Ling Jiang"], "title": "Survey of Specialized Large Language Model", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 1 figures", "summary": "The rapid evolution of specialized large language models (LLMs) has\ntransitioned from simple domain adaptation to sophisticated native\narchitectures, marking a paradigm shift in AI development. This survey\nsystematically examines this progression across healthcare, finance, legal, and\ntechnical domains. Besides the wide use of specialized LLMs, technical\nbreakthrough such as the emergence of domain-native designs beyond fine-tuning,\ngrowing emphasis on parameter efficiency through sparse computation and\nquantization, increasing integration of multimodal capabilities and so on are\napplied to recent LLM agent. Our analysis reveals how these innovations address\nfundamental limitations of general-purpose LLMs in professional applications,\nwith specialized models consistently performance gains on domain-specific\nbenchmarks. The survey further highlights the implications for E-Commerce field\nto fill gaps in the field.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e13\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u7b80\u5355\u9886\u57df\u9002\u914d\u5230\u590d\u6742\u539f\u751f\u67b6\u6784\u7684\u6f14\u53d8\uff0c\u5206\u6790\u5404\u9886\u57df\u5e94\u7528\u53ca\u521b\u65b0\uff0c\u6307\u51fa\u5176\u89e3\u51b3\u901a\u7528\u6a21\u578b\u5c40\u9650\uff0c\u8fd8\u63d0\u53ca\u5bf9\u7535\u5546\u9886\u57df\u7684\u610f\u4e49\u3002", "motivation": "\u968f\u7740\u4e13\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u7cfb\u7edf\u7814\u7a76\u5176\u4ece\u7b80\u5355\u9002\u914d\u5230\u590d\u6742\u67b6\u6784\u7684\u6f14\u53d8\u53ca\u5728\u591a\u9886\u57df\u5e94\u7528\u3002", "method": "\u5bf9\u533b\u7597\u3001\u91d1\u878d\u3001\u6cd5\u5f8b\u548c\u6280\u672f\u7b49\u9886\u57df\u4e13\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u8fdb\u884c\u7cfb\u7edf\u8003\u5bdf\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4e13\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u521b\u65b0\u80fd\u89e3\u51b3\u901a\u7528\u6a21\u578b\u5728\u4e13\u4e1a\u5e94\u7528\u4e2d\u7684\u5c40\u9650\uff0c\u5728\u7279\u5b9a\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5f3a\u8c03\u8fd9\u4e9b\u8fdb\u5c55\u5bf9\u7535\u5546\u9886\u57df\u6709\u586b\u8865\u7a7a\u767d\u7684\u610f\u4e49\u3002"}}
{"id": "2508.19910", "pdf": "https://arxiv.org/pdf/2508.19910", "abs": "https://arxiv.org/abs/2508.19910", "authors": ["Sergio Hernandez", "Christophe Peucheret", "Francesco Da Ros", "Darko Zibar"], "title": "Experimental End-to-End Optimization of Directly Modulated Laser-based IM/DD Transmission", "categories": ["eess.SP", "cs.LG"], "comment": "10 pages, 10 figures, submitted to journal of lightwave technology", "summary": "Directly modulated lasers (DMLs) are an attractive technology for short-reach\nintensity modulation and direct detection communication systems. However, their\ncomplex nonlinear dynamics make the modeling and optimization of DML-based\nsystems challenging. In this paper, we study the end-to-end optimization of\nDML-based systems based on a data-driven surrogate model trained on\nexperimental data. The end-to-end optimization includes the pulse shaping and\nequalizer filters, the bias current and the modulation radio-frequency (RF)\npower applied to the laser. The performance of the end-to-end optimization\nscheme is tested on the experimental setup and compared to 4 different\nbenchmark schemes based on linear and nonlinear receiver-side equalization. The\nresults show that the proposed end-to-end scheme is able to deliver better\nperformance throughout the studied symbol rates and transmission distances\nwhile employing lower modulation RF power, fewer filter taps and utilizing a\nsmaller signal bandwidth.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u5b9e\u9a8c\u6570\u636e\u8bad\u7ec3\u7684\u6570\u636e\u9a71\u52a8\u4ee3\u7406\u6a21\u578b\uff0c\u5bf9\u57fa\u4e8e\u76f4\u63a5\u8c03\u5236\u6fc0\u5149\u5668\uff08DML\uff09\u7684\u7cfb\u7edf\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u5e76\u4e0e4\u79cd\u57fa\u51c6\u65b9\u6848\u5bf9\u6bd4\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6848\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u76f4\u63a5\u8c03\u5236\u6fc0\u5149\u5668\u590d\u6742\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4f7f\u57fa\u4e8eDML\u7684\u7cfb\u7edf\u5efa\u6a21\u548c\u4f18\u5316\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u7aef\u5230\u7aef\u4f18\u5316\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5b9e\u9a8c\u6570\u636e\u8bad\u7ec3\u6570\u636e\u9a71\u52a8\u4ee3\u7406\u6a21\u578b\uff0c\u5bf9\u57fa\u4e8eDML\u7684\u7cfb\u7edf\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u5305\u62ec\u8109\u51b2\u6574\u5f62\u548c\u5747\u8861\u5668\u6ee4\u6ce2\u5668\u3001\u504f\u7f6e\u7535\u6d41\u548c\u8c03\u5236\u5c04\u9891\u529f\u7387\u7b49\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7aef\u5230\u7aef\u65b9\u6848\u5728\u7814\u7a76\u7684\u7b26\u53f7\u7387\u548c\u4f20\u8f93\u8ddd\u79bb\u8303\u56f4\u5185\uff0c\u80fd\u4ee5\u66f4\u4f4e\u7684\u8c03\u5236\u5c04\u9891\u529f\u7387\u3001\u66f4\u5c11\u7684\u6ee4\u6ce2\u5668\u62bd\u5934\u548c\u66f4\u5c0f\u7684\u4fe1\u53f7\u5e26\u5bbd\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7aef\u5230\u7aef\u4f18\u5316\u65b9\u6848\u4f18\u4e8e\u57fa\u4e8e\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u63a5\u6536\u7aef\u5747\u8861\u7684\u57fa\u51c6\u65b9\u6848\u3002"}}
{"id": "2508.20030", "pdf": "https://arxiv.org/pdf/2508.20030", "abs": "https://arxiv.org/abs/2508.20030", "authors": ["Kangwei Xu", "Denis Schwachhofer", "Jason Blocklove", "Ilia Polian", "Peter Domanski", "Dirk Pfl\u00fcger", "Siddharth Garg", "Ramesh Karri", "Ozgur Sinanoglu", "Johann Knechtel", "Zhuorui Zhao", "Ulf Schlichtmann", "Bing Li"], "title": "Large Language Models (LLMs) for Electronic Design Automation (EDA)", "categories": ["eess.SY", "cs.AI", "cs.AR", "cs.LG", "cs.SY"], "comment": "Accepted by IEEE International System-on-Chip Conference", "summary": "With the growing complexity of modern integrated circuits, hardware engineers\nare required to devote more effort to the full design-to-manufacturing\nworkflow. This workflow involves numerous iterations, making it both\nlabor-intensive and error-prone. Therefore, there is an urgent demand for more\nefficient Electronic Design Automation (EDA) solutions to accelerate hardware\ndevelopment. Recently, large language models (LLMs) have shown remarkable\nadvancements in contextual comprehension, logical reasoning, and generative\ncapabilities. Since hardware designs and intermediate scripts can be\nrepresented as text, integrating LLM for EDA offers a promising opportunity to\nsimplify and even automate the entire workflow. Accordingly, this paper\nprovides a comprehensive overview of incorporating LLMs into EDA, with emphasis\non their capabilities, limitations, and future opportunities. Three case\nstudies, along with their outlook, are introduced to demonstrate the\ncapabilities of LLMs in hardware design, testing, and optimization. Finally,\nfuture directions and challenges are highlighted to further explore the\npotential of LLMs in shaping the next-generation EDA, providing valuable\ninsights for researchers interested in leveraging advanced AI technologies for\nEDA.", "AI": {"tldr": "\u73b0\u4ee3\u96c6\u6210\u7535\u8def\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u4f20\u7edf\u8bbe\u8ba1\u6d41\u7a0b\u4f4e\u6548\uff0c\u672c\u6587\u5168\u9762\u4ecb\u7ecd\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u878d\u5165\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\uff08EDA\uff09\uff0c\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u5176\u80fd\u529b\uff0c\u6307\u51fa\u672a\u6765\u65b9\u5411\u548c\u6311\u6218\u3002", "motivation": "\u73b0\u4ee3\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u6d41\u7a0b\u590d\u6742\u3001\u52b3\u52a8\u5bc6\u96c6\u4e14\u6613\u51fa\u9519\uff0c\u6025\u9700\u66f4\u9ad8\u6548\u7684 EDA \u89e3\u51b3\u65b9\u6848\uff0c\u800c LLMs \u80fd\u529b\u63d0\u5347\uff0c\u4e3a EDA \u5e26\u6765\u673a\u9047\u3002", "method": "\u5bf9\u5c06 LLMs \u878d\u5165 EDA \u8fdb\u884c\u5168\u9762\u6982\u8ff0\uff0c\u5f15\u5165\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u5c55\u793a\u4e86 LLMs \u5728\u786c\u4ef6\u8bbe\u8ba1\u3001\u6d4b\u8bd5\u548c\u4f18\u5316\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "\u6307\u51fa\u672a\u6765\u65b9\u5411\u548c\u6311\u6218\uff0c\u4e3a\u5229\u7528\u5148\u8fdb AI \u6280\u672f\u8fdb\u884c EDA \u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2508.19697", "pdf": "https://arxiv.org/pdf/2508.19697", "abs": "https://arxiv.org/abs/2508.19697", "authors": ["Chao Huang", "Zefeng Zhang", "Juewei Yue", "Quangang Li", "Chuang Zhang", "Tingwen Liu"], "title": "Safety Alignment Should Be Made More Than Just A Few Attention Heads", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Current safety alignment for large language models(LLMs) continues to present\nvulnerabilities, given that adversarial prompting can effectively bypass their\nsafety measures.Our investigation shows that these safety mechanisms\npredominantly depend on a limited subset of attention heads: removing or\nablating these heads can severely compromise model safety. To identify and\nevaluate these safety-critical components, we introduce RDSHA, a targeted\nablation method that leverages the model's refusal direction to pinpoint\nattention heads mostly responsible for safety behaviors. Further analysis shows\nthat existing jailbreak attacks exploit this concentration by selectively\nbypassing or manipulating these critical attention heads. To address this\nissue, we propose AHD, a novel training strategy designed to promote the\ndistributed encoding of safety-related behaviors across numerous attention\nheads. Experimental results demonstrate that AHD successfully distributes\nsafety-related capabilities across more attention heads. Moreover, evaluations\nunder several mainstream jailbreak attacks show that models trained with AHD\nexhibit considerably stronger safety robustness, while maintaining overall\nfunctional utility.", "AI": {"tldr": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u6709\u6f0f\u6d1e\uff0c\u63d0\u51faRDSHA\u8bc6\u522b\u5173\u952e\u6ce8\u610f\u529b\u5934\uff0c\u63d0\u51faAHD\u8bad\u7ec3\u7b56\u7565\u63d0\u5347\u6a21\u578b\u5b89\u5168\u9c81\u68d2\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5f53\u524d\u5b89\u5168\u5bf9\u9f50\u5b58\u5728\u6f0f\u6d1e\uff0c\u5bf9\u6297\u6027\u63d0\u793a\u53ef\u7ed5\u8fc7\u5b89\u5168\u63aa\u65bd\u3002", "method": "\u5f15\u5165RDSHA\u65b9\u6cd5\u8bc6\u522b\u5bf9\u5b89\u5168\u884c\u4e3a\u8d1f\u8d23\u7684\u6ce8\u610f\u529b\u5934\uff1b\u63d0\u51faAHD\u8bad\u7ec3\u7b56\u7565\u4f7f\u5b89\u5168\u76f8\u5173\u884c\u4e3a\u7f16\u7801\u5206\u6563\u5230\u66f4\u591a\u6ce8\u610f\u529b\u5934\u3002", "result": "AHD\u6210\u529f\u5c06\u5b89\u5168\u76f8\u5173\u80fd\u529b\u5206\u6563\u5230\u66f4\u591a\u6ce8\u610f\u529b\u5934\uff0c\u5728\u4e3b\u6d41\u8d8a\u72f1\u653b\u51fb\u8bc4\u4f30\u4e2d\uff0c\u7528AHD\u8bad\u7ec3\u7684\u6a21\u578b\u5b89\u5168\u9c81\u68d2\u6027\u66f4\u5f3a\uff0c\u4e14\u4fdd\u6301\u6574\u4f53\u529f\u80fd\u5b9e\u7528\u6027\u3002", "conclusion": "AHD\u8bad\u7ec3\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.19708", "pdf": "https://arxiv.org/pdf/2508.19708", "abs": "https://arxiv.org/abs/2508.19708", "authors": ["B. Sankar", "Dibakar Sen"], "title": "Attention is also needed for form design", "categories": ["cs.HC", "cs.AI", "68T07, 68T42, 68T50", "I.2; J.5; J.6"], "comment": "55 pages, 45 figures,", "summary": "Conventional product design is a cognitively demanding process, limited by\nits time-consuming nature, reliance on subjective expertise, and the opaque\ntranslation of inspiration into tangible concepts. This research introduces a\nnovel, attention-aware framework that integrates two synergistic systems:\nEUPHORIA, an immersive Virtual Reality environment using eye-tracking to\nimplicitly capture a designer's aesthetic preferences, and RETINA, an agentic\nAI pipeline that translates these implicit preferences into concrete design\noutputs. The foundational principles were validated in a two-part study. An\ninitial study correlated user's implicit attention with explicit preference and\nthe next one correlated mood to attention. A comparative study where 4\ndesigners solved challenging design problems using 4 distinct workflows, from a\nmanual process to an end-to-end automated pipeline, showed the integrated\nEUPHORIA-RETINA workflow was over 4 times more time-efficient than the\nconventional method. A panel of 50 design experts evaluated the 16 final\nrenderings. Designs generated by the fully automated system consistently\nreceived the highest Worthiness (calculated by an inverse Plackett-Luce model\nbased on gradient descent optimization) and Design Effectiveness scores,\nindicating superior quality across 8 criteria: novelty, visual appeal,\nemotional resonance, clarity of purpose, distinctiveness of silhouette, implied\nmateriality, proportional balance, & adherence to the brief. This research\npresents a validated paradigm shift from traditional Computer-Assisted Design\n(CAD) to a collaborative model of Designer-Assisting Computers (DAC). By\nautomating logistical and skill-dependent generative tasks, the proposed\nframework elevates the designer's role to that of a creative director,\nsynergizing human intuition with the generative power of agentic AI to produce\nhigher-quality designs more efficiently.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u578b\u6ce8\u610f\u529b\u611f\u77e5\u6846\u67b6\uff0c\u7ed3\u5408EUPHORIA\u548cRETINA\u7cfb\u7edf\uff0c\u7ecf\u7814\u7a76\u9a8c\u8bc1\u5176\u6bd4\u4f20\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u66f4\u7701\u65f6\u3001\u8bbe\u8ba1\u8d28\u91cf\u66f4\u9ad8\uff0c\u5b9e\u73b0\u4eceCAD\u5230DAC\u7684\u8303\u5f0f\u8f6c\u53d8\u3002", "motivation": "\u4f20\u7edf\u4ea7\u54c1\u8bbe\u8ba1\u8fc7\u7a0b\u8ba4\u77e5\u8981\u6c42\u9ad8\u3001\u8017\u65f6\u4e45\u3001\u4f9d\u8d56\u4e3b\u89c2\u7ecf\u9a8c\u4e14\u7075\u611f\u8f6c\u5316\u4e0d\u900f\u660e\uff0c\u9700\u6539\u8fdb\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u7ed3\u5408EUPHORIA\u548cRETINA\u7684\u6ce8\u610f\u529b\u611f\u77e5\u6846\u67b6\uff0c\u8fdb\u884c\u4e24\u90e8\u5206\u57fa\u7840\u539f\u7406\u9a8c\u8bc1\u7814\u7a76\u548c\u5bf9\u6bd4\u7814\u7a76\uff0c\u8ba9\u8bbe\u8ba1\u5e08\u7528\u4e0d\u540c\u5de5\u4f5c\u6d41\u89e3\u51b3\u95ee\u9898\uff0c\u7531\u4e13\u5bb6\u8bc4\u4f30\u8bbe\u8ba1\u6210\u679c\u3002", "result": "EUPHORIA - RETINA\u5de5\u4f5c\u6d41\u6bd4\u4f20\u7edf\u65b9\u6cd5\u65f6\u95f4\u6548\u7387\u9ad84\u500d\u591a\uff0c\u5168\u81ea\u52a8\u7cfb\u7edf\u751f\u6210\u7684\u8bbe\u8ba1\u5728\u591a\u4e2a\u6807\u51c6\u4e0a\u5f97\u5206\u6700\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u4eceCAD\u5230DAC\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u80fd\u5c06\u4eba\u7c7b\u76f4\u89c9\u4e0eAI\u751f\u6210\u80fd\u529b\u7ed3\u5408\uff0c\u9ad8\u6548\u4ea7\u51fa\u9ad8\u8d28\u91cf\u8bbe\u8ba1\u3002"}}
{"id": "2508.20068", "pdf": "https://arxiv.org/pdf/2508.20068", "abs": "https://arxiv.org/abs/2508.20068", "authors": ["Chengzu Li", "Wenshan Wu", "Huanyu Zhang", "Qingtao Li", "Zeyu Gao", "Yan Xia", "Jos\u00e9 Hern\u00e1ndez-Orallo", "Ivan Vuli\u0107", "Furu Wei"], "title": "11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": "9 pages, 4 figures (22 pages, 7 figures, 7 tables including\n  references and appendices)", "summary": "For human cognitive process, spatial reasoning and perception are closely\nentangled, yet the nature of this interplay remains underexplored in the\nevaluation of multimodal large language models (MLLMs). While recent MLLM\nadvancements show impressive performance on reasoning, their capacity for\nhuman-like spatial cognition remains an open question. In this work, we\nintroduce a systematic evaluation framework to assess the spatial reasoning\nabilities of state-of-the-art MLLMs relative to human performance. Central to\nour work is 11Plus-Bench, a high-quality benchmark derived from realistic\nstandardized spatial aptitude tests. 11Plus-Bench also features fine-grained\nexpert annotations of both perceptual complexity and reasoning process,\nenabling detailed instance-level analysis of model behavior. Through extensive\nexperiments across 14 MLLMs and human evaluation, we find that current MLLMs\nexhibit early signs of spatial cognition. Despite a large performance gap\ncompared to humans, MLLMs' cognitive profiles resemble those of humans in that\ncognitive effort correlates strongly with reasoning-related complexity.\nHowever, instance-level performance in MLLMs remains largely random, whereas\nhuman correctness is highly predictable and shaped by abstract pattern\ncomplexity. These findings highlight both emerging capabilities and limitations\nin current MLLMs' spatial reasoning capabilities and provide actionable\ninsights for advancing model design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u752811Plus - Bench\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30MLLMs\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0MLLMs\u6709\u7a7a\u95f4\u8ba4\u77e5\u8ff9\u8c61\u4f46\u4e0e\u4eba\u7c7b\u5dee\u8ddd\u5927\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u4eba\u7c7b\u7a7a\u95f4\u8ba4\u77e5\u4e0e\u63a8\u7406\u4ea4\u4e92\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8bc4\u4f30\u5176\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u752811Plus - Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u540814\u4e2aMLLMs\u5b9e\u9a8c\u548c\u4eba\u7c7b\u8bc4\u4f30\u3002", "result": "\u5f53\u524dMLLMs\u6709\u7a7a\u95f4\u8ba4\u77e5\u65e9\u671f\u8ff9\u8c61\uff0c\u4e0e\u4eba\u7c7b\u6709\u8f83\u5927\u6027\u80fd\u5dee\u8ddd\uff0c\u8ba4\u77e5\u7279\u5f81\u6709\u76f8\u4f3c\u6027\uff0c\u4f46\u5b9e\u4f8b\u7ea7\u8868\u73b0MLLMs\u968f\u673a\uff0c\u4eba\u7c7b\u8868\u73b0\u53ef\u9884\u6d4b\u3002", "conclusion": "\u6307\u51fa\u5f53\u524dMLLMs\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\uff0c\u4e3a\u6a21\u578b\u8bbe\u8ba1\u6539\u8fdb\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2508.19724", "pdf": "https://arxiv.org/pdf/2508.19724", "abs": "https://arxiv.org/abs/2508.19724", "authors": ["Aritra Dutta", "Swapnanil Mukherjee", "Deepanway Ghosal", "Somak Aditya"], "title": "NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Commonsense visual-question answering often hinges on knowledge that is\nmissing from the image or the question. Small vision-language models (sVLMs)\nsuch as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative\ncounterparts. To study the effect of careful commonsense knowledge integration\non sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural\nlanguage facts, (ii) prompts an LLM to craft natural language explanations, and\n(iii) feeds both signals to sVLMs respectively across two commonsense VQA\ndatasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts\nretrieved using a fine-tuned ColBERTv2 and an object information-enriched\nprompt yield explanations that largely cut down hallucinations, while lifting\nthe end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA\nand other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B\nand SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional\nfinetuning using noise-robust losses (such as symmetric cross entropy and\ngeneralised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our\nfindings expose when LLM-based commonsense knowledge beats retrieval from\ncommonsense knowledge bases, how noise-aware training stabilises small models\nin the context of external knowledge augmentation, and why parameter-efficient\ncommonsense reasoning is now within reach for 250M models.", "AI": {"tldr": "\u63d0\u51fa\u7aef\u5230\u7aef\u6846\u67b6NLKI\uff0c\u5c06\u5e38\u8bc6\u77e5\u8bc6\u96c6\u6210\u5230\u5c0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5206\u6790\u4e0d\u540c\u7b56\u7565\u6548\u679c\u3002", "motivation": "\u7814\u7a76\u4ed4\u7ec6\u96c6\u6210\u5e38\u8bc6\u77e5\u8bc6\u5bf9\u5c0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5e38\u8bc6\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faNLKI\u6846\u67b6\uff0c\u5305\u62ec\u68c0\u7d22\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u3001\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u89e3\u91ca\uff0c\u5c06\u4fe1\u53f7\u8f93\u5165\u5c0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff1b\u4f7f\u7528\u5fae\u8c03\u7684ColBERTv2\u68c0\u7d22\u4e8b\u5b9e\uff1b\u7528\u6297\u566a\u58f0\u635f\u5931\u51fd\u6570\u5fae\u8c03\u3002", "result": "\u51cf\u5c11\u5e7b\u89c9\uff0c\u7aef\u5230\u7aef\u7b54\u6848\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u53477%\uff0c\u8ba9\u5c0f\u6a21\u578b\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u4e2d\u7b49\u6a21\u578b\uff1b\u6297\u566a\u58f0\u635f\u5931\u5fae\u8c03\u5728\u4e0d\u540c\u6570\u636e\u96c6\u989d\u5916\u63d0\u53472.5% - 5.5%\u3002", "conclusion": "\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u5e38\u8bc6\u77e5\u8bc6\u4f55\u65f6\u4f18\u4e8e\u77e5\u8bc6\u5e93\u68c0\u7d22\uff0c\u6297\u566a\u58f0\u8bad\u7ec3\u7a33\u5b9a\u5c0f\u6a21\u578b\uff0c250M\u6a21\u578b\u5b9e\u73b0\u9ad8\u6548\u5e38\u8bc6\u63a8\u7406\u6210\u4e3a\u53ef\u80fd\u3002"}}
{"id": "2508.20072", "pdf": "https://arxiv.org/pdf/2508.20072", "abs": "https://arxiv.org/abs/2508.20072", "authors": ["Zhixuan Liang", "Yizhuo Li", "Tianshuo Yang", "Chengyue Wu", "Sitong Mao", "Liuao Pei", "Xiaokang Yang", "Jiangmiao Pang", "Yao Mu", "Ping Luo"], "title": "Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "15 pages", "summary": "Vision-Language-Action (VLA) models adapt large vision-language backbones to\nmap images and instructions to robot actions. However, prevailing VLA decoders\neither generate actions autoregressively in a fixed left-to-right order or\nattach continuous diffusion or flow matching heads outside the backbone,\ndemanding specialized training and iterative sampling that hinder a unified,\nscalable architecture. We present Discrete Diffusion VLA, a single-transformer\npolicy that models discretized action chunks with discrete diffusion and is\ntrained with the same cross-entropy objective as the VLM backbone. The design\nretains diffusion's progressive refinement paradigm while remaining natively\ncompatible with the discrete token interface of VLMs. Our method achieves an\nadaptive decoding order that resolves easy action elements before harder ones\nand uses secondary remasking to revisit uncertain predictions across refinement\nrounds, which improves consistency and enables robust error correction. This\nunified decoder preserves pretrained vision language priors, supports parallel\ndecoding, breaks the autoregressive bottleneck, and reduces the number of\nfunction evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO,\n71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv\nBridge, improving over both autoregressive and continuous diffusion baselines.\nThese findings indicate that discrete-diffusion action decoder supports precise\naction modeling and consistent training, laying groundwork for scaling VLA to\nlarger models and datasets.", "AI": {"tldr": "\u63d0\u51faDiscrete Diffusion VLA\u65b9\u6cd5\uff0c\u89e3\u51b3\u73b0\u6709VLA\u89e3\u7801\u5668\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709VLA\u89e3\u7801\u5668\u9700\u4e13\u95e8\u8bad\u7ec3\u548c\u8fed\u4ee3\u91c7\u6837\uff0c\u7f3a\u4e4f\u7edf\u4e00\u53ef\u6269\u5c55\u67b6\u6784\u3002", "method": "\u7528\u79bb\u6563\u6269\u6563\u5bf9\u79bb\u6563\u52a8\u4f5c\u5757\u5efa\u6a21\uff0c\u4ee5\u4ea4\u53c9\u71b5\u76ee\u6807\u8bad\u7ec3\uff0c\u6709\u81ea\u9002\u5e94\u89e3\u7801\u987a\u5e8f\u548c\u4e8c\u6b21\u63a9\u7801\u3002", "result": "\u5728LIBERO\u3001SimplerEnv Fractal\u548cSimplerEnv Bridge\u4e0a\u8868\u73b0\u4f18\u4e8e\u81ea\u56de\u5f52\u548c\u8fde\u7eed\u6269\u6563\u57fa\u7ebf\u3002", "conclusion": "\u79bb\u6563\u6269\u6563\u52a8\u4f5c\u89e3\u7801\u5668\u652f\u6301\u7cbe\u786e\u52a8\u4f5c\u5efa\u6a21\u548c\u4e00\u81f4\u8bad\u7ec3\uff0c\u4e3aVLA\u6269\u5c55\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.19804", "pdf": "https://arxiv.org/pdf/2508.19804", "abs": "https://arxiv.org/abs/2508.19804", "authors": ["Christian Marzahl", "Brian Napora"], "title": "A bag of tricks for real-time Mitotic Figure detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Mitotic figure (MF) detection in histopathology images is challenging due to\nlarge variations in slide scanners, staining protocols, tissue types, and the\npresence of artifacts. This paper presents a collection of training techniques\n- a bag of tricks - that enable robust, real-time MF detection across diverse\ndomains. We build on the efficient RTMDet single stage object detector to\nachieve high inference speed suitable for clinical deployment. Our method\naddresses scanner variability and tumor heterogeneity via extensive\nmulti-domain training data, balanced sampling, and careful augmentation.\nAdditionally, we employ targeted, hard negative mining on necrotic and debris\ntissue to reduce false positives. In a grouped 5-fold cross-validation across\nmultiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On\nthe preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025\nchallenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81,\noutperforming larger models and demonstrating adaptability to new, unfamiliar\ndomains. The proposed solution offers a practical trade-off between accuracy\nand speed, making it attractive for real-world clinical adoption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u7ec4\u8bad\u7ec3\u6280\u5de7\u5b9e\u73b0\u8de8\u9886\u57df\u6709\u4e1d\u5206\u88c2\u56fe\uff08MF\uff09\u5b9e\u65f6\u68c0\u6d4b\uff0c\u57fa\u4e8eRTMDet\uff0c\u5728\u591a\u6570\u636e\u96c6\u9a8c\u8bc1\u8868\u73b0\u826f\u597d\uff0c\u517c\u987e\u51c6\u786e\u6027\u4e0e\u901f\u5ea6\uff0c\u9002\u5408\u4e34\u5e8a\u5e94\u7528\u3002", "motivation": "\u7531\u4e8e\u5e7b\u706f\u7247\u626b\u63cf\u4eea\u3001\u67d3\u8272\u534f\u8bae\u3001\u7ec4\u7ec7\u7c7b\u578b\u5dee\u5f02\u53ca\u4f2a\u5f71\u5b58\u5728\uff0c\u7ec4\u7ec7\u75c5\u7406\u5b66\u56fe\u50cf\u4e2dMF\u68c0\u6d4b\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u5b9e\u73b0\u8de8\u9886\u57df\u7684\u7a33\u5065\u5b9e\u65f6\u68c0\u6d4b\u3002", "method": "\u57fa\u4e8e\u9ad8\u6548\u7684RTMDet\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u591a\u9886\u57df\u8bad\u7ec3\u6570\u636e\u3001\u5e73\u8861\u91c7\u6837\u548c\u7cbe\u5fc3\u589e\u5f3a\u89e3\u51b3\u626b\u63cf\u4eea\u53d8\u5f02\u6027\u548c\u80bf\u7624\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5bf9\u574f\u6b7b\u548c\u788e\u7247\u7ec4\u7ec7\u8fdb\u884c\u9488\u5bf9\u6027\u96be\u8d1f\u6837\u672c\u6316\u6398\u4ee5\u51cf\u5c11\u8bef\u62a5\u3002", "result": "\u5728\u591aMF\u6570\u636e\u96c6\u7684\u5206\u7ec45\u6298\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\uff0c\u6a21\u578bF1\u5206\u6570\u57280.78 - 0.84\u4e4b\u95f4\uff1b\u5728MIDOG 2025\u6311\u6218\u7684\u521d\u6b65\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u57fa\u4e8eRTMDet - S\u7684\u5355\u9636\u6bb5\u65b9\u6cd5F1\u8fbe\u52300.81\uff0c\u4f18\u4e8e\u66f4\u5927\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u65b9\u6848\u5728\u51c6\u786e\u6027\u548c\u901f\u5ea6\u4e4b\u95f4\u53d6\u5f97\u5b9e\u7528\u5e73\u8861\uff0c\u9002\u5408\u73b0\u5b9e\u4e34\u5e8a\u5e94\u7528\u3002"}}
{"id": "2508.20076", "pdf": "https://arxiv.org/pdf/2508.20076", "abs": "https://arxiv.org/abs/2508.20076", "authors": ["Xiaotong Cheng", "Setareh Maghsudi"], "title": "Anomaly Detection in Networked Bandits", "categories": ["cs.MA", "cs.LG"], "comment": null, "summary": "The nodes' interconnections on a social network often reflect their\ndependencies and information-sharing behaviors. Nevertheless, abnormal nodes,\nwhich significantly deviate from most of the network concerning patterns or\nbehaviors, can lead to grave consequences. Therefore, it is imperative to\ndesign efficient online learning algorithms that robustly learn users'\npreferences while simultaneously detecting anomalies.\n  We introduce a novel bandit algorithm to address this problem. Through\nnetwork knowledge, the method characterizes the users' preferences and\nresiduals of feature information. By learning and analyzing these preferences\nand residuals, it develops a personalized recommendation strategy for each user\nand simultaneously detects anomalies. We rigorously prove an upper bound on the\nregret of the proposed algorithm and experimentally compare it with several\nstate-of-the-art collaborative contextual bandit algorithms on both synthetic\nand real-world datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8001\u864e\u673a\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u793e\u4ea4\u7f51\u7edc\u4e2d\u5b66\u4e60\u7528\u6237\u504f\u597d\u5e76\u68c0\u6d4b\u5f02\u5e38\uff0c\u8bc1\u660e\u4e86\u7b97\u6cd5\u9057\u61be\u4e0a\u754c\u5e76\u8fdb\u884c\u5b9e\u9a8c\u5bf9\u6bd4\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u4e2d\u5f02\u5e38\u8282\u70b9\u4f1a\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\uff0c\u9700\u8981\u8bbe\u8ba1\u9ad8\u6548\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u6765\u5b66\u4e60\u7528\u6237\u504f\u597d\u5e76\u68c0\u6d4b\u5f02\u5e38\u3002", "method": "\u5f15\u5165\u65b0\u7684\u8001\u864e\u673a\u7b97\u6cd5\uff0c\u5229\u7528\u7f51\u7edc\u77e5\u8bc6\u523b\u753b\u7528\u6237\u504f\u597d\u548c\u7279\u5f81\u4fe1\u606f\u6b8b\u5dee\uff0c\u5b66\u4e60\u5206\u6790\u540e\u5236\u5b9a\u4e2a\u6027\u5316\u63a8\u8350\u7b56\u7565\u5e76\u68c0\u6d4b\u5f02\u5e38\u3002", "result": "\u4e25\u683c\u8bc1\u660e\u4e86\u7b97\u6cd5\u9057\u61be\u7684\u4e0a\u754c\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4e0e\u591a\u4e2a\u5148\u8fdb\u7b97\u6cd5\u8fdb\u884c\u4e86\u5b9e\u9a8c\u5bf9\u6bd4\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u63a8\u6d4b\u65b0\u7b97\u6cd5\u6709\u671b\u5728\u793e\u4ea4\u7f51\u7edc\u4e2d\u6709\u6548\u5b66\u4e60\u7528\u6237\u504f\u597d\u548c\u68c0\u6d4b\u5f02\u5e38\u3002"}}
{"id": "2508.20095", "pdf": "https://arxiv.org/pdf/2508.20095", "abs": "https://arxiv.org/abs/2508.20095", "authors": ["Jinhao Liang", "Sven Koenig", "Ferdinando Fioretto"], "title": "Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Multi-Robot Motion Planning (MRMP) involves generating collision-free\ntrajectories for multiple robots operating in a shared continuous workspace.\nWhile discrete multi-agent path finding (MAPF) methods are broadly adopted due\nto their scalability, their coarse discretization severely limits trajectory\nquality. In contrast, continuous optimization-based planners offer\nhigher-quality paths but suffer from the curse of dimensionality, resulting in\npoor scalability with respect to the number of robots. This paper tackles the\nlimitations of these two approaches by introducing a novel framework that\nintegrates discrete MAPF solvers with constrained generative diffusion models.\nThe resulting framework, called Discrete-Guided Diffusion (DGD), has three key\ncharacteristics: (1) it decomposes the original nonconvex MRMP problem into\ntractable subproblems with convex configuration spaces, (2) it combines\ndiscrete MAPF solutions with constrained optimization techniques to guide\ndiffusion models capture complex spatiotemporal dependencies among robots, and\n(3) it incorporates a lightweight constraint repair mechanism to ensure\ntrajectory feasibility. The proposed method sets a new state-of-the-art\nperformance in large-scale, complex environments, scaling to 100 robots while\nachieving planning efficiency and high success rates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u79bb\u6563\u5f15\u5bfc\u6269\u6563\uff08DGD\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u79bb\u6563\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u6c42\u89e3\u5668\u4e0e\u7ea6\u675f\u751f\u6210\u6269\u6563\u6a21\u578b\u89e3\u51b3\u591a\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u95ee\u9898\uff0c\u5728\u5927\u89c4\u6a21\u590d\u6742\u73af\u5883\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u79bb\u6563\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u8f68\u8ff9\u8d28\u91cf\u5dee\uff0c\u8fde\u7eed\u4f18\u5316\u89c4\u5212\u5668\u6269\u5c55\u6027\u4e0d\u4f73\uff0c\u9700\u89e3\u51b3\u4e24\u8005\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165DGD\u6846\u67b6\uff0c\u5c06\u539f\u975e\u51f8MRMP\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u5904\u7406\u5b50\u95ee\u9898\uff0c\u7ed3\u5408\u79bb\u6563MAPF\u89e3\u4e0e\u7ea6\u675f\u4f18\u5316\u6280\u672f\u5f15\u5bfc\u6269\u6563\u6a21\u578b\uff0c\u52a0\u5165\u8f7b\u91cf\u7ea7\u7ea6\u675f\u4fee\u590d\u673a\u5236\u3002", "result": "\u5728\u5927\u89c4\u6a21\u590d\u6742\u73af\u5883\u4e2d\u8fbe\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0c\u53ef\u6269\u5c55\u5230100\u4e2a\u673a\u5668\u4eba\uff0c\u89c4\u5212\u6548\u7387\u9ad8\u4e14\u6210\u529f\u7387\u9ad8\u3002", "conclusion": "DGD\u6846\u67b6\u6709\u6548\u89e3\u51b3\u73b0\u6709\u591a\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5728\u5927\u89c4\u6a21\u573a\u666f\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2508.19815", "pdf": "https://arxiv.org/pdf/2508.19815", "abs": "https://arxiv.org/abs/2508.19815", "authors": ["Linkuan Zhou", "Zhexin Chen", "Yufei Shen", "Junlin Xu", "Ping Xuan", "Yixin Zhu", "Yuqi Fang", "Cong Cong", "Leyi Wei", "Ran Su", "Jia Zhou", "Qiangguo Jin"], "title": "ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Automated segmentation of the fetal head in ultrasound images is critical for\nprenatal monitoring. However, achieving robust segmentation remains challenging\ndue to the poor quality of ultrasound images and the lack of annotated data.\nSemi-supervised methods alleviate the lack of annotated data but struggle with\nthe unique characteristics of fetal head ultrasound images, making it\nchallenging to generate reliable pseudo-labels and enforce effective\nconsistency regularization constraints. To address this issue, we propose a\nnovel semi-supervised framework, ERSR, for fetal head ultrasound segmentation.\nOur framework consists of the dual-scoring adaptive filtering strategy, the\nellipse-constrained pseudo-label refinement, and the symmetry-based multiple\nconsistency regularization. The dual-scoring adaptive filtering strategy uses\nboundary consistency and contour regularity criteria to evaluate and filter\nteacher outputs. The ellipse-constrained pseudo-label refinement refines these\nfiltered outputs by fitting least-squares ellipses, which strengthens pixels\nnear the center of the fitted ellipse and suppresses noise simultaneously. The\nsymmetry-based multiple consistency regularization enforces multi-level\nconsistency across perturbed images, symmetric regions, and between original\npredictions and pseudo-labels, enabling the model to capture robust and stable\nshape representations. Our method achieves state-of-the-art performance on two\nbenchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36%\nwith 10% and 20% labeled data, respectively. On the PSFH dataset, the scores\nare 91.68% and 93.70% under the same settings.", "AI": {"tldr": "\u63d0\u51fa\u534a\u76d1\u7763\u6846\u67b6 ERSR \u7528\u4e8e\u80ce\u513f\u5934\u90e8\u8d85\u58f0\u5206\u5272\uff0c\u65b9\u6cd5\u5305\u542b\u4e09\u9879\u7b56\u7565\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u7ee9\u3002", "motivation": "\u8d85\u58f0\u56fe\u50cf\u8d28\u91cf\u5dee\u548c\u6807\u6ce8\u6570\u636e\u7f3a\u4e4f\uff0c\u73b0\u6709\u534a\u76d1\u7763\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u80ce\u513f\u5934\u90e8\u8d85\u58f0\u56fe\u50cf\u7684\u72ec\u7279\u7279\u5f81\u3002", "method": "\u63d0\u51fa ERSR \u6846\u67b6\uff0c\u5305\u542b\u53cc\u8bc4\u5206\u81ea\u9002\u5e94\u8fc7\u6ee4\u7b56\u7565\u3001\u692d\u5706\u7ea6\u675f\u4f2a\u6807\u7b7e\u7ec6\u5316\u548c\u57fa\u4e8e\u5bf9\u79f0\u7684\u591a\u91cd\u4e00\u81f4\u6027\u6b63\u5219\u5316\u3002", "result": "\u5728 HC18 \u6570\u636e\u96c6\u4e0a\uff0c10% \u548c 20% \u6807\u6ce8\u6570\u636e\u4e0b Dice \u5206\u6570\u5206\u522b\u8fbe 92.05% \u548c 95.36%\uff1b\u5728 PSFH \u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u540c\u8bbe\u7f6e\u4e0b\u5206\u6570\u4e3a 91.68% \u548c 93.70%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u8fbe\u5230\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd"}}
{"id": "2508.20096", "pdf": "https://arxiv.org/pdf/2508.20096", "abs": "https://arxiv.org/abs/2508.20096", "authors": ["Zeyi Sun", "Yuhang Cao", "Jianze Liang", "Qiushi Sun", "Ziyu Liu", "Zhixiong Zhang", "Yuhang Zang", "Xiaoyi Dong", "Kai Chen", "Dahua Lin", "Jiaqi Wang"], "title": "CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "code available at this url: https://github.com/OpenIXCLab/CODA", "summary": "Autonomous agents for Graphical User Interfaces (GUIs) face significant\nchallenges in specialized domains such as scientific computing, where both\nlong-horizon planning and precise execution are required. Existing approaches\nsuffer from a trade-off: generalist agents excel at planning but perform poorly\nin execution, while specialized agents demonstrate the opposite weakness.\nRecent compositional frameworks attempt to bridge this gap by combining a\nplanner and an actor, but they are typically static and non-trainable, which\nprevents adaptation from experience. This is a critical limitation given the\nscarcity of high-quality data in scientific domains. To address these\nlimitations, we introduce CODA, a novel and trainable compositional framework\nthat integrates a generalist planner (Cerebrum) with a specialist executor\n(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,\nSpecialization, we apply a decoupled GRPO approach to train an expert planner\nfor each scientific application individually, bootstrapping from a small set of\ntask trajectories. In the second stage, Generalization, we aggregate all\nsuccessful trajectories from the specialized experts to build a consolidated\ndataset, which is then used for supervised fine-tuning of the final planner.\nThis equips CODA with both robust execution and cross-domain generalization.\nEvaluated on four challenging applications from the ScienceBoard benchmark,\nCODA significantly outperforms baselines and establishes a new state of the art\namong open-source models.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u8bad\u7ec3\u7684\u7ec4\u5408\u6846\u67b6CODA\uff0c\u7ed3\u5408\u901a\u7528\u89c4\u5212\u5668\u548c\u4e13\u5bb6\u6267\u884c\u5668\uff0c\u7ecf\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5728\u79d1\u5b66\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u56fe\u5f62\u7528\u6237\u754c\u9762\u81ea\u4e3b\u4ee3\u7406\u5728\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u5b58\u5728\u89c4\u5212\u548c\u6267\u884c\u96be\u4ee5\u517c\u987e\u3001\u7ec4\u5408\u6846\u67b6\u9759\u6001\u4e0d\u53ef\u8bad\u7ec3\u4e14\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165CODA\u6846\u67b6\uff0c\u7ed3\u5408\u901a\u7528\u89c4\u5212\u5668Cerebrum\u548c\u4e13\u5bb6\u6267\u884c\u5668Cerebellum\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u5148\u4e3a\u5404\u5e94\u7528\u8bad\u7ec3\u4e13\u5bb6\u89c4\u5212\u5668\uff0c\u518d\u6c47\u603b\u6210\u529f\u8f68\u8ff9\u5fae\u8c03\u6700\u7ec8\u89c4\u5212\u5668\u3002", "result": "\u5728ScienceBoard\u57fa\u51c6\u7684\u56db\u4e2a\u5e94\u7528\u4e2d\uff0cCODA\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5f00\u521b\u5f00\u6e90\u6a21\u578b\u65b0\u6c34\u5e73\u3002", "conclusion": "CODA\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u81ea\u4e3b\u4ee3\u7406\u5728\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u7684\u95ee\u9898\uff0c\u5177\u5907\u5f3a\u5927\u6267\u884c\u548c\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.19830", "pdf": "https://arxiv.org/pdf/2508.19830", "abs": "https://arxiv.org/abs/2508.19830", "authors": ["Yilin Zhang", "Cai Xu", "You Wu", "Ziyu Guan", "Wei Zhao"], "title": "Gradient Rectification for Robust Calibration under Distribution Shift", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, under review", "summary": "Deep neural networks often produce overconfident predictions, undermining\ntheir reliability in safety-critical applications. This miscalibration is\nfurther exacerbated under distribution shift, where test data deviates from the\ntraining distribution due to environmental or acquisition changes. While\nexisting approaches improve calibration through training-time regularization or\npost-hoc adjustment, their reliance on access to or simulation of target\ndomains limits their practicality in real-world scenarios. In this paper, we\npropose a novel calibration framework that operates without access to target\ndomain information. From a frequency-domain perspective, we identify that\ndistribution shifts often distort high-frequency visual cues exploited by deep\nmodels, and introduce a low-frequency filtering strategy to encourage reliance\non domain-invariant features. However, such information loss may degrade\nIn-Distribution (ID) calibration performance. Therefore, we further propose a\ngradient-based rectification mechanism that enforces ID calibration as a hard\nconstraint during optimization. Experiments on synthetic and real-world shifted\ndatasets, including CIFAR-10/100-C and WILDS, demonstrate that our method\nsignificantly improves calibration under distribution shift while maintaining\nstrong in-distribution performance.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u76ee\u6807\u57df\u4fe1\u606f\u7684\u6821\u51c6\u6846\u67b6\uff0c\u7ed3\u5408\u4f4e\u9891\u6ee4\u6ce2\u548c\u68af\u5ea6\u6821\u6b63\u673a\u5236\uff0c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u63d0\u5347\u6821\u51c6\u6548\u679c\u5e76\u4fdd\u6301\u5206\u5e03\u5185\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u5e38\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u6821\u51c6\u95ee\u9898\u52a0\u5267\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u76ee\u6807\u57df\u4fe1\u606f\uff0c\u5b9e\u7528\u6027\u53d7\u9650\u3002", "method": "\u4ece\u9891\u57df\u89d2\u5ea6\uff0c\u91c7\u7528\u4f4e\u9891\u6ee4\u6ce2\u7b56\u7565\u9f13\u52b1\u4f9d\u8d56\u57df\u4e0d\u53d8\u7279\u5f81\uff0c\u63d0\u51fa\u57fa\u4e8e\u68af\u5ea6\u7684\u6821\u6b63\u673a\u5236\u5728\u4f18\u5316\u65f6\u5f3a\u5236\u5206\u5e03\u5185\u6821\u51c6\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684\u504f\u79fb\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6821\u51c6\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5206\u5e03\u5185\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u5728\u65e0\u76ee\u6807\u57df\u4fe1\u606f\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u89e3\u51b3\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6821\u51c6\u95ee\u9898\u3002"}}
{"id": "2508.19843", "pdf": "https://arxiv.org/pdf/2508.19843", "abs": "https://arxiv.org/abs/2508.19843", "authors": ["Shuo Shao", "Yiming Li", "Yu He", "Hongwei Yao", "Wenyuan Yang", "Dacheng Tao", "Zhan Qin"], "title": "SoK: Large Language Model Copyright Auditing via Fingerprinting", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "The broad capabilities and substantial resources required to train Large\nLanguage Models (LLMs) make them valuable intellectual property, yet they\nremain vulnerable to copyright infringement, such as unauthorized use and model\ntheft. LLM fingerprinting, a non-intrusive technique that extracts and compares\nthe distinctive features from LLMs to identify infringements, offers a\npromising solution to copyright auditing. However, its reliability remains\nuncertain due to the prevalence of diverse model modifications and the lack of\nstandardized evaluation. In this SoK, we present the first comprehensive study\nof LLM fingerprinting. We introduce a unified framework and formal taxonomy\nthat categorizes existing methods into white-box and black-box approaches,\nproviding a structured overview of the state of the art. We further propose\nLeaFBench, the first systematic benchmark for evaluating LLM fingerprinting\nunder realistic deployment scenarios. Built upon mainstream foundation models\nand comprising 149 distinct model instances, LeaFBench integrates 13\nrepresentative post-development techniques, spanning both parameter-altering\nmethods (e.g., fine-tuning, quantization) and parameter-independent mechanisms\n(e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the\nstrengths and weaknesses of existing methods, thereby outlining future research\ndirections and critical open problems in this emerging field. The code is\navailable at https://github.com/shaoshuo-ss/LeaFBench.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u6307\u7eb9\u8bc6\u522b\uff0c\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u548c\u5206\u7c7b\u6cd5\uff0c\u6784\u5efaLeaFBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u63ed\u793a\u73b0\u6709\u65b9\u6cd5\u4f18\u7f3a\u70b9\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6613\u53d7\u7248\u6743\u4fb5\u72af\uff0c\u6307\u7eb9\u8bc6\u522b\u867d\u6709\u6f5c\u529b\u4f46\u53ef\u9760\u6027\u56e0\u6a21\u578b\u4fee\u6539\u591a\u6837\u548c\u7f3a\u4e4f\u6807\u51c6\u8bc4\u4f30\u800c\u4e0d\u786e\u5b9a\uff0c\u9700\u8981\u5168\u9762\u7814\u7a76\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u6846\u67b6\u548c\u5f62\u5f0f\u5316\u5206\u7c7b\u6cd5\u5bf9\u73b0\u6709\u65b9\u6cd5\u5206\u7c7b\uff0c\u6784\u5efaLeaFBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e3b\u6d41\u57fa\u7840\u6a21\u578b\u548c\u591a\u79cd\u6a21\u578b\u4fee\u6539\u6280\u672f\u3002", "result": "\u5728LeaFBench\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "\u6307\u660e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u6307\u7eb9\u8bc6\u522b\u8fd9\u4e00\u65b0\u5174\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u5173\u952e\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2508.19881", "pdf": "https://arxiv.org/pdf/2508.19881", "abs": "https://arxiv.org/abs/2508.19881", "authors": ["Narges Takhtkeshha", "Gabriele Mazzacca", "Fabio Remondino", "Juha Hyypp\u00e4", "Gottfried Mandlburger"], "title": "Multispectral LiDAR data for extracting tree points in urban and suburban areas", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Monitoring urban tree dynamics is vital for supporting greening policies and\nreducing risks to electrical infrastructure. Airborne laser scanning has\nadvanced large-scale tree management, but challenges remain due to complex\nurban environments and tree variability. Multispectral (MS) light detection and\nranging (LiDAR) improves this by capturing both 3D spatial and spectral data,\nenabling detailed mapping. This study explores tree point extraction using\nMS-LiDAR and deep learning (DL) models. Three state-of-the-art models are\nevaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point\nTransformer V1 (PTv1). Results show the notable time efficiency and accuracy of\nSPT, with a mean intersection over union (mIoU) of 85.28%. The highest\ndetection accuracy is achieved by incorporating pseudo normalized difference\nvegetation index (pNDVI) with spatial data, reducing error rate by 10.61\npercentage points (pp) compared to using spatial information alone. These\nfindings highlight the potential of MS-LiDAR and DL to improve tree extraction\nand further tree inventories.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528MS - LiDAR\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u6811\u6728\u70b9\u63d0\u53d6\uff0c\u8bc4\u4f30\u4e09\u4e2a\u6a21\u578b\uff0cSPT\u8868\u73b0\u4f73\uff0c\u7ed3\u5408pNDVI\u4e0e\u7a7a\u95f4\u6570\u636e\u68c0\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u51f8\u663eMS - LiDAR\u548cDL\u6f5c\u529b\u3002", "motivation": "\u76d1\u6d4b\u57ce\u5e02\u6811\u6728\u52a8\u6001\u5bf9\u652f\u6301\u7eff\u5316\u653f\u7b56\u548c\u964d\u4f4e\u7535\u529b\u57fa\u7840\u8bbe\u65bd\u98ce\u9669\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u548c\u6811\u6728\u591a\u53d8\u6027\u4e0b\u6709\u6311\u6218\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5229\u7528MS - LiDAR\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u6811\u6728\u70b9\u63d0\u53d6\uff0c\u8bc4\u4f30Superpoint Transformer (SPT)\u3001Point Transformer V3 (PTv3)\u548cPoint Transformer V1 (PTv1)\u4e09\u4e2a\u6a21\u578b\u3002", "result": "SPT\u65f6\u95f4\u6548\u7387\u548c\u51c6\u786e\u6027\u663e\u8457\uff0cmIoU\u4e3a85.28%\uff1b\u7ed3\u5408pNDVI\u4e0e\u7a7a\u95f4\u6570\u636e\u68c0\u6d4b\u7cbe\u5ea6\u6700\u9ad8\uff0c\u6bd4\u4ec5\u7528\u7a7a\u95f4\u4fe1\u606f\u8bef\u5dee\u7387\u964d\u4f4e10.61\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "MS - LiDAR\u548c\u6df1\u5ea6\u5b66\u4e60\u6709\u6539\u5584\u6811\u6728\u63d0\u53d6\u548c\u6811\u6728\u6e05\u67e5\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.19883", "pdf": "https://arxiv.org/pdf/2508.19883", "abs": "https://arxiv.org/abs/2508.19883", "authors": ["Chiman Salavati", "Shannon Song", "Scott A. Hale", "Roberto E. Montenegro", "Shiri Dori-Hacohen", "Fabricio Murai"], "title": "AI-Powered Detection of Inappropriate Language in Medical School Curricula", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.1; I.2.7"], "comment": "Accepted at 2025 AAAI/ACM AI, Ethics and Society Conference (AIES'25)", "summary": "The use of inappropriate language -- such as outdated, exclusionary, or\nnon-patient-centered terms -- medical instructional materials can significantly\ninfluence clinical training, patient interactions, and health outcomes. Despite\ntheir reputability, many materials developed over past decades contain examples\nnow considered inappropriate by current medical standards. Given the volume of\ncurricular content, manually identifying instances of inappropriate use of\nlanguage (IUL) and its subcategories for systematic review is prohibitively\ncostly and impractical. To address this challenge, we conduct a first-in-class\nevaluation of small language models (SLMs) fine-tuned on labeled data and\npre-trained LLMs with in-context learning on a dataset containing approximately\n500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL\nclassifier, (2) subcategory-specific binary classifiers, (3) a multilabel\nclassifier, and (4) a two-stage hierarchical pipeline for general IUL detection\nfollowed by multilabel classification. For LLMs, we consider variations of\nprompts that include subcategory definitions and/or shots. We found that both\nLLama-3 8B and 70B, even with carefully curated shots, are largely outperformed\nby SLMs. While the multilabel classifier performs best on annotated data,\nsupplementing training with unflagged excerpts as negative examples boosts the\nspecific classifiers' AUC by up to 25%, making them most effective models for\nmitigating harmful language in medical curricula.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u68c0\u6d4b\u533b\u5b66\u6559\u6750\u4e2d\u4e0d\u5f53\u8bed\u8a00\u7684\u6548\u679c\uff0c\u53d1\u73b0SLMs\u8868\u73b0\u66f4\u597d\uff0c\u8865\u5145\u672a\u6807\u8bb0\u6bb5\u843d\u4f5c\u8d1f\u4f8b\u53ef\u63d0\u5347\u7279\u5b9a\u5206\u7c7b\u5668\u6027\u80fd\u3002", "motivation": "\u533b\u5b66\u6559\u5b66\u6750\u6599\u4e2d\u5b58\u5728\u5927\u91cf\u4e0d\u7b26\u5408\u5f53\u524d\u6807\u51c6\u7684\u4e0d\u5f53\u8bed\u8a00\uff0c\u624b\u52a8\u8bc6\u522b\u6210\u672c\u9ad8\u4e14\u4e0d\u73b0\u5b9e\uff0c\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u68c0\u6d4b\u3002", "method": "\u5728\u7ea6500\u4efd\u6587\u4ef6\u3001\u8d8512000\u9875\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5fae\u8c03\u7684SLMs\u548c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u9884\u8bad\u7ec3LLMs\uff0c\u5bf9SLMs\u91c7\u7528\u591a\u79cd\u5206\u7c7b\u5668\uff0c\u5bf9LLMs\u91c7\u7528\u4e0d\u540c\u63d0\u793a\u65b9\u5f0f\u3002", "result": "LLama - 3 8B\u548c70B\u5373\u4f7f\u6709\u7cbe\u5fc3\u6311\u9009\u7684\u793a\u4f8b\u4e5f\u5927\u591a\u4e0d\u5982SLMs\uff0c\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u5728\u6807\u6ce8\u6570\u636e\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u8865\u5145\u8d1f\u4f8b\u53ef\u4f7f\u7279\u5b9a\u5206\u7c7b\u5668AUC\u63d0\u5347\u8fbe25%\u3002", "conclusion": "\u8865\u5145\u8d1f\u4f8b\u8bad\u7ec3\u7684\u7279\u5b9a\u5206\u7c7b\u5668\u662f\u51cf\u8f7b\u533b\u5b66\u8bfe\u7a0b\u4e2d\u6709\u5bb3\u8bed\u8a00\u7684\u6700\u6709\u6548\u6a21\u578b\u3002"}}
{"id": "2508.19903", "pdf": "https://arxiv.org/pdf/2508.19903", "abs": "https://arxiv.org/abs/2508.19903", "authors": ["Ramya Keerthy Thatikonda", "Wray Buntine", "Ehsan Shareghi"], "title": "Logical Reasoning with Outcome Reward Models for Test-Time Scaling", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025", "summary": "Logical reasoning is a critical benchmark for evaluating the capabilities of\nlarge language models (LLMs), as it reflects their ability to derive valid\nconclusions from given premises. While the combination of test-time scaling\nwith dedicated outcome or process reward models has opened up new avenues to\nenhance LLMs performance in complex reasoning tasks, this space is\nunder-explored in deductive logical reasoning. We present a set of Outcome\nReward Models (ORMs) for deductive reasoning. To train the ORMs we mainly\ngenerate data using Chain-of-Thought (CoT) with single and multiple samples.\nAdditionally, we propose a novel tactic to further expand the type of errors\ncovered in the training dataset of the ORM. In particular, we propose an echo\ngeneration technique that leverages LLMs' tendency to reflect incorrect\nassumptions made in prompts to extract additional training data, covering\npreviously unexplored error types. While a standard CoT chain may contain\nerrors likely to be made by the reasoner, the echo strategy deliberately steers\nthe model toward incorrect reasoning. We show that ORMs trained on CoT and\necho-augmented data demonstrate improved performance on the FOLIO, JustLogic,\nand ProverQA datasets across four different LLMs.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u6f14\u7ece\u63a8\u7406\u7684\u7ed3\u679c\u5956\u52b1\u6a21\u578b\uff08ORMs\uff09\uff0c\u7ed3\u5408\u601d\u7ef4\u94fe\uff08CoT\uff09\u548c\u56de\u58f0\u751f\u6210\u6280\u672f\u6269\u5145\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e86\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6f14\u7ece\u903b\u8f91\u63a8\u7406\u9886\u57df\u63a2\u7d22\u4e0d\u8db3\uff0c\u9700\u8981\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6f14\u7ece\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u6f14\u7ece\u63a8\u7406\u7684ORMs\uff0c\u4f7f\u7528CoT\u5355\u6837\u672c\u548c\u591a\u6837\u672c\u751f\u6210\u6570\u636e\u8bad\u7ec3ORMs\uff0c\u63d0\u51fa\u56de\u58f0\u751f\u6210\u6280\u672f\u6269\u5145\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728FOLIO\u3001JustLogic\u548cProverQA\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u4e8eCoT\u548c\u56de\u58f0\u589e\u5f3a\u6570\u636e\u8bad\u7ec3\u7684ORMs\u5728\u56db\u4e2a\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6f14\u7ece\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.19927", "pdf": "https://arxiv.org/pdf/2508.19927", "abs": "https://arxiv.org/abs/2508.19927", "authors": ["Fayaz Ali", "Muhammad Zawish", "Steven Davy", "Radu Timofte"], "title": "WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "Transformers have demonstrated promising performance in computer vision\ntasks, including image super-resolution (SR). The quadratic computational\ncomplexity of window self-attention mechanisms in many transformer-based SR\nmethods forces the use of small, fixed windows, limiting the receptive field.\nIn this paper, we propose a new approach by embedding the wavelet transform\nwithin a hierarchical transformer framework, called (WaveHiT-SR). First, using\nadaptive hierarchical windows instead of static small windows allows to capture\nfeatures across different levels and greatly improve the ability to model\nlong-range dependencies. Secondly, the proposed model utilizes wavelet\ntransforms to decompose images into multiple frequency subbands, allowing the\nnetwork to focus on both global and local features while preserving structural\ndetails. By progressively reconstructing high-resolution images through\nhierarchical processing, the network reduces computational complexity without\nsacrificing performance. The multi-level decomposition strategy enables the\nnetwork to capture fine-grained information in lowfrequency components while\nenhancing high-frequency textures. Through extensive experimentation, we\nconfirm the effectiveness and efficiency of our WaveHiT-SR. Our refined\nversions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR\nresults, achieving higher efficiency with fewer parameters, lower FLOPs, and\nfaster speeds.", "AI": {"tldr": "\u63d0\u51faWaveHiT - SR\u65b9\u6cd5\uff0c\u7ed3\u5408\u5c0f\u6ce2\u53d8\u6362\u548c\u5206\u5c42transformer\u6846\u67b6\u7528\u4e8e\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u9ad8\u6548\u3002", "motivation": "\u8bb8\u591a\u57fa\u4e8etransformer\u7684\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u4e2d\u7a97\u53e3\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\u9650\u5236\u4e86\u611f\u53d7\u91ce\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5c06\u5c0f\u6ce2\u53d8\u6362\u5d4c\u5165\u5206\u5c42transformer\u6846\u67b6\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u5206\u5c42\u7a97\u53e3\uff0c\u5229\u7528\u5c0f\u6ce2\u53d8\u6362\u5206\u89e3\u56fe\u50cf\uff0c\u901a\u8fc7\u5206\u5c42\u5904\u7406\u9010\u6b65\u91cd\u5efa\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u3002", "result": "WaveHiT - SR\u7684\u6539\u8fdb\u7248\u672cSwinIR - Light\u3001SwinIR - NG\u548cSRFormer - Light\u53d6\u5f97\u524d\u6cbf\u8d85\u5206\u8fa8\u7387\u7ed3\u679c\uff0c\u53c2\u6570\u66f4\u5c11\u3001FLOPs\u66f4\u4f4e\u3001\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "WaveHiT - SR\u65b9\u6cd5\u6709\u6548\u4e14\u9ad8\u6548\u3002"}}
{"id": "2508.19966", "pdf": "https://arxiv.org/pdf/2508.19966", "abs": "https://arxiv.org/abs/2508.19966", "authors": ["Slimane Bellaouar", "Attia Nehar", "Soumia Souffi", "Mounia Bouameur"], "title": "Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "25 pages, 7 figures", "summary": "Despite its significance, Arabic, a linguistically rich and morphologically\ncomplex language, faces the challenge of being under-resourced. The scarcity of\nlarge annotated datasets hampers the development of accurate tools for\nsubjectivity analysis in Arabic. Recent advances in deep learning and\nTransformers have proven highly effective for text classification in English\nand French. This paper proposes a new approach for subjectivity assessment in\nArabic textual data. To address the dearth of specialized annotated datasets,\nwe developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic\ndatasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we\nfine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and\nArabianGPT) on AraDhati+ for effective subjectivity classification.\nFurthermore, we experimented with an ensemble decision approach to harness the\nstrengths of individual models. Our approach achieves a remarkable accuracy of\n97.79\\,\\% for Arabic subjectivity classification. Results demonstrate the\neffectiveness of the proposed approach in addressing the challenges posed by\nlimited resources in Arabic language processing.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u4e3b\u89c2\u6027\u5206\u6790\u8d44\u6e90\u4e0d\u8db3\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5fae\u8c03\u6a21\u578b\u5e76\u91c7\u7528\u96c6\u6210\u51b3\u7b56\uff0c\u5b9e\u73b097.79%\u51c6\u786e\u7387\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u8d44\u6e90\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u5927\u578b\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u963b\u788d\u4e3b\u89c2\u6027\u5206\u6790\u5de5\u5177\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u7efc\u5408\u6570\u636e\u96c6AraDhati+\uff0c\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u5fae\u8c03XLM - RoBERTa\u3001AraBERT\u548cArabianGPT\u7b49\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u96c6\u6210\u51b3\u7b56\u65b9\u6cd5\u3002", "result": "\u963f\u62c9\u4f2f\u8bed\u4e3b\u89c2\u6027\u5206\u7c7b\u51c6\u786e\u7387\u8fbe97.79%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u963f\u62c9\u4f2f\u8bed\u5904\u7406\u8d44\u6e90\u6709\u9650\u7684\u6311\u6218\u3002"}}
{"id": "2508.19972", "pdf": "https://arxiv.org/pdf/2508.19972", "abs": "https://arxiv.org/abs/2508.19972", "authors": ["Seongheon Park", "Yixuan Li"], "title": "GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Object hallucination in large vision-language models presents a significant\nchallenge to their safe deployment in real-world applications. Recent works\nhave proposed object-level hallucination scores to estimate the likelihood of\nobject hallucination; however, these methods typically adopt either a global or\nlocal perspective in isolation, which may limit detection reliability. In this\npaper, we introduce GLSim, a novel training-free object hallucination detection\nframework that leverages complementary global and local embedding similarity\nsignals between image and text modalities, enabling more accurate and reliable\nhallucination detection in diverse scenarios. We comprehensively benchmark\nexisting object hallucination detection methods and demonstrate that GLSim\nachieves superior detection performance, outperforming competitive baselines by\na significant margin.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u76ee\u6807\u5e7b\u89c9\u68c0\u6d4b\u6846\u67b6GLSim\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u68c0\u6d4b\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u76ee\u6807\u5e7b\u89c9\u5206\u6570\u4f30\u8ba1\u65b9\u6cd5\u4ec5\u4ece\u5168\u5c40\u6216\u5c40\u90e8\u5355\u4e00\u89c6\u89d2\u51fa\u53d1\uff0c\u9650\u5236\u68c0\u6d4b\u53ef\u9760\u6027\uff0c\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u76ee\u6807\u5e7b\u89c9\u95ee\u9898\u5f71\u54cd\u5176\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u5f15\u5165GLSim\u6846\u67b6\uff0c\u5229\u7528\u56fe\u50cf\u548c\u6587\u672c\u6a21\u6001\u95f4\u4e92\u8865\u7684\u5168\u5c40\u548c\u5c40\u90e8\u5d4c\u5165\u76f8\u4f3c\u6027\u4fe1\u53f7\u3002", "result": "\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0cGLSim\u68c0\u6d4b\u6027\u80fd\u4f18\u8d8a\uff0c\u5927\u5e45\u8d85\u8d8a\u7ade\u4e89\u57fa\u7ebf\u3002", "conclusion": "GLSim\u80fd\u5728\u591a\u6837\u573a\u666f\u4e0b\u5b9e\u73b0\u66f4\u51c6\u786e\u53ef\u9760\u7684\u5e7b\u89c9\u68c0\u6d4b\u3002"}}
{"id": "2508.19982", "pdf": "https://arxiv.org/pdf/2508.19982", "abs": "https://arxiv.org/abs/2508.19982", "authors": ["Pengxiang Li", "Yefan Zhou", "Dilxat Muhtar", "Lu Yin", "Shilin Yan", "Li Shen", "Yi Liang", "Soroush Vosoughi", "Shiwei Liu"], "title": "Diffusion Language Models Know the Answer Before Decoding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion language models (DLMs) have recently emerged as an alternative to\nautoregressive approaches, offering parallel sequence generation and flexible\ntoken orders. However, their inference remains slower than that of\nautoregressive models, primarily due to the cost of bidirectional attention and\nthe large number of refinement steps required for high quality outputs. In this\nwork, we highlight and leverage an overlooked property of DLMs early answer\nconvergence: in many cases, the correct answer can be internally identified by\nhalf steps before the final decoding step, both under semi-autoregressive and\nrandom remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%\nof instances, respectively, can be decoded correctly using only half of the\nrefinement steps. Building on this observation, we introduce Prophet, a\ntraining-free fast decoding paradigm that enables early commit decoding.\nSpecifically, Prophet dynamically decides whether to continue refinement or to\ngo \"all-in\" (i.e., decode all remaining tokens in one step), using the\nconfidence gap between the top-2 prediction candidates as the criterion. It\nintegrates seamlessly into existing DLM implementations, incurs negligible\noverhead, and requires no additional training. Empirical evaluations of\nLLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the\nnumber of decoding steps by up to 3.4x while preserving high generation\nquality. These results recast DLM decoding as a problem of when to stop\nsampling, and demonstrate that early decode convergence provides a simple yet\npowerful mechanism for accelerating DLM inference, complementary to existing\nspeedup techniques. Our code is publicly available at\nhttps://github.com/pixeli99/Prophet.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08DLMs\uff09\u5b58\u5728\u65e9\u671f\u7b54\u6848\u6536\u655b\u7279\u6027\uff0c\u63d0\u51fa\u65e0\u8bad\u7ec3\u5feb\u901f\u89e3\u7801\u8303\u5f0fProphet\uff0c\u51cf\u5c11\u89e3\u7801\u6b65\u9aa4\u5e76\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3DLMs\u63a8\u7406\u901f\u5ea6\u6162\u7684\u95ee\u9898\uff0c\u56e0\u5176\u53cc\u5411\u6ce8\u610f\u529b\u6210\u672c\u548c\u9ad8\u8d28\u91cf\u8f93\u51fa\u6240\u9700\u7684\u5927\u91cf\u7ec6\u5316\u6b65\u9aa4\u3002", "method": "\u5229\u7528DLMs\u65e9\u671f\u7b54\u6848\u6536\u655b\u7279\u6027\uff0c\u63d0\u51faProphet\u8303\u5f0f\uff0c\u4ee5top - 2\u9884\u6d4b\u5019\u9009\u7684\u7f6e\u4fe1\u5ea6\u5dee\u8ddd\u4e3a\u6807\u51c6\u52a8\u6001\u51b3\u5b9a\u662f\u5426\u7ee7\u7eed\u7ec6\u5316\u6216\u4e00\u6b65\u89e3\u7801\u5269\u4f59\u6807\u8bb0\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u5bf9LLaDA - 8B\u548cDream - 7B\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cProphet\u6700\u591a\u53ef\u5c06\u89e3\u7801\u6b65\u9aa4\u51cf\u5c113.4\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "DLM\u89e3\u7801\u53ef\u89c6\u4e3a\u4f55\u65f6\u505c\u6b62\u91c7\u6837\u7684\u95ee\u9898\uff0c\u65e9\u671f\u89e3\u7801\u6536\u655b\u4e3a\u52a0\u901fDLM\u63a8\u7406\u63d0\u4f9b\u4e86\u7b80\u5355\u6709\u6548\u7684\u673a\u5236\uff0c\u53ef\u4e0e\u73b0\u6709\u52a0\u901f\u6280\u672f\u4e92\u8865\u3002"}}
{"id": "2508.19993", "pdf": "https://arxiv.org/pdf/2508.19993", "abs": "https://arxiv.org/abs/2508.19993", "authors": ["Debanjana Kar", "Leopold B\u00f6ss", "Dacia Braca", "Sebastian Maximilian Dennerlein", "Nina Christine Hubig", "Philipp Wintersberger", "Yufang Hou"], "title": "MathBuddy: A Multimodal System for Affective Math Tutoring", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "The rapid adoption of LLM-based conversational systems is already\ntransforming the landscape of educational technology. However, the current\nstate-of-the-art learning models do not take into account the student's\naffective states. Multiple studies in educational psychology support the claim\nthat positive or negative emotional states can impact a student's learning\ncapabilities. To bridge this gap, we present MathBuddy, an emotionally aware\nLLM-powered Math Tutor, which dynamically models the student's emotions and\nmaps them to relevant pedagogical strategies, making the tutor-student\nconversation a more empathetic one. The student's emotions are captured from\nthe conversational text as well as from their facial expressions. The student's\nemotions are aggregated from both modalities to confidently prompt our LLM\nTutor for an emotionally-aware response. We have effectively evaluated our\nmodel using automatic evaluation metrics across eight pedagogical dimensions\nand user studies. We report a massive 23 point performance gain using the win\nrate and a 3 point gain at an overall level using DAMR scores which strongly\nsupports our hypothesis of improving LLM-based tutor's pedagogical abilities by\nmodeling students' emotions.", "AI": {"tldr": "\u63d0\u51fa\u60c5\u611f\u611f\u77e5\u7684\u6570\u5b66\u8f85\u5bfc\u7cfb\u7edfMathBuddy\uff0c\u901a\u8fc7\u8003\u8651\u5b66\u751f\u60c5\u611f\u63d0\u5347\u6559\u5b66\u80fd\u529b\uff0c\u8bc4\u4f30\u663e\u793a\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u6a21\u578b\u672a\u8003\u8651\u5b66\u751f\u60c5\u611f\u72b6\u6001\uff0c\u800c\u60c5\u611f\u4f1a\u5f71\u54cd\u5b66\u4e60\u80fd\u529b\uff0c\u9700\u5f25\u8865\u6b64\u5dee\u8ddd\u3002", "method": "\u6784\u5efaMathBuddy\u7cfb\u7edf\uff0c\u4ece\u5bf9\u8bdd\u6587\u672c\u548c\u9762\u90e8\u8868\u60c5\u6355\u6349\u5b66\u751f\u60c5\u611f\uff0c\u805a\u5408\u540e\u63d0\u793aLLM\u5bfc\u5e08\u7ed9\u51fa\u60c5\u611f\u611f\u77e5\u56de\u5e94\u3002", "result": "\u4f7f\u7528\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u548c\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u6a21\u578b\uff0c\u80dc\u7387\u670923\u5206\u63d0\u5347\uff0cDAMR\u603b\u5206\u67093\u5206\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5efa\u6a21\u5b66\u751f\u60c5\u611f\u80fd\u6709\u6548\u63d0\u9ad8\u57fa\u4e8eLLM\u7684\u5bfc\u5e08\u7684\u6559\u5b66\u80fd\u529b\u3002"}}
{"id": "2508.20033", "pdf": "https://arxiv.org/pdf/2508.20033", "abs": "https://arxiv.org/abs/2508.20033", "authors": ["Liana Patel", "Negar Arabzadeh", "Harshit Gupta", "Ankita Sundar", "Ion Stoica", "Matei Zaharia", "Carlos Guestrin"], "title": "DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The ability to research and synthesize knowledge is central to human\nexpertise and progress. An emerging class of systems promises these exciting\ncapabilities through generative research synthesis, performing retrieval over\nthe live web and synthesizing discovered sources into long-form, cited\nsummaries. However, evaluating such systems remains an open challenge: existing\nquestion-answering benchmarks focus on short-form factual responses, while\nexpert-curated datasets risk staleness and data contamination. Both fail to\ncapture the complexity and evolving nature of real research synthesis tasks. In\nthis work, we introduce DeepScholar-bench, a live benchmark and holistic,\nautomated evaluation framework designed to evaluate generative research\nsynthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv\npapers and focuses on a real research synthesis task: generating the related\nwork sections of a paper by retrieving, synthesizing, and citing prior\nresearch. Our evaluation framework holistically assesses performance across\nthree key dimensions, knowledge synthesis, retrieval quality, and\nverifiability. We also develop DeepScholar-base, a reference pipeline\nimplemented efficiently using the LOTUS API. Using the DeepScholar-bench\nframework, we perform a systematic evaluation of prior open-source systems,\nsearch AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that\nDeepScholar-base establishes a strong baseline, attaining competitive or higher\nperformance than each other method. We also find that DeepScholar-bench remains\nfar from saturated, with no system exceeding a score of $19\\%$ across all\nmetrics. These results underscore the difficulty of DeepScholar-bench, as well\nas its importance for progress towards AI systems capable of generative\nresearch synthesis. We make our code available at\nhttps://github.com/guestrin-lab/deepscholar-bench.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u5f0f\u7814\u7a76\u5408\u6210\u7684DeepScholar - bench\u57fa\u51c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf9\u73b0\u6709\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0DeepScholar - base\u8868\u73b0\u826f\u597d\uff0c\u4e14\u8be5\u57fa\u51c6\u8fdc\u672a\u9971\u548c\u3002", "motivation": "\u73b0\u6709\u95ee\u7b54\u57fa\u51c6\u548c\u4e13\u5bb6\u6574\u7406\u6570\u636e\u96c6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u751f\u6210\u5f0f\u7814\u7a76\u5408\u6210\u7cfb\u7edf\uff0c\u9700\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165DeepScholar - bench\u57fa\u51c6\uff0c\u4ece\u8fd1\u671f\u9ad8\u8d28\u91cfArXiv\u8bba\u6587\u63d0\u53d6\u67e5\u8be2\uff0c\u805a\u7126\u751f\u6210\u8bba\u6587\u76f8\u5173\u5de5\u4f5c\u90e8\u5206\uff1b\u8bc4\u4f30\u6846\u67b6\u4ece\u77e5\u8bc6\u5408\u6210\u3001\u68c0\u7d22\u8d28\u91cf\u548c\u53ef\u9a8c\u8bc1\u6027\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\uff1b\u5f00\u53d1DeepScholar - base\u53c2\u8003\u7ba1\u9053\u3002", "result": "DeepScholar - base\u5efa\u7acb\u4e86\u5f3a\u5927\u57fa\u7ebf\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff1b\u6240\u6709\u7cfb\u7edf\u5728\u6240\u6709\u6307\u6807\u4e0a\u5f97\u5206\u672a\u8d8519%\u3002", "conclusion": "DeepScholar - bench\u6709\u96be\u5ea6\u4e14\u5bf9\u751f\u6210\u5f0f\u7814\u7a76\u5408\u6210AI\u7cfb\u7edf\u53d1\u5c55\u5f88\u91cd\u8981\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.20064", "pdf": "https://arxiv.org/pdf/2508.20064", "abs": "https://arxiv.org/abs/2508.20064", "authors": ["Philippe Zhang", "Weili Jiang", "Yihao Li", "Jing Zhang", "Sarah Matta", "Yubo Tan", "Hui Lin", "Haoshen Wang", "Jiangtian Pan", "Hui Xu", "Laurent Borderie", "Alexandre Le Guilcher", "B\u00e9atrice Cochener", "Chubin Ou", "Gwenol\u00e9 Quellec", "Mathieu Lamard"], "title": "Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 5 figures, 3 tables, challenge/conference paper", "summary": "Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting\nvisual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments\nhave been effective in slowing the progression of neovascular AMD, with better\noutcomes achieved through timely diagnosis and consistent monitoring. Tracking\nthe progression of neovascular activity in OCT scans of patients with exudative\nAMD allows for the development of more personalized and effective treatment\nplans. This was the focus of the Monitoring Age-related Macular Degeneration\nProgression in Optical Coherence Tomography (MARIO) challenge, in which we\nparticipated. In Task 1, which involved classifying the evolution between two\npairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN\nnetwork with model ensembling to further enhance the model's performance. For\nTask 2, which focused on predicting progression over the next three months\nbased on current exam data, we proposed the Patch Progression Masked\nAutoencoder that generates an OCT for the next exam and then classifies the\nevolution between the current OCT and the one generated using our solution from\nTask 1. The results we achieved allowed us to place in the Top 10 for both\ntasks. Some team members are part of the same organization as the challenge\norganizers; therefore, we are not eligible to compete for the prize.", "AI": {"tldr": "\u672c\u6587\u805a\u7126AMD\uff0c\u53c2\u4e0eMARIO\u6311\u6218\uff0c\u7528\u878d\u5408CNN\u7f51\u7edc\u548cPatch Progression Masked Autoencoder\u5b8c\u6210\u4e24\u9879\u4efb\u52a1\uff0c\u6392\u540d\u524d\u5341\u4f46\u56e0\u7ec4\u7ec7\u5173\u7cfb\u65e0\u83b7\u5956\u8d44\u683c\u3002", "motivation": "AMD\u5f71\u54cd\u89c6\u529b\uff0c\u53ca\u65f6\u8bca\u65ad\u548c\u76d1\u6d4b\u5bf9\u6cbb\u7597\u91cd\u8981\uff0c\u901a\u8fc7\u8ffd\u8e2a\u60a3\u8005OCT\u626b\u63cf\u4e2d\u65b0\u751f\u8840\u7ba1\u6d3b\u52a8\u8fdb\u5c55\u5236\u5b9a\u4e2a\u6027\u5316\u6cbb\u7597\u65b9\u6848\u3002", "method": "\u4efb\u52a11\u7528\u878d\u5408CNN\u7f51\u7edc\u548c\u6a21\u578b\u96c6\u6210\uff1b\u4efb\u52a12\u63d0\u51faPatch Progression Masked Autoencoder\u751f\u6210\u4e0b\u6b21OCT\u5e76\u5206\u7c7b\u3002", "result": "\u4e24\u9879\u4efb\u52a1\u6392\u540d\u8fdb\u5165\u524d10\u3002", "conclusion": "\u867d\u53d6\u5f97\u8f83\u597d\u6392\u540d\uff0c\u4f46\u56e0\u90e8\u5206\u56e2\u961f\u6210\u5458\u4e0e\u4e3b\u529e\u65b9\u540c\u5c5e\u4e00\u7ec4\u7ec7\uff0c\u65e0\u83b7\u5956\u8d44\u683c\u3002"}}
