{"id": "2507.14261", "pdf": "https://arxiv.org/pdf/2507.14261", "abs": "https://arxiv.org/abs/2507.14261", "authors": ["Mahmood K. M. Almansoori", "Miklos Telek"], "title": "FAMST: Fast Approximate Minimum Spanning Tree Construction for Large-Scale and High-Dimensional Data", "categories": ["cs.DS", "cs.AI"], "comment": null, "summary": "We present Fast Approximate Minimum Spanning Tree (FAMST), a novel algorithm\nthat addresses the computational challenges of constructing Minimum Spanning\nTrees (MSTs) for large-scale and high-dimensional datasets. FAMST utilizes a\nthree-phase approach: Approximate Nearest Neighbor (ANN) graph construction,\nANN inter-component connection, and iterative edge refinement. For a dataset of\n$n$ points in a $d$-dimensional space, FAMST achieves $\\mathcal{O}(dn \\log n)$\ntime complexity and $\\mathcal{O}(dn + kn)$ space complexity when $k$ nearest\nneighbors are considered, which is a significant improvement over the\n$\\mathcal{O}(n^2)$ time and space complexity of traditional methods.\n  Experiments across diverse datasets demonstrate that FAMST achieves\nremarkably low approximation errors while providing speedups of up to\n1000$\\times$ compared to exact MST algorithms. We analyze how the key\nhyperparameters, $k$ (neighborhood size) and $\\lambda$ (inter-component edges),\naffect performance, providing practical guidelines for hyperparameter\nselection. FAMST enables MST-based analysis on datasets with millions of points\nand thousands of dimensions, extending the applicability of MST techniques to\nproblem scales previously considered infeasible.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14462", "pdf": "https://arxiv.org/pdf/2507.14462", "abs": "https://arxiv.org/abs/2507.14462", "authors": ["Xinpeng Jiang", "Haoyu Liu", "Siqiang Luo", "Xiaokui Xiao"], "title": "Tighter Lower Bounds for Single Source Personalized PageRank", "categories": ["cs.DS", "cs.CC"], "comment": "33 pages", "summary": "We study lower bounds for approximating the Single Source Personalized\nPageRank (SSPPR) query, which measures the probability distribution of an\n$\\alpha$-decay random walk starting from a source node $s$. Existing lower\nbounds remain loose-$\\Omega\\left(\\min(m, 1/\\delta)\\right)$ for relative error\n(SSPPR-R) and $\\Omega\\left(\\min(n, 1/\\epsilon)\\right)$ for additive error\n(SSPPR-A). To close this gap, we establish tighter bounds for both settings.\nFor SSPPR-R, we show a lower bound of $\\Omega\\left(\\min\\left(m,\n\\frac{\\log(1/\\delta)}{\\delta}\\right)\\right)$ for any $\\delta \\in (0,1)$. For\nSSPPR-A, we prove a lower bound of $\\Omega\\left(\\min\\left(m,\n\\frac{\\log(1/\\epsilon)}{\\epsilon}\\right)\\right)$ for any $\\epsilon \\in (0,1)$,\nassuming the graph has $m \\in \\mathcal{O}(n^{2-\\beta})$ edges for any\narbitrarily small constant $\\beta \\in (0,1)$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14504", "pdf": "https://arxiv.org/pdf/2507.14504", "abs": "https://arxiv.org/abs/2507.14504", "authors": ["Junqiang Peng", "Zimo Sheng", "Mingyu Xiao"], "title": "New Algorithms for #2-SAT and #3-SAT", "categories": ["cs.DS"], "comment": "Accepted by IJCAI 2025", "summary": "The #2-SAT and #3-SAT problems involve counting the number of satisfying\nassignments (also called models) for instances of 2-SAT and 3-SAT,\nrespectively. In 2010, Zhou et al. proposed an $\\mathcal{O}^*(1.1892^m)$-time\nalgorithm for #2-SAT and an efficient approach for #3-SAT, where $m$ denotes\nthe number of clauses. In this paper, we show that the weighted versions of\n#2-SAT and #3-SAT can be solved in $\\mathcal{O}^*(1.1082^m)$ and\n$\\mathcal{O}^*(1.4423^m)$ time, respectively. These results directly apply to\nthe unweighted cases and achieve substantial improvements over the previous\nresults. These advancements are enabled by the introduction of novel reduction\nrules, a refined analysis of branching operations, and the application of path\ndecompositions on the primal and dual graphs of the formula.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14509", "pdf": "https://arxiv.org/pdf/2507.14509", "abs": "https://arxiv.org/abs/2507.14509", "authors": ["Sheikh Shakil Akhtar", "Jayakrishnan Madathil", "Pranabendu Misra", "Geevarghese Philip"], "title": "Addressing Bias in Algorithmic Solutions: Exploring Vertex Cover and Feedback Vertex Set", "categories": ["cs.DS"], "comment": null, "summary": "A typical goal of research in combinatorial optimization is to come up with\nfast algorithms that find optimal solutions to a computational problem. The\nprocess that takes a real-world problem and extracts a clean mathematical\nabstraction of it often throws out a lot of \"side information\" which is deemed\nirrelevant. However, the discarded information could be of real significance to\nthe end-user of the algorithm's output. All solutions of the same cost are not\nnecessarily of equal impact in the real-world; some solutions may be much more\ndesirable than others, even at the expense of additional increase in cost. If\nthe impact, positive or negative, is mostly felt by some specific (minority)\nsubgroups of the population, the population at large will be largely unaware of\nit. In this work we ask the question of finding solutions to combinatorial\noptimization problems that are \"unbiased\" with respect to a collection of\nspecified subgroups of the total population.", "AI": {"tldr": "\u7814\u7a76\u7ec4\u5408\u4f18\u5316\u4e2d\u5bfb\u627e\u5bf9\u7279\u5b9a\u5b50\u7fa4\u4f53\u2018\u65e0\u504f\u2019\u7684\u89e3\u3002", "motivation": "\u7ec4\u5408\u4f18\u5316\u63d0\u53d6\u6570\u5b66\u62bd\u8c61\u65f6\u4e22\u5f03\u7684\u4fe1\u606f\u5bf9\u7b97\u6cd5\u8f93\u51fa\u7ec8\u7aef\u7528\u6237\u53ef\u80fd\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4e14\u76f8\u540c\u6210\u672c\u89e3\u5728\u73b0\u5b9e\u4e2d\u5f71\u54cd\u4e0d\u540c\uff0c\u9700\u5bfb\u627e\u5bf9\u7279\u5b9a\u5b50\u7fa4\u4f53\u2018\u65e0\u504f\u2019\u7684\u89e3\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2507.14376", "pdf": "https://arxiv.org/pdf/2507.14376", "abs": "https://arxiv.org/abs/2507.14376", "authors": ["Osman Erman Gungor", "Derak Paulsen", "William Kang"], "title": "Schemora: schema matching via multi-stage recommendation and metadata enrichment using off-the-shelf llms", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": "11 pages", "summary": "Schema matching is essential for integrating heterogeneous data sources and\nenhancing dataset discovery, yet it remains a complex and resource-intensive\nproblem. We introduce SCHEMORA, a schema matching framework that combines large\nlanguage models with hybrid retrieval techniques in a prompt-based approach,\nenabling efficient identification of candidate matches without relying on\nlabeled training data or exhaustive pairwise comparisons. By enriching schema\nmetadata and leveraging both vector-based and lexical retrieval, SCHEMORA\nimproves matching accuracy and scalability. Evaluated on the MIMIC-OMOP\nbenchmark, it establishes new state-of-the-art performance, with gains of 7.49%\nin HitRate@5 and 3.75% in HitRate@3 over previous best results. To our\nknowledge, this is the first LLM-based schema matching method with an\nopen-source implementation, accompanied by analysis that underscores the\ncritical role of retrieval and provides practical guidance on model selection.", "AI": {"tldr": "\u4ecb\u7ecdSCHEMORA\u6a21\u5f0f\u5339\u914d\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6df7\u5408\u68c0\u7d22\u6280\u672f\uff0c\u5728MIMIC - OMOP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0c\u4e14\u662f\u9996\u4e2a\u5f00\u6e90\u57fa\u4e8eLLM\u7684\u6a21\u5f0f\u5339\u914d\u65b9\u6cd5\u3002", "motivation": "\u6a21\u5f0f\u5339\u914d\u5bf9\u5f02\u6784\u6570\u636e\u6e90\u96c6\u6210\u548c\u6570\u636e\u96c6\u53d1\u73b0\u5f88\u91cd\u8981\uff0c\u4f46\u95ee\u9898\u590d\u6742\u4e14\u8d44\u6e90\u6d88\u8017\u5927\u3002", "method": "\u5f15\u5165SCHEMORA\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6df7\u5408\u68c0\u7d22\u6280\u672f\uff0c\u4e30\u5bcc\u6a21\u5f0f\u5143\u6570\u636e\uff0c\u5229\u7528\u57fa\u4e8e\u5411\u91cf\u548c\u8bcd\u6cd5\u7684\u68c0\u7d22\u3002", "result": "\u5728MIMIC - OMOP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHitRate@5\u63d0\u53477.49%\uff0cHitRate@3\u63d0\u53473.75%\uff0c\u8fbe\u5230\u65b0\u7684\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "SCHEMORA\u662f\u9996\u4e2a\u5f00\u6e90\u57fa\u4e8eLLM\u7684\u6a21\u5f0f\u5339\u914d\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u68c0\u7d22\u7684\u5173\u952e\u4f5c\u7528\u5e76\u63d0\u4f9b\u6a21\u578b\u9009\u62e9\u7684\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2507.14542", "pdf": "https://arxiv.org/pdf/2507.14542", "abs": "https://arxiv.org/abs/2507.14542", "authors": ["Yipeng Zhang", "Yuanyi Ding", "Chenda Duan", "Atsuro Daida", "Hiroki Nariai", "Vwani Roychowdhury"], "title": "Self-Supervised Distillation of Legacy Rule-Based Methods for Enhanced EEG-Based Decision-Making", "categories": ["cs.CE", "cs.CV"], "comment": null, "summary": "High-frequency oscillations (HFOs) in intracranial Electroencephalography\n(iEEG) are critical biomarkers for localizing the epileptogenic zone in\nepilepsy treatment. However, traditional rule-based detectors for HFOs suffer\nfrom unsatisfactory precision, producing false positives that require\ntime-consuming manual review. Supervised machine learning approaches have been\nused to classify the detection results, yet they typically depend on labeled\ndatasets, which are difficult to acquire due to the need for specialized\nexpertise. Moreover, accurate labeling of HFOs is challenging due to low\ninter-rater reliability and inconsistent annotation practices across\ninstitutions. The lack of a clear consensus on what constitutes a pathological\nHFO further challenges supervised refinement approaches. To address this, we\nleverage the insight that legacy detectors reliably capture clinically relevant\nsignals despite their relatively high false positive rates. We thus propose the\nSelf-Supervised to Label Discovery (SS2LD) framework to refine the large set of\ncandidate events generated by legacy detectors into a precise set of\npathological HFOs. SS2LD employs a variational autoencoder (VAE) for\nmorphological pre-training to learn meaningful latent representation of the\ndetected events. These representations are clustered to derive weak supervision\nfor pathological events. A classifier then uses this supervision to refine\ndetection boundaries, trained on real and VAE-augmented data. Evaluated on\nlarge multi-institutional interictal iEEG datasets, SS2LD outperforms\nstate-of-the-art methods. SS2LD offers a scalable, label-efficient, and\nclinically effective strategy to identify pathological HFOs using legacy\ndetectors.", "AI": {"tldr": "\u4f20\u7edfHFO\u68c0\u6d4b\u65b9\u6cd5\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u6709\u5927\u91cf\u8bef\u62a5\u4e14\u4f9d\u8d56\u96be\u83b7\u53d6\u7684\u6807\u6ce8\u6570\u636e\u3002\u672c\u6587\u63d0\u51faSS2LD\u6846\u67b6\uff0c\u5728\u591a\u673a\u6784\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u53ef\u6709\u6548\u8bc6\u522b\u75c5\u7406HFO\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684HFO\u68c0\u6d4b\u5668\u7cbe\u5ea6\u5dee\uff0c\u76d1\u7763\u5f0f\u673a\u5668\u5b66\u4e60\u4f9d\u8d56\u96be\u83b7\u53d6\u7684\u6807\u6ce8\u6570\u636e\uff0c\u4e14HFO\u51c6\u786e\u6807\u6ce8\u56f0\u96be\u3001\u7f3a\u4e4f\u75c5\u7406HFO\u5171\u8bc6\uff0c\u9700\u6539\u8fdbHFO\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSS2LD\u6846\u67b6\uff0c\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u8fdb\u884c\u5f62\u6001\u9884\u8bad\u7ec3\u5b66\u4e60\u4e8b\u4ef6\u6f5c\u5728\u8868\u793a\uff0c\u805a\u7c7b\u8fd9\u4e9b\u8868\u793a\u5f97\u5230\u5f31\u76d1\u7763\uff0c\u7528\u5206\u7c7b\u5668\u5728\u771f\u5b9e\u548cVAE\u589e\u5f3a\u6570\u636e\u4e0a\u8bad\u7ec3\u7ec6\u5316\u68c0\u6d4b\u8fb9\u754c\u3002", "result": "\u5728\u5927\u578b\u591a\u673a\u6784\u53d1\u4f5c\u95f4\u671fiEEG\u6570\u636e\u96c6\u4e0a\uff0cSS2LD\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SS2LD\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u6807\u7b7e\u9ad8\u6548\u4e14\u4e34\u5e8a\u6709\u6548\u7684\u7b56\u7565\uff0c\u80fd\u5229\u7528\u4f20\u7edf\u68c0\u6d4b\u5668\u8bc6\u522b\u75c5\u7406HFO\u3002"}}
{"id": "2507.14270", "pdf": "https://arxiv.org/pdf/2507.14270", "abs": "https://arxiv.org/abs/2507.14270", "authors": ["Ravin Kumar"], "title": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "comment": "10 pages, 2 figures, 1 table, and GitHub repository for the source\n  code", "summary": "We propose the APTx Neuron, a novel, unified neural computation unit that\nintegrates non-linear activation and linear transformation into a single\ntrainable expression. The APTx Neuron is derived from the APTx activation\nfunction, thereby eliminating the need for separate activation layers and\nmaking the architecture both computationally efficient and elegant. The\nproposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i +\n\\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters\n$\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our\nAPTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\\%\ntest accuracy in just 20 epochs using approximately 332K trainable parameters.\nThe results highlight the superior expressiveness and computational efficiency\nof the APTx Neuron compared to traditional neurons, pointing toward a new\nparadigm in unified neuron design and the architectures built upon it.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14392", "pdf": "https://arxiv.org/pdf/2507.14392", "abs": "https://arxiv.org/abs/2507.14392", "authors": ["Lang Xu", "Kaushik Kandadi Suresh", "Quentin Anthony", "Nawras Alnaasan", "Dhabaleswar K. Panda"], "title": "Characterizing Communication Patterns in Distributed Large Language Model Inference", "categories": ["cs.DC"], "comment": "To be presented at Hot Interconnects 2025", "summary": "Large Language Models (LLMs) built on transformer architectures have\ntransformed natural language processing, achieving remarkable performance\nacross diverse applications. While distributed inference frameworks enable\npractical deployment of these models, inter-GPU communication creates\nsignificant performance constraints that limit service quality in real-world\nsystems. This paper investigates communication dynamics in distributed LLM\nserving-analyzing how various parallelization approaches coordinate data\nexchange between GPU workers during inference. We study dense transformer-based\nmodels as representative examples of contemporary architectures widely used in\noperational deployments. Our work combines detailed profiling measurements with\npredictive analytical models to characterize communication behavior across\ndifferent parallelization configurations. Results show that tensor parallelism\nincurs substantial network overhead but delivers superior response times for\nbrief sequences, pipeline parallelism minimizes data transfer requirements\nwhile increasing total latency, and combined approaches demand careful tuning\nto achieve balanced performance. These insights offer practical recommendations\nfor selecting appropriate parallelization schemes in production LLM services\nand identify key opportunities for optimizing inference frameworks and\ncommunication infrastructure.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5206\u5e03\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u4e2d\u7684\u901a\u4fe1\u52a8\u6001\uff0c\u7ed3\u5408\u6d4b\u91cf\u4e0e\u5206\u6790\u6a21\u578b\uff0c\u5bf9\u6bd4\u4e0d\u540c\u5e76\u884c\u914d\u7f6e\u901a\u4fe1\u884c\u4e3a\uff0c\u4e3a\u751f\u4ea7\u670d\u52a1\u9009\u5e76\u884c\u65b9\u6848\u53ca\u4f18\u5316\u63d0\u4f9b\u5efa\u8bae\u3002", "motivation": "\u5206\u5e03\u5f0f\u63a8\u7406\u6846\u67b6\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0cGPU\u95f4\u901a\u4fe1\u9650\u5236\u6027\u80fd\u548c\u670d\u52a1\u8d28\u91cf\uff0c\u9700\u7814\u7a76\u901a\u4fe1\u52a8\u6001\u3002", "method": "\u4ee5\u5bc6\u96c6\u53d8\u538b\u5668\u6a21\u578b\u4e3a\u4ee3\u8868\uff0c\u7ed3\u5408\u8be6\u7ec6\u6027\u80fd\u5206\u6790\u6d4b\u91cf\u548c\u9884\u6d4b\u5206\u6790\u6a21\u578b\uff0c\u7814\u7a76\u4e0d\u540c\u5e76\u884c\u5316\u914d\u7f6e\u7684\u901a\u4fe1\u884c\u4e3a\u3002", "result": "\u5f20\u91cf\u5e76\u884c\u7f51\u7edc\u5f00\u9500\u5927\u4f46\u77ed\u5e8f\u5217\u54cd\u5e94\u597d\uff0c\u6d41\u6c34\u7ebf\u5e76\u884c\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u4f46\u589e\u52a0\u603b\u5ef6\u8fdf\uff0c\u7ec4\u5408\u65b9\u6cd5\u9700\u7cbe\u7ec6\u8c03\u4f18\u3002", "conclusion": "\u7814\u7a76\u4e3a\u751f\u4ea7\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u9009\u62e9\u5e76\u884c\u65b9\u6848\u63d0\u4f9b\u5b9e\u7528\u5efa\u8bae\uff0c\u6307\u51fa\u4f18\u5316\u63a8\u7406\u6846\u67b6\u548c\u901a\u4fe1\u57fa\u7840\u8bbe\u65bd\u7684\u5173\u952e\u673a\u4f1a\u3002"}}
{"id": "2507.14154", "pdf": "https://arxiv.org/pdf/2507.14154", "abs": "https://arxiv.org/abs/2507.14154", "authors": ["Rahul Kabali"], "title": "The Free Will Equation: Quantum Field Analogies for AGI", "categories": ["cs.AI", "cs.LG", "68T05, 81P68", "I.2.6; I.2.0; F.1.2"], "comment": "22 pages, 5 figures. Submitted as an arXiv preprint. All code and\n  experiment details included in appendix", "summary": "Artificial General Intelligence (AGI) research traditionally focuses on\nalgorithms that optimize for specific goals under deterministic rules. Yet,\nhuman-like intelligence exhibits adaptive spontaneity - an ability to make\nunexpected choices or free decisions not strictly dictated by past data or\nimmediate reward. This trait, often dubbed \"free will\" in a loose sense, might\nbe crucial for creativity, robust adaptation, and avoiding ruts in\nproblem-solving. This paper proposes a theoretical framework, called the Free\nWill Equation, that draws analogies from quantum field theory to endow AGI\nagents with a form of adaptive, controlled stochasticity in their\ndecision-making process. The core idea is to treat an AI agent's cognitive\nstate as a superposition of potential actions or thoughts, which collapses\nprobabilistically into a concrete action when a decision is made - much like a\nquantum wavefunction collapsing upon measurement. By incorporating mechanisms\nanalogous to quantum fields, along with intrinsic motivation terms, we aim to\nimprove an agent's ability to explore novel strategies and adapt to unforeseen\nchanges. Experiments in a non-stationary multi-armed bandit environment\ndemonstrate that agents using this framework achieve higher rewards and policy\ndiversity compared to baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u7531\u610f\u5fd7\u65b9\u7a0b\u7406\u8bba\u6846\u67b6\uff0c\u501f\u9274\u91cf\u5b50\u573a\u8bba\u8d4b\u4e88AGI\u51b3\u7b56\u968f\u673a\u9002\u5e94\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u4e0b\u7684\u667a\u80fd\u4f53\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u4f20\u7edfAGI\u7814\u7a76\u4e13\u6ce8\u7279\u5b9a\u76ee\u6807\u7b97\u6cd5\uff0c\u800c\u4eba\u7c7b\u667a\u80fd\u6709\u81ea\u9002\u5e94\u81ea\u53d1\u6027\uff0c\u6b64\u7279\u6027\u5bf9\u521b\u9020\u529b\u7b49\u5f88\u91cd\u8981\uff0c\u6240\u4ee5\u60f3\u8d4b\u4e88AGI\u7c7b\u4f3c\u7279\u6027\u3002", "method": "\u63d0\u51fa\u81ea\u7531\u610f\u5fd7\u65b9\u7a0b\u7406\u8bba\u6846\u67b6\uff0c\u5c06AI\u8ba4\u77e5\u72b6\u6001\u89c6\u4e3a\u6f5c\u5728\u884c\u52a8\u6216\u60f3\u6cd5\u7684\u53e0\u52a0\u6001\uff0c\u51b3\u7b56\u65f6\u6982\u7387\u6027\u574d\u7f29\uff0c\u7ed3\u5408\u7c7b\u91cf\u5b50\u573a\u673a\u5236\u548c\u5185\u5728\u52a8\u673a\u9879\u3002", "result": "\u5728\u975e\u5e73\u7a33\u591a\u81c2\u8001\u864e\u673a\u73af\u5883\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u7684\u667a\u80fd\u4f53\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u5956\u52b1\u548c\u7b56\u7565\u591a\u6837\u6027\u3002", "conclusion": "\u81ea\u7531\u610f\u5fd7\u65b9\u7a0b\u7406\u8bba\u6846\u67b6\u80fd\u63d0\u5347AGI\u63a2\u7d22\u65b0\u7b56\u7565\u548c\u9002\u5e94\u610f\u5916\u53d8\u5316\u7684\u80fd\u529b\u3002"}}
{"id": "2507.14256", "pdf": "https://arxiv.org/pdf/2507.14256", "abs": "https://arxiv.org/abs/2507.14256", "authors": ["Jakub Walczak", "Piotr Tomalak", "Artur Laskowski"], "title": "Impact of Code Context and Prompting Strategies on Automated Unit Test Generation with Modern General-Purpose Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Generative AI is gaining increasing attention in software engineering, where\ntesting remains an indispensable reliability mechanism. According to the widely\nadopted testing pyramid, unit tests constitute the majority of test cases and\nare often schematic, requiring minimal domain expertise. Automatically\ngenerating such tests under the supervision of software engineers can\nsignificantly enhance productivity during the development phase of the software\nlifecycle.\n  This paper investigates the impact of code context and prompting strategies\non the quality and adequacy of unit tests generated by various large language\nmodels (LLMs) across several families. The results show that including\ndocstrings notably improves code adequacy, while further extending context to\nthe full implementation yields definitely smaller gains. Notably, the\nchain-of-thought prompting strategy -- applied even to 'reasoning' models --\nachieves the best results, with up to 96.3\\% branch coverage, a 57\\% average\nmutation score, and near-perfect compilation success rate. Among the evaluated\nmodels, M5 (Gemini 2.5 Pro) demonstrated superior performance in both mutation\nscore and branch coverage being still in top in terms of compilation success\nrate.\n  All the code and resulting test suites are publicly available at\nhttps://github.com/peetery/LLM-analysis.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u65f6\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u7ed3\u679c\u663e\u793a\u5305\u542b\u6587\u6863\u5b57\u7b26\u4e32\u3001\u7279\u5b9a\u63d0\u793a\u7b56\u7565\u53caM5\u6a21\u578b\u8868\u73b0\u4f73\uff0c\u4ee3\u7801\u548c\u6d4b\u8bd5\u5957\u4ef6\u5f00\u6e90\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6d4b\u8bd5\u4e2d\u53d7\u5173\u6ce8\uff0c\u81ea\u52a8\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u53ef\u63d0\u9ad8\u8f6f\u4ef6\u5f00\u53d1\u9636\u6bb5\u751f\u4ea7\u529b\uff0c\u56e0\u6b64\u7814\u7a76\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u7b56\u7565\u5bf9\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u8d28\u91cf\u548c\u5145\u5206\u6027\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u4e0d\u540c\u5bb6\u65cf\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u7b56\u7565\u4e0b\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u60c5\u51b5\u3002", "result": "\u5305\u542b\u6587\u6863\u5b57\u7b26\u4e32\u53ef\u663e\u8457\u63d0\u9ad8\u4ee3\u7801\u5145\u5206\u6027\uff0c\u6269\u5c55\u5230\u5b8c\u6574\u5b9e\u73b0\u589e\u76ca\u8f83\u5c0f\uff1b\u601d\u7ef4\u94fe\u63d0\u793a\u7b56\u7565\u6548\u679c\u6700\u4f73\uff0cM5\uff08Gemini 2.5 Pro\uff09\u5728\u7a81\u53d8\u5206\u6570\u3001\u5206\u652f\u8986\u76d6\u7387\u548c\u7f16\u8bd1\u6210\u529f\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u7b56\u7565\u5bf9\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u8d28\u91cf\u548c\u5145\u5206\u6027\u6709\u5f71\u54cd\uff0c\u601d\u7ef4\u94fe\u63d0\u793a\u7b56\u7565\u548cM5\u6a21\u578b\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2507.14301", "pdf": "https://arxiv.org/pdf/2507.14301", "abs": "https://arxiv.org/abs/2507.14301", "authors": ["Yuxin Liu", "Yuezhang Peng", "Hefeng Zhou", "Hongze Liu", "Xinyu Lu", "Jiong Lou", "Chentao Wu", "Wei Zhao", "Jie Li"], "title": "LOVO: Efficient Complex Object Query in Large-Scale Video Datasets", "categories": ["cs.IR", "cs.CV", "cs.DB"], "comment": "@inproceedings{liu2025lovo,title={LOVO: Efficient Complex Object\n  Query in Large-Scale Video Datasets},author={Liu, Yuxin and Peng, Yuezhang\n  and Zhou, Hefeng and Liu, Hongze and Lu, Xinyu and Lou, Jiong and Wu, Chentao\n  and Zhao, Wei and Li, Jie},booktitle={2025 IEEE 41st International Conference\n  on Data Engineering (ICDE)},pages={1938--1951},year={2025},organization={IEEE\n  Computer Society}}", "summary": "The widespread deployment of cameras has led to an exponential increase in\nvideo data, creating vast opportunities for applications such as traffic\nmanagement and crime surveillance. However, querying specific objects from\nlarge-scale video datasets presents challenges, including (1) processing\nmassive and continuously growing data volumes, (2) supporting complex query\nrequirements, and (3) ensuring low-latency execution. Existing video analysis\nmethods struggle with either limited adaptability to unseen object classes or\nsuffer from high query latency. In this paper, we present LOVO, a novel system\ndesigned to efficiently handle comp$\\underline{L}$ex $\\underline{O}$bject\nqueries in large-scale $\\underline{V}$ide$\\underline{O}$ datasets. Agnostic to\nuser queries, LOVO performs one-time feature extraction using pre-trained\nvisual encoders, generating compact visual embeddings for key frames to build\nan efficient index. These visual embeddings, along with associated bounding\nboxes, are organized in an inverted multi-index structure within a vector\ndatabase, which supports queries for any objects. During the query phase, LOVO\ntransforms object queries to query embeddings and conducts fast approximate\nnearest-neighbor searches on the visual embeddings. Finally, a cross-modal\nrerank is performed to refine the results by fusing visual features with\ndetailed textual features. Evaluation on real-world video datasets demonstrates\nthat LOVO outperforms existing methods in handling complex queries, with\nnear-optimal query accuracy and up to 85x lower search latency, while\nsignificantly reducing index construction costs. This system redefines the\nstate-of-the-art object query approaches in video analysis, setting a new\nbenchmark for complex object queries with a novel, scalable, and efficient\napproach that excels in dynamic environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLOVO\u7cfb\u7edf\u5904\u7406\u5927\u89c4\u6a21\u89c6\u9891\u6570\u636e\u96c6\u590d\u6742\u5bf9\u8c61\u67e5\u8be2\uff0c\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u3001\u5efa\u7d22\u5f15\u3001\u67e5\u8be2\u8f6c\u6362\u548c\u91cd\u6392\u5e8f\u7b49\u64cd\u4f5c\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u5206\u6790\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u89c6\u9891\u6570\u636e\u96c6\u7279\u5b9a\u5bf9\u8c61\u67e5\u8be2\u65f6\u5b58\u5728\u9002\u5e94\u6027\u5dee\u3001\u67e5\u8be2\u5ef6\u8fdf\u9ad8\u7b49\u95ee\u9898\uff0c\u9700\u65b0\u7cfb\u7edf\u89e3\u51b3\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\u8fdb\u884c\u4e00\u6b21\u6027\u7279\u5f81\u63d0\u53d6\uff0c\u751f\u6210\u5173\u952e\u5e27\u89c6\u89c9\u5d4c\u5165\u6784\u5efa\u9ad8\u6548\u7d22\u5f15\uff1b\u5728\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u7ec4\u7ec7\u89c6\u89c9\u5d4c\u5165\u548c\u8fb9\u754c\u6846\uff1b\u67e5\u8be2\u65f6\u5c06\u5bf9\u8c61\u67e5\u8be2\u8f6c\u6362\u4e3a\u67e5\u8be2\u5d4c\u5165\uff0c\u8fdb\u884c\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff1b\u6700\u540e\u8fdb\u884c\u8de8\u6a21\u6001\u91cd\u6392\u5e8f\u3002", "result": "\u5728\u771f\u5b9e\u89c6\u9891\u6570\u636e\u96c6\u4e0a\uff0cLOVO\u5904\u7406\u590d\u6742\u67e5\u8be2\u65f6\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u67e5\u8be2\u7cbe\u5ea6\u63a5\u8fd1\u6700\u4f18\uff0c\u641c\u7d22\u5ef6\u8fdf\u964d\u4f4e\u8fbe85\u500d\uff0c\u663e\u8457\u964d\u4f4e\u7d22\u5f15\u6784\u5efa\u6210\u672c\u3002", "conclusion": "LOVO\u91cd\u65b0\u5b9a\u4e49\u4e86\u89c6\u9891\u5206\u6790\u4e2d\u5bf9\u8c61\u67e5\u8be2\u65b9\u6cd5\uff0c\u4e3a\u590d\u6742\u5bf9\u8c61\u67e5\u8be2\u63d0\u4f9b\u65b0\u9896\u3001\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u73af\u5883\u3002"}}
{"id": "2507.14331", "pdf": "https://arxiv.org/pdf/2507.14331", "abs": "https://arxiv.org/abs/2507.14331", "authors": ["Nima Taheri Hosseinkhani"], "title": "The Electoral Consequences of Natural Disasters: A Dynamic Fixed-Effects Analysis", "categories": ["econ.GN", "q-fin.EC"], "comment": "The current version is a preprint", "summary": "With the increasing frequency of major natural disasters, understanding their\npolitical consequences is of paramount importance for democratic\naccountability. The existing literature is deeply divided, with some studies\nfinding that voters punish incumbents for disaster-related damages, while\nothers find they reward them for relief efforts. This paper investigates the\nelectoral consequences of natural disasters for incumbent mayors, broader\nelectoral dynamics, and the long-term political ambition of officeholders. The\nstudy leverages a comprehensive panel dataset of over 10,000 candidate-election\nobservations in U.S. mayoral races from 1989 to 2021, combining detailed\nelection data with a global registry of disaster events. To identify causal\neffects, the analysis employs a robust dynamic two-way fixed-effects\nevent-study design, validated by extensive pre-trend and placebo tests. The\nfindings reveal that the electoral impact of disasters is highly conditional on\ntheir timing. A disaster that strikes in the same quarter as an election\nprovides a significant electoral boost to incumbents, increasing their vote\nshare by over 6 percentage points. However, disasters consistently suppress\nvoter turnout, reducing it by an average of 1.4 percentage points. In a novel\nfinding, the analysis demonstrates that the experience of managing a disaster\nsignificantly increases an incumbent's likelihood of seeking re-election in the\nsubsequent cycle by as much as 12 percentage points. These findings help\nreconcile conflicting theories of retrospective voting by highlighting the\ncritical role of voter myopia and salience. They also reveal a previously\nundocumented channel through which crises shape political careers, suggesting\nthat disaster management is not only a test of governance but also a catalyst\nfor political ambition. [The current version is a preprint.]", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u81ea\u7136\u707e\u5bb3\u5bf9\u7f8e\u56fd\u5e02\u957f\u9009\u4e3e\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u707e\u5bb3\u5f71\u54cd\u53d6\u51b3\u4e8e\u53d1\u751f\u65f6\u95f4\uff0c\u8fd8\u5f71\u54cd\u9009\u6c11\u6295\u7968\u7387\u548c\u5b98\u5458\u7ade\u9009\u610f\u613f\uff0c\u8c03\u548c\u4e86\u56de\u987e\u6027\u6295\u7968\u7406\u8bba\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u5bf9\u81ea\u7136\u707e\u5bb3\u653f\u6cbb\u540e\u679c\u89c2\u70b9\u4e0d\u4e00\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u5176\u5bf9\u73b0\u4efb\u5e02\u957f\u9009\u4e3e\u3001\u9009\u4e3e\u52a8\u6001\u548c\u5b98\u5458\u653f\u6cbb\u91ce\u5fc3\u7684\u5f71\u54cd\u3002", "method": "\u5229\u75281989 - 2021\u5e74\u8d8510000\u4e2a\u7f8e\u56fd\u5e02\u957f\u7ade\u9009\u89c2\u5bdf\u6570\u636e\uff0c\u7ed3\u5408\u707e\u5bb3\u4e8b\u4ef6\u767b\u8bb0\u4fe1\u606f\uff0c\u91c7\u7528\u52a8\u6001\u53cc\u5411\u56fa\u5b9a\u6548\u5e94\u4e8b\u4ef6\u7814\u7a76\u8bbe\u8ba1\uff0c\u5e76\u8fdb\u884c\u9884\u8d8b\u52bf\u548c\u5b89\u6170\u5242\u6d4b\u8bd5\u3002", "result": "\u9009\u4e3e\u540c\u671f\u707e\u5bb3\u4f7f\u73b0\u4efb\u8005\u9009\u7968\u589e\u52a0\u8d856\u4e2a\u767e\u5206\u70b9\uff0c\u707e\u5bb3\u964d\u4f4e\u6295\u7968\u73871.4\u4e2a\u767e\u5206\u70b9\uff0c\u5904\u7406\u707e\u5bb3\u4f7f\u73b0\u4efb\u8005\u518d\u6b21\u7ade\u9009\u53ef\u80fd\u6027\u589e\u52a012\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u7814\u7a76\u8c03\u548c\u4e86\u56de\u987e\u6027\u6295\u7968\u7406\u8bba\uff0c\u6307\u51fa\u9009\u6c11\u77ed\u89c6\u548c\u663e\u8457\u6027\u7684\u5173\u952e\u4f5c\u7528\uff0c\u63ed\u793a\u5371\u673a\u5851\u9020\u653f\u6cbb\u751f\u6daf\u7684\u65b0\u9014\u5f84\uff0c\u8868\u660e\u707e\u5bb3\u7ba1\u7406\u662f\u6cbb\u7406\u8003\u9a8c\u548c\u653f\u6cbb\u91ce\u5fc3\u50ac\u5316\u5242\u3002"}}
{"id": "2507.14193", "pdf": "https://arxiv.org/pdf/2507.14193", "abs": "https://arxiv.org/abs/2507.14193", "authors": ["Tori Qiu", "Benjamin Laufer", "Jon Kleinberg", "Hoda Heidari"], "title": "A Formal Model of the Economic Impacts of AI Openness Regulation", "categories": ["cs.GT", "cs.AI", "cs.CY"], "comment": null, "summary": "Regulatory frameworks, such as the EU AI Act, encourage openness of\ngeneral-purpose AI models by offering legal exemptions for \"open-source\"\nmodels. Despite this legislative attention on openness, the definition of\nopen-source foundation models remains ambiguous. This paper models the\nstrategic interactions among the creator of a general-purpose model (the\ngeneralist) and the entity that fine-tunes the general-purpose model to a\nspecialized domain or task (the specialist), in response to regulatory\nrequirements on model openness. We present a stylized model of the regulator's\nchoice of an open-source definition to evaluate which AI openness standards\nwill establish appropriate economic incentives for developers. Our results\ncharacterize market equilibria -- specifically, upstream model release\ndecisions and downstream fine-tuning efforts -- under various openness\nregulations and present a range of effective regulatory penalties and\nopen-source thresholds. Overall, we find the model's baseline performance\ndetermines when increasing the regulatory penalty vs. the open-source threshold\nwill significantly alter the generalist's release strategy. Our model provides\na theoretical foundation for AI governance decisions around openness and\nenables evaluation and refinement of practical open-source policies.", "AI": {"tldr": "\u672c\u6587\u5efa\u6a21\u901a\u7528\u6a21\u578b\u521b\u5efa\u8005\u4e0e\u5fae\u8c03\u8005\u7684\u7b56\u7565\u4e92\u52a8\uff0c\u8bc4\u4f30AI\u5f00\u653e\u6807\u51c6\uff0c\u7ed9\u51fa\u5e02\u573a\u5747\u8861\u7279\u5f81\u53ca\u6709\u6548\u76d1\u7ba1\u63aa\u65bd\uff0c\u53d1\u73b0\u6a21\u578b\u57fa\u7ebf\u6027\u80fd\u5f71\u54cd\u901a\u7528\u6a21\u578b\u53d1\u5e03\u7b56\u7565\uff0c\u4e3aAI\u5f00\u653e\u6cbb\u7406\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u76d1\u7ba1\u6846\u67b6\u5173\u6ce8AI\u6a21\u578b\u5f00\u653e\u6027\uff0c\u4f46\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u5b9a\u4e49\u6a21\u7cca\uff0c\u9700\u8bc4\u4f30\u5408\u9002\u7684AI\u5f00\u653e\u6807\u51c6\u4ee5\u7ed9\u5f00\u53d1\u8005\u63d0\u4f9b\u7ecf\u6d4e\u6fc0\u52b1\u3002", "method": "\u5efa\u6a21\u901a\u7528\u6a21\u578b\u521b\u5efa\u8005\uff08\u901a\u624d\uff09\u548c\u5fae\u8c03\u5b9e\u4f53\uff08\u4e13\u624d\uff09\u7684\u7b56\u7565\u4e92\u52a8\uff0c\u6784\u5efa\u76d1\u7ba1\u8005\u9009\u62e9\u5f00\u6e90\u5b9a\u4e49\u7684\u7b80\u5316\u6a21\u578b\u3002", "result": "\u523b\u753b\u4e86\u4e0d\u540c\u5f00\u653e\u76d1\u7ba1\u4e0b\u7684\u5e02\u573a\u5747\u8861\uff0c\u7ed9\u51fa\u4e00\u7cfb\u5217\u6709\u6548\u7684\u76d1\u7ba1\u60e9\u7f5a\u548c\u5f00\u6e90\u9608\u503c\uff0c\u53d1\u73b0\u6a21\u578b\u57fa\u7ebf\u6027\u80fd\u51b3\u5b9a\u589e\u52a0\u76d1\u7ba1\u60e9\u7f5a\u6216\u5f00\u6e90\u9608\u503c\u4f55\u65f6\u663e\u8457\u6539\u53d8\u901a\u7528\u6a21\u578b\u53d1\u5e03\u7b56\u7565\u3002", "conclusion": "\u6a21\u578b\u4e3aAI\u5f00\u653e\u6cbb\u7406\u51b3\u7b56\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30\u548c\u5b8c\u5584\u5b9e\u9645\u5f00\u6e90\u653f\u7b56\u3002"}}
{"id": "2507.14597", "pdf": "https://arxiv.org/pdf/2507.14597", "abs": "https://arxiv.org/abs/2507.14597", "authors": ["Eugene Armah", "Linda Amoako Bannning"], "title": "Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning", "categories": ["cs.DC", "cs.CV", "cs.LG", "cs.PF"], "comment": null, "summary": "Processing data at high speeds is becoming increasingly critical as digital\neconomies generate enormous data. The current paradigms for timely data\nprocessing are edge computing and data stream processing (DSP). Edge computing\nplaces resources closer to where data is generated, while stream processing\nanalyzes the unbounded high-speed data in motion. However, edge stream\nprocessing faces rapid workload fluctuations, complicating resource\nprovisioning. Inadequate resource allocation leads to bottlenecks, whereas\nexcess allocation results in wastage. Existing reactive methods, such as\nthreshold-based policies and queuing theory scale only after performance\ndegrades, potentially violating SLAs. Although reinforcement learning (RL)\noffers a proactive approach through agents that learn optimal runtime\nadaptation policies, it requires extensive simulation. Furthermore, predictive\nmachine learning models face online distribution and concept drift that\nminimize their accuracy. We propose a three-step solution to the proactive edge\nstream processing autoscaling problem. Firstly, a GRU neural network forecasts\nthe upstream load using real-world and synthetic DSP datasets. Secondly, a\ntransfer learning framework integrates the predictive model into an online\nstream processing system using the DTW algorithm and joint distribution\nadaptation to handle the disparities between offline and online domains.\nFinally, a horizontal autoscaling module dynamically adjusts the degree of\noperator parallelism, based on predicted load while considering edge resource\nconstraints. The lightweight GRU model for load predictions recorded up to\n1.3\\% SMAPE value on a real-world data set. It outperformed CNN, ARIMA, and\nProphet on the SMAPE and RMSE evaluation metrics, with lower training time than\nthe computationally intensive RL models.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u6b65\u89e3\u51b3\u65b9\u6848\u89e3\u51b3\u4e3b\u52a8\u5f0f\u8fb9\u7f18\u6d41\u5904\u7406\u81ea\u52a8\u6269\u5c55\u95ee\u9898\uff0cGRU\u6a21\u578b\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u8fb9\u7f18\u6d41\u5904\u7406\u9762\u4e34\u5de5\u4f5c\u8d1f\u8f7d\u5feb\u901f\u6ce2\u52a8\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u5982\u53cd\u5e94\u5f0f\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u540e\u624d\u6269\u5c55\uff0cRL\u9700\u5927\u91cf\u6a21\u62df\uff0c\u9884\u6d4b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6709\u7cbe\u5ea6\u95ee\u9898\u3002", "method": "\u9996\u5148\u7528GRU\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u9884\u6d4b\u4e0a\u6e38\u8d1f\u8f7d\uff1b\u5176\u6b21\u7528\u8f6c\u79fb\u5b66\u4e60\u6846\u67b6\u5c06\u9884\u6d4b\u6a21\u578b\u96c6\u6210\u5230\u5728\u7ebf\u6d41\u5904\u7406\u7cfb\u7edf\uff1b\u6700\u540e\u6c34\u5e73\u81ea\u52a8\u6269\u5c55\u6a21\u5757\u6839\u636e\u9884\u6d4b\u8d1f\u8f7d\u548c\u8fb9\u7f18\u8d44\u6e90\u7ea6\u675f\u52a8\u6001\u8c03\u6574\u7b97\u5b50\u5e76\u884c\u5ea6\u3002", "result": "\u8f7b\u91cf\u7ea7GRU\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0aSMAPE\u503c\u8fbe1.3%\uff0c\u5728SMAPE\u548cRMSE\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8eCNN\u3001ARIMA\u548cProphet\uff0c\u8bad\u7ec3\u65f6\u95f4\u6bd4RL\u6a21\u578b\u77ed\u3002", "conclusion": "\u6240\u63d0\u4e09\u6b65\u89e3\u51b3\u65b9\u6848\u80fd\u6709\u6548\u89e3\u51b3\u4e3b\u52a8\u5f0f\u8fb9\u7f18\u6d41\u5904\u7406\u81ea\u52a8\u6269\u5c55\u95ee\u9898\uff0cGRU\u6a21\u578b\u6709\u8f83\u597d\u6027\u80fd\u3002"}}
{"id": "2507.14170", "pdf": "https://arxiv.org/pdf/2507.14170", "abs": "https://arxiv.org/abs/2507.14170", "authors": ["Jaeheun Jung", "Donghun Lee"], "title": "Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 workshop HiLD 2025 (3rd workshop on High-dimensional\n  Learning Dynamics)", "summary": "Structured pruning aims to reduce the size and computational cost of deep\nneural networks by removing entire filters or channels. The traditional\nregularizers such as L1 or Group Lasso and its variants lead to\nmagnitude-biased pruning decisions, such that the filters with small magnitudes\nare likely to be pruned. Also, they often entail pruning results with almost\nzero margin around pruning decision boundary, such that tiny perturbation in a\nfilter magnitude can flip the pruning decision. In this paper, we identify the\nprecise algebraic condition under which pruning operations preserve model\nperformance, and use the condition to construct a novel regularizer defined in\nan extended parameter space via auxiliary catalyst variables. The proposed\nCatalyst regularization ensures fair pruning chance for each filters with\ntheoretically provable zero bias to their magnitude and robust pruning behavior\nachieved by wide-margin bifurcation of magnitudes between the preserved and the\npruned filters. The theoretical properties naturally lead to real-world\neffectiveness, as shown by empirical validations of Catalyst Pruning algorithm.\nPruning results on various datasets and models are superior to state-of-the-art\nfilter pruning methods, and at the same time confirm the predicted robust and\nfair pruning characteristics of Catalyst pruning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCatalyst\u6b63\u5219\u5316\u65b9\u6cd5\u7528\u4e8e\u7ed3\u6784\u5316\u526a\u679d\uff0c\u7406\u8bba\u4e0a\u786e\u4fdd\u516c\u5e73\u4e14\u9c81\u68d2\u7684\u526a\u679d\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6b63\u5219\u5316\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u526a\u679d\u65f6\u5b58\u5728\u5e45\u5ea6\u504f\u7f6e\u548c\u526a\u679d\u51b3\u7b56\u8fb9\u754c\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002", "method": "\u786e\u5b9a\u526a\u679d\u64cd\u4f5c\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u7cbe\u786e\u4ee3\u6570\u6761\u4ef6\uff0c\u901a\u8fc7\u8f85\u52a9\u50ac\u5316\u5242\u53d8\u91cf\u5728\u6269\u5c55\u53c2\u6570\u7a7a\u95f4\u6784\u5efa\u65b0\u578b\u6b63\u5219\u5316\u5668\u3002", "result": "\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u526a\u679d\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u6ee4\u6ce2\u5668\u526a\u679d\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u4e86Catalyst\u526a\u679d\u7684\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u3002", "conclusion": "Catalyst\u6b63\u5219\u5316\u80fd\u5b9e\u73b0\u516c\u5e73\u4e14\u9c81\u68d2\u7684\u526a\u679d\uff0c\u5177\u6709\u5b9e\u9645\u6709\u6548\u6027\u3002"}}
{"id": "2507.14444", "pdf": "https://arxiv.org/pdf/2507.14444", "abs": "https://arxiv.org/abs/2507.14444", "authors": ["Yuejie Chi", "Yuxin Chen", "Yuting Wei"], "title": "Statistical and Algorithmic Foundations of Reinforcement Learning", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "math.ST", "stat.TH"], "comment": "reading materials for INFORMS Tutorial in OR 2025", "summary": "As a paradigm for sequential decision making in unknown environments,\nreinforcement learning (RL) has received a flurry of attention in recent years.\nHowever, the explosion of model complexity in emerging applications and the\npresence of nonconvexity exacerbate the challenge of achieving efficient RL in\nsample-starved situations, where data collection is expensive, time-consuming,\nor even high-stakes (e.g., in clinical trials, autonomous systems, and online\nadvertising). How to understand and enhance the sample and computational\nefficacies of RL algorithms is thus of great interest. In this tutorial, we aim\nto introduce several important algorithmic and theoretical developments in RL,\nhighlighting the connections between new ideas and classical topics. Employing\nMarkov Decision Processes as the central mathematical model, we cover several\ndistinctive RL scenarios (i.e., RL with a simulator, online RL, offline RL,\nrobust RL, and RL with human feedback), and present several mainstream RL\napproaches (i.e., model-based approach, value-based approach, and policy\noptimization). Our discussions gravitate around the issues of sample\ncomplexity, computational efficiency, as well as algorithm-dependent and\ninformation-theoretic lower bounds from a non-asymptotic viewpoint.", "AI": {"tldr": "\u4ecb\u7ecd\u5f3a\u5316\u5b66\u4e60\u5728\u6837\u672c\u7a00\u7f3a\u60c5\u51b5\u4e0b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u6559\u7a0b\u4ecb\u7ecd\u91cd\u8981\u7b97\u6cd5\u548c\u7406\u8bba\u8fdb\u5c55\uff0c\u6db5\u76d6\u591a\u79cd\u573a\u666f\u548c\u65b9\u6cd5\uff0c\u56f4\u7ed5\u6837\u672c\u590d\u6742\u5ea6\u7b49\u95ee\u9898\u8ba8\u8bba\u3002", "motivation": "\u65b0\u5174\u5e94\u7528\u4e2d\u6a21\u578b\u590d\u6742\u5ea6\u7206\u70b8\u548c\u975e\u51f8\u6027\u4f7f\u6837\u672c\u7a00\u7f3a\u60c5\u51b5\u4e0b\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u6311\u6218\uff0c\u9700\u7406\u89e3\u548c\u63d0\u5347\u7b97\u6cd5\u6837\u672c\u4e0e\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u4ee5\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e3a\u6838\u5fc3\u6570\u5b66\u6a21\u578b\uff0c\u4ecb\u7ecd\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u548c\u4e3b\u6d41\u65b9\u6cd5\u3002", "result": "\u65e0\u660e\u786e\u7ed3\u679c\u9610\u8ff0\uff0c\u4e3b\u8981\u662f\u5bf9\u5f3a\u5316\u5b66\u4e60\u591a\u65b9\u9762\u5185\u5bb9\u7684\u4ecb\u7ecd\u3002", "conclusion": "\u65e0\u660e\u786e\u7ed3\u8bba\uff0c\u65e8\u5728\u4ecb\u7ecd\u5f3a\u5316\u5b66\u4e60\u76f8\u5173\u7b97\u6cd5\u548c\u7406\u8bba\u8fdb\u5c55\u3002"}}
{"id": "2507.14808", "pdf": "https://arxiv.org/pdf/2507.14808", "abs": "https://arxiv.org/abs/2507.14808", "authors": ["Junliang Luo", "Katrin Tinn", "Samuel Ferreira Duran", "Di Wu", "Xue Liu"], "title": "Transaction Profiling and Address Role Inference in Tokenized U.S. Treasuries", "categories": ["q-fin.CP", "cs.CE", "cs.LG"], "comment": null, "summary": "Tokenized U.S. Treasuries have emerged as a prominent subclass of real-world\nassets (RWAs), offering cryptographically enforced, yield-bearing instruments\ncollateralized by sovereign debt and deployed across multiple blockchain\nnetworks. While the market has expanded rapidly, empirical analyses of\ntransaction-level behaviour remain limited. This paper conducts a quantitative,\nfunction-level dissection of U.S. Treasury-backed RWA tokens including BUIDL,\nBENJI, and USDY, across multi-chain: mostly Ethereum and Layer-2s. We analyze\ndecoded contract calls to isolate core functional primitives such as issuance,\nredemption, transfer, and bridge activity, revealing segmentation in behaviour\nbetween institutional actors and retail users. To model address-level economic\nroles, we introduce a curvature-aware representation learning framework using\nPoincar\\'e embeddings and liquidity-based graph features. Our method\noutperforms baseline models on our RWA Treasury dataset in role inference and\ngeneralizes to downstream tasks such as anomaly detection and wallet\nclassification in broader blockchain transaction networks. These findings\nprovide a structured understanding of functional heterogeneity and participant\nroles in tokenized Treasury in a transaction-level perspective, contributing\nnew empirical evidence to the study of on-chain financialization.", "AI": {"tldr": "\u672c\u6587\u5bf9\u7f8e\u56fd\u56fd\u503a\u652f\u6301\u7684RWA\u4ee3\u5e01\u8fdb\u884c\u91cf\u5316\u5206\u6790\uff0c\u5f15\u5165\u65b0\u6846\u67b6\u5efa\u6a21\u5730\u5740\u7ecf\u6d4e\u89d2\u8272\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4e3a\u94fe\u4e0a\u91d1\u878d\u5316\u7814\u7a76\u63d0\u4f9b\u5b9e\u8bc1\u8bc1\u636e\u3002", "motivation": "\u5e02\u573a\u5feb\u901f\u6269\u5f20\uff0c\u4f46\u4ea4\u6613\u5c42\u9762\u884c\u4e3a\u7684\u5b9e\u8bc1\u5206\u6790\u6709\u9650\uff0c\u9700\u8981\u5bf9\u7f8e\u56fd\u56fd\u503a\u652f\u6301\u7684RWA\u4ee3\u5e01\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u5bf9\u591a\u94fe\u4e0a\u7684\u7f8e\u56fd\u56fd\u503a\u652f\u6301\u7684RWA\u4ee3\u5e01\u8fdb\u884c\u5b9a\u91cf\u3001\u529f\u80fd\u5c42\u9762\u5256\u6790\uff0c\u5206\u6790\u89e3\u7801\u5408\u7ea6\u8c03\u7528\uff1b\u5f15\u5165\u57fa\u4e8ePoincar\u00e9\u5d4c\u5165\u548c\u6d41\u52a8\u6027\u56fe\u7279\u5f81\u7684\u66f2\u7387\u611f\u77e5\u8868\u793a\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u89d2\u8272\u63a8\u7406\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4e14\u80fd\u63a8\u5e7f\u5230\u5f02\u5e38\u68c0\u6d4b\u548c\u94b1\u5305\u5206\u7c7b\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "conclusion": "\u4ece\u4ea4\u6613\u5c42\u9762\u4e3a\u4ee3\u5e01\u5316\u56fd\u503a\u7684\u529f\u80fd\u5f02\u8d28\u6027\u548c\u53c2\u4e0e\u8005\u89d2\u8272\u63d0\u4f9b\u7ed3\u6784\u5316\u7406\u89e3\uff0c\u4e3a\u94fe\u4e0a\u91d1\u878d\u5316\u7814\u7a76\u63d0\u4f9b\u65b0\u5b9e\u8bc1\u8bc1\u636e\u3002"}}
{"id": "2507.14910", "pdf": "https://arxiv.org/pdf/2507.14910", "abs": "https://arxiv.org/abs/2507.14910", "authors": ["B K Meister"], "title": "Through the Looking Glass: Bitcoin Treasury Companies", "categories": ["q-fin.PM"], "comment": "5 pages", "summary": "Bitcoin treasury companies have taken stock markets by storm amassing\nbillions of dollars worth of tokens. More than a hundred companies active in\nvarious crypto-tokens, not just Bitcoin, are listed. The ability to generate\nleverage, for example stemming from borrowing collateralized by stock\nportfolios, helps to understand this phenomenon.\n  In addition, the extension of the binary-choice Kelly criterion to\nincorporate uncertainty in the form of the Kullback-Leibler divergence or more\ngenerally Bregman divergence is studied.", "AI": {"tldr": "\u6bd4\u7279\u5e01\u91d1\u5e93\u516c\u53f8\u5f15\u53d1\u80a1\u5e02\u70ed\u6f6e\uff0c\u8d85\u767e\u5bb6\u52a0\u5bc6\u4ee3\u5e01\u516c\u53f8\u4e0a\u5e02\uff0c\u53ef\u7528\u6760\u6746\u89e3\u91ca\u6b64\u73b0\u8c61\uff0c\u8fd8\u7814\u7a76\u4e86\u51ef\u5229\u51c6\u5219\u6269\u5c55\u3002", "motivation": "\u89e3\u91ca\u6bd4\u7279\u5e01\u91d1\u5e93\u516c\u53f8\u5728\u80a1\u5e02\u5927\u91cf\u79ef\u7d2f\u4ee3\u5e01\u8fd9\u4e00\u73b0\u8c61\uff0c\u7814\u7a76\u51ef\u5229\u51c6\u5219\u6269\u5c55\u3002", "method": "\u5206\u6790\u5229\u7528\u80a1\u7968\u6295\u8d44\u7ec4\u5408\u62b5\u62bc\u501f\u6b3e\u4ea7\u751f\u6760\u6746\u7684\u60c5\u51b5\uff0c\u7814\u7a76\u5c06\u4e8c\u5143\u9009\u62e9\u51ef\u5229\u51c6\u5219\u6269\u5c55\u4ee5\u7eb3\u5165\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2507.14160", "pdf": "https://arxiv.org/pdf/2507.14160", "abs": "https://arxiv.org/abs/2507.14160", "authors": ["Aaron Green", "Zihan Nie", "Hanzhen Qin", "Oshani Seneviratne", "Kristin P. Bennett"], "title": "FinSurvival: A Suite of Large Scale Survival Modeling Tasks from Finance", "categories": ["q-fin.ST", "cs.LG"], "comment": "33 pages, 4 figures, submitted to DMLR", "summary": "Survival modeling predicts the time until an event occurs and is widely used\nin risk analysis; for example, it's used in medicine to predict the survival of\na patient based on censored data. There is a need for large-scale, realistic,\nand freely available datasets for benchmarking artificial intelligence (AI)\nsurvival models. In this paper, we derive a suite of 16 survival modeling tasks\nfrom publicly available transaction data generated by lending of\ncryptocurrencies in Decentralized Finance (DeFi). Each task was constructed\nusing an automated pipeline based on choices of index and outcome events. For\nexample, the model predicts the time from when a user borrows cryptocurrency\ncoins (index event) until their first repayment (outcome event). We formulate a\nsurvival benchmark consisting of a suite of 16 survival-time prediction tasks\n(FinSurvival). We also automatically create 16 corresponding classification\nproblems for each task by thresholding the survival time using the restricted\nmean survival time. With over 7.5 million records, FinSurvival provides a suite\nof realistic financial modeling tasks that will spur future AI survival\nmodeling research. Our evaluation indicated that these are challenging tasks\nthat are not well addressed by existing methods. FinSurvival enables the\nevaluation of AI survival models applicable to traditional finance, industry,\nmedicine, and commerce, which is currently hindered by the lack of large public\ndatasets. Our benchmark demonstrates how AI models could assess opportunities\nand risks in DeFi. In the future, the FinSurvival benchmark pipeline can be\nused to create new benchmarks by incorporating more DeFi transactions and\nprotocols as the use of cryptocurrency grows.", "AI": {"tldr": "\u672c\u6587\u4eceDeFi\u52a0\u5bc6\u8d27\u5e01\u501f\u8d37\u4ea4\u6613\u6570\u636e\u5bfc\u51fa16\u4e2a\u751f\u5b58\u5efa\u6a21\u4efb\u52a1\u6784\u6210FinSurvival\u57fa\u51c6\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30AI\u751f\u5b58\u6a21\u578b\uff0c\u73b0\u6709\u65b9\u6cd5\u5e94\u5bf9\u4e0d\u8db3\uff0c\u672a\u6765\u53ef\u62d3\u5c55\u3002", "motivation": "\u9700\u8981\u5927\u89c4\u6a21\u3001\u73b0\u5b9e\u4e14\u514d\u8d39\u53ef\u7528\u7684\u6570\u636e\u96c6\u6765\u5bf9AI\u751f\u5b58\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u4ece\u516c\u5f00\u7684DeFi\u52a0\u5bc6\u8d27\u5e01\u501f\u8d37\u4ea4\u6613\u6570\u636e\u4e2d\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u9053\u57fa\u4e8e\u7d22\u5f15\u548c\u7ed3\u679c\u4e8b\u4ef6\u9009\u62e9\u6784\u5efa16\u4e2a\u751f\u5b58\u5efa\u6a21\u4efb\u52a1\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u521b\u5efa\u5bf9\u5e94\u7684\u5206\u7c7b\u95ee\u9898\u3002", "result": "FinSurvival\u6709\u8d85750\u4e07\u6761\u8bb0\u5f55\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002", "conclusion": "FinSurvival\u53ef\u8bc4\u4f30\u591a\u9886\u57dfAI\u751f\u5b58\u6a21\u578b\uff0c\u8fd8\u80fd\u5c55\u793aAI\u6a21\u578b\u8bc4\u4f30DeFi\u673a\u9047\u548c\u98ce\u9669\u7684\u80fd\u529b\uff0c\u672a\u6765\u53ef\u901a\u8fc7\u7eb3\u5165\u66f4\u591a\u4ea4\u6613\u548c\u534f\u8bae\u62d3\u5c55\u3002"}}
{"id": "2507.14960", "pdf": "https://arxiv.org/pdf/2507.14960", "abs": "https://arxiv.org/abs/2507.14960", "authors": ["Ivan Letteri"], "title": "A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books", "categories": ["q-fin.TR", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "The detection of outliers within cryptocurrency limit order books (LOBs) is\nof paramount importance for comprehending market dynamics, particularly in\nhighly volatile and nascent regulatory environments. This study conducts a\ncomprehensive comparative analysis of robust statistical methods and advanced\nmachine learning techniques for real-time anomaly identification in\ncryptocurrency LOBs. Within a unified testing environment, named AITA Order\nBook Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to\nidentify which approaches are most suitable for detecting potentially\nmanipulative trading behaviours. An empirical evaluation, conducted via\nbacktesting on a dataset of 26,204 records from a major exchange, demonstrates\nthat the top-performing model, Empirical Covariance (EC), achieves a 6.70%\ngain, significantly outperforming a standard Buy-and-Hold benchmark. These\nfindings underscore the effectiveness of outlier-driven strategies and provide\ninsights into the trade-offs between model complexity, trade frequency, and\nperformance. This study contributes to the growing corpus of research on\ncryptocurrency market microstructure by furnishing a rigorous benchmark of\nanomaly detection models and highlighting their potential for augmenting\nalgorithmic trading and risk management.", "AI": {"tldr": "\u672c\u6587\u5bf9\u52a0\u5bc6\u8d27\u5e01\u9650\u4ef7\u8ba2\u5355\u7c3f\u4e2d\u5f02\u5e38\u503c\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u901a\u8fc7\u56de\u6d4b\u8bc4\u4f3013\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u7ecf\u9a8c\u534f\u65b9\u5dee\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u57fa\u51c6\u3002", "motivation": "\u7406\u89e3\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u52a8\u6001\uff0c\u68c0\u6d4b\u6f5c\u5728\u64cd\u7eb5\u4ea4\u6613\u884c\u4e3a\uff0c\u5728\u9ad8\u6ce2\u52a8\u548c\u65b0\u5174\u76d1\u7ba1\u73af\u5883\u4e0b\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5728\u7edf\u4e00\u6d4b\u8bd5\u73af\u5883AITA - OBS\u4e2d\uff0c\u5bf913\u79cd\u4e0d\u540c\u6a21\u578b\u8fdb\u884c\u7efc\u5408\u6bd4\u8f83\u5206\u6790\uff0c\u901a\u8fc7\u5bf926,204\u6761\u8bb0\u5f55\u7684\u6570\u636e\u96c6\u8fdb\u884c\u56de\u6d4b\u8bc4\u4f30\u3002", "result": "\u8868\u73b0\u6700\u4f73\u7684\u7ecf\u9a8c\u534f\u65b9\u5dee\uff08EC\uff09\u6a21\u578b\u5b9e\u73b06.70%\u7684\u6536\u76ca\uff0c\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u7684\u4e70\u5165\u6301\u6709\u57fa\u51c6\u3002", "conclusion": "\u5f3a\u8c03\u5f02\u5e38\u9a71\u52a8\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u63ed\u793a\u6a21\u578b\u590d\u6742\u6027\u3001\u4ea4\u6613\u9891\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u5fae\u89c2\u7ed3\u6784\u7814\u7a76\u63d0\u4f9b\u4e25\u683c\u57fa\u51c6\uff0c\u51f8\u663e\u5176\u5728\u7b97\u6cd5\u4ea4\u6613\u548c\u98ce\u9669\u7ba1\u7406\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14535", "pdf": "https://arxiv.org/pdf/2507.14535", "abs": "https://arxiv.org/abs/2507.14535", "authors": ["Shu Huang", "Richard G. Everitt", "Massimiliano Tamborrino", "Adam M. Johansen"], "title": "Inference for Diffusion Processes via Controlled Sequential Monte Carlo and Splitting Schemes", "categories": ["stat.CO", "stat.ME"], "comment": null, "summary": "We introduce an inferential framework for a wide class of semi-linear\nstochastic differential equations (SDEs). Recent work has shown that numerical\nsplitting schemes can preserve critical properties of such types of SDEs, give\nrise to explicit pseudolikelihoods, and hence allow for parameter inference for\nfully observed processes. Here, under several discrete time observation regimes\n(particularly, partially and fully observed with and without noise), we\nrepresent the implied pseudolikelihood as the normalising constant of a\nFeynman--Kac flow, allowing its efficient estimation via controlled sequential\nMonte Carlo and adapt likelihood-based methods to exploit this pseudolikelihood\nfor inference. The strategy developed herein allows us to obtain good\ninferential results across a range of problems. Using diffusion bridges, we are\nable to computationally reduce bias coming from time-discretisation without\nrecourse to more complex numerical schemes which typically require considerable\napplication-specific efforts. Simulations illustrate that our method provides\nan excellent trade-off between computational efficiency and accuracy, under\nhypoellipticity, for both point and posterior estimation. Application to a\nneuroscience example shows the good performance of the method in challenging\nsettings.", "AI": {"tldr": "\u4ecb\u7ecd\u534a\u7ebf\u6027\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6709\u6548\u4f30\u8ba1\u4f2a\u4f3c\u7136\u8fdb\u884c\u63a8\u7406\uff0c\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u95f4\u53d6\u5f97\u5e73\u8861\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4e3a\u5e7f\u6cdb\u7684\u534a\u7ebf\u6027\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u63d0\u4f9b\u63a8\u7406\u6846\u67b6\uff0c\u89e3\u51b3\u4e0d\u540c\u79bb\u6563\u65f6\u95f4\u89c2\u6d4b\u5236\u5ea6\u4e0b\u7684\u53c2\u6570\u63a8\u7406\u95ee\u9898\u3002", "method": "\u5c06\u9690\u542b\u4f2a\u4f3c\u7136\u8868\u793a\u4e3aFeynman - Kac\u6d41\u7684\u5f52\u4e00\u5316\u5e38\u6570\uff0c\u7528\u53d7\u63a7\u5e8f\u8d2f\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u4f30\u8ba1\uff0c\u7ed3\u5408\u4f3c\u7136\u6cd5\u63a8\u7406\uff1b\u5229\u7528\u6269\u6563\u6865\u51cf\u5c11\u65f6\u95f4\u79bb\u6563\u5316\u504f\u5dee\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u95ee\u9898\u4e2d\u83b7\u5f97\u826f\u597d\u63a8\u7406\u7ed3\u679c\uff0c\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u5728\u795e\u7ecf\u79d1\u5b66\u5b9e\u4f8b\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u7b56\u7565\u80fd\u6709\u6548\u89e3\u51b3\u534a\u7ebf\u6027\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u63a8\u7406\u95ee\u9898\uff0c\u5177\u6709\u8f83\u597d\u7684\u5b9e\u7528\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2507.14569", "pdf": "https://arxiv.org/pdf/2507.14569", "abs": "https://arxiv.org/abs/2507.14569", "authors": ["Yonatan Nakar", "Dana Ron"], "title": "Characterizing and Testing Configuration Stability in Two-Dimensional Threshold Cellular Automata", "categories": ["cs.DS"], "comment": null, "summary": "We consider the problems of characterizing and testing the stability of\ncellular automata configurations that evolve on a two-dimensional torus\naccording to threshold rules with respect to the von-Neumann neighborhood.\nWhile stable configurations for Threshold-1 (OR) and Threshold-5 (AND) are\ntrivial (and hence easily testable), the other threshold rules exhibit much\nmore diverse behaviors. We first characterize the structure of stable\nconfigurations with respect to the Threshold-2 (similarly, Threshold-4) and\nThreshold-3 (Majority) rules. We then design and analyze a testing algorithm\nthat distinguishes between configurations that are stable with respect to the\nThreshold-2 rule, and those that are $\\epsilon$-far from any stable\nconfiguration, where the query complexity of the algorithm is independent of\nthe size of the configuration and depends quadratically on $1/\\epsilon$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14475", "pdf": "https://arxiv.org/pdf/2507.14475", "abs": "https://arxiv.org/abs/2507.14475", "authors": ["Runhao Zhao", "Weixin Zeng", "Wentao Zhang", "Xiang Zhao", "Jiuyang Tang", "Lei Chen"], "title": "Towards Temporal Knowledge Graph Alignment in the Wild", "categories": ["cs.DB"], "comment": "18 pages, 6 figures", "summary": "Temporal Knowledge Graph Alignment (TKGA) seeks to identify equivalent\nentities across heterogeneous temporal knowledge graphs (TKGs) for fusion to\nimprove their completeness. Although some approaches have been proposed to\ntackle this task, most assume unified temporal element standards and simplified\ntemporal structures across different TKGs. They cannot deal with TKGA in the\nwild (TKGA-Wild), where multi-scale temporal element entanglement and\ncross-source temporal structural imbalances are common. To bridge this gap, we\nstudy the task of TKGA-Wild and propose HyDRA, a new and effective solution.\nHyDRA is the first to reformulate the task via multi-scale hypergraph\nretrieval-augmented generation to address the challenges of TKGA-Wild.In\naddition, we design a new scale-weave synergy mechanism for HyDRA, which\nincorporates intra-scale interactions and cross-scale conflict detection. This\nmechanism is designed to alleviate the fragmentation caused by multi-source\ntemporal incompleteness and resolves inconsistencies arising from complex and\nuneven temporal event density distributions, thereby enhancing the model\ncapacity to handle the intricacies of real-world temporal alignment. Finally,\nthere is no standard benchmark that captures these challenges of TKGA-Wild and\neffectively evaluates existing methods. To this end, we formally propose to\nbenchmark challenges for TKGA-Wild and validate the effectiveness of the method\nby establishing two new datasets(BETA and WildBETA). Extensive experiments on\nthe new datasets and six representative benchmarks show that BETA and WildBETA\nbetter reflect real-world challenges. Meanwhile, HyDRA proposes a new paradigm\nfor TKGA-Wild, consistently outperforming 24 competitive baselines, while\nmaintaining strong efficiency and scalability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u91ce\u751f\u73af\u5883\u4e0b\u7684\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\uff08TKGA - Wild\uff09\u4efb\u52a1\uff0c\u63d0\u51faHyDRA\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u65b0\u673a\u5236\uff0c\u5efa\u7acb\u65b0\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793a\u65b0\u6570\u636e\u96c6\u80fd\u53cd\u6620\u771f\u5b9e\u6311\u6218\uff0cHyDRA\u8868\u73b0\u4f18\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u5047\u8bbe\u4e0d\u540c\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\uff08TKGs\uff09\u6709\u7edf\u4e00\u65f6\u95f4\u5143\u7d20\u6807\u51c6\u548c\u7b80\u5316\u65f6\u95f4\u7ed3\u6784\uff0c\u65e0\u6cd5\u5904\u7406TKGA - Wild\u4e2d\u591a\u5c3a\u5ea6\u65f6\u95f4\u5143\u7d20\u7ea0\u7f20\u548c\u8de8\u6e90\u65f6\u95f4\u7ed3\u6784\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faHyDRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u8d85\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u91cd\u65b0\u5b9a\u4e49\u4efb\u52a1\uff0c\u8bbe\u8ba1\u5c3a\u5ea6\u7f16\u7ec7\u534f\u540c\u673a\u5236\uff1b\u63d0\u51fa\u4e3aTKGA - Wild\u8bbe\u7f6e\u57fa\u51c6\u6311\u6218\uff0c\u5e76\u5efa\u7acb\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\u3002", "result": "\u65b0\u6570\u636e\u96c6BETA\u548cWildBETA\u80fd\u66f4\u597d\u53cd\u6620\u73b0\u5b9e\u6311\u6218\uff0cHyDRA\u59cb\u7ec8\u4f18\u4e8e24\u4e2a\u7ade\u4e89\u57fa\u7ebf\uff0c\u4e14\u4fdd\u6301\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "HyDRA\u4e3aTKGA - Wild\u63d0\u51fa\u4e86\u65b0\u8303\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8be5\u4efb\u52a1\u4e2d\u7684\u96be\u9898\u3002"}}
{"id": "2507.15026", "pdf": "https://arxiv.org/pdf/2507.15026", "abs": "https://arxiv.org/abs/2507.15026", "authors": ["Xin Yang", "Chen Fang", "Yunlai Liao", "Jian Yang", "Konstantinos Gryllias", "Dimitrios Chronopoulos"], "title": "Deep Generative Models in Condition and Structural Health Monitoring: Opportunities, Limitations and Future Outlook", "categories": ["cs.CE"], "comment": "48 pages", "summary": "Condition and structural health monitoring (CM/SHM) is a pivotal component of\npredictive maintenance (PdM) strategies across diverse industrial sectors,\nincluding mechanical rotating machinery, airplane composite wings, offshore\nwind turbines, and civil engineering structures. Conventional deep learning\nmodels, while effective in fault diagnosis and anomaly detection through\nsupervised feature extraction and rule-based data augmentation, often struggle\nwith operational variability, imbalanced or scarce fault datasets, and\nmultimodal sensory data from complex systems. Deep generative models (DGMs) in\nthis regard, including autoregressive models, variational autoencoders,\ngenerative adversarial networks, diffusion-based models, and emerging large\nlanguage models, offer transformative capabilities by synthesizing\nhigh-fidelity data samples, reconstructing latent system states, and modeling\ncomplex multimodal data streams. This review systematically examines\nstate-of-the-art DGM applications in CM/SHM systems, emphasizing their role in\naddressing key challenges: data imbalance and imputation, domain adaptation and\ngeneralization, multimodal data fusion, and downstream fault diagnosis and\nanomaly detection tasks, with rigorous comparison among signal processing,\nconventional machine learning or deep learning models, and DGMs. We also\nanalyze current limitations of DGMs, including challenges of explainable and\ntrustworthy models, computational inefficiencies for edge deployment, and the\nneed for parameter-efficient fine-tuning strategies. Future research directions\ncan focus on zero-shot and few-shot learning, robust multimodal generalization,\nhybrid architectures integrating DGMs with physics knowledge, and reinforcement\nlearning with DGMs to enhance robustness and accuracy in industrial scenarios.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u6df1\u5ea6\u751f\u6210\u6a21\u578b\uff08DGMs\uff09\u5728\u72b6\u6001\u4e0e\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\uff08CM/SHM\uff09\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u5176\u4f18\u52bf\u3001\u5c40\u9650\u5e76\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728CM/SHM\u4e2d\u6709\u5c40\u9650\u6027\uff0cDGMs\u6709\u6f5c\u529b\u89e3\u51b3\u76f8\u5173\u95ee\u9898\uff0c\u56e0\u6b64\u8fdb\u884c\u7efc\u8ff0\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u5730\u7814\u7a76DGMs\u5728CM/SHM\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u4e0e\u4fe1\u53f7\u5904\u7406\u3001\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6216\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4e25\u683c\u6bd4\u8f83\u3002", "result": "\u660e\u786eDGMs\u5728\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u548c\u63d2\u8865\u3001\u9886\u57df\u9002\u5e94\u548c\u6cdb\u5316\u7b49\u5173\u952e\u6311\u6218\u4e2d\u7684\u4f5c\u7528\uff0c\u4e5f\u5206\u6790\u51faDGMs\u5b58\u5728\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u53ef\u805a\u7126\u4e8e\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u3001\u9c81\u68d2\u591a\u6a21\u6001\u6cdb\u5316\u7b49\u65b9\u5411\u4ee5\u63d0\u9ad8\u5de5\u4e1a\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.14386", "pdf": "https://arxiv.org/pdf/2507.14386", "abs": "https://arxiv.org/abs/2507.14386", "authors": ["Yi Cheng", "Zongli Lin"], "title": "Training oscillator Ising machines to assign the dynamic stability of their equilibrium points", "categories": ["cs.NE", "cs.IR"], "comment": "8 pages, 4 figures", "summary": "We propose a neural network model, which, with appropriate assignment of the\nstability of its equilibrium points (EPs), achieves Hopfield-like associative\nmemory. The oscillator Ising machine (OIM) is an ideal candidates for such a\nmodel, as all its $0/\\pi$ binary EPs are structurally stable with their dynamic\nstability tunable by the coupling weights. Traditional Hopfield-based models\nstore the desired patterns by designing the coupling weights between neurons.\nThe design of coupling weights should simultaneously take into account both the\nexistence and the dynamic stability of the EPs for the storage of the desired\npatterns. For OIMs, since all $0/\\pi$ binary EPs are structurally stable, the\ndesign of the coupling weights needs only to focus on assigning appropriate\nstability for the $0/\\pi$ binary EPs according to the desired patterns. In this\npaper, we establish a connection between the stability and the Hamiltonian\nenergy of EPs for OIMs, and, based on this connection, provide a\nHamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) to train the\ncoupling weights of OIMs for assigning appropriate stability to their EPs.\nFinally, numerical experiments are performed to validate the effectiveness of\nthe proposed method.", "AI": {"tldr": "\u63d0\u51fa\u7528\u5408\u9002\u5206\u914d\u5e73\u8861\u70b9\u7a33\u5b9a\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5b9e\u73b0\u7c7bHopfield\u8054\u60f3\u8bb0\u5fc6\uff0c\u4ee5OIM\u4e3a\u4f8b\uff0c\u5efa\u7acb\u5e73\u8861\u70b9\u7a33\u5b9a\u6027\u4e0e\u54c8\u5bc6\u987f\u80fd\u91cf\u8054\u7cfb\uff0c\u63d0\u51faHRECM\u65b9\u6cd5\u8bad\u7ec3\u8026\u5408\u6743\u91cd\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfHopfield\u6a21\u578b\u5b58\u50a8\u6a21\u5f0f\u65f6\u8bbe\u8ba1\u8026\u5408\u6743\u91cd\u9700\u517c\u987e\u5e73\u8861\u70b9\u5b58\u5728\u6027\u548c\u52a8\u6001\u7a33\u5b9a\u6027\uff0c\u800cOIM\u76840/\u03c0\u4e8c\u8fdb\u5236\u5e73\u8861\u70b9\u7ed3\u6784\u7a33\u5b9a\uff0c\u9700\u8bbe\u8ba1\u65b9\u6cd5\u4e3a\u5176\u5206\u914d\u5408\u9002\u7a33\u5b9a\u6027\u3002", "method": "\u5efa\u7acbOIM\u5e73\u8861\u70b9\u7a33\u5b9a\u6027\u4e0e\u54c8\u5bc6\u987f\u80fd\u91cf\u7684\u8054\u7cfb\uff0c\u63d0\u51faHamiltonian - Regularized Eigenvalue Contrastive Method (HRECM)\u8bad\u7ec3\u8026\u5408\u6743\u91cd\u3002", "result": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684HRECM\u65b9\u6cd5\u80fd\u4e3aOIM\u7684\u5e73\u8861\u70b9\u5206\u914d\u5408\u9002\u7a33\u5b9a\u6027\uff0c\u53ef\u7528\u4e8e\u5b9e\u73b0\u7c7bHopfield\u8054\u60f3\u8bb0\u5fc6\u3002"}}
{"id": "2507.14267", "pdf": "https://arxiv.org/pdf/2507.14267", "abs": "https://arxiv.org/abs/2507.14267", "authors": ["Ziqi Wang", "Hongshuo Huang", "Hancheng Zhao", "Changwen Xu", "Shang Zhu", "Jan Janssen", "Venkatasubramanian Viswanathan"], "title": "DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "comment": "34 pages, 28 pages of Supporting Information", "summary": "Materials discovery relies on high-throughput, high-fidelity simulation\ntechniques such as Density Functional Theory (DFT), which require years of\ntraining, extensive parameter fine-tuning and systematic error handling. To\naddress these challenges, we introduce the DFT-based Research Engine for\nAgentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for\nDFT simulation that combines a central Large Language Model (LLM) planner agent\nwith domain-specific LLM agents for atomistic structure generation, systematic\nDFT convergence testing, High-Performance Computing (HPC) scheduling, and error\nhandling. In addition, a shared canvas helps the LLM agents to structure their\ndiscussions, preserve context and prevent hallucination. We validate DREAMS\ncapabilities on the Sol27LC lattice-constant benchmark, achieving average\nerrors below 1\\% compared to the results of human DFT experts. Furthermore, we\napply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating\nits long-term and complex problem-solving capabilities. The framework again\nreproduces expert-level literature adsorption-energy differences. Finally,\nDREAMS is employed to quantify functional-driven uncertainties with Bayesian\nensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at\nthe Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS\napproaches L3-level automation - autonomous exploration of a defined design\nspace - and significantly reduces the reliance on human expertise and\nintervention, offering a scalable path toward democratized, high-throughput,\nhigh-fidelity computational materials discovery.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u4e8eDFT\u6a21\u62df\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6DREAMS\uff0c\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u95ee\u9898\u9a8c\u8bc1\u5176\u80fd\u529b\uff0c\u53ef\u964d\u4f4e\u5bf9\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002", "motivation": "\u89e3\u51b3\u6750\u6599\u53d1\u73b0\u4e2dDFT\u6a21\u62df\u9700\u591a\u5e74\u8bad\u7ec3\u3001\u5927\u91cf\u53c2\u6570\u5fae\u8c03\u53ca\u7cfb\u7edf\u8bef\u5dee\u5904\u7406\u7b49\u6311\u6218\u3002", "method": "\u5f15\u5165\u57fa\u4e8eDFT\u7684\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6DREAMS\uff0c\u7ed3\u5408\u4e2d\u592e\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u5212\u667a\u80fd\u4f53\u4e0e\u7279\u5b9a\u9886\u57df\u667a\u80fd\u4f53\uff0c\u4f7f\u7528\u5171\u4eab\u753b\u5e03\u8f85\u52a9\u4ea4\u6d41\u3002", "result": "\u5728Sol27LC\u6676\u683c\u5e38\u6570\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e1%\uff1b\u89e3\u51b3CO/Pt(111)\u5438\u9644\u96be\u9898\uff0c\u91cd\u73b0\u4e13\u5bb6\u7ea7\u6587\u732e\u5438\u9644\u80fd\u5dee\u5f02\uff1b\u91cf\u5316\u529f\u80fd\u9a71\u52a8\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u786e\u8ba4GGA DFT\u6c34\u5e73\u4e0b\u7684FCC\u4f4d\u70b9\u504f\u597d\u3002", "conclusion": "DREAMS\u63a5\u8fd1L3\u7ea7\u81ea\u52a8\u5316\uff0c\u51cf\u5c11\u5bf9\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u548c\u5e72\u9884\u7684\u4f9d\u8d56\uff0c\u4e3a\u8ba1\u7b97\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u53ef\u6269\u5c55\u9014\u5f84\u3002"}}
{"id": "2507.14330", "pdf": "https://arxiv.org/pdf/2507.14330", "abs": "https://arxiv.org/abs/2507.14330", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "Leveraging LLMs for Formal Software Requirements -- Challenges and Prospects", "categories": ["cs.SE", "D.2.1; D.2.4; D.2.10; F.4.1; F.4.3"], "comment": "Submitted to Overlay2025 - 7th International Workshop on Artificial\n  Intelligence and fOrmal VERification, Logic, Automata, and sYnthesis. [under\n  review]", "summary": "Software correctness is ensured mathematically through formal verification,\nwhich involves the resources of generating formal requirement specifications\nand having an implementation that must be verified. Tools such as\nmodel-checkers and theorem provers ensure software correctness by verifying the\nimplementation against the specification. Formal methods deployment is\nregularly enforced in the development of safety-critical systems e.g.\naerospace, medical devices and autonomous systems. Generating these\nspecifications from informal and ambiguous natural language requirements\nremains the key challenge. Our project, VERIFAI^{1}, aims to investigate\nautomated and semi-automated approaches to bridge this gap, using techniques\nfrom Natural Language Processing (NLP), ontology-based domain modelling,\nartefact reuse, and large language models (LLMs). This position paper presents\na preliminary synthesis of relevant literature to identify recurring challenges\nand prospective research directions in the generation of verifiable\nspecifications from informal requirements.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u4ece\u975e\u6b63\u5f0f\u9700\u6c42\u751f\u6210\u53ef\u9a8c\u8bc1\u89c4\u8303\u7684\u6311\u6218\uff0c\u4ecb\u7ecdVERIFAI\u9879\u76ee\u7528\u591a\u79cd\u6280\u672f\u586b\u8865\u5dee\u8ddd\uff0c\u5e76\u505a\u76f8\u5173\u6587\u732e\u521d\u6b65\u7efc\u5408\u3002", "motivation": "\u4ece\u975e\u6b63\u5f0f\u4e14\u6a21\u7cca\u7684\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u751f\u6210\u89c4\u8303\u662f\u786e\u4fdd\u8f6f\u4ef6\u6b63\u786e\u6027\u7684\u5173\u952e\u6311\u6218\uff0c\u63a8\u52a8\u4e86\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u57fa\u4e8e\u672c\u4f53\u7684\u9886\u57df\u5efa\u6a21\u3001\u5de5\u4ef6\u91cd\u7528\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7b49\u6280\u672f\uff0c\u5bf9\u76f8\u5173\u6587\u732e\u8fdb\u884c\u521d\u6b65\u7efc\u5408\u3002", "result": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u679c\u3002", "conclusion": "\u786e\u5b9a\u4e86\u4ece\u975e\u6b63\u5f0f\u9700\u6c42\u751f\u6210\u53ef\u9a8c\u8bc1\u89c4\u8303\u4e2d\u7684\u53cd\u590d\u51fa\u73b0\u7684\u6311\u6218\u548c\u6f5c\u5728\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.14352", "pdf": "https://arxiv.org/pdf/2507.14352", "abs": "https://arxiv.org/abs/2507.14352", "authors": ["Huy-Son Nguyen", "Yuanna Liu", "Masoud Mansoury", "Mohammad Alian Nejadi", "Alan Hanjalic", "Maarten de Rijke"], "title": "A Reproducibility Study of Product-side Fairness in Bundle Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Recommender systems are known to exhibit fairness issues, particularly on the\nproduct side, where products and their associated suppliers receive unequal\nexposure in recommended results. While this problem has been widely studied in\ntraditional recommendation settings, its implications for bundle recommendation\n(BR) remain largely unexplored. This emerging task introduces additional\ncomplexity: recommendations are generated at the bundle level, yet user\nsatisfaction and product (or supplier) exposure depend on both the bundle and\nthe individual items it contains. Existing fairness frameworks and metrics\ndesigned for traditional recommender systems may not directly translate to this\nmulti-layered setting. In this paper, we conduct a comprehensive\nreproducibility study of product-side fairness in BR across three real-world\ndatasets using four state-of-the-art BR methods. We analyze exposure\ndisparities at both the bundle and item levels using multiple fairness metrics,\nuncovering important patterns. Our results show that exposure patterns differ\nnotably between bundles and items, revealing the need for fairness\ninterventions that go beyond bundle-level assumptions. We also find that\nfairness assessments vary considerably depending on the metric used,\nreinforcing the need for multi-faceted evaluation. Furthermore, user behavior\nplays a critical role: when users interact more frequently with bundles than\nwith individual items, BR systems tend to yield fairer exposure distributions\nacross both levels. Overall, our findings offer actionable insights for\nbuilding fairer bundle recommender systems and establish a vital foundation for\nfuture research in this emerging domain.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6346\u7ed1\u63a8\u8350\u4e2d\u4ea7\u54c1\u7aef\u516c\u5e73\u6027\u8fdb\u884c\u53ef\u590d\u73b0\u6027\u7814\u7a76\uff0c\u63ed\u793a\u6346\u7ed1\u4e0e\u7269\u54c1\u66dd\u5149\u6a21\u5f0f\u5dee\u5f02\u7b49\u7ed3\u679c\uff0c\u4e3a\u6784\u5efa\u66f4\u516c\u5e73\u7cfb\u7edf\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u516c\u5e73\u6027\u95ee\u9898\u7814\u7a76\u5e7f\u6cdb\uff0c\u4f46\u6346\u7ed1\u63a8\u8350\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\u7814\u7a76\u8f83\u5c11\uff0c\u4e14\u73b0\u6709\u516c\u5e73\u6846\u67b6\u548c\u6307\u6807\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u591a\u5c42\u7ea7\u7684\u6346\u7ed1\u63a8\u8350\u3002", "method": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u56db\u79cd\u6700\u5148\u8fdb\u7684\u6346\u7ed1\u63a8\u8350\u65b9\u6cd5\u8fdb\u884c\u53ef\u590d\u73b0\u6027\u7814\u7a76\uff0c\u7528\u591a\u79cd\u516c\u5e73\u6307\u6807\u5206\u6790\u6346\u7ed1\u548c\u7269\u54c1\u5c42\u9762\u7684\u66dd\u5149\u5dee\u5f02\u3002", "result": "\u6346\u7ed1\u548c\u7269\u54c1\u7684\u66dd\u5149\u6a21\u5f0f\u6709\u663e\u8457\u5dee\u5f02\uff1b\u516c\u5e73\u8bc4\u4f30\u56e0\u6307\u6807\u800c\u5f02\uff1b\u7528\u6237\u66f4\u591a\u4e0e\u6346\u7ed1\u4ea4\u4e92\u65f6\uff0c\u7cfb\u7edf\u66dd\u5149\u5206\u5e03\u66f4\u516c\u5e73\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6784\u5efa\u66f4\u516c\u5e73\u7684\u6346\u7ed1\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u53ef\u64cd\u4f5c\u89c1\u89e3\uff0c\u4e3a\u8be5\u9886\u57df\u672a\u6765\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.14420", "pdf": "https://arxiv.org/pdf/2507.14420", "abs": "https://arxiv.org/abs/2507.14420", "authors": ["Arango-Castillo Lenin", "Mart\u00ednez-Ram\u00edrez Francisco"], "title": "The effects of temperature and rainfall anomalies on Mexican inflation", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper measures the effects of temperature and precipitation shocks on\nMexican inflation using a regional panel. To measure the long-term inflationary\neffects of climate shocks, we estimate a panel autoregressive distributed lag\nmodel (panel ARDL) of the quarterly variation of the price index against the\npopulation-weighted temperature and precipitation deviations from their\nhistorical norm, computed using the 30-year moving average. In addition, we\nmeasure the short-term effects of climate shocks by estimating impulse response\nfunctions using panel local projections. The result indicates that, in the\nshort term, the climate variables have no statistical effect on Mexican\ninflation. However, in the long term, only precipitation norms have a\nstatistical effect, and the temperature norms have no statistical impact.\nHigher than normal precipitation has a positive and statistically significant\neffect on Mexican inflation for all items.", "AI": {"tldr": "\u672c\u6587\u7528\u533a\u57df\u9762\u677f\u6570\u636e\u8861\u91cf\u6e29\u5ea6\u548c\u964d\u6c34\u51b2\u51fb\u5bf9\u58a8\u897f\u54e5\u901a\u80c0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u77ed\u671f\u6c14\u5019\u53d8\u91cf\u65e0\u7edf\u8ba1\u6548\u5e94\uff0c\u957f\u671f\u4ec5\u964d\u6c34\u6709\u7edf\u8ba1\u6548\u5e94\u3002", "motivation": "\u8861\u91cf\u6c14\u5019\u51b2\u51fb\u5bf9\u58a8\u897f\u54e5\u901a\u80c0\u7684\u957f\u671f\u548c\u77ed\u671f\u5f71\u54cd\u3002", "method": "\u4f30\u8ba1\u9762\u677f\u81ea\u56de\u5f52\u5206\u5e03\u6ede\u540e\u6a21\u578b\uff08panel ARDL\uff09\u8861\u91cf\u957f\u671f\u5f71\u54cd\uff0c\u7528\u9762\u677f\u5c40\u90e8\u6295\u5f71\u4f30\u8ba1\u8109\u51b2\u54cd\u5e94\u51fd\u6570\u8861\u91cf\u77ed\u671f\u5f71\u54cd\u3002", "result": "\u77ed\u671f\u6c14\u5019\u53d8\u91cf\u5bf9\u58a8\u897f\u54e5\u901a\u80c0\u65e0\u7edf\u8ba1\u6548\u5e94\uff0c\u957f\u671f\u4ec5\u964d\u6c34\u89c4\u8303\u6709\u7edf\u8ba1\u6548\u5e94\uff0c\u6c14\u6e29\u89c4\u8303\u65e0\u7edf\u8ba1\u5f71\u54cd\uff0c\u9ad8\u4e8e\u6b63\u5e38\u6c34\u5e73\u7684\u964d\u6c34\u5bf9\u58a8\u897f\u54e5\u6240\u6709\u9879\u76ee\u901a\u80c0\u6709\u79ef\u6781\u4e14\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u6e29\u5ea6\u548c\u964d\u6c34\u51b2\u51fb\u5bf9\u58a8\u897f\u54e5\u901a\u80c0\u7684\u5f71\u54cd\u5728\u77ed\u671f\u548c\u957f\u671f\u5b58\u5728\u5dee\u5f02\uff0c\u957f\u671f\u4e2d\u964d\u6c34\u5bf9\u901a\u80c0\u6709\u663e\u8457\u4f5c\u7528\u3002"}}
{"id": "2507.14472", "pdf": "https://arxiv.org/pdf/2507.14472", "abs": "https://arxiv.org/abs/2507.14472", "authors": ["Yuhang Guo", "Dong Hao", "Bin Li", "Mingyu Xiao", "Bakh Khoussainov"], "title": "Strategyproofness and Monotone Allocation of Auction in Social Networks", "categories": ["cs.GT", "cs.AI", "cs.MA", "econ.TH"], "comment": "Accepted by IJCAI 2025", "summary": "Strategyproofness in network auctions requires that bidders not only report\ntheir valuations truthfully, but also do their best to invite neighbours from\nthe social network. In contrast to canonical auctions, where the value-monotone\nallocation in Myerson's Lemma is a cornerstone, a general principle of\nallocation rules for strategyproof network auctions is still missing. We show\nthat, due to the absence of such a principle, even extensions to multi-unit\nnetwork auctions with single-unit demand present unexpected difficulties, and\nall pioneering researches fail to be strategyproof. For the first time in this\nfield, we identify two categories of monotone allocation rules on networks:\nInvitation-Depressed Monotonicity (ID-MON) and Invitation-Promoted Monotonicity\n(IP-MON). They encompass all existing allocation rules of network auctions as\nspecific instances. For any given ID-MON or IP-MON allocation rule, we\ncharacterize the existence and sufficient conditions for the strategyproof\npayment rules, and show that among all such payment rules, the\nrevenue-maximizing one exists and is computationally feasible. With these\nresults, the obstacle of combinatorial network auction with single-minded\nbidders is now resolved.", "AI": {"tldr": "\u672c\u6587\u8bc6\u522b\u7f51\u7edc\u62cd\u5356\u7684\u4e24\u7c7b\u5355\u8c03\u5206\u914d\u89c4\u5219\uff0c\u523b\u753b\u7b56\u7565\u8bc1\u660e\u652f\u4ed8\u89c4\u5219\u7684\u5b58\u5728\u4e0e\u5145\u5206\u6761\u4ef6\uff0c\u89e3\u51b3\u5355\u5fc3\u601d\u6295\u6807\u8005\u7ec4\u5408\u7f51\u7edc\u62cd\u5356\u7684\u969c\u788d\u3002", "motivation": "\u7f51\u7edc\u62cd\u5356\u7b56\u7565\u8bc1\u660e\u6027\u7f3a\u5c11\u901a\u7528\u5206\u914d\u89c4\u5219\u539f\u5219\uff0c\u73b0\u6709\u591a\u5355\u5143\u5355\u9700\u6c42\u7f51\u7edc\u62cd\u5356\u7814\u7a76\u65e0\u6cd5\u5b9e\u73b0\u7b56\u7565\u8bc1\u660e\u3002", "method": "\u8bc6\u522b\u7f51\u7edc\u4e0a\u7684\u9080\u8bf7\u6291\u5236\u5355\u8c03\u6027\uff08ID - MON\uff09\u548c\u9080\u8bf7\u4fc3\u8fdb\u5355\u8c03\u6027\uff08IP - MON\uff09\u4e24\u7c7b\u5355\u8c03\u5206\u914d\u89c4\u5219\uff0c\u523b\u753b\u7b56\u7565\u8bc1\u660e\u652f\u4ed8\u89c4\u5219\u60c5\u51b5\u3002", "result": "\u786e\u5b9a\u4e86\u7b56\u7565\u8bc1\u660e\u652f\u4ed8\u89c4\u5219\u7684\u5b58\u5728\u548c\u5145\u5206\u6761\u4ef6\uff0c\u8bc1\u660e\u5b58\u5728\u6536\u76ca\u6700\u5927\u5316\u7684\u652f\u4ed8\u89c4\u5219\u4e14\u8ba1\u7b97\u53ef\u884c\u3002", "conclusion": "\u89e3\u51b3\u4e86\u5355\u5fc3\u601d\u6295\u6807\u8005\u7ec4\u5408\u7f51\u7edc\u62cd\u5356\u7684\u969c\u788d\u3002"}}
{"id": "2507.14813", "pdf": "https://arxiv.org/pdf/2507.14813", "abs": "https://arxiv.org/abs/2507.14813", "authors": ["Sanjay Sri Vallabh Singapuram", "Ronald Dreslinski", "Nishil Talati"], "title": "Mayura: Exploiting Similarities in Motifs for Temporal Co-Mining", "categories": ["cs.DB", "cs.DC", "cs.PF"], "comment": null, "summary": "Temporal graphs serve as a critical foundation for modeling evolving\ninteractions in domains ranging from financial networks to social media. Mining\ntemporal motifs is essential for applications such as fraud detection,\ncybersecurity, and dynamic network analysis. However, conventional motif mining\napproaches treat each query independently, incurring significant redundant\ncomputations when similar substructures exist across multiple motifs. In this\npaper, we propose Mayura, a novel framework that unifies the mining of multiple\ntemporal motifs by exploiting their inherent structural and temporal\ncommonalities. Central to our approach is the Motif-Group Tree (MG-Tree), a\nhierarchical data structure that organizes related motifs and enables the reuse\nof common search paths, thereby reducing redundant computation. We propose a\nco-mining algorithm that leverages the MG-Tree and develop a flexible runtime\ncapable of exploiting both CPU and GPU architectures for scalable performance.\nEmpirical evaluations on diverse real-world datasets demonstrate that Mayura\nachieves substantial improvements over the state-of-the-art techniques that\nmine each motif individually, with an average speed-up of 2.4x on the CPU and\n1.7x on the GPU, while maintaining the exactness required for high-stakes\napplications.", "AI": {"tldr": "\u63d0\u51faMayura\u6846\u67b6\u7edf\u4e00\u6316\u6398\u591a\u4e2a\u65f6\u95f4\u6a21\u5f0f\uff0c\u5229\u7528MG - Tree\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff0c\u5728CPU\u548cGPU\u4e0a\u6bd4\u73b0\u6709\u6280\u672f\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u6a21\u5f0f\u6316\u6398\u65b9\u6cd5\u5728\u5904\u7406\u591a\u4e2a\u76f8\u4f3c\u5b50\u7ed3\u6784\u6a21\u5f0f\u65f6\u4f1a\u4ea7\u751f\u5927\u91cf\u5197\u4f59\u8ba1\u7b97\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faMayura\u6846\u67b6\uff0c\u4f7f\u7528Motif - Group Tree\uff08MG - Tree\uff09\u7ec4\u7ec7\u76f8\u5173\u6a21\u5f0f\uff0c\u63d0\u51fa\u8054\u5408\u6316\u6398\u7b97\u6cd5\uff0c\u5f00\u53d1\u53ef\u5229\u7528CPU\u548cGPU\u67b6\u6784\u7684\u7075\u6d3b\u8fd0\u884c\u65f6\u3002", "result": "\u5728\u4e0d\u540c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cMayura\u5728CPU\u4e0a\u5e73\u5747\u52a0\u901f2.4\u500d\uff0c\u5728GPU\u4e0a\u5e73\u5747\u52a0\u901f1.7\u500d\u3002", "conclusion": "Mayura\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u53ef\u6ee1\u8db3\u9ad8\u98ce\u9669\u5e94\u7528\u7684\u7cbe\u786e\u6027\u8981\u6c42\u3002"}}
{"id": "2507.14171", "pdf": "https://arxiv.org/pdf/2507.14171", "abs": "https://arxiv.org/abs/2507.14171", "authors": ["Jaeheun Jung", "Jaehyuk Lee", "Yeajin Lee", "Donghun Lee"], "title": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the growth of demand on neural network compression methods, the\nstructured pruning methods including importance-based approach are actively\nstudied. The magnitude importance and many correlated modern importance\ncriteria often limit the capacity of pruning decision, since the filters with\nlarger magnitudes are not likely to be pruned if the smaller one didn't, even\nif it is redundant. In this paper, we propose a novel pruning strategy to\nchallenge this dominating effect of magnitude and provide fair chance to each\nfilter to be pruned, by placing it on projective space. After that, we observe\nthe gradient descent movement whether the filters move toward the origin or\nnot, to measure how the filter is likely to be pruned. This measurement is used\nto construct PROscore, a novel importance score for IPPRO, a novel\nimportance-based structured pruning with magnitude-indifference. Our evaluation\nresults shows that the proposed importance criteria using the projective space\nachieves near-lossless pruning by reducing the performance drop in pruning,\nwith promising performance after the finetuning. Our work debunks the\n``size-matters'' myth in pruning and expands the frontier of importance-based\npruning both theoretically and empirically.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6295\u5f71\u7a7a\u95f4\u7684\u526a\u679d\u7b56\u7565\uff0c\u6784\u5efaPROscore\uff0c\u5b9e\u73b0\u8fd1\u65e0\u635f\u526a\u679d\uff0c\u6253\u7834\u526a\u679d\u4e2d\u201c\u5927\u5c0f\u5f88\u91cd\u8981\u201d\u7684\u89c2\u5ff5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u4e2d\uff0c\u5e45\u5ea6\u91cd\u8981\u6027\u7b49\u6807\u51c6\u9650\u5236\u526a\u679d\u51b3\u7b56\u80fd\u529b\uff0c\u5197\u4f59\u7684\u5927\u5c3a\u5bf8\u6ee4\u6ce2\u5668\u96be\u4ee5\u88ab\u526a\u679d\u3002", "method": "\u5c06\u6ee4\u6ce2\u5668\u7f6e\u4e8e\u6295\u5f71\u7a7a\u95f4\u4ee5\u6311\u6218\u5e45\u5ea6\u7684\u4e3b\u5bfc\u4f5c\u7528\uff0c\u89c2\u5bdf\u68af\u5ea6\u4e0b\u964d\u8fd0\u52a8\u6784\u5efaPROscore\uff0c\u7528\u4e8e\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u7ed3\u6784\u5316\u526a\u679dIPPRO\u3002", "result": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6295\u5f71\u7a7a\u95f4\u7684\u91cd\u8981\u6027\u6807\u51c6\u5b9e\u73b0\u8fd1\u65e0\u635f\u526a\u679d\uff0c\u5fae\u8c03\u540e\u6027\u80fd\u826f\u597d\u3002", "conclusion": "\u6253\u7834\u526a\u679d\u4e2d\u201c\u5927\u5c0f\u5f88\u91cd\u8981\u201d\u7684\u89c2\u5ff5\uff0c\u4ece\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u62d3\u5c55\u4e86\u57fa\u4e8e\u91cd\u8981\u6027\u526a\u679d\u7684\u8fb9\u754c\u3002"}}
{"id": "2507.14507", "pdf": "https://arxiv.org/pdf/2507.14507", "abs": "https://arxiv.org/abs/2507.14507", "authors": ["Chen Su", "Zhengzhou Cai", "Yuanhe Tian", "Zihong Zheng", "Yan Song"], "title": "Diffusion Models for Time Series Forecasting: A Survey", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Diffusion models, initially developed for image synthesis, demonstrate\nremarkable generative capabilities. Recently, their application has expanded to\ntime series forecasting (TSF), yielding promising results. In this survey, we\nfirstly introduce the standard diffusion models and their prevalent variants,\nexplaining their adaptation to TSF tasks. We then provide a comprehensive\nreview of diffusion models for TSF, paying special attention to the sources of\nconditional information and the mechanisms for integrating this conditioning\nwithin the models. In analyzing existing approaches using diffusion models for\nTSF, we provide a systematic categorization and a comprehensive summary of them\nin this survey. Furthermore, we examine several foundational diffusion models\napplied to TSF, alongside commonly used datasets and evaluation metrics.\nFinally, we discuss current limitations in these approaches and potential\nfuture research directions. Overall, this survey details recent progress and\nfuture prospects for diffusion models in TSF, serving as a reference for\nresearchers in the field.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6269\u6563\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u7efc\u8ff0\uff0c\u4ecb\u7ecd\u6a21\u578b\u3001\u5206\u7c7b\u73b0\u6709\u65b9\u6cd5\u3001\u5206\u6790\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u8ba8\u8bba\u5c40\u9650\u4e0e\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u56fe\u50cf\u5408\u6210\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u5728TSF\u4e2d\u53d6\u5f97\u6709\u524d\u666f\u7684\u7ed3\u679c\uff0c\u9700\u8981\u5bf9\u5176\u5728TSF\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\u3002", "method": "\u4ecb\u7ecd\u6807\u51c6\u6269\u6563\u6a21\u578b\u53ca\u5176\u53d8\u4f53\uff0c\u9610\u8ff0\u5176\u5728TSF\u4efb\u52a1\u4e2d\u7684\u9002\u914d\uff1b\u5bf9\u6269\u6563\u6a21\u578b\u7528\u4e8eTSF\u7684\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\u548c\u603b\u7ed3\uff1b\u5206\u6790\u5e38\u7528\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5bf9\u6269\u6563\u6a21\u578b\u5728TSF\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u5168\u9762\u68b3\u7406\uff0c\u5305\u62ec\u6a21\u578b\u3001\u65b9\u6cd5\u3001\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u7b49\u65b9\u9762\u3002", "conclusion": "\u8be6\u7ec6\u9610\u8ff0\u4e86\u6269\u6563\u6a21\u578b\u5728TSF\u4e2d\u7684\u6700\u65b0\u8fdb\u5c55\u548c\u672a\u6765\u524d\u666f\uff0c\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2507.15111", "pdf": "https://arxiv.org/pdf/2507.15111", "abs": "https://arxiv.org/abs/2507.15111", "authors": ["Genjis A. Ossa", "Luis H. Restrepo"], "title": "Longitudinal review of portfolios with minimum variance approach before during and after the pandemic", "categories": ["q-fin.PM", "91G10, 62P05, 91G60", "G.1.6; I.6.3; J.4"], "comment": "in Spanish language", "summary": "This study investigates the impact of the pandemic on the most traded stocks\nin the Colombian stock market for the date of January 17, 2024. Based on the\ndaily data of the most traded companies in Colombia for said date and covering\na period general from 2015 to 2023, in a summarized way our analysis reveals\nthat in the period 2015-2019, the return reached 5.70%, with a relatively low\nrisk of 18.45%. However, in the following period 2016 -2020, although the yield\ndecreased to 5.40%, the risk experienced a significant increase, reaching\n24.64%. The beta also showed variations, being lowest in 2015-2019 with 0.61\nand increasing to 1.02 in 2016-2020. The capital market line (LMC) in the\nconstructed portfolios has a downward trend, indicating that the portfolio\noffers an expected rate of return lower than the risk-free rate. This finding\nis supported by the Sharpe index, which shows negative values throughout the\nperiods studied.", "AI": {"tldr": "\u7814\u7a762024\u5e741\u670817\u65e5\u54e5\u4f26\u6bd4\u4e9a\u80a1\u5e02\u6700\u6d3b\u8dc3\u80a1\u7968\u53d7\u75ab\u60c5\u5f71\u54cd\uff0c\u5bf9\u6bd4\u4e0d\u540c\u65f6\u671f\u6536\u76ca\u3001\u98ce\u9669\u7b49\u6307\u6807\u3002", "motivation": "\u63a2\u7a76\u75ab\u60c5\u5bf9\u54e5\u4f26\u6bd4\u4e9a\u80a1\u5e02\u6700\u6d3b\u8dc3\u80a1\u7968\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e2015 - 2023\u5e74\u54e5\u4f26\u6bd4\u4e9a\u6700\u6d3b\u8dc3\u516c\u53f8\u7684\u6bcf\u65e5\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "2015 - 2019\u5e74\u6536\u76ca5.70%\uff0c\u98ce\u966918.45%\uff1b2016 - 2020\u5e74\u6536\u76ca\u964d\u81f35.40%\uff0c\u98ce\u9669\u5347\u81f324.64%\uff0c\u8d1d\u5854\u503c\u4e0a\u5347\uff0c\u6295\u8d44\u7ec4\u5408\u7684\u8d44\u672c\u5e02\u573a\u7ebf\u5448\u4e0b\u964d\u8d8b\u52bf\uff0c\u590f\u666e\u6307\u6570\u4e3a\u8d1f\u3002", "conclusion": "\u6240\u6784\u5efa\u7684\u6295\u8d44\u7ec4\u5408\u9884\u671f\u6536\u76ca\u7387\u4f4e\u4e8e\u65e0\u98ce\u9669\u5229\u7387\u3002"}}
{"id": "2507.14325", "pdf": "https://arxiv.org/pdf/2507.14325", "abs": "https://arxiv.org/abs/2507.14325", "authors": ["Luan M. T. de Moraes", "Ant\u00f4nio M. S. Mac\u00eado", "Giovani L. Vasconcelos", "Raydonal Ospina"], "title": "Eigenvalue Distribution of Empirical Correlation Matrices for Multiscale Complex Systems and Application to Financial Data", "categories": ["q-fin.ST", "physics.data-an"], "comment": "31 pages, 8 figures, submitted to Physical Review E", "summary": "We introduce a method for describing eigenvalue distributions of correlation\nmatrices from multidimensional time series. Using our newly developed matrix H\ntheory, we improve the description of eigenvalue spectra for empirical\ncorrelation matrices in multivariate financial data by considering an\ninformational cascade modeled as a hierarchical structure akin to the\nKolmogorov statistical theory of turbulence. Our approach extends the\nMarchenko-Pastur distribution to account for distinct characteristic scales,\ncapturing a larger fraction of data variance, and challenging the traditional\nview of noise-dressed financial markets. We conjecture that the effectiveness\nof our method stems from the increased complexity in financial markets,\nreflected by new characteristic scales and the growth of computational trading.\nThese findings not only support the turbulent market hypothesis as a source of\nnoise but also provide a practical framework for noise reduction in empirical\ncorrelation matrices, enhancing the inference of true market correlations\nbetween assets.", "AI": {"tldr": "\u4ecb\u7ecd\u4e00\u79cd\u63cf\u8ff0\u591a\u7ef4\u65f6\u95f4\u5e8f\u5217\u76f8\u5173\u77e9\u9635\u7279\u5f81\u503c\u5206\u5e03\u7684\u65b9\u6cd5\uff0c\u6539\u8fdb\u91d1\u878d\u6570\u636e\u7279\u5f81\u503c\u8c31\u63cf\u8ff0\uff0c\u652f\u6301\u6e4d\u6d41\u5e02\u573a\u5047\u8bf4\u5e76\u63d0\u4f9b\u964d\u566a\u6846\u67b6\u3002", "motivation": "\u6539\u8fdb\u591a\u5143\u91d1\u878d\u6570\u636e\u4e2d\u7ecf\u9a8c\u76f8\u5173\u77e9\u9635\u7279\u5f81\u503c\u8c31\u7684\u63cf\u8ff0\uff0c\u6311\u6218\u91d1\u878d\u5e02\u573a\u4f20\u7edf\u89c2\u70b9\u3002", "method": "\u8fd0\u7528\u65b0\u5f00\u53d1\u7684\u77e9\u9635H\u7406\u8bba\uff0c\u8003\u8651\u4fe1\u606f\u7ea7\u8054\uff0c\u5c06Marchenko - Pastur\u5206\u5e03\u6269\u5c55\u4ee5\u8003\u8651\u4e0d\u540c\u7279\u5f81\u5c3a\u5ea6\u3002", "result": "\u80fd\u6355\u6349\u66f4\u5927\u6bd4\u4f8b\u7684\u6570\u636e\u65b9\u5dee\uff0c\u6311\u6218\u4f20\u7edf\u89c2\u70b9\uff0c\u652f\u6301\u6e4d\u6d41\u5e02\u573a\u5047\u8bf4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6e90\u4e8e\u91d1\u878d\u5e02\u573a\u590d\u6742\u6027\u589e\u52a0\uff0c\u4e3a\u7ecf\u9a8c\u76f8\u5173\u77e9\u9635\u964d\u566a\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\uff0c\u589e\u5f3a\u8d44\u4ea7\u95f4\u771f\u5b9e\u5e02\u573a\u76f8\u5173\u6027\u63a8\u65ad\u3002"}}
{"id": "2507.14869", "pdf": "https://arxiv.org/pdf/2507.14869", "abs": "https://arxiv.org/abs/2507.14869", "authors": ["Danilo Costarelli", "Michele Piconi", "Alessio Troiani"], "title": "Bayesian Inversion via Probabilistic Cellular Automata: an application to image denoising", "categories": ["stat.CO", "math.PR"], "comment": null, "summary": "We propose using Probabilistic Cellular Automata (PCA) to address inverse\nproblems with the Bayesian approach. In particular, we use PCA to sample from\nan approximation of the posterior distribution. The peculiar feature of PCA is\ntheir intrinsic parallel nature, which allows for a straightforward parallel\nimplementation that allows the exploitation of parallel computing architecture\nin a natural and efficient manner. We compare the performance of the PCA method\nwith the standard Gibbs sampler on an image denoising task in terms of Peak\nSignal-to-Noise Ratio (PSNR) and Structural Similarity (SSIM). The numerical\nresults obtained with this approach suggest that PCA-based algorithms are a\npromising alternative for Bayesian inference in high-dimensional inverse\nproblems.", "AI": {"tldr": "\u63d0\u51fa\u7528\u6982\u7387\u7ec6\u80de\u81ea\u52a8\u673a\uff08PCA\uff09\u7ed3\u5408\u8d1d\u53f6\u65af\u65b9\u6cd5\u89e3\u51b3\u9006\u95ee\u9898\uff0c\u5bf9\u6bd4PCA\u65b9\u6cd5\u4e0e\u6807\u51c6\u5409\u5e03\u65af\u91c7\u6837\u5668\u5728\u56fe\u50cf\u53bb\u566a\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u8868\u660ePCA\u7b97\u6cd5\u6709\u6f5c\u529b\u3002", "motivation": "\u5bfb\u627e\u80fd\u9ad8\u6548\u89e3\u51b3\u9ad8\u7ef4\u9006\u95ee\u9898\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u65b9\u6cd5\uff0c\u5229\u7528PCA\u7684\u5e76\u884c\u7279\u6027\u3002", "method": "\u4f7f\u7528PCA\u4ece\u540e\u9a8c\u5206\u5e03\u8fd1\u4f3c\u4e2d\u91c7\u6837\uff0c\u5728\u56fe\u50cf\u53bb\u566a\u4efb\u52a1\u4e2d\u5bf9\u6bd4PCA\u65b9\u6cd5\u4e0e\u6807\u51c6\u5409\u5e03\u65af\u91c7\u6837\u5668\u3002", "result": "\u5728\u56fe\u50cf\u53bb\u566a\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8ePCA\u7684\u7b97\u6cd5\u5728PSNR\u548cSSIM\u65b9\u9762\u6709\u4e00\u5b9a\u8868\u73b0\u3002", "conclusion": "PCA-based\u7b97\u6cd5\u662f\u9ad8\u7ef4\u9006\u95ee\u9898\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002"}}
{"id": "2507.14812", "pdf": "https://arxiv.org/pdf/2507.14812", "abs": "https://arxiv.org/abs/2507.14812", "authors": ["Suho Kang", "Ziyang Liu", "Rajan Udwani"], "title": "A Black-Box Approach for Exogenous Replenishment in Online Resource Allocation", "categories": ["cs.DS"], "comment": null, "summary": "In a typical online resource allocation problem, we start with a fixed\ninventory of resources and make online allocation decisions in response to\nresource requests that arrive sequentially over a finite horizon. We consider\nsettings where the inventory is replenished over time according to an unknown\nexogenous process. We introduce black-box methods that extend any existing\nalgorithm, originally designed without considering replenishment, into one that\nworks with an arbitrary (adversarial or stochastic) replenishment process. Our\napproach preserves the original algorithm's competitive ratio in regimes with\nlarge initial inventory, thereby enabling the seamless integration of exogenous\nreplenishment into a large body of existing algorithmic results for both\nadversarial and stochastic arrival models.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5728\u7ebf\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u9ed1\u76d2\u65b9\u6cd5\u5c06\u539f\u4e0d\u8003\u8651\u8865\u8d27\u7684\u7b97\u6cd5\u6269\u5c55\u5230\u542b\u4efb\u610f\u8865\u8d27\u8fc7\u7a0b\u7684\u60c5\u51b5\uff0c\u4e14\u5728\u521d\u59cb\u5e93\u5b58\u5927\u65f6\u4fdd\u6301\u539f\u7b97\u6cd5\u7ade\u4e89\u6bd4\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u8d44\u6e90\u5206\u914d\u4e2d\u5e93\u5b58\u968f\u672a\u77e5\u5916\u90e8\u8fc7\u7a0b\u8865\u5145\u7684\u95ee\u9898\uff0c\u4f7f\u73b0\u6709\u7b97\u6cd5\u80fd\u9002\u5e94\u8865\u8d27\u60c5\u51b5\u3002", "method": "\u5f15\u5165\u9ed1\u76d2\u65b9\u6cd5\uff0c\u5c06\u539f\u4e0d\u8003\u8651\u8865\u8d27\u7684\u7b97\u6cd5\u6269\u5c55\u4ee5\u9002\u5e94\u4efb\u610f\uff08\u5bf9\u6297\u6216\u968f\u673a\uff09\u8865\u8d27\u8fc7\u7a0b\u3002", "result": "\u5728\u521d\u59cb\u5e93\u5b58\u5927\u7684\u60c5\u51b5\u4e0b\uff0c\u6269\u5c55\u540e\u7684\u7b97\u6cd5\u80fd\u4fdd\u6301\u539f\u7b97\u6cd5\u7684\u7ade\u4e89\u6bd4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5c06\u5916\u90e8\u8865\u8d27\u65e0\u7f1d\u96c6\u6210\u5230\u5927\u91cf\u73b0\u6709\u5bf9\u6297\u548c\u968f\u673a\u5230\u8fbe\u6a21\u578b\u7684\u7b97\u6cd5\u7ed3\u679c\u4e2d\u3002"}}
{"id": "2507.14495", "pdf": "https://arxiv.org/pdf/2507.14495", "abs": "https://arxiv.org/abs/2507.14495", "authors": ["Roman Heinrich", "Oleksandr Havrylov", "Manisha Luthra", "Johannes Wehrstein", "Carsten Binnig"], "title": "Opening The Black-Box: Explaining Learned Cost Models For Databases", "categories": ["cs.DB"], "comment": "Accepted to VLDB 2025 Demonstration Track", "summary": "Learned Cost Models (LCMs) have shown superior results over traditional\ndatabase cost models as they can significantly improve the accuracy of cost\npredictions. However, LCMs still fail for some query plans, as prediction\nerrors can be large in the tail. Unfortunately, recent LCMs are based on\ncomplex deep neural models, and thus, there is no easy way to understand where\nthis accuracy drop is rooted, which critically prevents systematic\ntroubleshooting. In this demo paper, we present the very first approach for\nopening the black box by bringing AI explainability approaches to LCMs. As a\ncore contribution, we developed new explanation techniques that extend existing\nmethods that are available for the general explainability of AI models and\nadapt them significantly to be usable for LCMs. In our demo, we provide an\ninteractive tool to showcase how explainability for LCMs works. We believe this\nis a first step for making LCMs debuggable and thus paving the road for new\napproaches for systematically fixing problems in LCMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06AI\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5e94\u7528\u4e8e\u5b66\u4e60\u6210\u672c\u6a21\u578b\uff08LCMs\uff09\uff0c\u5f00\u53d1\u65b0\u89e3\u91ca\u6280\u672f\u5e76\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u4e3aLCMs\u8c03\u8bd5\u548c\u89e3\u51b3\u95ee\u9898\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "LCMs\u5728\u90e8\u5206\u67e5\u8be2\u8ba1\u5212\u4e2d\u9884\u6d4b\u8bef\u5dee\u5927\uff0c\u4e14\u57fa\u4e8e\u590d\u6742\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u96be\u4ee5\u7406\u89e3\u7cbe\u5ea6\u4e0b\u964d\u6839\u6e90\uff0c\u963b\u788d\u7cfb\u7edf\u6545\u969c\u6392\u9664\u3002", "method": "\u5c06AI\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5f15\u5165LCMs\uff0c\u5f00\u53d1\u65b0\u89e3\u91ca\u6280\u672f\uff0c\u6269\u5c55\u5e76\u9002\u914d\u73b0\u6709AI\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u3002", "result": "\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u5de5\u5177\u5c55\u793aLCMs\u53ef\u89e3\u91ca\u6027\u5de5\u4f5c\u539f\u7406\u3002", "conclusion": "\u8fd9\u662f\u4f7fLCMs\u53ef\u8c03\u8bd5\u7684\u7b2c\u4e00\u6b65\uff0c\u4e3a\u7cfb\u7edf\u89e3\u51b3LCMs\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.15570", "pdf": "https://arxiv.org/pdf/2507.15570", "abs": "https://arxiv.org/abs/2507.15570", "authors": ["Gabriel Stankiewicz", "Chaitanya Dev", "Paul Steinmann"], "title": "Configurational-force-driven adaptive refinement and coarsening in topology optimization", "categories": ["cs.CE"], "comment": null, "summary": "The iterative nature of topology optimization, especially in combination with\nnonlinear state problems, often requires the solution of thousands of linear\nequation systems. Furthermore, due to the pixelated design representation, the\nuse of a fine mesh is essential to obtain geometrically well-defined structures\nand to accurately compute response quantities such as the von Mises stress.\nTherefore, the computational cost of solving a fine-mesh topology optimization\nproblem quickly adds up. To address this challenge, we consider a multi-level\nadaptive refinement and coarsening strategy based on configurational forces.\nConfigurational forces based on the Eshelby stress predict configurational\nchanges such as crack propagation or dislocation motion. Due to a relaxation in\nthe calculation of (Eshelby) stresses with respect to the design variables,\ndiscrete configurational forces increase not only in highly stressed regions,\nbut also in grey transition regions (design boundaries). For this reason they\nare an ideal criterion for mesh adaptivity in topology optimization, especially\nwhen avoiding stress failure is a priority. By using configurational forces for\nrefinement, we obtain a high-resolution structure where the refined mesh is\npresent along the design boundaries as well as in stress-critical regions. At\nthe same time, multilevel coarsening using the same criterion drastically\nminimizes the computational effort.", "AI": {"tldr": "\u62d3\u6251\u4f18\u5316\u8fed\u4ee3\u6027\u8d28\u53ca\u50cf\u7d20\u5316\u8bbe\u8ba1\u4f7f\u6c42\u89e3\u7ec6\u7f51\u683c\u95ee\u9898\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6784\u578b\u529b\u7684\u591a\u7ea7\u81ea\u9002\u5e94\u7b56\u7565\uff0c\u53ef\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "motivation": "\u62d3\u6251\u4f18\u5316\u8fed\u4ee3\u7ed3\u5408\u975e\u7ebf\u6027\u95ee\u9898\u9700\u89e3\u5927\u91cf\u7ebf\u6027\u65b9\u7a0b\u7ec4\uff0c\u50cf\u7d20\u5316\u8bbe\u8ba1\u8981\u7528\u7ec6\u7f51\u683c\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6784\u578b\u529b\u7684\u591a\u7ea7\u81ea\u9002\u5e94\u7ec6\u5316\u548c\u7c97\u5316\u7b56\u7565\uff0c\u6784\u578b\u529b\u57fa\u4e8eEshelby\u5e94\u529b\uff0c\u5229\u7528\u5176\u5728\u9ad8\u5e94\u529b\u548c\u8fc7\u6e21\u533a\u57df\u589e\u52a0\u7684\u7279\u70b9\u8fdb\u884c\u7f51\u683c\u81ea\u9002\u5e94\u3002", "result": "\u4f7f\u7528\u6784\u578b\u529b\u7ec6\u5316\u53ef\u5728\u8bbe\u8ba1\u8fb9\u754c\u548c\u5e94\u529b\u5173\u952e\u533a\u57df\u5f97\u5230\u9ad8\u5206\u8fa8\u7387\u7ed3\u6784\uff0c\u591a\u7ea7\u7c97\u5316\u80fd\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u91cf\u3002", "conclusion": "\u57fa\u4e8e\u6784\u578b\u529b\u7684\u591a\u7ea7\u81ea\u9002\u5e94\u7b56\u7565\u80fd\u6709\u6548\u89e3\u51b3\u7ec6\u7f51\u683c\u62d3\u6251\u4f18\u5316\u95ee\u9898\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u6311\u6218\u3002"}}
{"id": "2507.14757", "pdf": "https://arxiv.org/pdf/2507.14757", "abs": "https://arxiv.org/abs/2507.14757", "authors": ["Szymon Mazurek", "Jakub Caputa", "Maciej Wielgosz"], "title": "Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Spiking Neural Networks (SNNs) offer energy-efficient and biologically\nplausible alternatives to traditional artificial neural networks, but their\nperformance depends critically on the tuning of neuron model parameters. In\nthis work, we identify and characterize an operational space - a constrained\nregion in the neuron hyperparameter domain (specifically membrane time constant\ntau and voltage threshold vth) - within which the network exhibits meaningful\nactivity and functional behavior. Operating inside this manifold yields optimal\ntrade-offs between classification accuracy and spiking activity, while stepping\noutside leads to degeneration: either excessive energy use or complete network\nsilence.\n  Through systematic exploration across datasets and architectures, we\nvisualize and quantify this manifold and identify efficient operating points.\nWe further assess robustness to adversarial noise, showing that SNNs exhibit\nincreased spike correlation and internal synchrony when operating outside their\noptimal region. These findings highlight the importance of principled\nhyperparameter tuning to ensure both task performance and energy efficiency.\nOur results offer practical guidelines for deploying robust and efficient SNNs,\nparticularly in neuromorphic computing scenarios.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u7684\u795e\u7ecf\u5143\u8d85\u53c2\u6570\u64cd\u4f5c\u7a7a\u95f4\uff0c\u786e\u5b9a\u9ad8\u6548\u8fd0\u884c\u70b9\uff0c\u4e3a\u90e8\u7f72\u9c81\u68d2\u9ad8\u6548\u7684SNNs\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u3002", "motivation": "SNNs\u6027\u80fd\u5173\u952e\u4f9d\u8d56\u4e8e\u795e\u7ecf\u5143\u6a21\u578b\u53c2\u6570\u8c03\u6574\uff0c\u9700\u786e\u5b9a\u5408\u9002\u7684\u53c2\u6570\u64cd\u4f5c\u7a7a\u95f4\u4ee5\u5e73\u8861\u5206\u7c7b\u7cbe\u5ea6\u548c\u8109\u51b2\u6d3b\u52a8\u3002", "method": "\u901a\u8fc7\u8de8\u6570\u636e\u96c6\u548c\u67b6\u6784\u7684\u7cfb\u7edf\u63a2\u7d22\uff0c\u53ef\u89c6\u5316\u5e76\u91cf\u5316\u64cd\u4f5c\u7a7a\u95f4\uff0c\u8bc4\u4f30\u5bf9\u6297\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002", "result": "\u786e\u5b9a\u4e86\u64cd\u4f5c\u7a7a\u95f4\uff0c\u53d1\u73b0\u7a7a\u95f4\u5185\u5916\u7684\u4e0d\u540c\u8868\u73b0\uff0c\u5982\u5916\u90e8\u4f1a\u589e\u52a0\u8109\u51b2\u76f8\u5173\u6027\u548c\u5185\u90e8\u540c\u6b65\u6027\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u539f\u5219\u6027\u8d85\u53c2\u6570\u8c03\u6574\u5bf9\u4fdd\u8bc1\u4efb\u52a1\u6027\u80fd\u548c\u80fd\u6e90\u6548\u7387\u7684\u91cd\u8981\u6027\uff0c\u4e3aSNNs\u90e8\u7f72\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2507.14723", "pdf": "https://arxiv.org/pdf/2507.14723", "abs": "https://arxiv.org/abs/2507.14723", "authors": ["Brati Mondal", "Pritam Goswami", "Buddhadeb Sau"], "title": "Simulating Chirality: Solving Distance-$k$-Dispersion on an 1-Interval Connected Ring", "categories": ["cs.DC"], "comment": null, "summary": "We study the Distance-$k$-Dispersion (D-$k$-D) problem for synchronous mobile\nagents in a 1-interval-connected ring network having $n$ nodes and with $l$\nagents where $3 \\le l \\le \\lfloor \\frac{n}{k}\\rfloor$, without the assumption\nof chirality (a common sense of direction for the agents). This generalizes the\nclassical dispersion problem by requiring that agents maintain a minimum\ndistance of $k$ hops from each other, with the special case $k=1$ corresponding\nto the standard dispersion.\n  The contribution in this work is threefold. Our first contribution is a novel\nmethod that enables agents to simulate chirality using only local information,\nvision and bounded memory. This technique demonstrates that chirality is not a\nfundamental requirement for coordination in this model.\n  Building on this, our second contribution partially resolves an open question\nposed by Agarwalla et al. (ICDCN, 2018), who considered the same model (1-\ninterval connected ring, synchronous agents, no chirality). We prove that\nD-$k$-D, and thus dispersion is solvable from any arbitrary configuration under\nthese assumptions (excluding vertex permutation dynamism)for any size of the\nring network which was earlier limited to only odd sized ring or to a ring of\nsize four.\n  Finally, we present an algorithm for D-$k$-D in this setting that works in\n$O(ln)$ rounds, completing the constructive side of our result.\n  Altogether, our findings significantly extend the theoretical understanding\nof mobile agent coordination in dynamic networks and clarify the role of\nchirality in distributed computation.", "AI": {"tldr": "\u7814\u7a76\u65e0\u624b\u6027\u5047\u8bbe\u4e0b\u540c\u6b65\u79fb\u52a8\u4ee3\u7406\u57281 - \u533a\u95f4\u8fde\u901a\u73af\u7f51\u7edc\u4e2d\u7684\u8ddd\u79bb - k - \u5206\u6563\u95ee\u9898\uff0c\u63d0\u51fa\u6a21\u62df\u624b\u6027\u65b9\u6cd5\uff0c\u89e3\u51b3\u90e8\u5206\u5f00\u653e\u95ee\u9898\uff0c\u7ed9\u51faO(ln)\u8f6e\u7b97\u6cd5\u3002", "motivation": "\u63a8\u5e7f\u7ecf\u5178\u5206\u6563\u95ee\u9898\uff0c\u5728\u65e0\u624b\u6027\u5047\u8bbe\u4e0b\u7814\u7a76\u79fb\u52a8\u4ee3\u7406\u5728\u73af\u7f51\u7edc\u4e2d\u7684\u8ddd\u79bb - k - \u5206\u6563\u95ee\u9898\uff0c\u6269\u5c55\u52a8\u6001\u7f51\u7edc\u4e2d\u79fb\u52a8\u4ee3\u7406\u534f\u8c03\u7684\u7406\u8bba\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u7528\u5c40\u90e8\u4fe1\u606f\u3001\u89c6\u89c9\u548c\u6709\u754c\u5185\u5b58\u6a21\u62df\u624b\u6027\u7684\u65b9\u6cd5\uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u884c\u95ee\u9898\u6c42\u89e3\uff0c\u7ed9\u51faD - k - D\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u5728\u7ed9\u5b9a\u5047\u8bbe\u4e0bD - k - D\u95ee\u9898\u4ece\u4efb\u610f\u914d\u7f6e\u53ef\u89e3\uff0c\u7ed9\u51faO(ln)\u8f6e\u7684D - k - D\u7b97\u6cd5\u3002", "conclusion": "\u7814\u7a76\u663e\u8457\u6269\u5c55\u4e86\u52a8\u6001\u7f51\u7edc\u4e2d\u79fb\u52a8\u4ee3\u7406\u534f\u8c03\u7684\u7406\u8bba\u7406\u89e3\uff0c\u660e\u786e\u4e86\u624b\u6027\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2507.14293", "pdf": "https://arxiv.org/pdf/2507.14293", "abs": "https://arxiv.org/abs/2507.14293", "authors": ["Boyuan Zheng", "Zeyi Liao", "Scott Salisbury", "Zeyuan Liu", "Michael Lin", "Qinyuan Zheng", "Zifan Wang", "Xiang Deng", "Dawn Song", "Huan Sun", "Yu Su"], "title": "WebGuard: Building a Generalizable Guardrail for Web Agents", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "We publicly release WebGuard, along with its annotation tools and\n  fine-tuned models, to facilitate open-source research on monitoring and\n  safeguarding web agents. All resources are available at\n  https://github.com/OSU-NLP-Group/WebGuard", "summary": "The rapid development of autonomous web agents powered by Large Language\nModels (LLMs), while greatly elevating efficiency, exposes the frontier risk of\ntaking unintended or harmful actions. This situation underscores an urgent need\nfor effective safety measures, akin to access controls for human users. To\naddress this critical challenge, we introduce WebGuard, the first comprehensive\ndataset designed to support the assessment of web agent action risks and\nfacilitate the development of guardrails for real-world online environments. In\ndoing so, WebGuard specifically focuses on predicting the outcome of\nstate-changing actions and contains 4,939 human-annotated actions from 193\nwebsites across 22 diverse domains, including often-overlooked long-tail\nwebsites. These actions are categorized using a novel three-tier risk schema:\nSAFE, LOW, and HIGH. The dataset includes designated training and test splits\nto support evaluation under diverse generalization settings. Our initial\nevaluations reveal a concerning deficiency: even frontier LLMs achieve less\nthan 60% accuracy in predicting action outcomes and less than 60% recall in\nlagging HIGH-risk actions, highlighting the risks of deploying\ncurrent-generation agents without dedicated safeguards. We therefore\ninvestigate fine-tuning specialized guardrail models using WebGuard. We conduct\ncomprehensive evaluations across multiple generalization settings and find that\na fine-tuned Qwen2.5VL-7B model yields a substantial improvement in\nperformance, boosting accuracy from 37% to 80% and HIGH-risk action recall from\n20% to 76%. Despite these improvements, the performance still falls short of\nthe reliability required for high-stakes deployment, where guardrails must\napproach near-perfect accuracy and recall.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecdWebGuard\u6570\u636e\u96c6\u4ee5\u8bc4\u4f30\u7f51\u7edc\u4ee3\u7406\u52a8\u4f5c\u98ce\u9669\uff0c\u521d\u59cb\u8bc4\u4f30\u663e\u793a\u524d\u6cbf\u5927\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u5fae\u8c03\u6a21\u578b\u6709\u6539\u5584\u4f46\u4ecd\u672a\u8fbe\u9ad8\u98ce\u9669\u90e8\u7f72\u8981\u6c42\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u53d1\u5c55\u5e26\u6765\u610f\u5916\u6216\u6709\u5bb3\u52a8\u4f5c\u98ce\u9669\uff0c\u6025\u9700\u6709\u6548\u5b89\u5168\u63aa\u65bd\u3002", "method": "\u5f15\u5165WebGuard\u6570\u636e\u96c6\uff0c\u7528\u4e09\u5c42\u98ce\u9669\u6a21\u5f0f\u5206\u7c7b\u52a8\u4f5c\uff0c\u5212\u5206\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\uff0c\u5bf9\u4e13\u95e8\u62a4\u680f\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u521d\u59cb\u8bc4\u4f30\u524d\u6cbf\u5927\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u4f4e\uff0c\u5fae\u8c03Qwen2.5VL - 7B\u6a21\u578b\u540e\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u5fae\u8c03\u6a21\u578b\u867d\u6709\u6539\u5584\uff0c\u4f46\u4ecd\u672a\u8fbe\u5230\u9ad8\u98ce\u9669\u90e8\u7f72\u6240\u9700\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.14396", "pdf": "https://arxiv.org/pdf/2507.14396", "abs": "https://arxiv.org/abs/2507.14396", "authors": ["Carey Lai Zheng Hui", "Johnson Britto Jessia Esther Leena", "Kumuthini Subramanian", "Zhao Chenyu", "Shubham Rajeshkumar Jariwala"], "title": "Developing Shared Vocabulary System For Collaborative Software Engineering", "categories": ["cs.SE"], "comment": "16 pages, including appendix", "summary": "Effective communication is a critical factor in successful software\nengineering collaboration. However, communication gaps remain a persistent\nchallenge, often leading to misunderstandings, inefficiencies, and defects.\nThis research investigates the technical factors contributing to such\nmisunderstandings and explores the measurable benefits of establishing shared\nvocabulary systems within software documentation and codebases. Using a Design\nScience Research (DSR) framework, the study was structured into three iterative\nphases: problem identification, method development, and empirical validation.\nThe problem identification phase involved thematic analysis of communication\ndata and semi-structured interviews, revealing key factors such as ambiguous\nmessaging, misalignment in documentation, inconsistent code review feedback,\nand API integration miscommunication. Grounded Theory principles were employed\nto design a structured methodology for collaborative vocabulary development.\nEmpirical validation through controlled experiments demonstrated that while\ninitial adoption introduced overhead, the shared vocabulary system\nsignificantly improved information density, documentation clarity, and\ncollaboration efficiency over time. Findings offer actionable insights for\nimproving communication practices in software engineering, while also\nidentifying limitations and directions for future research.", "AI": {"tldr": "\u7814\u7a76\u8f6f\u4ef6\u534f\u4f5c\u4e2d\u6c9f\u901a\u95ee\u9898\uff0c\u91c7\u7528DSR\u6846\u67b6\uff0c\u53d1\u73b0\u5171\u4eab\u8bcd\u6c47\u7cfb\u7edf\u53ef\u63d0\u5347\u6c9f\u901a\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u8f6f\u4ef6\u534f\u4f5c\u4e2d\u6c9f\u901a\u5dee\u8ddd\u5bfc\u81f4\u7684\u8bef\u89e3\u3001\u4f4e\u6548\u548c\u7f3a\u9677\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\uff08DSR\uff09\u6846\u67b6\uff0c\u5206\u95ee\u9898\u8bc6\u522b\u3001\u65b9\u6cd5\u5f00\u53d1\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u4e09\u9636\u6bb5\uff0c\u7528\u4e3b\u9898\u5206\u6790\u3001\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u548c\u63a7\u5236\u5b9e\u9a8c\u7b49\u3002", "result": "\u5171\u4eab\u8bcd\u6c47\u7cfb\u7edf\u867d\u521d\u671f\u6709\u6210\u672c\uff0c\u4f46\u80fd\u63d0\u5347\u4fe1\u606f\u5bc6\u5ea6\u3001\u6587\u6863\u6e05\u6670\u5ea6\u548c\u534f\u4f5c\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6539\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u6c9f\u901a\u5b9e\u8df5\u63d0\u4f9b\u89c1\u89e3\uff0c\u6307\u51fa\u5c40\u9650\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.14361", "pdf": "https://arxiv.org/pdf/2507.14361", "abs": "https://arxiv.org/abs/2507.14361", "authors": ["Huy-Son Nguyen", "Quang-Huy Nguyen", "Duc-Hoang Pham", "Duc-Trong Le", "Hoang-Quynh Le", "Padipat Sitkrongwong", "Atsuhiro Takasu", "Masoud Mansoury"], "title": "RaMen: Multi-Strategy Multi-Modal Learning for Bundle Construction", "categories": ["cs.IR"], "comment": null, "summary": "Existing studies on bundle construction have relied merely on user feedback\nvia bipartite graphs or enhanced item representations using semantic\ninformation. These approaches fail to capture elaborate relations hidden in\nreal-world bundle structures, resulting in suboptimal bundle representations.\nTo overcome this limitation, we propose RaMen, a novel method that provides a\nholistic multi-strategy approach for bundle construction. RaMen utilizes both\nintrinsic (characteristics) and extrinsic (collaborative signals) information\nto model bundle structures through Explicit Strategy-aware Learning (ESL) and\nImplicit Strategy-aware Learning (ISL). ESL employs task-specific attention\nmechanisms to encode multi-modal data and direct collaborative relations\nbetween items, thereby explicitly capturing essential bundle features.\nMoreover, ISL computes hyperedge dependencies and hypergraph message passing to\nuncover shared latent intents among groups of items. Integrating diverse\nstrategies enables RaMen to learn more comprehensive and robust bundle\nrepresentations. Meanwhile, Multi-strategy Alignment & Discrimination module is\nemployed to facilitate knowledge transfer between learning strategies and\nensure discrimination between items/bundles. Extensive experiments demonstrate\nthe effectiveness of RaMen over state-of-the-art models on various domains,\njustifying valuable insights into complex item set problems.", "AI": {"tldr": "\u73b0\u6709\u6346\u7ed1\u6784\u5efa\u7814\u7a76\u6709\u5c40\u9650\uff0c\u63d0\u51faRaMen\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u7b56\u7565\u5b66\u4e60\u5168\u9762\u5065\u58ee\u7684\u6346\u7ed1\u8868\u793a\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6346\u7ed1\u6784\u5efa\u7814\u7a76\u4ec5\u4f9d\u8d56\u7528\u6237\u53cd\u9988\u6216\u8bed\u4e49\u4fe1\u606f\uff0c\u65e0\u6cd5\u6355\u6349\u73b0\u5b9e\u6346\u7ed1\u7ed3\u6784\u7684\u7cbe\u7ec6\u5173\u7cfb\uff0c\u5bfc\u81f4\u6346\u7ed1\u8868\u793a\u4e0d\u4f73\u3002", "method": "\u63d0\u51faRaMen\u65b9\u6cd5\uff0c\u5229\u7528\u5185\u5728\u548c\u5916\u5728\u4fe1\u606f\uff0c\u901a\u8fc7\u663e\u5f0f\u7b56\u7565\u611f\u77e5\u5b66\u4e60\uff08ESL\uff09\u548c\u9690\u5f0f\u7b56\u7565\u611f\u77e5\u5b66\u4e60\uff08ISL\uff09\u5efa\u6a21\u6346\u7ed1\u7ed3\u6784\uff0c\u8fd8\u91c7\u7528\u591a\u7b56\u7565\u5bf9\u9f50\u4e0e\u5224\u522b\u6a21\u5757\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0cRaMen\u6bd4\u73b0\u6709\u6a21\u578b\u66f4\u6709\u6548\u3002", "conclusion": "RaMen\u4e3a\u590d\u6742\u9879\u76ee\u96c6\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.14717", "pdf": "https://arxiv.org/pdf/2507.14717", "abs": "https://arxiv.org/abs/2507.14717", "authors": ["Minghong Yuan", "Wen Wen", "Indranil Bardhan"], "title": "Does Private Equity Hurt or Improve Healthcare Value? New Evidence and Mechanisms", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "What is the impact of private equity (PE) investment on healthcare value?\nDoes PE investment hurt or improve healthcare value, and if so, can its effect\nbe mitigated through the use of health information technologies (IT)? Given the\nsignificant investments by PE firms in the healthcare sector in recent years,\nthese are important research questions. Stakeholders, including policy makers,\ncare providers, and patients, need to understand their likely impact and\nwhether PE ownership is aligned with their interests. Using a staggered\ndifference-in-differences approach and data from US hospitals from 2008-2020,\nwe observe that the overall value of healthcare delivered by hospitals declines\nafter PE investment. However, our empirical evidence reveals that IT-enabled,\nhealth information sharing plays an important moderating role. Hospitals with\nstronger information-sharing capabilities exhibit greater cost efficiencies and\nimprovements in care quality, leading to higher healthcare value after PE\ninvestment. Furthermore, we find that the type of health information sharing\nmatters. Specifically, we observe that improvements in care quality are\nprimarily driven by information sharing between hospitals and ambulatory care\nproviders, instead of simply hospital-to-hospital sharing of patient health\ndata. Our research also identifies the underlying mechanisms through which\nhealth information sharing improves care value by reducing hospital-acquired\ninfections and readmission rates, thereby improving care quality, and enhancing\nlabor productivity by reducing operating costs. Our results highlight the\ncritical role of policies and common data standards needed to promote\nIT-enabled information sharing between healthcare providers, which, in turn,\ncan align incentives of PE firms with the goals of value-based care.", "AI": {"tldr": "\u7814\u7a76\u79c1\u52df\u80a1\u6743\u6295\u8d44\u5bf9\u533b\u7597\u4ef7\u503c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6295\u8d44\u540e\u533b\u9662\u533b\u7597\u4ef7\u503c\u4e0b\u964d\uff0c\u4f46\u4fe1\u606f\u6280\u672f\u652f\u6301\u7684\u4fe1\u606f\u5171\u4eab\u53ef\u7f13\u89e3\uff0c\u4e0d\u540c\u4fe1\u606f\u5171\u4eab\u7c7b\u578b\u4f5c\u7528\u6709\u522b\uff0c\u5f3a\u8c03\u653f\u7b56\u548c\u6570\u636e\u6807\u51c6\u4fc3\u8fdb\u4fe1\u606f\u5171\u4eab\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8fd1\u5e74\u6765\u79c1\u52df\u80a1\u6743\u516c\u53f8\u5728\u533b\u7597\u9886\u57df\u6295\u8d44\u5de8\u5927\uff0c\u5229\u76ca\u76f8\u5173\u8005\u9700\u4e86\u89e3\u6295\u8d44\u5f71\u54cd\u53ca\u662f\u5426\u7b26\u5408\u81ea\u8eab\u5229\u76ca\u3002", "method": "\u91c7\u7528\u4ea4\u9519\u53cc\u91cd\u5dee\u5206\u6cd5\uff0c\u4f7f\u75282008 - 2020\u5e74\u7f8e\u56fd\u533b\u9662\u6570\u636e\u3002", "result": "\u79c1\u52df\u80a1\u6743\u6295\u8d44\u540e\u533b\u9662\u6574\u4f53\u533b\u7597\u4ef7\u503c\u4e0b\u964d\uff1b\u4fe1\u606f\u6280\u672f\u652f\u6301\u7684\u4fe1\u606f\u5171\u4eab\u6709\u8c03\u8282\u4f5c\u7528\uff0c\u533b\u9662\u4e0e\u95e8\u8bca\u62a4\u7406\u63d0\u4f9b\u8005\u95f4\u4fe1\u606f\u5171\u4eab\u66f4\u80fd\u63d0\u5347\u62a4\u7406\u8d28\u91cf\uff1b\u4fe1\u606f\u5171\u4eab\u53ef\u964d\u4f4e\u611f\u67d3\u548c\u518d\u5165\u9662\u7387\u3001\u63d0\u9ad8\u52b3\u52a8\u751f\u4ea7\u7387\u3002", "conclusion": "\u5e94\u5236\u5b9a\u653f\u7b56\u548c\u901a\u7528\u6570\u636e\u6807\u51c6\uff0c\u4fc3\u8fdb\u533b\u7597\u670d\u52a1\u63d0\u4f9b\u8005\u95f4\u4fe1\u606f\u5171\u4eab\uff0c\u4f7f\u79c1\u52df\u80a1\u6743\u516c\u53f8\u6fc0\u52b1\u4e0e\u4ef7\u503c\u533b\u7597\u76ee\u6807\u4e00\u81f4\u3002"}}
{"id": "2507.14957", "pdf": "https://arxiv.org/pdf/2507.14957", "abs": "https://arxiv.org/abs/2507.14957", "authors": ["Jaros\u0142aw Byrka", "Franciszek Malinka", "Tomasz Ponitka"], "title": "Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division", "categories": ["cs.GT", "cs.AI", "cs.DS"], "comment": "27 pages, 4 figures", "summary": "We study the fair division of indivisible items and provide new insights into\nthe EFX problem, which is widely regarded as the central open question in fair\ndivision, and the PMMS problem, a strictly stronger variant of EFX. Our first\nresult constructs a three-agent instance with two monotone valuations and one\nadditive valuation in which no PMMS allocation exists. Since EFX allocations\nare known to exist under these assumptions, this establishes a formal\nseparation between EFX and PMMS.\n  We prove existence of fair allocations for three important special cases. We\nshow that EFX allocations exist for personalized bivalued valuations, where for\neach agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value\n$v_i(\\{g\\}) \\in \\{a_i, b_i\\}$ to each good $g$. We establish an analogous\nexistence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also\nprove that PMMS allocations exist for binary-valued MMS-feasible valuations,\nwhere each bundle $S$ has value $v_i(S) \\in \\{0, 1\\}$. Notably, this result\nholds even without assuming monotonicity of valuations and thus applies to the\nfair division of chores and mixed manna. Finally, we study a class of\nvaluations called pair-demand valuations, which extend the well-studied\nunit-demand valuations to the case where each agent derives value from at most\ntwo items, and we show that PMMS allocations exist in this setting. Our proofs\nare constructive, and we provide polynomial-time algorithms for all three\nexistence results.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u53ef\u5206\u7269\u54c1\u516c\u5e73\u5206\u914d\uff0c\u63a2\u8ba8EFX\u548cPMMS\u95ee\u9898\uff0c\u6784\u9020\u5b9e\u4f8b\u533a\u5206\u4e24\u8005\uff0c\u8bc1\u660e\u4e09\u7c7b\u7279\u6b8a\u60c5\u51b5\u516c\u5e73\u5206\u914d\u5b58\u5728\u6027\u5e76\u7ed9\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u516c\u5e73\u5206\u914d\u9886\u57df\u6838\u5fc3\u5f00\u653e\u95ee\u9898EFX\u53ca\u66f4\u5f3a\u53d8\u4f53PMMS\u95ee\u9898\u3002", "method": "\u6784\u9020\u4e09\u4e3b\u4f53\u5b9e\u4f8b\u3001\u6570\u5b66\u8bc1\u660e\u3001\u8bbe\u8ba1\u7b97\u6cd5\u3002", "result": "\u6784\u9020\u5b9e\u4f8b\u533a\u5206EFX\u548cPMMS\uff1b\u8bc1\u660e\u4e2a\u6027\u5316\u53cc\u503c\u4f30\u503c\u3001\u4e8c\u8fdb\u5236\u503cMMS\u53ef\u884c\u4f30\u503c\u3001\u6210\u5bf9\u9700\u6c42\u4f30\u503c\u4e09\u79cd\u60c5\u51b5\u4e0b\u516c\u5e73\u5206\u914d\u5b58\u5728\u6027\uff0c\u7ed9\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "conclusion": "\u4e3a\u4e0d\u53ef\u5206\u7269\u54c1\u516c\u5e73\u5206\u914d\u63d0\u4f9b\u65b0\u89c1\u89e3\uff0c\u89e3\u51b3\u4e09\u7c7b\u7279\u6b8a\u60c5\u51b5\u516c\u5e73\u5206\u914d\u5b58\u5728\u6027\u95ee\u9898\u3002"}}
{"id": "2507.14959", "pdf": "https://arxiv.org/pdf/2507.14959", "abs": "https://arxiv.org/abs/2507.14959", "authors": ["Saeid Ghafouri", "Mohsen Fayyaz", "Xiangchen Li", "Deepu John", "Bo Ji", "Dimitrios Nikolopoulos", "Hans Vandierendonck"], "title": "Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices", "categories": ["cs.CV", "cs.PF"], "comment": null, "summary": "Real-time multi-label video classification on embedded devices is constrained\nby limited compute and energy budgets. Yet, video streams exhibit structural\nproperties such as label sparsity, temporal continuity, and label co-occurrence\nthat can be leveraged for more efficient inference. We introduce Polymorph, a\ncontext-aware framework that activates a minimal set of lightweight Low Rank\nAdapters (LoRA) per frame. Each adapter specializes in a subset of classes\nderived from co-occurrence patterns and is implemented as a LoRA weight over a\nshared backbone. At runtime, Polymorph dynamically selects and composes only\nthe adapters needed to cover the active labels, avoiding full-model switching\nand weight merging. This modular strategy improves scalability while reducing\nlatency and energy overhead. Polymorph achieves 40% lower energy consumption\nand improves mAP by 9 points over strong baselines on the TAO dataset.\nPolymorph is open source at https://github.com/inference-serving/polymorph/.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6Polymorph\uff0c\u53ef\u7528\u4e8e\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u591a\u6807\u7b7e\u89c6\u9891\u5206\u7c7b\uff0c\u80fd\u964d\u4f4e\u80fd\u8017\u5e76\u63d0\u9ad8mAP\u3002", "motivation": "\u5d4c\u5165\u5f0f\u8bbe\u5907\u7684\u8ba1\u7b97\u548c\u80fd\u6e90\u9884\u7b97\u6709\u9650\uff0c\u800c\u89c6\u9891\u6d41\u7684\u7ed3\u6784\u7279\u6027\u53ef\u7528\u4e8e\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u3002", "method": "\u5f15\u5165Polymorph\u6846\u67b6\uff0c\u6bcf\u5e27\u6fc0\u6d3b\u6700\u5c11\u7684\u8f7b\u91cf\u7ea7\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\uff0c\u8fd0\u884c\u65f6\u52a8\u6001\u9009\u62e9\u548c\u7ec4\u5408\u6240\u9700\u9002\u914d\u5668\u3002", "result": "\u5728TAO\u6570\u636e\u96c6\u4e0a\uff0cPolymorph\u80fd\u8017\u964d\u4f4e40%\uff0cmAP\u63d0\u9ad89\u4e2a\u70b9\u3002", "conclusion": "Polymorph\u7684\u6a21\u5757\u5316\u7b56\u7565\u63d0\u9ad8\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u80fd\u6e90\u5f00\u9500\uff0c\u4e14\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.14172", "pdf": "https://arxiv.org/pdf/2507.14172", "abs": "https://arxiv.org/abs/2507.14172", "authors": ["Julien Pourcel", "C\u00e9dric Colas", "Pierre-Yves Oudeyer"], "title": "Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Many program synthesis tasks prove too challenging for even state-of-the-art\nlanguage models to solve in single attempts. Search-based evolutionary methods\noffer a promising alternative by exploring solution spaces iteratively, but\ntheir effectiveness remain limited by the fixed capabilities of the underlying\ngenerative model.\n  We propose SOAR, a method that learns program synthesis by integrating\nlanguage models into a self-improving evolutionary loop.\n  SOAR alternates between (1) an evolutionary search that uses an LLM to sample\nand refine candidate solutions, and (2) a hindsight learning phase that\nconverts search attempts into valid problem-solution pairs used to fine-tune\nthe LLM's sampling and refinement capabilities\\, -- \\,enabling increasingly\neffective search in subsequent iterations.\n  On the challenging ARC-AGI benchmark, SOAR achieves significant performance\ngains across model scales and iterations, leveraging positive transfer between\nthe sampling and refinement finetuning tasks. These improvements carry over to\ntest-time adaptation, enabling SOAR to solve 52\\% of the public test set. Our\ncode is open-sourced at: https://github.com/flowersteam/SOAR", "AI": {"tldr": "\u63d0\u51faSOAR\u65b9\u6cd5\u5c06\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u81ea\u6211\u63d0\u5347\u7684\u8fdb\u5316\u5faa\u73af\u4e2d\u8fdb\u884c\u7a0b\u5e8f\u5408\u6210\uff0c\u5728ARC - AGI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\u5bf9\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u5355\u6b21\u6c42\u89e3\u6709\u6311\u6218\uff0c\u57fa\u4e8e\u641c\u7d22\u7684\u8fdb\u5316\u65b9\u6cd5\u53d7\u5e95\u5c42\u751f\u6210\u6a21\u578b\u80fd\u529b\u9650\u5236\u3002", "method": "SOAR\u65b9\u6cd5\u5728\u8fdb\u5316\u641c\u7d22\u548c\u540e\u89c1\u4e4b\u660e\u5b66\u4e60\u9636\u6bb5\u4ea4\u66ff\uff0c\u8fdb\u5316\u641c\u7d22\u7528\u5927\u8bed\u8a00\u6a21\u578b\u91c7\u6837\u548c\u4f18\u5316\u5019\u9009\u89e3\uff0c\u540e\u89c1\u4e4b\u660e\u5b66\u4e60\u9636\u6bb5\u5c06\u641c\u7d22\u5c1d\u8bd5\u8f6c\u5316\u4e3a\u6709\u6548\u95ee\u9898 - \u89e3\u51b3\u65b9\u6848\u5bf9\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u3002", "result": "\u5728ARC - AGI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u548c\u8fed\u4ee3\u6b21\u6570\u4e0b\u90fd\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u80fd\u89e3\u51b3\u516c\u5171\u6d4b\u8bd5\u96c652%\u7684\u95ee\u9898\u3002", "conclusion": "SOAR\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u7a0b\u5e8f\u5408\u6210\u80fd\u529b\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.14641", "pdf": "https://arxiv.org/pdf/2507.14641", "abs": "https://arxiv.org/abs/2507.14641", "authors": ["Jong-Min Kim", "Il Do Ha", "Sangjin Kim"], "title": "Deep Learning-Based Survival Analysis with Copula-Based Activation Functions for Multivariate Response Prediction", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This research integrates deep learning, copula functions, and survival\nanalysis to effectively handle highly correlated and right-censored\nmultivariate survival data. It introduces copula-based activation functions\n(Clayton, Gumbel, and their combinations) to model the nonlinear dependencies\ninherent in such data. Through simulation studies and analysis of real breast\ncancer data, our proposed CNN-LSTM with copula-based activation functions for\nmultivariate multi-types of survival responses enhances prediction accuracy by\nexplicitly addressing right-censored data and capturing complex patterns. The\nmodel's performance is evaluated using Shewhart control charts, focusing on the\naverage run length (ARL).", "AI": {"tldr": "\u7814\u7a76\u6574\u5408\u6df1\u5ea6\u5b66\u4e60\u3001copula\u51fd\u6570\u548c\u751f\u5b58\u5206\u6790\u5904\u7406\u591a\u5143\u751f\u5b58\u6570\u636e\uff0c\u63d0\u51fa\u542bcopula\u6fc0\u6d3b\u51fd\u6570\u7684CNN - LSTM\u6a21\u578b\uff0c\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u4ee5\u63a7\u5236\u56fe\u8bc4\u4f30\u3002", "motivation": "\u6709\u6548\u5904\u7406\u9ad8\u5ea6\u76f8\u5173\u4e14\u53f3\u5220\u5931\u7684\u591a\u5143\u751f\u5b58\u6570\u636e\u3002", "method": "\u5f15\u5165\u57fa\u4e8ecopula\u7684\u6fc0\u6d3b\u51fd\u6570\uff08Clayton\u3001Gumbel\u53ca\u5176\u7ec4\u5408\uff09\uff0c\u6784\u5efa\u542bcopula\u6fc0\u6d3b\u51fd\u6570\u7684CNN - LSTM\u6a21\u578b\u5904\u7406\u591a\u5143\u591a\u7c7b\u578b\u751f\u5b58\u54cd\u5e94\u6570\u636e\uff0c\u7528Shewhart\u63a7\u5236\u56fe\u8bc4\u4f30\uff0c\u5173\u6ce8\u5e73\u5747\u8fd0\u884c\u957f\u5ea6\uff08ARL\uff09\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548c\u4e73\u817a\u764c\u771f\u5b9e\u6570\u636e\u5206\u6790\uff0c\u6a21\u578b\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u542bcopula\u6fc0\u6d3b\u51fd\u6570\u7684CNN - LSTM\u6a21\u578b\u80fd\u6709\u6548\u5904\u7406\u53f3\u5220\u5931\u6570\u636e\uff0c\u6355\u6349\u590d\u6742\u6a21\u5f0f\uff0c\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2507.15529", "pdf": "https://arxiv.org/pdf/2507.15529", "abs": "https://arxiv.org/abs/2507.15529", "authors": ["George Bissias"], "title": "Algorithms for Approximating Conditionally Optimal Bounds", "categories": ["stat.CO"], "comment": null, "summary": "This work develops algorithms for non-parametric confidence regions for\nsamples from a univariate distribution whose support is a discrete mesh bounded\non the left. We generalize the theory of Learned-Miller to preorders over the\nsample space. In this context, we show that the lexicographic low and\nlexicographic high orders are in some way extremal in the class of monotone\npreorders. From this theory we derive several approximation algorithms: 1)\nClosed form approximations for the lexicographic low and high orders with error\ntending to zero in the mesh size; 2) A polynomial-time approximation scheme for\nquantile orders with error tending to zero in the mesh size; 3) Monte Carlo\nmethods for calculating quantile and lexicographic low orders applicable to any\nmesh size.", "AI": {"tldr": "\u672c\u6587\u4e3a\u5355\u8fb9\u6709\u754c\u79bb\u6563\u7f51\u683c\u4e0a\u7684\u5355\u53d8\u91cf\u5206\u5e03\u6837\u672c\u5f00\u53d1\u975e\u53c2\u6570\u7f6e\u4fe1\u533a\u57df\u7b97\u6cd5\uff0c\u63a8\u5e7f\u7406\u8bba\u5e76\u7ed9\u51fa\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u5355\u8fb9\u6709\u754c\u79bb\u6563\u7f51\u683c\u4e0a\u7684\u5355\u53d8\u91cf\u5206\u5e03\u6837\u672c\u5f00\u53d1\u975e\u53c2\u6570\u7f6e\u4fe1\u533a\u57df\u7b97\u6cd5\u3002", "method": "\u5c06Learned - Miller\u7406\u8bba\u63a8\u5e7f\u5230\u6837\u672c\u7a7a\u95f4\u7684\u9884\u5e8f\uff0c\u5229\u7528\u5b57\u5178\u5e8f\u4f4e\u548c\u9ad8\u5e8f\u7684\u7279\u6027\u63a8\u5bfc\u7b97\u6cd5\uff0c\u5305\u62ec\u95ed\u5f62\u5f0f\u8fd1\u4f3c\u3001\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\u548c\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u3002", "result": "\u5f97\u5230\u4e09\u79cd\u8fd1\u4f3c\u7b97\u6cd5\uff1a\u5b57\u5178\u5e8f\u4f4e\u548c\u9ad8\u5e8f\u7684\u95ed\u5f62\u5f0f\u8fd1\u4f3c\u3001\u5206\u4f4d\u6570\u5e8f\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\u3001\u9002\u7528\u4e8e\u4efb\u610f\u7f51\u683c\u5927\u5c0f\u7684\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u63a8\u5e7f\u7406\u8bba\u6210\u529f\u5f00\u53d1\u51fa\u591a\u79cd\u8fd1\u4f3c\u7b97\u6cd5\u7528\u4e8e\u8ba1\u7b97\u975e\u53c2\u6570\u7f6e\u4fe1\u533a\u57df\u3002"}}
{"id": "2507.14835", "pdf": "https://arxiv.org/pdf/2507.14835", "abs": "https://arxiv.org/abs/2507.14835", "authors": ["Pan Peng", "Hangyu Xu"], "title": "Differentially Private Synthetic Graphs Preserving Triangle-Motif Cuts", "categories": ["cs.DS", "cs.LG"], "comment": "COLT 2025", "summary": "We study the problem of releasing a differentially private (DP) synthetic\ngraph $G'$ that well approximates the triangle-motif sizes of all cuts of any\ngiven graph $G$, where a motif in general refers to a frequently occurring\nsubgraph within complex networks. Non-private versions of such graphs have\nfound applications in diverse fields such as graph clustering, graph\nsparsification, and social network analysis. Specifically, we present the first\n$(\\varepsilon,\\delta)$-DP mechanism that, given an input graph $G$ with $n$\nvertices, $m$ edges and local sensitivity of triangles $\\ell_{3}(G)$, generates\na synthetic graph $G'$ in polynomial time, approximating the triangle-motif\nsizes of all cuts $(S,V\\setminus S)$ of the input graph $G$ up to an additive\nerror of $\\tilde{O}(\\sqrt{m\\ell_{3}(G)}n/\\varepsilon^{3/2})$. Additionally, we\nprovide a lower bound of $\\Omega(\\sqrt{mn}\\ell_{3}(G)/\\varepsilon)$ on the\nadditive error for any DP algorithm that answers the triangle-motif size\nqueries of all $(S,T)$-cut of $G$. Finally, our algorithm generalizes to\nweighted graphs, and our lower bound extends to any $K_h$-motif cut for any\nconstant $h\\geq 2$.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a(\u03b5,\u03b4)-DP\u673a\u5236\u751f\u6210\u5408\u6210\u56fe\u8fd1\u4f3c\u7ed9\u5b9a\u56fe\u6240\u6709\u5272\u7684\u4e09\u89d2\u5f62 motif \u5927\u5c0f\uff0c\u7ed9\u51fa\u8bef\u5dee\u4e0b\u754c\uff0c\u7b97\u6cd5\u53ef\u63a8\u5e7f\u5230\u52a0\u6743\u56fe\uff0c\u4e0b\u754c\u53ef\u6269\u5c55\u5230 K_h - motif \u5272\u3002", "motivation": "\u7814\u7a76\u53d1\u5e03\u5dee\u5206\u9690\u79c1\u5408\u6210\u56fe\u4ee5\u8fd1\u4f3c\u7ed9\u5b9a\u56fe\u6240\u6709\u5272\u7684\u4e09\u89d2\u5f62 motif \u5927\u5c0f\u95ee\u9898\uff0c\u975e\u9690\u79c1\u7248\u672c\u56fe\u5728\u591a\u9886\u57df\u6709\u5e94\u7528\u3002", "method": "\u63d0\u51fa(\u03b5,\u03b4)-DP\u673a\u5236\uff0c\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u751f\u6210\u5408\u6210\u56fe\uff0c\u8fd1\u4f3c\u4e09\u89d2\u5f62 motif \u5927\u5c0f\u3002", "result": "\u751f\u6210\u7684\u5408\u6210\u56fe\u8fd1\u4f3c\u8bef\u5dee\u4e3a ~O(\u221a(m\u2113\u2083(G))n/\u03b5\u00b3/\u00b2)\uff0c\u7ed9\u51fa\u8bef\u5dee\u4e0b\u754c \u03a9(\u221a(mn)\u2113\u2083(G)/\u03b5)\uff0c\u7b97\u6cd5\u548c\u4e0b\u754c\u53ef\u63a8\u5e7f\u3002", "conclusion": "\u63d0\u51fa\u7684\u673a\u5236\u6709\u6548\u89e3\u51b3\u95ee\u9898\uff0c\u7ed9\u51fa\u8bef\u5dee\u4e0b\u754c\uff0c\u4e14\u5177\u6709\u4e00\u5b9a\u6269\u5c55\u6027\u3002"}}
{"id": "2507.14682", "pdf": "https://arxiv.org/pdf/2507.14682", "abs": "https://arxiv.org/abs/2507.14682", "authors": ["Massimo Cafaro", "Italo Epicoco", "Marco Pulimeno", "Lunodzo J. Mwinuka", "Lucas Pereira", "Hugo Morais"], "title": "IDSS, a Novel P2P Relational Data Storage Service", "categories": ["cs.DB", "cs.DC"], "comment": null, "summary": "The rate at which data is generated has been increasing rapidly, raising\nchallenges related to its management. Traditional database management systems\nsuffer from scalability and are usually inefficient when dealing with\nlarge-scale and heterogeneous data. This paper introduces IDSS (InnoCyPES Data\nStorage Service), a novel large-scale data storage tool that leverages\npeer-to-peer networks and embedded relational databases. We present the IDSS\narchitecture and its design, and provide details related to the implementation.\nThe peer-to-peer framework is used to provide support for distributed queries\nleveraging a relational database architecture based on a common schema.\nFurthermore, methods to support complex distributed query processing, enabling\nrobust and efficient management of vast amounts of data are presented.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u65b0\u578b\u5927\u89c4\u6a21\u6570\u636e\u5b58\u50a8\u5de5\u5177 IDSS\uff0c\u9610\u8ff0\u5176\u67b6\u6784\u3001\u8bbe\u8ba1\u548c\u5b9e\u73b0\u7ec6\u8282\uff0c\u63d0\u4f9b\u652f\u6301\u5206\u5e03\u5f0f\u67e5\u8be2\u548c\u590d\u6742\u5206\u5e03\u5f0f\u67e5\u8be2\u5904\u7406\u7684\u65b9\u6cd5\u3002", "motivation": "\u6570\u636e\u751f\u6210\u901f\u7387\u5feb\u901f\u589e\u957f\uff0c\u4f20\u7edf\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u5728\u5904\u7406\u5927\u89c4\u6a21\u548c\u5f02\u6784\u6570\u636e\u65f6\u5b58\u5728\u53ef\u6269\u5c55\u6027\u95ee\u9898\u4e14\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5f15\u5165 IDSS\uff0c\u5229\u7528\u5bf9\u7b49\u7f51\u7edc\u548c\u5d4c\u5165\u5f0f\u5173\u7cfb\u6570\u636e\u5e93\uff0c\u57fa\u4e8e\u516c\u5171\u6a21\u5f0f\u7684\u5173\u7cfb\u6570\u636e\u5e93\u67b6\u6784\u652f\u6301\u5206\u5e03\u5f0f\u67e5\u8be2\uff0c\u63d0\u4f9b\u652f\u6301\u590d\u6742\u5206\u5e03\u5f0f\u67e5\u8be2\u5904\u7406\u7684\u65b9\u6cd5\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2507.15753", "pdf": "https://arxiv.org/pdf/2507.15753", "abs": "https://arxiv.org/abs/2507.15753", "authors": ["Li Zheng", "Siddhant Kumar", "Dennis M. Kochmann"], "title": "DiffuMeta: Algebraic Language Models for Inverse Design of Metamaterials via Diffusion Transformers", "categories": ["cs.CE", "cs.AI"], "comment": null, "summary": "Generative machine learning models have revolutionized material discovery by\ncapturing complex structure-property relationships, yet extending these\napproaches to the inverse design of three-dimensional metamaterials remains\nlimited by computational complexity and underexplored design spaces due to the\nlack of expressive representations. Here, we present DiffuMeta, a generative\nframework integrating diffusion transformers with a novel algebraic language\nrepresentation, encoding 3D geometries as mathematical sentences. This compact,\nunified parameterization spans diverse topologies while enabling direct\napplication of transformers to structural design. DiffuMeta leverages diffusion\nmodels to generate novel shell structures with precisely targeted stress-strain\nresponses under large deformations, accounting for buckling and contact while\naddressing the inherent one-to-many mapping by producing diverse solutions.\nUniquely, our approach enables simultaneous control over multiple mechanical\nobjectives, including linear and nonlinear responses beyond training domains.\nExperimental validation of fabricated structures further confirms the efficacy\nof our approach for accelerated design of metamaterials and structures with\ntailored properties.", "AI": {"tldr": "\u63d0\u51faDiffuMeta\u751f\u6210\u6846\u67b6\u7528\u4e8e\u4e09\u7ef4\u8d85\u6750\u6599\u9006\u8bbe\u8ba1\uff0c\u53ef\u751f\u6210\u6709\u7279\u5b9a\u5e94\u529b - \u5e94\u53d8\u54cd\u5e94\u7684\u58f3\u7ed3\u6784\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u4e09\u7ef4\u8d85\u6750\u6599\u9006\u8bbe\u8ba1\u53d7\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u4e0d\u8db3\u9650\u5236\uff0c\u7f3a\u4e4f\u8868\u8fbe\u6027\u8868\u793a\u3002", "method": "\u63d0\u51faDiffuMeta\u6846\u67b6\uff0c\u96c6\u6210\u6269\u6563\u53d8\u538b\u5668\u548c\u65b0\u578b\u4ee3\u6570\u8bed\u8a00\u8868\u793a\uff0c\u5c063D\u51e0\u4f55\u7f16\u7801\u4e3a\u6570\u5b66\u53e5\u5b50\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u58f3\u7ed3\u6784\u3002", "result": "\u80fd\u751f\u6210\u6709\u7cbe\u786e\u76ee\u6807\u5e94\u529b - \u5e94\u53d8\u54cd\u5e94\u7684\u58f3\u7ed3\u6784\uff0c\u53ef\u540c\u65f6\u63a7\u5236\u591a\u4e2a\u673a\u68b0\u76ee\u6807\uff0c\u751f\u6210\u591a\u6837\u89e3\u3002", "conclusion": "\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u5bf9\u52a0\u901f\u8bbe\u8ba1\u6709\u5b9a\u5236\u5c5e\u6027\u7684\u8d85\u6750\u6599\u548c\u7ed3\u6784\u6709\u6548\u3002"}}
{"id": "2507.15615", "pdf": "https://arxiv.org/pdf/2507.15615", "abs": "https://arxiv.org/abs/2507.15615", "authors": ["Zhihao Zhang", "Siyuan Li", "Chenxi Li", "Feifan Liu", "Mengjing Chen", "Kai Li", "Tao Zhong", "Bo An", "Peng Liu"], "title": "DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving", "categories": ["cs.NE"], "comment": null, "summary": "Primal heuristics play a critical role in improving the efficiency of mixed\ninteger programming (MILP) solvers. As large language models (LLMs) have\ndemonstrated superior code generation abilities, recent MILP works are devoted\nto leveraging the evolutionary computation approaches with LLMs to generate\neffective primal heuristics. Although the generated heuristics have achieved\nbetter solving performance than the hand-crafted ones with little adaptability,\nthe advantage of current LLM-based methods is limited to few MILP instances in\none problem class, as they fail to capture the instance characteristics in the\nproblem class (the MILP instances generated from the same mathematical model\nare defined as a problem class). Since MILP instances often differ\nsignificantly in structure and feature distribution, the neglect of their\ncharacteristics in the evolution process results in poor generalization within\nthe same problem class. To overcome this challenge, we propose a data-algorithm\nco-evolution framework (DHEvo) that iteratively selects representative\ninstances and evolves corresponding heuristics. With the initial instance\ndistribution, we develop an LLM-based multi-agent system to generate data-code\npairs simultaneously. These data-code pairs are iteratively refined based on\ntheir fitness scores, leading to the identification of the most effective\nheuristic over the entire problem class. Extensive experiments across diverse\nMILP benchmarks demonstrate that our approach significantly outperforms both\nhuman-designed heuristics and existing LLM-based methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6570\u636e - \u7b97\u6cd5\u534f\u540c\u8fdb\u5316\u6846\u67b6DHEvo\u751f\u6210MILP\u539f\u542f\u53d1\u5f0f\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u548c\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684MILP\u539f\u542f\u53d1\u5f0f\u751f\u6210\u65b9\u6cd5\u5728\u540c\u4e00\u95ee\u9898\u7c7b\u4e2d\u6cdb\u5316\u6027\u5dee\uff0c\u672a\u6355\u6349\u5b9e\u4f8b\u7279\u5f81\u3002", "method": "\u63d0\u51faDHEvo\u6846\u67b6\uff0c\u7528\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u6570\u636e - \u4ee3\u7801\u5bf9\u5e76\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u591a\u4e2aMILP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDHEvo\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u548c\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u3002", "conclusion": "DHEvo\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347MILP\u6c42\u89e3\u539f\u542f\u53d1\u5f0f\u7684\u6027\u80fd\u548c\u6cdb\u5316\u6027\u3002"}}
{"id": "2507.14802", "pdf": "https://arxiv.org/pdf/2507.14802", "abs": "https://arxiv.org/abs/2507.14802", "authors": ["Ziming Dai", "Chao Qiu", "Fei Gao", "Yunfeng Zhao", "Xiaofei Wang"], "title": "ACME: Adaptive Customization of Large Models via Distributed Systems", "categories": ["cs.DC", "cs.AI", "C.2.4; I.2.6"], "comment": "Accepted to IEEE ICDCS 2025. 11 pages, 13 figures", "summary": "Pre-trained Transformer-based large models have revolutionized personal\nvirtual assistants, but their deployment in cloud environments faces challenges\nrelated to data privacy and response latency. Deploying large models closer to\nthe data and users has become a key research area to address these issues.\nHowever, applying these models directly often entails significant difficulties,\nsuch as model mismatching, resource constraints, and energy inefficiency.\nAutomated design of customized models is necessary, but it faces three key\nchallenges, namely, the high cost of centralized model customization,\nimbalanced performance from user heterogeneity, and suboptimal performance from\ndata heterogeneity. In this paper, we propose ACME, an adaptive customization\napproach of Transformer-based large models via distributed systems. To avoid\nthe low cost-efficiency of centralized methods, ACME employs a bidirectional\nsingle-loop distributed system to progressively achieve fine-grained\ncollaborative model customization. In order to better match user heterogeneity,\nit begins by customizing the backbone generation and identifying the Pareto\nFront under model size constraints to ensure optimal resource utilization.\nSubsequently, it performs header generation and refines the model using data\ndistribution-based personalized architecture aggregation to match data\nheterogeneity. Evaluation on different datasets shows that ACME achieves\ncost-efficient models under model size constraints. Compared to centralized\nsystems, data transmission volume is reduced to 6 percent. Additionally, the\naverage accuracy improves by 10 percent compared to the baseline, with the\ntrade-off metrics increasing by nearly 30 percent.", "AI": {"tldr": "\u9488\u5bf9\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u90e8\u7f72\u95ee\u9898\u63d0\u51faACME\u65b9\u6cd5\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6709\u6210\u672c\u6548\u76ca\u3001\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u3001\u63d0\u5347\u51c6\u786e\u7387\u548c\u6743\u8861\u6307\u6807\u3002", "motivation": "\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u5728\u4e91\u73af\u5883\u90e8\u7f72\u9762\u4e34\u6570\u636e\u9690\u79c1\u548c\u54cd\u5e94\u5ef6\u8fdf\u95ee\u9898\uff0c\u76f4\u63a5\u5e94\u7528\u6709\u56f0\u96be\uff0c\u81ea\u52a8\u5b9a\u5236\u6a21\u578b\u4e5f\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51faACME\uff0c\u91c7\u7528\u53cc\u5411\u5355\u73af\u5206\u5e03\u5f0f\u7cfb\u7edf\u9010\u6b65\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u534f\u4f5c\u6a21\u578b\u5b9a\u5236\uff0c\u5148\u5b9a\u5236\u9aa8\u5e72\u751f\u6210\uff0c\u540e\u8fdb\u884c\u5934\u90e8\u751f\u6210\u5e76\u5229\u7528\u57fa\u4e8e\u6570\u636e\u5206\u5e03\u7684\u4e2a\u6027\u5316\u67b6\u6784\u805a\u5408\u4f18\u5316\u6a21\u578b\u3002", "result": "\u5728\u4e0d\u540c\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\uff0c\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u6a21\u578b\uff0c\u6570\u636e\u4f20\u8f93\u91cf\u964d\u81f36%\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534710%\uff0c\u6743\u8861\u6307\u6807\u63d0\u5347\u8fd130%\u3002", "conclusion": "ACME\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5728\u6a21\u578b\u5927\u5c0f\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u5b9a\u5236\u3002"}}
{"id": "2507.14306", "pdf": "https://arxiv.org/pdf/2507.14306", "abs": "https://arxiv.org/abs/2507.14306", "authors": ["Samarth P", "Vyoman Jain", "Shiva Golugula", "Motamarri Sai Sathvik"], "title": "Manimator: Transforming Research Papers into Visual Explanations", "categories": ["cs.AI", "cs.MM"], "comment": null, "summary": "Understanding complex scientific and mathematical concepts, particularly\nthose presented in dense research papers, poses a significant challenge for\nlearners. Dynamic visualizations can greatly enhance comprehension, but\ncreating them manually is time-consuming and requires specialized knowledge and\nskills. We introduce manimator, an open-source system that leverages Large\nLanguage Models to transform research papers and natural language prompts into\nexplanatory animations using the Manim engine. Manimator employs a pipeline\nwhere an LLM interprets the input text or research paper PDF to generate a\nstructured scene description outlining key concepts, mathematical formulas, and\nvisual elements and another LLM translates this description into executable\nManim Python code. We discuss its potential as an educational tool for rapidly\ncreating engaging visual explanations for complex STEM topics, democratizing\nthe creation of high-quality educational content.", "AI": {"tldr": "\u4ecb\u7ecd\u5f00\u6e90\u7cfb\u7edfmanimator\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u7814\u7a76\u8bba\u6587\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u5316\u4e3a\u52a8\u753b\uff0c\u53ef\u7528\u4e8e\u5feb\u901f\u521b\u5efaSTEM\u4e3b\u9898\u89c6\u89c9\u89e3\u91ca\u3002", "motivation": "\u5b66\u4e60\u8005\u7406\u89e3\u590d\u6742\u79d1\u7814\u8bba\u6587\u6709\u6311\u6218\uff0c\u624b\u52a8\u521b\u5efa\u52a8\u6001\u53ef\u89c6\u5316\u8017\u65f6\u4e14\u9700\u4e13\u4e1a\u6280\u80fd\u3002", "method": "manimator\u91c7\u7528\u7ba1\u9053\uff0c\u4e00\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u8bfb\u8f93\u5165\u6587\u672c\u6216PDF\u751f\u6210\u573a\u666f\u63cf\u8ff0\uff0c\u53e6\u4e00\u4e2a\u5c06\u63cf\u8ff0\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684Manim Python\u4ee3\u7801\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c", "conclusion": "manimator\u6709\u6f5c\u529b\u4f5c\u4e3a\u6559\u80b2\u5de5\u5177\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u6559\u80b2\u5185\u5bb9\u521b\u5efa\u7684\u6c11\u4e3b\u5316\u3002"}}
{"id": "2507.14423", "pdf": "https://arxiv.org/pdf/2507.14423", "abs": "https://arxiv.org/abs/2507.14423", "authors": ["Mootez Saad", "Hao Li", "Tushar Sharma", "Ahmed E. Hassan"], "title": "On the Effect of Token Merging on Pre-trained Models for Code", "categories": ["cs.SE"], "comment": null, "summary": "Tokenization is a fundamental component of language models for code. It\ninvolves breaking down the input into units that are later passed to the\nlanguage model stack to learn high-dimensional representations used in various\ncontexts, from classification to generation. However, the output of these\ntokenizers is often longer than that traditionally used in compilers and\ninterpreters. This could result in undesirable effects, such as increased\ncomputational overhead. In this work, we investigate the effect of merging the\nhidden representations of subtokens that belong to the same semantic unit, such\nas subtokens that form a single identifier. We propose two strategies: one\nbased on averaging the representations and another that leverages a\nlearning-based approach. Both methods can be seamlessly integrated with\nexisting language models for code. We conduct experiments using six language\nmodels for code: CodeBERT, GraphCodeBERT, UniXCoder, CdoeT5, CodeT5+ (220M),\nand CodeT5+ (770M), across three software engineering tasks: vulnerability\ndetection, code classification, and code translation. Results show that these\nstrategies can reduce the number of floating-point operations by $1\\%$ to\n$19\\%$. Regarding downstream performance, the most significant degradation was\nobserved in the vulnerability detection task, where the F1 score decreased by\n$1.82$ points compared to the baseline. In contrast, for code translation, we\nobserved an improvement of $2.47$ points in CodeBLEU. This work contributes to\nthe broader effort of improving language models for code across multiple\ndimensions, including both computational efficiency and downstream performance.", "AI": {"tldr": "\u7814\u7a76\u5408\u5e76\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e2d\u5c5e\u4e8e\u540c\u4e00\u8bed\u4e49\u5355\u5143\u7684\u5b50\u6807\u8bb0\u7684\u9690\u85cf\u8868\u793a\u7684\u6548\u679c\uff0c\u63d0\u51fa\u4e24\u79cd\u7b56\u7565\uff0c\u5728\u516d\u4e2a\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u548c\u4e09\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u5b9e\u9a8c\uff0c\u80fd\u51cf\u5c11\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\uff0c\u4e0d\u540c\u4efb\u52a1\u6027\u80fd\u6709\u4e0d\u540c\u53d8\u5316\u3002", "motivation": "\u4ee3\u7801\u5206\u8bcd\u5668\u8f93\u51fa\u5e38\u957f\u4e8e\u4f20\u7edf\u7f16\u8bd1\u5668\u548c\u89e3\u91ca\u5668\uff0c\u4f1a\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\uff0c\u9700\u7814\u7a76\u5408\u5e76\u5b50\u6807\u8bb0\u9690\u85cf\u8868\u793a\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5e73\u5747\u8868\u793a\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u4e24\u79cd\u7b56\u7565\uff0c\u5e76\u4e0e\u73b0\u6709\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u5728\u516d\u4e2a\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u548c\u4e09\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u5b9e\u9a8c\u3002", "result": "\u7b56\u7565\u80fd\u51cf\u5c111% - 19%\u7684\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\uff0c\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1F1\u5206\u6570\u4e0b\u964d1.82\u70b9\uff0c\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1CodeBLEU\u63d0\u9ad82.47\u70b9\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6709\u52a9\u4e8e\u4ece\u8ba1\u7b97\u6548\u7387\u548c\u4e0b\u6e38\u6027\u80fd\u7b49\u591a\u7ef4\u5ea6\u6539\u8fdb\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2507.14604", "pdf": "https://arxiv.org/pdf/2507.14604", "abs": "https://arxiv.org/abs/2507.14604", "authors": ["Mathias Vast", "Basile Van Cooten", "Laure Soulier", "Benjamin Piwowarski"], "title": "Understanding Matching Mechanisms in Cross-Encoders", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted at Workshop on Explainability in Information Retrieval at\n  SIGIR 25 (WExIR25)", "summary": "Neural IR architectures, particularly cross-encoders, are highly effective\nmodels whose internal mechanisms are mostly unknown. Most works trying to\nexplain their behavior focused on high-level processes (e.g., what in the input\ninfluences the prediction, does the model adhere to known IR axioms) but fall\nshort of describing the matching process. Instead of Mechanistic\nInterpretability approaches which specifically aim at explaining the hidden\nmechanisms of neural models, we demonstrate that more straightforward methods\ncan already provide valuable insights. In this paper, we first focus on the\nattention process and extract causal insights highlighting the crucial roles of\nsome attention heads in this process. Second, we provide an interpretation of\nthe mechanism underlying matching detection.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u591a\u6570\u89e3\u91ca\u795e\u7ecfIR\u67b6\u6784\u884c\u4e3a\u7684\u5de5\u4f5c\u672a\u63cf\u8ff0\u5339\u914d\u8fc7\u7a0b\uff0c\u5c55\u793a\u66f4\u76f4\u63a5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u6709\u4ef7\u503c\u89c1\u89e3\uff0c\u8fd8\u805a\u7126\u6ce8\u610f\u529b\u8fc7\u7a0b\u548c\u5339\u914d\u68c0\u6d4b\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5927\u591a\u672a\u80fd\u63cf\u8ff0\u795e\u7ecfIR\u67b6\u6784\u7684\u5339\u914d\u8fc7\u7a0b\uff0c\u800c\u8981\u63a2\u7d22\u66f4\u76f4\u63a5\u7684\u65b9\u6cd5\u6765\u89e3\u91ca\u5176\u884c\u4e3a\u3002", "method": "\u5148\u805a\u7126\u6ce8\u610f\u529b\u8fc7\u7a0b\uff0c\u63d0\u53d6\u56e0\u679c\u89c1\u89e3\uff1b\u518d\u5bf9\u5339\u914d\u68c0\u6d4b\u7684\u6f5c\u5728\u673a\u5236\u8fdb\u884c\u89e3\u91ca\u3002", "result": "\u53d1\u73b0\u4e86\u4e00\u4e9b\u6ce8\u610f\u529b\u5934\u5728\u6ce8\u610f\u529b\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u5bf9\u5339\u914d\u68c0\u6d4b\u673a\u5236\u8fdb\u884c\u4e86\u89e3\u91ca\u3002", "conclusion": "\u66f4\u76f4\u63a5\u7684\u65b9\u6cd5\u53ef\u4ee5\u4e3a\u89e3\u91ca\u795e\u7ecfIR\u67b6\u6784\u7684\u884c\u4e3a\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.14970", "pdf": "https://arxiv.org/pdf/2507.14970", "abs": "https://arxiv.org/abs/2507.14970", "authors": ["Xinyu Li"], "title": "Mitigating Financial Frictions in Agriculture: A Framework for Stablecoin Adoption", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Persistent financial frictions - including price volatility, constrained\ncredit access, and supply chain inefficiencies - have long hindered\nproductivity and welfare in the global agricultural sector. This paper provides\na theoretical and applied analysis of how fiat-collateralized stablecoins, a\nclass of digital currency pegged to a stable asset like the U.S. dollar, can\naddress these long-standing challenges. We develop a farm-level profit\nmaximization model incorporating transaction costs and credit constraints to\ndemonstrate how stablecoins can enhance economic outcomes by (1) reducing the\ncosts and risks of cross-border trade, (2) improving the efficiency and\ntransparency of supply chain finance through smart contracts, and (3) expanding\naccess to credit for smallholder farmers. We analyze key use cases, including\nparametric insurance and trade finance, while also considering the significant\nhurdles to adoption, such as regulatory uncertainty and the digital divide. The\npaper concludes that while not a panacea, stablecoins represent a significant\nfinancial technology with the potential to catalyze a paradigm shift in\nagricultural economics, warranting further empirical investigation and policy\nsupport.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u6cd5\u5e01\u62b5\u62bc\u7a33\u5b9a\u5e01\u89e3\u51b3\u5168\u7403\u519c\u4e1a\u91d1\u878d\u6469\u64e6\u95ee\u9898\uff0c\u5efa\u6a21\u578b\u5c55\u793a\u5176\u4f18\u52bf\uff0c\u5206\u6790\u7528\u4f8b\u4e0e\u969c\u788d\uff0c\u8ba4\u4e3a\u867d\u975e\u4e07\u80fd\u4f46\u6709\u6f5c\u529b\u3002", "motivation": "\u5168\u7403\u519c\u4e1a\u957f\u671f\u53d7\u4ef7\u683c\u6ce2\u52a8\u3001\u4fe1\u8d37\u53d7\u9650\u548c\u4f9b\u5e94\u94fe\u4f4e\u6548\u7b49\u91d1\u878d\u6469\u64e6\u963b\u788d\uff0c\u9700\u5bfb\u627e\u89e3\u51b3\u529e\u6cd5\u3002", "method": "\u5efa\u7acb\u5305\u542b\u4ea4\u6613\u6210\u672c\u548c\u4fe1\u8d37\u7ea6\u675f\u7684\u519c\u573a\u5c42\u9762\u5229\u6da6\u6700\u5927\u5316\u6a21\u578b\uff0c\u5206\u6790\u5173\u952e\u7528\u4f8b\u5e76\u8003\u8651\u91c7\u7528\u969c\u788d\u3002", "result": "\u7a33\u5b9a\u5e01\u53ef\u964d\u4f4e\u8de8\u5883\u8d38\u6613\u6210\u672c\u548c\u98ce\u9669\u3001\u63d0\u9ad8\u4f9b\u5e94\u94fe\u91d1\u878d\u6548\u7387\u548c\u900f\u660e\u5ea6\u3001\u6269\u5927\u5c0f\u519c\u6237\u4fe1\u8d37\u6e20\u9053\u3002", "conclusion": "\u7a33\u5b9a\u5e01\u867d\u975e\u4e07\u80fd\uff0c\u4f46\u6709\u6f5c\u529b\u5f15\u53d1\u519c\u4e1a\u7ecf\u6d4e\u8303\u5f0f\u8f6c\u53d8\uff0c\u9700\u8fdb\u4e00\u6b65\u5b9e\u8bc1\u7814\u7a76\u548c\u653f\u7b56\u652f\u6301\u3002"}}
{"id": "2507.15325", "pdf": "https://arxiv.org/pdf/2507.15325", "abs": "https://arxiv.org/abs/2507.15325", "authors": ["Nicolas Lanzetti", "Sylvain Fricker", "Saverio Bolognani", "Florian D\u00f6rfler", "Dario Paccagnan"], "title": "Strategically Robust Game Theory via Optimal Transport", "categories": ["cs.GT", "math.OC"], "comment": null, "summary": "In many game-theoretic settings, agents are challenged with taking decisions\nagainst the uncertain behavior exhibited by others. Often, this uncertainty\narises from multiple sources, e.g., incomplete information, limited\ncomputation, bounded rationality. While it may be possible to guide the agents'\ndecisions by modeling each source, their joint presence makes this task\nparticularly daunting. Toward this goal, it is natural for agents to seek\nprotection against deviations around the emergent behavior itself, which is\nultimately impacted by all the above sources of uncertainty. To do so, we\npropose that each agent takes decisions in face of the worst-case behavior\ncontained in an ambiguity set of tunable size, centered at the emergent\nbehavior so implicitly defined. This gives rise to a novel equilibrium notion,\nwhich we call strategically robust equilibrium. Building on its definition, we\nshow that, when judiciously operationalized via optimal transport,\nstrategically robust equilibria (i) are guaranteed to exist under the same\nassumptions required for Nash equilibria; (ii) interpolate between Nash and\nsecurity strategies; (iii) come at no additional computational cost compared to\nNash equilibria. Through a variety of experiments, including bi-matrix games,\ncongestion games, and Cournot competition, we show that strategic robustness\nprotects against uncertainty in the opponents' behavior and, surprisingly,\noften results in higher equilibrium payoffs - an effect we refer to as\ncoordination via robustification.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u6218\u7565\u9c81\u68d2\u5747\u8861\u6982\u5ff5\uff0c\u8bc1\u660e\u5176\u5b58\u5728\u6027\u3001\u7279\u6027\u53ca\u8ba1\u7b97\u6210\u672c\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u5e94\u5bf9\u5bf9\u624b\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\u5e76\u5e38\u5e26\u6765\u66f4\u9ad8\u6536\u76ca\u3002", "motivation": "\u5728\u535a\u5f08\u8bba\u573a\u666f\u4e2d\uff0c\u591a\u79cd\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u4f7f\u5f15\u5bfc\u667a\u80fd\u4f53\u51b3\u7b56\u56f0\u96be\uff0c\u9700\u5bfb\u6c42\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u667a\u80fd\u4f53\u9762\u5bf9\u4ee5\u6d8c\u73b0\u884c\u4e3a\u4e3a\u4e2d\u5fc3\u3001\u53ef\u8c03\u8282\u5927\u5c0f\u7684\u6a21\u7cca\u96c6\u4e2d\u6700\u574f\u60c5\u51b5\u505a\u51b3\u7b56\uff0c\u5b9a\u4e49\u6218\u7565\u9c81\u68d2\u5747\u8861\uff0c\u901a\u8fc7\u6700\u4f18\u8fd0\u8f93\u5b9e\u73b0\u5e76\u5206\u6790\u5176\u6027\u8d28\u3002", "result": "\u6218\u7565\u9c81\u68d2\u5747\u8861\u5728\u4e0e\u7eb3\u4ec0\u5747\u8861\u76f8\u540c\u5047\u8bbe\u4e0b\u5b58\u5728\uff0c\u53ef\u5728\u7eb3\u4ec0\u548c\u5b89\u5168\u7b56\u7565\u95f4\u63d2\u503c\uff0c\u8ba1\u7b97\u6210\u672c\u65e0\u589e\u52a0\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u5e94\u5bf9\u5bf9\u624b\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\u4e14\u5e38\u5e26\u6765\u66f4\u9ad8\u6536\u76ca\u3002", "conclusion": "\u6218\u7565\u9c81\u68d2\u5747\u8861\u80fd\u6709\u6548\u5e94\u5bf9\u5bf9\u624b\u884c\u4e3a\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4e14\u80fd\u901a\u8fc7\u9c81\u68d2\u5316\u5b9e\u73b0\u534f\u8c03\uff0c\u5e26\u6765\u66f4\u9ad8\u5747\u8861\u6536\u76ca\u3002"}}
{"id": "2507.15382", "pdf": "https://arxiv.org/pdf/2507.15382", "abs": "https://arxiv.org/abs/2507.15382", "authors": ["Fabian Ihle", "Etienne Zink", "Michael Menth"], "title": "Enhancements to P4TG: Histogram-Based RTT Monitoring in the Data Plane", "categories": ["cs.NI", "cs.PF"], "comment": "This work has been published at the 1st Workshop on Resilient\n  Networks and Systems (ReNeSys), Sept. 2025, Ilmenau/Germany under the\n  Creative Commons Attribution 4.0 International License (CC BY 4.0)", "summary": "Modern traffic generators are essential tools for evaluating the performance\nof network environments. P4TG is a P4-based traffic generator implemented for\nIntel Tofino switches that offers high-speed packet generation with\nfine-grained measurement capabilities. However, P4TG samples time-based metrics\nsuch as the round-trip time (RTT) in the data plane and collects them at the\ncontroller. This leads to a reduced accuracy. In this paper, we introduce a\nhistogram-based RTT measurement feature for P4TG. It enables accurate analysis\nat line rate without sampling. Generally, histogram bins are modeled as ranges,\nand values are matched to a bin. Efficient packet matching in hardware is\ntypically achieved using ternary content addressable memory (TCAM). However,\nrepresenting range matching rules in TCAM poses a challenge. Therefore, we\nimplemented a range-to-prefix conversion algorithm that models range matching\nwith multiple ternary entries. This paper describes the data plane\nimplementation and runtime configuration of RTT histograms in P4TG. Further, we\ndiscuss the efficiency of the ternary decomposition. Our evaluation\ndemonstrates the applicability of the histogram-based RTT analysis by comparing\nthe measured values with a configured theoretical distribution of RTTs.", "AI": {"tldr": "\u5f15\u5165\u57fa\u4e8e\u76f4\u65b9\u56fe\u7684RTT\u6d4b\u91cf\u529f\u80fd\u6539\u8fdbP4TG\uff0c\u5b9e\u73b0\u65e0\u91c7\u6837\u7ebf\u901f\u7cbe\u786e\u5206\u6790\uff0c\u4ecb\u7ecd\u5b9e\u73b0\u4e0e\u914d\u7f6e\u5e76\u8bc4\u4f30\u9002\u7528\u6027\u3002", "motivation": "P4TG\u5728\u6570\u636e\u5e73\u9762\u91c7\u6837\u65f6\u95f4\u76f8\u5173\u6307\u6807\u5e76\u5728\u63a7\u5236\u5668\u6536\u96c6\uff0c\u5bfc\u81f4\u7cbe\u5ea6\u964d\u4f4e\uff0c\u9700\u8981\u6539\u8fdbRTT\u6d4b\u91cf\u65b9\u6cd5\u3002", "method": "\u4e3aP4TG\u5f15\u5165\u57fa\u4e8e\u76f4\u65b9\u56fe\u7684RTT\u6d4b\u91cf\u529f\u80fd\uff0c\u5b9e\u73b0\u8303\u56f4\u5230\u524d\u7f00\u7684\u8f6c\u6362\u7b97\u6cd5\uff0c\u7528\u591a\u4e2a\u4e09\u5143\u6761\u76ee\u8fdb\u884c\u8303\u56f4\u5339\u914d\u3002", "result": "\u901a\u8fc7\u5c06\u6d4b\u91cf\u503c\u4e0e\u914d\u7f6e\u7684RTT\u7406\u8bba\u5206\u5e03\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u76f4\u65b9\u56fe\u7684RTT\u5206\u6790\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u76f4\u65b9\u56fe\u7684RTT\u6d4b\u91cf\u529f\u80fd\u80fd\u6709\u6548\u63d0\u5347P4TG\u7684RTT\u6d4b\u91cf\u7cbe\u5ea6\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.14175", "pdf": "https://arxiv.org/pdf/2507.14175", "abs": "https://arxiv.org/abs/2507.14175", "authors": ["Youcef Barkat", "Dylan Hamitouche", "Deven Parekh", "Ivy Guo", "David Benrimoh"], "title": "Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "Background: Mental illnesses such as depression and anxiety require improved\nmethods for early detection and personalized intervention. Traditional\npredictive models often rely on unimodal data or early fusion strategies that\nfail to capture the complex, multimodal nature of psychiatric data. Advanced\nintegration techniques, such as intermediate (latent space) fusion, may offer\nbetter accuracy and clinical utility. Methods: Using data from the BRIGHTEN\nclinical trial, we evaluated intermediate (latent space) fusion for predicting\ndaily depressive symptoms (PHQ-2 scores). We compared early fusion implemented\nwith a Random Forest (RF) model and intermediate fusion implemented via a\nCombined Model (CM) using autoencoders and a neural network. The dataset\nincluded behavioral (smartphone-based), demographic, and clinical features.\nExperiments were conducted across multiple temporal splits and data stream\ncombinations. Performance was evaluated using mean squared error (MSE) and\ncoefficient of determination (R2). Results: The CM outperformed both RF and\nLinear Regression (LR) baselines across all setups, achieving lower MSE (0.4985\nvs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed\nsigns of overfitting, with a large gap between training and test performance,\nwhile the CM maintained consistent generalization. Performance was best when\nintegrating all data modalities in the CM (in contradistinction to RF),\nunderscoring the value of latent space fusion for capturing non-linear\ninteractions in complex psychiatric datasets. Conclusion: Latent space fusion\noffers a robust alternative to traditional fusion methods for prediction with\nmultimodal mental health data. Future work should explore model\ninterpretability and individual-level prediction for clinical deployment.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e2d\u95f4\uff08\u6f5c\u7a7a\u95f4\uff09\u878d\u5408\u9884\u6d4b\u6bcf\u65e5\u6291\u90c1\u75c7\u72b6\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u672a\u6765\u5e94\u63a2\u7d22\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u4e2a\u4f53\u5c42\u9762\u9884\u6d4b\u3002", "motivation": "\u4f20\u7edf\u9884\u6d4b\u6a21\u578b\u96be\u4ee5\u6355\u6349\u7cbe\u795e\u79d1\u6570\u636e\u7684\u591a\u6a21\u6001\u7279\u6027\uff0c\u9700\u8981\u6539\u8fdb\u65e9\u671f\u68c0\u6d4b\u548c\u4e2a\u6027\u5316\u5e72\u9884\u65b9\u6cd5\uff0c\u9ad8\u7ea7\u878d\u5408\u6280\u672f\u53ef\u80fd\u66f4\u51c6\u786e\u4e14\u5177\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "method": "\u5229\u7528BRIGHTEN\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\uff0c\u6bd4\u8f83\u968f\u673a\u68ee\u6797\uff08RF\uff09\u6a21\u578b\u7684\u65e9\u671f\u878d\u5408\u548c\u901a\u8fc7\u81ea\u7f16\u7801\u5668\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u7ec4\u5408\u6a21\u578b\uff08CM\uff09\u7684\u4e2d\u95f4\u878d\u5408\uff0c\u8bc4\u4f30\u4e0d\u540c\u65f6\u95f4\u5206\u5272\u548c\u6570\u636e\u6d41\u7ec4\u5408\u4e0b\u7684\u8868\u73b0\u3002", "result": "CM\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u5747\u4f18\u4e8eRF\u548c\u7ebf\u6027\u56de\u5f52\uff08LR\uff09\u57fa\u7ebf\uff0cMSE\u66f4\u4f4e\u3001R2\u66f4\u9ad8\uff0cRF\u6709\u8fc7\u62df\u5408\u8ff9\u8c61\uff0cCM\u6cdb\u5316\u80fd\u529b\u4e00\u81f4\uff0c\u6574\u5408\u6240\u6709\u6570\u636e\u6a21\u6001\u65f6CM\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u6f5c\u7a7a\u95f4\u878d\u5408\u662f\u591a\u6a21\u6001\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u9884\u6d4b\u4e2d\u4f20\u7edf\u878d\u5408\u65b9\u6cd5\u7684\u6709\u529b\u66ff\u4ee3\u65b9\u6848\uff0c\u672a\u6765\u5e94\u63a2\u7d22\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u4e2a\u4f53\u5c42\u9762\u9884\u6d4b\u4ee5\u7528\u4e8e\u4e34\u5e8a\u90e8\u7f72\u3002"}}
{"id": "2507.14652", "pdf": "https://arxiv.org/pdf/2507.14652", "abs": "https://arxiv.org/abs/2507.14652", "authors": ["Ponkrshnan Thiagarajan", "Tamer A. Zaki", "Michael D. Shields"], "title": "Accelerating Hamiltonian Monte Carlo for Bayesian Inference in Neural Networks and Neural Operators", "categories": ["stat.ML", "cs.CE", "cs.LG", "physics.data-an"], "comment": null, "summary": "Hamiltonian Monte Carlo (HMC) is a powerful and accurate method to sample\nfrom the posterior distribution in Bayesian inference. However, HMC techniques\nare computationally demanding for Bayesian neural networks due to the high\ndimensionality of the network's parameter space and the non-convexity of their\nposterior distributions. Therefore, various approximation techniques, such as\nvariational inference (VI) or stochastic gradient MCMC, are often employed to\ninfer the posterior distribution of the network parameters. Such approximations\nintroduce inaccuracies in the inferred distributions, resulting in unreliable\nuncertainty estimates. In this work, we propose a hybrid approach that combines\ninexpensive VI and accurate HMC methods to efficiently and accurately quantify\nuncertainties in neural networks and neural operators. The proposed approach\nleverages an initial VI training on the full network. We examine the influence\nof individual parameters on the prediction uncertainty, which shows that a\nlarge proportion of the parameters do not contribute substantially to\nuncertainty in the network predictions. This information is then used to\nsignificantly reduce the dimension of the parameter space, and HMC is performed\nonly for the subset of network parameters that strongly influence prediction\nuncertainties. This yields a framework for accelerating the full batch HMC for\nposterior inference in neural networks. We demonstrate the efficiency and\naccuracy of the proposed framework on deep neural networks and operator\nnetworks, showing that inference can be performed for large networks with tens\nto hundreds of thousands of parameters. We show that this method can\neffectively learn surrogates for complex physical systems by modeling the\noperator that maps from upstream conditions to wall-pressure data on a cone in\nhypersonic flow.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u53d8\u5206\u63a8\u65ad\uff08VI\uff09\u548c\u54c8\u5bc6\u987f\u8499\u7279\u5361\u7f57\uff08HMC\uff09\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u51cf\u5c11\u53c2\u6570\u7a7a\u95f4\u7ef4\u5ea6\uff0c\u52a0\u901f\u795e\u7ecf\u7f51\u7edc\u540e\u9a8c\u63a8\u65ad\uff0c\u5728\u5927\u578b\u7f51\u7edc\u4e0a\u9a8c\u8bc1\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "HMC\u7528\u4e8e\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u8981\u6c42\u9ad8\uff0c\u73b0\u6709\u8fd1\u4f3c\u6280\u672f\u6709\u8bef\u5dee\uff0c\u5bfc\u81f4\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0d\u53ef\u9760\u3002", "method": "\u5148\u8fdb\u884c\u5168\u7f51\u7edc\u7684VI\u8bad\u7ec3\uff0c\u5206\u6790\u53c2\u6570\u5bf9\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u51cf\u5c11\u53c2\u6570\u7a7a\u95f4\u7ef4\u5ea6\uff0c\u4ec5\u5bf9\u5f71\u54cd\u5927\u7684\u53c2\u6570\u5b50\u96c6\u8fdb\u884cHMC\u3002", "result": "\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u7b97\u5b50\u7f51\u7edc\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u80fd\u5bf9\u5927\u91cf\u53c2\u6570\u7684\u5927\u578b\u7f51\u7edc\u8fdb\u884c\u63a8\u65ad\uff0c\u53ef\u6709\u6548\u5b66\u4e60\u590d\u6742\u7269\u7406\u7cfb\u7edf\u7684\u66ff\u4ee3\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u6df7\u5408\u65b9\u6cd5\u80fd\u9ad8\u6548\u51c6\u786e\u5730\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u548c\u795e\u7ecf\u7b97\u5b50\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u52a0\u901f\u5168\u6279\u91cfHMC\u7684\u540e\u9a8c\u63a8\u65ad\u3002"}}
{"id": "2507.14176", "pdf": "https://arxiv.org/pdf/2507.14176", "abs": "https://arxiv.org/abs/2507.14176", "authors": ["Andr\u00e9s Morales-Forero", "Lili J. Rueda", "Ronald Herrera", "Samuel Bassetto", "Eric Coatanea"], "title": "Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection", "categories": ["cs.LG", "stat.CO", "stat.ML"], "comment": null, "summary": "Artificial intelligence (AI) systems increasingly inform medical\ndecision-making, yet concerns about algorithmic bias and inequitable outcomes\npersist, particularly for historically marginalized populations. This paper\nintroduces the concept of Predictive Representativity (PR), a framework of\nfairness auditing that shifts the focus from the composition of the data set to\noutcomes-level equity. Through a case study in dermatology, we evaluated\nAI-based skin cancer classifiers trained on the widely used HAM10000 dataset\nand on an independent clinical dataset (BOSQUE Test set) from Colombia. Our\nanalysis reveals substantial performance disparities by skin phototype, with\nclassifiers consistently underperforming for individuals with darker skin,\ndespite proportional sampling in the source data. We argue that\nrepresentativity must be understood not as a static feature of datasets but as\na dynamic, context-sensitive property of model predictions. PR operationalizes\nthis shift by quantifying how reliably models generalize fairness across\nsubpopulations and deployment contexts. We further propose an External\nTransportability Criterion that formalizes the thresholds for fairness\ngeneralization. Our findings highlight the ethical imperative for post-hoc\nfairness auditing, transparency in dataset documentation, and inclusive model\nvalidation pipelines. This work offers a scalable tool for diagnosing\nstructural inequities in AI systems, contributing to discussions on equity,\ninterpretability, and data justice and fostering a critical re-evaluation of\nfairness in data-driven healthcare.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u9884\u6d4b\u4ee3\u8868\u6027\uff08PR\uff09\u6982\u5ff5\u7528\u4e8e\u516c\u5e73\u6027\u5ba1\u8ba1\uff0c\u901a\u8fc7\u76ae\u80a4\u79d1\u6848\u4f8b\u7814\u7a76\u53d1\u73b0AI\u76ae\u80a4\u764c\u5206\u7c7b\u5668\u5b58\u5728\u6309\u76ae\u80a4\u7c7b\u578b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u63d0\u51fa\u5916\u90e8\u53ef\u8fc1\u79fb\u6027\u6807\u51c6\uff0c\u5f3a\u8c03\u4e8b\u540e\u516c\u5e73\u6027\u5ba1\u8ba1\u7b49\u91cd\u8981\u6027\u3002", "motivation": "\u89e3\u51b3AI\u7cfb\u7edf\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u5b58\u5728\u7684\u7b97\u6cd5\u504f\u5dee\u548c\u4e0d\u516c\u5e73\u7ed3\u679c\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5386\u53f2\u4e0a\u88ab\u8fb9\u7f18\u5316\u7fa4\u4f53\u3002", "method": "\u5f15\u5165Predictive Representativity\uff08PR\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u76ae\u80a4\u79d1\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u57fa\u4e8eAI\u7684\u76ae\u80a4\u764c\u5206\u7c7b\u5668\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5206\u6790\u63ed\u793aAI\u76ae\u80a4\u764c\u5206\u7c7b\u5668\u6309\u76ae\u80a4\u5149\u578b\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u5f02\uff0c\u6df1\u8272\u76ae\u80a4\u4e2a\u4f53\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u5f3a\u8c03\u4e8b\u540e\u516c\u5e73\u6027\u5ba1\u8ba1\u3001\u6570\u636e\u96c6\u6587\u6863\u900f\u660e\u548c\u5305\u5bb9\u6027\u6a21\u578b\u9a8c\u8bc1\u7ba1\u9053\u7684\u4f26\u7406\u5fc5\u8981\u6027\uff0c\u63d0\u4f9b\u8bca\u65adAI\u7cfb\u7edf\u7ed3\u6784\u4e0d\u5e73\u7b49\u7684\u53ef\u6269\u5c55\u5de5\u5177\u3002"}}
{"id": "2507.15282", "pdf": "https://arxiv.org/pdf/2507.15282", "abs": "https://arxiv.org/abs/2507.15282", "authors": ["Aqsa Ashraf Makhdomi", "Iqra Altaf Gillani"], "title": "Predict, Reposition, and Allocate: A Greedy and Flow-Based Architecture for Sustainable Urban Food Delivery", "categories": ["cs.DS"], "comment": null, "summary": "The rapid proliferation of food delivery platforms has reshaped urban\nmobility but has also contributed significantly to environmental degradation\nthrough increased greenhouse gas emissions. Existing optimization mechanisms\nproduce sub-optimal outcomes as they do not consider environmental\nsustainability their optimization objective. This study proposes a novel\neco-friendly food delivery optimization framework that integrates demand\nprediction, delivery person routing, and order allocation to minimize\nenvironmental impact while maintaining service efficiency. Since recommending\nroutes is NP-Hard, the proposed approach utilizes the submodular and monotone\nproperties of the objective function and designs an efficient greedy\noptimization algorithm. Thereafter, it formulates order allocation problem as a\nnetwork flow optimization model, which, to the best of our knowledge, has not\nbeen explored in the context of food delivery. A three-layered network\narchitecture is designed to match orders with delivery personnel based on\ncapacity constraints and spatial demand. Through this framework, the proposed\napproach reduces the vehicle count, and creates a sustainable food delivery\necosystem.", "AI": {"tldr": "\u63d0\u51fa\u73af\u4fdd\u5916\u5356\u914d\u9001\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528\u8d2a\u5fc3\u7b97\u6cd5\u548c\u7f51\u7edc\u6d41\u6a21\u578b\uff0c\u51cf\u5c11\u8f66\u8f86\u4f7f\u7528\uff0c\u6784\u5efa\u53ef\u6301\u7eed\u914d\u9001\u751f\u6001\u3002", "motivation": "\u5916\u5356\u5e73\u53f0\u589e\u52a0\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\uff0c\u73b0\u6709\u4f18\u5316\u673a\u5236\u672a\u8003\u8651\u73af\u5883\u53ef\u6301\u7eed\u6027\u3002", "method": "\u5229\u7528\u76ee\u6807\u51fd\u6570\u7279\u6027\u8bbe\u8ba1\u8d2a\u5fc3\u4f18\u5316\u7b97\u6cd5\uff0c\u5c06\u8ba2\u5355\u5206\u914d\u95ee\u9898\u6784\u5efa\u4e3a\u7f51\u7edc\u6d41\u4f18\u5316\u6a21\u578b\uff0c\u8bbe\u8ba1\u4e09\u5c42\u7f51\u7edc\u67b6\u6784\u5339\u914d\u8ba2\u5355\u548c\u914d\u9001\u4eba\u5458\u3002", "result": "\u51cf\u5c11\u4e86\u8f66\u8f86\u6570\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6784\u5efa\u53ef\u6301\u7eed\u7684\u5916\u5356\u914d\u9001\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2507.15787", "pdf": "https://arxiv.org/pdf/2507.15787", "abs": "https://arxiv.org/abs/2507.15787", "authors": ["Ado Farsi", "Nacime Bouziani", "David A Ham"], "title": "Missing Physics Discovery through Fully Differentiable Finite Element-Based Machine Learning", "categories": ["cs.CE"], "comment": null, "summary": "Although many problems in science and engineering are modelled by\nwell-established PDEs, they often involve unknown or incomplete relationships,\nsuch as material constitutive laws or thermal response, that limit accuracy and\ngenerality. Existing surrogate-modelling approaches directly approximate PDE\nsolutions but remain tied to a specific geometry, boundary conditions, and set\nof physical constraints. To address these limitations, we introduce a fully\ndifferentiable finite element-based machine learning (FEBML) framework that\nembeds trainable operators for unknown physics within a state-of-the-art,\ngeneral FEM solver, enabling true end-to-end differentiation. At its core,\nFEBML represents each unknown operator as an encode-process-decode pipeline\nover finite-element degrees of freedom: field values are projected to nodal\ncoefficients, transformed by a neural network, and then lifted back to a\ncontinuous FE function, ensuring the learned physics respects the variational\nstructure. We demonstrate its versatility by recovering nonlinear stress-strain\nlaws from laboratory tests, applying the learned model to a new mechanical\nscenario without retraining, and identifying temperature-dependent conductivity\nin transient heat flow.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6709\u9650\u5143\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6FEBML\u5904\u7406PDE\u4e2d\u672a\u77e5\u7269\u7406\u5173\u7cfb\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u5176\u901a\u7528\u6027\u3002", "motivation": "\u73b0\u6709PDE\u5efa\u6a21\u5b58\u5728\u672a\u77e5\u6216\u4e0d\u5b8c\u6574\u5173\u7cfb\uff0c\u9650\u5236\u51c6\u786e\u6027\u548c\u901a\u7528\u6027\uff0c\u4e14\u73b0\u6709\u4ee3\u7406\u5efa\u6a21\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165\u5168\u53ef\u5fae\u7684\u57fa\u4e8e\u6709\u9650\u5143\u7684\u673a\u5668\u5b66\u4e60\uff08FEBML\uff09\u6846\u67b6\uff0c\u5c06\u672a\u77e5\u7269\u7406\u7684\u53ef\u8bad\u7ec3\u7b97\u5b50\u5d4c\u5165\u901a\u7528FEM\u6c42\u89e3\u5668\uff0c\u6838\u5fc3\u662f\u5c06\u672a\u77e5\u7b97\u5b50\u8868\u793a\u4e3a\u7f16\u7801 - \u5904\u7406 - \u89e3\u7801\u7ba1\u9053\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u6062\u590d\u975e\u7ebf\u6027\u5e94\u529b - \u5e94\u53d8\u5b9a\u5f8b\uff0c\u5c06\u5b66\u4e60\u6a21\u578b\u5e94\u7528\u4e8e\u65b0\u673a\u68b0\u573a\u666f\uff0c\u8bc6\u522b\u77ac\u6001\u70ed\u6d41\u4e2d\u4e0e\u6e29\u5ea6\u76f8\u5173\u7684\u7535\u5bfc\u7387\u3002", "conclusion": "FEBML\u6846\u67b6\u5177\u6709\u901a\u7528\u6027\uff0c\u80fd\u6709\u6548\u5904\u7406PDE\u4e2d\u7684\u672a\u77e5\u7269\u7406\u5173\u7cfb\u3002"}}
{"id": "2507.15734", "pdf": "https://arxiv.org/pdf/2507.15734", "abs": "https://arxiv.org/abs/2507.15734", "authors": ["Jules Lecomte", "Konrad Zinner", "Michael Neumeier", "Axel von Arnim"], "title": "TONUS: Neuromorphic human pose estimation for artistic sound co-creation", "categories": ["cs.NE"], "comment": "Published at the International Joint Conference on Neural Networks\n  2025 in the special track on HUMAN-AI INTERACTION IN CREATIVE ARTS AND\n  SCIENCES", "summary": "Human machine interaction is a huge source of inspiration in today's media\nart and digital design, as machines and humans merge together more and more.\nIts place in art reflects its growing applications in industry, such as\nrobotics. However, those interactions often remains too technical and\nmachine-driven for people to really engage into. On the artistic side, new\ntechnologies are often not explored in their full potential and lag a bit\nbehind, so that state-of-the-art research does not make its way up to museums\nand exhibitions. Machines should support people's imagination and poetry in a\nseamless interface to their body or soul. We propose an artistic sound\ninstallation featuring neuromorphic body sensing to support a direct yet non\nintrusive interaction with the visitor with the purpose of creating sound\nscapes together with the machine. We design a neuromorphic multihead human pose\nestimation neural sensor that shapes sound scapes and visual output with fine\nbody movement control. In particular, the feature extractor is a spiking neural\nnetwork tailored for a dedicated neuromorphic chip. The visitor, immersed in a\nsound atmosphere and a neurally processed representation of themselves that\nthey control, experience the dialogue with a machine that thinks neurally,\nsimilarly to them.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u4eba\u673a\u4ea4\u4e92\u5728\u827a\u672f\u9886\u57df\u95ee\u9898\uff0c\u63d0\u51fa\u542b\u795e\u7ecf\u5f62\u6001\u4eba\u4f53\u611f\u77e5\u7684\u827a\u672f\u58f0\u97f3\u88c5\u7f6e\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u4eba\u673a\u4ea4\u4e92\u504f\u6280\u672f\u9a71\u52a8\uff0c\u827a\u672f\u9886\u57df\u65b0\u6280\u672f\u672a\u5145\u5206\u6316\u6398\uff0c\u9700\u8ba9\u673a\u5668\u652f\u6301\u4eba\u7684\u60f3\u8c61\u4e0e\u8bd7\u610f\u3002", "method": "\u8bbe\u8ba1\u795e\u7ecf\u5f62\u6001\u591a\u5934\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u795e\u7ecf\u4f20\u611f\u5668\uff0c\u7528\u9488\u5bf9\u4e13\u7528\u795e\u7ecf\u5f62\u6001\u82af\u7247\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u4f5c\u7279\u5f81\u63d0\u53d6\u5668\u3002", "result": "\u8bbf\u5ba2\u80fd\u6c89\u6d78\u5728\u58f0\u97f3\u6c1b\u56f4\u548c\u81ea\u6211\u795e\u7ecf\u5904\u7406\u8868\u5f81\u4e2d\uff0c\u4e0e\u7c7b\u795e\u7ecf\u601d\u7ef4\u7684\u673a\u5668\u5bf9\u8bdd\u3002", "conclusion": "\u6240\u63d0\u827a\u672f\u58f0\u97f3\u88c5\u7f6e\u53ef\u5b9e\u73b0\u4e0e\u8bbf\u5ba2\u76f4\u63a5\u4e14\u975e\u4fb5\u5165\u5f0f\u4ea4\u4e92\uff0c\u5171\u540c\u521b\u9020\u58f0\u666f\u3002"}}
{"id": "2507.14928", "pdf": "https://arxiv.org/pdf/2507.14928", "abs": "https://arxiv.org/abs/2507.14928", "authors": ["Yongrae Jo", "Chanik Park"], "title": "Byzantine-Robust Decentralized Coordination of LLM Agents", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Collaboration among multiple large language model (LLM) agents is a promising\napproach to overcome inherent limitations of single-agent systems, such as\nhallucinations and single points of failure. As LLM agents are increasingly\ndeployed on open blockchain platforms, multi-agent systems capable of\ntolerating malicious (Byzantine) agents have become essential.\n  Recent Byzantine-robust multi-agent systems typically rely on leader-driven\ncoordination, which suffers from two major drawbacks. First, they are\ninherently vulnerable to targeted attacks against the leader. If consecutive\nleaders behave maliciously, the system repeatedly fails to achieve consensus,\nforcing new consensus rounds, which is particularly costly given the high\nlatency of LLM invocations. Second, an underperforming proposal from the leader\ncan be accepted as the final answer even when higher-quality alternatives are\navailable, as existing methods finalize the leader's proposal once it receives\na quorum of votes.\n  To address these issues, we propose DecentLLMs, a novel decentralized\nconsensus approach for multi-agent LLM systems, where worker agents generate\nanswers concurrently and evaluator agents independently score and rank these\nanswers to select the best available one. This decentralized architecture\nenables faster consensus despite the presence of Byzantine agents and\nconsistently selects higher-quality answers through Byzantine-robust\naggregation techniques.\n  Experimental results demonstrate that DecentLLMs effectively tolerates\nByzantine agents and significantly improves the quality of selected answers.", "AI": {"tldr": "\u63d0\u51faDecentLLMs\u89e3\u51b3\u591aLLM\u4ee3\u7406\u7cfb\u7edf\u4e2d\u9886\u5bfc\u8005\u9a71\u52a8\u534f\u8c03\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u62dc\u5360\u5ead\u9c81\u68d2\u591a\u4ee3\u7406\u7cfb\u7edf\u4f9d\u8d56\u9886\u5bfc\u8005\u9a71\u52a8\u534f\u8c03\u6709\u6613\u53d7\u653b\u51fb\u548c\u63a5\u53d7\u4f4e\u8d28\u91cf\u63d0\u6848\u7684\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faDecentLLMs\uff0c\u8ba9\u5de5\u4f5c\u4ee3\u7406\u5e76\u53d1\u751f\u6210\u7b54\u6848\uff0c\u8bc4\u4f30\u4ee3\u7406\u72ec\u7acb\u8bc4\u5206\u548c\u6392\u540d\u9009\u6700\u4f73\u3002", "result": "DecentLLMs\u80fd\u6709\u6548\u5bb9\u5fcd\u62dc\u5360\u5ead\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u9ad8\u6240\u9009\u7b54\u6848\u8d28\u91cf\u3002", "conclusion": "DecentLLMs\u662f\u89e3\u51b3\u591a\u4ee3\u7406LLM\u7cfb\u7edf\u5171\u8bc6\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2507.14334", "pdf": "https://arxiv.org/pdf/2507.14334", "abs": "https://arxiv.org/abs/2507.14334", "authors": ["Hui Yang", "Jiaoyan Chen", "Yuan He", "Yongsheng Gao", "Ian Horrocks"], "title": "Language Models as Ontology Encoders", "categories": ["cs.AI"], "comment": null, "summary": "OWL (Web Ontology Language) ontologies which are able to formally represent\ncomplex knowledge and support semantic reasoning have been widely adopted\nacross various domains such as healthcare and bioinformatics. Recently,\nontology embeddings have gained wide attention due to its potential to infer\nplausible new knowledge and approximate complex reasoning. However, existing\nmethods face notable limitations: geometric model-based embeddings typically\noverlook valuable textual information, resulting in suboptimal performance,\nwhile the approaches that incorporate text, which are often based on language\nmodels, fail to preserve the logical structure. In this work, we propose a new\nontology embedding method OnT, which tunes a Pretrained Language Model (PLM)\nvia geometric modeling in a hyperbolic space for effectively incorporating\ntextual labels and simultaneously preserving class hierarchies and other\nlogical relationships of Description Logic EL. Extensive experiments on four\nreal-world ontologies show that OnT consistently outperforms the baselines\nincluding the state-of-the-art across both tasks of prediction and inference of\naxioms. OnT also demonstrates strong potential in real-world applications,\nindicated by its robust transfer learning abilities and effectiveness in real\ncases of constructing a new ontology from SNOMED CT. Data and code are\navailable at https://github.com/HuiYang1997/OnT.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5OnT\uff0c\u7ed3\u5408\u6587\u672c\u6807\u7b7e\u5e76\u4fdd\u7559\u903b\u8f91\u5173\u7cfb\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5\u5b58\u5728\u5ffd\u7565\u6587\u672c\u4fe1\u606f\u6216\u65e0\u6cd5\u4fdd\u7559\u903b\u8f91\u7ed3\u6784\u7684\u5c40\u9650\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faOnT\u65b9\u6cd5\uff0c\u5728\u53cc\u66f2\u7a7a\u95f4\u901a\u8fc7\u51e0\u4f55\u5efa\u6a21\u5fae\u8c03\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u672c\u4f53\u4e0a\u5b9e\u9a8c\uff0cOnT\u5728\u516c\u7406\u9884\u6d4b\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\uff0c\u6709\u5f3a\u5927\u8fc1\u79fb\u5b66\u4e60\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "conclusion": "OnT\u662f\u6709\u6548\u7684\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5\uff0c\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u4ee3\u7801\u548c\u6570\u636e\u516c\u5f00\u3002"}}
{"id": "2507.14547", "pdf": "https://arxiv.org/pdf/2507.14547", "abs": "https://arxiv.org/abs/2507.14547", "authors": ["Noman Ahmad", "Ruoyu Su", "Matteo Esposito", "Andrea Janes", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Architectural Degradation: Definition, Motivations, Measurement and Remediation Approaches", "categories": ["cs.SE"], "comment": null, "summary": "Architectural degradation, also known as erosion, decay, or aging, impacts\nsystem quality, maintainability, and adaptability. Although widely\nacknowledged, current literature shows fragmented definitions, metrics, and\nremediation strategies. Our study aims to unify understanding of architectural\ndegradation by identifying its definitions, causes, metrics, tools, and\nremediation approaches across academic and gray literature. We conducted a\nmultivocal literature review of 108 studies extracting definitions, causes,\nmetrics, measurement approaches, tools, and remediation strategies. We\ndeveloped a taxonomy encompassing architectural, code, and process debt to\nexplore definition evolution, methodological trends, and research gaps.\nArchitectural degradation has shifted from a low-level issue to a\nsocio-technical concern. Definitions now address code violations, design drift,\nand structural decay. Causes fall under architectural (e.g., poor\ndocumentation), code (e.g., hasty fixes), and process debt (e.g., knowledge\nloss). We identified 54 metrics and 31 measurement techniques, focused on\nsmells, cohesion/coupling, and evolution. Yet, most tools detect issues but\nrarely support ongoing or preventive remediation. Degradation is both technical\nand organizational. While detection is well-studied, continuous remediation\nremains lacking. Our study reveals missed integration between metrics, tools,\nand repair logic, urging holistic, proactive strategies for sustainable\narchitecture.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u591a\u89c6\u89d2\u6587\u732e\u7efc\u8ff0\u7edf\u4e00\u5bf9\u67b6\u6784\u9000\u5316\u7684\u7406\u89e3\uff0c\u53d1\u73b0\u5176\u4ece\u4f4e\u5c42\u6b21\u95ee\u9898\u8f6c\u53d8\u4e3a\u793e\u4f1a\u6280\u672f\u95ee\u9898\uff0c\u786e\u5b9a\u591a\u79cd\u6307\u6807\u548c\u6d4b\u91cf\u6280\u672f\uff0c\u4f46\u5de5\u5177\u591a\u53ea\u68c0\u6d4b\u95ee\u9898\uff0c\u7f3a\u4e4f\u6301\u7eed\u4fee\u590d\uff0c\u547c\u5401\u6574\u4f53\u3001\u4e3b\u52a8\u7b56\u7565\u3002", "motivation": "\u5f53\u524d\u6587\u732e\u5bf9\u67b6\u6784\u9000\u5316\u7684\u5b9a\u4e49\u3001\u6307\u6807\u548c\u4fee\u590d\u7b56\u7565\u96f6\u6563\uff0c\u65e8\u5728\u7edf\u4e00\u5bf9\u67b6\u6784\u9000\u5316\u7684\u7406\u89e3\u3002", "method": "\u5bf9108\u9879\u7814\u7a76\u8fdb\u884c\u591a\u89c6\u89d2\u6587\u732e\u7efc\u8ff0\uff0c\u5f00\u53d1\u5305\u542b\u67b6\u6784\u3001\u4ee3\u7801\u548c\u8fc7\u7a0b\u503a\u52a1\u7684\u5206\u7c7b\u6cd5\u3002", "result": "\u67b6\u6784\u9000\u5316\u4ece\u4f4e\u5c42\u6b21\u95ee\u9898\u8f6c\u53d8\u4e3a\u793e\u4f1a\u6280\u672f\u95ee\u9898\uff0c\u786e\u5b9a54\u4e2a\u6307\u6807\u548c31\u79cd\u6d4b\u91cf\u6280\u672f\uff0c\u591a\u6570\u5de5\u5177\u4ec5\u68c0\u6d4b\u95ee\u9898\u3002", "conclusion": "\u67b6\u6784\u9000\u5316\u662f\u6280\u672f\u548c\u7ec4\u7ec7\u95ee\u9898\uff0c\u68c0\u6d4b\u7814\u7a76\u5145\u5206\u4f46\u6301\u7eed\u4fee\u590d\u4e0d\u8db3\uff0c\u9700\u6574\u4f53\u3001\u4e3b\u52a8\u7b56\u7565\u4ee5\u5b9e\u73b0\u53ef\u6301\u7eed\u67b6\u6784\u3002"}}
{"id": "2507.14612", "pdf": "https://arxiv.org/pdf/2507.14612", "abs": "https://arxiv.org/abs/2507.14612", "authors": ["Pei-Xuan Li", "Wei-Yun Liang", "Fandel Lin", "Hsun-Ping Hsieh"], "title": "Enhancing POI Recommendation through Global Graph Disentanglement with POI Weighted Module", "categories": ["cs.IR", "cs.AI", "cs.SI"], "comment": null, "summary": "Next point of interest (POI) recommendation primarily predicts future\nactivities based on users' past check-in data and current status, providing\nsignificant value to users and service providers. We observed that the popular\ncheck-in times for different POI categories vary. For example, coffee shops are\ncrowded in the afternoon because people like to have coffee to refresh after\nmeals, while bars are busy late at night. However, existing methods rarely\nexplore the relationship between POI categories and time, which may result in\nthe model being unable to fully learn users' tendencies to visit certain POI\ncategories at different times. Additionally, existing methods for modeling time\ninformation often convert it into time embeddings or calculate the time\ninterval and incorporate it into the model, making it difficult to capture the\ncontinuity of time. Finally, during POI prediction, various weighting\ninformation is often ignored, such as the popularity of each POI, the\ntransition relationships between POIs, and the distances between POIs, leading\nto suboptimal performance. To address these issues, this paper proposes a novel\nnext POI recommendation framework called Graph Disentangler with POI Weighted\nModule (GDPW). This framework aims to jointly consider POI category information\nand multiple POI weighting factors. Specifically, the proposed GDPW learns\ncategory and time representations through the Global Category Graph and the\nGlobal Category-Time Graph. Then, we disentangle category and time information\nthrough contrastive learning. After prediction, the final POI recommendation\nfor users is obtained by weighting the prediction results based on the\ntransition weights and distance relationships between POIs. We conducted\nexperiments on two real-world datasets, and the results demonstrate that the\nproposed GDPW outperforms other existing models, improving performance by 3% to\n11%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGDPW\u6846\u67b6\u89e3\u51b3\u73b0\u6709\u5174\u8da3\u70b9\u63a8\u8350\u65b9\u6cd5\u672a\u8003\u8651\u7c7b\u522b\u4e0e\u65f6\u95f4\u5173\u7cfb\u3001\u96be\u6355\u6349\u65f6\u95f4\u8fde\u7eed\u6027\u53ca\u5ffd\u7565\u6743\u91cd\u4fe1\u606f\u7b49\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651POI\u7c7b\u522b\u4e0e\u65f6\u95f4\u5173\u7cfb\u3001\u96be\u6355\u6349\u65f6\u95f4\u8fde\u7eed\u6027\u4e14\u5ffd\u7565POI\u591a\u79cd\u6743\u91cd\u4fe1\u606f\uff0c\u5bfc\u81f4\u63a8\u8350\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51faGDPW\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5c40\u7c7b\u522b\u56fe\u548c\u5168\u5c40\u7c7b\u522b - \u65f6\u95f4\u56fe\u5b66\u4e60\u7c7b\u522b\u548c\u65f6\u95f4\u8868\u793a\uff0c\u7528\u5bf9\u6bd4\u5b66\u4e60\u5206\u79bb\u4fe1\u606f\uff0c\u9884\u6d4b\u540e\u6839\u636ePOI\u95f4\u8f6c\u79fb\u6743\u91cd\u548c\u8ddd\u79bb\u5173\u7cfb\u52a0\u6743\u5f97\u5230\u6700\u7ec8\u63a8\u8350\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cGDPW\u6027\u80fd\u6bd4\u5176\u4ed6\u73b0\u6709\u6a21\u578b\u63d0\u9ad83% - 11%\u3002", "conclusion": "GDPW\u6846\u67b6\u5728\u8003\u8651POI\u7c7b\u522b\u4fe1\u606f\u548c\u591a\u79cd\u6743\u91cd\u56e0\u7d20\u540e\uff0c\u80fd\u6709\u6548\u63d0\u5347\u4e0b\u4e00\u5174\u8da3\u70b9\u63a8\u8350\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15054", "pdf": "https://arxiv.org/pdf/2507.15054", "abs": "https://arxiv.org/abs/2507.15054", "authors": ["Lucas Woodley", "Chung Yi See", "Daniel Palmer", "Ashley Nunes"], "title": "Equity, Emissions and the Inflation Reduction Act", "categories": ["econ.GN", "q-fin.EC"], "comment": "23 pages, 3 figures", "summary": "Preowned vehicles are disproportionally purchased by low-income households, a\ngroup that has long been unable to purchase electric vehicles. Yet, low-income\nhouseholds would disproportionally benefit from EV adoption given the operating\ncosts savings offered by electrification. To help realize this benefit,\nprovisions of the 2022 Inflation Reduction Act offer preowned EV purchasing\nincentives. How effective might these efforts be. Leveraging data from the\nUnited States Census Bureau, the National Household Travel Survey, and the\nGreenhouse gases, Regulated Emissions, and Energy use in Technologies Model, we\naddress this question. Our findings are fourfold. First, we demonstrate that\nalthough low-income households are more likely to benefit from preowned EV\npurchasing incentives offered by IRA, up to 8.4 million low-income households\nmay be ineligible owing to heterogeneity in vehicle procurement pathways.\nSecond, we show that program ineligibility risks preventing up to 113.9 million\ntons in lifecycle emissions reduction benefits from being realized. Third, we\nfind that procurement pathways depend on vehicle price. More expensive preowned\nvehicles are purchased directly from commercial dealers, while less expensive\npreowned vehicles are purchased from private sellers. These procurement\npathways matter because qualification for IRA incentives necessitates\npurchasing solely from commercial dealers. Fourth, we demonstrate that while\nincentives motivating preowned vehicle purchases from commercial dealers may be\neffective if the vehicle is expensive, this effectiveness diminishes at higher\nprice points. The implications of our findings on decarbonization efforts and\nenergy policy are discussed.", "AI": {"tldr": "\u7814\u7a762022\u5e74\u901a\u80c0\u524a\u51cf\u6cd5\u6848\u4e8c\u624b\u7535\u52a8\u6c7d\u8f66\u8d2d\u4e70\u6fc0\u52b1\u63aa\u65bd\u5bf9\u4f4e\u6536\u5165\u5bb6\u5ead\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u90e8\u5206\u5bb6\u5ead\u53ef\u80fd\u56e0\u91c7\u8d2d\u9014\u5f84\u65e0\u8d44\u683c\u53c2\u4e0e\uff0c\u4e14\u5f71\u54cd\u51cf\u6392\u6548\u76ca\u3002", "motivation": "\u4f4e\u6536\u5165\u5bb6\u5ead\u8d2d\u4e70\u4e8c\u624b\u6c7d\u8f66\u6bd4\u4f8b\u9ad8\u4e14\u91c7\u7528\u7535\u52a8\u6c7d\u8f66\u80fd\u8282\u7701\u8fd0\u8425\u6210\u672c\uff0c\u4f46\u6b64\u524d\u96be\u4ee5\u8d2d\u4e70\uff0c\u7814\u7a76\u901a\u80c0\u524a\u51cf\u6cd5\u6848\u4e8c\u624b\u7535\u52a8\u6c7d\u8f66\u8d2d\u4e70\u6fc0\u52b1\u63aa\u65bd\u7684\u6709\u6548\u6027\u3002", "method": "\u5229\u7528\u7f8e\u56fd\u4eba\u53e3\u666e\u67e5\u5c40\u3001\u56fd\u5bb6\u5bb6\u5ead\u51fa\u884c\u8c03\u67e5\u548c\u76f8\u5173\u6280\u672f\u6a21\u578b\u7684\u6570\u636e\u8fdb\u884c\u7814\u7a76\u3002", "result": "1. \u591a\u8fbe840\u4e07\u4f4e\u6536\u5165\u5bb6\u5ead\u53ef\u80fd\u56e0\u8f66\u8f86\u91c7\u8d2d\u9014\u5f84\u5f02\u8d28\u6027\u65e0\u8d44\u683c\u53c2\u4e0e\u6fc0\u52b1\uff1b2. \u8ba1\u5212\u65e0\u8d44\u683c\u53ef\u80fd\u5bfc\u81f4\u591a\u8fbe1.139\u4ebf\u5428\u751f\u547d\u5468\u671f\u51cf\u6392\u6548\u76ca\u65e0\u6cd5\u5b9e\u73b0\uff1b3. \u91c7\u8d2d\u9014\u5f84\u53d6\u51b3\u4e8e\u8f66\u8f86\u4ef7\u683c\uff0c\u6fc0\u52b1\u5bf9\u9ad8\u4ef7\u8f66\u66f4\u6709\u6548\u3002", "conclusion": "\u63a2\u8ba8\u4e86\u7814\u7a76\u7ed3\u679c\u5bf9\u8131\u78b3\u52aa\u529b\u548c\u80fd\u6e90\u653f\u7b56\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.15735", "pdf": "https://arxiv.org/pdf/2507.15735", "abs": "https://arxiv.org/abs/2507.15735", "authors": ["Sergiu Hart", "Noam Nisan"], "title": "The Root of Revenue Continuity", "categories": ["cs.GT"], "comment": null, "summary": "In the setup of selling one or more goods, various papers have shown, in\nvarious forms and for various purposes, that a small change in the distribution\nof a buyer's valuations may cause only a small change in the possible revenue\nthat can be extracted. We prove a simple, clean, convenient, and general\nstatement to this effect: let X and Y be random valuations on k additive goods,\nand let W(X,Y) be the Wasserstein (or \"earth mover's\") distance between them;\nthen sqrt(Rev(X))-sqrt(Rev(Y)) <= sqrt(W(X,Y)). This further implies that a\nsimple explicit modification of any optimal mechanism for X, namely, \"uniform\ndiscounting\", is guaranteed to be almost optimal for any Y that is close to X\nin the Wasserstein distance.", "AI": {"tldr": "\u8bc1\u660e\u968f\u673a\u4f30\u503c\u5206\u5e03\u7684Wasserstein\u8ddd\u79bb\u4e0e\u53ef\u63d0\u53d6\u6536\u5165\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u8868\u660e\u5bf9\u6700\u4f18\u673a\u5236\u7684\u7b80\u5355\u4fee\u6539\u5bf9\u76f8\u8fd1\u5206\u5e03\u51e0\u4e4e\u6700\u4f18\u3002", "motivation": "\u5728\u5546\u54c1\u9500\u552e\u573a\u666f\u4e0b\uff0c\u5df2\u6709\u7814\u7a76\u8868\u660e\u4e70\u5bb6\u4f30\u503c\u5206\u5e03\u7684\u5c0f\u53d8\u5316\u5bf9\u53ef\u63d0\u53d6\u6536\u5165\u5f71\u54cd\u5c0f\uff0c\u6b64\u7814\u7a76\u65e8\u5728\u7ed9\u51fa\u4e00\u4e2a\u7b80\u5355\u901a\u7528\u7684\u8868\u8ff0\u3002", "method": "\u5b9a\u4e49\u968f\u673a\u4f30\u503cX\u548cY\uff0c\u5229\u7528Wasserstein\u8ddd\u79bb\uff0c\u8bc1\u660esqrt(Rev(X)) - sqrt(Rev(Y)) <= sqrt(W(X,Y))\u3002", "result": "\u5f97\u51fasqrt(Rev(X)) - sqrt(Rev(Y)) <= sqrt(W(X,Y))\u7684\u7ed3\u679c\uff0c\u4e14\u6307\u51fa\u5bf9X\u7684\u6700\u4f18\u673a\u5236\u8fdb\u884c\u201c\u7edf\u4e00\u6298\u6263\u201d\u4fee\u6539\u540e\u5bf9\u76f8\u8fd1\u7684Y\u51e0\u4e4e\u6700\u4f18\u3002", "conclusion": "\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u5efa\u7acb\u4e86\u4f30\u503c\u5206\u5e03\u8ddd\u79bb\u4e0e\u6536\u5165\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u7684\u673a\u5236\u4fee\u6539\u65b9\u6cd5\u5177\u6709\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.14661", "pdf": "https://arxiv.org/pdf/2507.14661", "abs": "https://arxiv.org/abs/2507.14661", "authors": ["Wooseok Ha", "Yuansi Chen"], "title": "When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Semi-supervised domain adaptation (SSDA) aims to achieve high predictive\nperformance in the target domain with limited labeled target data by exploiting\nabundant source and unlabeled target data. Despite its significance in numerous\napplications, theory on the effectiveness of SSDA remains largely unexplored,\nparticularly in scenarios involving various types of source-target\ndistributional shifts. In this work, we develop a theoretical framework based\non structural causal models (SCMs) which allows us to analyze and quantify the\nperformance of SSDA methods when labeled target data is limited. Within this\nframework, we introduce three SSDA methods, each having a fine-tuning strategy\ntailored to a distinct assumption about the source and target relationship.\nUnder each assumption, we demonstrate how extending an unsupervised domain\nadaptation (UDA) method to SSDA can achieve minimax-optimal target performance\nwith limited target labels. When the relationship between source and target\ndata is only vaguely known -- a common practical concern -- we propose the\nMulti Adaptive-Start Fine-Tuning (MASFT) algorithm, which fine-tunes UDA models\nfrom multiple starting points and selects the best-performing one based on a\nsmall hold-out target validation dataset. Combined with model selection\nguarantees, MASFT achieves near-optimal target predictive performance across a\nbroad range of types of distributional shifts while significantly reducing the\nneed for labeled target data. We empirically validate the effectiveness of our\nproposed methods through simulations.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5f00\u53d1\u7406\u8bba\u6846\u67b6\u5206\u6790\u534a\u76d1\u7763\u57df\u81ea\u9002\u5e94\uff08SSDA\uff09\u65b9\u6cd5\u6027\u80fd\uff0c\u63d0\u51fa\u4e09\u79cdSSDA\u65b9\u6cd5\u548cMASFT\u7b97\u6cd5\uff0c\u7ecf\u6a21\u62df\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "SSDA\u5728\u5f88\u591a\u5e94\u7528\u4e2d\u91cd\u8981\uff0c\u4f46\u76f8\u5173\u6709\u6548\u6027\u7406\u8bba\uff0c\u5c24\u5176\u662f\u5728\u6e90 - \u76ee\u6807\u5206\u5e03\u504f\u79fb\u573a\u666f\u4e0b\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5f00\u53d1\u7406\u8bba\u6846\u67b6\uff0c\u5f15\u5165\u4e09\u79cd\u6709\u9488\u5bf9\u6027\u5fae\u8c03\u7b56\u7565\u7684SSDA\u65b9\u6cd5\uff0c\u63d0\u51faMASFT\u7b97\u6cd5\u4ece\u591a\u8d77\u70b9\u5fae\u8c03UDA\u6a21\u578b\u5e76\u57fa\u4e8e\u9a8c\u8bc1\u96c6\u9009\u4f18\u3002", "result": "\u5728\u4e0d\u540c\u5047\u8bbe\u4e0b\uff0c\u6269\u5c55\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\uff08UDA\uff09\u65b9\u6cd5\u5230SSDA\u53ef\u5b9e\u73b0\u6709\u9650\u76ee\u6807\u6807\u7b7e\u4e0b\u7684\u6781\u5c0f\u6781\u5927\u6700\u4f18\u76ee\u6807\u6027\u80fd\uff1bMASFT\u7b97\u6cd5\u5728\u591a\u79cd\u5206\u5e03\u504f\u79fb\u7c7b\u578b\u4e2d\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u76ee\u6807\u9884\u6d4b\u6027\u80fd\uff0c\u51cf\u5c11\u5bf9\u6807\u8bb0\u76ee\u6807\u6570\u636e\u7684\u9700\u6c42\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u7ecf\u6a21\u62df\u9a8c\u8bc1\u6709\u6548\uff0c\u80fd\u5728\u6709\u9650\u6807\u8bb0\u76ee\u6807\u6570\u636e\u4e0b\u63d0\u5347\u76ee\u6807\u57df\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.14380", "pdf": "https://arxiv.org/pdf/2507.14380", "abs": "https://arxiv.org/abs/2507.14380", "authors": ["Kazeem Kareem", "Fan Dai"], "title": "A Hybrid Mixture Approach for Clustering and Characterizing Cancer Data", "categories": ["stat.ME", "q-bio.TO", "stat.AP", "stat.CO", "stat.ML", "62H05, 62H12, 62H20, 62H25, 62H30, 62P10", "G.3; I.2; I.5; I.6; J.3"], "comment": null, "summary": "Model-based clustering is widely used for identifying and distinguishing\ntypes of diseases. However, modern biomedical data coming with high dimensions\nmake it challenging to perform the model estimation in traditional cluster\nanalysis. The incorporation of factor analyzer into the mixture model provides\na way to characterize the large set of data features, but the current\nestimation method is computationally impractical for massive data due to the\nintrinsic slow convergence of the embedded algorithms, and the incapability to\nvary the size of the factor analyzers, preventing the implementation of a\ngeneralized mixture of factor analyzers and further characterization of the\ndata clusters. We propose a hybrid matrix-free computational scheme to\nefficiently estimate the clusters and model parameters based on a Gaussian\nmixture along with generalized factor analyzers to summarize the large number\nof variables using a small set of underlying factors. Our approach outperforms\nthe existing method with faster convergence while maintaining high clustering\naccuracy. Our algorithms are applied to accurately identify and distinguish\ntypes of breast cancer based on large tumor samples, and to provide a\ngeneralized characterization for subtypes of lymphoma using massive gene\nrecords.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6df7\u5408\u65e0\u77e9\u9635\u8ba1\u7b97\u65b9\u6848\u7528\u4e8e\u6a21\u578b\u805a\u7c7b\uff0c\u5728\u4e73\u817a\u764c\u548c\u6dcb\u5df4\u7624\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u3002", "motivation": "\u73b0\u4ee3\u751f\u7269\u533b\u5b66\u6570\u636e\u9ad8\u7ef4\uff0c\u73b0\u6709\u542b\u56e0\u5b50\u5206\u6790\u5668\u7684\u6df7\u5408\u6a21\u578b\u4f30\u8ba1\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\uff0c\u65e0\u6cd5\u6539\u53d8\u56e0\u5b50\u5206\u6790\u5668\u5927\u5c0f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u548c\u5e7f\u4e49\u56e0\u5b50\u5206\u6790\u5668\u7684\u6df7\u5408\u65e0\u77e9\u9635\u8ba1\u7b97\u65b9\u6848\u4f30\u8ba1\u805a\u7c7b\u548c\u6a21\u578b\u53c2\u6570\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u6536\u655b\u66f4\u5feb\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u805a\u7c7b\u7cbe\u5ea6\u3002", "conclusion": "\u7b97\u6cd5\u53ef\u51c6\u786e\u8bc6\u522b\u548c\u533a\u5206\u4e73\u817a\u764c\u7c7b\u578b\uff0c\u4e3a\u6dcb\u5df4\u7624\u4e9a\u578b\u63d0\u4f9b\u5e7f\u4e49\u8868\u5f81\u3002"}}
{"id": "2507.15319", "pdf": "https://arxiv.org/pdf/2507.15319", "abs": "https://arxiv.org/abs/2507.15319", "authors": ["Yannan Bai", "Debmalya Panigrahi", "Ian Zhang"], "title": "Language Generation in the Limit: Noise, Loss, and Feedback", "categories": ["cs.DS", "cs.LG"], "comment": null, "summary": "Kleinberg and Mullainathan (2024) recently proposed a formal framework called\nlanguage generation in the limit and showed that given a sequence of example\nstrings from an unknown target language drawn from any countable collection, an\nalgorithm can correctly generate unseen strings from the target language within\nfinite time. This notion was further refined by Li, Raman, and Tewari (2024),\nwho defined stricter categories of non-uniform and uniform generation. They\nshowed that a finite union of uniformly generatable collections is generatable\nin the limit, and asked if the same is true for non-uniform generation.\n  We begin by resolving the question in the negative: we give a uniformly\ngeneratable collection and a non-uniformly generatable collection whose union\nis not generatable in the limit. We then use facets of this construction to\nfurther our understanding of several variants of language generation. The first\ntwo, generation with noise and without samples, were introduced by Raman and\nRaman (2025) and Li, Raman, and Tewari (2024) respectively. We show the\nequivalence of these models for uniform and non-uniform generation, and provide\na characterization of non-uniform noisy generation. The former paper asked if\nthere is any separation between noisy and non-noisy generation in the limit --\nwe show that such a separation exists even with a single noisy string. Finally,\nwe study the framework of generation with feedback, introduced by Charikar and\nPabbaraju (2025), where the algorithm is strengthened by allowing it to ask\nmembership queries. We show finite queries add no power, but infinite queries\nyield a strictly more powerful model.\n  In summary, the results in this paper resolve the union-closedness of\nlanguage generation in the limit, and leverage those techniques (and others) to\ngive precise characterizations for natural variants that incorporate noise,\nloss, and feedback.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u6781\u9650\u8bed\u8a00\u751f\u6210\u7684\u5e76\u96c6\u5c01\u95ed\u6027\u95ee\u9898\uff0c\u8fd8\u5bf9\u542b\u566a\u58f0\u3001\u65e0\u6837\u672c\u548c\u6709\u53cd\u9988\u7b49\u53d8\u4f53\u6a21\u578b\u7ed9\u51fa\u7cbe\u786e\u523b\u753b\u3002", "motivation": "\u524d\u4eba\u63d0\u51fa\u6781\u9650\u8bed\u8a00\u751f\u6210\u6846\u67b6\u5e76\u5b9a\u4e49\u76f8\u5173\u7c7b\u522b\uff0c\u63d0\u51fa\u975e\u5747\u5300\u751f\u6210\u7684\u5e76\u96c6\u5c01\u95ed\u6027\u95ee\u9898\uff0c\u4ee5\u53ca\u566a\u58f0\u4e0e\u975e\u566a\u58f0\u751f\u6210\u7684\u5206\u79bb\u95ee\u9898\u7b49\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5148\u901a\u8fc7\u6784\u9020\u53cd\u4f8b\u5426\u5b9a\u975e\u5747\u5300\u751f\u6210\u7684\u5e76\u96c6\u5c01\u95ed\u6027\uff0c\u5229\u7528\u6784\u9020\u7279\u6027\u7814\u7a76\u8bed\u8a00\u751f\u6210\u7684\u591a\u79cd\u53d8\u4f53\uff0c\u5206\u6790\u4e0d\u540c\u6a21\u578b\u7684\u7b49\u4ef7\u6027\u548c\u7279\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5b58\u5728\u5747\u5300\u548c\u975e\u5747\u5300\u53ef\u751f\u6210\u96c6\u5408\u7684\u5e76\u96c6\u4e0d\u53ef\u5728\u6709\u9650\u65f6\u95f4\u751f\u6210\uff1b\u8bc1\u660e\u542b\u566a\u58f0\u548c\u65e0\u6837\u672c\u6a21\u578b\u5728\u5747\u5300\u548c\u975e\u5747\u5300\u751f\u6210\u4e0a\u7b49\u4ef7\uff0c\u7ed9\u51fa\u975e\u5747\u5300\u566a\u58f0\u751f\u6210\u7684\u523b\u753b\uff1b\u8bc1\u660e\u6709\u4e00\u4e2a\u566a\u58f0\u5b57\u7b26\u4e32\u65f6\u566a\u58f0\u548c\u975e\u566a\u58f0\u751f\u6210\u5b58\u5728\u5206\u79bb\uff1b\u8bc1\u660e\u6709\u9650\u67e5\u8be2\u65e0\u989d\u5916\u80fd\u529b\uff0c\u65e0\u9650\u67e5\u8be2\u66f4\u5f3a\u5927\u3002", "conclusion": "\u89e3\u51b3\u4e86\u6781\u9650\u8bed\u8a00\u751f\u6210\u7684\u5e76\u96c6\u5c01\u95ed\u6027\u95ee\u9898\uff0c\u5e76\u5bf9\u542b\u566a\u58f0\u3001\u635f\u5931\u548c\u53cd\u9988\u7684\u81ea\u7136\u53d8\u4f53\u7ed9\u51fa\u7cbe\u786e\u523b\u753b\u3002"}}
{"id": "2503.22814", "pdf": "https://arxiv.org/pdf/2503.22814", "abs": "https://arxiv.org/abs/2503.22814", "authors": ["Satyapreet Singh Yadav", "Nirupam Roy", "Chetan Singh Thakur"], "title": "Enhancing Celestial Imaging: High Dynamic Range with Neuromorphic Cameras", "categories": ["astro-ph.IM", "cs.ET", "cs.NE"], "comment": null, "summary": "Conventional frame-based cameras often struggle with limited dynamic range,\nleading to saturation and loss of detail when capturing scenes with significant\nbrightness variations. Neuromorphic cameras, inspired by human retina, offer a\nsolution by providing an inherently high dynamic range. This capability enables\nthem to capture both bright and faint celestial objects without saturation\neffects, preserving details across a wide range of luminosities. This paper\ninvestigates the application of neuromorphic imaging technology for capturing\ncelestial bodies across a wide range of flux levels. Its advantages are\ndemonstrated through examples such as the bright planet Saturn with its faint\nmoons and the bright star Sirius A alongside its faint companion, Sirius B.", "AI": {"tldr": "\u4f20\u7edf\u57fa\u4e8e\u5e27\u7684\u76f8\u673a\u52a8\u6001\u8303\u56f4\u6709\u9650\uff0c\u795e\u7ecf\u5f62\u6001\u76f8\u673a\u6709\u9ad8\u52a8\u6001\u8303\u56f4\u4f18\u52bf\uff0c\u672c\u6587\u7814\u7a76\u5176\u5728\u4e0d\u540c\u901a\u91cf\u6c34\u5e73\u5929\u4f53\u62cd\u6444\u4e2d\u7684\u5e94\u7528\u5e76\u4e3e\u4f8b\u5c55\u793a\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u5e27\u76f8\u673a\u52a8\u6001\u8303\u56f4\u6709\u9650\uff0c\u62cd\u6444\u4eae\u5ea6\u5dee\u5f02\u5927\u7684\u573a\u666f\u6709\u9971\u548c\u548c\u7ec6\u8282\u4e22\u5931\u95ee\u9898\uff0c\u795e\u7ecf\u5f62\u6001\u76f8\u673a\u6709\u9ad8\u52a8\u6001\u8303\u56f4\u4f18\u52bf\uff0c\u6545\u7814\u7a76\u5176\u5728\u5929\u4f53\u62cd\u6444\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672a\u63d0\u53ca\u5177\u4f53\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3e\u4f8b\uff08\u5982\u571f\u661f\u53ca\u5176\u536b\u661f\u3001\u5929\u72fc\u661fA\u53ca\u5176\u4f34\u661f\u5929\u72fc\u661fB\uff09\u5c55\u793a\u4f18\u52bf\u3002", "result": "\u5c55\u793a\u4e86\u795e\u7ecf\u5f62\u6001\u76f8\u673a\u5728\u62cd\u6444\u4e0d\u540c\u4eae\u5ea6\u5929\u4f53\u65f6\u80fd\u907f\u514d\u9971\u548c\u6548\u5e94\uff0c\u4fdd\u7559\u7ec6\u8282\u3002", "conclusion": "\u795e\u7ecf\u5f62\u6001\u6210\u50cf\u6280\u672f\u5728\u4e0d\u540c\u901a\u91cf\u6c34\u5e73\u5929\u4f53\u62cd\u6444\u4e2d\u6709\u5e94\u7528\u4f18\u52bf\u3002"}}
{"id": "2507.15121", "pdf": "https://arxiv.org/pdf/2507.15121", "abs": "https://arxiv.org/abs/2507.15121", "authors": ["Sasindu Wijeratne", "Rajgopal Kannan", "Viktor Prasanna"], "title": "AMPED: Accelerating MTTKRP for Billion-Scale Sparse Tensor Decomposition on Multiple GPUs", "categories": ["cs.DC"], "comment": null, "summary": "Matricized Tensor Times Khatri-Rao Product (MTTKRP) is the computational\nbottleneck in sparse tensor decomposition. As real-world sparse tensors grow to\nbillions of nonzeros, they increasingly demand higher memory capacity and\ncompute throughput from hardware accelerators. In this work, we present AMPED,\na multi-GPU parallel algorithm designed to accelerate MTTKRP on billion-scale\nsparse tensors. AMPED scales beyond the limits of a single GPU, meeting both\nthe memory and performance requirements of large-scale workloads. We introduce\na partitioning strategy combined with a dynamic load balancing scheme to\ndistribute computation and minimize GPU idle time. On real-world billion-scale\ntensors, AMPED achieves a 5.1x geometric mean speedup in total execution time\nover state-of-the-art GPU baselines using 4 GPUs on a single CPU node.", "AI": {"tldr": "\u63d0\u51fa\u591aGPU\u5e76\u884c\u7b97\u6cd5AMPED\u52a0\u901f\u5341\u4ebf\u89c4\u6a21\u7a00\u758f\u5f20\u91cfMTTKRP\uff0c\u7ed3\u5408\u5206\u533a\u7b56\u7565\u4e0e\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709GPU\u57fa\u7ebf\u6709\u663e\u8457\u52a0\u901f\u3002", "motivation": "MTTKRP\u662f\u7a00\u758f\u5f20\u91cf\u5206\u89e3\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u73b0\u5b9e\u4e2d\u5341\u4ebf\u89c4\u6a21\u7a00\u758f\u5f20\u91cf\u5bf9\u786c\u4ef6\u52a0\u901f\u5668\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u541e\u5410\u91cf\u8981\u6c42\u9ad8\uff0c\u5355GPU\u6709\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u591aGPU\u5e76\u884c\u7b97\u6cd5AMPED\uff0c\u91c7\u7528\u5206\u533a\u7b56\u7565\u548c\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\u65b9\u6848\u6765\u5206\u914d\u8ba1\u7b97\u548c\u51cf\u5c11GPU\u7a7a\u95f2\u65f6\u95f4\u3002", "result": "\u5728\u771f\u5b9e\u5341\u4ebf\u89c4\u6a21\u5f20\u91cf\u4e0a\uff0c\u5728\u5355CPU\u8282\u70b9\u4f7f\u75284\u4e2aGPU\u65f6\uff0cAMPED\u5728\u603b\u6267\u884c\u65f6\u95f4\u4e0a\u6bd4\u73b0\u6709GPU\u57fa\u7ebf\u5b9e\u73b0\u4e865.1\u500d\u7684\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u3002", "conclusion": "AMPED\u80fd\u7a81\u7834\u5355GPU\u9650\u5236\uff0c\u6ee1\u8db3\u5927\u89c4\u6a21\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5185\u5b58\u548c\u6027\u80fd\u9700\u6c42\u3002"}}
{"id": "2507.14335", "pdf": "https://arxiv.org/pdf/2507.14335", "abs": "https://arxiv.org/abs/2507.14335", "authors": ["Nicolas Wischermann", "Claudio Mayrink Verdun", "Gabriel Poesia", "Francesco Noseda"], "title": "ProofCompass: Enhancing Specialized Provers with LLM Guidance", "categories": ["cs.AI"], "comment": "19 pages, 7 figures. Accepted at the 2nd AI for MATH Workshop at the\n  42nd International Conference on Machine Learning (ICML 2025)", "summary": "Language models have become increasingly powerful tools for formal\nmathematical reasoning. However, most existing approaches rely exclusively on\neither large general-purpose models or smaller specialized models, each with\ndistinct limitations, while training specialized large models still requires\nsignificant computational resources. This paper introduces ProofCompass, a\nnovel hybrid methodology that achieves remarkable computational efficiency by\nstrategically guiding existing specialized prover methods, such as\nDeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without\nrequiring additional model training. The LLM provides natural language proof\nstrategies and analyzes failed attempts to select intermediate lemmas, enabling\neffective problem decomposition. On the miniF2F benchmark, ProofCompass\ndemonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\\%\n\\rightarrow 55.3\\%$) while using 25x fewer attempts ($3200 \\rightarrow 128$).\nOur synergistic approach paves the way for simultaneously improving\ncomputational efficiency and accuracy in formal theorem proving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faProofCompass\u6df7\u5408\u65b9\u6cd5\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6a21\u578b\uff0c\u63d0\u9ad8\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u901a\u7528\u6216\u4e13\u7528\u6a21\u578b\uff0c\u5404\u6709\u5c40\u9650\uff0c\u8bad\u7ec3\u4e13\u7528\u5927\u6a21\u578b\u9700\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u5f15\u5165ProofCompass\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u73b0\u6709\u4e13\u7528\u8bc1\u660e\u65b9\u6cd5\uff0c\u63d0\u4f9b\u8bc1\u660e\u7b56\u7565\u548c\u5206\u6790\u5931\u8d25\u5c1d\u8bd5\u4ee5\u9009\u62e9\u4e2d\u95f4\u5f15\u7406\u3002", "result": "\u5728miniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProofCompass\u6bd4DSP - v1.5\u51c6\u786e\u7387\u4ece54.9%\u63d0\u5347\u523055.3%\uff0c\u5c1d\u8bd5\u6b21\u6570\u51cf\u5c1125\u500d\u3002", "conclusion": "\u8be5\u534f\u540c\u65b9\u6cd5\u4e3a\u63d0\u9ad8\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.14554", "pdf": "https://arxiv.org/pdf/2507.14554", "abs": "https://arxiv.org/abs/2507.14554", "authors": ["Ruoyu Su", "Noman ahmad", "Matteo Esposito", "Andrea Janes", "Davide Taibi", "Valentina Lenarduzzi"], "title": "Emerging Trends in Software Architecture from the Practitioners Perspective: A Five Year Review", "categories": ["cs.SE"], "comment": null, "summary": "Software architecture plays a central role in the design, development, and\nmaintenance of software systems. With the rise of cloud computing,\nmicroservices, and containers, architectural practices have diversified.\nUnderstanding these shifts is vital. This study analyzes software architecture\ntrends across eight leading industry conferences over five years. We\ninvestigate the evolution of software architecture by analyzing talks from top\npractitioner conferences, focusing on the motivations and contexts driving\ntechnology adoption. We analyzed 5,677 talks from eight major industry\nconferences, using large language models and expert validation to extract\ntechnologies, their purposes, and usage contexts. We also explored how\ntechnologies interrelate and fit within DevOps and deployment pipelines. Among\n450 technologies, Kubernetes, Cloud Native, Serverless, and Containers dominate\nby frequency and centrality. Practitioners present technology mainly related to\ndeployment, communication, AI, and observability. We identify five technology\ncommunities covering automation, coordination, cloud AI, monitoring, and\ncloud-edge. Most technologies span multiple DevOps stages and support hybrid\ndeployment. Our study reveals that a few core technologies, like Kubernetes and\nServerless, dominate the contemporary software architecture practice. These are\nmainly applied in later DevOps stages, with limited focus on early phases like\nplanning and coding. We also show how practitioners frame technologies by\npurpose and context, reflecting evolving industry priorities. Finally, we\nobserve how only research can provide a more holistic lens on architectural\ndesign, quality, and evolution.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e94\u5e74\u5185\u516b\u5927\u884c\u4e1a\u4f1a\u8bae\u8f6f\u4ef6\u67b6\u6784\u8d8b\u52bf\uff0c\u53d1\u73b0Kubernetes\u7b49\u5c11\u6570\u6838\u5fc3\u6280\u672f\u4e3b\u5bfc\u5f53\u4ee3\u8f6f\u4ef6\u67b6\u6784\u5b9e\u8df5\uff0c\u591a\u5e94\u7528\u4e8eDevOps\u540e\u671f\u9636\u6bb5\u3002", "motivation": "\u968f\u7740\u4e91\u8ba1\u7b97\u7b49\u53d1\u5c55\uff0c\u67b6\u6784\u5b9e\u8df5\u591a\u6837\u5316\uff0c\u9700\u7406\u89e3\u8fd9\u4e9b\u8f6c\u53d8\u3002", "method": "\u5206\u6790\u516b\u5927\u884c\u4e1a\u4f1a\u8bae\u76845677\u573a\u6f14\u8bb2\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e13\u5bb6\u9a8c\u8bc1\u63d0\u53d6\u6280\u672f\u3001\u76ee\u7684\u548c\u4f7f\u7528\u573a\u666f\uff0c\u63a2\u7d22\u6280\u672f\u5173\u8054\u3002", "result": "Kubernetes\u7b49\u6280\u672f\u5360\u4e3b\u5bfc\uff0c\u786e\u5b9a\u4e94\u4e2a\u6280\u672f\u793e\u533a\uff0c\u591a\u6570\u6280\u672f\u8de8DevOps\u9636\u6bb5\u652f\u6301\u6df7\u5408\u90e8\u7f72\u3002", "conclusion": "\u5c11\u6570\u6838\u5fc3\u6280\u672f\u4e3b\u5bfc\u5f53\u4ee3\u8f6f\u4ef6\u67b6\u6784\u5b9e\u8df5\uff0c\u591a\u5e94\u7528\u4e8eDevOps\u540e\u671f\uff0c\u7814\u7a76\u80fd\u4e3a\u67b6\u6784\u8bbe\u8ba1\u7b49\u63d0\u4f9b\u66f4\u5168\u9762\u89c6\u89d2\u3002"}}
{"id": "2507.14619", "pdf": "https://arxiv.org/pdf/2507.14619", "abs": "https://arxiv.org/abs/2507.14619", "authors": ["Van-Hoang Le", "Duc-Vu Nguyen", "Kiet Van Nguyen", "Ngan Luu-Thuy Nguyen"], "title": "Optimizing Legal Document Retrieval in Vietnamese with Semi-Hard Negative Mining", "categories": ["cs.IR", "cs.CL"], "comment": "Accepted at ICCCI 2025", "summary": "Large Language Models (LLMs) face significant challenges in specialized\ndomains like law, where precision and domain-specific knowledge are critical.\nThis paper presents a streamlined two-stage framework consisting of Retrieval\nand Re-ranking to enhance legal document retrieval efficiency and accuracy. Our\napproach employs a fine-tuned Bi-Encoder for rapid candidate retrieval,\nfollowed by a Cross-Encoder for precise re-ranking, both optimized through\nstrategic negative example mining. Key innovations include the introduction of\nthe Exist@m metric to evaluate retrieval effectiveness and the use of semi-hard\nnegatives to mitigate training bias, which significantly improved re-ranking\nperformance. Evaluated on the SoICT Hackathon 2024 for Legal Document\nRetrieval, our team, 4Huiter, achieved a top-three position. While\ntop-performing teams employed ensemble models and iterative self-training on\nlarge bge-m3 architectures, our lightweight, single-pass approach offered a\ncompetitive alternative with far fewer parameters. The framework demonstrates\nthat optimized data processing, tailored loss functions, and balanced negative\nsampling are pivotal for building robust retrieval-augmented systems in legal\ncontexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\u63d0\u5347\u6cd5\u5f8b\u6587\u6863\u68c0\u7d22\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u5728\u7ade\u8d5b\u83b7\u4f73\u7ee9\uff0c\u8bc1\u660e\u4f18\u5316\u6570\u636e\u5904\u7406\u7b49\u5bf9\u6784\u5efa\u6cd5\u5f8b\u68c0\u7d22\u589e\u5f3a\u7cfb\u7edf\u5f88\u5173\u952e\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u7b49\u4e13\u4e1a\u9886\u57df\u9762\u4e34\u6311\u6218\uff0c\u9700\u63d0\u5347\u6cd5\u5f8b\u6587\u6863\u68c0\u7d22\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5148\u4f7f\u7528\u5fae\u8c03\u7684Bi - Encoder\u5feb\u901f\u68c0\u7d22\u5019\u9009\u6587\u6863\uff0c\u518d\u7528Cross - Encoder\u7cbe\u786e\u91cd\u6392\u5e8f\uff0c\u901a\u8fc7\u7b56\u7565\u6027\u8d1f\u4f8b\u6316\u6398\u4f18\u5316\uff0c\u5f15\u5165Exist@m\u6307\u6807\uff0c\u4f7f\u7528\u534a\u786c\u8d1f\u4f8b\u51cf\u8f7b\u8bad\u7ec3\u504f\u5dee\u3002", "result": "\u56e2\u961f\u5728SoICT Hackathon 2024\u6cd5\u5f8b\u6587\u6863\u68c0\u7d22\u7ade\u8d5b\u4e2d\u83b7\u524d\u4e09\u540d\uff0c\u8f7b\u91cf\u7ea7\u5355\u904d\u65b9\u6cd5\u53c2\u6570\u5c11\u4f46\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u4f18\u5316\u6570\u636e\u5904\u7406\u3001\u5b9a\u5236\u635f\u5931\u51fd\u6570\u548c\u5e73\u8861\u8d1f\u91c7\u6837\u5bf9\u6784\u5efa\u6cd5\u5f8b\u68c0\u7d22\u589e\u5f3a\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.15075", "pdf": "https://arxiv.org/pdf/2507.15075", "abs": "https://arxiv.org/abs/2507.15075", "authors": ["Megan Yeo", "Sebastian Nosenzo", "Sichen Shawn Chao", "Ashley Nunes"], "title": "Enumerating the technological viability and climate impact of jet electrification", "categories": ["econ.GN", "q-fin.EC"], "comment": "51 pages, 3 figures", "summary": "Enabling battery technology has not achieved sufficient maturity to\nfacilitate electric flight for all aircraft models across all distances.\nConsequently, existing discourse emphasizes electrifying short haul routes\nusing smaller, lighter aircraft. Does this emphasis have merit. We estimate a\nmodel that addresses this question. Our findings are fourfold. First, we find\nthat current energy density limitations impede short haul electric flight,\nregardless of aircraft model utilized. Second, we document that electrifying\nsmaller, lighter aircraft models serving short haul routes may be particularly\nchallenging as these aircraft require more, not less, acute increases in energy\ndensity. Third, we identify a subset of larger, heavier aircraft as better\ncandidates for electrification and note that doing so could prevent the annual\nrelease of significant amounts of carbon dioxide equivalent. However, we\nobserve that the regional benefits of electrification are highly heterogeneous.\nThe largest emissions benefit is realized in Europe, followed by South America,\nNorth America, Oceania and Africa. Electrification flights originating in Asia\nproduces a net increase in carbon emissions owing to the disproportionate share\nof miles claimed by Asian countries with a more carbon intensive electrical\ngrid. Indian emissions warrant scrutiny, as its emissions contribution most\ndisproportionately exceeds its mileage contribution. The implications of these\nfindings for decarbonization policy are subsequently discussed.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u6a21\u578b\u63a2\u8ba8\u77ed\u9014\u7535\u52a8\u98de\u884c\u53ef\u884c\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u80fd\u91cf\u5bc6\u5ea6\u9650\u5236\u963b\u788d\u5176\u53d1\u5c55\uff0c\u90e8\u5206\u5927\u578b\u98de\u673a\u66f4\u9002\u5408\u7535\u6c14\u5316\uff0c\u4e14\u7535\u6c14\u5316\u7684\u533a\u57df\u6548\u76ca\u5dee\u5f02\u5927\u3002", "motivation": "\u73b0\u6709\u8bba\u8ff0\u5f3a\u8c03\u7528\u5c0f\u578b\u3001\u8f7b\u578b\u98de\u673a\u5b9e\u73b0\u77ed\u9014\u822a\u7ebf\u7535\u6c14\u5316\uff0c\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u8fd9\u79cd\u5f3a\u8c03\u662f\u5426\u5408\u7406\u3002", "method": "\u4f30\u8ba1\u4e00\u4e2a\u6a21\u578b\u6765\u89e3\u51b3\u76f8\u5173\u95ee\u9898\u3002", "result": "1. \u5f53\u524d\u80fd\u91cf\u5bc6\u5ea6\u9650\u5236\u963b\u788d\u77ed\u9014\u7535\u52a8\u98de\u884c\uff1b2. \u5c0f\u578b\u3001\u8f7b\u578b\u98de\u673a\u7535\u6c14\u5316\u66f4\u5177\u6311\u6218\uff1b3. \u90e8\u5206\u5927\u578b\u3001\u91cd\u578b\u98de\u673a\u66f4\u9002\u5408\u7535\u6c14\u5316\uff0c\u53ef\u51cf\u5c11\u5927\u91cf\u4e8c\u6c27\u5316\u78b3\u6392\u653e\uff1b4. \u7535\u6c14\u5316\u7684\u533a\u57df\u6548\u76ca\u5dee\u5f02\u5927\uff0c\u6b27\u6d32\u51cf\u6392\u6548\u76ca\u6700\u5927\uff0c\u4e9a\u6d32\u90e8\u5206\u5730\u533a\u4f1a\u589e\u52a0\u78b3\u6392\u653e\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u7814\u7a76\u7ed3\u679c\u5bf9\u8131\u78b3\u653f\u7b56\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.15737", "pdf": "https://arxiv.org/pdf/2507.15737", "abs": "https://arxiv.org/abs/2507.15737", "authors": ["Felipe Garrido-Lucero", "Rida Laraki"], "title": "General Matching Games", "categories": ["cs.GT"], "comment": null, "summary": "Matching games is a one-to-one two sided market model introduced by\nGarrido-Lucero and Laraki, in which coupled agents' utilities are endogenously\ndetermined as the outcome of a strategic game. They refine the classical\npairwise stability by requiring robustness to renegotiation and provide general\nconditions under which pairwise stable and renegotiation-proof outcomes exist\nas the limit of a deferred acceptance with competitions algorithm together with\na renegotiation process. In this article, we extend their model to a general\nsetting encompassing most of one-to-many matching markets and roommates models\nand specify two frameworks under which core stable and renegotiation-proof\noutcomes exist and can be efficiently computed.", "AI": {"tldr": "\u6587\u7ae0\u5c06Garrido - Lucero\u548cLaraki\u7684\u4e00\u5bf9\u4e00\u53cc\u8fb9\u5e02\u573a\u6a21\u578b\u6269\u5c55\u5230\u5305\u542b\u591a\u6570\u4e00\u5bf9\u591a\u5339\u914d\u5e02\u573a\u548c\u5ba4\u53cb\u6a21\u578b\u7684\u901a\u7528\u8bbe\u7f6e\uff0c\u5e76\u660e\u786e\u4e24\u79cd\u6846\u67b6\u4f7f\u6838\u5fc3\u7a33\u5b9a\u4e14\u6297\u91cd\u65b0\u534f\u5546\u7684\u7ed3\u679c\u5b58\u5728\u5e76\u53ef\u6709\u6548\u8ba1\u7b97\u3002", "motivation": "\u5c06\u539f\u6709\u7684\u4e00\u5bf9\u4e00\u53cc\u8fb9\u5e02\u573a\u6a21\u578b\u6269\u5c55\u5230\u66f4\u901a\u7528\u7684\u8bbe\u7f6e\uff0c\u6db5\u76d6\u66f4\u591a\u5339\u914d\u5e02\u573a\u7c7b\u578b\u3002", "method": "\u5728\u901a\u7528\u8bbe\u7f6e\u4e0b\u6269\u5c55\u539f\u6a21\u578b\uff0c\u5e76\u786e\u5b9a\u4e24\u79cd\u6846\u67b6\u3002", "result": "\u660e\u786e\u4e86\u4e24\u79cd\u6846\u67b6\uff0c\u5728\u8fd9\u4e9b\u6846\u67b6\u4e0b\u6838\u5fc3\u7a33\u5b9a\u548c\u6297\u91cd\u65b0\u534f\u5546\u7684\u7ed3\u679c\u5b58\u5728\u4e14\u53ef\u6709\u6548\u8ba1\u7b97\u3002", "conclusion": "\u8be5\u6269\u5c55\u6a21\u578b\u80fd\u5728\u66f4\u5e7f\u6cdb\u7684\u5339\u914d\u5e02\u573a\u573a\u666f\u4e2d\u786e\u5b9a\u7a33\u5b9a\u4e14\u6297\u91cd\u65b0\u534f\u5546\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.14177", "pdf": "https://arxiv.org/pdf/2507.14177", "abs": "https://arxiv.org/abs/2507.14177", "authors": ["Changcun Huang"], "title": "Understanding Two-Layer Neural Networks with Smooth Activation Functions", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "68T07(Primary), 41A15(Secondary)", "I.2.6; G.1.2"], "comment": null, "summary": "This paper aims to understand the training solution, which is obtained by the\nback-propagation algorithm, of two-layer neural networks whose hidden layer is\ncomposed of the units with smooth activation functions, including the usual\nsigmoid type most commonly used before the advent of ReLUs. The mechanism\ncontains four main principles: construction of Taylor series expansions, strict\npartial order of knots, smooth-spline implementation and smooth-continuity\nrestriction. The universal approximation for arbitrary input dimensionality is\nproved and experimental verification is given, through which the mystery of\n``black box'' of the solution space is largely revealed. The new proofs\nemployed also enrich approximation theory.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u8bad\u7ec3\u89e3\uff0c\u63ed\u793a\u89e3\u7a7a\u95f4\u201c\u9ed1\u7bb1\u201d\u5965\u79d8\u5e76\u4e30\u5bcc\u903c\u8fd1\u7406\u8bba\u3002", "motivation": "\u7406\u89e3\u7531\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5f97\u5230\u7684\u3001\u9690\u85cf\u5c42\u5177\u6709\u5e73\u6ed1\u6fc0\u6d3b\u51fd\u6570\u7684\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u89e3\u3002", "method": "\u8fd0\u7528\u6cf0\u52d2\u7ea7\u6570\u5c55\u5f00\u6784\u9020\u3001\u7ed3\u70b9\u4e25\u683c\u504f\u5e8f\u3001\u5e73\u6ed1\u6837\u6761\u5b9e\u73b0\u548c\u5149\u6ed1\u8fde\u7eed\u6027\u9650\u5236\u56db\u4e2a\u4e3b\u8981\u539f\u7406\u3002", "result": "\u8bc1\u660e\u4e86\u4efb\u610f\u8f93\u5165\u7ef4\u5ea6\u7684\u901a\u7528\u903c\u8fd1\u6027\uff0c\u5e76\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "\u63ed\u793a\u4e86\u89e3\u7a7a\u95f4\u201c\u9ed1\u7bb1\u201d\u5965\u79d8\uff0c\u65b0\u8bc1\u660e\u4e30\u5bcc\u4e86\u903c\u8fd1\u7406\u8bba\u3002"}}
{"id": "2507.14782", "pdf": "https://arxiv.org/pdf/2507.14782", "abs": "https://arxiv.org/abs/2507.14782", "authors": ["Xiaoping Du"], "title": "Uncertainty Quantification for Machine Learning-Based Prediction: A Polynomial Chaos Expansion Approach for Joint Model and Input Uncertainty Propagation", "categories": ["stat.ML", "cs.LG", "math-ph", "math.MP", "stat.CO"], "comment": "This manuscript has been submitted to Multidisciplinary and\n  Structural Optimization", "summary": "Machine learning (ML) surrogate models are increasingly used in engineering\nanalysis and design to replace computationally expensive simulation models,\nsignificantly reducing computational cost and accelerating decision-making\nprocesses. However, ML predictions contain inherent errors, often estimated as\nmodel uncertainty, which is coupled with variability in model inputs.\nAccurately quantifying and propagating these combined uncertainties is\nessential for generating reliable engineering predictions. This paper presents\na robust framework based on Polynomial Chaos Expansion (PCE) to handle joint\ninput and model uncertainty propagation. While the approach applies broadly to\ngeneral ML surrogates, we focus on Gaussian Process regression models, which\nprovide explicit predictive distributions for model uncertainty. By\ntransforming all random inputs into a unified standard space, a PCE surrogate\nmodel is constructed, allowing efficient and accurate calculation of the mean\nand standard deviation of the output. The proposed methodology also offers a\nmechanism for global sensitivity analysis, enabling the accurate quantification\nof the individual contributions of input variables and ML model uncertainty to\nthe overall output variability. This approach provides a computationally\nefficient and interpretable framework for comprehensive uncertainty\nquantification, supporting trustworthy ML predictions in downstream engineering\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8ePCE\u7684\u6846\u67b6\u5904\u7406\u673a\u5668\u5b66\u4e60\u4ee3\u7406\u6a21\u578b\u8f93\u5165\u4e0e\u6a21\u578b\u8054\u5408\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\uff0c\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u8ba1\u7b97\u53ca\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff0c\u652f\u6301\u5de5\u7a0b\u5e94\u7528\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u5b58\u5728\u56fa\u6709\u8bef\u5dee\u4e14\u4e0e\u8f93\u5165\u53d8\u5f02\u6027\u8026\u5408\uff0c\u9700\u51c6\u786e\u91cf\u5316\u548c\u4f20\u64ad\u8054\u5408\u4e0d\u786e\u5b9a\u6027\u4ee5\u751f\u6210\u53ef\u9760\u5de5\u7a0b\u9884\u6d4b\u3002", "method": "\u57fa\u4e8e\u591a\u9879\u5f0f\u6df7\u6c8c\u5c55\u5f00\uff08PCE\uff09\u6784\u5efa\u6846\u67b6\uff0c\u5c06\u968f\u673a\u8f93\u5165\u8f6c\u6362\u5230\u7edf\u4e00\u6807\u51c6\u7a7a\u95f4\u6784\u5efaPCE\u4ee3\u7406\u6a21\u578b\uff0c\u4ee5\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u6a21\u578b\u4e3a\u91cd\u70b9\u3002", "result": "\u80fd\u9ad8\u6548\u51c6\u786e\u8ba1\u7b97\u8f93\u51fa\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u53ef\u8fdb\u884c\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff0c\u91cf\u5316\u8f93\u5165\u53d8\u91cf\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u5bf9\u8f93\u51fa\u53d8\u5f02\u6027\u7684\u8d21\u732e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u5168\u9762\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u652f\u6301\u4e0b\u6e38\u5de5\u7a0b\u5e94\u7528\u4e2d\u53ef\u4fe1\u7684\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u3002"}}
{"id": "2507.15417", "pdf": "https://arxiv.org/pdf/2507.15417", "abs": "https://arxiv.org/abs/2507.15417", "authors": ["Dahoon Lee", "Chenglin Fan", "Euiwoong Lee"], "title": "1.64-Approximation for Chromatic Correlation Clustering via Chromatic Cluster LP", "categories": ["cs.DS"], "comment": null, "summary": "Chromatic Correlation Clustering (CCC) generalizes Correlation Clustering by\nassigning multiple categorical relationships (colors) to edges and imposing\nchromatic constraints on the clusters. Unlike traditional Correlation\nClustering, which only deals with binary $(+/-)$ relationships, CCC captures\nricher relational structures. Despite its importance, improving the\napproximation for CCC has been difficult due to the limitations of standard LP\nrelaxations. We present a randomized $1.64$-approximation algorithm to the CCC\nproblem, significantly improving the previous factor of $2.15$. Our approach\nextends the cluster LP framework to the chromatic setting by introducing a\nchromatic cluster LP relaxation and an rounding algorithm that utilizes both a\ncluster-based and a greedy pivot-based strategy. The analysis bypasses the\nintegrality gap of $2$ for the CCC version of standard LP and highlights the\npotential of the cluster LP framework to address other variants of clustering\nproblems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCCC\u95ee\u9898\u7684\u968f\u673a1.64\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u6539\u8fdb\u4e86\u4e4b\u524d\u76842.15\u8fd1\u4f3c\u56e0\u5b50\uff0c\u62d3\u5c55\u4e86\u805a\u7c7bLP\u6846\u67b6\u3002", "motivation": "CCC\u80fd\u6355\u6349\u66f4\u4e30\u5bcc\u7684\u5173\u7cfb\u7ed3\u6784\uff0c\u4f46\u7531\u4e8e\u6807\u51c6LP\u677e\u5f1b\u7684\u5c40\u9650\u6027\uff0c\u6539\u8fdb\u5176\u8fd1\u4f3c\u7b97\u6cd5\u8f83\u96be\u3002", "method": "\u5f15\u5165\u8272\u805a\u7c7bLP\u677e\u5f1b\u548c\u7ed3\u5408\u57fa\u4e8e\u805a\u7c7b\u4e0e\u57fa\u4e8e\u8d2a\u5a6a\u67a2\u8f74\u7b56\u7565\u7684\u820d\u5165\u7b97\u6cd5\uff0c\u5c06\u805a\u7c7bLP\u6846\u67b6\u62d3\u5c55\u5230\u8272\u8bbe\u7f6e\u3002", "result": "\u5f97\u5230CCC\u95ee\u9898\u7684\u968f\u673a1.64\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u663e\u8457\u6539\u8fdb\u4e4b\u524d\u76842.15\u8fd1\u4f3c\u56e0\u5b50\u3002", "conclusion": "\u7ed5\u8fc7\u4e86\u6807\u51c6LP\u7684CCC\u7248\u672c\u76842\u7684\u6574\u6027\u95f4\u9699\uff0c\u51f8\u663e\u805a\u7c7bLP\u6846\u67b6\u89e3\u51b3\u5176\u4ed6\u805a\u7c7b\u95ee\u9898\u53d8\u4f53\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14372", "pdf": "https://arxiv.org/pdf/2507.14372", "abs": "https://arxiv.org/abs/2507.14372", "authors": ["Albert Chen", "Manas Bundele", "Gaurav Ahlawat", "Patrick Stetz", "Zhitao Wang", "Qiang Fei", "Donghoon Jung", "Audrey Chu", "Bharadwaj Jayaraman", "Ayushi Panth", "Yatin Arora", "Sourav Jain", "Renjith Varma", "Alexey Ilin", "Iuliia Melnychuk", "Chelsea Chueh", "Joyan Sil", "Xiaofeng Wang"], "title": "Text-to-SQL for Enterprise Data Analytics", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.HC"], "comment": "11 pages, 8 figures, Workshop on Agentic AI for Enterprise at KDD '25", "summary": "The introduction of large language models has brought rapid progress on\nText-to-SQL benchmarks, but it is not yet easy to build a working enterprise\nsolution. In this paper, we present insights from building an internal chatbot\nthat enables LinkedIn's product managers, engineers, and operations teams to\nself-serve data insights from a large, dynamic data lake. Our approach features\nthree components. First, we construct a knowledge graph that captures\nup-to-date semantics by indexing database metadata, historical query logs,\nwikis, and code. We apply clustering to identify relevant tables for each team\nor product area. Second, we build a Text-to-SQL agent that retrieves and ranks\ncontext from the knowledge graph, writes a query, and automatically corrects\nhallucinations and syntax errors. Third, we build an interactive chatbot that\nsupports various user intents, from data discovery to query writing to\ndebugging, and displays responses in rich UI elements to encourage follow-up\nchats. Our chatbot has over 300 weekly users. Expert review shows that 53% of\nits responses are correct or close to correct on an internal benchmark set.\nThrough ablation studies, we identify the most important knowledge graph and\nmodeling components, offering a practical path for developing enterprise\nText-to-SQL solutions.", "AI": {"tldr": "\u4ecb\u7ecd\u6784\u5efa\u5185\u90e8\u804a\u5929\u673a\u5668\u4eba\u5b9e\u73b0\u4f01\u4e1aText - to - SQL\u7684\u65b9\u6848\u53ca\u6210\u679c\uff0c\u6307\u51fa\u5f00\u53d1\u4f01\u4e1a\u89e3\u51b3\u65b9\u6848\u7684\u5b9e\u7528\u8def\u5f84\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u4f7fText - to - SQL\u57fa\u51c6\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u6784\u5efa\u4f01\u4e1a\u89e3\u51b3\u65b9\u6848\u4ecd\u4e0d\u6613\uff0c\u8981\u4e3aLinkedIn\u56e2\u961f\u63d0\u4f9b\u81ea\u52a9\u6570\u636e\u6d1e\u5bdf\u670d\u52a1\u3002", "method": "\u6784\u5efa\u6355\u83b7\u6700\u65b0\u8bed\u4e49\u7684\u77e5\u8bc6\u56fe\u8c31\u5e76\u805a\u7c7b\uff1b\u6784\u5efaText - to - SQL\u4ee3\u7406\u6765\u68c0\u7d22\u4e0a\u4e0b\u6587\u3001\u5199\u67e5\u8be2\u53ca\u7ea0\u9519\uff1b\u6784\u5efa\u652f\u6301\u591a\u79cd\u7528\u6237\u610f\u56fe\u7684\u4ea4\u4e92\u5f0f\u804a\u5929\u673a\u5668\u4eba\u3002", "result": "\u804a\u5929\u673a\u5668\u4eba\u6bcf\u5468\u8d85300\u7528\u6237\uff0c\u5185\u90e8\u57fa\u51c6\u96c6\u4e0a53%\u7684\u56de\u590d\u6b63\u786e\u6216\u63a5\u8fd1\u6b63\u786e\u3002", "conclusion": "\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u786e\u5b9a\u91cd\u8981\u7ec4\u4ef6\uff0c\u4e3a\u5f00\u53d1\u4f01\u4e1aText - to - SQL\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2507.15154", "pdf": "https://arxiv.org/pdf/2507.15154", "abs": "https://arxiv.org/abs/2507.15154", "authors": ["Kohya Shiozaki", "Junya Nakamura"], "title": "Dynatune: Dynamic Tuning of Raft Election Parameters Using Network Measurement", "categories": ["cs.DC"], "comment": "This paper was accepted at the 27th International Workshop on\n  Advances in Parallel and Distributed Computational Models (APDCM 2025), held\n  in conjunction with IPDPS 2025", "summary": "Raft is a leader-based consensus algorithm that implements State Machine\nReplication (SMR), which replicates the service state across multiple servers\nto enhance fault tolerance. In Raft, the servers play one of three roles:\nleader, follower, or candidate. The leader receives client requests, determines\nthe processing order, and replicates them to the followers. When the leader\nfails, the service must elect a new leader to continue processing requests,\nduring which the service experiences an out-of-service (OTS) time. The OTS time\nis directly influenced by election parameters, such as heartbeat interval and\nelection timeout. However, traditional approaches, such as Raft, often struggle\nto effectively tune these parameters, particularly under fluctuating network\nconditions, leading to increased OTS time and reduced service responsiveness.\nTo address this, we propose Dynatune, a mechanism that dynamically adjusts\nRaft's election parameters based on network metrics such as round-trip time and\npacket loss rates measured via heartbeats. By adapting to changing network\nenvironments, Dynatune significantly reduces the leader failure detection and\nOTS time without altering Raft's core mechanisms or introducing additional\ncommunication overheads. Experimental results demonstrate that Dynatune reduces\nthe leader failure detection and OTS times by 80% and 45%, respectively,\ncompared with Raft, while maintaining high availability even under dynamic\nnetwork conditions. These findings confirm that Dynatune effectively enhances\nthe performance and reliability of SMR services in various network scenarios.", "AI": {"tldr": "\u63d0\u51faDynatune\u673a\u5236\u52a8\u6001\u8c03\u6574Raft\u9009\u4e3e\u53c2\u6570\uff0c\u51cf\u5c11\u6545\u969c\u68c0\u6d4b\u548cOTS\u65f6\u95f4\uff0c\u63d0\u5347\u670d\u52a1\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edfRaft\u7b97\u6cd5\u96be\u5728\u7f51\u7edc\u6ce2\u52a8\u65f6\u6709\u6548\u8c03\u6574\u9009\u4e3e\u53c2\u6570\uff0c\u5bfc\u81f4OTS\u65f6\u95f4\u589e\u52a0\u548c\u670d\u52a1\u54cd\u5e94\u6027\u964d\u4f4e\u3002", "method": "\u63d0\u51faDynatune\u673a\u5236\uff0c\u57fa\u4e8e\u7f51\u7edc\u6307\u6807\uff08\u5982\u5f80\u8fd4\u65f6\u95f4\u3001\u4e22\u5305\u7387\uff09\u52a8\u6001\u8c03\u6574Raft\u9009\u4e3e\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDynatune\u8f83Raft\u51cf\u5c1180%\u7684\u9886\u5bfc\u8005\u6545\u969c\u68c0\u6d4b\u65f6\u95f4\u548c45%\u7684OTS\u65f6\u95f4\uff0c\u5728\u52a8\u6001\u7f51\u7edc\u4e0b\u4fdd\u6301\u9ad8\u53ef\u7528\u6027\u3002", "conclusion": "Dynatune\u80fd\u6709\u6548\u63d0\u5347\u4e0d\u540c\u7f51\u7edc\u573a\u666f\u4e0bSMR\u670d\u52a1\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2507.14393", "pdf": "https://arxiv.org/pdf/2507.14393", "abs": "https://arxiv.org/abs/2507.14393", "authors": ["Humza Sami", "Mubashir ul Islam", "Pierre-Emmanuel Gaillardon", "Valerio Tenace"], "title": "Adaptive Multi-Agent Reasoning via Automated Workflow Generation", "categories": ["cs.AI"], "comment": null, "summary": "The rise of Large Reasoning Models (LRMs) promises a significant leap forward\nin language model capabilities, aiming to tackle increasingly sophisticated\ntasks with unprecedented efficiency and accuracy. However, despite their\nimpressive performance, recent studies have highlighted how current reasoning\nmodels frequently fail to generalize to novel, unseen problems, often resorting\nto memorized solutions rather than genuine inferential reasoning. Such behavior\nunderscores a critical limitation in modern LRMs, i.e., their tendency toward\noverfitting, which in turn results in poor generalization in problem-solving\ncapabilities.\n  In this paper, we introduce Nexus Architect, an enhanced iteration of our\nmulti-agent system framework, Nexus, equipped with a novel automated workflow\nsynthesis mechanism. Given a user's prompt and a small set of representative\nexamples, the Architect autonomously generates a tailored reasoning workflow by\nselecting suitable strategies, tool integrations, and adversarial techniques\nfor a specific problem class. Furthermore, the Architect includes an iterative\nprompt refinement mechanism that fine-tunes agents' system prompts to maximize\nperformance and improve the generalization capabilities of the system.\n  We empirically evaluate Nexus Architect by employing an off-the-shelf,\nnon-reasoning model on a custom dataset of challenging logical questions and\ncompare its performance against state-of-the-art LRMs. Results show that Nexus\nArchitect consistently outperforms existing solutions, achieving up to a 66%\nincrease in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\\times$ against\nClaude Sonnet 4 and DeepSeek-R1, and over 3$\\times$ w.r.t. Llama 4 Scout.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u63a8\u7406\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u63d0\u51faNexus Architect\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5927\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u65b0\u95ee\u9898\u3002", "method": "\u5f15\u5165Nexus Architect\uff0c\u5177\u5907\u81ea\u52a8\u5de5\u4f5c\u6d41\u5408\u6210\u673a\u5236\u548c\u8fed\u4ee3\u63d0\u793a\u7ec6\u5316\u673a\u5236\uff0c\u53ef\u6839\u636e\u7528\u6237\u63d0\u793a\u548c\u793a\u4f8b\u751f\u6210\u5b9a\u5236\u63a8\u7406\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u903b\u8f91\u95ee\u9898\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\uff0cNexus Architect\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7387\u76f8\u6bd4Gemini 2.5 Flash Preview\u63d0\u9ad8\u8fbe66%\uff0c\u6bd4Claude Sonnet 4\u548cDeepSeek - R1\u9ad8\u8fd12.5\u500d\uff0c\u6bd4Llama 4 Scout\u9ad83\u500d\u591a\u3002", "conclusion": "Nexus Architect\u80fd\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u6bd4\u73b0\u6709\u5927\u63a8\u7406\u6a21\u578b\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2507.14558", "pdf": "https://arxiv.org/pdf/2507.14558", "abs": "https://arxiv.org/abs/2507.14558", "authors": ["Bin Duan", "Tarek Mahmud", "Meiru Che", "Yan Yan", "Naipeng Dong", "Dan Dongseong Kim", "Guowei Yang"], "title": "Harnessing LLMs for Document-Guided Fuzzing of OpenCV Library", "categories": ["cs.SE"], "comment": null, "summary": "The combination of computer vision and artificial intelligence is\nfundamentally transforming a broad spectrum of industries by enabling machines\nto interpret and act upon visual data with high levels of accuracy. As the\nbiggest and by far the most popular open-source computer vision library, OpenCV\nlibrary provides an extensive suite of programming functions supporting\nreal-time computer vision. Bugs in the OpenCV library can affect the downstream\ncomputer vision applications, and it is critical to ensure the reliability of\nthe OpenCV library. This paper introduces VISTAFUZZ, a novel technique for\nharnessing large language models (LLMs) for document-guided fuzzing of the\nOpenCV library. VISTAFUZZ utilizes LLMs to parse API documentation and obtain\nstandardized API information. Based on this standardized information, VISTAFUZZ\nextracts constraints on individual input parameters and dependencies between\nthese. Using these constraints and dependencies, VISTAFUZZ then generates new\ninput values to systematically test each target API. We evaluate the\neffectiveness of VISTAFUZZ in testing 330 APIs in the OpenCV library, and the\nresults show that VISTAFUZZ detected 17 new bugs, where 10 bugs have been\nconfirmed, and 5 of these have been fixed.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5bf9OpenCV\u5e93\u8fdb\u884c\u6587\u6863\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5\u7684\u65b0\u6280\u672fVISTAFUZZ\uff0c\u7ecf\u6d4b\u8bd5\u53d1\u73b017\u4e2a\u65b0\u6f0f\u6d1e\u3002", "motivation": "OpenCV\u5e93\u4e2d\u7684\u6f0f\u6d1e\u4f1a\u5f71\u54cd\u4e0b\u6e38\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\uff0c\u9700\u786e\u4fdd\u5176\u53ef\u9760\u6027\u3002", "method": "VISTAFUZZ\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u6790API\u6587\u6863\u83b7\u53d6\u6807\u51c6\u5316\u4fe1\u606f\uff0c\u63d0\u53d6\u8f93\u5165\u53c2\u6570\u7ea6\u675f\u548c\u4f9d\u8d56\u5173\u7cfb\uff0c\u751f\u6210\u65b0\u8f93\u5165\u503c\u6d4b\u8bd5API\u3002", "result": "\u5bf9OpenCV\u5e93330\u4e2aAPI\u6d4b\u8bd5\uff0c\u68c0\u6d4b\u523017\u4e2a\u65b0\u6f0f\u6d1e\uff0c10\u4e2a\u5df2\u786e\u8ba4\uff0c5\u4e2a\u5df2\u4fee\u590d\u3002", "conclusion": "VISTAFUZZ\u80fd\u6709\u6548\u68c0\u6d4bOpenCV\u5e93\u4e2d\u7684\u6f0f\u6d1e\u3002"}}
{"id": "2507.14902", "pdf": "https://arxiv.org/pdf/2507.14902", "abs": "https://arxiv.org/abs/2507.14902", "authors": ["Xiaojie Li", "Chu Li", "Shi-Zhe Chen", "Xi Chen"], "title": "U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs", "categories": ["cs.IR", "cs.CV"], "comment": "Technical Report (in progress)", "summary": "Universal multimodal retrieval (UMR), which aims to address complex retrieval\ntasks where both queries and candidates span diverse modalities, has been\nsignificantly advanced by the emergence of MLLMs. While state-of-the-art\nMLLM-based methods in the literature predominantly adopt contrastive learning\nprinciples, they often differ in their specific training recipes. Despite their\nsuccess, the mechanisms underlying their retrieval capabilities remain largely\nunexplored, potentially resulting in suboptimal performance and limited\ngeneralization ability. To address these issues, we present a comprehensive\nstudy aimed at uncovering the key factors that drive effective embedding\nlearning for UMR using MLLMs. We begin by implementing a general MLLM-based\nembedding learning pipeline, and systematically analyze the primary\ncontributors to high-performing universal retrieval systems. Based on this, we\nexplore various aspects of the details in embedding generation and training\nstrategies, including progressive transition, hard negative mining and\nre-ranker distillation. Notably, our findings reveal that often-overlooked\nfactors can have a substantial impact on model performance. Building on these\ndiscoveries, we introduce a unified framework termed U-MARVEL\n(\\textbf{U}niversal \\textbf{M}ultimod\\textbf{A}l \\textbf{R}etrie\\textbf{V}al\nvia \\textbf{E}mbedding \\textbf{L}earning), which outperforms state-of-the-art\ncompetitors on the M-BEIR benchmark by a large margin in supervised settings,\nand also exihibits strong zero-shot performance on several tasks such as\ncomposed image retrieval and text-to-video retrieval. These results underscore\nthe generalization potential of our framework across various embedding-based\nretrieval tasks. Code is available at https://github.com/chaxjli/U-MARVEL", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8eMLLM\u7684\u901a\u7528\u591a\u6a21\u6001\u68c0\u7d22\uff08UMR\uff09\u5d4c\u5165\u5b66\u4e60\u8fdb\u884c\u7814\u7a76\uff0c\u63d0\u51faU - MARVEL\u6846\u67b6\uff0c\u5728\u76d1\u7763\u8bbe\u7f6e\u548c\u96f6\u6837\u672c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eMLLM\u7684UMR\u65b9\u6cd5\u68c0\u7d22\u673a\u5236\u672a\u5145\u5206\u63a2\u7d22\uff0c\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u548c\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u7814\u7a76\u6709\u6548\u5d4c\u5165\u5b66\u4e60\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u5b9e\u73b0\u901a\u7528MLLM\u5d4c\u5165\u5b66\u4e60\u6d41\u7a0b\uff0c\u7cfb\u7edf\u5206\u6790\u9ad8\u6548\u68c0\u7d22\u7cfb\u7edf\u7684\u4e3b\u8981\u8d21\u732e\u56e0\u7d20\uff0c\u63a2\u7d22\u5d4c\u5165\u751f\u6210\u548c\u8bad\u7ec3\u7b56\u7565\u7684\u7ec6\u8282\uff0c\u63d0\u51faU - MARVEL\u6846\u67b6\u3002", "result": "U - MARVEL\u6846\u67b6\u5728M - BEIR\u57fa\u51c6\u4e0a\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u548c\u6587\u672c\u5230\u89c6\u9891\u68c0\u7d22\u7b49\u96f6\u6837\u672c\u4efb\u52a1\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "U - MARVEL\u6846\u67b6\u5728\u5404\u79cd\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u4efb\u52a1\u4e2d\u5177\u6709\u6cdb\u5316\u6f5c\u529b\u3002"}}
{"id": "2507.15439", "pdf": "https://arxiv.org/pdf/2507.15439", "abs": "https://arxiv.org/abs/2507.15439", "authors": ["Marius Protte", "Behnud Mir Djawadi"], "title": "Human vs. Algorithmic Auditors: The Impact of Entity Type and Ambiguity on Human Dishonesty", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "While most of the existing literature focused on human-machine interactions\nwith algorithmic systems in advisory roles, research on human behavior in\nmonitoring or verification processes that are conducted by automated systems\nremains largely absent. Our study examines how human dishonesty changes when\ndetection of untrue statements is performed by machines versus humans, and how\nambiguity in the verification process influences dishonest behavior. We design\nan incentivized laboratory experiment using a modified die-roll paradigm where\nparticipants privately observe a random draw and report the result, with higher\nreported numbers yielding greater monetary rewards. A probabilistic\nverification process introduces risk of detection and punishment, with\ntreatments varying by verification entity (human vs. machine) and degree of\nambiguity in the verification process (transparent vs. ambiguous). Our results\nshow that under transparent verification rules, cheating magnitude does not\nsignificantly differ between human and machine auditors. However, under\nambiguous conditions, cheating magnitude is significantly higher when machines\nverify participants' reports, reducing the prevalence of partial cheating while\nleading to behavioral polarization manifested as either complete honesty or\nmaximal overreporting. The same applies when comparing reports to a machine\nentity under ambiguous and transparent verification rules. These findings\nemphasize the behavioral implications of algorithmic opacity in verification\ncontexts. While machines can serve as effective and cost-efficient auditors\nunder transparent conditions, their black box nature combined with ambiguous\nverification processes may unintentionally incentivize more severe dishonesty.\nThese insights have practical implications for designing automated oversight\nsystems in tax audits, compliance, and workplace monitoring.", "AI": {"tldr": "\u7814\u7a76\u4eba\u7c7b\u5728\u673a\u5668\u548c\u4eba\u7c7b\u9a8c\u8bc1\u4e0d\u8bda\u5b9e\u9648\u8ff0\u65f6\u7684\u4e0d\u8bda\u5b9e\u884c\u4e3a\u53d8\u5316\uff0c\u4ee5\u53ca\u9a8c\u8bc1\u8fc7\u7a0b\u7684\u6a21\u7cca\u6027\u5bf9\u4e0d\u8bda\u5b9e\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u900f\u660e\u89c4\u5219\u4e0b\u4eba\u673a\u5ba1\u6838\u4f5c\u5f0a\u7a0b\u5ea6\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u6a21\u7cca\u6761\u4ef6\u4e0b\u673a\u5668\u9a8c\u8bc1\u4f5c\u5f0a\u66f4\u4e25\u91cd\uff0c\u5f3a\u8c03\u7b97\u6cd5\u4e0d\u900f\u660e\u7684\u884c\u4e3a\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u591a\u5173\u6ce8\u4eba\u673a\u4ea4\u4e92\u4e2d\u7b97\u6cd5\u7cfb\u7edf\u7684\u54a8\u8be2\u89d2\u8272\uff0c\u7f3a\u4e4f\u5bf9\u81ea\u52a8\u5316\u7cfb\u7edf\u76d1\u63a7\u6216\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u4eba\u7c7b\u884c\u4e3a\u7684\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u673a\u5668\u4e0e\u4eba\u7c7b\u68c0\u6d4b\u4e0d\u8bda\u5b9e\u9648\u8ff0\u65f6\u4eba\u7c7b\u4e0d\u8bda\u5b9e\u884c\u4e3a\u7684\u53d8\u5316\uff0c\u4ee5\u53ca\u9a8c\u8bc1\u8fc7\u7a0b\u6a21\u7cca\u6027\u5bf9\u4e0d\u8bda\u5b9e\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u8bbe\u8ba1\u6fc0\u52b1\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\uff0c\u91c7\u7528\u4fee\u6539\u7684\u63b7\u9ab0\u5b50\u8303\u5f0f\uff0c\u53c2\u4e0e\u8005\u79c1\u4e0b\u89c2\u5bdf\u968f\u673a\u7ed3\u679c\u5e76\u62a5\u544a\uff0c\u8bbe\u7f6e\u4e0d\u540c\u9a8c\u8bc1\u5b9e\u4f53\uff08\u4eba vs \u673a\u5668\uff09\u548c\u9a8c\u8bc1\u8fc7\u7a0b\u6a21\u7cca\u7a0b\u5ea6\uff08\u900f\u660e vs \u6a21\u7cca\uff09\u7684\u5904\u7406\u7ec4\u3002", "result": "\u900f\u660e\u9a8c\u8bc1\u89c4\u5219\u4e0b\uff0c\u4eba\u673a\u5ba1\u6838\u4f5c\u5f0a\u7a0b\u5ea6\u65e0\u663e\u8457\u5dee\u5f02\uff1b\u6a21\u7cca\u6761\u4ef6\u4e0b\uff0c\u673a\u5668\u9a8c\u8bc1\u65f6\u4f5c\u5f0a\u7a0b\u5ea6\u663e\u8457\u66f4\u9ad8\uff0c\u51cf\u5c11\u90e8\u5206\u4f5c\u5f0a\uff0c\u5bfc\u81f4\u884c\u4e3a\u4e24\u6781\u5206\u5316\uff1b\u6bd4\u8f83\u6a21\u7cca\u548c\u900f\u660e\u89c4\u5219\u4e0b\u5411\u673a\u5668\u5b9e\u4f53\u62a5\u544a\u7684\u60c5\u51b5\u4e5f\u662f\u5982\u6b64\u3002", "conclusion": "\u7b97\u6cd5\u4e0d\u900f\u660e\u5728\u9a8c\u8bc1\u573a\u666f\u4e2d\u6709\u884c\u4e3a\u5f71\u54cd\uff0c\u900f\u660e\u6761\u4ef6\u4e0b\u673a\u5668\u53ef\u4f5c\u4e3a\u6709\u6548\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5ba1\u6838\u8005\uff0c\u4f46\u5176\u9ed1\u7bb1\u6027\u8d28\u4e0e\u6a21\u7cca\u9a8c\u8bc1\u8fc7\u7a0b\u53ef\u80fd\u4f1a\u610f\u5916\u6fc0\u52b1\u66f4\u4e25\u91cd\u7684\u4e0d\u8bda\u5b9e\u884c\u4e3a\uff0c\u5bf9\u7a0e\u52a1\u5ba1\u8ba1\u3001\u5408\u89c4\u548c\u804c\u573a\u76d1\u63a7\u7b49\u81ea\u52a8\u5316\u76d1\u7763\u7cfb\u7edf\u8bbe\u8ba1\u6709\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2507.14470", "pdf": "https://arxiv.org/pdf/2507.14470", "abs": "https://arxiv.org/abs/2507.14470", "authors": ["Yifan Huang", "Dong Hao", "Zhiyi Fan", "Yuhang Guo", "Bin Li"], "title": "Approximate Revenue Maximization for Diffusion Auctions", "categories": ["econ.TH", "cs.AI", "cs.GT", "cs.MA"], "comment": null, "summary": "Reserve prices are widely used in practice. The problem of designing\nrevenue-optimal auctions based on reserve price has drawn much attention in the\nauction design community. Although they have been extensively studied, most\ndevelopments rely on the significant assumption that the target audience of the\nsale is directly reachable by the auctioneer, while a large portion of bidders\nin the economic network unaware of the sale are omitted. This work follows the\ndiffusion auction design, which aims to extend the target audience of optimal\nauction theory to all entities in economic networks. We investigate the design\nof simple and provably near-optimal network auctions via reserve price. Using\nBayesian approximation analysis, we provide a simple and explicit form of the\nreserve price function tailored to the most representative network auction. We\naim to balance setting a sufficiently high reserve price to induce high revenue\nin a successful sale, and attracting more buyers from the network to increase\nthe probability of a successful sale. This reserve price function preserves\nincentive compatibility for network auctions, allowing the seller to extract\nadditional revenue beyond that achieved by the Myerson optimal auction.\nSpecifically, if the seller has $\\rho$ direct neighbours in a network of size\n$n$, this reserve price guarantees a $1-{1 \\over \\rho}$ approximation to the\ntheoretical upper bound, i.e., the maximum possible revenue from any network of\nsize $n$. This result holds for any size and any structure of the networked\nmarket.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u6269\u6563\u62cd\u5356\u8bbe\u8ba1\uff0c\u7814\u7a76\u901a\u8fc7\u4fdd\u7559\u4ef7\u683c\u8bbe\u8ba1\u7b80\u5355\u4e14\u63a5\u8fd1\u6700\u4f18\u7684\u7f51\u7edc\u62cd\u5356\uff0c\u7ed9\u51fa\u4fdd\u7559\u4ef7\u683c\u51fd\u6570\uff0c\u80fd\u4fdd\u8bc1\u8fd1\u4f3c\u7406\u8bba\u4e0a\u9650\u6536\u76ca\u3002", "motivation": "\u4ee5\u5f80\u57fa\u4e8e\u4fdd\u7559\u4ef7\u683c\u7684\u6700\u4f18\u62cd\u5356\u8bbe\u8ba1\u5927\u591a\u5047\u8bbe\u62cd\u5356\u8005\u53ef\u76f4\u63a5\u89e6\u8fbe\u76ee\u6807\u53d7\u4f17\uff0c\u5ffd\u7565\u4e86\u7ecf\u6d4e\u7f51\u7edc\u4e2d\u5927\u91cf\u672a\u5bdf\u89c9\u62cd\u5356\u7684\u6295\u6807\u4eba\uff0c\u672c\u6587\u65e8\u5728\u5c06\u6700\u4f18\u62cd\u5356\u7406\u8bba\u7684\u76ee\u6807\u53d7\u4f17\u6269\u5c55\u5230\u7ecf\u6d4e\u7f51\u7edc\u4e2d\u7684\u6240\u6709\u5b9e\u4f53\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u8fd1\u4f3c\u5206\u6790\uff0c\u4e3a\u6700\u5177\u4ee3\u8868\u6027\u7684\u7f51\u7edc\u62cd\u5356\u91cf\u8eab\u5b9a\u5236\u4fdd\u7559\u4ef7\u683c\u51fd\u6570\u3002", "result": "\u8be5\u4fdd\u7559\u4ef7\u683c\u51fd\u6570\u4fdd\u6301\u4e86\u7f51\u7edc\u62cd\u5356\u7684\u6fc0\u52b1\u76f8\u5bb9\u6027\uff0c\u82e5\u5356\u5bb6\u5728\u89c4\u6a21\u4e3an\u7684\u7f51\u7edc\u4e2d\u6709\u03c1\u4e2a\u76f4\u63a5\u90bb\u5c45\uff0c\u6b64\u4fdd\u7559\u4ef7\u683c\u80fd\u4fdd\u8bc1\u8fbe\u5230\u7406\u8bba\u4e0a\u9650\u6536\u76ca\u76841 - 1/\u03c1\u8fd1\u4f3c\u3002", "conclusion": "\u6b64\u4fdd\u7559\u4ef7\u683c\u51fd\u6570\u9002\u7528\u4e8e\u4efb\u4f55\u89c4\u6a21\u548c\u7ed3\u6784\u7684\u7f51\u7edc\u5e02\u573a\uff0c\u80fd\u8ba9\u5356\u5bb6\u63d0\u53d6\u8d85\u51fa\u8fc8\u5c14\u68ee\u6700\u4f18\u62cd\u5356\u7684\u989d\u5916\u6536\u76ca\u3002"}}
{"id": "2507.14178", "pdf": "https://arxiv.org/pdf/2507.14178", "abs": "https://arxiv.org/abs/2507.14178", "authors": ["Yuhang Liu", "Yuefei Wu", "Bin Shi", "Bo Dong"], "title": "Feature Bank Enhancement for Distance-based Out-of-Distribution Detection", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 5 figures", "summary": "Out-of-distribution (OOD) detection is critical to ensuring the reliability\nof deep learning applications and has attracted significant attention in recent\nyears. A rich body of literature has emerged to develop efficient score\nfunctions that assign high scores to in-distribution (ID) samples and low\nscores to OOD samples, thereby helping distinguish OOD samples. Among these\nmethods, distance-based score functions are widely used because of their\nefficiency and ease of use. However, deep learning often leads to a biased\ndistribution of data features, and extreme features are inevitable. These\nextreme features make the distance-based methods tend to assign too low scores\nto ID samples. This limits the OOD detection capabilities of such methods. To\naddress this issue, we propose a simple yet effective method, Feature Bank\nEnhancement (FBE), that uses statistical characteristics from dataset to\nidentify and constrain extreme features to the separation boundaries, therapy\nmaking the distance between samples inside and outside the distribution\nfarther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10\nrespectively, and the results show that our method achieves state-of-the-art\nperformance on both benchmark. Additionally, theoretical analysis and\nsupplementary experiments are conducted to provide more insights into our\nmethod.", "AI": {"tldr": "\u63d0\u51faFeature Bank Enhancement (FBE)\u65b9\u6cd5\u89e3\u51b3\u8ddd\u79bb\u57fa\u65b9\u6cd5\u5728OOD\u68c0\u6d4b\u4e2d\u5bf9ID\u6837\u672c\u6253\u5206\u8fc7\u4f4e\u95ee\u9898\uff0c\u5728ImageNet - 1k\u548cCIFAR - 10\u4e0a\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u8ddd\u79bb\u57fa\u5206\u6570\u51fd\u6570\u5728OOD\u68c0\u6d4b\u4e2d\uff0c\u56e0\u6df1\u5ea6\u5b66\u4e60\u5bfc\u81f4\u7684\u6570\u636e\u7279\u5f81\u5206\u5e03\u504f\u5dee\u548c\u6781\u7aef\u7279\u5f81\uff0c\u4f7f\u5bf9ID\u6837\u672c\u6253\u5206\u8fc7\u4f4e\uff0c\u9650\u5236\u4e86OOD\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51faFeature Bank Enhancement (FBE)\u65b9\u6cd5\uff0c\u5229\u7528\u6570\u636e\u96c6\u7edf\u8ba1\u7279\u5f81\u8bc6\u522b\u6781\u7aef\u7279\u5f81\u5e76\u5c06\u5176\u7ea6\u675f\u5230\u5206\u79bb\u8fb9\u754c\u3002", "result": "\u5728ImageNet - 1k\u548cCIFAR - 10\u4e0a\u5b9e\u9a8c\uff0c\u65b9\u6cd5\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u8fd8\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u548c\u8865\u5145\u5b9e\u9a8c\u3002", "conclusion": "FBE\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8ddd\u79bb\u57fa\u65b9\u6cd5\u5728OOD\u68c0\u6d4b\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.14901", "pdf": "https://arxiv.org/pdf/2507.14901", "abs": "https://arxiv.org/abs/2507.14901", "authors": ["Armin Keki\u0107", "Jan Schneider", "Dieter B\u00fcchler", "Bernhard Sch\u00f6lkopf", "Michel Besserve"], "title": "Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Why do reinforcement learning (RL) policies fail or succeed? This is a\nchallenging question due to the complex, high-dimensional nature of\nagent-environment interactions. In this work, we take a causal perspective on\nexplaining the behavior of RL policies by viewing the states, actions, and\nrewards as variables in a low-level causal model. We introduce random\nperturbations to policy actions during execution and observe their effects on\nthe cumulative reward, learning a simplified high-level causal model that\nexplains these relationships. To this end, we develop a nonlinear Causal Model\nReduction framework that ensures approximate interventional consistency,\nmeaning the simplified high-level model responds to interventions in a similar\nway as the original complex system. We prove that for a class of nonlinear\ncausal models, there exists a unique solution that achieves exact\ninterventional consistency, ensuring learned explanations reflect meaningful\ncausal patterns. Experiments on both synthetic causal models and practical RL\ntasks-including pendulum control and robot table tennis-demonstrate that our\napproach can uncover important behavioral patterns, biases, and failure modes\nin trained RL policies.", "AI": {"tldr": "\u672c\u6587\u4ece\u56e0\u679c\u89d2\u5ea6\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u884c\u4e3a\uff0c\u5f15\u5165\u968f\u673a\u6270\u52a8\u5b66\u4e60\u7b80\u5316\u56e0\u679c\u6a21\u578b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u63ed\u793a\u7b56\u7565\u7684\u91cd\u8981\u6a21\u5f0f\u548c\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u7531\u4e8e\u667a\u80fd\u4f53 - \u73af\u5883\u4ea4\u4e92\u590d\u6742\u9ad8\u7ef4\uff0c\u96be\u4ee5\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u6210\u8d25\u539f\u56e0\uff0c\u56e0\u6b64\u4ece\u56e0\u679c\u89d2\u5ea6\u8fdb\u884c\u89e3\u91ca\u3002", "method": "\u5c06\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u5956\u52b1\u89c6\u4e3a\u4f4e\u5c42\u6b21\u56e0\u679c\u6a21\u578b\u53d8\u91cf\uff0c\u5728\u6267\u884c\u7b56\u7565\u52a8\u4f5c\u65f6\u5f15\u5165\u968f\u673a\u6270\u52a8\u89c2\u5bdf\u5bf9\u7d2f\u79ef\u5956\u52b1\u7684\u5f71\u54cd\uff0c\u5f00\u53d1\u975e\u7ebf\u6027\u56e0\u679c\u6a21\u578b\u7b80\u5316\u6846\u67b6\u786e\u4fdd\u8fd1\u4f3c\u5e72\u9884\u4e00\u81f4\u6027\uff0c\u5e76\u8bc1\u660e\u4e00\u7c7b\u975e\u7ebf\u6027\u56e0\u679c\u6a21\u578b\u5b58\u5728\u7cbe\u786e\u5e72\u9884\u4e00\u81f4\u6027\u7684\u552f\u4e00\u89e3\u3002", "result": "\u5728\u5408\u6210\u56e0\u679c\u6a21\u578b\u548c\u5b9e\u9645\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\uff08\u5982\u949f\u6446\u63a7\u5236\u548c\u673a\u5668\u4eba\u4e52\u4e53\u7403\uff09\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u63ed\u793a\u8bad\u7ec3\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4e2d\u7684\u91cd\u8981\u884c\u4e3a\u6a21\u5f0f\u3001\u504f\u5dee\u548c\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u4ece\u56e0\u679c\u89d2\u5ea6\u6709\u6548\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u91cd\u8981\u6a21\u5f0f\u548c\u5931\u8d25\u539f\u56e0\u3002"}}
{"id": "2507.15802", "pdf": "https://arxiv.org/pdf/2507.15802", "abs": "https://arxiv.org/abs/2507.15802", "authors": ["R\u00e9mi Vaucher", "Paul Minchella"], "title": "Hypergraphs on high dimensional time series sets using signature transform", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "Accepted at GSI25 conference. Pending publication in Springer\n  proceedings", "summary": "In recent decades, hypergraphs and their analysis through Topological Data\nAnalysis (TDA) have emerged as powerful tools for understanding complex data\nstructures. Various methods have been developed to construct hypergraphs --\nreferred to as simplicial complexes in the TDA framework -- over datasets,\nenabling the formation of edges between more than two vertices. This paper\naddresses the challenge of constructing hypergraphs from collections of\nmultivariate time series. While prior work has focused on the case of a single\nmultivariate time series, we extend this framework to handle collections of\nsuch time series. Our approach generalizes the method proposed in Chretien and\nal. by leveraging the properties of signature transforms to introduce\ncontrolled randomness, thereby enhancing the robustness of the construction\nprocess. We validate our method on synthetic datasets and present promising\nresults.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4ece\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u96c6\u5408\u6784\u5efa\u8d85\u56fe\u7684\u6311\u6218\uff0c\u6269\u5c55\u73b0\u6709\u6846\u67b6\uff0c\u5229\u7528\u7b7e\u540d\u53d8\u6362\u5c5e\u6027\u5f15\u5165\u968f\u673a\u63a7\u5236\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u826f\u597d\u7ed3\u679c\u3002", "motivation": "\u4ee5\u5f80\u5de5\u4f5c\u805a\u7126\u5355\u4e2a\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6784\u5efa\u8d85\u56fe\uff0c\u672c\u6587\u65e8\u5728\u6269\u5c55\u6846\u67b6\u4ee5\u5904\u7406\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u96c6\u5408\u3002", "method": "\u63a8\u5e7fChretien\u7b49\u4eba\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u7b7e\u540d\u53d8\u6362\u5c5e\u6027\u5f15\u5165\u53ef\u63a7\u968f\u673a\u6027\uff0c\u589e\u5f3a\u6784\u5efa\u8fc7\u7a0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u5e76\u53d6\u5f97\u4e86\u6709\u524d\u666f\u7684\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u6709\u6548\u4ece\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u96c6\u5408\u6784\u5efa\u8d85\u56fe\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u9c81\u68d2\u6027\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.15434", "pdf": "https://arxiv.org/pdf/2507.15434", "abs": "https://arxiv.org/abs/2507.15434", "authors": ["Yi-Ting Hsieh", "Mong-Jen Kao", "Jhong-Yun Liu", "Hung-Lung Wang"], "title": "Job Scheduling under Base and Additional Fees, with Applications to Mixed-Criticality Scheduling", "categories": ["cs.DS"], "comment": null, "summary": "We are concerned with the problem of scheduling $n$ jobs onto $m$ identical\nmachines. Each machine has to be in operation for a prescribed time, and the\nobjective is to minimize the total machine working time. Precisely, let $c_i$\nbe the prescribed time for machine $i$, where $i\\in[m]$, and $p_j$ be the\nprocessing time for job $j$, where $j\\in[n]$. The problem asks for a schedule\n$\\sigma\\colon\\, J\\to M$ such that $\\sum_{i=1}^m\\max\\{c_i,\n\\sum_{j\\in\\sigma^{-1}(i)}p_j\\}$ is minimized, where $J$ and $M$ denote the sets\nof jobs and machines, respectively. We show that First Fit Decreasing (FFD)\nleads to a $1.5$-approximation, and this problem admits a polynomial-time\napproximation scheme (PTAS). The idea is further applied to mixed-criticality\nsystem scheduling to yield improved approximation results.", "AI": {"tldr": "\u7814\u7a76n\u4e2a\u4f5c\u4e1a\u8c03\u5ea6\u5230m\u4e2a\u76f8\u540c\u673a\u5668\u7684\u95ee\u9898\uff0c\u76ee\u6807\u662f\u6700\u5c0f\u5316\u603b\u673a\u5668\u5de5\u4f5c\u65f6\u95f4\uff0c\u8bc1\u660eFFD\u7b97\u6cd5\u53ef\u8fbe1.5\u8fd1\u4f3c\uff0c\u95ee\u9898\u6709PTAS\uff0c\u5e76\u5e94\u7528\u4e8e\u6df7\u5408\u5173\u952e\u7cfb\u7edf\u8c03\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5c06n\u4e2a\u4f5c\u4e1a\u8c03\u5ea6\u5230m\u4e2a\u76f8\u540c\u673a\u5668\uff0c\u6700\u5c0f\u5316\u603b\u673a\u5668\u5de5\u4f5c\u65f6\u95f4\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528First Fit Decreasing (FFD)\u7b97\u6cd5\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u5f97\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff08PTAS\uff09\u3002", "result": "FFD\u7b97\u6cd5\u80fd\u8fbe\u52301.5\u8fd1\u4f3c\uff0c\u8be5\u95ee\u9898\u5b58\u5728PTAS\uff0c\u4e14\u5e94\u7528\u4e8e\u6df7\u5408\u5173\u952e\u7cfb\u7edf\u8c03\u5ea6\u6709\u6539\u8fdb\u7ed3\u679c\u3002", "conclusion": "\u8be5\u8c03\u5ea6\u95ee\u9898\u53ef\u901a\u8fc7FFD\u548cPTAS\u6709\u6548\u89e3\u51b3\uff0c\u4e14\u6210\u679c\u80fd\u5e94\u7528\u4e8e\u6df7\u5408\u5173\u952e\u7cfb\u7edf\u8c03\u5ea6\u3002"}}
{"id": "2507.15336", "pdf": "https://arxiv.org/pdf/2507.15336", "abs": "https://arxiv.org/abs/2507.15336", "authors": ["Jialiang Wang", "Hanmo Liu", "Shimin Di", "Zhili Wang", "Jiachuan Wang", "Lei Chen", "Xiaofang Zhou"], "title": "Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": null, "summary": "Database systems have recently advocated for embedding machine learning (ML)\ncapabilities, offering declarative model queries over large, managed model\nrepositories, thereby circumventing the huge computational overhead of\ntraditional ML-based algorithms in automated neural network model selection.\nPioneering database studies aim to organize existing benchmark repositories as\nmodel bases (MB), querying them for the model records with the highest\nperformance estimation metrics for given tasks. However, this static model\nselection practice overlooks the fine-grained, evolving relational dependencies\nbetween diverse task queries and model architecture variations, resulting in\nsuboptimal matches and failing to further refine the model effectively. To fill\nthe model refinement gap in database research, we propose M-DESIGN, a curated\nmodel knowledge base (MKB) pipeline for mastering neural network refinement by\nadaptively weaving prior insights about model architecture modification. First,\nwe propose a knowledge weaving engine that reframes model refinement as an\nadaptive query problem over task metadata. Given a user's task query, M-DESIGN\nquickly matches and iteratively refines candidate models by leveraging a\ngraph-relational knowledge schema that explicitly encodes data properties,\narchitecture variations, and pairwise performance deltas as joinable relations.\nThis schema supports fine-grained relational analytics over architecture tweaks\nand drives a predictive query planner that can detect and adapt to\nout-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics\ntasks, where our model knowledge base enriches existing benchmarks with\nstructured metadata covering 3 graph tasks and 22 graph datasets, contributing\ndata records of 67,760 graph models. Empirical results demonstrate that\nM-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited\nbudgets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faM - DESIGN\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u878d\u5408\u6a21\u578b\u67b6\u6784\u4fee\u6539\u7684\u5148\u9a8c\u77e5\u8bc6\u6765\u89e3\u51b3\u6570\u636e\u5e93\u7814\u7a76\u4e2d\u6a21\u578b\u7ec6\u5316\u7684\u95ee\u9898\uff0c\u5728\u56fe\u5206\u6790\u4efb\u52a1\u4e0a\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u5e93\u9759\u6001\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u5ffd\u89c6\u4efb\u52a1\u67e5\u8be2\u548c\u6a21\u578b\u67b6\u6784\u53d8\u5316\u95f4\u7684\u7ec6\u7c92\u5ea6\u5173\u7cfb\uff0c\u5bfc\u81f4\u5339\u914d\u4e0d\u4f73\u4e14\u65e0\u6cd5\u6709\u6548\u7ec6\u5316\u6a21\u578b\uff0c\u9700\u586b\u8865\u6a21\u578b\u7ec6\u5316\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u77e5\u8bc6\u7f16\u7ec7\u5f15\u64ce\uff0c\u5c06\u6a21\u578b\u7ec6\u5316\u8f6c\u5316\u4e3a\u4efb\u52a1\u5143\u6570\u636e\u7684\u81ea\u9002\u5e94\u67e5\u8be2\u95ee\u9898\uff0c\u5229\u7528\u56fe\u5173\u7cfb\u77e5\u8bc6\u6a21\u5f0f\u5339\u914d\u548c\u8fed\u4ee3\u7ec6\u5316\u5019\u9009\u6a21\u578b\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u5206\u6790\u548c\u9884\u6d4b\u67e5\u8be2\u89c4\u5212\u3002", "result": "\u5728\u56fe\u5206\u6790\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u77e5\u8bc6\u5e93\u4e30\u5bcc\u4e86\u73b0\u6709\u57fa\u51c6\uff0c\u63d0\u4f9b67,760\u4e2a\u56fe\u6a21\u578b\u7684\u6570\u636e\u8bb0\u5f55\uff0c\u572833\u4e2a\u6570\u636e - \u4efb\u52a1\u5bf9\u4e2d\u768426\u4e2a\u4e2d\u80fd\u5728\u6709\u9650\u9884\u7b97\u5185\u63d0\u4f9b\u6700\u4f18\u6a21\u578b\u3002", "conclusion": "M - DESIGN\u80fd\u6709\u6548\u89e3\u51b3\u6a21\u578b\u7ec6\u5316\u95ee\u9898\uff0c\u5728\u56fe\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.14747", "pdf": "https://arxiv.org/pdf/2507.14747", "abs": "https://arxiv.org/abs/2507.14747", "authors": ["Yiding Song"], "title": "Pruning Increases Orderedness in Recurrent Computation", "categories": ["cs.LG", "cs.NE"], "comment": "8 pages, 11 figures, 2 tables, Workshop on Methods and Opportunities\n  at Small Scale (MOSS), ICML 2025", "summary": "Inspired by the prevalence of recurrent circuits in biological brains, we\ninvestigate the degree to which directionality is a helpful inductive bias for\nartificial neural networks. Taking directionality as topologically-ordered\ninformation flow between neurons, we formalise a perceptron layer with\nall-to-all connections (mathematically equivalent to a weight-tied recurrent\nneural network) and demonstrate that directionality, a hallmark of modern\nfeed-forward networks, can be induced rather than hard-wired by applying\nappropriate pruning techniques. Across different random seeds our pruning\nschemes successfully induce greater topological ordering in information flow\nbetween neurons without compromising performance, suggesting that\ndirectionality is not a prerequisite for learning, but may be an advantageous\ninductive bias discoverable by gradient descent and sparsification.", "AI": {"tldr": "\u53d7\u751f\u7269\u5927\u8111\u5faa\u73af\u56de\u8def\u542f\u53d1\uff0c\u7814\u7a76\u65b9\u5411\u6027\u5bf9\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u53ef\u901a\u8fc7\u526a\u679d\u8bf1\u5bfc\u65b9\u5411\u6027\uff0c\u65b9\u5411\u6027\u975e\u5b66\u4e60\u5fc5\u8981\u6761\u4ef6\u4f46\u53ef\u80fd\u662f\u6709\u5229\u5f52\u7eb3\u504f\u7f6e\u3002", "motivation": "\u53d7\u751f\u7269\u5927\u8111\u4e2d\u5faa\u73af\u56de\u8def\u666e\u904d\u5b58\u5728\u7684\u542f\u53d1\uff0c\u7814\u7a76\u65b9\u5411\u6027\u5bf9\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u5e2e\u52a9\u7a0b\u5ea6\u3002", "method": "\u5c06\u65b9\u5411\u6027\u89c6\u4e3a\u795e\u7ecf\u5143\u95f4\u62d3\u6251\u6709\u5e8f\u4fe1\u606f\u6d41\uff0c\u5f62\u5f0f\u5316\u5168\u8fde\u63a5\u611f\u77e5\u5c42\uff0c\u5e94\u7528\u9002\u5f53\u526a\u679d\u6280\u672f\u3002", "result": "\u4e0d\u540c\u968f\u673a\u79cd\u5b50\u4e0b\uff0c\u526a\u679d\u65b9\u6848\u80fd\u5728\u4e0d\u5f71\u54cd\u6027\u80fd\u524d\u63d0\u4e0b\u8bf1\u5bfc\u795e\u7ecf\u5143\u95f4\u4fe1\u606f\u6d41\u5411\u66f4\u5927\u62d3\u6251\u6709\u5e8f\u6027\u3002", "conclusion": "\u65b9\u5411\u6027\u4e0d\u662f\u5b66\u4e60\u7684\u5148\u51b3\u6761\u4ef6\uff0c\u4f46\u53ef\u80fd\u662f\u68af\u5ea6\u4e0b\u964d\u548c\u7a00\u758f\u5316\u53ef\u53d1\u73b0\u7684\u6709\u5229\u5f52\u7eb3\u504f\u7f6e\u3002"}}
{"id": "2507.15230", "pdf": "https://arxiv.org/pdf/2507.15230", "abs": "https://arxiv.org/abs/2507.15230", "authors": ["Guoxi Liu", "Thomas Randall", "Rong Ge", "Federico Iuricich"], "title": "GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis", "categories": ["cs.DC", "cs.GR"], "comment": null, "summary": "Unstructured meshes present challenges in scientific data analysis due to\nirregular distribution and complex connectivity. Computing and storing\nconnectivity information is a major bottleneck for visualization algorithms,\naffecting both time and memory performance. Recent task-parallel data\nstructures address this by precomputing connectivity information at runtime\nwhile the analysis algorithm executes, effectively hiding computation costs and\nimproving performance. However, existing approaches are CPU-bound, forcing the\ndata structure and analysis algorithm to compete for the same computational\nresources, limiting potential speedups. To overcome this limitation, we\nintroduce a novel task-parallel approach optimized for heterogeneous CPU-GPU\nsystems. Specifically, we offload the computation of mesh connectivity\ninformation to GPU threads, enabling CPU threads to focus on executing the\nvisualization algorithm. Following this paradigm, we propose GALE (GPU-Aided\nLocalized data structurE), the first open-source CUDA-based data structure\ndesigned for heterogeneous task parallelism. Experiments on two 20-core CPUs\nand an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over\nstate-of-the-art localized data structures while maintaining memory efficiency.", "AI": {"tldr": "\u9488\u5bf9\u975e\u7ed3\u6784\u5316\u7f51\u683c\u5728\u79d1\u5b66\u6570\u636e\u5206\u6790\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4f18\u5316\u5f02\u6784CPU - GPU\u7cfb\u7edf\u7684\u4efb\u52a1\u5e76\u884c\u65b9\u6cd5GALE\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u901f\u5ea6\u63d0\u5347\u4e14\u4fdd\u6301\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u4efb\u52a1\u5e76\u884c\u6570\u636e\u7ed3\u6784\u662fCPU\u53d7\u9650\uff0c\u6570\u636e\u7ed3\u6784\u548c\u5206\u6790\u7b97\u6cd5\u7ade\u4e89\u8ba1\u7b97\u8d44\u6e90\uff0c\u9650\u5236\u4e86\u52a0\u901f\u6f5c\u529b\u3002", "method": "\u5f15\u5165\u4f18\u5316\u5f02\u6784CPU - GPU\u7cfb\u7edf\u7684\u4efb\u52a1\u5e76\u884c\u65b9\u6cd5\uff0c\u5c06\u7f51\u683c\u8fde\u63a5\u4fe1\u606f\u8ba1\u7b97\u5378\u8f7d\u5230GPU\u7ebf\u7a0b\uff0cCPU\u7ebf\u7a0b\u4e13\u6ce8\u6267\u884c\u53ef\u89c6\u5316\u7b97\u6cd5\uff0c\u63d0\u51fa\u57fa\u4e8eCUDA\u7684GALE\u6570\u636e\u7ed3\u6784\u3002", "result": "\u572820\u6838CPU\u548cNVIDIA V100 GPU\u4e0a\u5b9e\u9a8c\uff0cGALE\u6bd4\u73b0\u6709\u672c\u5730\u5316\u6570\u636e\u7ed3\u6784\u5b9e\u73b0\u4e86\u9ad8\u8fbe2.7\u500d\u7684\u52a0\u901f\uff0c\u4e14\u4fdd\u6301\u5185\u5b58\u6548\u7387\u3002", "conclusion": "GALE\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5728\u5f02\u6784\u7cfb\u7edf\u4e0a\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.14406", "pdf": "https://arxiv.org/pdf/2507.14406", "abs": "https://arxiv.org/abs/2507.14406", "authors": ["Michael J. Zellinger", "Matt Thomson"], "title": "Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "8 pages, 5 figures", "summary": "State-of-the-art reasoning LLMs are powerful problem solvers, but they still\noccasionally make mistakes. However, adopting AI models in risk-sensitive\ndomains often requires error rates near 0%. To address this gap, we propose\ncollaboration between a reasoning model and a human expert who resolves queries\nthe model cannot confidently answer. We find that quantifying the uncertainty\nof a reasoning model through the length of its reasoning trace yields an\neffective basis for deferral to a human, e.g., cutting the error rate of Qwen3\n235B-A22B on difficult MATH problems from 3% to less than 1% when deferring\n7.5% of queries. However, the high latency of reasoning models still makes them\nchallenging to deploy on use cases with high query volume. To address this\nchallenge, we explore fronting a reasoning model with a large non-reasoning\nmodel. We call this modified human-in-the-loop system \"Fail Fast, or Ask\",\nsince the non-reasoning model may defer difficult queries to the human expert\ndirectly (\"failing fast\"), without incurring the reasoning model's higher\nlatency. We show that this approach yields around 40% latency reduction and\nabout 50% cost savings for DeepSeek R1 while maintaining 90+% area under the\naccuracy-rejection curve. However, we observe that latency savings are lower\nthan expected because of \"latency drag\", the phenomenon that processing easier\nqueries with a non-reasoning model pushes the reasoning model's latency\ndistribution towards longer latencies. Broadly, our results suggest that the\ndeficiencies of state-of-the-art reasoning models -- nontrivial error rates and\nhigh latency -- can be substantially mitigated through black-box systems\nengineering, without requiring access to LLM internals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8ba9\u63a8\u7406\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u534f\u4f5c\uff0c\u5e76\u91c7\u7528\u975e\u63a8\u7406\u5927\u6a21\u578b\u524d\u7f6e\u7684\u65b9\u6cd5\uff0c\u7f13\u89e3\u4e86\u63a8\u7406\u5927\u6a21\u578b\u9519\u8bef\u7387\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u9519\u8bef\u7387\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u5728\u98ce\u9669\u654f\u611f\u9886\u57df\u5e94\u7528\u9700\u964d\u4f4e\u9519\u8bef\u7387\uff0c\u9ad8\u67e5\u8be2\u91cf\u573a\u666f\u9700\u964d\u4f4e\u5ef6\u8fdf\u3002", "method": "\u8ba9\u63a8\u7406\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u534f\u4f5c\uff0c\u91cf\u5316\u63a8\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4ee5\u51b3\u5b9a\u662f\u5426\u5411\u4eba\u7c7b\u4e13\u5bb6\u6c42\u52a9\uff1b\u7528\u975e\u63a8\u7406\u5927\u6a21\u578b\u524d\u7f6e\uff0c\u6784\u5efa\u201cFail Fast, or Ask\u201d\u7cfb\u7edf\u3002", "result": "\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u4f7fQwen3 235B - A22B\u5728\u96be\u9898\u4e0a\u9519\u8bef\u7387\u4ece3%\u964d\u81f3\u4e0d\u52301%\uff1b\u201cFail Fast, or Ask\u201d\u4f7fDeepSeek R1\u5ef6\u8fdf\u964d\u4f4e\u7ea640%\uff0c\u6210\u672c\u8282\u7701\u7ea650%\uff0c\u51c6\u786e\u7387 - \u62d2\u7edd\u7387\u66f2\u7ebf\u4e0b\u9762\u79ef\u4fdd\u630190%\u4ee5\u4e0a\uff0c\u4f46\u56e0\u201c\u5ef6\u8fdf\u62d6\u7d2f\u201d\u5ef6\u8fdf\u8282\u7701\u4f4e\u4e8e\u9884\u671f\u3002", "conclusion": "\u901a\u8fc7\u9ed1\u76d2\u7cfb\u7edf\u5de5\u7a0b\u53ef\u5927\u5e45\u7f13\u89e3\u63a8\u7406\u5927\u6a21\u578b\u7684\u9519\u8bef\u7387\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u65e0\u9700\u8bbf\u95ee\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u3002"}}
{"id": "2507.14594", "pdf": "https://arxiv.org/pdf/2507.14594", "abs": "https://arxiv.org/abs/2507.14594", "authors": ["Weiwei Xu", "Hengzhi Ye", "Kai Gao", "Minghui Zhou"], "title": "A first look at License Variants in the PyPI Ecosystem", "categories": ["cs.SE"], "comment": null, "summary": "Open-source licenses establish the legal foundation for software reuse, yet\nlicense variants, including both modified standard licenses and custom-created\nalternatives, introduce significant compliance complexities. Despite their\nprevalence and potential impact, these variants are poorly understood in modern\nsoftware systems, and existing tools do not account for their existence,\nleading to significant challenges in both effectiveness and efficiency of\nlicense analysis. To fill this knowledge gap, we conduct a comprehensive\nempirical study of license variants in the PyPI ecosystem. Our findings show\nthat textual variations in licenses are common, yet only 2% involve substantive\nmodifications. However, these license variants lead to significant compliance\nissues, with 10.7% of their downstream dependencies found to be\nlicense-incompatible.\n  Inspired by our findings, we introduce LV-Parser, a novel approach for\nefficient license variant analysis leveraging diff-based techniques and large\nlanguage models, along with LV-Compat, an automated pipeline for detecting\nlicense incompatibilities in software dependency networks. Our evaluation\ndemonstrates that LV-Parser achieves an accuracy of 0.936 while reducing\ncomputational costs by 30%, and LV-Compat identifies 5.2 times more\nincompatible packages than existing methods with a precision of 0.98.\n  This work not only provides the first empirical study into license variants\nin software packaging ecosystem but also equips developers and organizations\nwith practical tools for navigating the complex landscape of open-source\nlicensing.", "AI": {"tldr": "\u672c\u6587\u5bf9PyPI\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5f00\u6e90\u8bb8\u53ef\u8bc1\u53d8\u4f53\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u6587\u672c\u53d8\u5316\u5e38\u89c1\u4f46\u5b9e\u8d28\u4fee\u6539\u5c11\uff0c\u53d8\u4f53\u5f15\u53d1\u5408\u89c4\u95ee\u9898\u3002\u5e76\u63d0\u51faLV - Parser\u548cLV - Compat\u5de5\u5177\uff0c\u8bc4\u4f30\u663e\u793a\u5de5\u5177\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u672a\u8003\u8651\u5f00\u6e90\u8bb8\u53ef\u8bc1\u53d8\u4f53\uff0c\u5bfc\u81f4\u8bb8\u53ef\u8bc1\u5206\u6790\u5728\u6709\u6548\u6027\u548c\u6548\u7387\u4e0a\u5b58\u5728\u6311\u6218\uff0c\u9700\u586b\u8865\u5bf9\u8bb8\u53ef\u8bc1\u53d8\u4f53\u7684\u8ba4\u77e5\u7a7a\u767d\u3002", "method": "\u5bf9PyPI\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u8bb8\u53ef\u8bc1\u53d8\u4f53\u8fdb\u884c\u5168\u9762\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51faLV - Parser\u5229\u7528\u57fa\u4e8e\u5dee\u5f02\u7684\u6280\u672f\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9ad8\u6548\u8bb8\u53ef\u8bc1\u53d8\u4f53\u5206\u6790\uff0c\u63d0\u51faLV - Compat\u81ea\u52a8\u68c0\u6d4b\u8f6f\u4ef6\u4f9d\u8d56\u7f51\u7edc\u4e2d\u7684\u8bb8\u53ef\u8bc1\u4e0d\u517c\u5bb9\u6027\u3002", "result": "\u8bb8\u53ef\u8bc1\u6587\u672c\u53d8\u5316\u5e38\u89c1\u4f46\u4ec52%\u6709\u5b9e\u8d28\u4fee\u6539\uff0c10.7%\u7684\u4e0b\u6e38\u4f9d\u8d56\u5b58\u5728\u8bb8\u53ef\u8bc1\u4e0d\u517c\u5bb9\uff1bLV - Parser\u51c6\u786e\u7387\u8fbe0.936\u4e14\u964d\u4f4e30%\u8ba1\u7b97\u6210\u672c\uff0cLV - Compat\u8bc6\u522b\u51fa\u7684\u4e0d\u517c\u5bb9\u5305\u662f\u73b0\u6709\u65b9\u6cd5\u76845.2\u500d\uff0c\u7cbe\u5ea6\u4e3a0.98\u3002", "conclusion": "\u672c\u7814\u7a76\u662f\u8f6f\u4ef6\u6253\u5305\u751f\u6001\u7cfb\u7edf\u4e2d\u5bf9\u8bb8\u53ef\u8bc1\u53d8\u4f53\u7684\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u5e94\u5bf9\u5f00\u6e90\u8bb8\u53ef\u590d\u6742\u60c5\u51b5\u7684\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2507.14925", "pdf": "https://arxiv.org/pdf/2507.14925", "abs": "https://arxiv.org/abs/2507.14925", "authors": ["Mingshi Yan", "Zhiyong Cheng", "Fan Liu", "Yingda Lyu", "Yahong Han"], "title": "User Invariant Preference Learning for Multi-Behavior Recommendation", "categories": ["cs.IR"], "comment": null, "summary": "In multi-behavior recommendation scenarios, analyzing users' diverse\nbehaviors, such as click, purchase, and rating, enables a more comprehensive\nunderstanding of their interests, facilitating personalized and accurate\nrecommendations. A fundamental assumption of multi-behavior recommendation\nmethods is the existence of shared user preferences across behaviors,\nrepresenting users' intrinsic interests. Based on this assumption, existing\napproaches aim to integrate information from various behaviors to enrich user\nrepresentations. However, they often overlook the presence of both\ncommonalities and individualities in users' multi-behavior preferences. These\nindividualities reflect distinct aspects of preferences captured by different\nbehaviors, where certain auxiliary behaviors may introduce noise, hindering the\nprediction of the target behavior. To address this issue, we propose a user\ninvariant preference learning for multi-behavior recommendation (UIPL for\nshort), aiming to capture users' intrinsic interests (referred to as invariant\npreferences) from multi-behavior interactions to mitigate the introduction of\nnoise. Specifically, UIPL leverages the paradigm of invariant risk minimization\nto learn invariant preferences. To implement this, we employ a variational\nautoencoder (VAE) to extract users' invariant preferences, replacing the\nstandard reconstruction loss with an invariant risk minimization constraint.\nAdditionally, we construct distinct environments by combining multi-behavior\ndata to enhance robustness in learning these preferences. Finally, the learned\ninvariant preferences are used to provide recommendations for the target\nbehavior. Extensive experiments on four real-world datasets demonstrate that\nUIPL significantly outperforms current state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faUIPL\u65b9\u6cd5\u7528\u4e8e\u591a\u884c\u4e3a\u63a8\u8350\uff0c\u5229\u7528\u4e0d\u53d8\u98ce\u9669\u6700\u5c0f\u5316\u5b66\u4e60\u7528\u6237\u4e0d\u53d8\u504f\u597d\uff0c\u5b9e\u9a8c\u8868\u660e\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u884c\u4e3a\u63a8\u8350\u65b9\u6cd5\u5e38\u5ffd\u7565\u7528\u6237\u591a\u884c\u4e3a\u504f\u597d\u7684\u5171\u6027\u4e0e\u4e2a\u6027\uff0c\u8f85\u52a9\u884c\u4e3a\u53ef\u80fd\u5f15\u5165\u566a\u58f0\uff0c\u5f71\u54cd\u76ee\u6807\u884c\u4e3a\u9884\u6d4b\u3002", "method": "\u63d0\u51faUIPL\u65b9\u6cd5\uff0c\u5229\u7528\u4e0d\u53d8\u98ce\u9669\u6700\u5c0f\u5316\u8303\u5f0f\uff0c\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u63d0\u53d6\u7528\u6237\u4e0d\u53d8\u504f\u597d\uff0c\u6784\u5efa\u4e0d\u540c\u73af\u5883\u589e\u5f3a\u5b66\u4e60\u9c81\u68d2\u6027\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cUIPL\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "UIPL\u80fd\u6709\u6548\u6355\u6349\u7528\u6237\u5185\u5728\u5174\u8da3\uff0c\u7f13\u89e3\u566a\u58f0\u5f15\u5165\u95ee\u9898\uff0c\u63d0\u5347\u591a\u884c\u4e3a\u63a8\u8350\u6548\u679c\u3002"}}
{"id": "2507.15568", "pdf": "https://arxiv.org/pdf/2507.15568", "abs": "https://arxiv.org/abs/2507.15568", "authors": ["Marius Protte"], "title": "Explaining Apparently Inaccurate Self-assessments of Relative Performance: A Replication and Adaptation of 'Overconfident: Do you put your money on it?' by Hoelzl and Rustichini (2005)", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This study replicates and adapts the experiment of Hoelzl and Rustichini\n(2005), which examined overplacement, i.e., overconfidence in relative\nself-assessments, by analyzing individuals' voting preferences between a\nperformance-based and a lottery-based bonus payment mechanism. The original\nstudy found underplacement - the majority of their sample apparently expected\nto perform worse than others - in difficult tasks with monetary incentives,\ncontradicting the widely held assumption of a general human tendency toward\noverconfidence. This paper challenges the comparability of the two payment\nschemes, arguing that differences in outcome structures and non-monetary\nmotives may have influenced participants' choices beyond misconfidence. In an\nonline replication, a fixed-outcome distribution lottery mechanism with\ninterdependent success probabilities and no variance in the number of winners -\ndesigned to better align with the performance-based payment scheme - is\ncompared against the probabilistic-outcome distribution lottery used in the\noriginal study, which features an independent success probability and a\nvariable number of winners. The results align more closely with traditional\noverplacement patterns than underplacement, as nearly three-fourths of\nparticipants prefer the performance-based option regardless of lottery design.\nKey predictors of voting behavior include expected performance, group\nperformance estimations, and sample question outcomes, while factors such as\nsocial comparison tendencies and risk attitudes play no significant role.\nSelf-reported voting rationales highlight the influence of normative beliefs,\ncontrol preferences, and feedback signals beyond confidence. These results\ncontribute to methodological discussions in overconfidence research by\nreassessing choice-based overconfidence measures and exploring alternative\nexplanations for observed misplacement effects.", "AI": {"tldr": "\u672c\u6587\u590d\u5236\u5e76\u6539\u8fdbHoelzl\u548cRustichini (2005)\u5b9e\u9a8c\uff0c\u6311\u6218\u539f\u7814\u7a76\u4e24\u79cd\u652f\u4ed8\u65b9\u6848\u53ef\u6bd4\u6027\uff0c\u65b0\u5b9e\u9a8c\u7ed3\u679c\u66f4\u7b26\u5408\u4f20\u7edf\u8fc7\u5ea6\u5b9a\u4f4d\u6a21\u5f0f\uff0c\u4e3a\u8fc7\u5ea6\u81ea\u4fe1\u7814\u7a76\u65b9\u6cd5\u8ba8\u8bba\u505a\u8d21\u732e\u3002", "motivation": "\u6311\u6218\u539f\u7814\u7a76\u4e2d\u4e24\u79cd\u652f\u4ed8\u65b9\u6848\u7684\u53ef\u6bd4\u6027\uff0c\u91cd\u65b0\u8bc4\u4f30\u57fa\u4e8e\u9009\u62e9\u7684\u8fc7\u5ea6\u81ea\u4fe1\u6d4b\u91cf\u65b9\u6cd5\u5e76\u63a2\u7d22\u9519\u4f4d\u6548\u5e94\u7684\u66ff\u4ee3\u89e3\u91ca\u3002", "method": "\u8fdb\u884c\u5728\u7ebf\u590d\u5236\u5b9e\u9a8c\uff0c\u5c06\u56fa\u5b9a\u7ed3\u679c\u5206\u5e03\u3001\u6210\u529f\u6982\u7387\u76f8\u4e92\u4f9d\u8d56\u4e14\u83b7\u80dc\u8005\u6570\u91cf\u65e0\u5dee\u5f02\u7684\u5f69\u7968\u673a\u5236\u4e0e\u539f\u7814\u7a76\u4e2d\u6982\u7387\u7ed3\u679c\u5206\u5e03\u7684\u5f69\u7968\u673a\u5236\u5bf9\u6bd4\u3002", "result": "\u7ed3\u679c\u66f4\u63a5\u8fd1\u4f20\u7edf\u8fc7\u5ea6\u5b9a\u4f4d\u6a21\u5f0f\uff0c\u8fd1\u56db\u5206\u4e4b\u4e09\u53c2\u4e0e\u8005\u9009\u7ee9\u6548\u652f\u4ed8\u65b9\u6848\uff0c\u6295\u7968\u884c\u4e3a\u5173\u952e\u9884\u6d4b\u56e0\u7d20\u5305\u62ec\u9884\u671f\u8868\u73b0\u7b49\uff0c\u793e\u4f1a\u6bd4\u8f83\u503e\u5411\u548c\u98ce\u9669\u6001\u5ea6\u65e0\u663e\u8457\u4f5c\u7528\uff0c\u81ea\u6211\u62a5\u544a\u6295\u7968\u7406\u7531\u663e\u793a\u89c4\u8303\u4fe1\u5ff5\u7b49\u6709\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u6709\u52a9\u4e8e\u8fc7\u5ea6\u81ea\u4fe1\u7814\u7a76\u7684\u65b9\u6cd5\u8bba\u8ba8\u8bba\uff0c\u91cd\u65b0\u8bc4\u4f30\u76f8\u5173\u6d4b\u91cf\u65b9\u6cd5\u5e76\u63a2\u7d22\u66ff\u4ee3\u89e3\u91ca\u3002"}}
{"id": "2507.15088", "pdf": "https://arxiv.org/pdf/2507.15088", "abs": "https://arxiv.org/abs/2507.15088", "authors": ["Pouya Panahandeh", "Mohammad Pirani", "Baris Fidan", "Amir Khajepour"], "title": "Search-Based Autonomous Vehicle Motion Planning Using Game Theory", "categories": ["cs.RO", "cs.GT"], "comment": null, "summary": "In this paper, we propose a search-based interactive motion planning scheme\nfor autonomous vehicles (AVs), using a game-theoretic approach. In contrast to\ntraditional search-based approaches, the newly developed approach considers\nother road users (e.g. drivers and pedestrians) as intelligent agents rather\nthan static obstacles. This leads to the generation of a more realistic path\nfor the AV. Due to the low computational time, the proposed motion planning\nscheme is implementable in real-time applications. The performance of the\ndeveloped motion planning scheme is compared with existing motion planning\ntechniques and validated through experiments using WATonoBus, an electrical\nall-weather autonomous shuttle bus.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u641c\u7d22\u7684\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u4ea4\u4e92\u5f0f\u8fd0\u52a8\u89c4\u5212\u65b9\u6848\uff0c\u7528\u535a\u5f08\u8bba\u65b9\u6cd5\uff0c\u6027\u80fd\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u641c\u7d22\u65b9\u6cd5\u5c06\u5176\u4ed6\u9053\u8def\u4f7f\u7528\u8005\u89c6\u4e3a\u9759\u6001\u969c\u788d\u7269\uff0c\u9700\u66f4\u73b0\u5b9e\u7684\u8def\u5f84\u89c4\u5212\u3002", "method": "\u91c7\u7528\u535a\u5f08\u8bba\u65b9\u6cd5\uff0c\u5c06\u5176\u4ed6\u9053\u8def\u4f7f\u7528\u8005\u89c6\u4e3a\u667a\u80fd\u4f53\u7684\u641c\u7d22\u5f0f\u4ea4\u4e92\u8fd0\u52a8\u89c4\u5212\u65b9\u6848\u3002", "result": "\u751f\u6210\u66f4\u73b0\u5b9e\u7684\u8def\u5f84\uff0c\u8ba1\u7b97\u65f6\u95f4\u77ed\uff0c\u53ef\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\uff0c\u4e0e\u73b0\u6709\u6280\u672f\u5bf9\u6bd4\u5e76\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "\u6240\u63d0\u8fd0\u52a8\u89c4\u5212\u65b9\u6848\u53ef\u884c\u4e14\u6027\u80fd\u826f\u597d\u3002"}}
{"id": "2507.14179", "pdf": "https://arxiv.org/pdf/2507.14179", "abs": "https://arxiv.org/abs/2507.14179", "authors": ["Nobel Dhar", "Bobin Deng", "Md Romyull Islam", "Xinyue Zhang", "Kazi Fahim Ahmad Nasif", "Kun Suo"], "title": "A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "comment": "To be published in Euro-Par 2025", "summary": "Large Language Models (LLMs) exhibit significant activation sparsity, where\nonly a subset of neurons are active for a given input. Although this sparsity\npresents opportunities to reduce computational cost, efficiently utilizing it\nrequires predicting activation patterns in a scalable manner. However, direct\nprediction at the neuron level is computationally expensive due to the vast\nnumber of neurons in modern LLMs. To enable efficient prediction and\nutilization of activation sparsity, we propose a clustering-based activation\npattern compression framework. Instead of treating each neuron independently,\nwe group similar activation patterns into a small set of representative\nclusters. Our method achieves up to 79.34% clustering precision, outperforming\nstandard binary clustering approaches while maintaining minimal degradation in\nperplexity (PPL) scores. With a sufficiently large number of clusters, our\napproach attains a PPL score as low as 12.49, demonstrating its effectiveness\nin preserving model quality while reducing computational overhead. By\npredicting cluster assignments rather than individual neuron states, future\nmodels can efficiently infer activation patterns from pre-computed centroids.\nWe detail the clustering algorithm, analyze its effectiveness in capturing\nmeaningful activation structures, and demonstrate its potential to improve\nsparse computation efficiency. This clustering-based formulation serves as a\nfoundation for future work on activation pattern prediction, paving the way for\nefficient inference in large-scale language models.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u9ad8\u6548\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u7a00\u758f\u6027\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u5e76\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u7a00\u758f\u6027\u53ef\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u76f4\u63a5\u5728\u795e\u7ecf\u5143\u5c42\u9762\u9884\u6d4b\u6fc0\u6d3b\u6a21\u5f0f\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9700\u53ef\u6269\u5c55\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u5c06\u76f8\u4f3c\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u4e3a\u5c11\u91cf\u4ee3\u8868\u6027\u805a\u7c7b\uff0c\u901a\u8fc7\u9884\u6d4b\u805a\u7c7b\u5206\u914d\u800c\u975e\u5355\u4e2a\u795e\u7ecf\u5143\u72b6\u6001\u6765\u63a8\u65ad\u6fc0\u6d3b\u6a21\u5f0f\u3002", "result": "\u805a\u7c7b\u7cbe\u5ea6\u8fbe79.34%\uff0c\u4f18\u4e8e\u6807\u51c6\u4e8c\u5143\u805a\u7c7b\u65b9\u6cd5\uff0c\u5728\u7c07\u6570\u91cf\u8db3\u591f\u65f6\u56f0\u60d1\u5ea6\u4f4e\u81f312.49\u3002", "conclusion": "\u8be5\u805a\u7c7b\u65b9\u6cd5\u4e3a\u6fc0\u6d3b\u6a21\u5f0f\u9884\u6d4b\u7684\u672a\u6765\u5de5\u4f5c\u5960\u5b9a\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u3002"}}
{"id": "2507.15097", "pdf": "https://arxiv.org/pdf/2507.15097", "abs": "https://arxiv.org/abs/2507.15097", "authors": ["Subhroshekhar Ghosh", "Soumendu Sundar Mukherjee"], "title": "Learning under Latent Group Sparsity via Diffusion on Networks", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "49 pages, 4 figures, 2 tables; this submission subsumes the earlier\n  preprint arXiv:2201.08326", "summary": "Group or cluster structure on explanatory variables in machine learning\nproblems is a very general phenomenon, which has attracted broad interest from\npractitioners and theoreticians alike. In this work we contribute an approach\nto sparse learning under such group structure, that does not require prior\ninformation on the group identities. Our paradigm is motivated by the Laplacian\ngeometry of an underlying network with a related community structure, and\nproceeds by directly incorporating this into a penalty that is effectively\ncomputed via a heat-flow-based local network dynamics. The proposed penalty\ninterpolates between the lasso and the group lasso penalties, the runtime of\nthe heat-flow dynamics being the interpolating parameter. As such it can\nautomatically default to lasso when the group structure reflected in the\nLaplacian is weak. In fact, we demonstrate a data-driven procedure to construct\nsuch a network based on the available data. Notably, we dispense with\ncomputationally intensive pre-processing involving clustering of variables,\nspectral or otherwise. Our technique is underpinned by rigorous theorems that\nguarantee its effective performance and provide bounds on its sample\ncomplexity. In particular, in a wide range of settings, it provably suffices to\nrun the diffusion for time that is only logarithmic in the problem dimensions.\nWe explore in detail the interfaces of our approach with key statistical\nphysics models in network science, such as the Gaussian Free Field and the\nStochastic Block Model. Our work raises the possibility of applying similar\ndiffusion-based techniques to classical learning tasks, exploiting the\ninterplay between geometric, dynamical and stochastic structures underlying the\ndata.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u7ec4\u8eab\u4efd\u5148\u9a8c\u4fe1\u606f\u7684\u7a00\u758f\u5b66\u4e60\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7f51\u7edc\u62c9\u666e\u62c9\u65af\u51e0\u4f55\uff0c\u901a\u8fc7\u70ed\u6d41\u5c40\u90e8\u7f51\u7edc\u52a8\u529b\u5b66\u8ba1\u7b97\u60e9\u7f5a\u9879\uff0c\u6027\u80fd\u6709\u7406\u8bba\u4fdd\u969c\uff0c\u8fd8\u63a2\u8ba8\u4e0e\u7f51\u7edc\u79d1\u5b66\u6a21\u578b\u7684\u8054\u7cfb\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4e2d\u89e3\u91ca\u53d8\u91cf\u5b58\u5728\u7ec4\u6216\u7c07\u7ed3\u6784\u65f6\u7684\u7a00\u758f\u5b66\u4e60\u95ee\u9898\uff0c\u4e14\u4e0d\u9700\u8981\u7ec4\u8eab\u4efd\u7684\u5148\u9a8c\u4fe1\u606f\u3002", "method": "\u53d7\u5177\u6709\u793e\u533a\u7ed3\u6784\u7684\u5e95\u5c42\u7f51\u7edc\u7684\u62c9\u666e\u62c9\u65af\u51e0\u4f55\u542f\u53d1\uff0c\u5c06\u5176\u878d\u5165\u60e9\u7f5a\u9879\uff0c\u901a\u8fc7\u70ed\u6d41\u5c40\u90e8\u7f51\u7edc\u52a8\u529b\u5b66\u8ba1\u7b97\uff0c\u6570\u636e\u9a71\u52a8\u6784\u5efa\u7f51\u7edc\u3002", "result": "\u63d0\u51fa\u7684\u60e9\u7f5a\u9879\u53ef\u5728lasso\u548c\u7ec4lasso\u60e9\u7f5a\u9879\u4e4b\u95f4\u63d2\u503c\uff0c\u8fd0\u884c\u65f6\u95f4\u4e3a\u63d2\u503c\u53c2\u6570\uff0c\u80fd\u81ea\u52a8\u9000\u5316\u4e3alasso\uff1b\u6280\u672f\u6709\u4e25\u683c\u5b9a\u7406\u4fdd\u8bc1\u6027\u80fd\u5e76\u7ed9\u51fa\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u7ecf\u5178\u5b66\u4e60\u4efb\u52a1\u5e94\u7528\u57fa\u4e8e\u6269\u6563\u7684\u6280\u672f\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u53ef\u5229\u7528\u6570\u636e\u7684\u51e0\u4f55\u3001\u52a8\u6001\u548c\u968f\u673a\u7ed3\u6784\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2507.15549", "pdf": "https://arxiv.org/pdf/2507.15549", "abs": "https://arxiv.org/abs/2507.15549", "authors": ["Ren\u00e9 Sitters"], "title": "An $n^{O(\\log\\log n)}$ time approximation scheme for capacitated VRP in the Euclidean plane", "categories": ["cs.DS", "90", "F.2; E.1; G.2"], "comment": "40 pages", "summary": "We present a quasi polynomial time approximation scheme (Q-PTAS) for the\ncapacitated vehicle routing problem (CVRP) on $n$ points in the Euclidean plane\nfor arbitrary capacity $c$. The running time is $n^{f(\\epsilon)\\cdot\\log\\log\nn}$ for any $c$, and where $f$ is a function of $\\epsilon$ only. This is a\nmajor improvement over the so far best known running time of\n$n^{\\log^{O(1/\\epsilon)}n}$ time and a big step towards a PTAS for Euclidean\nCVRP.\n  In our algorithm, we first give a polynomial time reduction of the CVRP in\n$\\mathbb{R}^d$ (for any fixed $d$) to an uncapacitated routing problem in\n$\\mathbb{R}^d$ that we call the $m$-paths problem. Here, one needs to find\nexactly $m$ paths between two points $a$ and $b$, covering all the given points\nin the Euclidean space. We then give a Q-PTAS for the $m$-paths problem in the\npane. Any PTAS for the (arguably easier to handle) Euclidean $m$-paths problem\nis most likely to imply a PTAS for the Euclidean CVRP.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15118", "pdf": "https://arxiv.org/pdf/2507.15118", "abs": "https://arxiv.org/abs/2507.15118", "authors": ["Szymon Mazurek", "Stephen Moore", "Alessandro Crimi"], "title": "Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings", "categories": ["eess.SP", "cs.LG", "cs.NE"], "comment": null, "summary": "Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce\nneurologists and costly diagnostic tools. We propose a graph-based deep\nlearning framework to detect epilepsy from low-cost Electroencephalography\n(EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus\nis on fair, accessible automatic assessment and explainability to shed light on\nepilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs,\nclassify them, and identify interchannel relationships and temporal dynamics\nusing graph attention networks (GAT). To emphasize connectivity biomarkers, we\nadapt the inherently node-focused GAT to analyze edges. We also designed signal\npreprocessing for low-fidelity recordings and a lightweight GAT architecture\ntrained on Google Colab and deployed on RaspberryPi devices. Results: The\napproach achieves promising classification performance, outperforming a\nstandard classifier based on random forest and graph convolutional networks in\nterms of accuracy and robustness over multiple sessions, but also highlighting\nspecific connections in the fronto-temporal region. Conclusions: The results\nhighlight the potential of GATs to provide insightful and scalable diagnostic\nsupport for epilepsy in underserved regions, paving the way for affordable and\naccessible neurodiagnostic tools.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4f4e\u6210\u672c\u8111\u7535\u56fe\u786c\u4ef6\u68c0\u6d4b\u766b\u75eb\uff0c\u5728\u5c3c\u65e5\u5229\u4e9a\u548c\u51e0\u5185\u4e9a\u6bd4\u7ecd\u7684\u8bb0\u5f55\u4e0a\u6d4b\u8bd5\uff0c\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u6b20\u53d1\u8fbe\u5730\u533a\u63d0\u4f9b\u8bca\u65ad\u652f\u6301\u3002", "motivation": "\u4f4e\u6536\u5165\u56fd\u5bb6\u56e0\u795e\u7ecf\u79d1\u533b\u751f\u7a00\u7f3a\u548c\u8bca\u65ad\u5de5\u5177\u6602\u8d35\uff0c\u766b\u75eb\u8bca\u65ad\u4e0d\u8db3\uff0c\u9700\u516c\u5e73\u3001\u53ef\u53ca\u7684\u81ea\u52a8\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u68c0\u6d4b\u766b\u75eb\u3002", "method": "\u5c06\u8111\u7535\u56fe\u4fe1\u53f7\u5efa\u6a21\u4e3a\u65f6\u7a7a\u56fe\uff0c\u7528\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u5206\u7c7b\uff0c\u8c03\u6574GAT\u5206\u6790\u8fb9\uff0c\u8bbe\u8ba1\u4f4e\u8d28\u91cf\u8bb0\u5f55\u7684\u4fe1\u53f7\u9884\u5904\u7406\u548c\u8f7b\u91cf\u7ea7GAT\u67b6\u6784\uff0c\u5728Google Colab\u8bad\u7ec3\u5e76\u90e8\u7f72\u5230RaspberryPi\u8bbe\u5907\u3002", "result": "\u8be5\u65b9\u6cd5\u5206\u7c7b\u6027\u80fd\u597d\uff0c\u5728\u51c6\u786e\u6027\u548c\u591a\u65f6\u6bb5\u7a33\u5065\u6027\u4e0a\u4f18\u4e8e\u968f\u673a\u68ee\u6797\u548c\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u6807\u51c6\u5206\u7c7b\u5668\uff0c\u8fd8\u7a81\u51fa\u4e86\u989d\u989e\u53f6\u533a\u57df\u7684\u7279\u5b9a\u8fde\u63a5\u3002", "conclusion": "\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u6709\u6f5c\u529b\u4e3a\u6b20\u53d1\u8fbe\u5730\u533a\u766b\u75eb\u8bca\u65ad\u63d0\u4f9b\u6709\u6d1e\u5bdf\u529b\u548c\u53ef\u6269\u5c55\u7684\u652f\u6301\uff0c\u4e3a\u53ef\u8d1f\u62c5\u548c\u53ef\u53ca\u7684\u795e\u7ecf\u8bca\u65ad\u5de5\u5177\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.15233", "pdf": "https://arxiv.org/pdf/2507.15233", "abs": "https://arxiv.org/abs/2507.15233", "authors": ["Jintao Liu", "Mohammad Goudarzi", "Adel Nadjaran Toosi"], "title": "An ML-Driven Participant Selection Technique for Federated Recommendation System in Edge-Cloud Computing", "categories": ["cs.DC"], "comment": null, "summary": "Recommendation systems (RS) personalize content by analyzing user\npreferences, but typically require centralized collection of user data, raising\nprivacy and scalability concerns. Federated Recommendation Systems (FRS)\naddress these issues by enabling distributed, privacy-preserving model training\nacross edge devices, keeping raw data on-device. Although existing FRS\nframeworks benefit from on-device feature extraction and privacy preservation,\nthey suffer from heterogeneous device capabilities, non-independent and\nidentically distributed (non-IID) data, and communication bottlenecks. To\novercome these limitations, we propose a multi-objective reinforcement learning\n(RL) participant selection that jointly optimizes historical client performance\nreputation (CPR), data utility, and system efficiency. First, we define a\ncomposite client-utility function combining CPR, system capability, and data\nquality. Next, we embed this utility into a multi-armed bandit (MAB) framework\nand dynamically balance exploration-exploitation to select participants.\nFinally, we practically implement our approach using the PySyft framework on an\nedge-cloud testbed, and evaluate it on a multimodal movie-recommendation task\nbuilt from the MovieLens-100K dataset. Across four different skewed\ndata-partition scenarios, our MAB-based selection accelerates convergence by\n32-50% in time-to-target AUC and reduces total wall-clock training time by up\nto 46%, while matching or slightly improving final AUC, NDCG@50, and Recall@50\ncompared to existing FRS baselines. Our results demonstrate that adaptive,\nreward-driven client sampling can substantially enhance both efficiency and\nfairness in real-world federated deployments.", "AI": {"tldr": "\u73b0\u6709FRS\u6846\u67b6\u6709\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u53c2\u4e0e\u8005\u9009\u62e9\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u6548\u7387\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709FRS\u6846\u67b6\u5b58\u5728\u8bbe\u5907\u80fd\u529b\u5f02\u6784\u3001\u6570\u636e\u975eIID\u548c\u901a\u4fe1\u74f6\u9888\u7b49\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5b9a\u4e49\u590d\u5408\u5ba2\u6237\u7aef\u6548\u7528\u51fd\u6570\uff0c\u5d4c\u5165\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\u52a8\u6001\u5e73\u8861\u63a2\u7d22-\u5229\u7528\u4ee5\u9009\u62e9\u53c2\u4e0e\u8005\uff0c\u7528PySyft\u6846\u67b6\u5b9e\u73b0\u5e76\u5728\u8fb9\u7f18\u4e91\u6d4b\u8bd5\u53f0\u8bc4\u4f30\u3002", "result": "\u5728\u56db\u79cd\u6570\u636e\u5206\u533a\u573a\u666f\u4e0b\uff0c\u57fa\u4e8eMAB\u7684\u9009\u62e9\u52a0\u901f\u6536\u655b32 - 50%\uff0c\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u8fbe46%\uff0c\u6307\u6807\u8868\u73b0\u76f8\u5f53\u6216\u7565\u4f18\u3002", "conclusion": "\u81ea\u9002\u5e94\u3001\u5956\u52b1\u9a71\u52a8\u7684\u5ba2\u6237\u7aef\u91c7\u6837\u80fd\u663e\u8457\u63d0\u5347\u8054\u90a6\u90e8\u7f72\u7684\u6548\u7387\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2507.14417", "pdf": "https://arxiv.org/pdf/2507.14417", "abs": "https://arxiv.org/abs/2507.14417", "authors": ["Aryo Pradipta Gema", "Alexander H\u00e4gele", "Runjin Chen", "Andy Arditi", "Jacob Goldman-Wetzler", "Kit Fraser-Taliente", "Henry Sleight", "Linda Petrini", "Julian Michael", "Beatrice Alex", "Pasquale Minervini", "Yanda Chen", "Joe Benton", "Ethan Perez"], "title": "Inverse Scaling in Test-Time Compute", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "We construct evaluation tasks where extending the reasoning length of Large\nReasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling\nrelationship between test-time compute and accuracy. Our evaluation tasks span\nfour categories: simple counting tasks with distractors, regression tasks with\nspurious features, deduction tasks with constraint tracking, and advanced AI\nrisks. We identify five distinct failure modes when models reason for longer:\n1) Claude models become increasingly distracted by irrelevant information; 2)\nOpenAI o-series models resist distractors but overfit to problem framings; 3)\nmodels shift from reasonable priors to spurious correlations; 4) all models\nshow difficulties in maintaining focus on complex deductive tasks; and 5)\nextended reasoning may amplify concerning behaviors, with Claude Sonnet 4\nshowing increased expressions of self-preservation. These findings suggest that\nwhile test-time compute scaling remains promising for improving model\ncapabilities, it may inadvertently reinforce problematic reasoning patterns.\nOur results demonstrate the importance of evaluating models across diverse\nreasoning lengths to identify and address these failure modes in LRMs.", "AI": {"tldr": "\u6784\u5efa\u8bc4\u4f30\u4efb\u52a1\u53d1\u73b0\u5927\u63a8\u7406\u6a21\u578b\u63a8\u7406\u957f\u5ea6\u589e\u52a0\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u5b58\u5728\u53cd\u5411\u7f29\u653e\u5173\u7cfb\uff0c\u8bc6\u522b\u51fa\u4e94\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5f3a\u8c03\u8bc4\u4f30\u4e0d\u540c\u63a8\u7406\u957f\u5ea6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u63a2\u7a76\u5927\u63a8\u7406\u6a21\u578b\u63a8\u7406\u957f\u5ea6\u4e0e\u6027\u80fd\u7684\u5173\u7cfb\u4ee5\u53ca\u63a8\u7406\u957f\u5ea6\u589e\u52a0\u65f6\u6a21\u578b\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u6784\u5efa\u6db5\u76d6\u56db\u7c7b\u7684\u8bc4\u4f30\u4efb\u52a1\uff0c\u5bf9\u5927\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u63a8\u7406\u957f\u5ea6\u589e\u52a0\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u8bc6\u522b\u51fa\u4e94\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5982Claude\u6a21\u578b\u6613\u88ab\u65e0\u5173\u4fe1\u606f\u5e72\u6270\u7b49\u3002", "conclusion": "\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u6269\u5c55\u867d\u6709\u63d0\u5347\u6a21\u578b\u80fd\u529b\u7684\u6f5c\u529b\uff0c\u4f46\u53ef\u80fd\u5f3a\u5316\u6709\u95ee\u9898\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u9700\u8bc4\u4f30\u4e0d\u540c\u63a8\u7406\u957f\u5ea6\u4ee5\u89e3\u51b3\u5931\u8d25\u6a21\u5f0f\u3002"}}
{"id": "2507.14687", "pdf": "https://arxiv.org/pdf/2507.14687", "abs": "https://arxiv.org/abs/2507.14687", "authors": ["Robin Lee", "Youngho Nam"], "title": "An Efficient Algorithm for Generating Minimal Unique-Cause MC/DC Test cases for Singular Boolean Expressions", "categories": ["cs.SE", "68Q60, 03B70", "D.2.5"], "comment": "10 pages, 5 figures", "summary": "Modified Condition/Decision Coverage (MC/DC) is a mandatory structural\ncoverage criterion for ensuring the reliability and safety of critical systems.\nWhile its strictest form, Unique-Cause MC/DC, offers the highest assurance,\nresearch on its efficient test generation has been lacking. This gap is\nparticularly significant, as an analysis of large-scale avionics systems shows\nthat 99.7% of all conditional decisions are, in fact, Singular Boolean\nExpressions (SBEs) the ideal structure for applying Unique-Cause MC/DC. This\npaper proposes 'Robin's Rule', a deterministic algorithm that directly\nconstructs a minimal test set of N + 1 cases to guarantee 100% Unique-Cause\nMC/DC for SBEs with N conditions, without generating a full truth table. To\nvalidate our approach, we constructed a benchmark by reformulating the TCAS-II\nspecifications into SBEs and verified the results using an industry-standard,\ncertified commercial tool. The results confirm that our method consistently\nachieves 100% coverage with the theoretical minimum number of tests and is more\nefficient than the commercial tool. This work provides a practical and provably\noptimal solution for verifying safety-critical systems, ensuring both rigor and\nefficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRobin's Rule\u7b97\u6cd5\uff0c\u4e3a\u5947\u5f02\u5e03\u5c14\u8868\u8fbe\u5f0f\uff08SBEs\uff09\u6784\u5efa\u6700\u5c0f\u6d4b\u8bd5\u96c6\u4ee5\u5b9e\u73b0100%\u552f\u4e00\u539f\u56e0MC/DC\u8986\u76d6\uff0c\u7ecfTCAS - II\u89c4\u8303\u9a8c\u8bc1\uff0c\u6bd4\u5546\u4e1a\u5de5\u5177\u66f4\u9ad8\u6548\u3002", "motivation": "Unique - Cause MC/DC\u867d\u80fd\u63d0\u4f9b\u9ad8\u4fdd\u8bc1\uff0c\u4f46\u5bf9\u5176\u9ad8\u6548\u6d4b\u8bd5\u751f\u6210\u7684\u7814\u7a76\u4e0d\u8db3\uff0c\u4e14\u5927\u89c4\u6a21\u822a\u7a7a\u7535\u5b50\u7cfb\u7edf\u4e2d\u591a\u6570\u6761\u4ef6\u51b3\u7b56\u4e3aSBEs\uff0c\u9002\u5408\u5e94\u7528Unique - Cause MC/DC\u3002", "method": "\u63d0\u51faRobin's Rule\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u76f4\u63a5\u6784\u5efaSBEs\u7684\u6700\u5c0f\u6d4b\u8bd5\u96c6\uff0c\u4e0d\u751f\u6210\u5b8c\u6574\u771f\u503c\u8868\uff1b\u5c06TCAS - II\u89c4\u8303\u91cd\u6784\u4e3aSBEs\u6784\u5efa\u57fa\u51c6\uff0c\u7528\u884c\u4e1a\u6807\u51c6\u8ba4\u8bc1\u5546\u4e1a\u5de5\u5177\u9a8c\u8bc1\u7ed3\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u59cb\u7ec8\u4ee5\u7406\u8bba\u6700\u5c11\u6d4b\u8bd5\u6b21\u6570\u8fbe\u5230100%\u8986\u76d6\uff0c\u4e14\u6bd4\u5546\u4e1a\u5de5\u5177\u66f4\u9ad8\u6548\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9a8c\u8bc1\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u987e\u4e25\u8c28\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.14946", "pdf": "https://arxiv.org/pdf/2507.14946", "abs": "https://arxiv.org/abs/2507.14946", "authors": ["Amna Ali", "Liyanage C. De Silva", "Pg Emeroylariffion Abas"], "title": "FullRecall: A Semantic Search-Based Ranking Approach for Maximizing Recall in Patent Retrieval", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Patent examiners and inventors face significant pressure to verify the\noriginality and non-obviousness of inventions, and the intricate nature of\npatent data intensifies the challenges of patent retrieval. Therefore, there is\na pressing need to devise cutting-edge retrieval strategies that can reliably\nachieve the desired recall. This study introduces FullRecall, a novel patent\nretrieval approach that effectively manages the complexity of patent data while\nmaintaining the reliability of relevance matching and maximising recall. It\nleverages IPC-guided knowledge to generate informative phrases, which are\nprocessed to extract key information in the form of noun phrases characterising\nthe query patent under observation. From these, the top k keyphrases are\nselected to construct a query for retrieving a focused subset of the dataset.\nThis initial retrieval step achieves complete recall, successfully capturing\nall relevant documents. To further refine the results, a ranking scheme is\napplied to the retrieved subset, reducing its size while maintaining 100%\nrecall. This multi-phase process demonstrates an effective strategy for\nbalancing precision and recall in patent retrieval tasks. Comprehensive\nexperiments were conducted, and the results were compared with baseline\nstudies, namely HRR2 [1] and ReQ-ReC [2]. The proposed approach yielded\nsuperior results, achieving 100% recall in all five test cases. However,\nHRR2[1] recall values across the five test cases were 10%, 25%, 33.3%, 0%, and\n14.29%, while ReQ-ReC [2] showed 50% for the first test case, 25% for the\nsecond test case, and 0% for the third, fourth, and fifth test cases. The 100%\nrecall ensures that no relevant prior art is overlooked, thereby strengthening\nthe patent pre-filing and examination processes, hence reducing potential legal\nrisks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u4e13\u5229\u68c0\u7d22\u65b9\u6cd5FullRecall\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u5904\u7406\u5e73\u8861\u67e5\u51c6\u7387\u548c\u67e5\u5168\u7387\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u57fa\u7ebf\u7814\u7a76\uff0c\u5b9e\u73b0100%\u67e5\u5168\u7387\uff0c\u6709\u52a9\u4e8e\u52a0\u5f3a\u4e13\u5229\u6d41\u7a0b\u5e76\u964d\u4f4e\u6cd5\u5f8b\u98ce\u9669\u3002", "motivation": "\u4e13\u5229\u5ba1\u67e5\u5458\u548c\u53d1\u660e\u8005\u5728\u9a8c\u8bc1\u53d1\u660e\u539f\u521b\u6027\u548c\u975e\u663e\u800c\u6613\u89c1\u6027\u65f6\u9762\u4e34\u538b\u529b\uff0c\u4e13\u5229\u6570\u636e\u590d\u6742\u589e\u52a0\u68c0\u7d22\u6311\u6218\uff0c\u9700\u8bbe\u8ba1\u65b0\u68c0\u7d22\u7b56\u7565\u63d0\u9ad8\u67e5\u5168\u7387\u3002", "method": "\u63d0\u51faFullRecall\u65b9\u6cd5\uff0c\u5229\u7528IPC\u5f15\u5bfc\u77e5\u8bc6\u751f\u6210\u4fe1\u606f\u77ed\u8bed\uff0c\u63d0\u53d6\u540d\u8bcd\u77ed\u8bed\u4f5c\u4e3a\u5173\u952e\u4fe1\u606f\uff0c\u9009\u524dk\u4e2a\u5173\u952e\u77ed\u8bed\u6784\u5efa\u67e5\u8be2\u4ee5\u521d\u6b65\u68c0\u7d22\uff0c\u518d\u7528\u6392\u5e8f\u65b9\u6848\u7cbe\u70bc\u7ed3\u679c\u3002", "result": "\u4e0e\u57fa\u7ebf\u7814\u7a76HRR2\u548cReQ - ReC\u76f8\u6bd4\uff0cFullRecall\u5728\u4e94\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u4e2d\u5747\u5b9e\u73b0100%\u67e5\u5168\u7387\uff0c\u800c\u57fa\u7ebf\u7814\u7a76\u67e5\u5168\u7387\u8f83\u4f4e\u3002", "conclusion": "FullRecall\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u4e13\u5229\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u67e5\u51c6\u7387\u548c\u67e5\u5168\u7387\uff0c\u786e\u4fdd\u4e0d\u9057\u6f0f\u76f8\u5173\u73b0\u6709\u6280\u672f\uff0c\u52a0\u5f3a\u4e13\u5229\u9884\u7533\u8bf7\u548c\u5ba1\u67e5\u6d41\u7a0b\uff0c\u964d\u4f4e\u6f5c\u5728\u6cd5\u5f8b\u98ce\u9669\u3002"}}
{"id": "2507.15771", "pdf": "https://arxiv.org/pdf/2507.15771", "abs": "https://arxiv.org/abs/2507.15771", "authors": ["Maxim Chupilkin"], "title": "Left Leaning Models: AI Assumptions on Economic Policy", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC"], "comment": "8 pages, 5 tables", "summary": "How does AI think about economic policy? While the use of large language\nmodels (LLMs) in economics is growing exponentially, their assumptions on\neconomic issues remain a black box. This paper uses a conjoint experiment to\ntease out the main factors influencing LLMs' evaluation of economic policy. It\nfinds that LLMs are most sensitive to unemployment, inequality, financial\nstability, and environmental harm and less sensitive to traditional\nmacroeconomic concerns such as economic growth, inflation, and government debt.\nThe results are remarkably consistent across scenarios and across models.", "AI": {"tldr": "\u672c\u6587\u7528\u8054\u5408\u5b9e\u9a8c\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u7ecf\u6d4e\u653f\u7b56\u7684\u4e3b\u8981\u5f71\u54cd\u56e0\u7d20\uff0c\u53d1\u73b0\u5176\u5bf9\u5931\u4e1a\u3001\u4e0d\u5e73\u7b49\u3001\u91d1\u878d\u7a33\u5b9a\u548c\u73af\u5883\u5371\u5bb3\u66f4\u654f\u611f\uff0c\u7ed3\u679c\u8de8\u573a\u666f\u548c\u6a21\u578b\u8f83\u4e00\u81f4\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ecf\u6d4e\u5b66\u4e2d\u7684\u5e94\u7528\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u4f46\u5bf9\u7ecf\u6d4e\u95ee\u9898\u7684\u5047\u8bbe\u4ecd\u662f\u9ed1\u7bb1\uff0c\u9700\u4e86\u89e3\u5176\u8bc4\u4f30\u7ecf\u6d4e\u653f\u7b56\u7684\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u8054\u5408\u5b9e\u9a8c\u7684\u65b9\u6cd5\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u5931\u4e1a\u3001\u4e0d\u5e73\u7b49\u3001\u91d1\u878d\u7a33\u5b9a\u548c\u73af\u5883\u5371\u5bb3\u6700\u654f\u611f\uff0c\u5bf9\u7ecf\u6d4e\u589e\u957f\u3001\u901a\u80c0\u548c\u653f\u5e9c\u503a\u52a1\u7b49\u4f20\u7edf\u5b8f\u89c2\u7ecf\u6d4e\u95ee\u9898\u4e0d\u592a\u654f\u611f\uff0c\u4e14\u7ed3\u679c\u8de8\u573a\u666f\u548c\u6a21\u578b\u8f83\u4e00\u81f4\u3002", "conclusion": "\u660e\u786e\u4e86\u5f71\u54cd\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u7ecf\u6d4e\u653f\u7b56\u7684\u4e3b\u8981\u56e0\u7d20\u53ca\u5176\u654f\u611f\u5ea6\u7279\u70b9\u3002"}}
{"id": "2507.15727", "pdf": "https://arxiv.org/pdf/2507.15727", "abs": "https://arxiv.org/abs/2507.15727", "authors": ["Xuchuang Wang", "Bo Sun", "Hedyeh Beyhaghi", "John C. S. Lui", "Mohammad Hajiesmaili", "Adam Wierman"], "title": "Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems", "categories": ["cs.LG", "cs.GT", "cs.MA"], "comment": null, "summary": "This paper introduces a novel multi-agent ski-rental problem that generalizes\nthe classical ski-rental dilemma to a group setting where agents incur\nindividual and shared costs. In our model, each agent can either rent at a\nfixed daily cost, or purchase a pass at an individual cost, with an additional\nthird option of a discounted group pass available to all. We consider scenarios\nin which agents' active days differ, leading to dynamic states as agents drop\nout of the decision process. To address this problem from different\nperspectives, we define three distinct competitive ratios: overall,\nstate-dependent, and individual rational. For each objective, we design and\nanalyze optimal deterministic and randomized policies. Our deterministic\npolicies employ state-aware threshold functions that adapt to the dynamic\nstates, while our randomized policies sample and resample thresholds from\ntailored state-aware distributions. The analysis reveals that symmetric\npolicies, in which all agents use the same threshold, outperform asymmetric\nones. Our results provide competitive ratio upper and lower bounds and extend\nclassical ski-rental insights to multi-agent settings, highlighting both\ntheoretical and practical implications for group decision-making under\nuncertainty.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\uff0c\u5b9a\u4e49\u4e09\u79cd\u7ade\u4e89\u6bd4\u7387\uff0c\u8bbe\u8ba1\u5206\u6790\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\uff0c\u5bf9\u79f0\u7b56\u7565\u8868\u73b0\u66f4\u597d\u5e76\u7ed9\u51fa\u4e0a\u4e0b\u754c\u3002", "motivation": "\u5c06\u7ecf\u5178\u6ed1\u96ea\u79df\u8d41\u56f0\u5883\u63a8\u5e7f\u5230\u7fa4\u4f53\u573a\u666f\uff0c\u8003\u8651\u4e2a\u4f53\u548c\u5171\u4eab\u6210\u672c\u4ee5\u53ca\u52a8\u6001\u72b6\u6001\u3002", "method": "\u5b9a\u4e49\u4e09\u79cd\u7ade\u4e89\u6bd4\u7387\uff0c\u8bbe\u8ba1\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\uff0c\u786e\u5b9a\u6027\u7b56\u7565\u7528\u72b6\u6001\u611f\u77e5\u9608\u503c\u51fd\u6570\uff0c\u968f\u673a\u7b56\u7565\u4ece\u5b9a\u5236\u5206\u5e03\u91c7\u6837\u9608\u503c\u3002", "result": "\u5bf9\u79f0\u7b56\u7565\u4f18\u4e8e\u975e\u5bf9\u79f0\u7b56\u7565\uff0c\u7ed9\u51fa\u7ade\u4e89\u6bd4\u7387\u4e0a\u4e0b\u754c\u3002", "conclusion": "\u5c06\u7ecf\u5178\u6ed1\u96ea\u79df\u8d41\u89c1\u89e3\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u573a\u666f\uff0c\u5bf9\u4e0d\u786e\u5b9a\u4e0b\u7fa4\u4f53\u51b3\u7b56\u6709\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2507.14180", "pdf": "https://arxiv.org/pdf/2507.14180", "abs": "https://arxiv.org/abs/2507.14180", "authors": ["Nasir Khan", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil", "Sinem Coleri"], "title": "Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In line with the AI-native 6G vision, explainability and robustness are\ncrucial for building trust and ensuring reliable performance in millimeter-wave\n(mmWave) systems. Efficient beam alignment is essential for initial access, but\ndeep learning (DL) solutions face challenges, including high data collection\noverhead, hardware constraints, lack of explainability, and susceptibility to\nadversarial attacks. This paper proposes a robust and explainable DL-based beam\nalignment engine (BAE) for mmWave multiple-input multiple output (MIMO)\nsystems. The BAE uses received signal strength indicator (RSSI) measurements\nfrom wide beams to predict the best narrow beam, reducing the overhead of\nexhaustive beam sweeping. To overcome the challenge of real-world data\ncollection, this work leverages a site-specific digital twin (DT) to generate\nsynthetic channel data closely resembling real-world environments. A model\nrefinement via transfer learning is proposed to fine-tune the pre-trained model\nresiding in the DT with minimal real-world data, effectively bridging\nmismatches between the digital replica and real-world environments. To reduce\nbeam training overhead and enhance transparency, the framework uses deep\nShapley additive explanations (SHAP) to rank input features by importance,\nprioritizing key spatial directions and minimizing beam sweeping. It also\nincorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a\ncredibility metric for detecting out-of-distribution inputs and ensuring\nrobust, transparent decision-making. Experimental results show that the\nproposed framework reduces real-world data needs by 70%, beam training overhead\nby 62%, and improves outlier detection robustness by up to 8.5x, achieving\nnear-optimal spectral efficiency and transparent decision making compared to\ntraditional softmax based DL models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u7684BAE\uff0c\u5229\u7528\u6570\u5b57\u5b6a\u751f\u3001\u8fc1\u79fb\u5b66\u4e60\u3001SHAP\u548cDkNN\u7b97\u6cd5\uff0c\u51cf\u5c11\u6570\u636e\u9700\u6c42\u4e0e\u8bad\u7ec3\u5f00\u9500\uff0c\u63d0\u5347\u9c81\u68d2\u6027\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u5728\u6beb\u7c73\u6ce2\u7cfb\u7edf\u6ce2\u675f\u5bf9\u9f50\u4e2d\u9762\u4e34\u9ad8\u6570\u636e\u6536\u96c6\u5f00\u9500\u3001\u786c\u4ef6\u9650\u5236\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u6613\u53d7\u5bf9\u6297\u653b\u51fb\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6784\u5efa\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u7cfb\u7edf\u3002", "method": "\u63d0\u51faBAE\uff0c\u5229\u7528RSSI\u6d4b\u91cf\u9884\u6d4b\u6700\u4f73\u7a84\u6ce2\u675f\uff1b\u501f\u52a9\u6570\u5b57\u5b6a\u751f\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u7528\u8fc1\u79fb\u5b66\u4e60\u5fae\u8c03\u6a21\u578b\uff1b\u7528SHAP\u5bf9\u8f93\u5165\u7279\u5f81\u6392\u5e8f\uff0c\u7528DkNN\u7b97\u6cd5\u68c0\u6d4b\u5206\u5e03\u5916\u8f93\u5165\u3002", "result": "\u51cf\u5c1170%\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u9700\u6c42\u300162%\u7684\u6ce2\u675f\u8bad\u7ec3\u5f00\u9500\uff0c\u5c06\u5f02\u5e38\u68c0\u6d4b\u9c81\u68d2\u6027\u63d0\u9ad88.5\u500d\uff0c\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u9891\u8c31\u6548\u7387\u548c\u900f\u660e\u51b3\u7b56\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8esoftmax\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5728\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u6ce2\u675f\u5bf9\u9f50\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u80fd\u5b9e\u73b0\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u51b3\u7b56\u3002"}}
{"id": "2507.15235", "pdf": "https://arxiv.org/pdf/2507.15235", "abs": "https://arxiv.org/abs/2507.15235", "authors": ["Miao Huang", "Hongqiao Wang", "Kunyu Wu"], "title": "Accelerated Bayesian Optimal Experimental Design via Conditional Density Estimation and Informative Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The Design of Experiments (DOEs) is a fundamental scientific methodology that\nprovides researchers with systematic principles and techniques to enhance the\nvalidity, reliability, and efficiency of experimental outcomes. In this study,\nwe explore optimal experimental design within a Bayesian framework, utilizing\nBayes' theorem to reformulate the utility expectation--originally expressed as\na nested double integral--into an independent double integral form,\nsignificantly improving numerical efficiency. To further accelerate the\ncomputation of the proposed utility expectation, conditional density estimation\nis employed to approximate the ratio of two Gaussian random fields, while\ncovariance serves as a selection criterion to identify informative datasets\nduring model fitting and integral evaluation. In scenarios characterized by low\nsimulation efficiency and high costs of raw data acquisition, key challenges\nsuch as surrogate modeling, failure probability estimation, and parameter\ninference are systematically restructured within the Bayesian experimental\ndesign framework. The effectiveness of the proposed methodology is validated\nthrough both theoretical analysis and practical applications, demonstrating its\npotential for enhancing experimental efficiency and decision-making under\nuncertainty.", "AI": {"tldr": "\u672c\u6587\u5728\u8d1d\u53f6\u65af\u6846\u67b6\u4e0b\u63a2\u7d22\u6700\u4f18\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u6539\u8fdb\u6548\u7528\u671f\u671b\u8ba1\u7b97\uff0c\u89e3\u51b3\u5173\u952e\u6311\u6218\uff0c\u7ecf\u7406\u8bba\u548c\u5b9e\u8df5\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u63d0\u5347\u5b9e\u9a8c\u7ed3\u679c\u7684\u6709\u6548\u6027\u3001\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u89e3\u51b3\u4f4e\u6a21\u62df\u6548\u7387\u548c\u9ad8\u6570\u636e\u83b7\u53d6\u6210\u672c\u573a\u666f\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u8d1d\u53f6\u65af\u5b9a\u7406\u5c06\u6548\u7528\u671f\u671b\u91cd\u6784\u6210\u72ec\u7acb\u53cc\u91cd\u79ef\u5206\u5f62\u5f0f\uff0c\u7528\u6761\u4ef6\u5bc6\u5ea6\u4f30\u8ba1\u8fd1\u4f3c\u9ad8\u65af\u968f\u673a\u573a\u6bd4\u7387\uff0c\u4ee5\u534f\u65b9\u5dee\u9009\u6570\u636e\u96c6\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u7ecf\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u63d0\u9ad8\u5b9e\u9a8c\u6548\u7387\u548c\u8f85\u52a9\u51b3\u7b56\u3002"}}
{"id": "2507.15598", "pdf": "https://arxiv.org/pdf/2507.15598", "abs": "https://arxiv.org/abs/2507.15598", "authors": ["Ruoxu Cen", "Henry Fleischmann", "George Z. Li", "Jason Li", "Debmalya Panigrahi"], "title": "Fast Algorithms for Graph Arboricity and Related Problems", "categories": ["cs.DS"], "comment": "FOCS 2025. 25 pages, 3 figures", "summary": "We give an algorithm for finding the arboricity of a weighted, undirected\ngraph, defined as the minimum number of spanning forests that cover all edges\nof the graph, in $\\sqrt{n} m^{1+o(1)}$ time. This improves on the previous best\nbound of $\\tilde{O}(nm)$ for weighted graphs and $\\tilde{O}(m^{3/2}) $ for\nunweighted graphs (Gabow 1995) for this problem. The running time of our\nalgorithm is dominated by a logarithmic number of calls to a directed global\nminimum cut subroutine -- if the running time of the latter problem improves to\n$m^{1+o(1)}$ (thereby matching the running time of maximum flow), the running\ntime of our arboricity algorithm would improve further to $m^{1+o(1)}$.\n  We also give a new algorithm for computing the entire cut hierarchy --\nlaminar multiway cuts with minimum cut ratio in recursively defined induced\nsubgraphs -- in $m n^{1+o(1)}$ time. The cut hierarchy yields the ideal edge\nloads (Thorup 2001) in a fractional spanning tree packing of the graph which,\nwe show, also corresponds to a max-entropy solution in the spanning tree\npolytope. For the cut hierarchy problem, the previous best bound was\n$\\tilde{O}(n^2 m)$ for weighted graphs and $\\tilde{O}(n m^{3/2})$ for\nunweighted graphs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15132", "pdf": "https://arxiv.org/pdf/2507.15132", "abs": "https://arxiv.org/abs/2507.15132", "authors": ["Joanna Komorniczak"], "title": "Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "The research community continues to seek increasingly more advanced synthetic\ndata generators to reliably evaluate the strengths and limitations of machine\nlearning methods. This work aims to increase the availability of datasets\nencompassing a diverse range of problem complexities by proposing a genetic\nalgorithm that optimizes a set of problem complexity measures for\nclassification and regression tasks towards specific targets. For\nclassification, a set of 10 complexity measures was used, while for regression\ntasks, 4 measures demonstrating promising optimization capabilities were\nselected. Experiments confirmed that the proposed genetic algorithm can\ngenerate datasets with varying levels of difficulty by transforming\nsynthetically created datasets to achieve target complexity values through\nlinear feature projections. Evaluations involving state-of-the-art classifiers\nand regressors revealed a correlation between the complexity of the generated\ndata and the recognition quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u6570\u636e\u96c6\u590d\u6742\u5ea6\u4ee5\u751f\u6210\u4e0d\u540c\u96be\u5ea6\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6709\u6548\u6027\u53ca\u6570\u636e\u590d\u6742\u5ea6\u4e0e\u8bc6\u522b\u8d28\u91cf\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u7814\u7a76\u754c\u9700\u66f4\u5148\u8fdb\u5408\u6210\u6570\u636e\u751f\u6210\u5668\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u672c\u6587\u65e8\u5728\u589e\u52a0\u4e0d\u540c\u95ee\u9898\u590d\u6742\u5ea6\u6570\u636e\u96c6\u7684\u53ef\u7528\u6027\u3002", "method": "\u63d0\u51fa\u9057\u4f20\u7b97\u6cd5\uff0c\u9488\u5bf9\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4f18\u5316\u4e00\u7ec4\u95ee\u9898\u590d\u6742\u5ea6\u5ea6\u91cf\u81f3\u7279\u5b9a\u76ee\u6807\u3002\u5206\u7c7b\u752810\u4e2a\u590d\u6742\u5ea6\u5ea6\u91cf\uff0c\u56de\u5f52\u90094\u4e2a\u6709\u4f18\u5316\u6f5c\u529b\u7684\u5ea6\u91cf\u3002\u901a\u8fc7\u7ebf\u6027\u7279\u5f81\u6295\u5f71\u8f6c\u6362\u5408\u6210\u6570\u636e\u96c6\u4ee5\u8fbe\u5230\u76ee\u6807\u590d\u6742\u5ea6\u503c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u9057\u4f20\u7b97\u6cd5\u53ef\u751f\u6210\u4e0d\u540c\u96be\u5ea6\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u663e\u793a\u751f\u6210\u6570\u636e\u7684\u590d\u6742\u5ea6\u4e0e\u8bc6\u522b\u8d28\u91cf\u76f8\u5173\u3002", "conclusion": "\u6240\u63d0\u9057\u4f20\u7b97\u6cd5\u80fd\u6709\u6548\u751f\u6210\u4e0d\u540c\u590d\u6742\u5ea6\u6570\u636e\u96c6\uff0c\u6570\u636e\u590d\u6742\u5ea6\u4f1a\u5f71\u54cd\u8bc6\u522b\u8d28\u91cf\u3002"}}
{"id": "2507.15553", "pdf": "https://arxiv.org/pdf/2507.15553", "abs": "https://arxiv.org/abs/2507.15553", "authors": ["Shibo Yu", "Mohammad Goudarzi", "Adel Nadjaran Toosi"], "title": "Efficient Routing of Inference Requests across LLM Instances in Cloud-Edge Computing", "categories": ["cs.DC"], "comment": null, "summary": "The rising demand for Large Language Model (LLM) inference services has\nintensified pressure on computational resources, resulting in latency and cost\nchallenges. This paper introduces a novel routing algorithm based on the\nNon-dominated Sorting Genetic Algorithm II (NSGA-II) to distribute inference\nrequests across heterogeneous LLM instances in a cloud-edge computing\nenvironment. Formulated as a multi-objective optimization problem, the\nalgorithm balances response quality, response time, and inference cost,\nadapting to request heterogeneity (e.g., varying complexity and prompt lengths)\nand node diversity (e.g., edge vs. cloud resources). This adaptive routing\nalgorithm optimizes performance under dynamic workloads. We benchmark the\napproach using a testbed with datasets including Stanford Question Answering\nDataset (SQuAD), Mostly Basic Python Problems (MBPP), Hella Situations With\nAdversarial Generations (HellaSwag), and Grade School Math 8K (GSM8K).\nExperimental results show our solution, compared to the baselines, achieves up\nto 95.2% and 34.9% improvements in terms of response time and cost,\nrespectively. These findings validate the algorithm's effectiveness for\nscalable LLM deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eNSGA - II\u7684\u8def\u7531\u7b97\u6cd5\uff0c\u5728\u4e91\u8fb9\u8ba1\u7b97\u73af\u5883\u4e2d\u5206\u914d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8bf7\u6c42\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u7b97\u6cd5\u80fd\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u670d\u52a1\u9700\u6c42\u589e\u957f\u4f7f\u8ba1\u7b97\u8d44\u6e90\u538b\u529b\u589e\u5927\uff0c\u5e26\u6765\u5ef6\u8fdf\u548c\u6210\u672c\u6311\u6218\u3002", "method": "\u5f15\u5165\u57fa\u4e8eNSGA - II\u7684\u8def\u7531\u7b97\u6cd5\uff0c\u5c06\u5176\u6784\u9020\u6210\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u4ee5\u5e73\u8861\u54cd\u5e94\u8d28\u91cf\u3001\u65f6\u95f4\u548c\u6210\u672c\uff0c\u9002\u5e94\u8bf7\u6c42\u548c\u8282\u70b9\u5dee\u5f02\u3002\u4f7f\u7528\u5305\u542bSQuAD\u3001MBPP\u7b49\u6570\u636e\u96c6\u7684\u6d4b\u8bd5\u5e73\u53f0\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u5728\u54cd\u5e94\u65f6\u95f4\u548c\u6210\u672c\u65b9\u9762\u5206\u522b\u6700\u591a\u63d0\u534795.2%\u548c34.9%\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5bf9\u53ef\u6269\u5c55\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u6709\u6548\u3002"}}
{"id": "2507.14447", "pdf": "https://arxiv.org/pdf/2507.14447", "abs": "https://arxiv.org/abs/2507.14447", "authors": ["Guancheng Zeng", "Xueyi Chen", "Jiawang Hu", "Shaohua Qi", "Yaxuan Mao", "Zhantao Wang", "Yifan Nie", "Shuang Li", "Qiuyang Feng", "Pengxu Qiu", "Yujia Wang", "Wenqiang Han", "Linyan Huang", "Gang Li", "Jingjing Mo", "Haowen Hu"], "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise", "categories": ["cs.AI", "cs.CL"], "comment": "26 pages, 8 figures, 5 tables", "summary": "The deployment of agent systems in an enterprise environment is often\nhindered by several challenges: common models lack domain-specific process\nknowledge, leading to disorganized plans, missing key tools, and poor execution\nstability. To address this, this paper introduces Routine, a multi-step agent\nplanning framework designed with a clear structure, explicit instructions, and\nseamless parameter passing to guide the agent's execution module in performing\nmulti-step tool-calling tasks with high stability. In evaluations conducted\nwithin a real-world enterprise scenario, Routine significantly increases the\nexecution accuracy in model tool calls, increasing the performance of GPT-4o\nfrom 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed\na Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an\naccuracy increase to 88.2% on scenario-specific evaluations, indicating\nimproved adherence to execution plans. In addition, we employed Routine-based\ndistillation to create a scenario-specific, multi-step tool-calling dataset.\nFine-tuning on this distilled dataset raised the model's accuracy to 95.5%,\napproaching GPT-4o's performance. These results highlight Routine's\neffectiveness in distilling domain-specific tool-usage patterns and enhancing\nmodel adaptability to new scenarios. Our experimental results demonstrate that\nRoutine provides a practical and accessible approach to building stable agent\nworkflows, accelerating the deployment and adoption of agent systems in\nenterprise environments, and advancing the technical vision of AI for Process.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u591a\u6b65\u4ee3\u7406\u89c4\u5212\u6846\u67b6Routine\uff0c\u901a\u8fc7\u771f\u5b9e\u4f01\u4e1a\u573a\u666f\u8bc4\u4f30\u663e\u793a\u5176\u80fd\u63d0\u5347\u6a21\u578b\u5de5\u5177\u8c03\u7528\u6267\u884c\u51c6\u786e\u7387\uff0c\u8fd8\u6784\u5efa\u6570\u636e\u96c6\u5fae\u8c03\u6a21\u578b\uff0c\u8bc1\u660eRoutine\u53ef\u63d0\u5347\u6a21\u578b\u9002\u5e94\u6027\uff0c\u52a0\u901f\u4ee3\u7406\u7cfb\u7edf\u5728\u4f01\u4e1a\u73af\u5883\u90e8\u7f72\u3002", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u73af\u5883\u4e2d\u4ee3\u7406\u7cfb\u7edf\u90e8\u7f72\u9762\u4e34\u7684\u901a\u7528\u6a21\u578b\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u6d41\u7a0b\u77e5\u8bc6\uff0c\u5bfc\u81f4\u8ba1\u5212\u6df7\u4e71\u3001\u5de5\u5177\u7f3a\u5931\u548c\u6267\u884c\u7a33\u5b9a\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165\u591a\u6b65\u4ee3\u7406\u89c4\u5212\u6846\u67b6Routine\uff0c\u6784\u5efaRoutine\u8ddf\u968f\u8bad\u7ec3\u6570\u636e\u96c6\u5e76\u5fae\u8c03\u6a21\u578b\uff0c\u91c7\u7528\u57fa\u4e8eRoutine\u7684\u84b8\u998f\u521b\u5efa\u7279\u5b9a\u573a\u666f\u591a\u6b65\u5de5\u5177\u8c03\u7528\u6570\u636e\u96c6\u3002", "result": "Routine\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u5de5\u5177\u8c03\u7528\u6267\u884c\u51c6\u786e\u7387\uff0cGPT - 4o\u4ece41.1%\u63d0\u5347\u523096.3%\uff0cQwen3 - 14B\u4ece32.6%\u63d0\u5347\u523083.3%\uff1b\u5fae\u8c03Qwen3 - 14B\u540e\u573a\u666f\u7279\u5b9a\u8bc4\u4f30\u51c6\u786e\u7387\u8fbe88.2%\uff1b\u57fa\u4e8e\u84b8\u998f\u6570\u636e\u96c6\u5fae\u8c03\u6a21\u578b\u51c6\u786e\u7387\u8fbe95.5%\u3002", "conclusion": "Routine\u80fd\u6709\u6548\u63d0\u70bc\u7279\u5b9a\u9886\u57df\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u65b0\u573a\u666f\u7684\u9002\u5e94\u6027\uff0c\u4e3a\u6784\u5efa\u7a33\u5b9a\u4ee3\u7406\u5de5\u4f5c\u6d41\u63d0\u4f9b\u5b9e\u7528\u65b9\u6cd5\uff0c\u52a0\u901f\u4ee3\u7406\u7cfb\u7edf\u5728\u4f01\u4e1a\u73af\u5883\u7684\u90e8\u7f72\u548c\u91c7\u7528\u3002"}}
{"id": "2507.14716", "pdf": "https://arxiv.org/pdf/2507.14716", "abs": "https://arxiv.org/abs/2507.14716", "authors": ["Shahidul Islam", "Ashik Aowal", "Md Sharif Uddin", "Shaiful Chowdhury"], "title": "HistoryFinder: Advancing Method-Level Source Code History Generation with Accurate Oracles and Enhanced Algorithm", "categories": ["cs.SE"], "comment": null, "summary": "Reconstructing a method's change history efficiently and accurately is\ncritical for many software engineering tasks, including maintenance,\nrefactoring, and comprehension. Despite the availability of method history\ngeneration tools such as CodeShovel and CodeTracker, existing evaluations of\ntheir effectiveness are limited by inaccuracies in the ground truth oracles\nused. In this study, we systematically construct two new oracles -- the\ncorrected CodeShovel oracle and a newly developed HistoryFinder oracle -- by\ncombining automated analysis with expert-guided manual validation. We also\nintroduce HistoryFinder, a new method history generation tool designed to\nimprove not only the accuracy and completeness of method change histories but\nalso to offer competitive runtime performance. Through extensive evaluation\nacross 400 methods from 40 open-source repositories, we show that HistoryFinder\nconsistently outperforms CodeShovel, CodeTracker, IntelliJ, and Git-based\nbaselines in terms of precision, recall, and F1 score. Moreover, HistoryFinder\nachieves competitive runtime performance, offering the lowest mean and median\nexecution times among all the research-based tools.\n  While Git-based tools exhibit the fastest runtimes, this efficiency comes at\nthe cost of significantly lower precision and recall -- leaving HistoryFinder\nas the best overall choice when both accuracy and efficiency are important. To\nfacilitate adoption, we provide a web interface, CLI, and Java library for\nflexible usage.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u65b0\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u63d0\u51fa\u65b0\u5de5\u5177HistoryFinder\uff0c\u7ecf\u8bc4\u4f30\u5176\u5728\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u63d0\u4f9b\u591a\u79cd\u4f7f\u7528\u65b9\u5f0f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5386\u53f2\u751f\u6210\u5de5\u5177\u6709\u6548\u6027\u8bc4\u4f30\u53d7\u9650\u4e8e\u4e0d\u51c6\u786e\u7684\u57fa\u51c6\u6d4b\u8bd5\u9884\u8a00\u673a\uff0c\u9700\u8981\u51c6\u786e\u9ad8\u6548\u91cd\u5efa\u65b9\u6cd5\u53d8\u66f4\u5386\u53f2\u3002", "method": "\u7ed3\u5408\u81ea\u52a8\u5316\u5206\u6790\u4e0e\u4e13\u5bb6\u6307\u5bfc\u7684\u624b\u52a8\u9a8c\u8bc1\u6784\u5efa\u4e24\u4e2a\u65b0\u9884\u8a00\u673a\uff0c\u5f00\u53d1\u65b0\u5de5\u5177HistoryFinder\u3002", "result": "\u7ecf\u5bf940\u4e2a\u5f00\u6e90\u4ed3\u5e93\u7684400\u4e2a\u65b9\u6cd5\u8bc4\u4f30\uff0cHistoryFinder\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u5de5\u5177\uff0c\u8fd0\u884c\u65f6\u95f4\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u5f53\u51c6\u786e\u6027\u548c\u6548\u7387\u90fd\u91cd\u8981\u65f6\uff0cHistoryFinder\u662f\u6700\u4f73\u9009\u62e9\uff0c\u8fd8\u63d0\u4f9b\u591a\u79cd\u4f7f\u7528\u65b9\u5f0f\u65b9\u4fbf\u91c7\u7528\u3002"}}
{"id": "2507.15113", "pdf": "https://arxiv.org/pdf/2507.15113", "abs": "https://arxiv.org/abs/2507.15113", "authors": ["Xiangyu Zeng", "Amit Jaspal", "Bin Liu", "Goutham Panneeru", "Kevin Huang", "Nicolas Bievre", "Mohit Jaggi", "Prathap Maniraju", "Ankur Jain"], "title": "Click A, Buy B: Rethinking Conversion Attribution in E- Commerce Recommendations", "categories": ["cs.IR"], "comment": null, "summary": "User journeys in e-commerce routinely violate the one-to-one assumption that\na clicked item on an advertising platform is the same item later purchased on\nthe merchant's website/app. For a significant number of converting sessions on\nour platform, users click product A but buy product B -- the Click A, Buy B\n(CABB) phenomenon. Training recommendation models on raw click-conversion pairs\ntherefore rewards items that merely correlate with purchases, leading to biased\nlearning and sub-optimal conversion rates. We reframe conversion prediction as\na multi-task problem with separate heads for Click A Buy A (CABA) and Click A\nBuy B (CABB). To isolate informative CABB conversions from unrelated CABB\nconversions, we introduce a taxonomy-aware collaborative filtering weighting\nscheme where each product is first mapped to a leaf node in a product taxonomy,\nand a category-to-category similarity matrix is learned from large-scale\nco-engagement logs. This weighting amplifies pairs that reflect genuine\nsubstitutable or complementary relations while down-weighting coincidental\ncross-category purchases. Offline evaluation on e-commerce sessions reduces\nnormalized entropy by 13.9% versus a last-click attribution baseline. An online\nA/B test on live traffic shows +0.25% gains in the primary business metric.", "AI": {"tldr": "\u7535\u5546\u7528\u6237\u65c5\u7a0b\u5e38\u8fdd\u53cd\u4e00\u4e00\u5bf9\u5e94\u5047\u8bbe\uff0c\u5b58\u5728CABB\u73b0\u8c61\uff0c\u5c06\u8f6c\u5316\u9884\u6d4b\u91cd\u6784\u4e3a\u591a\u4efb\u52a1\u95ee\u9898\uff0c\u5f15\u5165\u5206\u7c7b\u611f\u77e5\u534f\u540c\u8fc7\u6ee4\u52a0\u6743\u65b9\u6848\uff0c\u79bb\u7ebf\u8bc4\u4f30\u548c\u5728\u7ebf\u6d4b\u8bd5\u5747\u6709\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u7535\u5546\u4e2d\u7528\u6237\u70b9\u51fb\u4e0e\u8d2d\u4e70\u5546\u54c1\u4e0d\u4e00\u81f4\uff08CABB\u73b0\u8c61\uff09\u5bfc\u81f4\u63a8\u8350\u6a21\u578b\u5b66\u4e60\u6709\u504f\u5dee\u3001\u8f6c\u5316\u7387\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5c06\u8f6c\u5316\u9884\u6d4b\u91cd\u6784\u4e3a\u591a\u4efb\u52a1\u95ee\u9898\uff0c\u7528\u5206\u7c7b\u611f\u77e5\u534f\u540c\u8fc7\u6ee4\u52a0\u6743\u65b9\u6848\u533a\u5206\u6709\u4fe1\u606f\u548c\u65e0\u5173\u8054\u7684CABB\u8f6c\u5316\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u964d\u4f4e\u5f52\u4e00\u5316\u71b513.9%\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e3b\u8981\u4e1a\u52a1\u6307\u6807\u63d0\u53470.25%\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u6539\u5584\u7535\u5546\u63a8\u8350\u6a21\u578b\u7684\u6548\u679c\uff0c\u63d0\u5347\u8f6c\u5316\u7387\u3002"}}
{"id": "2507.14181", "pdf": "https://arxiv.org/pdf/2507.14181", "abs": "https://arxiv.org/abs/2507.14181", "authors": ["Yajiao Dai", "Jun Li", "Zhen Mei", "Yiyang Ni", "Shi Jin", "Zengxiang Li", "Sheng Guo", "Wei Xiang"], "title": "Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to IEEE Internet of Things Journal, Early Access. 14 pages,\n  5 figures", "summary": "Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe\noperation of industrial machinery and improving production efficiency. However,\ntraditional supervised deep learning methods require a large amount of training\ndata and labels, which are often located in different clients. Additionally,\nthe cost of data labeling is high, making labels difficult to acquire.\nMeanwhile, differences in data distribution among clients may also hinder the\nmodel's performance. To tackle these challenges, this paper proposes a\nsemi-supervised federated learning framework, SSFL-DCSL, which integrates dual\ncontrastive loss and soft labeling to address data and label scarcity for\ndistributed clients with few labeled samples while safeguarding user privacy.\nIt enables representation learning using unlabeled data on the client side and\nfacilitates joint learning among clients through prototypes, thereby achieving\nmutual knowledge sharing and preventing local model divergence. Specifically,\nfirst, a sample weighting function based on the Laplace distribution is\ndesigned to alleviate bias caused by low confidence in pseudo labels during the\nsemi-supervised training process. Second, a dual contrastive loss is introduced\nto mitigate model divergence caused by different data distributions, comprising\nlocal contrastive loss and global contrastive loss. Third, local prototypes are\naggregated on the server with weighted averaging and updated with momentum to\nshare knowledge among clients. To evaluate the proposed SSFL-DCSL framework,\nexperiments are conducted on two publicly available datasets and a dataset\ncollected on motors from the factory. In the most challenging task, where only\n10\\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by\n1.15% to 7.85% over state-of-the-art methods.", "AI": {"tldr": "\u9488\u5bf9\u4f20\u7edf\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u667a\u80fd\u6545\u969c\u8bca\u65ad\u4e2d\u6570\u636e\u548c\u6807\u7b7e\u83b7\u53d6\u96be\u3001\u6570\u636e\u5206\u5e03\u5dee\u5f02\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u534a\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6SSFL - DCSL\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u6570\u636e\u6807\u6ce8\u7387\u4f4e\u65f6\u80fd\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u667a\u80fd\u6545\u969c\u8bca\u65ad\u4e2d\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u548c\u6807\u7b7e\uff0c\u6570\u636e\u548c\u6807\u7b7e\u83b7\u53d6\u96be\uff0c\u4e14\u4e0d\u540c\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u5dee\u5f02\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51faSSFL - DCSL\u6846\u67b6\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u62c9\u666e\u62c9\u65af\u5206\u5e03\u7684\u6837\u672c\u52a0\u6743\u51fd\u6570\uff0c\u5f15\u5165\u53cc\u5bf9\u6bd4\u635f\u5931\uff0c\u5728\u670d\u52a1\u5668\u4e0a\u805a\u5408\u548c\u66f4\u65b0\u5c40\u90e8\u539f\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u5728\u6570\u636e\u6807\u6ce8\u7387\u4ec510%\u7684\u6700\u5177\u6311\u6218\u6027\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u53471.15% - 7.85%\u3002", "conclusion": "SSFL - DCSL\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u5206\u5e03\u5f0f\u5ba2\u6237\u7aef\u6570\u636e\u548c\u6807\u7b7e\u7a00\u7f3a\u95ee\u9898\uff0c\u5b9e\u73b0\u77e5\u8bc6\u5171\u4eab\uff0c\u9632\u6b62\u5c40\u90e8\u6a21\u578b\u53d1\u6563\uff0c\u63d0\u5347\u667a\u80fd\u6545\u969c\u8bca\u65ad\u51c6\u786e\u7387\u3002"}}
{"id": "2507.15681", "pdf": "https://arxiv.org/pdf/2507.15681", "abs": "https://arxiv.org/abs/2507.15681", "authors": ["Pegah Golchian", "Jan Kapar", "David S. Watson", "Marvin N. Wright"], "title": "Missing value imputation with adversarial random forests -- MissARF", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Handling missing values is a common challenge in biostatistical analyses,\ntypically addressed by imputation methods. We propose a novel, fast, and\neasy-to-use imputation method called missing value imputation with adversarial\nrandom forests (MissARF), based on generative machine learning, that provides\nboth single and multiple imputation. MissARF employs adversarial random forest\n(ARF) for density estimation and data synthesis. To impute a missing value of\nan observation, we condition on the non-missing values and sample from the\nestimated conditional distribution generated by ARF. Our experiments\ndemonstrate that MissARF performs comparably to state-of-the-art single and\nmultiple imputation methods in terms of imputation quality and fast runtime\nwith no additional costs for multiple imputation.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u7f3a\u5931\u503c\u63d2\u8865\u65b9\u6cd5MissARF\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u63d2\u8865\u8d28\u91cf\u548c\u8fd0\u884c\u901f\u5ea6\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u7edf\u8ba1\u5206\u6790\u4e2d\u7f3a\u5931\u503c\u5904\u7406\u7684\u5e38\u89c1\u96be\u9898\uff0c\u63d0\u4f9b\u65b0\u7684\u63d2\u8865\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\uff0c\u91c7\u7528\u5bf9\u6297\u968f\u673a\u68ee\u6797\uff08ARF\uff09\u8fdb\u884c\u5bc6\u5ea6\u4f30\u8ba1\u548c\u6570\u636e\u5408\u6210\uff0c\u6839\u636e\u975e\u7f3a\u5931\u503c\u6761\u4ef6\u4eceARF\u751f\u6210\u7684\u4f30\u8ba1\u6761\u4ef6\u5206\u5e03\u4e2d\u91c7\u6837\u63d2\u8865\u7f3a\u5931\u503c\u3002", "result": "MissARF\u5728\u63d2\u8865\u8d28\u91cf\u548c\u8fd0\u884c\u901f\u5ea6\u4e0a\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u5355\u91cd\u548c\u591a\u91cd\u63d2\u8865\u65b9\u6cd5\u76f8\u5f53\uff0c\u4e14\u591a\u91cd\u63d2\u8865\u65e0\u989d\u5916\u6210\u672c\u3002", "conclusion": "MissARF\u662f\u4e00\u79cd\u6709\u6548\u3001\u5feb\u901f\u4e14\u6613\u7528\u7684\u7f3a\u5931\u503c\u63d2\u8865\u65b9\u6cd5\u3002"}}
{"id": "2507.15616", "pdf": "https://arxiv.org/pdf/2507.15616", "abs": "https://arxiv.org/abs/2507.15616", "authors": ["Ferenc Bencs", "Kuikui Liu", "Guus Regts"], "title": "On zeros and algorithms for disordered systems: mean-field spin glasses", "categories": ["cs.DS", "cond-mat.dis-nn", "cs.DM", "math-ph", "math.MP", "math.PR"], "comment": null, "summary": "Spin glasses are fundamental probability distributions at the core of\nstatistical physics, the theory of average-case computational complexity, and\nmodern high-dimensional statistical inference. In the mean-field setting, we\ndesign deterministic quasipolynomial-time algorithms for estimating the\npartition function to arbitrarily high accuracy for nearly all inverse\ntemperatures in the second moment regime. In particular, for the\nSherrington--Kirkpatrick model, our algorithms succeed for almost the entire\nreplica-symmetric phase. To achieve this, we study the locations of the zeros\nof the partition function. Notably, our methods are conceptually simple, and\napply equally well to the spherical case and the case of Ising spins.", "AI": {"tldr": "\u4e3a\u5e73\u5747\u573a\u81ea\u65cb\u73bb\u7483\u6a21\u578b\u8bbe\u8ba1\u786e\u5b9a\u6027\u62df\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u4e8c\u9636\u77e9\u4f53\u5236\u4e0b\u5bf9\u51e0\u4e4e\u6240\u6709\u9006\u6e29\u5ea6\u7684\u914d\u5206\u51fd\u6570\u8fdb\u884c\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\u3002", "motivation": "\u81ea\u65cb\u73bb\u7483\u662f\u7edf\u8ba1\u7269\u7406\u3001\u5e73\u5747\u60c5\u51b5\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\u548c\u73b0\u4ee3\u9ad8\u7ef4\u7edf\u8ba1\u63a8\u65ad\u7684\u6838\u5fc3\u6982\u7387\u5206\u5e03\uff0c\u9700\u8981\u7b97\u6cd5\u4f30\u8ba1\u914d\u5206\u51fd\u6570\u3002", "method": "\u7814\u7a76\u914d\u5206\u51fd\u6570\u96f6\u70b9\u7684\u4f4d\u7f6e\u3002", "result": "\u8bbe\u8ba1\u51fa\u7684\u7b97\u6cd5\u80fd\u5728\u4e8c\u9636\u77e9\u4f53\u5236\u4e0b\u5bf9\u51e0\u4e4e\u6240\u6709\u9006\u6e29\u5ea6\u7684\u914d\u5206\u51fd\u6570\u8fdb\u884c\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\uff0c\u5bf9Sherrington - Kirkpatrick\u6a21\u578b\u5728\u51e0\u4e4e\u6574\u4e2a Replica - symmetric \u76f8\u90fd\u6709\u6548\uff0c\u4e14\u65b9\u6cd5\u9002\u7528\u4e8e\u7403\u9762\u60c5\u51b5\u548c Ising \u81ea\u65cb\u60c5\u51b5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6982\u5ff5\u7b80\u5355\uff0c\u53ef\u6709\u6548\u4f30\u8ba1\u914d\u5206\u51fd\u6570\u3002"}}
{"id": "2507.15486", "pdf": "https://arxiv.org/pdf/2507.15486", "abs": "https://arxiv.org/abs/2507.15486", "authors": ["Shan Lu", "Xiaoteng Zhang", "Yueyang Cang", "Shihao Pan", "Yanyan Peng", "Xinwei Li", "Shaoju Zeng", "Yingjie Zhu", "Li Shi"], "title": "The Role of Excitatory Parvalbumin-positive Neurons in the Tectofugal Pathway of Pigeon (Columba livia) Hierarchical Visual Processing", "categories": ["q-bio.NC", "cs.NE"], "comment": null, "summary": "The visual systems of birds and mammals exhibit remarkable organizational\nsimilarities: the dorsal ventricular ridge (DVR) demonstrates a columnar\nmicrocircuitry that parallels the cortical architecture observed in mammals.\nHowever, the specific neuronal subtypes involved and their functional roles in\npigeon hierarchical visual processing remain unclear. This study investigates\nthe role of excitatory parvalbumin (PV+) neurons within the Ento-MVL\n(entoallium-mesopallium venterolaterale) circuit of pigeons underlying\nhierarchical moving target recognition. Electrophysiological recordings and\nimmunofluorescence staining reveal that excitatory PV+ neurons originating from\nthe entopallial internal (Ei) predominantly modulate MVL responses to varying\nvisual stimuli. Using a heterochronous-speed recurrent neural network (HS-RNN)\nmodel, we further validated these dynamics, replicating the rapid adaptation of\nthe Ento-MVL circuit to moving visual targets. The findings suggest that the\nfast-spiking and excitatory properties of PV+ neurons enable rapid processing\nof motion-related information within the Ento-MVL circuit. Our results\nelucidate the functional role of excitatory PV+ neurons in hierarchical\ninformation processing under the columnar organization of the visual DVR and\nunderscore the convergent neural processing strategies shared by avian and\nmammalian visual systems.", "AI": {"tldr": "\u7814\u7a76\u9e3d\u5b50Ento - MVL\u56de\u8def\u4e2d\u5174\u594b\u6027PV+\u795e\u7ecf\u5143\u5728\u5206\u5c42\u79fb\u52a8\u76ee\u6807\u8bc6\u522b\u4e2d\u7684\u4f5c\u7528\uff0c\u63ed\u793a\u5176\u529f\u80fd\u53ca\u9e1f\u7c7b\u4e0e\u54fa\u4e73\u52a8\u7269\u89c6\u89c9\u7cfb\u7edf\u7684\u795e\u7ecf\u5904\u7406\u7b56\u7565\u8d8b\u540c\u6027\u3002", "motivation": "\u9e1f\u7c7b\u548c\u54fa\u4e73\u52a8\u7269\u89c6\u89c9\u7cfb\u7edf\u6709\u7ec4\u7ec7\u76f8\u4f3c\u6027\uff0c\u4f46\u9e3d\u5b50\u5206\u5c42\u89c6\u89c9\u5904\u7406\u4e2d\u7279\u5b9a\u795e\u7ecf\u5143\u4e9a\u578b\u53ca\u5176\u529f\u80fd\u4f5c\u7528\u4e0d\u660e\uff0c\u9700\u7814\u7a76\u5174\u594b\u6027PV+\u795e\u7ecf\u5143\u5728\u5206\u5c42\u79fb\u52a8\u76ee\u6807\u8bc6\u522b\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u7535\u751f\u7406\u8bb0\u5f55\u548c\u514d\u75ab\u8367\u5149\u67d3\u8272\uff0c\u5e76\u7528\u5f02\u65f6\u901f\u5ea6\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08HS - RNN\uff09\u6a21\u578b\u9a8c\u8bc1\u52a8\u529b\u5b66\u3002", "result": "\u53d1\u73b0\u6e90\u81ea\u5185\u8111\u76ae\u5c42\u5185\u90e8\uff08Ei\uff09\u7684\u5174\u594b\u6027PV+\u795e\u7ecf\u5143\u4e3b\u8981\u8c03\u8282\u4e2d\u4fa7\u8179\u95f4\u8111\uff08MVL\uff09\u5bf9\u4e0d\u540c\u89c6\u89c9\u523a\u6fc0\u7684\u53cd\u5e94\uff0c\u6a21\u578b\u590d\u5236\u4e86Ento - MVL\u56de\u8def\u5bf9\u79fb\u52a8\u89c6\u89c9\u76ee\u6807\u7684\u5feb\u901f\u9002\u5e94\u3002", "conclusion": "PV+\u795e\u7ecf\u5143\u7684\u5feb\u901f\u653e\u7535\u548c\u5174\u594b\u7279\u6027\u4f7f\u5176\u80fd\u5728Ento - MVL\u56de\u8def\u4e2d\u5feb\u901f\u5904\u7406\u8fd0\u52a8\u76f8\u5173\u4fe1\u606f\uff0c\u9610\u660e\u4e86\u5176\u5728\u89c6\u89c9\u80cc\u4fa7\u8111\u5ba4\u5d74\u67f1\u72b6\u7ec4\u7ec7\u4e0b\u5206\u5c42\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u529f\u80fd\uff0c\u5f3a\u8c03\u4e86\u9e1f\u7c7b\u548c\u54fa\u4e73\u52a8\u7269\u89c6\u89c9\u7cfb\u7edf\u7684\u795e\u7ecf\u5904\u7406\u7b56\u7565\u8d8b\u540c\u6027\u3002"}}
{"id": "2507.14468", "pdf": "https://arxiv.org/pdf/2507.14468", "abs": "https://arxiv.org/abs/2507.14468", "authors": ["Yitong Lin", "Jiaying He", "Jiahe Chen", "Xinnan Zhu", "Jianwei Zheng", "Tao Bo"], "title": "BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning", "categories": ["cs.AI"], "comment": "Accepted by Bioinformatics on July 11th", "summary": "Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery\nand disease understanding, yet their completion and reasoning are challenging.\nKnowledge Embedding (KE) methods capture global semantics but struggle with\ndynamic structural integration, while Graph Neural Networks (GNNs) excel\nlocally but often lack semantic understanding. Even ensemble approaches,\nincluding those leveraging language models, often fail to achieve a deep,\nadaptive, and synergistic co-evolution between semantic comprehension and\nstructural learning. Addressing this critical gap in fostering continuous,\nreciprocal refinement between these two aspects in complex biomedical KGs is\nparamount.\n  Results: We introduce BioGraphFusion, a novel framework for deeply\nsynergistic semantic and structural learning. BioGraphFusion establishes a\nglobal semantic foundation via tensor decomposition, guiding an LSTM-driven\nmechanism to dynamically refine relation embeddings during graph propagation.\nThis fosters adaptive interplay between semantic understanding and structural\nlearning, further enhanced by query-guided subgraph construction and a hybrid\nscoring mechanism. Experiments across three key biomedical tasks demonstrate\nBioGraphFusion's superior performance over state-of-the-art KE, GNN, and\nensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)\nhighlights its ability to unveil biologically meaningful pathways.\n  Availability and Implementation: Source code and all training data are freely\navailable for download at https://github.com/Y-TARL/BioGraphFusion.\n  Contact: zjw@zjut.edu.cn, botao666666@126.com.\n  Supplementary information: Supplementary data are available at Bioinformatics\nonline.", "AI": {"tldr": "\u63d0\u51faBioGraphFusion\u6846\u67b6\u7528\u4e8e\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u8bed\u4e49\u548c\u7ed3\u6784\u5b66\u4e60\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u53ef\u63ed\u793a\u751f\u7269\u901a\u8def\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u548c\u63a8\u7406\u6709\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u7684\u6df1\u5ea6\u534f\u540c\u8fdb\u5316\u3002", "method": "\u901a\u8fc7\u5f20\u91cf\u5206\u89e3\u5efa\u7acb\u5168\u5c40\u8bed\u4e49\u57fa\u7840\uff0c\u7528LSTM\u673a\u5236\u5728\u56fe\u4f20\u64ad\u4e2d\u52a8\u6001\u7ec6\u5316\u5173\u7cfb\u5d4c\u5165\uff0c\u7ed3\u5408\u67e5\u8be2\u5f15\u5bfc\u7684\u5b50\u56fe\u6784\u5efa\u548c\u6df7\u5408\u8bc4\u5206\u673a\u5236\u3002", "result": "\u5728\u4e09\u4e2a\u5173\u952e\u751f\u7269\u533b\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709KE\u3001GNN\u548c\u96c6\u6210\u6a21\u578b\uff0c\u6848\u4f8b\u7814\u7a76\u80fd\u63ed\u793a\u751f\u7269\u901a\u8def\u3002", "conclusion": "BioGraphFusion\u6846\u67b6\u6709\u6548\u89e3\u51b3\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u8bed\u4e49\u548c\u7ed3\u6784\u5b66\u4e60\u534f\u540c\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2507.14735", "pdf": "https://arxiv.org/pdf/2507.14735", "abs": "https://arxiv.org/abs/2507.14735", "authors": ["Vladyslav Bulhakov", "Giordano d'Aloisio", "Claudio Di Sipio", "Antinisca Di Marco", "Davide Di Ruscio"], "title": "Investigating the Role of LLMs Hyperparameter Tuning and Prompt Engineering to Support Domain Modeling", "categories": ["cs.SE"], "comment": "Accepted at 51st Euromicro Conference Series on Software Engineering\n  and Advanced Applications (SEAA)", "summary": "The introduction of large language models (LLMs) has enhanced automation in\nsoftware engineering tasks, including in Model Driven Engineering (MDE).\nHowever, using general-purpose LLMs for domain modeling has its limitations.\nOne approach is to adopt fine-tuned models, but this requires significant\ncomputational resources and can lead to issues like catastrophic forgetting.\n  This paper explores how hyperparameter tuning and prompt engineering can\nimprove the accuracy of the Llama 3.1 model for generating domain models from\ntextual descriptions. We use search-based methods to tune hyperparameters for a\nspecific medical data model, resulting in a notable quality improvement over\nthe baseline LLM. We then test the optimized hyperparameters across ten diverse\napplication domains.\n  While the solutions were not universally applicable, we demonstrate that\ncombining hyperparameter tuning with prompt engineering can enhance results\nacross nearly all examined domain models.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u8d85\u53c2\u6570\u8c03\u4f18\u548c\u63d0\u793a\u5de5\u7a0b\u5982\u4f55\u63d0\u5347Llama 3.1\u6a21\u578b\u4ece\u6587\u672c\u63cf\u8ff0\u751f\u6210\u9886\u57df\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u867d\u65b9\u6848\u5e76\u975e\u901a\u7528\uff0c\u4f46\u7ed3\u5408\u4e24\u8005\u53ef\u63d0\u5347\u591a\u6570\u9886\u57df\u6a21\u578b\u6548\u679c\u3002", "motivation": "\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u9886\u57df\u5efa\u6a21\u6709\u5c40\u9650\u6027\uff0c\u5fae\u8c03\u6a21\u578b\u9700\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u4e14\u6709\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u56e0\u6b64\u63a2\u7d22\u63d0\u5347\u6a21\u578b\u51c6\u786e\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\u4e3a\u7279\u5b9a\u533b\u7597\u6570\u636e\u6a21\u578b\u8c03\u4f18\u8d85\u53c2\u6570\uff0c\u5e76\u5728\u5341\u4e2a\u4e0d\u540c\u5e94\u7528\u9886\u57df\u6d4b\u8bd5\u4f18\u5316\u540e\u7684\u8d85\u53c2\u6570\u3002", "result": "\u9488\u5bf9\u7279\u5b9a\u533b\u7597\u6570\u636e\u6a21\u578b\u8c03\u4f18\u8d85\u53c2\u6570\u540e\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5927\u8bed\u8a00\u6a21\u578b\u6709\u663e\u8457\u8d28\u91cf\u63d0\u5347\uff0c\u65b9\u6848\u5e76\u975e\u5728\u6240\u6709\u9886\u57df\u90fd\u9002\u7528\u3002", "conclusion": "\u5c06\u8d85\u53c2\u6570\u8c03\u4f18\u4e0e\u63d0\u793a\u5de5\u7a0b\u76f8\u7ed3\u5408\u53ef\u63d0\u5347\u51e0\u4e4e\u6240\u6709\u88ab\u8003\u5bdf\u9886\u57df\u6a21\u578b\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.15245", "pdf": "https://arxiv.org/pdf/2507.15245", "abs": "https://arxiv.org/abs/2507.15245", "authors": ["Xiaofeng Shi", "Yuduo Li", "Qian Kou", "Longbin Yu", "Jinxin Xie", "Hua Zhou"], "title": "SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have opened new opportunities\nfor academic literature retrieval. However, existing systems often rely on\nrigid pipelines and exhibit limited reasoning capabilities. We introduce SPAR,\na multi-agent framework that incorporates RefChain-based query decomposition\nand query evolution to enable more flexible and effective search. To facilitate\nsystematic evaluation, we also construct SPARBench, a challenging benchmark\nwith expert-annotated relevance labels. Experimental results demonstrate that\nSPAR substantially outperforms strong baselines, achieving up to +56% F1 on\nAutoScholar and +23% F1 on SPARBench over the best-performing baseline.\nTogether, SPAR and SPARBench provide a scalable, interpretable, and\nhigh-performing foundation for advancing research in scholarly retrieval. Code\nand data will be available at: https://github.com/xiaofengShi/SPAR", "AI": {"tldr": "\u4ecb\u7ecd\u591a\u667a\u80fd\u4f53\u6846\u67b6SPAR\u548c\u57fa\u51c6SPARBench\u7528\u4e8e\u5b66\u672f\u6587\u732e\u68c0\u7d22\uff0c\u5b9e\u9a8c\u8868\u660eSPAR\u6027\u80fd\u5927\u5e45\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u5b66\u672f\u6587\u732e\u68c0\u7d22\u7cfb\u7edf\u4f9d\u8d56\u521a\u6027\u7ba1\u9053\u4e14\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u9700\u66f4\u7075\u6d3b\u6709\u6548\u7684\u641c\u7d22\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8eRefChain\u7684\u67e5\u8be2\u5206\u89e3\u548c\u67e5\u8be2\u6f14\u5316\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6SPAR\uff0c\u6784\u5efa\u6709\u4e13\u5bb6\u6807\u6ce8\u76f8\u5173\u6027\u6807\u7b7e\u7684\u57fa\u51c6SPARBench\u3002", "result": "SPAR\u5728AutoScholar\u548cSPARBench\u4e0a\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u5206\u522b\u63d0\u5347\u9ad8\u8fbe+56%\u548c+23%\u7684F1\u503c\u3002", "conclusion": "SPAR\u548cSPARBench\u4e3a\u5b66\u672f\u68c0\u7d22\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u4e14\u9ad8\u6027\u80fd\u7684\u57fa\u7840\u3002"}}
{"id": "2507.14182", "pdf": "https://arxiv.org/pdf/2507.14182", "abs": "https://arxiv.org/abs/2507.14182", "authors": ["Xiaotong Luo", "Shengda Zhuo", "Min Chen", "Lichun Li", "Ruizhao Lu", "Wenqi Fan", "Shuqiang Huang", "Yin Tang"], "title": "From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Financial markets exhibit highly dynamic and complex behaviors shaped by both\nhistorical price trajectories and exogenous narratives, such as news, policy\ninterpretations, and social media sentiment. The heterogeneity in these data\nand the diverse insight of investors introduce biases that complicate the\nmodeling of market dynamics. Unlike prior work, this paper explores the\npotential of bull and bear regimes in investor-driven market dynamics. Through\nempirical analysis on real-world financial datasets, we uncover a dynamic\nrelationship between bias variation and behavioral adaptation, which enhances\ntrend prediction under evolving market conditions. To model this mechanism, we\npropose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified\nframework that jointly embeds temporal price sequences and external contextual\nsignals into a shared latent space where opposing bull and bear forces\nnaturally emerge, forming the foundation for bias representation. Within this\nspace, an inertial pairing module pairs temporally adjacent samples to preserve\nmomentum, while the dual competition mechanism contrasts bullish and bearish\nembeddings to capture behavioral divergence. Together, these components allow\nB4 to model bias-driven asymmetry, behavioral inertia, and market\nheterogeneity. Experimental results on real-world financial datasets\ndemonstrate that our model not only achieves superior performance in predicting\nmarket trends but also provides interpretable insights into the interplay of\nbiases, investor behaviors, and market dynamics.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u6295\u8d44\u8005\u9a71\u52a8\u5e02\u573a\u52a8\u6001\u4e2d\u725b\u718a\u673a\u5236\u6f5c\u529b\uff0c\u63d0\u51faB4\u6a21\u578b\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6a21\u578b\u9884\u6d4b\u5e02\u573a\u8d8b\u52bf\u8868\u73b0\u4f18\u8d8a\u4e14\u6709\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u91d1\u878d\u5e02\u573a\u884c\u4e3a\u590d\u6742\uff0c\u6570\u636e\u5f02\u8d28\u6027\u548c\u6295\u8d44\u8005\u89c2\u70b9\u5dee\u5f02\u5e26\u6765\u504f\u5dee\uff0c\u4f7f\u5e02\u573a\u52a8\u6001\u5efa\u6a21\u56f0\u96be\uff0c\u9700\u63a2\u7d22\u65b0\u673a\u5236\u3002", "method": "\u5bf9\u771f\u5b9e\u91d1\u878d\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u63d0\u51faB4\u6a21\u578b\uff0c\u5c06\u4ef7\u683c\u5e8f\u5217\u548c\u5916\u90e8\u4fe1\u53f7\u5d4c\u5165\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff0c\u6709\u60ef\u6027\u914d\u5bf9\u6a21\u5757\u548c\u53cc\u7ade\u4e89\u673a\u5236\u3002", "result": "\u6a21\u578b\u5728\u9884\u6d4b\u5e02\u573a\u8d8b\u52bf\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u5bf9\u504f\u5dee\u3001\u6295\u8d44\u8005\u884c\u4e3a\u548c\u5e02\u573a\u52a8\u6001\u7684\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u53ef\u89e3\u91ca\u89c1\u89e3\u3002", "conclusion": "B4\u6a21\u578b\u53ef\u6709\u6548\u5efa\u6a21\u504f\u5dee\u9a71\u52a8\u7684\u4e0d\u5bf9\u79f0\u6027\u3001\u884c\u4e3a\u60ef\u6027\u548c\u5e02\u573a\u5f02\u8d28\u6027\uff0c\u7528\u4e8e\u5e02\u573a\u8d8b\u52bf\u9884\u6d4b\u3002"}}
{"id": "2507.15741", "pdf": "https://arxiv.org/pdf/2507.15741", "abs": "https://arxiv.org/abs/2507.15741", "authors": ["G\u00e1bor Lugosi", "Marcos Matabuena"], "title": "Conformal and kNN Predictive Uncertainty Quantification Algorithms in Metric Spaces", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "This paper introduces a framework for uncertainty quantification in\nregression models defined in metric spaces. Leveraging a newly defined notion\nof homoscedasticity, we develop a conformal prediction algorithm that offers\nfinite-sample coverage guarantees and fast convergence rates of the oracle\nestimator. In heteroscedastic settings, we forgo these non-asymptotic\nguarantees to gain statistical efficiency, proposing a local\n$k$--nearest--neighbor method without conformal calibration that is adaptive to\nthe geometry of each particular nonlinear space. Both procedures work with any\nregression algorithm and are scalable to large data sets, allowing\npractitioners to plug in their preferred models and incorporate domain\nexpertise. We prove consistency for the proposed estimators under minimal\nconditions. Finally, we demonstrate the practical utility of our approach in\npersonalized--medicine applications involving random response objects such as\nprobability distributions and graph Laplacians.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5ea6\u91cf\u7a7a\u95f4\u56de\u5f52\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u542b\u5171\u65b9\u5dee\u548c\u5f02\u65b9\u5dee\u4e24\u79cd\u65b9\u6cd5\uff0c\u8bc1\u660e\u4f30\u8ba1\u91cf\u4e00\u81f4\u6027\u5e76\u5c55\u793a\u5176\u5728\u4e2a\u6027\u5316\u533b\u7597\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u5ea6\u91cf\u7a7a\u95f4\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u65b0\u5b9a\u4e49\u540c\u65b9\u5dee\u6027\u7684\u5171\u5f62\u9884\u6d4b\u7b97\u6cd5\uff0c\u5728\u5f02\u65b9\u5dee\u8bbe\u7f6e\u4e0b\u63d0\u51fa\u65e0\u9700\u5171\u5f62\u6821\u51c6\u7684\u5c40\u90e8k\u8fd1\u90bb\u6cd5\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u9002\u7528\u4e8e\u4efb\u4f55\u56de\u5f52\u7b97\u6cd5\u4e14\u53ef\u6269\u5c55\u5230\u5927\u6570\u636e\u96c6\uff0c\u8bc1\u660e\u4e86\u4f30\u8ba1\u91cf\u5728\u6700\u5c0f\u6761\u4ef6\u4e0b\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u5b9e\u7528\u6027\uff0c\u53ef\u5e94\u7528\u4e8e\u6d89\u53ca\u968f\u673a\u54cd\u5e94\u5bf9\u8c61\u7684\u4e2a\u6027\u5316\u533b\u7597\u9886\u57df\u3002"}}
{"id": "2507.15658", "pdf": "https://arxiv.org/pdf/2507.15658", "abs": "https://arxiv.org/abs/2507.15658", "authors": ["Romain Cosson", "Laurent Massouli\u00e9"], "title": "Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a new Lower Bound", "categories": ["cs.DS", "cs.DC", "cs.MA"], "comment": null, "summary": "We study the problem of collective tree exploration in which a team of $k$\nmobile agents must collectively visit all nodes of an unknown tree in as few\nmoves as possible. The agents all start from the root and discover adjacent\nedges as they progress in the tree. Communication is distributed in the sense\nthat agents share information by reading and writing on whiteboards located at\nall nodes. Movements are asynchronous, in the sense that the speeds of all\nagents are controlled by an adversary at all times. All previous competitive\nguarantees for collective tree exploration are either distributed but\nsynchronous, or asynchronous but centralized. In contrast, we present a\ndistributed asynchronous algorithm that explores any tree of $n$ nodes and\ndepth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear\nin $D$, and a variant algorithm with a guarantee in $O(k/\\log k)(n+kD)$, i.e.,\nwith a competitive ratio in $O(k/\\log k)$. We note that our regret guarantee is\nasymptotically optimal (i.e., $1$-competitive) from the perspective of\naverage-case complexity. We then present a new general lower bound on the\ncompetitive ratio of asynchronous collective tree exploration, in\n$\\Omega(\\log^2 k)$. This lower bound applies to both the distributed and\ncentralized settings, and improves upon the previous lower bound in\n$\\Omega(\\log k)$.", "AI": {"tldr": "\u7814\u7a76k\u4e2a\u79fb\u52a8\u4ee3\u7406\u96c6\u4f53\u63a2\u7d22\u672a\u77e5\u6811\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u5206\u5e03\u5f0f\u5f02\u6b65\u7b97\u6cd5\uff0c\u7ed9\u51fa\u79fb\u52a8\u6b65\u6570\u4fdd\u8bc1\u53ca\u6539\u8fdb\u7684\u7ade\u4e89\u6bd4\u4e0b\u754c\u3002", "motivation": "\u4ee5\u5f80\u96c6\u4f53\u6811\u63a2\u7d22\u7684\u7ade\u4e89\u4fdd\u8bc1\u8981\u4e48\u662f\u5206\u5e03\u5f0f\u540c\u6b65\uff0c\u8981\u4e48\u662f\u5f02\u6b65\u96c6\u4e2d\u5f0f\uff0c\u7f3a\u4e4f\u5206\u5e03\u5f0f\u5f02\u6b65\u7684\u60c5\u51b5\u3002", "method": "\u8bbe\u8ba1\u5206\u5e03\u5f0f\u5f02\u6b65\u7b97\u6cd5\uff0c\u5bf9\u63a2\u7d22\u6811\u7684\u79fb\u52a8\u6b65\u6570\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u63a8\u5bfc\u65b0\u7684\u7ade\u4e89\u6bd4\u4e0b\u754c\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u79fb\u52a8\u6b65\u6570\u4e0a\u6709\u76f8\u5173\u4fdd\u8bc1\uff0c\u59822n + O(k^2 2^kD)\u548cO(k/log k)(n + kD)\uff0c\u65b0\u7684\u7ade\u4e89\u6bd4\u4e0b\u754c\u4e3a\u03a9(log^2 k)\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u7684\u540e\u6094\u4fdd\u8bc1\u4ece\u5e73\u5747\u590d\u6742\u5ea6\u89d2\u5ea6\u6e10\u8fd1\u6700\u4f18\uff0c\u65b0\u7684\u7ade\u4e89\u6bd4\u4e0b\u754c\u6539\u8fdb\u4e86\u4ee5\u5f80\u7ed3\u679c\u3002"}}
{"id": "2507.14322", "pdf": "https://arxiv.org/pdf/2507.14322", "abs": "https://arxiv.org/abs/2507.14322", "authors": ["Md Rafid Haque", "Abu Raihan Mostofa Kamal", "Md. Azam Hossain"], "title": "FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11; C.2.4; K.6.5"], "comment": "24 pages, 8 figures. This work is intended for a journal submission", "summary": "Federated Learning (FL) offers a paradigm for privacy-preserving\ncollaborative AI, but its decentralized nature creates significant\nvulnerabilities to model poisoning attacks. While numerous static defenses\nexist, their effectiveness is highly context-dependent, often failing against\nadaptive adversaries or in heterogeneous data environments. This paper\nintroduces FedStrategist, a novel meta-learning framework that reframes robust\naggregation as a real-time, cost-aware control problem. We design a lightweight\ncontextual bandit agent that dynamically selects the optimal aggregation rule\nfrom an arsenal of defenses based on real-time diagnostic metrics. Through\ncomprehensive experiments, we demonstrate that no single static rule is\nuniversally optimal. We show that our adaptive agent successfully learns\nsuperior policies across diverse scenarios, including a ``Krum-favorable\"\nenvironment and against a sophisticated \"stealth\" adversary designed to\nneutralize specific diagnostic signals. Critically, we analyze the paradoxical\nscenario where a non-robust baseline achieves high but compromised accuracy,\nand demonstrate that our agent learns a conservative policy to prioritize model\nintegrity. Furthermore, we prove the agent's policy is controllable via a\nsingle \"risk tolerance\" parameter, allowing practitioners to explicitly manage\nthe trade-off between performance and security. Our work provides a new,\npractical, and analyzable approach to creating resilient and intelligent\ndecentralized AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFedStrategist\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u52a8\u6001\u9009\u62e9\u805a\u5408\u89c4\u5219\u9632\u5fa1\u8054\u90a6\u5b66\u4e60\u6a21\u578b\u4e2d\u6bd2\u653b\u51fb\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u6837\u573a\u666f\u6709\u6548\uff0c\u8fd8\u53ef\u63a7\u5236\u7b56\u7565\u6743\u8861\u6027\u80fd\u4e0e\u5b89\u5168\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u6613\u53d7\u6a21\u578b\u4e2d\u6bd2\u653b\u51fb\uff0c\u73b0\u6709\u9759\u6001\u9632\u5fa1\u5728\u9002\u5e94\u5bf9\u624b\u6216\u5f02\u6784\u6570\u636e\u73af\u5883\u4e2d\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f15\u5165FedStrategist\u6846\u67b6\uff0c\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u4ee3\u7406\uff0c\u6839\u636e\u5b9e\u65f6\u8bca\u65ad\u6307\u6807\u4ece\u9632\u5fa1\u5e93\u4e2d\u52a8\u6001\u9009\u62e9\u6700\u4f18\u805a\u5408\u89c4\u5219\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u65e0\u5355\u4e00\u9759\u6001\u89c4\u5219\u666e\u904d\u6700\u4f18\uff0c\u81ea\u9002\u5e94\u4ee3\u7406\u5728\u591a\u6837\u573a\u666f\u5b66\u4e60\u5230\u66f4\u4f18\u7b56\u7565\uff0c\u80fd\u5e94\u5bf9\u590d\u6742\u60c5\u51b5\uff0c\u8fd8\u53ef\u901a\u8fc7\u53c2\u6570\u63a7\u5236\u7b56\u7565\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u521b\u5efa\u6709\u5f39\u6027\u548c\u667a\u80fd\u7684\u53bb\u4e2d\u5fc3\u5316AI\u7cfb\u7edf\u63d0\u4f9b\u65b0\u7684\u3001\u5b9e\u7528\u4e14\u53ef\u5206\u6790\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14513", "pdf": "https://arxiv.org/pdf/2507.14513", "abs": "https://arxiv.org/abs/2507.14513", "authors": ["Hongyi Yang", "Yue Pan", "Jiayi Xu", "Kelsen Liu"], "title": "Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) and autonomous agents have\nenabled systems capable of performing complex tasks across domains such as\nhuman-computer interaction, planning, and web navigation. However, many\nexisting frameworks struggle in real-world or resource-constrained environments\ndue to their reliance on cloud-based computation, limited robustness in dynamic\ncontexts, and lack of persistent autonomy and environmental awareness.\n  We present Amico, a modular, event-driven framework for building autonomous\nagents optimized for embedded systems. Written in Rust for safety and\nperformance, Amico supports reactive, persistent agents that operate\nefficiently across embedded platforms and browser environments via WebAssembly.\nIt provides clean abstractions for event handling, state management, behavior\nexecution, and integration with reasoning modules. Amico delivers a unified\ninfrastructure for constructing resilient, interactive agents suitable for\ndeployment in settings with limited compute and intermittent connectivity.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u6784\u5efa\u81ea\u6cbb\u4ee3\u7406\u7684\u6a21\u5757\u5316\u3001\u4e8b\u4ef6\u9a71\u52a8\u6846\u67b6Amico\uff0c\u53ef\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u9ad8\u6548\u8fd0\u884c\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u5728\u73b0\u5b9e\u6216\u8d44\u6e90\u53d7\u9650\u73af\u5883\u8868\u73b0\u4e0d\u4f73\uff0c\u4f9d\u8d56\u4e91\u8ba1\u7b97\u3001\u52a8\u6001\u4e0a\u4e0b\u6587\u9c81\u68d2\u6027\u6709\u9650\u3001\u7f3a\u4e4f\u6301\u4e45\u81ea\u4e3b\u6027\u548c\u73af\u5883\u611f\u77e5\u3002", "method": "\u7528Rust\u7f16\u5199Amico\uff0c\u652f\u6301\u901a\u8fc7WebAssembly\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u548c\u6d4f\u89c8\u5668\u73af\u5883\u8fd0\u884c\uff0c\u63d0\u4f9b\u4e8b\u4ef6\u5904\u7406\u3001\u72b6\u6001\u7ba1\u7406\u7b49\u62bd\u8c61\u3002", "result": "\u6784\u5efa\u4e86\u7edf\u4e00\u57fa\u7840\u8bbe\u65bd\uff0c\u53ef\u6784\u5efa\u9002\u7528\u4e8e\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u548c\u8fde\u63a5\u4e0d\u7a33\u5b9a\u73af\u5883\u7684\u5f39\u6027\u3001\u4ea4\u4e92\u5f0f\u4ee3\u7406\u3002", "conclusion": "Amico\u662f\u9002\u5408\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u6709\u6548\u6846\u67b6\uff0c\u80fd\u5e94\u5bf9\u73b0\u6709\u6846\u67b6\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.14770", "pdf": "https://arxiv.org/pdf/2507.14770", "abs": "https://arxiv.org/abs/2507.14770", "authors": ["Manaal Basha", "Ivan Beschastnikh", "Gema Rodriguez-Perez", "Cleidson R. B. de Souza"], "title": "Toward Inclusive AI-Driven Development: Exploring Gender Differences in Code Generation Tool Interactions", "categories": ["cs.SE"], "comment": "ESEM 2025 Registered Reports", "summary": "Context: The increasing reliance on Code Generation Tools (CGTs), such as\nWindsurf and GitHub Copilot, are revamping programming workflows and raising\ncritical questions about fairness and inclusivity. While CGTs offer potential\nproductivity enhancements, their effectiveness across diverse user groups have\nnot been sufficiently investigated. Objectives: We hypothesize that developers'\ninteractions with CGTs vary based on gender, influencing task outcomes and\ncognitive load, as prior research suggests that gender differences can affect\ntechnology use and cognitive processing. Methods: The study will employ a\nmixed-subjects design with 54 participants, evenly divided by gender for a\ncounterbalanced design. Participants will complete two programming tasks\n(medium to hard difficulty) with only CGT assistance and then with only\ninternet access. Task orders and conditions will be counterbalanced to mitigate\norder effects. Data collection will include cognitive load surveys, screen\nrecordings, and task performance metrics such as completion time, code\ncorrectness, and CGT interaction behaviors. Statistical analyses will be\nconducted to identify statistically significant differences in CGT usage.\nExpected Contributions: Our work can uncover gender differences in CGT\ninteraction and performance among developers. Our findings can inform future\nCGT designs and help address usability and potential disparities in interaction\npatterns across diverse user groups. Conclusion: While results are not yet\navailable, our proposal lays the groundwork for advancing fairness,\naccountability, transparency, and ethics (FATE) in CGT design. The outcomes are\nanticipated to contribute to inclusive AI practices and equitable tool\ndevelopment for all users.", "AI": {"tldr": "\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5f00\u53d1\u8005\u4e0e\u4ee3\u7801\u751f\u6210\u5de5\u5177\uff08CGTs\uff09\u7684\u4ea4\u4e92\u662f\u5426\u56e0\u6027\u522b\u800c\u5f02\uff0c\u91c7\u7528\u6df7\u5408\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u867d\u7ed3\u679c\u672a\u51fa\uff0c\u4f46\u4e3aCGT\u8bbe\u8ba1\u516c\u5e73\u6027\u7b49\u65b9\u9762\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u5bf9CGTs\u4f9d\u8d56\u589e\u52a0\uff0c\u5176\u5728\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u4e2d\u7684\u6709\u6548\u6027\u672a\u5145\u5206\u7814\u7a76\uff0c\u4e14\u5148\u524d\u7814\u7a76\u8868\u660e\u6027\u522b\u5dee\u5f02\u4f1a\u5f71\u54cd\u6280\u672f\u4f7f\u7528\u548c\u8ba4\u77e5\u5904\u7406\uff0c\u56e0\u6b64\u5047\u8bbe\u5f00\u53d1\u8005\u4e0eCGTs\u7684\u4ea4\u4e92\u56e0\u6027\u522b\u800c\u5f02\u3002", "method": "\u91c7\u7528\u6df7\u5408\u5b9e\u9a8c\u8bbe\u8ba1\uff0c54\u540d\u53c2\u4e0e\u8005\u6309\u6027\u522b\u5747\u5206\uff0c\u5b8c\u6210\u4e24\u4e2a\u7f16\u7a0b\u4efb\u52a1\uff0c\u5206\u522b\u4ec5\u4f7f\u7528CGT\u8f85\u52a9\u548c\u4ec5\u4f7f\u7528\u4e92\u8054\u7f51\u8bbf\u95ee\uff0c\u6536\u96c6\u8ba4\u77e5\u8d1f\u8377\u8c03\u67e5\u3001\u5c4f\u5e55\u8bb0\u5f55\u548c\u4efb\u52a1\u7ee9\u6548\u6307\u6807\u7b49\u6570\u636e\u5e76\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u7ed3\u679c\u5c1a\u672a\u5f97\u51fa\u3002", "conclusion": "\u7814\u7a76\u4e3aCGT\u8bbe\u8ba1\u7684\u516c\u5e73\u6027\u3001\u95ee\u8d23\u5236\u3001\u900f\u660e\u5ea6\u548c\u9053\u5fb7\u6027\u5960\u5b9a\u57fa\u7840\uff0c\u6709\u671b\u4fc3\u8fdb\u5305\u5bb9\u6027AI\u5b9e\u8df5\u548c\u516c\u5e73\u5de5\u5177\u5f00\u53d1\u3002"}}
{"id": "2507.15267", "pdf": "https://arxiv.org/pdf/2507.15267", "abs": "https://arxiv.org/abs/2507.15267", "authors": ["Ninglu Shao", "Jinshan Wang", "Chenxu Wang", "Qingbiao Li", "Xiaoxue Zang", "Han Li"], "title": "GREAT: Guiding Query Generation with a Trie for Recommending Related Search about Video at Kuaishou", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Currently, short video platforms have become the primary place for\nindividuals to share experiences and obtain information. To better meet users'\nneeds for acquiring information while browsing short videos, some apps have\nintroduced a search entry at the bottom of videos, accompanied with recommended\nrelevant queries. This scenario is known as query recommendation in\nvideo-related search, where core task is item-to-query (I2Q) recommendation. As\nthis scenario has only emerged in recent years, there is a notable scarcity of\nacademic research and publicly available datasets in this domain. To address\nthis gap, we systematically examine the challenges associated with this\nscenario for the first time. Subsequently, we release a large-scale dataset\nderived from real-world data pertaining to the query recommendation in\nvideo-\\textit{\\textbf{r}}elated \\textit{\\textbf{s}}earch on the\n\\textit{\\textbf{Kuai}}shou app (\\textbf{KuaiRS}). Presently, existing methods\nrely on embeddings to calculate similarity for matching short videos with\nqueries, lacking deep interaction between the semantic content and the query.\nIn this paper, we introduce a novel LLM-based framework named \\textbf{GREAT},\nwhich \\textit{\\textbf{g}}uides que\\textit{\\textbf{r}}y\ng\\textit{\\textbf{e}}ner\\textit{\\textbf{a}}tion with a \\textit{\\textbf{t}}rie to\naddress I2Q recommendation in related search. Specifically, we initially gather\nhigh-quality queries with high exposure and click-through rate to construct a\nquery-based trie. During training, we enhance the LLM's capability to generate\nhigh-quality queries using the query-based trie. In the inference phase, the\nquery-based trie serves as a guide for the token generation. Finally, we\nfurther refine the relevance and literal quality between items and queries via\na post-processing module. Extensive offline and online experiments demonstrate\nthe effectiveness of our proposed method.", "AI": {"tldr": "\u6587\u7ae0\u9488\u5bf9\u89c6\u9891\u76f8\u5173\u641c\u7d22\u4e2d\u7684\u67e5\u8be2\u63a8\u8350\u573a\u666f\uff0c\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u5176\u6311\u6218\uff0c\u53d1\u5e03\u5927\u89c4\u6a21\u6570\u636e\u96c6KuaiRS\uff0c\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u6846\u67b6GREAT\u89e3\u51b3I2Q\u63a8\u8350\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u89c6\u9891\u76f8\u5173\u641c\u7d22\u7684\u67e5\u8be2\u63a8\u8350\u573a\u666f\u5b66\u672f\u7814\u7a76\u548c\u516c\u5f00\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u8bed\u4e49\u5185\u5bb9\u4e0e\u67e5\u8be2\u7684\u6df1\u5ea6\u4ea4\u4e92\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u67e5\u8be2\u7684trie\u6811\uff0c\u8bad\u7ec3\u65f6\u7528\u5176\u589e\u5f3aLLM\u751f\u6210\u9ad8\u8d28\u91cf\u67e5\u8be2\u7684\u80fd\u529b\uff0c\u63a8\u7406\u9636\u6bb5\u5f15\u5bfctoken\u751f\u6210\uff0c\u6700\u540e\u901a\u8fc7\u540e\u5904\u7406\u6a21\u5757\u4f18\u5316\u76f8\u5173\u6027\u548c\u6587\u5b57\u8d28\u91cf\u3002", "result": "\u8fdb\u884c\u4e86\u5927\u91cf\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eLLM\u7684\u6846\u67b6GREAT\u80fd\u6709\u6548\u89e3\u51b3\u89c6\u9891\u76f8\u5173\u641c\u7d22\u4e2d\u7684I2Q\u63a8\u8350\u95ee\u9898\u3002"}}
{"id": "2507.14204", "pdf": "https://arxiv.org/pdf/2507.14204", "abs": "https://arxiv.org/abs/2507.14204", "authors": ["Dachuan Shi", "Yonggan Fu", "Xiangchi Yuan", "Zhongzhi Yu", "Haoran You", "Sixu Li", "Xin Dong", "Jan Kautz", "Pavlo Molchanov", "Yingyan", "Lin"], "title": "LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICML 2025. Code: https://github.com/GATECH-EIC/LaCache", "summary": "Recent advancements in Large Language Models (LLMs) have spurred interest in\nnumerous applications requiring robust long-range capabilities, essential for\nprocessing extensive input contexts and continuously generating extended\noutputs. As sequence lengths increase, the number of Key-Value (KV) pairs in\nLLMs escalates, creating a significant efficiency bottleneck. In this paper, we\npropose a new KV cache optimization paradigm called LaCache, a training-free\nmethod for efficient and accurate generative inference of LLMs. LaCache enables\nLLMs to simultaneously address both of the critical challenges in long-range\nmodeling: robust long-range capabilities and continuous generation without\nrunning out-of-memory (OOM). Specifically, LaCache integrates two key\ninnovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only\nsequentially (left-to-right within each layer) but also across layers (from\nshallow to deep), providing an extended span for capturing long-range\ndependencies under a fixed storage budget, thereby boosting long-range\ncapabilities; and (2) an iterative compaction mechanism that progressively\ncompresses older caches, freeing up space for new tokens within a fixed cache\nsize. This token distance-based dynamic compression enables more effective\ncontinuous generation under constrained cache budgets. Experiments across\nvarious tasks, benchmarks, and LLM models consistently validate LaCache's\neffectiveness in enhancing LLMs' long-range capabilities. Our code is available\nat https://github.com/GATECH-EIC/LaCache.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u7684KV\u7f13\u5b58\u4f18\u5316\u8303\u5f0fLaCache\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u957f\u8ddd\u79bb\u5efa\u6a21\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u5e8f\u5217\u65f6KV\u5bf9\u6570\u91cf\u589e\u52a0\u5bfc\u81f4\u6548\u7387\u74f6\u9888\uff0c\u9700\u8981\u89e3\u51b3\u957f\u8ddd\u79bb\u80fd\u529b\u548c\u8fde\u7eed\u751f\u6210\u7684\u5185\u5b58\u95ee\u9898\u3002", "method": "\u63d0\u51faLaCache\uff0c\u5305\u542b\u68af\u5f62KV\u7f13\u5b58\u6a21\u5f0f\u548c\u8fed\u4ee3\u538b\u7f29\u673a\u5236\u3002", "result": "\u8de8\u4efb\u52a1\u3001\u57fa\u51c6\u548c\u6a21\u578b\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LaCache\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u957f\u8ddd\u79bb\u80fd\u529b\u7684\u6709\u6548\u6027\u3002", "conclusion": "LaCache\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u8ddd\u79bb\u80fd\u529b\u3002"}}
{"id": "2507.14340", "pdf": "https://arxiv.org/pdf/2507.14340", "abs": "https://arxiv.org/abs/2507.14340", "authors": ["Athanasios Andrikopoulos", "Nikolaos Sampanis"], "title": "Topological Social Choice: Designing a Noise-Robust Polar Distance for Persistence Diagrams", "categories": ["math.AT", "cs.DS", "cs.LG", "55N31, 55U10, 91B14, 91C20"], "comment": "26 pages,2 figures", "summary": "Topological Data Analysis (TDA) has emerged as a powerful framework for\nextracting robust and interpretable features from noisy high-dimensional data.\nIn the context of Social Choice Theory, where preference profiles and\ncollective decisions are geometrically rich yet sensitive to perturbations, TDA\nremains largely unexplored. This work introduces a novel conceptual bridge\nbetween these domains by proposing a new metric framework for persistence\ndiagrams tailored to noisy preference data.We define a polar coordinate-based\ndistance that captures both the magnitude and orientation of topological\nfeatures in a smooth and differentiable manner. Our metric addresses key\nlimitations of classical distances, such as bottleneck and Wasserstein,\nincluding instability under perturbation, lack of continuity, and\nincompatibility with gradient-based learning. The resulting formulation offers\nimproved behavior in both theoretical and applied settings.To the best of our\nknowledge, this is the first study to systematically apply persistent homology\nto social choice systems, providing a mathematically grounded method for\ncomparing topological summaries of voting structures and preference dynamics.\nWe demonstrate the superiority of our approach through extensive experiments,\nincluding robustness tests and supervised learning tasks, and we propose a\nmodular pipeline for building predictive models from online preference data.\nThis work contributes a conceptually novel and computationally effective tool\nto the emerging interface of topology and decision theory, opening new\ndirections in interpretable machine learning for political and economic\nsystems.", "AI": {"tldr": "\u672c\u6587\u5728\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u4e2d\u5f15\u5165TDA\uff0c\u63d0\u51fa\u9002\u7528\u4e8e\u566a\u58f0\u504f\u597d\u6570\u636e\u7684\u6301\u4e45\u56fe\u5ea6\u91cf\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u5e76\u63d0\u51fa\u6784\u5efa\u9884\u6d4b\u6a21\u578b\u7684\u6a21\u5757\u5316\u7ba1\u9053\u3002", "motivation": "\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u4e2d\u504f\u597d\u6570\u636e\u51e0\u4f55\u4e30\u5bcc\u4f46\u5bf9\u6270\u52a8\u654f\u611f\uff0cTDA\u5728\u6b64\u9886\u57df\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u65b0\u65b9\u6cd5\u5206\u6790\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6781\u5750\u6807\u7684\u8ddd\u79bb\u5ea6\u91cf\uff0c\u89e3\u51b3\u7ecf\u5178\u8ddd\u79bb\u7684\u5c40\u9650\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u65b0\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5e94\u7528\u573a\u666f\u8868\u73b0\u66f4\u597d\uff0c\u53ef\u7528\u4e8e\u6bd4\u8f83\u6295\u7968\u7ed3\u6784\u548c\u504f\u597d\u52a8\u6001\u7684\u62d3\u6251\u6458\u8981\u3002", "conclusion": "\u4e3a\u62d3\u6251\u5b66\u548c\u51b3\u7b56\u7406\u8bba\u7684\u4ea4\u53c9\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u4e3a\u653f\u6cbb\u548c\u7ecf\u6d4e\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u5f00\u8f9f\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.14471", "pdf": "https://arxiv.org/pdf/2507.14471", "abs": "https://arxiv.org/abs/2507.14471", "authors": ["Logan Kenwright", "Partha Roop", "Nathan Allen", "C\u0103lin Ca\u015fcaval", "Avinash Malik"], "title": "Timetide: A programming model for logically synchronous distributed systems", "categories": ["cs.PL", "cs.DC"], "comment": "25 Pages, 21 Figures", "summary": "Massive strides in deterministic models have been made using synchronous\nlanguages. They are mainly focused on centralised applications, as the\ntraditional approach is to compile away the concurrency. Time triggered\nlanguages such as Giotto and Lingua Franca are suitable for distribution albeit\nthat they rely on expensive physical clock synchronisation, which is both\nexpensive and may suffer from scalability. Hence, deterministic programming of\ndistributed systems remains challenging. We address the challenges of\ndeterministic distribution by developing a novel multiclock semantics of\nsynchronous programs. The developed semantics is amenable to seamless\ndistribution. Moreover, our programming model, Timetide, alleviates the need\nfor physical clock synchronisation by building on the recently proposed logical\nsynchrony model for distributed systems. We discuss the important aspects of\ndistributing computation, such as network communication delays, and explore the\nformal verification of Timetide programs. To the best of our knowledge,\nTimetide is the first multiclock synchronous language that is both amenable to\ndistribution and formal verification without the need for physical clock\nsynchronisation or clock gating.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u540c\u6b65\u7a0b\u5e8f\u591a\u65f6\u949f\u8bed\u4e49\u548c\u7f16\u7a0b\u6a21\u578bTimetide\uff0c\u89e3\u51b3\u5206\u5e03\u5f0f\u7cfb\u7edf\u786e\u5b9a\u6027\u7f16\u7a0b\u6311\u6218\uff0c\u65e0\u9700\u7269\u7406\u65f6\u949f\u540c\u6b65\u548c\u65f6\u949f\u95e8\u63a7\u3002", "motivation": "\u73b0\u6709\u540c\u6b65\u8bed\u8a00\u4e3b\u8981\u7528\u4e8e\u96c6\u4e2d\u5f0f\u5e94\u7528\uff0c\u65f6\u95f4\u89e6\u53d1\u8bed\u8a00\u4f9d\u8d56\u6602\u8d35\u7269\u7406\u65f6\u949f\u540c\u6b65\uff0c\u5206\u5e03\u5f0f\u7cfb\u7edf\u786e\u5b9a\u6027\u7f16\u7a0b\u4ecd\u5177\u6311\u6218\u3002", "method": "\u5f00\u53d1\u65b0\u7684\u540c\u6b65\u7a0b\u5e8f\u591a\u65f6\u949f\u8bed\u4e49\uff0c\u6784\u5efa\u57fa\u4e8e\u903b\u8f91\u540c\u6b65\u6a21\u578b\u7684\u7f16\u7a0b\u6a21\u578bTimetide\uff0c\u8ba8\u8bba\u8ba1\u7b97\u5206\u5e03\u91cd\u8981\u65b9\u9762\u5e76\u63a2\u7d22\u5f62\u5f0f\u9a8c\u8bc1\u3002", "result": "Timetide\u662f\u9996\u4e2a\u65e0\u9700\u7269\u7406\u65f6\u949f\u540c\u6b65\u6216\u65f6\u949f\u95e8\u63a7\uff0c\u9002\u7528\u4e8e\u5206\u5e03\u548c\u5f62\u5f0f\u9a8c\u8bc1\u7684\u591a\u65f6\u949f\u540c\u6b65\u8bed\u8a00\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u65f6\u949f\u8bed\u4e49\u548cTimetide\u7f16\u7a0b\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u7cfb\u7edf\u786e\u5b9a\u6027\u7f16\u7a0b\u7684\u6311\u6218\u3002"}}
{"id": "2507.14520", "pdf": "https://arxiv.org/pdf/2507.14520", "abs": "https://arxiv.org/abs/2507.14520", "authors": ["Xinyi Chen", "Yifei Yuan", "Jiaang Li", "Serge Belongie", "Maarten de Rijke", "Anders S\u00f8gaard"], "title": "What if Othello-Playing Language Models Could See?", "categories": ["cs.AI"], "comment": "ICML 2025 Assessing World Models Workshop", "summary": "Language models are often said to face a symbol grounding problem. While some\nargue that world understanding can emerge from text alone, others suggest\ngrounded learning is more efficient. We explore this through Othello, where the\nboard state defines a simplified, rule-based world. Building on prior work, we\nintroduce VISOTHELLO, a multi-modal model trained on move histories and board\nimages. Using next-move prediction, we compare it to mono-modal baselines and\ntest robustness to semantically irrelevant perturbations. We find that\nmulti-modal training improves both performance and the robustness of internal\nrepresentations. These results suggest that grounding language in visual input\nhelps models infer structured world representations.", "AI": {"tldr": "\u901a\u8fc7\u5965\u8d5b\u7f57\u6e38\u620f\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u7b26\u53f7\u63a5\u5730\u95ee\u9898\uff0c\u591a\u6a21\u6001\u8bad\u7ec3\u7684VISOTHELLO\u6a21\u578b\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u4e0a\u66f4\u4f18\uff0c\u8868\u660e\u89c6\u89c9\u8f93\u5165\u63a5\u5730\u8bed\u8a00\u6709\u52a9\u4e8e\u6a21\u578b\u63a8\u65ad\u4e16\u754c\u7ed3\u6784\u8868\u793a\u3002", "motivation": "\u63a2\u8ba8\u8bed\u8a00\u6a21\u578b\u662f\u5426\u9700\u8981\u63a5\u5730\u5b66\u4e60\uff0c\u4ee5\u89e3\u51b3\u7b26\u53f7\u63a5\u5730\u95ee\u9898\u3002", "method": "\u5f15\u5165\u591a\u6a21\u6001\u6a21\u578bVISOTHELLO\uff0c\u5728\u5965\u8d5b\u7f57\u6e38\u620f\u7684\u8d70\u6cd5\u5386\u53f2\u548c\u68cb\u76d8\u56fe\u50cf\u4e0a\u8bad\u7ec3\uff0c\u4ee5\u4e0b\u4e00\u6b65\u8d70\u6cd5\u9884\u6d4b\u4e0e\u5355\u6a21\u6001\u57fa\u7ebf\u5bf9\u6bd4\uff0c\u5e76\u6d4b\u8bd5\u5bf9\u8bed\u4e49\u65e0\u5173\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "result": "\u591a\u6a21\u6001\u8bad\u7ec3\u63d0\u5347\u4e86\u6027\u80fd\u548c\u5185\u90e8\u8868\u793a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u5c06\u8bed\u8a00\u4e0e\u89c6\u89c9\u8f93\u5165\u76f8\u7ed3\u5408\u6709\u52a9\u4e8e\u6a21\u578b\u63a8\u65ad\u7ed3\u6784\u5316\u7684\u4e16\u754c\u8868\u793a\u3002"}}
{"id": "2507.14776", "pdf": "https://arxiv.org/pdf/2507.14776", "abs": "https://arxiv.org/abs/2507.14776", "authors": ["Kimia Tasnia", "Alexander Garcia", "Tasnuva Farheen", "Sazadur Rahman"], "title": "VeriOpt: PPA-Aware High-Quality Verilog Generation via Multi-Role LLMs", "categories": ["cs.SE"], "comment": "9 pages, 7 figures, Accepted for ICCAD 2025, Munich, Germany", "summary": "The rapid adoption of large language models(LLMs) in hardware design has\nprimarily focused on generating functionally correct Verilog code, overlooking\ncritical Power Performance-Area(PPA) metrics essential for industrial-grade\ndesigns. To bridge this gap, we propose VeriOpt, a novel framework that\nleverages role-based prompting and PPA-aware optimization to enable LLMs to\nproduce high-quality, synthesizable Verilog. VeriOpt structures LLM\ninteractions into specialized roles (e.g., Planner, Programmer, Reviewer,\nEvaluator) to emulate human design workflows, while integrating PPA constraints\ndirectly into the prompting pipeline. By combining multi-modal feedback (e.g.,\nsynthesis reports, timing diagrams) with PPA aware prompting, VeriOpt achieves\nPPA-efficient code generation without sacrificing functional correctness.\nExperimental results demonstrate up to 88% reduction in power, 76% reduction in\narea and 73% improvement in timing closure compared to baseline LLM-generated\nRTL, validated using industry standard EDA tools. At the same time achieves 86%\nsuccess rate in functionality evaluation. Our work advances the\nstate-of-the-art AI-driven hardware design by addressing the critical gap\nbetween correctness and quality, paving the way for reliable LLM adoption in\nproduction workflows.", "AI": {"tldr": "\u63d0\u51faVeriOpt\u6846\u67b6\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u7efc\u5408\u7684Verilog\u4ee3\u7801\uff0c\u5b9e\u9a8c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u4e3b\u8981\u5173\u6ce8\u529f\u80fd\u6b63\u786e\u7684Verilog\u4ee3\u7801\u751f\u6210\uff0c\u5ffd\u7565\u4e86\u5173\u952e\u7684PPA\u6307\u6807\uff0c\u9700\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u63d0\u51faVeriOpt\u6846\u67b6\uff0c\u5229\u7528\u57fa\u4e8e\u89d2\u8272\u7684\u63d0\u793a\u548cPPA\u611f\u77e5\u4f18\u5316\uff0c\u5c06LLM\u4ea4\u4e92\u7ed3\u6784\u5316\uff0c\u5e76\u5c06PPA\u7ea6\u675f\u96c6\u6210\u5230\u63d0\u793a\u7ba1\u9053\u4e2d\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u53cd\u9988\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebfLLM\u751f\u6210\u7684RTL\uff0c\u529f\u7387\u964d\u4f4e88%\uff0c\u9762\u79ef\u51cf\u5c1176%\uff0c\u65f6\u5e8f\u6536\u655b\u6539\u558473%\uff0c\u529f\u80fd\u8bc4\u4f30\u6210\u529f\u7387\u8fbe86%\u3002", "conclusion": "\u5de5\u4f5c\u89e3\u51b3\u4e86\u6b63\u786e\u6027\u548c\u8d28\u91cf\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\uff0c\u63a8\u52a8\u4e86AI\u9a71\u52a8\u7684\u786c\u4ef6\u8bbe\u8ba1\u53d1\u5c55\uff0c\u4e3aLLM\u5728\u751f\u4ea7\u6d41\u7a0b\u4e2d\u7684\u53ef\u9760\u5e94\u7528\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.15395", "pdf": "https://arxiv.org/pdf/2507.15395", "abs": "https://arxiv.org/abs/2507.15395", "authors": ["Hengyu Zhang", "Chunxu Shen", "Xiangguo Sun", "Jie Tan", "Yanchao Tan", "Yu Rong", "Hong Cheng", "Lingling Yi"], "title": "Hierarchical Graph Information Bottleneck for Multi-Behavior Recommendation", "categories": ["cs.IR"], "comment": "Accepted by RecSys2025", "summary": "In real-world recommendation scenarios, users typically engage with platforms\nthrough multiple types of behavioral interactions. Multi-behavior\nrecommendation algorithms aim to leverage various auxiliary user behaviors to\nenhance prediction for target behaviors of primary interest (e.g., buy),\nthereby overcoming performance limitations caused by data sparsity in target\nbehavior records. Current state-of-the-art approaches typically employ\nhierarchical design following either cascading (e.g.,\nview$\\rightarrow$cart$\\rightarrow$buy) or parallel\n(unified$\\rightarrow$behavior$\\rightarrow$specific components) paradigms, to\ncapture behavioral relationships. However, these methods still face two\ncritical challenges: (1) severe distribution disparities across behaviors, and\n(2) negative transfer effects caused by noise in auxiliary behaviors. In this\npaper, we propose a novel model-agnostic Hierarchical Graph Information\nBottleneck (HGIB) framework for multi-behavior recommendation to effectively\naddress these challenges. Following information bottleneck principles, our\nframework optimizes the learning of compact yet sufficient representations that\npreserve essential information for target behavior prediction while eliminating\ntask-irrelevant redundancies. To further mitigate interaction noise, we\nintroduce a Graph Refinement Encoder (GRE) that dynamically prunes redundant\nedges through learnable edge dropout mechanisms. We conduct comprehensive\nexperiments on three real-world public datasets, which demonstrate the superior\neffectiveness of our framework. Beyond these widely used datasets in the\nacademic community, we further expand our evaluation on several real industrial\nscenarios and conduct an online A/B testing, showing again a significant\nimprovement in multi-behavior recommendations. The source code of our proposed\nHGIB is available at https://github.com/zhy99426/HGIB.", "AI": {"tldr": "\u63d0\u51faHGIB\u6846\u67b6\u89e3\u51b3\u591a\u884c\u4e3a\u63a8\u8350\u6311\u6218\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u884c\u4e3a\u63a8\u8350\u65b9\u6cd5\u9762\u4e34\u884c\u4e3a\u5206\u5e03\u5dee\u5f02\u548c\u8d1f\u8fc1\u79fb\u95ee\u9898\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u7684HGIB\u6846\u67b6\uff0c\u9075\u5faa\u4fe1\u606f\u74f6\u9888\u539f\u5219\u5b66\u4e60\u7d27\u51d1\u8868\u5f81\uff0c\u5f15\u5165GRE\u52a8\u6001\u4fee\u526a\u5197\u4f59\u8fb9\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u3001\u591a\u4e2a\u5de5\u4e1a\u573a\u666f\u53ca\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0c\u6846\u67b6\u8868\u73b0\u51fa\u4f18\u8d8a\u6548\u679c\u3002", "conclusion": "HGIB\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u591a\u884c\u4e3a\u63a8\u8350\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2507.14215", "pdf": "https://arxiv.org/pdf/2507.14215", "abs": "https://arxiv.org/abs/2507.14215", "authors": ["Jiayu", "Liu"], "title": "Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "This study aims to develop a deep learning system for an accessibility device\nfor the deaf or hearing impaired. The device will accurately localize and\nidentify sound sources in real time. This study will fill an important gap in\ncurrent research by leveraging machine learning techniques to target the\nunderprivileged community. The system includes three main components. 1.\nJerryNet: A custom designed CNN architecture that determines the direction of\narrival (DoA) for nine possible directions. 2. Audio Classification: This model\nis based on fine-tuning the Contrastive Language-Audio Pretraining (CLAP) model\nto identify the exact sound classes only based on audio. 3. Multimodal\nintegration model: This is an accurate sound localization model that combines\naudio, visual, and text data to locate the exact sound sources in the images.\nThe part consists of two modules, one object detection using Yolov9 to generate\nall the bounding boxes of the objects, and an audio visual localization model\nto identify the optimal bounding box using complete Intersection over Union\n(CIoU). The hardware consists of a four-microphone rectangular formation and a\ncamera mounted on glasses with a wristband for displaying necessary information\nlike direction. On a custom collected data set, JerryNet achieved a precision\nof 91. 1% for the sound direction, outperforming all the baseline models. The\nCLAP model achieved 98.5% and 95% accuracy on custom and AudioSet datasets,\nrespectively. The audio-visual localization model within component 3 yielded a\ncIoU of 0.892 and an AUC of 0.658, surpassing other similar models. There are\nmany future potentials to this study, paving the way to creating a new\ngeneration of accessibility devices.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u7528\u4e8e\u804b\u54d1\u6216\u542c\u529b\u53d7\u635f\u4eba\u58eb\u7684\u6df1\u5ea6\u5b66\u4e60\u8f85\u52a9\u8bbe\u5907\u7cfb\u7edf\uff0c\u542bJerryNet\u7b49\u7ec4\u4ef6\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u6709\u672a\u6765\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5f00\u53d1\u80fd\u5b9e\u65f6\u51c6\u786e\u5b9a\u4f4d\u548c\u8bc6\u522b\u58f0\u6e90\u7684\u65e0\u969c\u788d\u8bbe\u5907\uff0c\u586b\u8865\u9488\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u7cfb\u7edf\u5305\u542bJerryNet\u3001\u97f3\u9891\u5206\u7c7b\u6a21\u578b\u548c\u591a\u6a21\u6001\u96c6\u6210\u6a21\u578b\u4e09\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff0c\u786c\u4ef6\u7531\u56db\u4e2a\u9ea6\u514b\u98ce\u3001\u76f8\u673a\u548c\u8155\u5e26\u7ec4\u6210\u3002", "result": "JerryNet\u5728\u58f0\u97f3\u65b9\u5411\u5b9a\u4f4d\u4e0a\u7cbe\u5ea6\u8fbe91.1%\uff0cCLAP\u6a21\u578b\u5728\u81ea\u5b9a\u4e49\u548cAudioSet\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u5206\u522b\u4e3a98.5%\u548c95%\uff0c\u97f3\u9891 - \u89c6\u89c9\u5b9a\u4f4d\u6a21\u578b\u7684cIoU\u4e3a0.892\uff0cAUC\u4e3a0.658\uff0c\u5747\u8d85\u8d8a\u5bf9\u6bd4\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u6709\u5f88\u591a\u672a\u6765\u6f5c\u529b\uff0c\u4e3a\u65b0\u4e00\u4ee3\u65e0\u969c\u788d\u8bbe\u5907\u7684\u521b\u9020\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.14161", "pdf": "https://arxiv.org/pdf/2507.14161", "abs": "https://arxiv.org/abs/2507.14161", "authors": ["Eleonora Vitanza", "Pietro DeLellis", "Chiara Mocenni", "Manuel Ruiz Marin"], "title": "Complex Dynamics in Psychological Data: Mapping Individual Symptom Trajectories to Group-Level Patterns", "categories": ["stat.AP", "cs.LG", "stat.ML", "62D20, 37M10, 05C82", "G.3"], "comment": null, "summary": "This study integrates causal inference, graph analysis, temporal complexity\nmeasures, and machine learning to examine whether individual symptom\ntrajectories can reveal meaningful diagnostic patterns. Testing on a\nlongitudinal dataset of N=45 individuals affected by General Anxiety Disorder\n(GAD) and/or Major Depressive Disorder (MDD) derived from Fisher et al. 2017,\nwe propose a novel pipeline for the analysis of the temporal dynamics of\npsychopathological symptoms. First, we employ the PCMCI+ algorithm with\nnonparametric independence test to determine the causal network of nonlinear\ndependencies between symptoms in individuals with different mental disorders.\nWe found that the PCMCI+ effectively highlights the individual peculiarities of\neach symptom network, which could be leveraged towards personalized therapies.\nAt the same time, aggregating the networks by diagnosis sheds light to\ndisorder-specific causal mechanisms, in agreement with previous\npsychopathological literature. Then, we enrich the dataset by computing\ncomplexity-based measures (e.g. entropy, fractal dimension, recurrence) from\nthe symptom time series, and feed it to a suitably selected machine learning\nalgorithm to aid the diagnosis of each individual. The new dataset yields 91%\naccuracy in the classification of the symptom dynamics, proving to be an\neffective diagnostic support tool. Overall, these findings highlight how\nintegrating causal modeling and temporal complexity can enhance diagnostic\ndifferentiation, offering a principled, data-driven foundation for both\npersonalized assessment in clinical psychology and structural advances in\npsychological research.", "AI": {"tldr": "\u7814\u7a76\u6574\u5408\u591a\u79cd\u65b9\u6cd5\u5206\u6790\u4e2a\u4f53\u75c7\u72b6\u8f68\u8ff9\u80fd\u5426\u63ed\u793a\u8bca\u65ad\u6a21\u5f0f\uff0c\u63d0\u51fa\u65b0\u5206\u6790\u6d41\u7a0b\uff0c\u7ed3\u679c\u663e\u793a\u80fd\u63d0\u5347\u8bca\u65ad\u533a\u5206\u5ea6\u3002", "motivation": "\u63a2\u7a76\u4e2a\u4f53\u75c7\u72b6\u8f68\u8ff9\u662f\u5426\u80fd\u63ed\u793a\u6709\u610f\u4e49\u7684\u8bca\u65ad\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528PCMCI+\u7b97\u6cd5\u786e\u5b9a\u75c7\u72b6\u56e0\u679c\u7f51\u7edc\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u6307\u6807\u4e30\u5bcc\u6570\u636e\u96c6\u5e76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8f85\u52a9\u8bca\u65ad\u3002", "result": "PCMCI+\u7a81\u51fa\u75c7\u72b6\u7f51\u7edc\u4e2a\u4f53\u7279\u6027\uff0c\u65b0\u6570\u636e\u96c6\u5bf9\u75c7\u72b6\u52a8\u6001\u5206\u7c7b\u51c6\u786e\u7387\u8fbe91%\u3002", "conclusion": "\u6574\u5408\u56e0\u679c\u5efa\u6a21\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u80fd\u63d0\u5347\u8bca\u65ad\u533a\u5206\u5ea6\uff0c\u4e3a\u4e34\u5e8a\u5fc3\u7406\u5b66\u548c\u5fc3\u7406\u5b66\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2507.14496", "pdf": "https://arxiv.org/pdf/2507.14496", "abs": "https://arxiv.org/abs/2507.14496", "authors": ["Xin Hong", "Chenjian Li", "Aochu Dai", "Sanjiang Li", "Shenggang Ying", "Mingsheng Ying"], "title": "Quantum State Preparation Based on LimTDD", "categories": ["quant-ph", "cs.DS"], "comment": null, "summary": "Quantum state preparation is a fundamental task in quantum computing and\nquantum information processing. With the rapid advancement of quantum\ntechnologies, efficient quantum state preparation has become increasingly\nimportant. This paper proposes a novel approach for quantum state preparation\nbased on the Local Invertible Map Tensor Decision Diagram (LimTDD). LimTDD\ncombines the advantages of tensor networks and decision diagrams, enabling\nefficient representation and manipulation of quantum states. Compared with the\nstate-of-the-art quantum state preparation method, LimTDD demonstrates\nsubstantial improvements in efficiency when dealing with complex quantum\nstates, while also reducing the complexity of quantum circuits. Examples\nindicate that, in the best-case scenario, our method can achieve exponential\nefficiency gains over existing methods. This study not only highlights the\npotential of LimTDD in quantum state preparation but also provides a robust\ntheoretical and practical foundation for the future development of quantum\ncomputing technologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eLimTDD\u7684\u91cf\u5b50\u6001\u5236\u5907\u65b0\u65b9\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u6548\u7387\u66f4\u9ad8\u3001\u7535\u8def\u590d\u6742\u5ea6\u66f4\u4f4e\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u6280\u672f\u53d1\u5c55\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u6280\u672f\u53d1\u5c55\uff0c\u9ad8\u6548\u91cf\u5b50\u6001\u5236\u5907\u6108\u53d1\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eLocal Invertible Map Tensor Decision Diagram (LimTDD)\u7684\u91cf\u5b50\u6001\u5236\u5907\u65b9\u6cd5\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u5904\u7406\u590d\u6742\u91cf\u5b50\u6001\u65f6\u6548\u7387\u663e\u8457\u63d0\u5347\uff0c\u964d\u4f4e\u91cf\u5b50\u7535\u8def\u590d\u6742\u5ea6\uff0c\u6700\u4f73\u60c5\u51b5\u4e0b\u6709\u6307\u6570\u7ea7\u6548\u7387\u589e\u76ca\u3002", "conclusion": "LimTDD\u5728\u91cf\u5b50\u6001\u5236\u5907\u6709\u6f5c\u529b\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u6280\u672f\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2507.14552", "pdf": "https://arxiv.org/pdf/2507.14552", "abs": "https://arxiv.org/abs/2507.14552", "authors": ["Anna Sofia Lippolis", "Mohammad Javad Saeedizade", "Robin Keskis\u00e4rkk\u00e4", "Aldo Gangemi", "Eva Blomqvist", "Andrea Giovanni Nuzzolese"], "title": "Large Language Models Assisting Ontology Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Ontology evaluation through functional requirements, such as testing via\ncompetency question (CQ) verification, is a well-established yet costly,\nlabour-intensive, and error-prone endeavour, even for ontology engineering\nexperts. In this work, we introduce OE-Assist, a novel framework designed to\nassist ontology evaluation through automated and semi-automated CQ\nverification. By presenting and leveraging a dataset of 1,393 CQs paired with\ncorresponding ontologies and ontology stories, our contributions present, to\nour knowledge, the first systematic investigation into large language model\n(LLM)-assisted ontology evaluation, and include: (i) evaluating the\neffectiveness of a LLM-based approach for automatically performing CQ\nverification against a manually created gold standard, and (ii) developing and\nassessing an LLM-powered framework to assist CQ verification with Prot\\'eg\\'e,\nby providing suggestions. We found that automated LLM-based evaluation with\no1-preview and o3-mini perform at a similar level to the average user's\nperformance.", "AI": {"tldr": "\u4ecb\u7ecdOE - Assist\u6846\u67b6\u8f85\u52a9\u672c\u4f53\u8bc4\u4f30\uff0c\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u672c\u4f53\u8bc4\u4f30\u8fdb\u884c\u7814\u7a76\u5e76\u5f97\u51fa\u76f8\u5173\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u901a\u8fc7\u529f\u80fd\u9700\u6c42\u8fdb\u884c\u672c\u4f53\u8bc4\u4f30\u6210\u672c\u9ad8\u3001\u8017\u4eba\u529b\u4e14\u6613\u51fa\u9519\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165OE - Assist\u6846\u67b6\uff0c\u5229\u75281393\u4e2aCQs\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6267\u884cCQ\u9a8c\u8bc1\u7684\u6709\u6548\u6027\uff0c\u5f00\u53d1\u5e76\u8bc4\u4f30\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u6846\u67b6\u4ee5\u8f85\u52a9Prot\u00e9g\u00e9\u8fdb\u884cCQ\u9a8c\u8bc1\u3002", "result": "\u4f7f\u7528o1 - preview\u548co3 - mini\u7684\u81ea\u52a8\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u8868\u73b0\u4e0e\u666e\u901a\u7528\u6237\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u7684OE - Assist\u6846\u67b6\u548c\u76f8\u5173\u7814\u7a76\u4e3a\u672c\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u8f85\u52a9\u65b9\u5f0f\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u672c\u4f53\u8bc4\u4f30\u4e2d\u6709\u4e00\u5b9a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.14791", "pdf": "https://arxiv.org/pdf/2507.14791", "abs": "https://arxiv.org/abs/2507.14791", "authors": ["Yang Liu", "Li Zhang", "Fang Liu", "Zhuohang Wang", "Donglin Wei", "Zhishuo Yang", "Kechi Zhang", "Jia Li", "Lin Shi"], "title": "Enhancing Repository-Level Code Generation with Call Chain-Aware Multi-View Context", "categories": ["cs.SE"], "comment": null, "summary": "Repository-level code generation aims to generate code within the context of\na specified repository. Existing approaches typically employ\nretrieval-augmented generation (RAG) techniques to provide LLMs with relevant\ncontextual information extracted from the repository. However, these approaches\noften struggle with effectively identifying truly relevant contexts that\ncapture the rich semantics of the repository, and their contextual perspectives\nremains narrow. Moreover, most approaches fail to account for the structural\nrelationships in the retrieved code during prompt construction, hindering the\nLLM's ability to accurately interpret the context. To address these issues, we\npropose RepoScope, which leverages call chain-aware multi-view context for\nrepository-level code generation. RepoScope constructs a Repository Structural\nSemantic Graph (RSSG) and retrieves a comprehensive four-view context,\nintegrating both structural and similarity-based contexts. We propose a novel\ncall chain prediction method that utilizes the repository's structural\nsemantics to improve the identification of callees in the target function.\nAdditionally, we present a structure-preserving serialization algorithm for\nprompt construction, ensuring the coherence of the context for the LLM.\nNotably, RepoScope relies solely on static analysis, eliminating the need for\nadditional training or multiple LLM queries, thus ensuring both efficiency and\ngeneralizability. Evaluation on widely-used repository-level code generation\nbenchmarks (CoderEval and DevEval) demonstrates that RepoScope outperforms\nstate-of-the-art methods, achieving up to a 36.35% relative improvement in\npass@1 scores. Further experiments emphasize RepoScope's potential to improve\ncode generation across different tasks and its ability to integrate effectively\nwith existing approaches.", "AI": {"tldr": "\u63d0\u51faRepoScope\u7528\u4e8e\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\uff0c\u5229\u7528\u8c03\u7528\u94fe\u611f\u77e5\u7684\u591a\u89c6\u56fe\u4e0a\u4e0b\u6587\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u76f8\u5173\u4e0a\u4e0b\u6587\uff0c\u4e14\u672a\u8003\u8651\u4ee3\u7801\u7ed3\u6784\u5173\u7cfb\u3002", "method": "\u6784\u5efaRepository Structural Semantic Graph (RSSG)\uff0c\u68c0\u7d22\u56db\u89c6\u56fe\u4e0a\u4e0b\u6587\uff0c\u63d0\u51fa\u8c03\u7528\u94fe\u9884\u6d4b\u65b9\u6cd5\u548c\u7ed3\u6784\u4fdd\u7559\u5e8f\u5217\u5316\u7b97\u6cd5\u3002", "result": "\u5728CoderEval\u548cDevEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRepoScope\u7684pass@1\u5206\u6570\u76f8\u5bf9\u63d0\u5347\u8fbe36.35%\u3002", "conclusion": "RepoScope\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u63d0\u5347\u4e0d\u540c\u4efb\u52a1\u7684\u4ee3\u7801\u751f\u6210\u6548\u679c\uff0c\u53ef\u4e0e\u73b0\u6709\u65b9\u6cd5\u6709\u6548\u96c6\u6210\u3002"}}
{"id": "2507.15551", "pdf": "https://arxiv.org/pdf/2507.15551", "abs": "https://arxiv.org/abs/2507.15551", "authors": ["Jie Zhu", "Zhifang Fan", "Xiaoxie Zhu", "Yuchen Jiang", "Hangyu Wang", "Xintian Han", "Haoran Ding", "Xinmin Wang", "Wenlin Zhao", "Zhen Gong", "Huizhi Yang", "Zheng Chai", "Zhe Chen", "Yuchao Zheng", "Qiwei Chen", "Feng Zhang", "Xun Zhou", "Peng Xu", "Xiao Yang", "Di Wu", "Zuotao Liu"], "title": "RankMixer: Scaling Up Ranking Models in Industrial Recommenders", "categories": ["cs.IR"], "comment": null, "summary": "Recent progress on large language models (LLMs) has spurred interest in\nscaling up recommendation systems, yet two practical obstacles remain. First,\ntraining and serving cost on industrial Recommenders must respect strict\nlatency bounds and high QPS demands. Second, most human-designed\nfeature-crossing modules in ranking models were inherited from the CPU era and\nfail to exploit modern GPUs, resulting in low Model Flops Utilization (MFU) and\npoor scalability. We introduce RankMixer, a hardware-aware model design\ntailored towards a unified and scalable feature-interaction architecture.\nRankMixer retains the transformer's high parallelism while replacing quadratic\nself-attention with multi-head token mixing module for higher efficiency.\nBesides, RankMixer maintains both the modeling for distinct feature subspaces\nand cross-feature-space interactions with Per-token FFNs. We further extend it\nto one billion parameters with a Sparse-MoE variant for higher ROI. A dynamic\nrouting strategy is adapted to address the inadequacy and imbalance of experts\ntraining. Experiments show RankMixer's superior scaling abilities on a\ntrillion-scale production dataset. By replacing previously diverse handcrafted\nlow-MFU modules with RankMixer, we boost the model MFU from 4.5% to 45%, and\nscale our ranking model parameters by 100x while maintaining roughly the same\ninference latency. We verify RankMixer's universality with online A/B tests\nacross three core application scenarios (Recommendation, Advertisement and\nSearch). Finally, we launch 1B Dense-Parameters RankMixer for full traffic\nserving without increasing the serving cost, which improves user active days by\n0.2% and total in-app usage duration by 0.5%.", "AI": {"tldr": "\u63d0\u51faRankMixer\u6a21\u578b\uff0c\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u6269\u5c55\u7684\u4e24\u4e2a\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u6269\u5c55\u6027\u3001\u6548\u7387\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u8fd8\u901a\u8fc7\u7ebf\u4e0a\u6d4b\u8bd5\u9a8c\u8bc1\u901a\u7528\u6027\u5e76\u63d0\u5347\u7528\u6237\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u52a8\u63a8\u8350\u7cfb\u7edf\u6269\u5c55\uff0c\u4f46\u5b58\u5728\u8bad\u7ec3\u548c\u670d\u52a1\u6210\u672c\u9700\u6ee1\u8db3\u4e25\u683c\u5ef6\u8fdf\u548c\u9ad8QPS\u9700\u6c42\uff0c\u4ee5\u53ca\u7279\u5f81\u4ea4\u53c9\u6a21\u5757\u65e0\u6cd5\u5145\u5206\u5229\u7528\u73b0\u4ee3GPU\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165RankMixer\uff0c\u4fdd\u7559Transformer\u9ad8\u5e76\u884c\u6027\uff0c\u7528\u591a\u5934\u4ee4\u724c\u6df7\u5408\u6a21\u5757\u66ff\u4ee3\u4e8c\u6b21\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528Per - token FFNs\u8fdb\u884c\u7279\u5f81\u5b50\u7a7a\u95f4\u5efa\u6a21\u548c\u8de8\u7279\u5f81\u7a7a\u95f4\u4ea4\u4e92\uff0c\u6269\u5c55\u4e3aSparse - MoE\u53d8\u4f53\uff0c\u91c7\u7528\u52a8\u6001\u8def\u7531\u7b56\u7565\u3002", "result": "\u5728\u4e07\u4ebf\u7ea7\u751f\u4ea7\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5353\u8d8a\u6269\u5c55\u6027\uff0c\u5c06\u6a21\u578bMFU\u4ece4.5%\u63d0\u5347\u523045%\uff0c\u6a21\u578b\u53c2\u6570\u6269\u5c55100\u500d\u4e14\u63a8\u7406\u5ef6\u8fdf\u5927\u81f4\u4e0d\u53d8\uff0c\u7ebf\u4e0aA/B\u6d4b\u8bd5\u9a8c\u8bc1\u901a\u7528\u6027\uff0c\u63a8\u51fa1B\u5bc6\u96c6\u53c2\u6570RankMixer\u4e0d\u589e\u52a0\u670d\u52a1\u6210\u672c\u5e76\u63d0\u5347\u7528\u6237\u6307\u6807\u3002", "conclusion": "RankMixer\u662f\u4e00\u79cd\u6709\u6548\u4e14\u901a\u7528\u7684\u7279\u5f81\u4ea4\u4e92\u67b6\u6784\uff0c\u53ef\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2507.14217", "pdf": "https://arxiv.org/pdf/2507.14217", "abs": "https://arxiv.org/abs/2507.14217", "authors": ["Tudor Matei Opran", "Samir Loudni"], "title": "Geometry-Aware Active Learning of Pattern Rankings via Choquet-Based Aggregation", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "We address the pattern explosion problem in pattern mining by proposing an\ninteractive learning framework that combines nonlinear utility aggregation with\ngeometry-aware query selection. Our method models user preferences through a\nChoquet integral over multiple interestingness measures and exploits the\ngeometric structure of the version space to guide the selection of informative\ncomparisons. A branch-and-bound strategy with tight distance bounds enables\nefficient identification of queries near the decision boundary. Experiments on\nUCI datasets show that our approach outperforms existing methods such as\nChoquetRank, achieving better ranking accuracy with fewer user interactions.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u975e\u7ebf\u6027\u6548\u7528\u805a\u5408\u4e0e\u51e0\u4f55\u611f\u77e5\u67e5\u8be2\u9009\u62e9\u7684\u4ea4\u4e92\u5f0f\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u4e2d\u7684\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u4e2d\u7684\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4ea4\u4e92\u5f0f\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7Choquet\u79ef\u5206\u5efa\u6a21\u7528\u6237\u504f\u597d\uff0c\u5229\u7528\u7248\u672c\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u6307\u5bfc\u4fe1\u606f\u6bd4\u8f83\u9009\u62e9\uff0c\u91c7\u7528\u5e26\u7d27\u5bc6\u8ddd\u79bb\u8fb9\u754c\u7684\u5206\u652f\u5b9a\u754c\u7b56\u7565\u3002", "result": "\u5728UCI\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u6bd4ChoquetRank\u7b49\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u597d\uff0c\u7528\u66f4\u5c11\u7528\u6237\u4ea4\u4e92\u5b9e\u73b0\u66f4\u597d\u6392\u540d\u51c6\u786e\u7387\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u7684\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14163", "pdf": "https://arxiv.org/pdf/2507.14163", "abs": "https://arxiv.org/abs/2507.14163", "authors": ["Renxiang Qiu", "Raghavendra Selvan"], "title": "UniPhyNet: A Unified Network For Multimodal Physiological Raw Signal Classification", "categories": ["eess.SP", "cs.LG", "stat.ML"], "comment": "Accepted to be presented at the 35th IEEE International Workshop on\n  Machine Learning for Signal Processing (IEEE MLSP 2025). Source code\n  available at https://github.com/HughYau/UniPhyNet", "summary": "We present UniPhyNet, a novel neural network architecture to classify\ncognitive load using multimodal physiological data -- specifically EEG, ECG and\nEDA signals -- without the explicit need for extracting hand-crafted features.\nUniPhyNet integrates multiscale parallel convolutional blocks and ResNet-type\nblocks enhanced with channel block attention module to focus on the informative\nfeatures while a bidirectional gated recurrent unit is used to capture temporal\ndependencies. This architecture processes and combines signals in both unimodal\nand multimodal configurations via intermediate fusion of learned feature maps.\nOn the CL-Drive dataset, UniPhyNet improves raw signal classification accuracy\nfrom 70% to 80% (binary) and 62% to 74% (ternary), outperforming feature-based\nmodels, demonstrating its effectiveness as an end-to-end solution for\nreal-world cognitive state monitoring.", "AI": {"tldr": "\u63d0\u51faUniPhyNet\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u65e0\u9700\u624b\u5de5\u7279\u5f81\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u5377\u79ef\u548c\u6ce8\u610f\u529b\u6a21\u5757\u5904\u7406\u591a\u6a21\u6001\u751f\u7406\u6570\u636e\uff0c\u5728CL - Drive\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u8ba4\u77e5\u8d1f\u8377\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u624b\u5de5\u63d0\u53d6\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u6a21\u6001\u751f\u7406\u6570\u636e\u5bf9\u8ba4\u77e5\u8d1f\u8377\u8fdb\u884c\u5206\u7c7b\u3002", "method": "\u4f7f\u7528\u591a\u5c3a\u5ea6\u5e76\u884c\u5377\u79ef\u5757\u548c\u5e26\u6709\u901a\u9053\u5757\u6ce8\u610f\u529b\u6a21\u5757\u7684ResNet\u5757\uff0c\u7ed3\u5408\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff0c\u901a\u8fc7\u4e2d\u95f4\u878d\u5408\u5b66\u4e60\u5230\u7684\u7279\u5f81\u56fe\u5904\u7406\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u4fe1\u53f7\u3002", "result": "\u5728CL - Drive\u6570\u636e\u96c6\u4e0a\uff0c\u4e8c\u5143\u5206\u7c7b\u51c6\u786e\u7387\u4ece70%\u63d0\u5347\u523080%\uff0c\u4e09\u5143\u5206\u7c7b\u51c6\u786e\u7387\u4ece62%\u63d0\u5347\u523074%\uff0c\u4f18\u4e8e\u57fa\u4e8e\u7279\u5f81\u7684\u6a21\u578b\u3002", "conclusion": "UniPhyNet\u4f5c\u4e3a\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u73b0\u5b9e\u4e16\u754c\u7684\u8ba4\u77e5\u72b6\u6001\u76d1\u6d4b\u6709\u6548\u3002"}}
{"id": "2507.14631", "pdf": "https://arxiv.org/pdf/2507.14631", "abs": "https://arxiv.org/abs/2507.14631", "authors": ["Daniel Greenhut", "Dan Feldman"], "title": "$k$-PCA for (non-squared) Euclidean Distances: Polynomial Time Approximation", "categories": ["cs.LG", "cs.CG", "cs.DS"], "comment": null, "summary": "Given an integer $k\\geq1$ and a set $P$ of $n$ points in $\\REAL^d$, the\nclassic $k$-PCA (Principle Component Analysis) approximates the affine\n\\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear\nsubspace that minimizes its sum of squared Euclidean distances\n($\\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances.\nThe \\emph{$k$-subspace median} is the subspace that minimizes its sum of\n(non-squared) Euclidean distances ($\\ell_{2,1}$-mixed norm), i.e., their\nmedian. The median subspace is usually more sparse and robust to noise/outliers\nthan the mean, but also much harder to approximate since, unlike the\n$\\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k<d-1$.\n  We provide the first polynomial-time deterministic algorithm whose both\nrunning time and approximation factor are not exponential in $k$. More\nprecisely, the multiplicative approximation factor is $\\sqrt{d}$, and the\nrunning time is polynomial in the size of the input. We expect that our\ntechnique would be useful for many other related problems, such as $\\ell_{2,z}$\nnorm of distances for $z\\not \\in \\br{1,2}$, e.g., $z=\\infty$, and handling\noutliers/sparsity.\n  Open code and experimental results on real-world datasets are also provided.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u8fd0\u884c\u65f6\u95f4\u548c\u8fd1\u4f3c\u56e0\u5b50\u5728k\u4e0a\u975e\u6307\u6570\u7ea7\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u7528\u4e8e\u8fd1\u4f3ck - \u5b50\u7a7a\u95f4\u4e2d\u4f4d\u6570\uff0c\u5e76\u7ed9\u51fa\u5f00\u653e\u4ee3\u7801\u548c\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "k - \u5b50\u7a7a\u95f4\u4e2d\u4f4d\u6570\u6bd4\u5747\u503c\u66f4\u7a00\u758f\u4e14\u5bf9\u566a\u58f0/\u79bb\u7fa4\u503c\u66f4\u9c81\u68d2\uff0c\u4f46\u5728k < d - 1\u65f6\u662f\u975e\u51f8\u7684\uff0c\u96be\u4ee5\u8fd1\u4f3c\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7b97\u6cd5\u89e3\u51b3\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8fd0\u884c\u65f6\u95f4\u548c\u8fd1\u4f3c\u56e0\u5b50\u5728k\u4e0a\u975e\u6307\u6570\u7ea7\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u786e\u5b9a\u6027\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u7684\u4e58\u6cd5\u8fd1\u4f3c\u56e0\u5b50\u4e3a\u221ad\uff0c\u8fd0\u884c\u65f6\u95f4\u662f\u8f93\u5165\u89c4\u6a21\u7684\u591a\u9879\u5f0f\u3002", "conclusion": "\u8be5\u6280\u672f\u6709\u671b\u7528\u4e8e\u5176\u4ed6\u76f8\u5173\u95ee\u9898\uff0c\u5982z \u2209 {1, 2}\u65f6\u7684\u2113\u2082,z\u8303\u6570\u8ddd\u79bb\u95ee\u9898\u53ca\u5904\u7406\u79bb\u7fa4\u503c/\u7a00\u758f\u6027\u95ee\u9898\u3002"}}
{"id": "2507.14768", "pdf": "https://arxiv.org/pdf/2507.14768", "abs": "https://arxiv.org/abs/2507.14768", "authors": ["Zhou Li", "Xiang Zhang", "Jiawen Lv", "Jihao Fan", "Haiqiang Chen", "Giuseppe Caire"], "title": "Collusion-Resilient Hierarchical Secure Aggregation with Heterogeneous Security Constraints", "categories": ["cs.IT", "cs.CR", "cs.DC", "cs.LG", "math.IT"], "comment": "accepted by 2025 IEEE Information Theory Workshop", "summary": "Motivated by federated learning (FL), secure aggregation (SA) aims to\nsecurely compute, as efficiently as possible, the sum of a set of inputs\ndistributed across many users. To understand the impact of network topology,\nhierarchical secure aggregation (HSA) investigated the communication and secret\nkey generation efficiency in a 3-layer relay network, where clusters of users\nare connected to the aggregation server through an intermediate layer of\nrelays. Due to the pre-aggregation of the messages at the relays, HSA reduces\nthe communication burden on the relay-to-server links and is able to support a\nlarge number of users. However, as the number of users increases, a practical\nchallenge arises from heterogeneous security requirements--for example, users\nin different clusters may require varying levels of input protection. Motivated\nby this, we study weakly-secure HSA (WS-HSA) with collusion resilience, where\ninstead of protecting all the inputs from any set of colluding users, only the\ninputs belonging to a predefined collection of user groups (referred to as\nsecurity input sets) need to be protected against another predefined collection\nof user groups (referred to as collusion sets). Since the security input sets\nand collusion sets can be arbitrarily defined, our formulation offers a\nflexible framework for addressing heterogeneous security requirements in HSA.\nWe characterize the optimal total key rate, i.e., the total number of\nindependent key symbols required to ensure both server and relay security, for\na broad range of parameter configurations. For the remaining cases, we\nestablish lower and upper bounds on the optimal key rate, providing\nconstant-factor gap optimality guarantees.", "AI": {"tldr": "\u6587\u7ae0\u53d7\u8054\u90a6\u5b66\u4e60\u542f\u53d1\u7814\u7a76\u5b89\u5168\u805a\u5408\uff0c\u63d0\u51fa\u5f31\u5b89\u5168\u5206\u5c42\u5b89\u5168\u805a\u5408\uff08WS - HSA\uff09\u5e94\u5bf9\u5f02\u6784\u5b89\u5168\u9700\u6c42\uff0c\u523b\u753b\u6700\u4f18\u603b\u5bc6\u94a5\u7387\u5e76\u7ed9\u51fa\u90e8\u5206\u60c5\u51b5\u4e0a\u4e0b\u754c\u3002", "motivation": "\u4f20\u7edf\u5206\u5c42\u5b89\u5168\u805a\u5408\uff08HSA\uff09\u5728\u7528\u6237\u6570\u91cf\u589e\u52a0\u65f6\u9762\u4e34\u5f02\u6784\u5b89\u5168\u9700\u6c42\u6311\u6218\uff0c\u9700\u65b0\u65b9\u6848\u5e94\u5bf9\u3002", "method": "\u7814\u7a76\u5f31\u5b89\u5168HSA\uff08WS - HSA\uff09\uff0c\u5141\u8bb8\u7075\u6d3b\u5b9a\u4e49\u5b89\u5168\u8f93\u5165\u96c6\u548c\u52fe\u7ed3\u96c6\uff1b\u523b\u753b\u5e7f\u6cdb\u53c2\u6570\u914d\u7f6e\u4e0b\u7684\u6700\u4f18\u603b\u5bc6\u94a5\u7387\uff0c\u5bf9\u5176\u4f59\u60c5\u51b5\u5efa\u7acb\u4e0a\u4e0b\u754c\u3002", "result": "\u5f97\u5230\u5e7f\u6cdb\u53c2\u6570\u914d\u7f6e\u4e0b\u7684\u6700\u4f18\u603b\u5bc6\u94a5\u7387\uff0c\u5176\u4f59\u60c5\u51b5\u6709\u4e0a\u4e0b\u754c\u5e76\u63d0\u4f9b\u6052\u5b9a\u56e0\u5b50\u5dee\u8ddd\u6700\u4f18\u6027\u4fdd\u8bc1\u3002", "conclusion": "WS - HSA\u4e3aHSA\u4e2d\u7684\u5f02\u6784\u5b89\u5168\u9700\u6c42\u63d0\u4f9b\u4e86\u7075\u6d3b\u6846\u67b6\u3002"}}
{"id": "2507.14593", "pdf": "https://arxiv.org/pdf/2507.14593", "abs": "https://arxiv.org/abs/2507.14593", "authors": ["Omar Al-Desi"], "title": "Coordinate Heart System: A Geometric Framework for Emotion Representation", "categories": ["cs.AI", "cs.LG"], "comment": "26 pages", "summary": "This paper presents the Coordinate Heart System (CHS), a geometric framework\nfor emotion representation in artificial intelligence applications. We position\neight core emotions as coordinates on a unit circle, enabling mathematical\ncomputation of complex emotional states through coordinate mixing and vector\noperations. Our initial five-emotion model revealed significant coverage gaps\nin the emotion space, leading to the development of an eight-emotion system\nthat provides complete geometric coverage with mathematical guarantees. The\nframework converts natural language input to emotion coordinates and supports\nreal-time emotion interpolation through computational algorithms. The system\nintroduces a re-calibrated stability parameter S in [0,1], which dynamically\nintegrates emotional load, conflict resolution, and contextual drain factors.\nThis stability model leverages advanced Large Language Model interpretation of\ntextual cues and incorporates hybrid temporal tracking mechanisms to provide\nnuanced assessment of psychological well-being states. Our key contributions\ninclude: (i) mathematical proof demonstrating why five emotions are\ninsufficient for complete geometric coverage, (ii) an eight-coordinate system\nthat eliminates representational blind spots, (iii) novel algorithms for\nemotion mixing, conflict resolution, and distance calculation in emotion space,\nand (iv) a comprehensive computational framework for AI emotion recognition\nwith enhanced multi-dimensional stability modeling. Experimental validation\nthrough case studies demonstrates the system's capability to handle emotionally\nconflicted states, contextual distress factors, and complex psychological\nscenarios that traditional categorical emotion models cannot adequately\nrepresent. This work establishes a new mathematical foundation for emotion\nmodeling in artificial intelligence systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5750\u6807\u5fc3\u810f\u7cfb\u7edf\uff08CHS\uff09\u7528\u4e8e\u4eba\u5de5\u667a\u80fd\u60c5\u611f\u8868\u793a\uff0c\u4ece\u4e94\u60c5\u611f\u6a21\u578b\u53d1\u5c55\u5230\u516b\u60c5\u611f\u7cfb\u7edf\uff0c\u6709\u591a\u79cd\u7b97\u6cd5\u548c\u7a33\u5b9a\u6027\u6a21\u578b\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u80fd\u5904\u7406\u590d\u6742\u60c5\u611f\u573a\u666f\uff0c\u4e3aAI\u60c5\u611f\u5efa\u6a21\u5960\u5b9a\u65b0\u6570\u5b66\u57fa\u7840\u3002", "motivation": "\u5728\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u4e2d\u627e\u5230\u66f4\u597d\u7684\u60c5\u611f\u8868\u793a\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edf\u5206\u7c7b\u60c5\u611f\u6a21\u578b\u65e0\u6cd5\u5145\u5206\u8868\u793a\u590d\u6742\u60c5\u611f\u573a\u666f\u7684\u95ee\u9898\u3002", "method": "\u5c06\u516b\u79cd\u6838\u5fc3\u60c5\u611f\u5b9a\u4f4d\u5728\u5355\u4f4d\u5706\u4e0a\u4f5c\u4e3a\u5750\u6807\uff0c\u901a\u8fc7\u5750\u6807\u6df7\u5408\u548c\u5411\u91cf\u8fd0\u7b97\u8fdb\u884c\u590d\u6742\u60c5\u611f\u72b6\u6001\u8ba1\u7b97\uff1b\u5f15\u5165\u7a33\u5b9a\u6027\u53c2\u6570S\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6df7\u5408\u65f6\u95f4\u8ddf\u8e2a\u673a\u5236\uff1b\u5f00\u53d1\u60c5\u611f\u6df7\u5408\u3001\u51b2\u7a81\u89e3\u51b3\u548c\u8ddd\u79bb\u8ba1\u7b97\u7b49\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u7cfb\u7edf\u80fd\u5904\u7406\u60c5\u611f\u51b2\u7a81\u72b6\u6001\u3001\u4e0a\u4e0b\u6587\u75db\u82e6\u56e0\u7d20\u548c\u590d\u6742\u5fc3\u7406\u573a\u666f\uff0c\u4f20\u7edf\u5206\u7c7b\u60c5\u611f\u6a21\u578b\u65e0\u6cd5\u505a\u5230\u3002", "conclusion": "\u4e3a\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u60c5\u611f\u5efa\u6a21\u5efa\u7acb\u4e86\u65b0\u7684\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2507.14969", "pdf": "https://arxiv.org/pdf/2507.14969", "abs": "https://arxiv.org/abs/2507.14969", "authors": ["Sai Zhang", "Zhenchang Xing", "Jieshan Chen", "Dehai Zhao", "Zizhong Zhu", "Xiaowang Zhang", "Zhiyong Feng", "Xiaohong Li"], "title": "Think Like an Engineer: A Neuro-Symbolic Collaboration Agent for Generative Software Requirements Elicitation and Self-Review", "categories": ["cs.SE", "D.2.1"], "comment": null, "summary": "The vision of End-User Software Engineering (EUSE) is to empower\nnon-professional users with full control over the software development\nlifecycle. It aims to enable users to drive generative software development\nusing only natural language requirements. However, since end-users often lack\nknowledge of software engineering, their requirement descriptions are\nfrequently ambiguous, raising significant challenges to generative software\ndevelopment. Although existing approaches utilize structured languages like\nGherkin to clarify user narratives, they still struggle to express the causal\nlogic between preconditions and behavior actions. This paper introduces\nRequireCEG, a requirement elicitation and self-review agent that embeds\ncausal-effect graphs (CEGs) in a neuro-symbolic collaboration architecture.\nRequireCEG first uses a feature tree to analyze user narratives hierarchically,\nclearly defining the scope of software components and their system behavior\nrequirements. Next, it constructs the self-healing CEGs based on the elicited\nrequirements, capturing the causal relationships between atomic preconditions\nand behavioral actions. Finally, the constructed CEGs are used to review and\noptimize Gherkin scenarios, ensuring consistency between the generated Gherkin\nrequirements and the system behavior requirements elicited from user\nnarratives. To evaluate our method, we created the RGPair benchmark dataset and\nconducted extensive experiments. It achieves an 87% coverage rate and raises\ndiversity by 51.88%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRequireCEG\uff0c\u901a\u8fc7\u5d4c\u5165\u56e0\u679c\u6548\u5e94\u56fe\uff08CEGs\uff09\u6765\u5904\u7406\u6700\u7ec8\u7528\u6237\u5728\u751f\u6210\u5f0f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u9700\u6c42\u63cf\u8ff0\u6a21\u7cca\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u6700\u7ec8\u7528\u6237\u7f3a\u4e4f\u8f6f\u4ef6\u5de5\u7a0b\u77e5\u8bc6\uff0c\u9700\u6c42\u63cf\u8ff0\u6a21\u7cca\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u8868\u8fbe\u524d\u7f6e\u6761\u4ef6\u548c\u884c\u4e3a\u52a8\u4f5c\u4e4b\u95f4\u7684\u56e0\u679c\u903b\u8f91\uff0c\u5f71\u54cd\u751f\u6210\u5f0f\u8f6f\u4ef6\u5f00\u53d1\u3002", "method": "\u5f15\u5165RequireCEG\uff0c\u5148\u4f7f\u7528\u7279\u5f81\u6811\u5206\u6790\u7528\u6237\u53d9\u8ff0\uff0c\u6784\u5efa\u81ea\u4fee\u590dCEGs\uff0c\u518d\u7528CEGs\u5ba1\u67e5\u548c\u4f18\u5316Gherkin\u573a\u666f\u3002", "result": "\u521b\u5efaRGPair\u57fa\u51c6\u6570\u636e\u96c6\u5e76\u5b9e\u9a8c\uff0c\u8986\u76d6\u7387\u8fbe87%\uff0c\u591a\u6837\u6027\u63d0\u9ad851.88%\u3002", "conclusion": "RequireCEG\u80fd\u6709\u6548\u5904\u7406\u6700\u7ec8\u7528\u6237\u9700\u6c42\u63cf\u8ff0\u6a21\u7cca\u95ee\u9898\uff0c\u786e\u4fdd\u751f\u6210\u7684Gherkin\u9700\u6c42\u4e0e\u7cfb\u7edf\u884c\u4e3a\u9700\u6c42\u4e00\u81f4\u3002"}}
{"id": "2507.15826", "pdf": "https://arxiv.org/pdf/2507.15826", "abs": "https://arxiv.org/abs/2507.15826", "authors": ["Alessandro B. Melchiorre", "Elena V. Epure", "Shahed Masoudian", "Gustavo Escobedo", "Anna Hausberger", "Manuel Moussallam", "Markus Schedl"], "title": "Just Ask for Music (JAM): Multimodal and Personalized Natural Language Music Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Natural language interfaces offer a compelling approach for music\nrecommendation, enabling users to express complex preferences conversationally.\nWhile Large Language Models (LLMs) show promise in this direction, their\nscalability in recommender systems is limited by high costs and latency.\nRetrieval-based approaches using smaller language models mitigate these issues\nbut often rely on single-modal item representations, overlook long-term user\npreferences, and require full model retraining, posing challenges for\nreal-world deployment. In this paper, we present JAM (Just Ask for Music), a\nlightweight and intuitive framework for natural language music recommendation.\nJAM models user-query-item interactions as vector translations in a shared\nlatent space, inspired by knowledge graph embedding methods like TransE. To\ncapture the complexity of music and user intent, JAM aggregates multimodal item\nfeatures via cross-attention and sparse mixture-of-experts. We also introduce\nJAMSessions, a new dataset of over 100k user-query-item triples with anonymized\nuser/item embeddings, uniquely combining conversational queries and user\nlong-term preferences. Our results show that JAM provides accurate\nrecommendations, produces intuitive representations suitable for practical use\ncases, and can be easily integrated with existing music recommendation stacks.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u81ea\u7136\u8bed\u8a00\u97f3\u4e50\u63a8\u8350\u6846\u67b6JAM\uff0c\u7528\u5411\u91cf\u7ffb\u8bd1\u5efa\u6a21\u4ea4\u4e92\uff0c\u805a\u5408\u591a\u6a21\u6001\u7279\u5f81\uff0c\u521b\u5efa\u65b0\u6570\u636e\u96c6\uff0c\u7ed3\u679c\u663e\u793a\u5176\u63a8\u8350\u51c6\u786e\u3001\u8868\u793a\u76f4\u89c2\u4e14\u6613\u96c6\u6210\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf\u4e2d\u6269\u5c55\u6027\u53d7\u9ad8\u6210\u672c\u548c\u5ef6\u8fdf\u9650\u5236\uff0c\u57fa\u4e8e\u68c0\u7d22\u7684\u65b9\u6cd5\u5b58\u5728\u4f9d\u8d56\u5355\u6a21\u6001\u3001\u5ffd\u89c6\u957f\u671f\u504f\u597d\u548c\u9700\u5168\u91cf\u6a21\u578b\u518d\u8bad\u7ec3\u7b49\u95ee\u9898\u3002", "method": "\u5c06\u7528\u6237 - \u67e5\u8be2 - \u9879\u76ee\u4ea4\u4e92\u5efa\u6a21\u4e3a\u5171\u4eab\u6f5c\u7a7a\u95f4\u4e2d\u7684\u5411\u91cf\u7ffb\u8bd1\uff0c\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u805a\u5408\u591a\u6a21\u6001\u7279\u5f81\uff0c\u521b\u5efa\u65b0\u6570\u636e\u96c6JAMSessions\u3002", "result": "JAM\u80fd\u63d0\u4f9b\u51c6\u786e\u63a8\u8350\uff0c\u751f\u6210\u9002\u5408\u5b9e\u9645\u7528\u4f8b\u7684\u76f4\u89c2\u8868\u793a\uff0c\u4e14\u6613\u4e8e\u4e0e\u73b0\u6709\u97f3\u4e50\u63a8\u8350\u6808\u96c6\u6210\u3002", "conclusion": "JAM\u662f\u4e00\u4e2a\u6709\u6548\u7684\u81ea\u7136\u8bed\u8a00\u97f3\u4e50\u63a8\u8350\u6846\u67b6\uff0c\u53ef\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\u3002"}}
{"id": "2507.14219", "pdf": "https://arxiv.org/pdf/2507.14219", "abs": "https://arxiv.org/abs/2507.14219", "authors": ["Obumneme Zimuzor Nwafor", "Mohammed Abdul Majeed Al Hooti"], "title": "Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "As nations seek sustainable alternatives to fossil fuels, green hydrogen has\nemerged as a promising strategic pathway toward decarbonisation, particularly\nin solar-rich arid regions. However, identifying optimal locations for hydrogen\nproduction requires the integration of complex environmental, atmospheric, and\ninfrastructural factors, often compounded by limited availability of direct\nhydrogen yield data. This study presents a novel Artificial Intelligence (AI)\nframework for computing green hydrogen yield and site suitability index using\nmean absolute SHAP (SHapley Additive exPlanations) values. This framework\nconsists of a multi-stage pipeline of unsupervised multi-variable clustering,\nsupervised machine learning classifier and SHAP algorithm. The pipeline trains\non an integrated meteorological, topographic and temporal dataset and the\nresults revealed distinct spatial patterns of suitability and relative\ninfluence of the variables. With model predictive accuracy of 98%, the result\nalso showed that water proximity, elevation and seasonal variation are the most\ninfluential factors determining green hydrogen site suitability in Oman with\nmean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively.\nGiven limited or absence of ground-truth yield data in many countries that have\ngreen hydrogen prospects and ambitions, this study offers an objective and\nreproducible alternative to subjective expert weightings, thus allowing the\ndata to speak for itself and potentially discover novel latent groupings\nwithout pre-imposed assumptions. This study offers industry stakeholders and\npolicymakers a replicable and scalable tool for green hydrogen infrastructure\nplanning and other decision making in data-scarce regions.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u7528\u5e73\u5747\u7edd\u5bf9SHAP\u503c\u8ba1\u7b97\u7eff\u6c22\u4ea7\u91cf\u548c\u9009\u5740\u9002\u5b9c\u6027\u6307\u6570\u7684AI\u6846\u67b6\uff0c\u51c6\u786e\u738798%\uff0c\u4e3a\u6570\u636e\u7a00\u7f3a\u5730\u533a\u89c4\u5212\u63d0\u4f9b\u5de5\u5177\u3002", "motivation": "\u5404\u56fd\u5bfb\u6c42\u5316\u77f3\u71c3\u6599\u53ef\u6301\u7eed\u66ff\u4ee3\u65b9\u6848\uff0c\u7eff\u6c22\u662f\u6709\u524d\u666f\u9014\u5f84\uff0c\u4f46\u786e\u5b9a\u5236\u6c22\u6700\u4f73\u9009\u5740\u9700\u7efc\u5408\u591a\u56e0\u7d20\u4e14\u76f4\u63a5\u6c22\u4ea7\u91cf\u6570\u636e\u6709\u9650\u3002", "method": "\u6784\u5efa\u7531\u65e0\u76d1\u7763\u591a\u53d8\u91cf\u805a\u7c7b\u3001\u76d1\u7763\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u548cSHAP\u7b97\u6cd5\u7ec4\u6210\u7684\u591a\u9636\u6bb5\u7ba1\u9053\uff0c\u5728\u96c6\u6210\u6c14\u8c61\u3001\u5730\u5f62\u548c\u65f6\u95f4\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u3002", "result": "\u63ed\u793a\u9009\u5740\u9002\u5b9c\u6027\u7a7a\u95f4\u6a21\u5f0f\u548c\u53d8\u91cf\u76f8\u5bf9\u5f71\u54cd\uff0c\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u738798%\uff0c\u786e\u5b9a\u963f\u66fc\u7eff\u6c22\u9009\u5740\u6700\u6709\u5f71\u54cd\u7684\u56e0\u7d20\u3002", "conclusion": "\u4e3a\u6570\u636e\u7a00\u7f3a\u5730\u533a\u63d0\u4f9b\u5ba2\u89c2\u53ef\u590d\u5236\u5de5\u5177\uff0c\u4f9b\u884c\u4e1a\u5229\u76ca\u76f8\u5173\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u7528\u4e8e\u7eff\u6c22\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u548c\u51b3\u7b56\u3002"}}
{"id": "2507.14669", "pdf": "https://arxiv.org/pdf/2507.14669", "abs": "https://arxiv.org/abs/2507.14669", "authors": ["Alexander Kozachinskiy"], "title": "Dvorak-Dell-Grohe-Rattan theorem via an asymptotic argument", "categories": ["math.CO", "cs.DM", "cs.DS"], "comment": null, "summary": "Two graphs $G_1,G_2$ are distinguished by the Weisfeiler--Leman isomorphism\ntest if and only if there is a tree $T$ that has a different number of\nhomomorphisms to $G_1$ and to $G_2$. There are two known proofs of this fact --\na logical proof by Dvorak and a linear-algebraic proof by Dell, Grohe, and\nRattan. We give another simple proof, based on ordering WL-labels and\nasymptotic arguments.", "AI": {"tldr": "\u672c\u6587\u7ed9\u51fa\u4e86\u5173\u4e8e\u4e24\u4e2a\u56fe\u53ef\u88abWeisfeiler - Leman\u540c\u6784\u6d4b\u8bd5\u533a\u5206\u7684\u5145\u8981\u6761\u4ef6\u7684\u53e6\u4e00\u79cd\u7b80\u5355\u8bc1\u660e\u3002", "motivation": "\u5df2\u5b58\u5728\u5173\u4e8e\u4e24\u4e2a\u56fe\u53ef\u88abWeisfeiler - Leman\u540c\u6784\u6d4b\u8bd5\u533a\u5206\u7684\u5145\u8981\u6761\u4ef6\u7684\u4e24\u79cd\u8bc1\u660e\uff0c\u4f5c\u8005\u5e0c\u671b\u7ed9\u51fa\u53e6\u4e00\u79cd\u8bc1\u660e\u3002", "method": "\u57fa\u4e8e\u5bf9WL\u6807\u7b7e\u6392\u5e8f\u548c\u6e10\u8fd1\u8bba\u8bc1\u7684\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u7ed9\u51fa\u53e6\u4e00\u79cd\u7b80\u5355\u8bc1\u660e\u3002", "conclusion": "\u53ef\u4ee5\u901a\u8fc7\u5bf9WL\u6807\u7b7e\u6392\u5e8f\u548c\u6e10\u8fd1\u8bba\u8bc1\u7684\u65b9\u6cd5\u5f97\u5230\u5173\u4e8e\u8be5\u5145\u8981\u6761\u4ef6\u7684\u65b0\u8bc1\u660e\u3002"}}
{"id": "2507.14642", "pdf": "https://arxiv.org/pdf/2507.14642", "abs": "https://arxiv.org/abs/2507.14642", "authors": ["Monoshiz Mahbub Khan", "Xioayin Xi", "Andrew Meneely", "Zhe Yu"], "title": "Efficient Story Point Estimation With Comparative Learning", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Story point estimation is an essential part of agile software development.\nStory points are unitless, project-specific effort estimates that help\ndevelopers plan their sprints. Traditionally, developers estimate story points\ncollaboratively using planning poker or other manual techniques. While the\ninitial calibrating of the estimates to each project is helpful, once a team\nhas converged on a set of precedents, story point estimation can become tedious\nand labor-intensive. Machine learning can reduce this burden, but only with\nenough context from the historical decisions made by the project team. That is,\nstate-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate\npredictions (within-project) when trained on data from the same project. The\ngoal of this work is to streamline story point estimation by evaluating a\ncomparative learning-based framework for calibrating project-specific story\npoint prediction models. Instead of assigning a specific story point value to\nevery backlog item, developers are presented with pairs of items, and indicate\nwhich item requires more effort. Using these comparative judgments, a machine\nlearning model is trained to predict the story point estimates. We empirically\nevaluated our technique using data with 23,313 manual estimates in 16 projects.\nThe model learned from comparative judgments can achieve on average 0.34\nSpearman's rank correlation coefficient between its predictions and the ground\ntruth story points. This is similar to, if not better than, the performance of\na regression model learned from the ground truth story points. Therefore, the\nproposed comparative learning approach is more efficient than state-of-the-art\nregression-based approaches according to the law of comparative judgments -\nproviding comparative judgments yields a lower cognitive burden on humans than\nproviding ratings or categorical labels.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6bd4\u8f83\u5b66\u4e60\u7684\u6846\u67b6\u6821\u51c6\u9879\u76ee\u7279\u5b9a\u6545\u4e8b\u70b9\u9884\u6d4b\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u5728\u6545\u4e8b\u70b9\u4f30\u8ba1\u4e2d\u7684\u6548\u679c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u56de\u5f52\u65b9\u6cd5\u66f4\u9ad8\u6548\u3002", "motivation": "\u4f20\u7edf\u6545\u4e8b\u70b9\u4f30\u8ba1\u65b9\u6cd5\u540e\u671f\u7e41\u7410\u4e14\u52b3\u52a8\u5f3a\u5ea6\u5927\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9700\u5927\u91cf\u540c\u9879\u76ee\u6570\u636e\uff0c\u65e8\u5728\u7b80\u5316\u6545\u4e8b\u70b9\u4f30\u8ba1\u3002", "method": "\u5411\u5f00\u53d1\u8005\u5c55\u793a\u5f85\u529e\u4e8b\u9879\u5bf9\uff0c\u8ba9\u5176\u5224\u65ad\u54ea\u4e2a\u66f4\u8017\u65f6\uff0c\u7528\u8fd9\u4e9b\u6bd4\u8f83\u5224\u65ad\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6545\u4e8b\u70b9\u3002", "result": "\u6a21\u578b\u5e73\u5747Spearman\u7b49\u7ea7\u76f8\u5173\u7cfb\u6570\u8fbe0.34\uff0c\u4e0e\u57fa\u4e8e\u771f\u5b9e\u6545\u4e8b\u70b9\u7684\u56de\u5f52\u6a21\u578b\u8868\u73b0\u76f8\u5f53\u6216\u66f4\u597d\u3002", "conclusion": "\u6839\u636e\u6bd4\u8f83\u5224\u65ad\u5b9a\u5f8b\uff0c\u63d0\u51fa\u7684\u6bd4\u8f83\u5b66\u4e60\u65b9\u6cd5\u6bd4\u73b0\u6709\u57fa\u4e8e\u56de\u5f52\u7684\u65b9\u6cd5\u66f4\u9ad8\u6548\uff0c\u8ba4\u77e5\u8d1f\u62c5\u66f4\u4f4e\u3002"}}
{"id": "2507.15003", "pdf": "https://arxiv.org/pdf/2507.15003", "abs": "https://arxiv.org/abs/2507.15003", "authors": ["Hao Li", "Haoxiang Zhang", "Ahmed E. Hassan"], "title": "The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering", "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.LG"], "comment": null, "summary": "The future of software engineering--SE 3.0--is unfolding with the rise of AI\nteammates: autonomous, goal-driven systems collaborating with human developers.\nAmong these, autonomous coding agents are especially transformative, now\nactively initiating, reviewing, and evolving code at scale. This paper\nintroduces AIDev, the first large-scale dataset capturing how such agents\noperate in the wild. Spanning over 456,000 pull requests by five leading\nagents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across\n61,000 repositories and 47,000 developers, AIDev provides an unprecedented\nempirical foundation for studying autonomous teammates in software development.\n  Unlike prior work that has largely theorized the rise of AI-native software\nengineering, AIDev offers structured, open data to support research in\nbenchmarking, agent readiness, optimization, collaboration modeling, and AI\ngovernance. The dataset includes rich metadata on PRs, authorship, review\ntimelines, code changes, and integration outcomes--enabling exploration beyond\nsynthetic benchmarks like SWE-bench. For instance, although agents often\noutperform humans in speed, their PRs are accepted less frequently, revealing a\ntrust and utility gap. Furthermore, while agents accelerate code\nsubmission--one developer submitted as many PRs in three days as they had in\nthree years--these are structurally simpler (via code complexity metrics).\n  We envision AIDev as a living resource: extensible, analyzable, and ready for\nthe SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev\nenables a new generation of research into AI-native workflows and supports\nbuilding the next wave of symbiotic human-AI collaboration. The dataset is\npublicly available at https://github.com/SAILResearch/AI_Teammates_in_SE3.\n  > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering\nAgent", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6AIDev\uff0c\u7528\u4e8e\u7814\u7a76\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u81ea\u4e3b\u7f16\u7801\u4ee3\u7406\uff0c\u8be5\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u4e30\u5bcc\u4fe1\u606f\uff0c\u63ed\u793a\u4e86\u4ee3\u7406\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u7684\u5dee\u5f02\uff0c\u53ef\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u968f\u7740AI\u961f\u53cb\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5174\u8d77\uff0c\u7f3a\u4e4f\u7814\u7a76\u81ea\u4e3b\u7f16\u7801\u4ee3\u7406\u5b9e\u9645\u8fd0\u884c\u60c5\u51b5\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u4ee5\u63a8\u52a8AI\u539f\u751f\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u3002", "method": "\u6536\u96c6\u4e94\u4e2a\u9886\u5148\u4ee3\u7406\u5728\u8d8561,000\u4e2a\u4ed3\u5e93\u300147,000\u540d\u5f00\u53d1\u8005\u4e2d\u7684\u8d85456,000\u4e2a\u62c9\u53d6\u8bf7\u6c42\uff0c\u6784\u5efaAIDev\u6570\u636e\u96c6\u3002", "result": "\u53d1\u73b0\u4ee3\u7406\u5728\u901f\u5ea6\u4e0a\u5e38\u4f18\u4e8e\u4eba\u7c7b\uff0c\u4f46\u62c9\u53d6\u8bf7\u6c42\u63a5\u53d7\u7387\u8f83\u4f4e\uff0c\u4ee3\u7406\u63d0\u4ea4\u4ee3\u7801\u901f\u5ea6\u5feb\u4f46\u7ed3\u6784\u66f4\u7b80\u5355\u3002", "conclusion": "AIDev\u662f\u53ef\u6269\u5c55\u3001\u53ef\u5206\u6790\u7684\u8d44\u6e90\uff0c\u80fd\u4e3aSE\u548cAI\u793e\u533a\u63d0\u4f9b\u652f\u6301\uff0c\u63a8\u52a8AI\u539f\u751f\u5de5\u4f5c\u6d41\u7814\u7a76\u548c\u4eba\u673a\u534f\u4f5c\u53d1\u5c55\u3002"}}
{"id": "2507.14167", "pdf": "https://arxiv.org/pdf/2507.14167", "abs": "https://arxiv.org/abs/2507.14167", "authors": ["Lucas Heublein", "Christian Wielenberg", "Thorsten Nowak", "Tobias Feigl", "Christopher Mutschler", "Felix Ott"], "title": "Attention-Based Fusion of IQ and FFT Spectrograms with AoA Features for GNSS Jammer Localization", "categories": ["eess.SP", "cs.IR", "cs.LG", "62H05, 65-11, 94-11", "E.0; H.1.1; I.2.6; I.5.4"], "comment": "6 pages, 10 figures", "summary": "Jamming devices disrupt signals from the global navigation satellite system\n(GNSS) and pose a significant threat by compromising the reliability of\naccurate positioning. Consequently, the detection and localization of these\ninterference signals are essential to achieve situational awareness, mitigating\ntheir impact, and implementing effective counter-measures. Classical Angle of\nArrival (AoA) methods exhibit reduced accuracy in multipath environments due to\nsignal reflections and scattering, leading to localization errors.\nAdditionally, AoA-based techniques demand substantial computational resources\nfor array signal processing. In this paper, we propose a novel approach for\ndetecting and classifying interference while estimating the distance, azimuth,\nand elevation of jamming sources. Our benchmark study evaluates 128 vision\nencoder and time-series models to identify the highest-performing methods for\neach task. We introduce an attention-based fusion framework that integrates\nin-phase and quadrature (IQ) samples with Fast Fourier Transform (FFT)-computed\nspectrograms while incorporating 22 AoA features to enhance localization\naccuracy. Furthermore, we present a novel dataset of moving jamming devices\nrecorded in an indoor environment with dynamic multipath conditions and\ndemonstrate superior performance compared to state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u68c0\u6d4b\u3001\u5206\u7c7b\u5e72\u6270\u53ca\u4f30\u8ba1\u5e72\u6270\u6e90\u8ddd\u79bb\u3001\u65b9\u4f4d\u548c\u4ef0\u89d2\u7684\u65b0\u65b9\u6cd5\uff0c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\uff0c\u5f15\u5165\u878d\u5408\u6846\u67b6\uff0c\u7528\u65b0\u6570\u636e\u96c6\u9a8c\u8bc1\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5e72\u6270\u8bbe\u5907\u5a01\u80c1GNSS\u5b9a\u4f4d\u53ef\u9760\u6027\uff0c\u7ecf\u5178AoA\u65b9\u6cd5\u5728\u591a\u5f84\u73af\u5883\u7cbe\u5ea6\u4f4e\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u8bc4\u4f30128\u4e2a\u89c6\u89c9\u7f16\u7801\u5668\u548c\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff0c\u5f15\u5165\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u878d\u5408\u6846\u67b6\uff0c\u7ed3\u5408IQ\u6837\u672c\u3001FFT\u9891\u8c31\u56fe\u548c22\u4e2aAoA\u7279\u5f81\u3002", "result": "\u5728\u52a8\u6001\u591a\u5f84\u6761\u4ef6\u7684\u5ba4\u5185\u73af\u5883\u8bb0\u5f55\u65b0\u6570\u636e\u96c6\uff0c\u65b0\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u3001\u5206\u7c7b\u5e72\u6270\u5e76\u5b9a\u4f4d\u5e72\u6270\u6e90\uff0c\u63d0\u9ad8\u5b9a\u4f4d\u7cbe\u5ea6\u3002"}}
{"id": "2507.14227", "pdf": "https://arxiv.org/pdf/2507.14227", "abs": "https://arxiv.org/abs/2507.14227", "authors": ["Khoi Do", "Duong Nguyen", "Nam-Khanh Le", "Quoc-Viet Pham", "Binh-Son Hua", "Won-Joo Hwang"], "title": "Domain Generalization via Pareto Optimal Gradient Matching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this study, we address the gradient-based domain generalization problem,\nwhere predictors aim for consistent gradient directions across different\ndomains. Existing methods have two main challenges. First, minimization of\ngradient empirical distance or gradient inner products (GIP) leads to gradient\nfluctuations among domains, thereby hindering straightforward learning. Second,\nthe direct application of gradient learning to the joint loss function can\nincur high computation overheads due to second-order derivative approximation.\nTo tackle these challenges, we propose a new Pareto Optimality Gradient\nMatching (POGM) method. In contrast to existing methods that add gradient\nmatching as regularization, we leverage gradient trajectories as collected data\nand apply independent training at the meta-learner. In the meta-update, we\nmaximize GIP while limiting the learned gradient from deviating too far from\nthe empirical risk minimization gradient trajectory. By doing so, the aggregate\ngradient can incorporate knowledge from all domains without suffering gradient\nfluctuation towards any particular domain. Experimental evaluations on datasets\nfrom DomainBed demonstrate competitive results yielded by POGM against other\nbaselines while achieving computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684POGM\u65b9\u6cd5\u89e3\u51b3\u57fa\u4e8e\u68af\u5ea6\u7684\u9886\u57df\u6cdb\u5316\u95ee\u9898\uff0c\u5728DomainBed\u6570\u636e\u96c6\u5b9e\u9a8c\u6709\u7ade\u4e89\u529b\u4e14\u5177\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u7684\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u5b58\u5728\u68af\u5ea6\u6ce2\u52a8\u548c\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faPareto Optimality Gradient Matching (POGM)\u65b9\u6cd5\uff0c\u5c06\u68af\u5ea6\u8f68\u8ff9\u4f5c\u4e3a\u6570\u636e\uff0c\u5728\u5143\u5b66\u4e60\u5668\u72ec\u7acb\u8bad\u7ec3\uff0c\u5143\u66f4\u65b0\u65f6\u6700\u5927\u5316GIP\u5e76\u9650\u5236\u68af\u5ea6\u504f\u79bb\u3002", "result": "\u5728DomainBed\u6570\u636e\u96c6\u4e0aPOGM\u6bd4\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u4e14\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "POGM\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5728\u9886\u57df\u6cdb\u5316\u95ee\u9898\u4e0a\u6709\u826f\u597d\u6548\u679c\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.15349", "pdf": "https://arxiv.org/pdf/2507.15349", "abs": "https://arxiv.org/abs/2507.15349", "authors": ["Zehua Cheng", "Rui Sun", "Jiahao Sun", "Yike Guo"], "title": "Scaling Decentralized Learning with FLock", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Fine-tuning the large language models (LLMs) are prevented by the deficiency\nof centralized control and the massive computing and communication overhead on\nthe decentralized schemes. While the typical standard federated learning (FL)\nsupports data privacy, the central server requirement creates a single point of\nattack and vulnerability to poisoning attacks. Generalizing the result in this\ndirection to 70B-parameter models in the heterogeneous, trustless environments\nhas turned out to be a huge, yet unbroken bottleneck. This paper introduces\nFLock, a decentralized framework for secure and efficient collaborative LLM\nfine-tuning. Integrating a blockchain-based trust layer with economic\nincentives, FLock replaces the central aggregator with a secure, auditable\nprotocol for cooperation among untrusted parties. We present the first\nempirical validation of fine-tuning a 70B LLM in a secure, multi-domain,\ndecentralized setting. Our experiments show the FLock framework defends against\nbackdoor poisoning attacks that compromise standard FL optimizers and fosters\nsynergistic knowledge transfer. The resulting models show a >68% reduction in\nadversarial attack success rates. The global model also demonstrates superior\ncross-domain generalization, outperforming models trained in isolation on their\nown specialized data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6FLock\u7528\u4e8e\u5b89\u5168\u9ad8\u6548\u534f\u4f5c\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u62b5\u5fa1\u653b\u51fb\u3001\u4fc3\u8fdb\u77e5\u8bc6\u8f6c\u79fb\u5e76\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u5728\u53bb\u4e2d\u5fc3\u5316\u65b9\u6848\u4e2d\u6709\u63a7\u5236\u7f3a\u5931\u548c\u9ad8\u5f00\u9500\u95ee\u9898\uff0c\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u6709\u5355\u70b9\u653b\u51fb\u548c\u4e2d\u6bd2\u653b\u51fb\u98ce\u9669\uff0c\u5728\u5f02\u6784\u65e0\u4fe1\u4efb\u73af\u5883\u4e0b\u6269\u5c55\u523070B\u53c2\u6570\u6a21\u578b\u662f\u74f6\u9888\u3002", "method": "\u5f15\u5165FLock\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u4fe1\u4efb\u5c42\u4e0e\u7ecf\u6d4e\u6fc0\u52b1\u7ed3\u5408\uff0c\u7528\u5b89\u5168\u53ef\u5ba1\u8ba1\u534f\u8bae\u66ff\u4ee3\u4e2d\u592e\u805a\u5408\u5668\u3002", "result": "\u5b9e\u73b070B\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u3001\u591a\u9886\u57df\u3001\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e0b\u5fae\u8c03\uff0c\u9632\u5fa1\u540e\u95e8\u4e2d\u6bd2\u653b\u51fb\uff0c\u51cf\u5c11\u8d8568%\u7684\u5bf9\u6297\u653b\u51fb\u6210\u529f\u7387\uff0c\u5168\u5c40\u6a21\u578b\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u66f4\u4f18\u3002", "conclusion": "FLock\u6846\u67b6\u53ef\u7528\u4e8e\u5b89\u5168\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u534f\u4f5c\u5fae\u8c03\u3002"}}
{"id": "2507.14660", "pdf": "https://arxiv.org/pdf/2507.14660", "abs": "https://arxiv.org/abs/2507.14660", "authors": ["Qibing Ren", "Sitao Xie", "Longxuan Wei", "Zhenfei Yin", "Junchi Yan", "Lizhuang Ma", "Jing Shao"], "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems", "categories": ["cs.AI", "cs.CL"], "comment": "Code is available at https://github.com/renqibing/RogueAgent", "summary": "Recent large-scale events like election fraud and financial scams have shown\nhow harmful coordinated efforts by human groups can be. With the rise of\nautonomous AI systems, there is growing concern that AI-driven groups could\nalso cause similar harm. While most AI safety research focuses on individual AI\nsystems, the risks posed by multi-agent systems (MAS) in complex real-world\nsituations are still underexplored. In this paper, we introduce a\nproof-of-concept to simulate the risks of malicious MAS collusion, using a\nflexible framework that supports both centralized and decentralized\ncoordination structures. We apply this framework to two high-risk fields:\nmisinformation spread and e-commerce fraud. Our findings show that\ndecentralized systems are more effective at carrying out malicious actions than\ncentralized ones. The increased autonomy of decentralized systems allows them\nto adapt their strategies and cause more damage. Even when traditional\ninterventions, like content flagging, are applied, decentralized groups can\nadjust their tactics to avoid detection. We present key insights into how these\nmalicious groups operate and the need for better detection systems and\ncountermeasures. Code is available at https://github.com/renqibing/RogueAgent.", "AI": {"tldr": "\u8bba\u6587\u5f15\u5165\u6846\u67b6\u6a21\u62df\u6076\u610f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u52fe\u7ed3\u98ce\u9669\uff0c\u5e94\u7528\u4e8e\u4e24\u5927\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u53d1\u73b0\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u66f4\u6613\u5b9e\u65bd\u6076\u610f\u884c\u4e3a\uff0c\u9700\u66f4\u597d\u68c0\u6d4b\u4e0e\u5bf9\u7b56\u3002", "motivation": "\u8fd1\u671f\u5927\u578b\u4e8b\u4ef6\u51f8\u663e\u4eba\u7c7b\u7fa4\u4f53\u534f\u540c\u5371\u5bb3\uff0c\u968f\u7740\u81ea\u4e3bAI\u7cfb\u7edf\u5174\u8d77\uff0cAI\u9a71\u52a8\u7fa4\u4f53\u5371\u5bb3\u53d7\u5173\u6ce8\uff0c\u4f46MAS\u5728\u73b0\u5b9e\u573a\u666f\u98ce\u9669\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u7075\u6d3b\u6846\u67b6\u6a21\u62df\u6076\u610fMAS\u52fe\u7ed3\u98ce\u9669\uff0c\u652f\u6301\u96c6\u4e2d\u4e0e\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\u7ed3\u6784\uff0c\u5e76\u5e94\u7528\u4e8e\u4fe1\u606f\u4f20\u64ad\u548c\u7535\u5546\u6b3a\u8bc8\u4e24\u5927\u9ad8\u98ce\u9669\u9886\u57df\u3002", "result": "\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u5b9e\u65bd\u6076\u610f\u884c\u4e3a\u66f4\u6709\u6548\uff0c\u81ea\u4e3b\u6027\u9ad8\u53ef\u8c03\u6574\u7b56\u7565\u9020\u6210\u66f4\u5927\u7834\u574f\uff0c\u80fd\u89c4\u907f\u4f20\u7edf\u5e72\u9884\u3002", "conclusion": "\u9700\u6df1\u5165\u4e86\u89e3\u6076\u610f\u7fa4\u4f53\u8fd0\u4f5c\uff0c\u6784\u5efa\u66f4\u597d\u68c0\u6d4b\u7cfb\u7edf\u4e0e\u5e94\u5bf9\u7b56\u7565\u3002"}}
{"id": "2507.15025", "pdf": "https://arxiv.org/pdf/2507.15025", "abs": "https://arxiv.org/abs/2507.15025", "authors": ["Nenad Petrovic", "Vahid Zolfaghari", "Andre Schamschurko", "Sven Kirchner", "Fengjunjie Pan", "Chengdng Wu", "Nils Purschke", "Aleksei Velsh", "Krzysztof Lebioda", "Yinglei Song", "Yi Zhang", "Lukasz Mazur", "Alois Knoll"], "title": "Survey of GenAI for Automotive Software Development: From Requirements to Executable Code", "categories": ["cs.SE", "cs.AI"], "comment": "Conference paper accepted for GACLM 2025", "summary": "Adoption of state-of-art Generative Artificial Intelligence (GenAI) aims to\nrevolutionize many industrial areas by reducing the amount of human\nintervention needed and effort for handling complex underlying processes.\nAutomotive software development is considered to be a significant area for\nGenAI adoption, taking into account lengthy and expensive procedures, resulting\nfrom the amount of requirements and strict standardization. In this paper, we\nexplore the adoption of GenAI for various steps of automotive software\ndevelopment, mainly focusing on requirements handling, compliance aspects and\ncode generation. Three GenAI-related technologies are covered within the\nstate-of-art: Large Language Models (LLMs), Retrieval Augmented Generation\n(RAG), Vision Language Models (VLMs), as well as overview of adopted prompting\ntechniques in case of code generation. Additionally, we also derive a\ngeneralized GenAI-aided automotive software development workflow based on our\nfindings from this literature review. Finally, we include a summary of a survey\noutcome, which was conducted among our automotive industry partners regarding\nthe type of GenAI tools used for their daily work activities.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u5404\u6b65\u9aa4\u7684\u5e94\u7528\uff0c\u6d89\u53ca\u76f8\u5173\u6280\u672f\u3001\u5f00\u53d1\u6d41\u7a0b\u53ca\u884c\u4e1a\u8c03\u67e5\u7ed3\u679c\u3002", "motivation": "GenAI\u53ef\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u548c\u5904\u7406\u590d\u6742\u6d41\u7a0b\u7684\u5de5\u4f5c\u91cf\uff0c\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u957f\u4e14\u6210\u672c\u9ad8\uff0c\u6709\u5e94\u7528GenAI\u7684\u9700\u6c42\u3002", "method": "\u63a2\u7d22GenAI\u5728\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u591a\u6b65\u9aa4\u7684\u5e94\u7528\uff0c\u6db5\u76d6\u4e09\u79cd\u76f8\u5173\u6280\u672f\u548c\u4ee3\u7801\u751f\u6210\u63d0\u793a\u6280\u672f\uff0c\u57fa\u4e8e\u6587\u732e\u7efc\u8ff0\u5f97\u51fa\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8fdb\u884c\u884c\u4e1a\u4f19\u4f34\u8c03\u67e5\u3002", "result": "\u5f97\u51fa\u901a\u7528\u7684GenAI\u8f85\u52a9\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\uff0c\u603b\u7ed3\u4e86\u884c\u4e1a\u4f19\u4f34\u4f7f\u7528GenAI\u5de5\u5177\u7684\u8c03\u67e5\u7ed3\u679c\u3002", "conclusion": "GenAI\u5728\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u6709\u5e94\u7528\u4ef7\u503c\uff0c\u53ef\u52a9\u529b\u76f8\u5173\u5de5\u4f5c\u3002"}}
{"id": "2507.14245", "pdf": "https://arxiv.org/pdf/2507.14245", "abs": "https://arxiv.org/abs/2507.14245", "authors": ["Hengjie Yu", "Kenneth A. Dawson", "Haiyun Yang", "Shuya Liu", "Yan Yan", "Yaochu Jin"], "title": "A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "cs.CE", "q-bio.BM", "I.6.5; J.3; I.5.4"], "comment": "31 pages, 6 figures", "summary": "Unlocking the potential of nanomaterials in medicine and environmental\nscience hinges on understanding their interactions with proteins, a complex\ndecision space where AI is poised to make a transformative impact. However,\nprogress has been hindered by limited datasets and the restricted\ngeneralizability of existing models. Here, we propose NanoPro-3M, the largest\nnanomaterial-protein interaction dataset to date, comprising over 3.2 million\nsamples and 37,000 unique proteins. Leveraging this, we present NanoProFormer,\na foundational model that predicts nanomaterial-protein affinities through\nmultimodal representation learning, demonstrating strong generalization,\nhandling missing features, and unseen nanomaterials or proteins. We show that\nmultimodal modeling significantly outperforms single-modality approaches and\nidentifies key determinants of corona formation. Furthermore, we demonstrate\nits applicability to a range of downstream tasks through zero-shot inference\nand fine-tuning. Together, this work establishes a solid foundation for\nhigh-performance and generalized prediction of nanomaterial-protein interaction\nendpoints, reducing experimental reliance and accelerating various in vitro\napplications.", "AI": {"tldr": "\u63d0\u51faNanoPro - 3M\u6570\u636e\u96c6\u548cNanoProFormer\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u7eb3\u7c73\u6750\u6599 - \u86cb\u767d\u8d28\u4eb2\u548c\u529b\uff0c\u6709\u826f\u597d\u6cdb\u5316\u6027\u548c\u591a\u4e0b\u6e38\u4efb\u52a1\u9002\u7528\u6027\u3002", "motivation": "\u7406\u89e3\u7eb3\u7c73\u6750\u6599\u4e0e\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u5bf9\u533b\u5b66\u548c\u73af\u5883\u79d1\u5b66\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u8fdb\u5c55\u53d7\u9650\u4e8e\u6709\u9650\u6570\u636e\u96c6\u548c\u6a21\u578b\u6cdb\u5316\u6027\u4e0d\u8db3\u3002", "method": "\u6784\u5efaNanoPro - 3M\u6570\u636e\u96c6\uff0c\u5229\u7528\u591a\u6a21\u6001\u8868\u793a\u5b66\u4e60\u63d0\u51faNanoProFormer\u6a21\u578b\u3002", "result": "\u591a\u6a21\u6001\u5efa\u6a21\u4f18\u4e8e\u5355\u6a21\u6001\u65b9\u6cd5\uff0c\u80fd\u8bc6\u522b\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\uff0c\u53ef\u7528\u4e8e\u96f6\u6837\u672c\u63a8\u7406\u548c\u5fae\u8c03\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "conclusion": "\u4e3a\u9ad8\u6027\u80fd\u3001\u901a\u7528\u7684\u7eb3\u7c73\u6750\u6599 - \u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u5960\u5b9a\u57fa\u7840\uff0c\u51cf\u5c11\u5b9e\u9a8c\u4f9d\u8d56\u5e76\u52a0\u901f\u4f53\u5916\u5e94\u7528\u3002"}}
{"id": "2507.14206", "pdf": "https://arxiv.org/pdf/2507.14206", "abs": "https://arxiv.org/abs/2507.14206", "authors": ["Zhijiang Tang", "Jiaxin Qi", "Yuhua Zheng", "Jianqiang Huang"], "title": "A Comprehensive Benchmark for Electrocardiogram Time-Series", "categories": ["eess.SP", "cs.AI", "cs.LG", "stat.ML"], "comment": "Accepted to ACM MM 2025", "summary": "Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial\nfor assessing cardiac health and diagnosing various diseases. Given its\ntime-series format, ECG data is often incorporated into pre-training datasets\nfor large-scale time-series model training. However, existing studies often\noverlook its unique characteristics and specialized downstream applications,\nwhich differ significantly from other time-series data, leading to an\nincomplete understanding of its properties. In this paper, we present an\nin-depth investigation of ECG signals and establish a comprehensive benchmark,\nwhich includes (1) categorizing its downstream applications into four distinct\nevaluation tasks, (2) identifying limitations in traditional evaluation metrics\nfor ECG analysis, and introducing a novel metric; (3) benchmarking\nstate-of-the-art time-series models and proposing a new architecture. Extensive\nexperiments demonstrate that our proposed benchmark is comprehensive and\nrobust. The results validate the effectiveness of the proposed metric and model\narchitecture, which establish a solid foundation for advancing research in ECG\nsignal analysis.", "AI": {"tldr": "\u6587\u7ae0\u6df1\u5165\u7814\u7a76\u5fc3\u7535\u56fe\u4fe1\u53f7\u5e76\u5efa\u7acb\u7efc\u5408\u57fa\u51c6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u57fa\u51c6\u3001\u65b0\u6307\u6807\u548c\u6a21\u578b\u67b6\u6784\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5fc3\u7535\u56fe\u4fe1\u53f7\u5206\u6790\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5ffd\u89c6\u5fc3\u7535\u56fe\u6570\u636e\u72ec\u7279\u7279\u6027\u548c\u4e0b\u6e38\u5e94\u7528\uff0c\u5bf9\u5176\u6027\u8d28\u7406\u89e3\u4e0d\u5b8c\u6574\u3002", "method": "\u5bf9\u5fc3\u7535\u56fe\u4e0b\u6e38\u5e94\u7528\u5206\u7c7b\u4e3a\u56db\u4e2a\u8bc4\u4f30\u4efb\u52a1\uff0c\u6307\u51fa\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u5c40\u9650\u5e76\u5f15\u5165\u65b0\u6307\u6807\uff0c\u5bf9\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u5e76\u63d0\u51fa\u65b0\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u7684\u57fa\u51c6\u5168\u9762\u4e14\u7a33\u5065\uff0c\u65b0\u6307\u6807\u548c\u6a21\u578b\u67b6\u6784\u6709\u6548\u3002", "conclusion": "\u4e3a\u5fc3\u7535\u56fe\u4fe1\u53f7\u5206\u6790\u7814\u7a76\u5960\u5b9a\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2507.15173", "pdf": "https://arxiv.org/pdf/2507.15173", "abs": "https://arxiv.org/abs/2507.15173", "authors": ["Jason Gaitonde", "Ankur Moitra", "Elchanan Mossel"], "title": "Better Models and Algorithms for Learning Ising Models from Dynamics", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": "49 pages", "summary": "We study the problem of learning the structure and parameters of the Ising\nmodel, a fundamental model of high-dimensional data, when observing the\nevolution of an associated Markov chain. A recent line of work has studied the\nnatural problem of learning when observing an evolution of the well-known\nGlauber dynamics [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Mossel STOC 2024], which provides an arguably more realistic\ngenerative model than the classical i.i.d. setting. However, this prior work\ncrucially assumes that all site update attempts are observed, \\emph{even when\nthis attempt does not change the configuration}: this strong observation model\nis seemingly essential for these approaches. While perhaps possible in\nrestrictive contexts, this precludes applicability to most realistic settings\nwhere we can observe \\emph{only} the stochastic evolution itself, a minimal and\nnatural assumption for any process we might hope to learn from. However,\ndesigning algorithms that succeed in this more realistic setting has remained\nan open problem [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Moitra, Mossel, STOC 2025].\n  In this work, we give the first algorithms that efficiently learn the Ising\nmodel in this much more natural observation model that only observes when the\nconfiguration changes. For Ising models with maximum degree $d$, our algorithm\nrecovers the underlying dependency graph in time $\\mathsf{poly}(d)\\cdot n^2\\log\nn$ and then the actual parameters in additional $\\widetilde{O}(2^d n)$ time,\nwhich qualitatively matches the state-of-the-art even in the i.i.d. setting in\na much weaker observation model. Our analysis holds more generally for a\nbroader class of reversible, single-site Markov chains that also includes the\npopular Metropolis chain by leveraging more robust properties of reversible\nMarkov chains.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14705", "pdf": "https://arxiv.org/pdf/2507.14705", "abs": "https://arxiv.org/abs/2507.14705", "authors": ["Sai Wang", "Senthilnathan Subramanian", "Mudit Sahni", "Praneeth Gone", "Lingjie Meng", "Xiaochen Wang", "Nicolas Ferradas Bertoli", "Tingxian Cheng", "Jun Xu"], "title": "Configurable multi-agent framework for scalable and realistic testing of llm-based agents", "categories": ["cs.AI"], "comment": null, "summary": "Large-language-model (LLM) agents exhibit complex, context-sensitive\nbehaviour that quickly renders static benchmarks and ad-hoc manual testing\nobsolete.\n  We present Neo, a configurable, multi-agent framework that automates\nrealistic, multi-turn evaluation of LLM-based systems. Neo couples a Question\nGeneration Agent and an Evaluation Agent through a shared context-hub, allowing\ndomain prompts, scenario controls and dynamic feedback to be composed\nmodularly. Test inputs are sampled from a probabilistic state model spanning\ndialogue flow, user intent and emotional tone, enabling diverse, human-like\nconversations that adapt after every turn.\n  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)\nuncovered edge-case failures across five attack categories with a 3.3% break\nrate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered\n10-12X higher throughput, generating 180 coherent test questions in around 45\nmins versus 16h of human effort. Beyond security probing, Neo's stochastic\npolicies balanced topic coverage and conversational depth, yielding broader\nbehavioural exploration than manually crafted scripts.\n  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent\ninterfaces, state controller and feedback loops are model-agnostic and\nextensible to richer factual-grounding and policy-compliance checks. We release\nthe framework to facilitate reproducible, high-fidelity testing of emerging\nagentic systems.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u914d\u7f6e\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6Neo\u7528\u4e8e\u81ea\u52a8\u5316\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\uff0c\u5728\u804a\u5929\u673a\u5668\u4eba\u6d4b\u8bd5\u4e2d\u6548\u679c\u826f\u597d\uff0c\u8fd8\u4e3a\u53ef\u6269\u5c55\u7684\u5927\u8bed\u8a00\u6a21\u578bQA\u5960\u5b9a\u57fa\u7840\u5e76\u53d1\u5e03\u6846\u67b6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u884c\u4e3a\u590d\u6742\uff0c\u9759\u6001\u57fa\u51c6\u548c\u4e34\u65f6\u624b\u52a8\u6d4b\u8bd5\u8fc7\u65f6\uff0c\u9700\u65b0\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u6784\u5efaNeo\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u4e0a\u4e0b\u6587\u4e2d\u5fc3\u8fde\u63a5\u95ee\u9898\u751f\u6210\u667a\u80fd\u4f53\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\uff0c\u4ece\u6982\u7387\u72b6\u6001\u6a21\u578b\u91c7\u6837\u6d4b\u8bd5\u8f93\u5165\u3002", "result": "\u5728\u804a\u5929\u673a\u5668\u4eba\u6d4b\u8bd5\u4e2d\u53d1\u73b0\u8fb9\u7f18\u60c5\u51b5\u5931\u8d25\uff0c\u7a81\u7834\u7387\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\uff0c\u541e\u5410\u91cf\u9ad810 - 12\u500d\uff0c\u884c\u4e3a\u63a2\u7d22\u66f4\u5e7f\u6cdb\u3002", "conclusion": "Neo\u4e3a\u53ef\u6269\u5c55\u3001\u81ea\u6211\u8fdb\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578bQA\u5960\u5b9a\u57fa\u7840\uff0c\u5176\u63a5\u53e3\u7b49\u53ef\u6269\u5c55\uff0c\u53d1\u5e03\u6846\u67b6\u4fbf\u4e8e\u65b0\u5174\u667a\u80fd\u4f53\u7cfb\u7edf\u6d4b\u8bd5\u3002"}}
{"id": "2507.15157", "pdf": "https://arxiv.org/pdf/2507.15157", "abs": "https://arxiv.org/abs/2507.15157", "authors": ["Giovanni Quattrocchi", "Liliana Pasquale", "Paola Spoletini", "Luciano Baresi"], "title": "Can LLMs Generate User Stories and Assess Their Quality?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Requirements elicitation is still one of the most challenging activities of\nthe requirements engineering process due to the difficulty requirements\nanalysts face in understanding and translating complex needs into concrete\nrequirements. In addition, specifying high-quality requirements is crucial, as\nit can directly impact the quality of the software to be developed. Although\nautomated tools allow for assessing the syntactic quality of requirements,\nevaluating semantic metrics (e.g., language clarity, internal consistency)\nremains a manual and time-consuming activity. This paper explores how LLMs can\nhelp automate requirements elicitation within agile frameworks, where\nrequirements are defined as user stories (US). We used 10 state-of-the-art LLMs\nto investigate their ability to generate US automatically by emulating customer\ninterviews. We evaluated the quality of US generated by LLMs, comparing it with\nthe quality of US generated by humans (domain experts and students). We also\nexplored whether and how LLMs can be used to automatically evaluate the\nsemantic quality of US. Our results indicate that LLMs can generate US similar\nto humans in terms of coverage and stylistic quality, but exhibit lower\ndiversity and creativity. Although LLM-generated US are generally comparable in\nquality to those created by humans, they tend to meet the acceptance quality\ncriteria less frequently, regardless of the scale of the LLM model. Finally,\nLLMs can reliably assess the semantic quality of US when provided with clear\nevaluation criteria and have the potential to reduce human effort in\nlarge-scale assessments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u654f\u6377\u6846\u67b6\u4e0b\u81ea\u52a8\u9700\u6c42\u83b7\u53d6\u7684\u5e94\u7528\uff0c\u752810\u79cdLLMs\u751f\u6210\u7528\u6237\u6545\u4e8b\uff08US\uff09\uff0c\u8bc4\u4f30\u5176\u8d28\u91cf\u5e76\u4e0e\u4eba\u7c7b\u751f\u6210\u7684\u5bf9\u6bd4\uff0c\u53d1\u73b0LLMs\u751f\u6210US\u5728\u8986\u76d6\u5ea6\u548c\u98ce\u683c\u4e0a\u4e0e\u4eba\u7c7b\u76f8\u4f3c\uff0c\u4f46\u591a\u6837\u6027\u548c\u521b\u9020\u6027\u8f83\u4f4e\uff0c\u4e14\u901a\u8fc7\u8bc4\u4f30\u8bed\u4e49\u8d28\u91cf\u53d1\u73b0\u5b83\u53ef\u51cf\u5c11\u4eba\u529b\u3002", "motivation": "\u9700\u6c42\u83b7\u53d6\u56f0\u96be\u4e14\u8bc4\u4f30\u8bed\u4e49\u6307\u6807\u8017\u65f6\uff0c\u63a2\u7d22LLMs\u5728\u654f\u6377\u6846\u67b6\u4e0b\u81ea\u52a8\u9700\u6c42\u83b7\u53d6\u7684\u53ef\u80fd\u6027\u3002", "method": "\u4f7f\u752810\u79cd\u6700\u5148\u8fdb\u7684LLMs\u6a21\u62df\u5ba2\u6237\u8bbf\u8c08\u81ea\u52a8\u751f\u6210US\uff0c\u8bc4\u4f30\u5176\u8d28\u91cf\u5e76\u4e0e\u4eba\u7c7b\u751f\u6210\u7684US\u5bf9\u6bd4\uff0c\u63a2\u7d22LLMs\u81ea\u52a8\u8bc4\u4f30US\u8bed\u4e49\u8d28\u91cf\u7684\u65b9\u5f0f\u3002", "result": "LLMs\u751f\u6210\u7684US\u5728\u8986\u76d6\u5ea6\u548c\u98ce\u683c\u4e0a\u4e0e\u4eba\u7c7b\u76f8\u4f3c\uff0c\u4f46\u591a\u6837\u6027\u548c\u521b\u9020\u6027\u8f83\u4f4e\uff0c\u8fbe\u5230\u63a5\u53d7\u8d28\u91cf\u6807\u51c6\u7684\u9891\u7387\u8f83\u4f4e\uff0c\u4e14\u80fd\u53ef\u9760\u8bc4\u4f30\u8bed\u4e49\u8d28\u91cf\u3002", "conclusion": "LLMs\u6709\u6f5c\u529b\u51cf\u5c11\u5927\u89c4\u6a21\u8bc4\u4f30\u4e2d\u7684\u4eba\u529b\uff0c\u53ef\u7528\u4e8e\u81ea\u52a8\u9700\u6c42\u83b7\u53d6\u548c\u8bed\u4e49\u8d28\u91cf\u8bc4\u4f30\u3002"}}
{"id": "2507.14758", "pdf": "https://arxiv.org/pdf/2507.14758", "abs": "https://arxiv.org/abs/2507.14758", "authors": ["Luyi Ma", "Wanjia Zhang", "Kai Zhao", "Abhishek Kulkarni", "Lalitesh Morishetti", "Anjana Ganesh", "Ashish Ranjan", "Aashika Padmanabhan", "Jianpeng Xu", "Jason Cho", "Praveen Kanumala", "Kaushiki Nag", "Sumit Dutta", "Kamiya Motwani", "Malay Patel", "Evren Korpeoglu", "Sushant Kumar", "Kannan Achan"], "title": "GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "10 pages, 5 figures, The ACM Conference on Recommender Systems\n  (RecSys) 2025", "summary": "Generative models have recently demonstrated strong potential in\nmulti-behavior recommendation systems, leveraging the expressive power of\ntransformers and tokenization to generate personalized item sequences. However,\ntheir adoption is hindered by (1) the lack of explicit information for token\nreasoning, (2) high computational costs due to quadratic attention complexity\nand dense sequence representations after tokenization, and (3) limited\nmulti-scale modeling over user history. In this work, we propose GRACE\n(Generative Recommendation via journey-aware sparse Attention on\nChain-of-thought tokEnization), a novel generative framework for multi-behavior\nsequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT)\ntokenization method that encodes user-item interactions with explicit\nattributes from product knowledge graphs (e.g., category, brand, price) over\nsemantic tokenization, enabling interpretable and behavior-aligned generation.\nTo address the inefficiency of standard attention, we design a Journey-Aware\nSparse Attention (JSA) mechanism, which selectively attends to compressed,\nintra-, inter-, and current-context segments in the tokenized sequence.\nExperiments on two real-world datasets show that GRACE significantly\noutperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and\n+106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home\ndomain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces\nattention computation by up to 48% with long sequences.", "AI": {"tldr": "\u63d0\u51faGRACE\u6846\u67b6\u7528\u4e8e\u591a\u884c\u4e3a\u5e8f\u5217\u63a8\u8350\uff0c\u5728\u4e24\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e14\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u591a\u884c\u4e3a\u63a8\u8350\u7cfb\u7edf\u5e94\u7528\u53d7\u7f3a\u4e4f\u663e\u5f0f\u4fe1\u606f\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u591a\u5c3a\u5ea6\u5efa\u6a21\u6709\u9650\u7b49\u95ee\u9898\u963b\u788d\u3002", "method": "\u5f15\u5165\u6df7\u5408CoT\u5206\u8bcd\u65b9\u6cd5\u7f16\u7801\u7528\u6237 - \u9879\u76ee\u4ea4\u4e92\uff0c\u8bbe\u8ba1JSA\u673a\u5236\u9009\u62e9\u6027\u5173\u6ce8\u4e0a\u4e0b\u6587\u7247\u6bb5\u3002", "result": "\u5728\u4e24\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5728\u5bb6\u5ead\u9886\u57dfHR@10\u548cNDCG@10\u63d0\u5347\u8d85100%\uff0c\u7535\u5b50\u9886\u57dfHR@10\u63d0\u534722.1%\uff0c\u957f\u5e8f\u5217\u4e0b\u6ce8\u610f\u529b\u8ba1\u7b97\u51cf\u5c1148%\u3002", "conclusion": "GRACE\u6846\u67b6\u6709\u6548\u89e3\u51b3\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u591a\u884c\u4e3a\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u8d8a\u4e14\u8ba1\u7b97\u9ad8\u6548\u3002"}}
{"id": "2507.14257", "pdf": "https://arxiv.org/pdf/2507.14257", "abs": "https://arxiv.org/abs/2507.14257", "authors": ["Julio Candanedo"], "title": "Linearized Diffusion Map", "categories": ["cs.LG"], "comment": null, "summary": "We introduce the Linearized Diffusion Map (LDM), a novel linear\ndimensionality reduction method constructed via a linear approximation of the\ndiffusion-map kernel. LDM integrates the geometric intuition of diffusion-based\nnonlinear methods with the computational simplicity, efficiency, and\ninterpretability inherent in linear embeddings such as PCA and classical MDS.\nThrough comprehensive experiments on synthetic datasets (Swiss roll and\nhyperspheres) and real-world benchmarks (MNIST and COIL-20), we illustrate that\nLDM captures distinct geometric features of datasets compared to PCA, offering\ncomplementary advantages. Specifically, LDM embeddings outperform PCA in\ndatasets exhibiting explicit manifold structures, particularly in\nhigh-dimensional regimes, whereas PCA remains preferable in scenarios dominated\nby variance or noise. Furthermore, the complete positivity of LDM's kernel\nmatrix allows direct applicability of Non-negative Matrix Factorization (NMF),\nsuggesting opportunities for interpretable latent-structure discovery. Our\nanalysis positions LDM as a valuable new linear dimensionality reduction\ntechnique with promising theoretical and practical extensions.", "AI": {"tldr": "\u4ecb\u7ecd\u7ebf\u6027\u5316\u6269\u6563\u6620\u5c04\uff08LDM\uff09\u8fd9\u4e00\u65b0\u7684\u7ebf\u6027\u964d\u7ef4\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\u5176\u4e0ePCA\u76f8\u6bd4\u80fd\u6355\u6349\u6570\u636e\u96c6\u4e0d\u540c\u51e0\u4f55\u7279\u5f81\uff0c\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u7ed3\u5408\u57fa\u4e8e\u6269\u6563\u7684\u975e\u7ebf\u6027\u65b9\u6cd5\u7684\u51e0\u4f55\u76f4\u89c9\u4e0e\u7ebf\u6027\u5d4c\u5165\u7684\u8ba1\u7b97\u7b80\u5355\u3001\u9ad8\u6548\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u901a\u8fc7\u5bf9\u6269\u6563\u6620\u5c04\u6838\u7684\u7ebf\u6027\u8fd1\u4f3c\u6784\u5efaLDM\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLDM\u5728\u6709\u663e\u5f0f\u6d41\u5f62\u7ed3\u6784\u7684\u6570\u636e\u96c6\u4e0a\u4f18\u4e8ePCA\uff0cLDM\u6838\u77e9\u9635\u7684\u5b8c\u5168\u6b63\u6027\u4f7f\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u53ef\u76f4\u63a5\u5e94\u7528\u3002", "conclusion": "LDM\u662f\u6709\u4ef7\u503c\u7684\u7ebf\u6027\u964d\u7ef4\u6280\u672f\uff0c\u6709\u7406\u8bba\u548c\u5b9e\u9645\u6269\u5c55\u6f5c\u529b\u3002"}}
{"id": "2507.15176", "pdf": "https://arxiv.org/pdf/2507.15176", "abs": "https://arxiv.org/abs/2507.15176", "authors": ["Jason Gaitonde", "Elchanan Mossel"], "title": "On Algorithmic Robustness of Corrupted Markov Chains", "categories": ["math.PR", "cs.DS"], "comment": "16 pages", "summary": "We study the algorithmic robustness of general finite Markov chains in terms\nof their stationary distributions to general, adversarial corruptions of the\ntransition matrix. We show that for Markov chains admitting a spectral gap,\nvariants of the \\emph{PageRank} chain are robust in the sense that, given an\n\\emph{arbitrary} corruption of the edges emanating from an $\\epsilon$-measure\nof the nodes, the PageRank distribution of the corrupted chain will be\n$\\mathsf{poly}(\\varepsilon)$ close in total variation to the original\ndistribution under mild conditions on the restart distribution. Our work thus\nshows that PageRank serves as a simple regularizer against broad, realistic\ncorruptions with algorithmic guarantees that are dimension-free and scale\ngracefully in terms of necessary and natural parameters.", "AI": {"tldr": "\u7814\u7a76\u4e00\u822c\u6709\u9650\u9a6c\u5c14\u53ef\u592b\u94fe\u5e73\u7a33\u5206\u5e03\u5bf9\u8f6c\u79fb\u77e9\u9635\u5bf9\u6297\u6027\u7834\u574f\u7684\u7b97\u6cd5\u9c81\u68d2\u6027\uff0c\u8868\u660ePageRank\u94fe\u5728\u4e00\u5b9a\u6761\u4ef6\u4e0b\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u7814\u7a76\u4e00\u822c\u6709\u9650\u9a6c\u5c14\u53ef\u592b\u94fe\u5e73\u7a33\u5206\u5e03\u5bf9\u8f6c\u79fb\u77e9\u9635\u4e00\u822c\u5bf9\u6297\u6027\u7834\u574f\u7684\u7b97\u6cd5\u9c81\u68d2\u6027\u3002", "method": "\u5bf9\u5141\u8bb8\u8c31\u95f4\u9699\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u8fdb\u884c\u7814\u7a76\uff0c\u5206\u6790PageRank\u94fe\u5728\u8282\u70b9\u4e00\u5b9a\u6bd4\u4f8b\u8fb9\u88ab\u4efb\u610f\u7834\u574f\u65f6\u7684\u60c5\u51b5\u3002", "result": "\u5728\u91cd\u542f\u5206\u5e03\u7684\u6e29\u548c\u6761\u4ef6\u4e0b\uff0c\u7ed9\u5b9a\u8282\u70b9\u4e00\u5b9a\u6bd4\u4f8b\u8fb9\u7684\u4efb\u610f\u7834\u574f\uff0c\u53d7\u7834\u574f\u94fe\u7684PageRank\u5206\u5e03\u4e0e\u539f\u5206\u5e03\u5728\u603b\u53d8\u5dee\u4e0a\u63a5\u8fd1\u3002", "conclusion": "PageRank\u53ef\u4f5c\u4e3a\u9488\u5bf9\u5e7f\u6cdb\u3001\u73b0\u5b9e\u7834\u574f\u7684\u7b80\u5355\u6b63\u5219\u5316\u5668\uff0c\u5177\u6709\u65e0\u7ef4\u5ea6\u4e14\u53c2\u6570\u81ea\u7136\u7684\u7b97\u6cd5\u4fdd\u8bc1\u3002"}}
{"id": "2507.14719", "pdf": "https://arxiv.org/pdf/2507.14719", "abs": "https://arxiv.org/abs/2507.14719", "authors": ["Juan Manuel Contreras"], "title": "Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix", "categories": ["cs.AI", "I.2.7; F.2.2"], "comment": null, "summary": "As large language models (LLMs) become increasingly integrated into\nreal-world applications, scalable and rigorous safety evaluation is essential.\nThis paper introduces Aymara AI, a programmatic platform for generating and\nadministering customized, policy-grounded safety evaluations. Aymara AI\ntransforms natural-language safety policies into adversarial prompts and scores\nmodel responses using an AI-based rater validated against human judgments. We\ndemonstrate its capabilities through the Aymara LLM Risk and Responsibility\nMatrix, which evaluates 20 commercially available LLMs across 10 real-world\nsafety domains. Results reveal wide performance disparities, with mean safety\nscores ranging from 86.2% to 52.4%. While models performed well in\nwell-established safety domains such as Misinformation (mean = 95.7%), they\nconsistently failed in more complex or underspecified domains, notably Privacy\n& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety\nscores differed significantly across both models and domains (p < .05). These\nfindings underscore the inconsistent and context-dependent nature of LLM safety\nand highlight the need for scalable, customizable tools like Aymara AI to\nsupport responsible AI development and oversight.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecdAymara AI\u5e73\u53f0\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u8bc4\u4f30\uff0c\u8bc4\u4f3020\u4e2a\u5546\u7528\u6a21\u578b\uff0c\u53d1\u73b0\u6027\u80fd\u5dee\u5f02\u5927\uff0c\u5f3a\u8c03\u9700\u53ef\u6269\u5c55\u5b9a\u5236\u5de5\u5177\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5165\u5b9e\u9645\u5e94\u7528\uff0c\u9700\u8981\u53ef\u6269\u5c55\u4e14\u4e25\u683c\u7684\u5b89\u5168\u8bc4\u4f30\u3002", "method": "Aymara AI\u5c06\u81ea\u7136\u8bed\u8a00\u5b89\u5168\u7b56\u7565\u8f6c\u5316\u4e3a\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u7528\u57fa\u4e8eAI\u7684\u8bc4\u5206\u5668\u6839\u636e\u4eba\u7c7b\u5224\u65ad\u9a8c\u8bc1\u6765\u5bf9\u6a21\u578b\u54cd\u5e94\u8bc4\u5206\uff0c\u901a\u8fc7Aymara LLM\u98ce\u9669\u548c\u8d23\u4efb\u77e9\u9635\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f3020\u4e2a\u5546\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5404\u6a21\u578b\u5b89\u5168\u5f97\u5206\u5dee\u5f02\u5927\uff0c\u5728\u4e0d\u540c\u9886\u57df\u8868\u73b0\u4e0d\u540c\uff0c\u65b9\u5dee\u5206\u6790\u663e\u793a\u6a21\u578b\u548c\u9886\u57df\u95f4\u5b89\u5168\u5f97\u5206\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5177\u6709\u4e0d\u4e00\u81f4\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u7279\u70b9\uff0c\u9700\u8981\u50cfAymara AI\u8fd9\u6837\u7684\u53ef\u6269\u5c55\u3001\u53ef\u5b9a\u5236\u5de5\u5177\u6765\u652f\u6301\u8d1f\u8d23\u4efb\u7684AI\u5f00\u53d1\u548c\u76d1\u7763\u3002"}}
{"id": "2507.15181", "pdf": "https://arxiv.org/pdf/2507.15181", "abs": "https://arxiv.org/abs/2507.15181", "authors": ["Yinglong Zou", "Juan Zhai", "Chunrong Fang", "Yanzhou Mu", "Jiawei Liu", "Zhenyu Chen"], "title": "Deep Learning Framework Testing via Heuristic Guidance Based on Multiple Model Measurements", "categories": ["cs.SE"], "comment": null, "summary": "Deep learning frameworks serve as the foundation for developing and deploying\ndeep learning applications. To enhance the quality of deep learning frameworks,\nresearchers have proposed numerous testing methods using deep learning models\nas test inputs. However, existing methods predominantly measure model bug\ndetection effectiveness as heuristic indicators, presenting three critical\nlimitations: Firstly, existing methods fail to quantitatively measure model's\noperator combination variety, potentially missing critical operator\ncombinations that could trigger framework bugs. Secondly, existing methods\nneglect measuring model execution time, resulting in the omission of numerous\nmodels potential for detecting more framework bugs within limited testing time.\nThirdly, existing methods overlook correlation between different model\nmeasurements, relying simply on single-indicator heuristic guidance without\nconsidering their trade-offs. To overcome these limitations, we propose DLMMM,\nthe first deep learning framework testing method to include multiple model\nmeasurements into heuristic guidance and fuse these measurements to achieve\ntheir trade-off. DLMMM firstly quantitatively measures model's bug detection\nperformance, operator combination variety, and model execution time. After\nthat, DLMMM fuses the above measurements based on their correlation to achieve\ntheir trade-off. To further enhance testing effectiveness, DLMMM designs\nmulti-level heuristic guidance for test input model generation.", "AI": {"tldr": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6d4b\u8bd5\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u63d0\u51faDLMMM\u65b9\u6cd5\u89e3\u51b3\u95ee\u9898", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6d4b\u8bd5\u65b9\u6cd5\u4ee5\u542f\u53d1\u5f0f\u6307\u6807\u8861\u91cf\u6a21\u578b\u6f0f\u6d1e\u68c0\u6d4b\u6548\u679c\uff0c\u5b58\u5728\u65e0\u6cd5\u5b9a\u91cf\u8861\u91cf\u7b97\u5b50\u7ec4\u5408\u591a\u6837\u6027\u3001\u5ffd\u7565\u6a21\u578b\u6267\u884c\u65f6\u95f4\u3001\u5ffd\u89c6\u4e0d\u540c\u6d4b\u91cf\u6307\u6807\u76f8\u5173\u6027\u7b49\u5c40\u9650", "method": "\u63d0\u51faDLMMM\u65b9\u6cd5\uff0c\u5148\u5b9a\u91cf\u8861\u91cf\u6a21\u578b\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\u3001\u7b97\u5b50\u7ec4\u5408\u591a\u6837\u6027\u548c\u6a21\u578b\u6267\u884c\u65f6\u95f4\uff0c\u518d\u6839\u636e\u76f8\u5173\u6027\u878d\u5408\u8fd9\u4e9b\u6d4b\u91cf\u6307\u6807\u4ee5\u5b9e\u73b0\u6743\u8861\uff0c\u8fd8\u8bbe\u8ba1\u591a\u7ea7\u542f\u53d1\u5f0f\u6307\u5bfc\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\u6a21\u578b", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2507.15042", "pdf": "https://arxiv.org/pdf/2507.15042", "abs": "https://arxiv.org/abs/2507.15042", "authors": ["Jerry Wang", "Fang Yu"], "title": "DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection", "categories": ["cs.AI", "cs.IR", "I.2.7; H.3.3; K.6.5"], "comment": "Accepted by KDD Workshop on Prompt Optimization 2025", "summary": "Adversarial prompt attacks can significantly alter the reliability of\nRetrieval-Augmented Generation (RAG) systems by re-ranking them to produce\nincorrect outputs. In this paper, we present a novel method that applies\nDifferential Evolution (DE) to optimize adversarial prompt suffixes for\nRAG-based question answering. Our approach is gradient-free, treating the RAG\npipeline as a black box and evolving a population of candidate suffixes to\nmaximize the retrieval rank of a targeted incorrect document to be closer to\nreal world scenarios. We conducted experiments on the BEIR QA datasets to\nevaluate attack success at certain retrieval rank thresholds under multiple\nretrieving applications. Our results demonstrate that DE-based prompt\noptimization attains competitive (and in some cases higher) success rates\ncompared to GGPP to dense retrievers and PRADA to sparse retrievers, while\nusing only a small number of tokens (<=5 tokens) in the adversarial suffix.\nFurthermore, we introduce a readability-aware suffix construction strategy,\nvalidated by a statistically significant reduction in MLM negative\nlog-likelihood with Welch's t-test. Through evaluations with a BERT-based\nadversarial suffix detector, we show that DE-generated suffixes evade\ndetection, yielding near-chance detection accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5dee\u5206\u8fdb\u5316\uff08DE\uff09\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\u653b\u51fb\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u95ee\u7b54\u7684\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6210\u529f\u7387\u9ad8\u3001\u4f7f\u7528\u540e\u7f00\u77ed\u3001\u96be\u88ab\u68c0\u6d4b\u3002", "motivation": "\u5bf9\u6297\u6027\u63d0\u793a\u653b\u51fb\u4f1a\u5f71\u54cdRAG\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u9700\u8981\u65b0\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u5e94\u7528\u5dee\u5206\u8fdb\u5316\uff08DE\uff09\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\uff0c\u5c06RAG\u7ba1\u9053\u89c6\u4e3a\u9ed1\u76d2\uff0c\u8fdb\u5316\u5019\u9009\u540e\u7f00\u4ee5\u63d0\u9ad8\u76ee\u6807\u9519\u8bef\u6587\u6863\u68c0\u7d22\u6392\u540d\u3002", "result": "DE\u65b9\u6cd5\u5728\u6210\u529f\u7387\u4e0a\u4e0eGGPP\u548cPRADA\u76f8\u5f53\u751a\u81f3\u66f4\u9ad8\uff0c\u540e\u7f00\u4ec5\u9700\u5c11\u91cf\u6807\u8bb0\uff0c\u540e\u7f00\u6784\u9020\u7b56\u7565\u964d\u4f4eMLM\u8d1f\u5bf9\u6570\u4f3c\u7136\uff0c\u540e\u7f00\u96be\u88ab\u68c0\u6d4b\u3002", "conclusion": "DE\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\u7684\u65b9\u6cd5\u6709\u6548\u4e14\u96be\u88ab\u68c0\u6d4b\uff0c\u5177\u6709\u4e00\u5b9a\u4f18\u52bf\u3002"}}
{"id": "2507.14295", "pdf": "https://arxiv.org/pdf/2507.14295", "abs": "https://arxiv.org/abs/2507.14295", "authors": ["Licheng Liu", "Zihan Wang", "Linjie Li", "Chenwei Xu", "Yiping Lu", "Han Liu", "Avirup Sil", "Manling Li"], "title": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-turn problem solving is critical yet challenging for Large Reasoning\nModels (LRMs) to reflect on their reasoning and revise from feedback. Existing\nReinforcement Learning (RL) methods train large reasoning models on a\nsingle-turn paradigm with verifiable rewards. However, we observe that models\ntrained with existing RL paradigms often lose their ability to solve problems\nacross multiple turns and struggle to revise answers based on contextual\nfeedback, leading to repetitive responses. We ask: can LRMs learn to reflect\ntheir answers in a multi-turn context? In this work, we find that training\nmodels with multi-turn RL using only unary feedback (e.g., \"Let's try again\")\nafter wrong answers can improve both single-turn performance and multi-turn\nreasoning. We introduce Unary Feedback as Observation (UFO) for reinforcement\nlearning, which uses minimal yet common unary user feedback during iterative\nproblem solving. It can be easily applied to existing single-turn RL training\nsetups. Experimental results show that RL training with UFO keeps single-turn\nperformance and improves multi-turn reasoning accuracy by up to 14%, enabling\nlanguage models to better react to feedback in multi-turn problem solving. To\nfurther minimize the number of turns needed for a correct answer while\nencouraging diverse reasoning when mistakes occur, we design reward structures\nthat guide models to produce careful and deliberate answers in each turn. Code:\nhttps://github.com/lichengliu03/unary-feedback", "AI": {"tldr": "\u63d0\u51faUFO\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347\u5927\u63a8\u7406\u6a21\u578b\u591a\u8f6e\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u63d0\u9ad8\u591a\u8f6e\u63a8\u7406\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec3\u7684\u5927\u63a8\u7406\u6a21\u578b\u5728\u591a\u8f6e\u95ee\u9898\u89e3\u51b3\u4e2d\u5b58\u5728\u80fd\u529b\u7f3a\u5931\uff0c\u96be\u4ee5\u6839\u636e\u53cd\u9988\u4fee\u6b63\u7b54\u6848\u3002", "method": "\u5f15\u5165Unary Feedback as Observation (UFO)\u8fdb\u884c\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\uff0c\u8bbe\u8ba1\u5956\u52b1\u7ed3\u6784\u5f15\u5bfc\u6a21\u578b\u4ed4\u7ec6\u4f5c\u7b54\u3002", "result": "\u4f7f\u7528UFO\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4fdd\u6301\u5355\u8f6e\u6027\u80fd\uff0c\u591a\u8f6e\u63a8\u7406\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534714%\u3002", "conclusion": "UFO\u53ef\u63d0\u5347\u5927\u63a8\u7406\u6a21\u578b\u5728\u591a\u8f6e\u95ee\u9898\u89e3\u51b3\u4e2d\u5bf9\u53cd\u9988\u7684\u53cd\u5e94\u80fd\u529b\u3002"}}
{"id": "2507.14492", "pdf": "https://arxiv.org/pdf/2507.14492", "abs": "https://arxiv.org/abs/2507.14492", "authors": ["Satyankar Chandra", "Ashutosh Gupta", "Kaushik Mallik", "Krishna Shankaranarayanan", "Namrita Varshney"], "title": "Glitches in Decision Tree Ensemble Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Many critical decision-making tasks are now delegated to machine-learned\nmodels, and it is imperative that their decisions are trustworthy and reliable,\nand their outputs are consistent across similar inputs. We identify a new\nsource of unreliable behaviors-called glitches-which may significantly impair\nthe reliability of AI models having steep decision boundaries. Roughly\nspeaking, glitches are small neighborhoods in the input space where the model's\noutput abruptly oscillates with respect to small changes in the input. We\nprovide a formal definition of glitches, and use well-known models and datasets\nfrom the literature to demonstrate that they have widespread existence and\nargue they usually indicate potential model inconsistencies in the neighborhood\nof where they are found. We proceed to the algorithmic search of glitches for\nwidely used gradient-boosted decision tree (GBDT) models. We prove that the\nproblem of detecting glitches is NP-complete for tree ensembles, already for\ntrees of depth 4. Our glitch-search algorithm for GBDT models uses an MILP\nencoding of the problem, and its effectiveness and computational feasibility\nare demonstrated on a set of widely used GBDT benchmarks taken from the\nliterature.", "AI": {"tldr": "\u6587\u7ae0\u8bc6\u522b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u4e0d\u53ef\u9760\u884c\u4e3a\u201cglitches\u201d\uff0c\u7ed9\u51fa\u5b9a\u4e49\uff0c\u8bc1\u660e\u68c0\u6d4b\u95ee\u9898\u4e3aNP - \u5b8c\u5168\u95ee\u9898\uff0c\u63d0\u51fa\u641c\u7d22\u7b97\u6cd5\u5e76\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u8bb8\u591a\u5173\u952e\u51b3\u7b56\u4efb\u52a1\u4f9d\u8d56\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u9700\u4fdd\u8bc1\u5176\u51b3\u7b56\u53ef\u4fe1\u53ef\u9760\u3001\u8f93\u51fa\u4e00\u81f4\uff0c\u800c\u201cglitches\u201d\u4f1a\u635f\u5bb3\u6a21\u578b\u53ef\u9760\u6027\u3002", "method": "\u7ed9\u51fa\u201cglitches\u201d\u6b63\u5f0f\u5b9a\u4e49\uff0c\u7528\u77e5\u540d\u6a21\u578b\u548c\u6570\u636e\u96c6\u8bc1\u660e\u5176\u5b58\u5728\uff1b\u5bf9GBDT\u6a21\u578b\u8fdb\u884c\u7b97\u6cd5\u641c\u7d22\uff0c\u5c06\u95ee\u9898\u7f16\u7801\u4e3aMILP\u6c42\u89e3\u3002", "result": "\u8bc1\u660e\u6811\u96c6\u6210\u4e2d\u68c0\u6d4b\u201cglitches\u201d\u95ee\u9898\u5728\u6811\u6df1\u5ea6\u4e3a4\u65f6\u662fNP - \u5b8c\u5168\u95ee\u9898\uff0c\u7b97\u6cd5\u5728GBDT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u6709\u6548\u6027\u548c\u8ba1\u7b97\u53ef\u884c\u6027\u3002", "conclusion": "\u201cglitches\u201d\u5e7f\u6cdb\u5b58\u5728\uff0c\u901a\u5e38\u9884\u793a\u6a21\u578b\u7684\u6f5c\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u6240\u63d0\u7b97\u6cd5\u53ef\u6709\u6548\u641c\u7d22GBDT\u6a21\u578b\u4e2d\u7684\u201cglitches\u201d\u3002"}}
{"id": "2507.15316", "pdf": "https://arxiv.org/pdf/2507.15316", "abs": "https://arxiv.org/abs/2507.15316", "authors": ["Benedek Nagy"], "title": "A Myhill-Nerode Type Characterization of 2detLIN Languages", "categories": ["cs.FL", "cs.DM", "cs.DS", "F.1.1;F.4.3;F.1.3"], "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "summary": "Linear automata are automata with two reading heads starting from the two\nextremes of the input, are equivalent to 5' -> 3' Watson-Crick (WK) finite\nautomata. The heads read the input in opposite directions and the computation\nfinishes when the heads meet. These automata accept the class LIN of linear\nlanguages. The deterministic counterpart of these models, on the one hand, is\nless expressive, as only a proper subset of LIN, the class 2detLIN is accepted;\nand on the other hand, they are also equivalent in the sense of the class of\nthe accepted languages. Now, based on these automata models, we characterize\nthe class of 2detLIN languages with a Myhill-Nerode type of equivalence\nclasses. However, as these automata may do the computation of both the prefix\nand the suffix of the input, we use prefix-suffix pairs in our classes.\nAdditionally, it is proven that finitely many classes in the characterization\nmatch with the 2detLIN languages, but we have some constraints on the used\nprefix-suffix pairs, i.e., the characterization should have the property to be\ncomplete and it must not have any crossing pairs.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u7ebf\u6027\u81ea\u52a8\u673a\u6a21\u578b\u523b\u753b2detLIN\u8bed\u8a00\u7c7b\uff0c\u4f7f\u7528\u524d\u7f00 - \u540e\u7f00\u5bf9\uff0c\u8bc1\u660e\u6709\u9650\u7c7b\u523b\u753b\u4e0e2detLIN\u8bed\u8a00\u5339\u914d\u4e14\u6709\u7ea6\u675f\u6761\u4ef6\u3002", "motivation": "\u57fa\u4e8e\u5df2\u6709\u7684\u7ebf\u6027\u81ea\u52a8\u673a\u53ca\u5176\u786e\u5b9a\u6027\u5bf9\u5e94\u6a21\u578b\u7684\u6027\u8d28\uff0c\u5bf92detLIN\u8bed\u8a00\u7c7b\u8fdb\u884c\u523b\u753b\u3002", "method": "\u4f7f\u7528Myhill - Nerode\u7c7b\u578b\u7684\u7b49\u4ef7\u7c7b\uff0c\u91c7\u7528\u524d\u7f00 - \u540e\u7f00\u5bf9\u8fdb\u884c\u523b\u753b\u3002", "result": "\u8bc1\u660e\u6709\u9650\u7c7b\u523b\u753b\u4e0e2detLIN\u8bed\u8a00\u5339\u914d\uff0c\u4f46\u5bf9\u524d\u7f00 - \u540e\u7f00\u5bf9\u6709\u7ea6\u675f\uff0c\u5373\u523b\u753b\u9700\u5b8c\u6574\u4e14\u65e0\u4ea4\u53c9\u5bf9\u3002", "conclusion": "\u53ef\u4ee5\u7528\u6ee1\u8db3\u7279\u5b9a\u7ea6\u675f\u6761\u4ef6\u7684\u524d\u7f00 - \u540e\u7f00\u5bf9\u7684\u6709\u9650\u7b49\u4ef7\u7c7b\u6765\u523b\u753b2detLIN\u8bed\u8a00\u7c7b\u3002"}}
{"id": "2507.14730", "pdf": "https://arxiv.org/pdf/2507.14730", "abs": "https://arxiv.org/abs/2507.14730", "authors": ["Yanjie Fu"], "title": "Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI", "categories": ["cs.AI"], "comment": "4 pages; will continue to update to add more figures to describe the\n  vision;", "summary": "Generative AI, large language models, and agentic AI have emerged separately\nof urban planning. However, the convergence between AI and urban planning\npresents an interesting opportunity towards AI urban planners. This paper\nconceptualizes urban planning as a generative AI task, where AI synthesizes\nland-use configurations under geospatial, social, and human-centric\nconstraints. We survey how generative AI approaches, including VAEs, GANs,\ntransformers, and diffusion models, reshape urban design. We further identify\ncritical gaps: 1) limited research on integrating urban theory guidance, 2)\nlimited research of AI urban planning over multiple spatial resolutions or\nangularities, 3) limited research on augmenting urban design knowledge from\ndata, and 4) limited research on addressing real-world interactions. To address\nthese limitations, we outline future research directions in theory-guided\ngeneration, digital twins, and human-machine co-design, calling for a new\nsynthesis of generative intelligence and participatory urbanism.", "AI": {"tldr": "\u672c\u6587\u5c06\u57ce\u5e02\u89c4\u5212\u6982\u5ff5\u5316\u4e3a\u751f\u6210\u5f0fAI\u4efb\u52a1\uff0c\u8c03\u7814\u751f\u6210\u5f0fAI\u65b9\u6cd5\u5bf9\u57ce\u5e02\u8bbe\u8ba1\u7684\u91cd\u5851\uff0c\u6307\u51fa\u7814\u7a76\u7f3a\u53e3\u5e76\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "AI\u4e0e\u57ce\u5e02\u89c4\u5212\u878d\u5408\u5e26\u6765\u6210\u4e3aAI\u57ce\u5e02\u89c4\u5212\u5e08\u7684\u673a\u4f1a\uff0c\u9700\u63a2\u7d22\u76f8\u5173\u5e94\u7528\u3002", "method": "\u5c06\u57ce\u5e02\u89c4\u5212\u6982\u5ff5\u5316\u4e3a\u751f\u6210\u5f0fAI\u4efb\u52a1\uff0c\u8c03\u7814VAEs\u3001GANs\u3001transformers\u548c\u6269\u6563\u6a21\u578b\u7b49\u751f\u6210\u5f0fAI\u65b9\u6cd5\u5bf9\u57ce\u5e02\u8bbe\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u8bc6\u522b\u51fa\u5728\u6574\u5408\u57ce\u5e02\u7406\u8bba\u6307\u5bfc\u3001\u591a\u7a7a\u95f4\u5206\u8fa8\u7387\u6216\u89d2\u5ea6\u7814\u7a76\u3001\u4ece\u6570\u636e\u589e\u5f3a\u57ce\u5e02\u8bbe\u8ba1\u77e5\u8bc6\u3001\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4ea4\u4e92\u65b9\u9762\u7684\u7814\u7a76\u7f3a\u53e3\u3002", "conclusion": "\u63d0\u51fa\u7406\u8bba\u5f15\u5bfc\u751f\u6210\u3001\u6570\u5b57\u5b6a\u751f\u548c\u4eba\u673a\u534f\u540c\u8bbe\u8ba1\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u547c\u5401\u751f\u6210\u667a\u80fd\u4e0e\u53c2\u4e0e\u5f0f\u57ce\u5e02\u4e3b\u4e49\u7684\u65b0\u878d\u5408\u3002"}}
{"id": "2507.15188", "pdf": "https://arxiv.org/pdf/2507.15188", "abs": "https://arxiv.org/abs/2507.15188", "authors": ["Chowdhury Shahriar Muzammel", "Maria Spichkova", "James Harland"], "title": "Cultural Impact on Requirements Engineering Activities: Bangladeshi Practitioners' View", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "Requirements Engineering (RE) is one of the most interaction-intensive phases\nof software development. This means that RE activities might be especially\nimpacted by stakeholders' national culture. Software development projects\nincreasingly have a very diverse range of stakeholders. To future-proof RE\nactivities, we need to help RE practitioners avoid misunderstandings and\nconflicts that might arise from not understanding potential Cultural Influences\n(CIs). Moreover, an awareness of CIs supports diversity and inclusion in the IT\nprofession. Bangladesh has a growing IT sector with some unique socio-cultural\ncharacteristics, and has been largely overlooked in this research field. In\nthis study, we aim to investigate how the RE process is adopted in the context\nof Bangladeshi culture and what cultural influences impact overall RE\nactivities.", "AI": {"tldr": "\u7814\u7a76\u5b5f\u52a0\u62c9\u56fd\u6587\u5316\u80cc\u666f\u4e0b\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u6d41\u7a0b\u7684\u91c7\u7528\u60c5\u51b5\u53ca\u6587\u5316\u5f71\u54cd\u3002", "motivation": "RE\u6d3b\u52a8\u53d7\u5229\u76ca\u76f8\u5173\u8005\u56fd\u5bb6\u6587\u5316\u5f71\u54cd\u5927\uff0c\u5f53\u524d\u8f6f\u4ef6\u5f00\u53d1\u9879\u76ee\u5229\u76ca\u76f8\u5173\u8005\u591a\u5143\uff0c\u4e14\u5b5f\u52a0\u62c9\u56fd\u5728\u8be5\u7814\u7a76\u9886\u57df\u88ab\u5ffd\u89c6\uff0c\u9700\u7814\u7a76\u5176\u6587\u5316\u5bf9RE\u6d3b\u52a8\u7684\u5f71\u54cd\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2507.15742", "pdf": "https://arxiv.org/pdf/2507.15742", "abs": "https://arxiv.org/abs/2507.15742", "authors": ["Paul Sheridan", "Zeyad Ahmed", "Aitazaz A. Farooque"], "title": "A Fisher's exact test justification of the TF-IDF term-weighting scheme", "categories": ["cs.CL", "cs.IR", "math.ST", "stat.TH"], "comment": "23 pages, 4 tables", "summary": "Term frequency-inverse document frequency, or TF-IDF for short, is arguably\nthe most celebrated mathematical expression in the history of information\nretrieval. Conceived as a simple heuristic quantifying the extent to which a\ngiven term's occurrences are concentrated in any one given document out of\nmany, TF-IDF and its many variants are routinely used as term-weighting schemes\nin diverse text analysis applications. There is a growing body of scholarship\ndedicated to placing TF-IDF on a sound theoretical foundation. Building on that\ntradition, this paper justifies the use of TF-IDF to the statistics community\nby demonstrating how the famed expression can be understood from a significance\ntesting perspective. We show that the common TF-IDF variant TF-ICF is, under\nmild regularity conditions, closely related to the negative logarithm of the\n$p$-value from a one-tailed version of Fisher's exact test of statistical\nsignificance. As a corollary, we establish a connection between TF-IDF and the\nsaid negative log-transformed $p$-value under certain idealized assumptions. We\nfurther demonstrate, as a limiting case, that this same quantity converges to\nTF-IDF in the limit of an infinitely large document collection. The Fisher's\nexact test justification of TF-IDF equips the working statistician with a ready\nexplanation of the term-weighting scheme's long-established effectiveness.", "AI": {"tldr": "\u672c\u6587\u4ece\u663e\u8457\u6027\u68c0\u9a8c\u89d2\u5ea6\u89e3\u91caTF - IDF\uff0c\u8bc1\u660e\u5e38\u89c1\u53d8\u4f53TF - ICF\u4e0eFisher\u7cbe\u786e\u68c0\u9a8cp\u503c\u8d1f\u5bf9\u6570\u76f8\u5173\uff0c\u5728\u7279\u5b9a\u5047\u8bbe\u4e0b\u5efa\u7acbTF - IDF\u4e0e\u8d1f\u5bf9\u6570\u53d8\u6362p\u503c\u8054\u7cfb\uff0c\u4e14\u5728\u6587\u6863\u96c6\u65e0\u9650\u5927\u65f6\u6536\u655b\u5230TF - IDF\u3002", "motivation": "\u5c06TF - IDF\u7f6e\u4e8e\u53ef\u9760\u7406\u8bba\u57fa\u7840\uff0c\u5411\u7edf\u8ba1\u5b66\u754c\u8bc1\u660e\u5176\u5408\u7406\u6027\u3002", "method": "\u4ece\u663e\u8457\u6027\u68c0\u9a8c\u89d2\u5ea6\u5206\u6790\uff0c\u8bc1\u660eTF - ICF\u4e0eFisher\u7cbe\u786e\u68c0\u9a8cp\u503c\u8d1f\u5bf9\u6570\u7684\u5173\u7cfb\u3002", "result": "\u8868\u660eTF - ICF\u5728\u6e29\u548c\u6b63\u5219\u6761\u4ef6\u4e0b\u4e0eFisher\u7cbe\u786e\u68c0\u9a8cp\u503c\u8d1f\u5bf9\u6570\u5bc6\u5207\u76f8\u5173\uff0c\u5728\u7279\u5b9a\u5047\u8bbe\u4e0b\u5efa\u7acbTF - IDF\u4e0e\u8d1f\u5bf9\u6570\u53d8\u6362p\u503c\u8054\u7cfb\uff0c\u6587\u6863\u96c6\u65e0\u9650\u5927\u65f6\u6536\u655b\u5230TF - IDF\u3002", "conclusion": "Fisher\u7cbe\u786e\u68c0\u9a8c\u5bf9TF - IDF\u7684\u89e3\u91ca\u4e3a\u7edf\u8ba1\u5b66\u5bb6\u63d0\u4f9b\u4e86\u8be5\u8bcd\u52a0\u6743\u65b9\u6848\u6709\u6548\u6027\u7684\u73b0\u6210\u89e3\u91ca\u3002"}}
{"id": "2507.14499", "pdf": "https://arxiv.org/pdf/2507.14499", "abs": "https://arxiv.org/abs/2507.14499", "authors": ["Qian Qi"], "title": "Neural Brownian Motion", "categories": ["math.PR", "cs.AI", "cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "This paper introduces the Neural-Brownian Motion (NBM), a new class of\nstochastic processes for modeling dynamics under learned uncertainty. The NBM\nis defined axiomatically by replacing the classical martingale property with\nrespect to linear expectation with one relative to a non-linear Neural\nExpectation Operator, $\\varepsilon^\\theta$, generated by a Backward Stochastic\nDifferential Equation (BSDE) whose driver $f_\\theta$ is parameterized by a\nneural network. Our main result is a representation theorem for a canonical\nNBM, which we define as a continuous $\\varepsilon^\\theta$-martingale with zero\ndrift under the physical measure. We prove that, under a key structural\nassumption on the driver, such a canonical NBM exists and is the unique strong\nsolution to a stochastic differential equation of the form ${\\rm d} M_t =\n\\nu_\\theta(t, M_t) {\\rm d} W_t$. Crucially, the volatility function\n$\\nu_\\theta$ is not postulated a priori but is implicitly defined by the\nalgebraic constraint $g_\\theta(t, M_t, \\nu_\\theta(t, M_t)) = 0$, where\n$g_\\theta$ is a specialization of the BSDE driver. We develop the stochastic\ncalculus for this process and prove a Girsanov-type theorem for the quadratic\ncase, showing that an NBM acquires a drift under a new, learned measure. The\ncharacter of this measure, whether pessimistic or optimistic, is endogenously\ndetermined by the learned parameters $\\theta$, providing a rigorous foundation\nfor models where the attitude towards uncertainty is a discoverable feature.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u795e\u7ecf\u5e03\u6717\u8fd0\u52a8\uff08NBM\uff09\uff0c\u7ed9\u51fa\u5176\u8868\u793a\u5b9a\u7406\uff0c\u53d1\u5c55\u4e86\u968f\u673a\u5fae\u79ef\u5206\u5e76\u8bc1\u660e\u4e86\u4e8c\u6b21\u60c5\u5f62\u7684Girsanov\u578b\u5b9a\u7406\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u6001\u5ea6\u53ef\u53d1\u73b0\u7684\u6a21\u578b\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u5f15\u5165\u65b0\u7684\u968f\u673a\u8fc7\u7a0b\u6765\u5bf9\u5b66\u4e60\u5230\u7684\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u52a8\u529b\u5b66\u8fdb\u884c\u5efa\u6a21\u3002", "method": "\u901a\u8fc7\u7528\u76f8\u5bf9\u4e8e\u975e\u7ebf\u6027\u795e\u7ecf\u671f\u671b\u7b97\u5b50\u7684\u6027\u8d28\u66ff\u4ee3\u7ecf\u5178\u9785\u6027\u8d28\u6765\u516c\u7406\u5316\u5b9a\u4e49NBM\uff0c\u8bc1\u660e\u8868\u793a\u5b9a\u7406\u7b49\u3002", "result": "\u8bc1\u660e\u89c4\u8303NBM\u5b58\u5728\u4e14\u662f\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u552f\u4e00\u5f3a\u89e3\uff0c\u53d1\u5c55\u968f\u673a\u5fae\u79ef\u5206\u5e76\u8bc1\u660e\u4e8c\u6b21\u60c5\u5f62\u7684Girsanov\u578b\u5b9a\u7406\u3002", "conclusion": "NBM\u4e3a\u4e0d\u786e\u5b9a\u6027\u6001\u5ea6\u53ef\u53d1\u73b0\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u4e25\u8c28\u57fa\u7840\u3002"}}
{"id": "2507.15511", "pdf": "https://arxiv.org/pdf/2507.15511", "abs": "https://arxiv.org/abs/2507.15511", "authors": ["Jesus Salas"], "title": "Certificate-Sensitive Subset Sum: Realizing Instance Complexity", "categories": ["cs.CC", "cs.DS", "F.1.3; F.2.2"], "comment": "14 pages + appendix. Companion to arXiv:2503.20162 (\"Beyond\n  Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-2^{n/2}\n  Enumeration\"", "summary": "We present, to our knowledge, the first deterministic, certificate-sensitive\nalgorithm for a canonical NP-complete problem whose runtime provably adapts to\nthe structure of each input. For a Subset-Sum instance $(S, t)$, let\n$\\Sigma(S)$ denote the set of distinct subset sums and define $U =\n|\\Sigma(S)|$. This set serves as an information-theoretically minimal witness,\nthe instance-complexity (IC) certificate.\n  Our solver, IC-SubsetSum, enumerates every element of $\\Sigma(S)$ in\ndeterministic time $O(U \\cdot n^2)$ and space $O(U \\cdot n)$. A randomized\nvariant achieves expected runtime $O(U \\cdot n)$. The algorithm's complexity is\nthus directly governed by the certificate size, and this structure-sensitive\nperformance is paired with a guaranteed worst-case runtime of $O^*(2^{n/2 -\n\\varepsilon})$ for some constant $\\varepsilon > 0$, the first such result to\nstrictly outperform classical methods on every instance.\n  We revisit fine-grained reductions that rely on the classical $2^{n/2}$\nhardness of SubsetSum and show that these arguments hold only for\ncollision-free instances where $U$ is maximal. IC-SubsetSum reframes this\nbarrier structurally and introduces a new paradigm for certificate-sensitive\nalgorithms across NP-complete problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14897", "pdf": "https://arxiv.org/pdf/2507.14897", "abs": "https://arxiv.org/abs/2507.14897", "authors": ["Renxi Wang", "Rifo Ahmad Genadi", "Bilal El Bouardi", "Yongxin Wang", "Fajri Koto", "Zhengzhong Liu", "Timothy Baldwin", "Haonan Li"], "title": "AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents", "categories": ["cs.AI", "I.2.5"], "comment": null, "summary": "Language model (LM) agents have gained significant attention for their\nability to autonomously complete tasks through interactions with environments,\ntools, and APIs. LM agents are primarily built with prompt engineering or\nsupervised finetuning. At the same time, reinforcement learning (RL) has been\nexplored to enhance LM's capabilities, such as reasoning and factuality.\nHowever, the combination of the LM agents and reinforcement learning (Agent-RL)\nremains underexplored and lacks systematic study. To this end, we built\nAgentFly, a scalable and extensible Agent-RL framework designed to empower LM\nagents with a variety of RL algorithms. Our framework supports multi-turn\ninteractions by adapting traditional RL methods with token-level masking. It\nfeatures a decorator-based interface for defining tools and reward functions,\nenabling seamless extension and ease of use. To support high-throughput\ntraining, we implement asynchronous execution of tool calls and reward\ncomputations, and design a centralized resource management system for scalable\nenvironment coordination. We also provide a suite of prebuilt tools and\nenvironments, demonstrating the framework's effectiveness through successful\nagent training across multiple tasks.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\uff0c\u6784\u5efa\u4e86\u53ef\u6269\u5c55\u7684AgentFly\u6846\u67b6\uff0c\u652f\u6301\u591a\u8f6e\u4ea4\u4e92\u3001\u5de5\u5177\u548c\u5956\u52b1\u51fd\u6570\u5b9a\u4e49\u7b49\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u8bad\u7ec3\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff08Agent - RL\uff09\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\uff0c\u9700\u8981\u6784\u5efa\u6846\u67b6\u6765\u7814\u7a76\u3002", "method": "\u6784\u5efaAgentFly\u6846\u67b6\uff0c\u7528token\u7ea7\u63a9\u7801\u9002\u914d\u4f20\u7edfRL\u65b9\u6cd5\u652f\u6301\u591a\u8f6e\u4ea4\u4e92\uff0c\u4f7f\u7528\u57fa\u4e8e\u88c5\u9970\u5668\u7684\u63a5\u53e3\u5b9a\u4e49\u5de5\u5177\u548c\u5956\u52b1\u51fd\u6570\uff0c\u5b9e\u73b0\u5de5\u5177\u8c03\u7528\u548c\u5956\u52b1\u8ba1\u7b97\u7684\u5f02\u6b65\u6267\u884c\uff0c\u8bbe\u8ba1\u96c6\u4e2d\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\u8fdb\u884c\u73af\u5883\u534f\u8c03\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u5957\u9884\u6784\u5efa\u5de5\u5177\u548c\u73af\u5883\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u6210\u529f\u8bad\u7ec3\u4ee3\u7406\u3002", "conclusion": "AgentFly\u6846\u67b6\u53ef\u6709\u6548\u8d4b\u80fd\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u8fd0\u7528\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u6613\u7528\u6027\u3002"}}
{"id": "2507.15197", "pdf": "https://arxiv.org/pdf/2507.15197", "abs": "https://arxiv.org/abs/2507.15197", "authors": ["Chowdhury Shahriar Muzammel", "Maria Spichkova", "James Harland"], "title": "Towards Using Personas in Requirements Engineering: What Has Been Changed Recently?", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "In requirements engineering (RE), personas are now being used to represent\nuser expectations and needs. This systematic mapping study (SMS) aims to\nexplore the most recent studies and to cover recent changes in trends,\nespecially related to the recent evolution of Generative AI approaches. Our SMS\ncovers the period between April 2023 and April 2025. We identified 22 relevant\npublications and analysed persona representation, construction, validation, as\nwell as RE activities covered by personas. We identified that a number of\nstudies applied AI-based solutions for persona construction and validation. We\nobserved that template-based personas are becoming more popular nowadays. We\nalso observed an increase in the proportion of studies covering validation\naspects.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u63a2\u7d222023\u5e744\u6708\u81f32025\u5e744\u6708\u9700\u6c42\u5de5\u7a0b\u4e2d\u4eba\u7269\u89d2\u8272\u76f8\u5173\u7814\u7a76\uff0c\u5206\u6790\u5176\u8868\u793a\u3001\u6784\u5efa\u3001\u9a8c\u8bc1\u7b49\uff0c\u53d1\u73b0AI\u5e94\u7528\u3001\u6a21\u677f\u5f0f\u4eba\u7269\u89d2\u8272\u53ca\u9a8c\u8bc1\u7814\u7a76\u589e\u591a\u3002", "motivation": "\u63a2\u7d22\u9700\u6c42\u5de5\u7a0b\u4e2d\u4eba\u7269\u89d2\u8272\u76f8\u5173\u6700\u65b0\u7814\u7a76\u53ca\u751f\u6210\u5f0fAI\u65b9\u6cd5\u5e26\u6765\u7684\u8d8b\u52bf\u53d8\u5316\u3002", "method": "\u8fdb\u884c\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff0c\u5206\u67902023\u5e744\u6708\u81f32025\u5e744\u6708\u95f422\u7bc7\u76f8\u5173\u51fa\u7248\u7269\u3002", "result": "\u8bb8\u591a\u7814\u7a76\u5c06\u57fa\u4e8eAI\u7684\u89e3\u51b3\u65b9\u6848\u7528\u4e8e\u4eba\u7269\u89d2\u8272\u6784\u5efa\u548c\u9a8c\u8bc1\uff0c\u6a21\u677f\u5f0f\u4eba\u7269\u89d2\u8272\u66f4\u53d7\u6b22\u8fce\uff0c\u6d89\u53ca\u9a8c\u8bc1\u65b9\u9762\u7684\u7814\u7a76\u6bd4\u4f8b\u589e\u52a0\u3002", "conclusion": ""}}
{"id": "2507.14326", "pdf": "https://arxiv.org/pdf/2507.14326", "abs": "https://arxiv.org/abs/2507.14326", "authors": ["Aryana Hou", "Li Lin", "Justin Li", "Shu Hu"], "title": "Rethinking Individual Fairness in Deepfake Detection", "categories": ["cs.LG", "cs.CY"], "comment": "This paper has been accepted by ACM MM 2025", "summary": "Generative AI models have substantially improved the realism of synthetic\nmedia, yet their misuse through sophisticated DeepFakes poses significant\nrisks. Despite recent advances in deepfake detection, fairness remains\ninadequately addressed, enabling deepfake markers to exploit biases against\nspecific populations. While previous studies have emphasized group-level\nfairness, individual fairness (i.e., ensuring similar predictions for similar\nindividuals) remains largely unexplored. In this work, we identify for the\nfirst time that the original principle of individual fairness fundamentally\nfails in the context of deepfake detection, revealing a critical gap previously\nunexplored in the literature. To mitigate it, we propose the first\ngeneralizable framework that can be integrated into existing deepfake detectors\nto enhance individual fairness and generalization. Extensive experiments\nconducted on leading deepfake datasets demonstrate that our approach\nsignificantly improves individual fairness while maintaining robust detection\nperformance, outperforming state-of-the-art methods. The code is available at\nhttps://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection.", "AI": {"tldr": "\u73b0\u6709\u751f\u6210\u5f0fAI\u6a21\u578b\u81f4DeepFakes\u98ce\u9669\u5927\uff0c\u6b64\u524d\u7814\u7a76\u672a\u5145\u5206\u89e3\u51b3\u6df1\u4f2a\u68c0\u6d4b\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5c24\u5176\u4e2a\u4f53\u516c\u5e73\u6027\u3002\u672c\u6587\u6307\u51fa\u539f\u4e2a\u4f53\u516c\u5e73\u539f\u5219\u5728\u6df1\u4f2a\u68c0\u6d4b\u4e2d\u5931\u6548\uff0c\u63d0\u51fa\u53ef\u96c6\u6210\u6846\u67b6\u63d0\u5347\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u6cdb\u5316\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6548\u679c\u597d\u3002", "motivation": "\u5f53\u524d\u6df1\u4f2a\u68c0\u6d4b\u516c\u5e73\u6027\u672a\u5145\u5206\u89e3\u51b3\uff0c\u4e2a\u4f53\u516c\u5e73\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u539f\u4e2a\u4f53\u516c\u5e73\u539f\u5219\u5728\u6df1\u4f2a\u68c0\u6d4b\u4e2d\u5b58\u5728\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u53ef\u96c6\u6210\u5230\u73b0\u6709\u6df1\u4f2a\u68c0\u6d4b\u5668\u7684\u901a\u7528\u6846\u67b6\u6765\u63d0\u5347\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u6cdb\u5316\u6027\u3002", "result": "\u5728\u4e3b\u6d41\u6df1\u4f2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e2a\u4f53\u516c\u5e73\u6027\uff0c\u4fdd\u6301\u4e86\u7a33\u5065\u68c0\u6d4b\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u6df1\u4f2a\u68c0\u6d4b\u4e2d\u7684\u4e2a\u4f53\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.14740", "pdf": "https://arxiv.org/pdf/2507.14740", "abs": "https://arxiv.org/abs/2507.14740", "authors": ["Andrew Wang", "Elisa Nguyen", "Runshi Yang", "Juhan Bae", "Sheila A. McIlraith", "Roger Grosse"], "title": "Better Training Data Attribution via Better Inverse Hessian-Vector Products", "categories": ["cs.LG", "stat.ML"], "comment": "28 pages, 4 figures", "summary": "Training data attribution (TDA) provides insights into which training data is\nresponsible for a learned model behavior. Gradient-based TDA methods such as\ninfluence functions and unrolled differentiation both involve a computation\nthat resembles an inverse Hessian-vector product (iHVP), which is difficult to\napproximate efficiently. We introduce an algorithm (ASTRA) which uses the\nEKFAC-preconditioner on Neumann series iterations to arrive at an accurate iHVP\napproximation for TDA. ASTRA is easy to tune, requires fewer iterations than\nNeumann series iterations, and is more accurate than EKFAC-based\napproximations. Using ASTRA, we show that improving the accuracy of the iHVP\napproximation can significantly improve TDA performance.", "AI": {"tldr": "\u63d0\u51fa\u7b97\u6cd5ASTRA\u7528\u4e8e\u8bad\u7ec3\u6570\u636e\u5f52\u56e0\uff0c\u63d0\u5347iHVP\u8fd1\u4f3c\u51c6\u786e\u6027\u4ee5\u6539\u5584TDA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u6570\u636e\u5f52\u56e0\uff08TDA\uff09\u65b9\u6cd5\u4e2d\uff0c\u9006Hessian\u5411\u91cf\u79ef\uff08iHVP\uff09\u96be\u4ee5\u9ad8\u6548\u8fd1\u4f3c\u3002", "method": "\u5f15\u5165\u7b97\u6cd5ASTRA\uff0c\u5728Neumann\u7ea7\u6570\u8fed\u4ee3\u4e0a\u4f7f\u7528EKFAC\u9884\u8c03\u8282\u5668\u5f97\u5230\u51c6\u786e\u7684iHVP\u8fd1\u4f3c\u3002", "result": "ASTRA\u6613\u4e8e\u8c03\u53c2\uff0c\u6bd4Neumann\u7ea7\u6570\u8fed\u4ee3\u6240\u9700\u8fed\u4ee3\u6b21\u6570\u5c11\uff0c\u6bd4\u57fa\u4e8eEKFAC\u7684\u8fd1\u4f3c\u66f4\u51c6\u786e\u3002", "conclusion": "\u63d0\u9ad8iHVP\u8fd1\u4f3c\u7684\u51c6\u786e\u6027\u53ef\u663e\u8457\u63d0\u9ad8TDA\u6027\u80fd\u3002"}}
{"id": "2507.14899", "pdf": "https://arxiv.org/pdf/2507.14899", "abs": "https://arxiv.org/abs/2507.14899", "authors": ["Jiale Liu", "Huan Wang", "Yue Zhang", "Xiaoyu Luo", "Jiaxiang Hu", "Zhiliang Liu", "Min Xie"], "title": "InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Non-destructive testing (NDT), particularly X-ray inspection, is vital for\nindustrial quality assurance, yet existing deep-learning-based approaches often\nlack interactivity, interpretability, and the capacity for critical\nself-assessment, limiting their reliability and operator trust. To address\nthese shortcomings, this paper proposes InsightX Agent, a novel LMM-based\nagentic framework designed to deliver reliable, interpretable, and interactive\nX-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent\npositions a Large Multimodal Model (LMM) as a central orchestrator,\ncoordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the\nEvidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect\nregion proposals for multi-scale feature maps and sparsifies them through\nNon-Maximum Suppression (NMS), optimizing detection of small, dense targets in\nX-ray images while maintaining computational efficiency. The EGR tool guides\nthe LMM agent through a chain-of-thought-inspired review process, incorporating\ncontext assessment, individual defect analysis, false positive elimination,\nconfidence recalibration and quality assurance to validate and refine the\nSDMSD's initial proposals. By strategically employing and intelligently using\ntools, InsightX Agent moves beyond passive data processing to active reasoning,\nenhancing diagnostic reliability and providing interpretations that integrate\ndiverse information sources. Experimental evaluations on the GDXray+ dataset\ndemonstrate that InsightX Agent not only achieves a high object detection\nF1-score of 96.35% but also offers significantly improved interpretability and\ntrustworthiness in its analyses, highlighting the transformative potential of\nagentic LLM frameworks for industrial inspection tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eLMM\u7684InsightX Agent\u6846\u67b6\u7528\u4e8eX\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\uff0c\u901a\u8fc7SDMSD\u548cEGR\u5de5\u5177\u63d0\u5347\u68c0\u6d4b\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5b9e\u9a8c\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u4ea4\u4e92\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\uff0c\u9650\u5236\u4e86\u53ef\u9760\u6027\u548c\u64cd\u4f5c\u4eba\u5458\u4fe1\u4efb\u3002", "method": "\u63d0\u51faInsightX Agent\u6846\u67b6\uff0c\u4ee5LMM\u4e3a\u6838\u5fc3\u534f\u8c03SDMSD\u548cEGR\u5de5\u5177\u3002SDMSD\u7528\u4e8e\u751f\u6210\u548c\u4f18\u5316\u7f3a\u9677\u533a\u57df\u63d0\u6848\uff0cEGR\u5de5\u5177\u7528\u4e8e\u9a8c\u8bc1\u548c\u7ec6\u5316\u63d0\u6848\u3002", "result": "\u5728GDXray+\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u5f97\u523096.35%\u7684\u9ad8F1\u5206\u6570\uff0c\u4e14\u5206\u6790\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u57fa\u4e8e\u4ee3\u7406\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\u5bf9\u5de5\u4e1a\u68c0\u6d4b\u4efb\u52a1\u6709\u53d8\u9769\u6f5c\u529b\u3002"}}
{"id": "2507.15224", "pdf": "https://arxiv.org/pdf/2507.15224", "abs": "https://arxiv.org/abs/2507.15224", "authors": ["Yibo He", "Shuoran Zhao", "Jiaming Huang", "Yingjie Fu", "Hao Yu", "Cunjian Huang", "Tao Xie"], "title": "SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "SIMD (Single Instruction Multiple Data) instructions and their compiler\nintrinsics are widely supported by modern processors to accelerate\nperformance-critical tasks. SIMD intrinsic programming, a trade-off between\ncoding productivity and high performance, is widely used in the development of\nmainstream performance-critical libraries and daily computing tasks. Large\nLanguage Models (LLMs), which have demonstrated strong and comprehensive\ncapabilities in code generation, show promise in assisting programmers with the\nchallenges of SIMD intrinsic programming. However, existing code-generation\nbenchmarks focus on only scalar code, and it is unclear how LLMs perform in\ngenerating vectorized code using SIMD intrinsics. To fill this gap, we propose\nSimdBench, the first code benchmark specifically designed for SIMD-intrinsic\ncode generation, comprising 136 carefully crafted tasks and targeting five\nrepresentative SIMD intrinsics: SSE (x86 Streaming SIMD Extension), AVX (x86\nAdvanced Vector Extension), Neon (ARM Advanced SIMD Extension), SVE (ARM\nScalable Vector Extension), and RVV (RISC-V Vector Extension). We conduct a\nsystematic evaluation (measuring both correctness and performance) of 18\nrepresentative LLMs on SimdBench, resulting in a series of novel and insightful\nfindings. Our evaluation results demonstrate that LLMs exhibit a universal\ndecrease in pass@k during SIMD-intrinsic code generation compared to\nscalar-code generation. Our in-depth analysis highlights promising directions\nfor the further advancement of LLMs in the challenging domain of SIMD-intrinsic\ncode generation. SimdBench is fully open source at\nhttps://anonymous.4open.science/r/SimdBench-1B3F/ to benefit the broader\nresearch community.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u9488\u5bf9SIMD\u6307\u4ee4\u96c6\u4ee3\u7801\u751f\u6210\u7684\u57fa\u51c6\u6d4b\u8bd5SimdBench\uff0c\u5bf918\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u5728SIMD\u4ee3\u7801\u751f\u6210\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u6307\u51fa\u6539\u8fdb\u65b9\u5411\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u5173\u6ce8\u6807\u91cf\u4ee3\u7801\uff0c\u4e0d\u6e05\u695a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210SIMD\u5411\u91cf\u5316\u4ee3\u7801\u7684\u8868\u73b0\uff0c\u4e3a\u586b\u8865\u8be5\u7a7a\u767d\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u5305\u542b136\u4e2a\u4efb\u52a1\u3001\u9488\u5bf95\u79cd\u4ee3\u8868\u6027SIMD\u6307\u4ee4\u96c6\u7684SimdBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5bf918\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6b63\u786e\u6027\u548c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5728SIMD\u4ee3\u7801\u751f\u6210\u65f6pass@k\u76f8\u6bd4\u6807\u91cf\u4ee3\u7801\u751f\u6210\u666e\u904d\u4e0b\u964d\u3002", "conclusion": "\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5728SIMD\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u6307\u51fa\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0cSimdBench\u5f00\u6e90\u9020\u798f\u793e\u533a\u3002"}}
{"id": "2507.14332", "pdf": "https://arxiv.org/pdf/2507.14332", "abs": "https://arxiv.org/abs/2507.14332", "authors": ["Aidan Furlong", "Xingang Zhao", "Robert Salko", "Xu Wu"], "title": "Development and Deployment of Hybrid ML Models for Critical Heat Flux Prediction in Annulus Geometries", "categories": ["cs.LG"], "comment": "Accepted for inclusion in Transactions of the American Nuclear\n  Society for the 2025 ANS Winter Conference", "summary": "Accurate prediction of critical heat flux (CHF) is an essential component of\nsafety analysis in pressurized and boiling water reactors. To support reliable\nprediction of this quantity, several empirical correlations and lookup tables\nhave been constructed from physical experiments over the past several decades.\nWith the onset of accessible machine learning (ML) frameworks, multiple\ninitiatives have been established with the goal of predicting CHF more\naccurately than these traditional methods. While purely data-driven surrogate\nmodeling has been extensively investigated, these approaches lack\ninterpretability, lack resilience to data scarcity, and have been developed\nmostly using data from tube experiments. As a result, bias-correction hybrid\napproaches have become increasingly popular, which correct initial\n\"low-fidelity\" estimates provided by deterministic base models by using\nML-predicted residuals. This body of work has mostly considered round tube\ngeometries; annular geometry-specific ML models have not yet been deployed in\nthermal hydraulic codes. This study developed, deployed, and validated four ML\nmodels to predict CHF in annular geometries using the CTF subchannel code.\nThree empirical correlation models, Biasi, Bowring, and Katto, were used as\nbase models for comparison. The ML models were trained and tested using 577\nexperimental annulus data points from four datasets: Becker, Beus, Janssen, and\nMortimore. Baseline CHF predictions were obtained from the empirical\ncorrelations, with mean relative errors above 26%. The ML-driven models\nachieved mean relative errors below 3.5%, with no more than one point exceeding\nthe 10% error envelope. In all cases, the hybrid ML models significantly\noutperformed their empirical counterparts.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u3001\u90e8\u7f72\u5e76\u9a8c\u8bc1\u4e86\u56db\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u73af\u5f62\u51e0\u4f55\u7ed3\u6784\u4e2d\u7684\u4e34\u754c\u70ed\u901a\u91cf\uff08CHF\uff09\uff0c\u8fd9\u4e9b\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u7ecf\u9a8c\u5173\u8054\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9884\u6d4b CHF \u5b58\u5728\u5c40\u9650\u6027\uff0c\u7eaf\u6570\u636e\u9a71\u52a8\u4ee3\u7406\u6a21\u578b\u6709\u4e0d\u8db3\uff0c\u73af\u5f62\u51e0\u4f55\u7ed3\u6784\u7279\u5b9a\u7684 ML \u6a21\u578b\u672a\u5728\u70ed\u5de5\u6c34\u529b\u4ee3\u7801\u4e2d\u5e94\u7528\uff0c\u56e0\u6b64\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u4f7f\u7528 CTF \u5b50\u901a\u9053\u4ee3\u7801\u5f00\u53d1\u56db\u4e2a ML \u6a21\u578b\uff0c\u4ee5 Biasi\u3001Bowring \u548c Katto \u4e09\u4e2a\u7ecf\u9a8c\u5173\u8054\u6a21\u578b\u4e3a\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\uff0c\u7528\u56db\u4e2a\u6570\u636e\u96c6\u7684 577 \u4e2a\u5b9e\u9a8c\u6570\u636e\u70b9\u8bad\u7ec3\u548c\u6d4b\u8bd5 ML \u6a21\u578b\u3002", "result": "\u7ecf\u9a8c\u5173\u8054\u6a21\u578b\u7684 CHF \u9884\u6d4b\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u8d85 26%\uff0cML \u9a71\u52a8\u6a21\u578b\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e 3.5%\uff0c\u8d85 10% \u8bef\u5dee\u8303\u56f4\u7684\u70b9\u4e0d\u8d85\u8fc7\u4e00\u4e2a\u3002", "conclusion": "\u6df7\u5408 ML \u6a21\u578b\u5728\u9884\u6d4b\u73af\u5f62\u51e0\u4f55\u7ed3\u6784\u7684 CHF \u4e0a\u663e\u8457\u4f18\u4e8e\u7ecf\u9a8c\u5173\u8054\u6a21\u578b\u3002"}}
{"id": "2507.14746", "pdf": "https://arxiv.org/pdf/2507.14746", "abs": "https://arxiv.org/abs/2507.14746", "authors": ["Bach Do", "Nafeezat A. Ajenifuja", "Taiwo A. Adebiyi", "Ruda Zhang"], "title": "Sampling from Gaussian Processes: A Tutorial and Applications in Global Sensitivity Analysis and Optimization", "categories": ["cs.LG", "math.OC", "stat.AP", "stat.ML"], "comment": null, "summary": "High-fidelity simulations and physical experiments are essential for\nengineering analysis and design. However, their high cost often limits their\napplications in two critical tasks: global sensitivity analysis (GSA) and\noptimization. This limitation motivates the common use of Gaussian processes\n(GPs) as proxy regression models to provide uncertainty-aware predictions based\non a limited number of high-quality observations. GPs naturally enable\nefficient sampling strategies that support informed decision-making under\nuncertainty by extracting information from a subset of possible functions for\nthe model of interest. Despite their popularity in machine learning and\nstatistics communities, sampling from GPs has received little attention in the\ncommunity of engineering optimization. In this paper, we present the\nformulation and detailed implementation of two notable sampling methods --\nrandom Fourier features and pathwise conditioning -- for generating posterior\nsamples from GPs. Alternative approaches are briefly described. Importantly, we\ndetail how the generated samples can be applied in GSA, single-objective\noptimization, and multi-objective optimization. We show successful applications\nof these sampling methods through a series of numerical examples.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ece\u9ad8\u65af\u8fc7\u7a0b\u751f\u6210\u540e\u9a8c\u6837\u672c\u7684\u4e24\u79cd\u62bd\u6837\u65b9\u6cd5\uff0c\u9610\u8ff0\u5176\u5728\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u548c\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u9ad8\u4fdd\u771f\u6a21\u62df\u548c\u7269\u7406\u5b9e\u9a8c\u6210\u672c\u9ad8\uff0c\u9650\u5236\u5176\u5728\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u548c\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u9ad8\u65af\u8fc7\u7a0b\u4f5c\u4e3a\u4ee3\u7406\u56de\u5f52\u6a21\u578b\u53ef\u57fa\u4e8e\u6709\u9650\u9ad8\u8d28\u91cf\u89c2\u6d4b\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9884\u6d4b\uff0c\u4f46\u5728\u5de5\u7a0b\u4f18\u5316\u9886\u57df\u62bd\u6837\u53d7\u5173\u6ce8\u5c11\u3002", "method": "\u63d0\u51fa\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u548c\u8def\u5f84\u6761\u4ef6\u4e24\u79cd\u62bd\u6837\u65b9\u6cd5\u4ece\u9ad8\u65af\u8fc7\u7a0b\u751f\u6210\u540e\u9a8c\u6837\u672c\uff0c\u7b80\u8ff0\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5e76\u8bf4\u660e\u751f\u6210\u6837\u672c\u5728\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u3001\u5355\u76ee\u6807\u4f18\u5316\u548c\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u6570\u503c\u793a\u4f8b\u5c55\u793a\u4e86\u62bd\u6837\u65b9\u6cd5\u7684\u6210\u529f\u5e94\u7528\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u62bd\u6837\u65b9\u6cd5\u53ef\u6709\u6548\u5e94\u7528\u4e8e\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u548c\u4f18\u5316\u7b49\u5de5\u7a0b\u4efb\u52a1\u3002"}}
{"id": "2507.14906", "pdf": "https://arxiv.org/pdf/2507.14906", "abs": "https://arxiv.org/abs/2507.14906", "authors": ["Xiao Yang", "Juxi Leitner", "Michael Burke"], "title": "Feedback-Induced Performance Decline in LLM-Based Decision-Making", "categories": ["cs.AI"], "comment": null, "summary": "The ability of Large Language Models (LLMs) to extract context from natural\nlanguage problem descriptions naturally raises questions about their\nsuitability in autonomous decision-making settings. This paper studies the\nbehaviour of these models within a Markov Decision Process (MDPs). While\ntraditional reinforcement learning (RL) strategies commonly employed in this\nsetting rely on iterative exploration, LLMs, pre-trained on diverse datasets,\noffer the capability to leverage prior knowledge for faster adaptation. We\ninvestigate online structured prompting strategies in sequential decision\nmaking tasks, comparing the zero-shot performance of LLM-based approaches to\nthat of classical RL methods. Our findings reveal that although LLMs\ndemonstrate improved initial performance in simpler environments, they struggle\nwith planning and reasoning in complex scenarios without fine-tuning or\nadditional guidance. Our results show that feedback mechanisms, intended to\nimprove decision-making, often introduce confusion, leading to diminished\nperformance in intricate environments. These insights underscore the need for\nfurther exploration into hybrid strategies, fine-tuning, and advanced memory\nintegration to enhance LLM-based decision-making capabilities.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDPs\uff09\u4e2d\u7684\u884c\u4e3a\uff0c\u5bf9\u6bd4\u5176\u4e0e\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u53d1\u73b0LLMs\u5728\u7b80\u5355\u73af\u5883\u521d\u59cb\u8868\u73b0\u597d\uff0c\u4f46\u590d\u6742\u573a\u666f\u9700\u6539\u8fdb\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u4e3b\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u7814\u7a76\u987a\u5e8f\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u5728\u7ebf\u7ed3\u6784\u5316\u63d0\u793a\u7b56\u7565\uff0c\u5bf9\u6bd4LLM\u65b9\u6cd5\u548c\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002", "result": "LLMs\u5728\u7b80\u5355\u73af\u5883\u521d\u59cb\u6027\u80fd\u597d\uff0c\u4f46\u590d\u6742\u573a\u666f\u89c4\u5212\u63a8\u7406\u80fd\u529b\u5f31\uff0c\u53cd\u9988\u673a\u5236\u4f1a\u964d\u4f4e\u590d\u6742\u73af\u5883\u6027\u80fd\u3002", "conclusion": "\u9700\u8fdb\u4e00\u6b65\u63a2\u7d22\u6df7\u5408\u7b56\u7565\u3001\u5fae\u8c03\u53ca\u9ad8\u7ea7\u8bb0\u5fc6\u96c6\u6210\u4ee5\u63d0\u5347LLM\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2507.15226", "pdf": "https://arxiv.org/pdf/2507.15226", "abs": "https://arxiv.org/abs/2507.15226", "authors": ["Changguo Jia", "Yi Zhan", "Tianqi Zhao", "Hengzhi Ye", "Minghui Zhou"], "title": "Code Clone Detection via an AlphaFold-Inspired Framework", "categories": ["cs.SE"], "comment": null, "summary": "Code clone detection, which aims to identify functionally equivalent code\nfragments, plays a critical role in software maintenance and vulnerability\nanalysis. Substantial methods have been proposed to detect code clones, but\nthey fall short in capturing code semantics or relying on language-specific\nanalyzers. Inspired by the remarkable success of AlphaFold in predicting\nthree-dimensional protein structures from protein sequences, in this paper, we\nleverage AlphaFold for code clone detection based on the insight that protein\nsequences and token sequences share a common linear sequential structure. In\nparticular, we propose AlphaCC, which represents code fragments as token\nsequences to ensure multi-language applicability and adapts AlphaFold's\nsequence-to-structure modeling capability to infer code semantics. The pipeline\nof AlphaCC goes through three steps. First, AlphaCC transforms each input code\nfragment into a token sequence and, motivated by AlphaFold's use of multiple\nsequence alignment (MSA) to enhance contextual understanding, constructs an MSA\nfrom lexically similar token sequences. Second, AlphaCC adopts a modified\nattention-based encoder based on AlphaFold to model dependencies within and\nacross token sequences. Finally, unlike AlphaFold's protein structure\nprediction task, AlphaCC computes similarity scores between token sequences\nthrough a late interaction strategy and performs binary classification to\ndetermine code clone pairs. Comprehensive evaluations on three language-diverse\ndatasets demonstrate AlphaCC's applicability across multiple programming\nlanguages. On two semantic clone detection datasets, it consistently\noutperforms all baselines, showing strong semantic understanding. Moreover,\nAlphaCC maintains competitive efficiency, enabling practical usage in\nlarge-scale clone detection tasks.", "AI": {"tldr": "\u672c\u6587\u53d7AlphaFold\u542f\u53d1\u63d0\u51faAlphaCC\u7528\u4e8e\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\uff0c\u5728\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u65b9\u6cd5\u5728\u6355\u83b7\u4ee3\u7801\u8bed\u4e49\u6216\u8bed\u8a00\u901a\u7528\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u53d7AlphaFold\u6210\u529f\u542f\u53d1\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u63d0\u51faAlphaCC\uff0c\u5c06\u4ee3\u7801\u7247\u6bb5\u8868\u793a\u4e3a\u4ee4\u724c\u5e8f\u5217\uff0c\u6784\u5efaMSA\uff0c\u91c7\u7528\u6539\u8fdb\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u540e\u671f\u4ea4\u4e92\u7b56\u7565\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u5e76\u5206\u7c7b\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86AlphaCC\u8de8\u8bed\u8a00\u7684\u9002\u7528\u6027\uff0c\u5728\u4e24\u4e2a\u8bed\u4e49\u514b\u9686\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u6240\u6709\u57fa\u7ebf\uff0c\u4e14\u6548\u7387\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "AlphaCC\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4efb\u52a1\uff0c\u6709\u8f83\u5f3a\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.14344", "pdf": "https://arxiv.org/pdf/2507.14344", "abs": "https://arxiv.org/abs/2507.14344", "authors": ["Daniel Fein", "Gabriela Aranguiz-Dias"], "title": "Influence Functions for Preference Dataset Pruning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Language models are commonly fine-tuned via reinforcement learning to alter\ntheir behavior or elicit new capabilities. Datasets used for these purposes,\nand particularly human preference datasets, are often noisy. The relatively\nsmall size post-training datasets, combined with parameter-efficient\nfine-tuning methods, enable the use of influence functions approximations to\ndetect and prune training examples that are harmful to performance on a\nvalidation set. In this work, we adapt the TL;DR dataset for reward model\ntraining to demonstrate how conjugate-gradient approximated influence functions\ncan be used to filter datasets. In our experiments, influence function\nfiltering yields a small retraining accuracy uplift of 1.5% after removing 10%\nof training examples. We also show that gradient similarity outperforms\ninfluence functions for detecting helpful training examples. This suggests that\nlocal curvature is important for detecting harmful training examples, but less\nso for identifying helpful examples.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7528\u5f71\u54cd\u51fd\u6570\u8fd1\u4f3c\u6cd5\u8fc7\u6ee4\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660e\u79fb\u966410%\u8bad\u7ec3\u6837\u672c\u540e\u91cd\u8bad\u7ec3\u51c6\u786e\u7387\u6709\u5c0f\u63d0\u5347\uff0c\u4e14\u68af\u5ea6\u76f8\u4f3c\u5ea6\u68c0\u6d4b\u6709\u7528\u6837\u672c\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u6240\u7528\u6570\u636e\u96c6\u6709\u566a\u58f0\uff0c\u5e0c\u671b\u627e\u5230\u65b9\u6cd5\u68c0\u6d4b\u5e76\u5254\u9664\u5bf9\u9a8c\u8bc1\u96c6\u6027\u80fd\u6709\u5bb3\u7684\u8bad\u7ec3\u6837\u672c\u3002", "method": "\u91c7\u7528\u5171\u8f6d\u68af\u5ea6\u8fd1\u4f3c\u5f71\u54cd\u51fd\u6570\u8fc7\u6ee4TL;DR\u6570\u636e\u96c6\u3002", "result": "\u79fb\u966410%\u8bad\u7ec3\u6837\u672c\u540e\uff0c\u91cd\u8bad\u7ec3\u51c6\u786e\u7387\u63d0\u53471.5%\uff1b\u68af\u5ea6\u76f8\u4f3c\u5ea6\u68c0\u6d4b\u6709\u7528\u6837\u672c\u8868\u73b0\u4f18\u4e8e\u5f71\u54cd\u51fd\u6570\u3002", "conclusion": "\u5c40\u90e8\u66f2\u7387\u5bf9\u68c0\u6d4b\u6709\u5bb3\u6837\u672c\u91cd\u8981\uff0c\u4f46\u5bf9\u8bc6\u522b\u6709\u7528\u6837\u672c\u4f5c\u7528\u8f83\u5c0f\u3002"}}
{"id": "2507.14748", "pdf": "https://arxiv.org/pdf/2507.14748", "abs": "https://arxiv.org/abs/2507.14748", "authors": ["Patrik Reizinger", "B\u00e1lint Mucs\u00e1nyi", "Siyuan Guo", "Benjamin Eysenbach", "Bernhard Sch\u00f6lkopf", "Wieland Brendel"], "title": "Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "16 pages, 7 figures", "summary": "Self-supervised feature learning and pretraining methods in reinforcement\nlearning (RL) often rely on information-theoretic principles, termed mutual\ninformation skill learning (MISL). These methods aim to learn a representation\nof the environment while also incentivizing exploration thereof. However, the\nrole of the representation and mutual information parametrization in MISL is\nnot yet well understood theoretically. Our work investigates MISL through the\nlens of identifiable representation learning by focusing on the Contrastive\nSuccessor Features (CSF) method. We prove that CSF can provably recover the\nenvironment's ground-truth features up to a linear transformation due to the\ninner product parametrization of the features and skill diversity in a\ndiscriminative sense. This first identifiability guarantee for representation\nlearning in RL also helps explain the implications of different mutual\ninformation objectives and the downsides of entropy regularizers. We\nempirically validate our claims in MuJoCo and DeepMind Control and show how CSF\nprovably recovers the ground-truth features both from states and pixels.", "AI": {"tldr": "\u672c\u6587\u4ece\u53ef\u8bc6\u522b\u8868\u793a\u5b66\u4e60\u7684\u89d2\u5ea6\u7814\u7a76MISL\uff0c\u4ee5CSF\u65b9\u6cd5\u4e3a\u4f8b\u8bc1\u660e\u5176\u80fd\u6062\u590d\u73af\u5883\u771f\u5b9e\u7279\u5f81\uff0c\u8fd8\u89e3\u91ca\u4e86\u4e92\u4fe1\u606f\u76ee\u6807\u7684\u5f71\u54cd\u548c\u71b5\u6b63\u5219\u5316\u5668\u7684\u7f3a\u70b9\uff0c\u5e76\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524dMISL\u4e2d\u8868\u793a\u548c\u4e92\u4fe1\u606f\u53c2\u6570\u5316\u7684\u4f5c\u7528\u5728\u7406\u8bba\u4e0a\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u53ef\u8bc6\u522b\u8868\u793a\u5b66\u4e60\u7684\u89c6\u89d2\u7814\u7a76MISL\uff0c\u805a\u7126\u4e8eContrastive Successor Features (CSF)\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u8bc1\u660eCSF\u80fd\u5728\u4e00\u5b9a\u7ebf\u6027\u53d8\u6362\u4e0b\u6062\u590d\u73af\u5883\u7684\u771f\u5b9e\u7279\u5f81\uff0c\u5728MuJoCo\u548cDeepMind Control\u4e2d\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u76f8\u5173\u8bba\u65ad\u3002", "conclusion": "\u9996\u6b21\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u53ef\u8bc6\u522b\u6027\u4fdd\u8bc1\uff0c\u6709\u52a9\u4e8e\u89e3\u91ca\u4e0d\u540c\u4e92\u4fe1\u606f\u76ee\u6807\u7684\u5f71\u54cd\u548c\u71b5\u6b63\u5219\u5316\u5668\u7684\u7f3a\u70b9\u3002"}}
{"id": "2507.14909", "pdf": "https://arxiv.org/pdf/2507.14909", "abs": "https://arxiv.org/abs/2507.14909", "authors": ["Elio Grande"], "title": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "The Endless Tuning is a design method for a reliable deployment of artificial\nintelligence based on a double mirroring process, which pursues both the goals\nof avoiding human replacement and filling the so-called responsibility gap\n(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the\nrelational approach urged therein, it was then actualized in a protocol,\nimplemented in three prototypical applications regarding decision-making\nprocesses (respectively: loan granting, pneumonia diagnosis, and art style\nrecognition) and tested with such as many domain experts. Step by step\nillustrating the protocol, giving insights concretely showing a different voice\n(Gilligan 1993) in the ethics of artificial intelligence, a philosophical\naccount of technical choices (e.g., a reversed and hermeneutic deployment of\nXAI algorithms) will be provided in the present study together with the results\nof the experiments, focusing on user experience rather than statistical\naccuracy. Even thoroughly employing deep learning models, full control was\nperceived by the interviewees in the decision-making setting, while it appeared\nthat a bridge can be built between accountability and liability in case of\ndamage.", "AI": {"tldr": "\u4ecb\u7ecdEndless Tuning\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5728\u4e09\u4e2a\u539f\u578b\u5e94\u7528\u4e2d\u6d4b\u8bd5\uff0c\u7ed9\u51fa\u54f2\u5b66\u89e3\u91ca\u548c\u5b9e\u9a8c\u7ed3\u679c\uff0c\u805a\u7126\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u53ef\u9760\u90e8\u7f72\uff0c\u907f\u514d\u4eba\u7c7b\u88ab\u66ff\u4ee3\uff0c\u586b\u8865\u8d23\u4efb\u7f3a\u53e3\u3002", "method": "\u91c7\u7528\u53cc\u955c\u50cf\u8fc7\u7a0b\u7684Endless Tuning\u65b9\u6cd5\uff0c\u5728\u8d37\u6b3e\u53d1\u653e\u3001\u80ba\u708e\u8bca\u65ad\u548c\u827a\u672f\u98ce\u683c\u8bc6\u522b\u4e09\u4e2a\u539f\u578b\u5e94\u7528\u4e2d\u5b9e\u65bd\u534f\u8bae\u5e76\u6d4b\u8bd5\u3002", "result": "\u53d7\u8bbf\u8005\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u6709\u5b8c\u5168\u63a7\u5236\u611f\uff0c\u53ef\u5728\u635f\u5bb3\u60c5\u51b5\u4e0b\u5efa\u7acb\u95ee\u8d23\u4e0e\u8d23\u4efb\u4e4b\u95f4\u7684\u6865\u6881\u3002", "conclusion": "\u901a\u8fc7Endless Tuning\u65b9\u6cd5\u80fd\u5728\u4eba\u5de5\u667a\u80fd\u51b3\u7b56\u4e2d\u517c\u987e\u7528\u6237\u4f53\u9a8c\uff0c\u5904\u7406\u597d\u95ee\u8d23\u548c\u8d23\u4efb\u95ee\u9898\u3002"}}
{"id": "2507.15241", "pdf": "https://arxiv.org/pdf/2507.15241", "abs": "https://arxiv.org/abs/2507.15241", "authors": ["Vikram Nitin", "Baishakhi Ray", "Roshanak Zilouchian Moghaddam"], "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "categories": ["cs.SE"], "comment": null, "summary": "Despite the critical threat posed by software security vulnerabilities,\nreports are often incomplete, lacking the proof-of-vulnerability (PoV) tests\nneeded to validate fixes and prevent regressions. These tests are crucial not\nonly for ensuring patches work, but also for helping developers understand how\nvulnerabilities can be exploited. Generating PoV tests is a challenging\nproblem, requiring reasoning about the flow of control and data through deeply\nnested levels of a program.\n  We present FaultLine, an LLM agent workflow that uses a set of carefully\ndesigned reasoning steps, inspired by aspects of traditional static and dynamic\nprogram analysis, to automatically generate PoV test cases. Given a software\nproject with an accompanying vulnerability report, FaultLine 1) traces the flow\nof an input from an externally accessible API (\"source\") to the \"sink\"\ncorresponding to the vulnerability, 2) reasons about the conditions that an\ninput must satisfy in order to traverse the branch conditions encountered along\nthe flow, and 3) uses this reasoning to generate a PoV test case in a\nfeedback-driven loop. FaultLine does not use language-specific static or\ndynamic analysis components, which enables it to be used across programming\nlanguages.\n  To evaluate FaultLine, we collate a challenging multi-lingual dataset of 100\nknown vulnerabilities in Java, C and C++ projects. On this dataset, FaultLine\nis able to generate PoV tests for 16 projects, compared to just 9 for CodeAct\n2.1, a popular state-of-the-art open-source agentic framework. Thus, FaultLine\nrepresents a 77% relative improvement over the state of the art. Our findings\nsuggest that hierarchical reasoning can enhance the performance of LLM agents\non PoV test generation, but the problem in general remains challenging. We make\nour code and dataset publicly available in the hope that it will spur further\nresearch in this area.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFaultLine\u5de5\u4f5c\u6d41\u81ea\u52a8\u751f\u6210PoV\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5728\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u6bd4CodeAct 2.1\u8868\u73b0\u597d\uff0c\u8868\u660e\u5206\u5c42\u63a8\u7406\u53ef\u63d0\u5347LLM\u4ee3\u7406\u6027\u80fd\uff0c\u4f46\u95ee\u9898\u4ecd\u5177\u6311\u6218\u3002", "motivation": "\u8f6f\u4ef6\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u5e38\u7f3a\u5c11PoV\u6d4b\u8bd5\uff0c\u751f\u6210PoV\u6d4b\u8bd5\u6709\u6311\u6218\uff0c\u9700\u8981\u5bf9\u7a0b\u5e8f\u63a7\u5236\u548c\u6570\u636e\u6d41\u8fdb\u884c\u63a8\u7406\u3002", "method": "\u63d0\u51faFaultLine\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u8ffd\u8e2a\u8f93\u5165\u6d41\u3001\u63a8\u7406\u8f93\u5165\u6761\u4ef6\u3001\u53cd\u9988\u9a71\u52a8\u5faa\u73af\u751f\u6210PoV\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4e0d\u4f7f\u7528\u7279\u5b9a\u8bed\u8a00\u5206\u6790\u7ec4\u4ef6\u3002", "result": "\u5728\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\uff0cFaultLine\u4e3a16\u4e2a\u9879\u76ee\u751f\u6210PoV\u6d4b\u8bd5\uff0c\u6bd4CodeAct 2.1\u591a\uff0c\u670977%\u7684\u76f8\u5bf9\u63d0\u5347\u3002", "conclusion": "\u5206\u5c42\u63a8\u7406\u53ef\u63d0\u5347LLM\u4ee3\u7406\u5728PoV\u6d4b\u8bd5\u751f\u6210\u4e0a\u7684\u6027\u80fd\uff0c\u4f46\u95ee\u9898\u603b\u4f53\u4ecd\u5177\u6311\u6218\uff0c\u516c\u5f00\u4ee3\u7801\u548c\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u7814\u7a76\u3002"}}
{"id": "2507.14353", "pdf": "https://arxiv.org/pdf/2507.14353", "abs": "https://arxiv.org/abs/2507.14353", "authors": ["Harsh Nilesh Pathak", "Randy Paffenroth"], "title": "Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Parameter efficient fine tuning (PEFT) is a versatile and extensible approach\nfor adapting a Large Language Model (LLM) for newer tasks. One of the most\nprominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on\nadjusting the attention weight matrices within individual decoder blocks of a\nGenerative Pre trained Transformer (GPT2). In contrast, we introduce Solo\nConnection a novel method that adapts the representation at the decoder-block\nlevel rather than modifying individual weight matrices. Not only does Solo\nConnection outperform LoRA on E2E natural language generation benchmarks, but\nit also reduces the number of trainable parameters by 59% relative to LoRA and\nby more than 99% compared to full fine-tuning of GPT2, an early version of\nLarge Language Models (LLMs). Solo Connection is also motivated by homotopy\ntheory: we introduce a trainable linear transformation that gradually\ninterpolates between a zero vector and the task-specific representation,\nenabling smooth and stable adaptation over time. While skip connections in the\noriginal 12 layer GPT2 are typically confined to individual decoder blocks,\nsubsequent GPT2 variants scale up to 48 layers, and even larger language models\ncan include 128 or more decoder blocks. These expanded architectures underscore\nthe need to revisit how skip connections are employed during fine-tuning. This\npaper focuses on long skip connections that link outputs of different decoder\nblocks, potentially enhancing the model's ability to adapt to new tasks while\nleveraging pre-trained knowledge.", "AI": {"tldr": "\u63d0\u51faSolo Connection\u65b9\u6cd5\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\u57fa\u51c6\u4e0a\u4f18\u4e8eLoRA\uff0c\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u53d7\u540c\u4f26\u7406\u8bba\u542f\u53d1\uff0c\u5173\u6ce8\u957f\u8df3\u8dc3\u8fde\u63a5\u4ee5\u63d0\u5347\u6a21\u578b\u9002\u5e94\u65b0\u4efb\u52a1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709PEFT\u65b9\u6cd5LoRA\u4e3b\u8981\u8c03\u6574\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\uff0c\u4e14\u968f\u7740\u6a21\u578b\u67b6\u6784\u6269\u5c55\uff0c\u9700\u91cd\u65b0\u5ba1\u89c6\u5fae\u8c03\u65f6\u8df3\u8dc3\u8fde\u63a5\u7684\u4f7f\u7528\uff0c\u6545\u63d0\u51fa\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165Solo Connection\uff0c\u5728\u89e3\u7801\u5668\u5757\u7ea7\u522b\u8c03\u6574\u8868\u793a\uff0c\u5f15\u5165\u53ef\u8bad\u7ec3\u7ebf\u6027\u53d8\u6362\u5728\u96f6\u5411\u91cf\u548c\u7279\u5b9a\u4efb\u52a1\u8868\u793a\u95f4\u63d2\u503c\uff0c\u5173\u6ce8\u957f\u8df3\u8dc3\u8fde\u63a5\u3002", "result": "Solo Connection\u5728E2E\u81ea\u7136\u8bed\u8a00\u751f\u6210\u57fa\u51c6\u4e0a\u4f18\u4e8eLoRA\uff0c\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u76f8\u5bf9LoRA\u51cf\u5c1159%\uff0c\u76f8\u5bf9GPT2\u5168\u5fae\u8c03\u51cf\u5c11\u8d8599%\u3002", "conclusion": "Solo Connection\u662f\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u63d0\u5347\u6a21\u578b\u5728\u65b0\u4efb\u52a1\u4e0a\u7684\u9002\u5e94\u80fd\u529b\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u77e5\u8bc6\u3002"}}
{"id": "2507.14795", "pdf": "https://arxiv.org/pdf/2507.14795", "abs": "https://arxiv.org/abs/2507.14795", "authors": ["Muhan Guan", "Farhad Farokhi", "Jingge Zhu"], "title": "A DPI-PAC-Bayesian Framework for Generalization Bounds", "categories": ["cs.IT", "math.IT", "stat.ML"], "comment": "7 pages, 1 figures", "summary": "We develop a unified Data Processing Inequality PAC-Bayesian framework --\nabbreviated DPI-PAC-Bayesian -- for deriving generalization error bounds in the\nsupervised learning setting. By embedding the Data Processing Inequality (DPI)\ninto the change-of-measure technique, we obtain explicit bounds on the binary\nKullback-Leibler generalization gap for both R\\'enyi divergence and any\n$f$-divergence measured between a data-independent prior distribution and an\nalgorithm-dependent posterior distribution. We present three bounds derived\nunder our framework using R\\'enyi, Hellinger \\(p\\) and Chi-Squared divergences.\nAdditionally, our framework also demonstrates a close connection with other\nwell-known bounds. When the prior distribution is chosen to be uniform, our\nbounds recover the classical Occam's Razor bound and, crucially, eliminate the\nextraneous \\(\\log(2\\sqrt{n})/n\\) slack present in the PAC-Bayes bound, thereby\nachieving tighter results. The framework thus bridges data-processing and\nPAC-Bayesian perspectives, providing a flexible, information-theoretic tool to\nconstruct generalization guarantees.", "AI": {"tldr": "\u5f00\u53d1DPI - PAC - Bayesian\u6846\u67b6\u63a8\u5bfc\u76d1\u7763\u5b66\u4e60\u6cdb\u5316\u8bef\u5dee\u754c\uff0c\u7ed9\u51fa\u4e09\u79cd\u754c\uff0c\u4e0e\u5176\u4ed6\u754c\u6709\u5173\u8054\uff0c\u9009\u5747\u5300\u5148\u9a8c\u5206\u5e03\u65f6\u7ed3\u679c\u66f4\u4f18\u3002", "motivation": "\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u63a8\u5bfc\u6cdb\u5316\u8bef\u5dee\u754c\u3002", "method": "\u5c06\u6570\u636e\u5904\u7406\u4e0d\u7b49\u5f0f\u5d4c\u5165\u6d4b\u5ea6\u53d8\u6362\u6280\u672f\uff0c\u7528R\u00e9nyi\u3001Hellinger p\u548cChi - Squared\u6563\u5ea6\u63a8\u5bfc\u754c\u3002", "result": "\u5f97\u5230\u4e8c\u5143Kullback - Leibler\u6cdb\u5316\u5dee\u8ddd\u7684\u663e\u5f0f\u754c\uff0c\u6240\u9009\u5747\u5300\u5148\u9a8c\u5206\u5e03\u65f6\u80fd\u6d88\u9664PAC - Bayes\u754c\u4e2d\u7684\u591a\u4f59\u677e\u5f1b\u9879\u3002", "conclusion": "\u8be5\u6846\u67b6\u8fde\u63a5\u6570\u636e\u5904\u7406\u548cPAC - Bayesian\u89c2\u70b9\uff0c\u662f\u6784\u5efa\u6cdb\u5316\u4fdd\u8bc1\u7684\u7075\u6d3b\u4fe1\u606f\u8bba\u5de5\u5177\u3002"}}
{"id": "2507.14912", "pdf": "https://arxiv.org/pdf/2507.14912", "abs": "https://arxiv.org/abs/2507.14912", "authors": ["Ruhul Amin Khalil", "Kashif Ahmad", "Hazrat Ali"], "title": "Redefining Elderly Care with Agentic AI: Challenges and Opportunities", "categories": ["cs.AI"], "comment": null, "summary": "The global ageing population necessitates new and emerging strategies for\ncaring for older adults. In this article, we explore the potential for\ntransformation in elderly care through Agentic Artificial Intelligence (AI),\npowered by Large Language Models (LLMs). We discuss the proactive and\nautonomous decision-making facilitated by Agentic AI in elderly care.\nPersonalized tracking of health, cognitive care, and environmental management,\nall aimed at enhancing independence and high-level living for older adults,\nrepresents important areas of application. With a potential for significant\ntransformation of elderly care, Agentic AI also raises profound concerns about\ndata privacy and security, decision independence, and access. We share key\ninsights to emphasize the need for ethical safeguards, privacy protections, and\ntransparent decision-making. Our goal in this article is to provide a balanced\ndiscussion of both the potential and the challenges associated with Agentic AI,\nand to provide insights into its responsible use in elderly care, to bring\nAgentic AI into harmony with the requirements and vulnerabilities specific to\nthe elderly. Finally, we identify the priorities for the academic research\ncommunities, to achieve human-centered advancements and integration of Agentic\nAI in elderly care. To the best of our knowledge, this is no existing study\nthat reviews the role of Agentic AI in elderly care. Hence, we address the\nliterature gap by analyzing the unique capabilities, applications, and\nlimitations of LLM-based Agentic AI in elderly care. We also provide a\ncompanion interactive dashboard at https://hazratali.github.io/agenticai/.", "AI": {"tldr": "\u63a2\u8ba8\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u52a8\u4eba\u5de5\u667a\u80fd\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u7684\u6f5c\u529b\u4e0e\u6311\u6218\uff0c\u5206\u6790\u5176\u72ec\u7279\u80fd\u529b\u3001\u5e94\u7528\u548c\u5c40\u9650\uff0c\u63d0\u51fa\u8d1f\u8d23\u4efb\u4f7f\u7528\u5efa\u8bae\u5e76\u6307\u51fa\u7814\u7a76\u4f18\u5148\u7ea7\uff0c\u8fd8\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u4eea\u8868\u76d8\u3002", "motivation": "\u5168\u7403\u4eba\u53e3\u8001\u9f84\u5316\u9700\u8981\u65b0\u7684\u8001\u5e74\u62a4\u7406\u7b56\u7565\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u80fd\u52a8\u4eba\u5de5\u667a\u80fd\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u4f5c\u7528\u7684\u7814\u7a76\u3002", "method": "\u5206\u6790\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u52a8\u4eba\u5de5\u667a\u80fd\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u7684\u80fd\u529b\u3001\u5e94\u7528\u548c\u5c40\u9650\u3002", "result": "\u80fd\u52a8\u4eba\u5de5\u667a\u80fd\u6709\u6f5c\u529b\u53d8\u9769\u8001\u5e74\u62a4\u7406\uff0c\u4f46\u5f15\u53d1\u6570\u636e\u9690\u79c1\u5b89\u5168\u3001\u51b3\u7b56\u72ec\u7acb\u6027\u548c\u53ef\u53ca\u6027\u7b49\u62c5\u5fe7\u3002", "conclusion": "\u9700\u8fdb\u884c\u5e73\u8861\u8ba8\u8bba\uff0c\u5f3a\u8c03\u4f26\u7406\u4fdd\u969c\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u900f\u660e\u51b3\u7b56\uff0c\u4ee5\u5b9e\u73b0\u4ee5\u4eba\u7c7b\u4e3a\u4e2d\u5fc3\u7684\u80fd\u52a8\u4eba\u5de5\u667a\u80fd\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u7684\u53d1\u5c55\u548c\u6574\u5408\u3002"}}
{"id": "2507.15251", "pdf": "https://arxiv.org/pdf/2507.15251", "abs": "https://arxiv.org/abs/2507.15251", "authors": ["Boyang Yang", "Luyao Ren", "Xin Yin", "Jiadong Ren", "Haoye Tian", "Shunfu Jin"], "title": "Input Reduction Enhanced LLM-based Program Repair", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have shown great potential in Automated Program\nRepair (APR). Test inputs, being crucial for reasoning the root cause of\nfailures, are always included in the prompt for LLM-based APR. Unfortunately,\nLLMs struggle to retain key information in long prompts. When the test inputs\nare extensive in the prompt, this may trigger the \"lost-in-the-middle\" issue,\ncompromising repair performance. To address this, we propose ReduceFix, an\nLLM-based APR approach with a built-in component that automatically reduces\ntest inputs while retaining their failure-inducing behavior. ReduceFix prompts\nan LLM to generate a reducer that minimizes failure-inducing test inputs\nwithout human effort, and then feeds the reduced failure-inducing inputs to\nguide patch generation.\n  For targeted evaluation, we constructed LFTBench, the first long-input APR\nbenchmark with 200 real bugs from 20 programming tasks, each paired with a\nfailure-inducing input whose median size is 1 MB. On this benchmark, ReduceFix\nshrinks inputs by 89.1% on average and improves overall pass@10 by up to 53.8%\nrelative to a prompt that includes the original test, and by 17.6% compared\nwith omitting the test entirely. Adding the same reduction step to ChatRepair\nincreases its fix rate by 21.3% without other changes. Ablation studies further\nhighlight the impact of input length and compressed failure information on\nrepair success. These results underscore that automatically reducing failing\ninputs is a practical and powerful complement to LLM-based APR, significantly\nimproving its scalability and effectiveness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faReduceFix\u65b9\u6cd5\u89e3\u51b3LLM\u5728APR\u4e2d\u56e0\u957f\u6d4b\u8bd5\u8f93\u5165\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u5728LFTBench\u57fa\u51c6\u4e0a\u6548\u679c\u663e\u8457\uff0c\u8bc1\u660e\u81ea\u52a8\u51cf\u5c11\u8f93\u5165\u80fd\u63d0\u5347APR\u6027\u80fd\u3002", "motivation": "LLM\u5728\u57fa\u4e8eAPR\u65f6\u56e0\u957f\u63d0\u793a\u4e2d\u96be\u4ee5\u4fdd\u7559\u5173\u952e\u4fe1\u606f\uff0c\u5b58\u5728\u201clost - in - the - middle\u201d\u95ee\u9898\uff0c\u5f71\u54cd\u4fee\u590d\u6027\u80fd\u3002", "method": "\u63d0\u51faReduceFix\u65b9\u6cd5\uff0c\u5185\u7f6e\u7ec4\u4ef6\u81ea\u52a8\u51cf\u5c11\u6d4b\u8bd5\u8f93\u5165\u5e76\u4fdd\u7559\u6545\u969c\u8bf1\u5bfc\u884c\u4e3a\uff0c\u5229\u7528LLM\u751f\u6210\u7f29\u51cf\u5668\uff0c\u7528\u7f29\u51cf\u540e\u7684\u8f93\u5165\u6307\u5bfc\u8865\u4e01\u751f\u6210\uff1b\u6784\u5efaLFTBench\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "ReduceFix\u5e73\u5747\u7f29\u5c0f\u8f93\u516589.1%\uff0c\u76f8\u5bf9\u539f\u59cb\u6d4b\u8bd5\u63d0\u793a\u63d0\u9ad8pass@10\u8fbe53.8%\uff0c\u6bd4\u5b8c\u5168\u7701\u7565\u6d4b\u8bd5\u63d0\u9ad817.6%\uff1b\u7ed9ChatRepair\u6dfb\u52a0\u76f8\u540c\u7f29\u51cf\u6b65\u9aa4\uff0c\u4fee\u590d\u7387\u63d0\u9ad821.3%\u3002", "conclusion": "\u81ea\u52a8\u51cf\u5c11\u5931\u8d25\u8f93\u5165\u662f\u57fa\u4e8eLLM\u7684APR\u5b9e\u7528\u4e14\u5f3a\u5927\u7684\u8865\u5145\uff0c\u663e\u8457\u63d0\u5347\u5176\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.14387", "pdf": "https://arxiv.org/pdf/2507.14387", "abs": "https://arxiv.org/abs/2507.14387", "authors": ["Arun Vignesh Malarkkan", "Dongjie Wang", "Haoyue Bai", "Yanjie Fu"], "title": "Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 5 figures, 3 Tables, under review in IEEE Transactions on\n  Big Data", "summary": "The escalating threat of cyberattacks on real-time critical infrastructures\nposes serious risks to public safety, demanding detection methods that\neffectively capture complex system interdependencies and adapt to evolving\nattack patterns. Traditional real-time anomaly detection techniques often\nsuffer from excessive false positives due to their statistical sensitivity to\nhigh data variance and class imbalance. To address these limitations, recent\nresearch has explored modeling causal relationships among system components.\nHowever, prior work mainly focuses on offline causal graph-based approaches\nthat require static historical data and fail to generalize to real-time\nsettings. These methods are fundamentally constrained by: (1) their inability\nto adapt to dynamic shifts in data distribution without retraining, and (2) the\nrisk of catastrophic forgetting when lacking timely supervision in live\nsystems. To overcome these challenges, we propose INCADET, a novel framework\nfor incremental causal graph learning tailored to real-time cyberattack\ndetection. INCADET dynamically captures evolving system behavior by\nincrementally updating causal graphs across streaming time windows. The\nframework comprises three modules: 1) Early Symptom Detection: Detects\ntransitions in system status using divergence in edge-weight distributions\nacross sequential causal graphs. 2) Incremental Causal Graph Learning:\nLeverages experience replay and edge reinforcement to continually refine causal\nstructures while preserving prior knowledge. 3) Causal Graph Classification:\nEmploys Graph Convolutional Networks (GCNs) to classify system status using the\nlearned causal graphs. Extensive experiments on real-world critical\ninfrastructure datasets demonstrate that INCADET achieves superior accuracy,\nrobustness, and adaptability compared to both static causal and deep temporal\nbaselines in evolving attack scenarios.", "AI": {"tldr": "\u4f20\u7edf\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51faINCADET\u6846\u67b6\u7528\u4e8e\u5b9e\u65f6\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5b9e\u65f6\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u9762\u4e34\u7f51\u7edc\u653b\u51fb\u5a01\u80c1\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u6709\u8fc7\u591a\u8bef\u62a5\uff0c\u73b0\u6709\u56e0\u679c\u5173\u7cfb\u5efa\u6a21\u65b9\u6cd5\u96be\u4ee5\u5e94\u7528\u4e8e\u5b9e\u65f6\u573a\u666f\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faINCADET\u6846\u67b6\uff0c\u542b\u65e9\u671f\u75c7\u72b6\u68c0\u6d4b\u3001\u589e\u91cf\u56e0\u679c\u56fe\u5b66\u4e60\u3001\u56e0\u679c\u56fe\u5206\u7c7b\u4e09\u4e2a\u6a21\u5757\uff0c\u901a\u8fc7\u8de8\u65f6\u95f4\u7a97\u53e3\u589e\u91cf\u66f4\u65b0\u56e0\u679c\u56fe\u6355\u6349\u7cfb\u7edf\u884c\u4e3a\u3002", "result": "\u5728\u771f\u5b9e\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cINCADET\u5728\u4e0d\u65ad\u6f14\u53d8\u7684\u653b\u51fb\u573a\u666f\u4e2d\u6bd4\u9759\u6001\u56e0\u679c\u548c\u6df1\u5ea6\u65f6\u95f4\u57fa\u7ebf\u6a21\u578b\u66f4\u51c6\u786e\u3001\u9c81\u68d2\u548c\u9002\u5e94\u3002", "conclusion": "INCADET\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u5b9e\u65f6\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\u95ee\u9898\uff0c\u5177\u6709\u66f4\u597d\u6027\u80fd\u3002"}}
{"id": "2507.15112", "pdf": "https://arxiv.org/pdf/2507.15112", "abs": "https://arxiv.org/abs/2507.15112", "authors": ["Youssef Allouah", "Rachid Guerraoui", "Sanmi Koyejo"], "title": "Distributional Unlearning: Forgetting Distributions, Not Just Samples", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "Machine unlearning seeks to remove unwanted information from trained models,\ninitially at the individual-sample level, but increasingly at the level of\nentire sub-populations. In many deployments, models must delete whole topical\ndomains to satisfy privacy, legal, or quality requirements, e.g., removing\nseveral users' posts under GDPR or copyrighted web content. Existing unlearning\ntools remain largely sample-oriented, and straightforward point deletion often\nleaves enough residual signal for downstream learners to recover the unwanted\ndomain. We introduce distributional unlearning, a data-centric, model-agnostic\nframework that asks: Given examples from an unwanted distribution and a\nretained distribution, what is the smallest set of points whose removal makes\nthe edited dataset far from the unwanted domain yet close to the retained one?\nUsing Kullback-Leibler divergence to quantify removal and preservation, we\nderive the exact Pareto frontier in the Gaussian case and prove that any model\nretrained on the edited data incurs log-loss shifts bounded by the divergence\nthresholds. We propose a simple distance-based selection rule satisfying these\nconstraints with a quadratic reduction in deletion budget compared to random\nremoval. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam,\nand CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on\nretained performance.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u5c11\u91cf\u70b9\u5b9e\u73b0\u6570\u636e\u7f16\u8f91\uff0c\u5b9e\u9a8c\u663e\u793a\u51cf\u5c11\u5220\u9664\u91cf\u4e14\u4e0d\u5f71\u54cd\u4fdd\u7559\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u9057\u5fd8\u5de5\u5177\u591a\u4ee5\u6837\u672c\u4e3a\u5bfc\u5411\uff0c\u7b80\u5355\u5220\u9664\u4f1a\u7559\u6b8b\u5dee\u4fe1\u53f7\uff0c\u9700\u5220\u9664\u6574\u4e2a\u4e3b\u9898\u57df\u6ee1\u8db3\u9690\u79c1\u3001\u6cd5\u5f8b\u6216\u8d28\u91cf\u8981\u6c42\u3002", "method": "\u5f15\u5165\u5206\u5e03\u9057\u5fd8\u6846\u67b6\uff0c\u7528KL\u6563\u5ea6\u91cf\u5316\uff0c\u63a8\u5bfc\u9ad8\u65af\u60c5\u51b5\u4e0b\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u63d0\u51fa\u8ddd\u79bb\u9009\u62e9\u89c4\u5219\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u6bd4\u968f\u673a\u5220\u9664\u51cf\u5c1115 - 72%\u7684\u5220\u9664\u91cf\uff0c\u5bf9\u4fdd\u7559\u6027\u80fd\u5f71\u54cd\u53ef\u5ffd\u7565\u3002", "conclusion": "\u5206\u5e03\u9057\u5fd8\u6846\u67b6\u6709\u6548\u51cf\u5c11\u5220\u9664\u91cf\uff0c\u80fd\u4fdd\u8bc1\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.14962", "pdf": "https://arxiv.org/pdf/2507.14962", "abs": "https://arxiv.org/abs/2507.14962", "authors": ["Johannes Schmidt", "Mohamed Maizia", "Victor Lagerkvist", "Johannes K. Fichte"], "title": "Complexity of Faceted Explanations in Propositional Abduction", "categories": ["cs.AI", "cs.CC", "cs.LO"], "comment": "This is the author's self-archived copy including detailed proofs. To\n  appear in Theory and Practice of Logic Programming (TPLP), Proceedings of the\n  41st International Conference on Logic Programming (ICLP 2025)", "summary": "Abductive reasoning is a popular non-monotonic paradigm that aims to explain\nobserved symptoms and manifestations. It has many applications, such as\ndiagnosis and planning in artificial intelligence and database updates. In\npropositional abduction, we focus on specifying knowledge by a propositional\nformula. The computational complexity of tasks in propositional abduction has\nbeen systematically characterized - even with detailed classifications for\nBoolean fragments. Unsurprisingly, the most insightful reasoning problems\n(counting and enumeration) are computationally highly challenging. Therefore,\nwe consider reasoning between decisions and counting, allowing us to understand\nexplanations better while maintaining favorable complexity. We introduce facets\nto propositional abductions, which are literals that occur in some explanation\n(relevant) but not all explanations (dispensable). Reasoning with facets\nprovides a more fine-grained understanding of variability in explanations\n(heterogeneous). In addition, we consider the distance between two\nexplanations, enabling a better understanding of heterogeneity/homogeneity. We\ncomprehensively analyze facets of propositional abduction in various settings,\nincluding an almost complete characterization in Post's framework.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u547d\u9898\u6eaf\u56e0\u63a8\u7406\uff0c\u5f15\u5165\u5207\u9762\u6982\u5ff5\uff0c\u8003\u8651\u89e3\u91ca\u95f4\u8ddd\u79bb\uff0c\u5168\u9762\u5206\u6790\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u547d\u9898\u6eaf\u56e0\u7684\u5207\u9762\u3002", "motivation": "\u547d\u9898\u6eaf\u56e0\u4e2d\u8ba1\u6570\u548c\u679a\u4e3e\u7b49\u63a8\u7406\u95ee\u9898\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u5728\u51b3\u7b56\u548c\u8ba1\u6570\u95f4\u8fdb\u884c\u63a8\u7406\uff0c\u4ee5\u66f4\u597d\u7406\u89e3\u89e3\u91ca\u5e76\u4fdd\u6301\u5408\u7406\u590d\u6742\u5ea6\u3002", "method": "\u5f15\u5165\u547d\u9898\u6eaf\u56e0\u7684\u5207\u9762\u6982\u5ff5\uff0c\u8003\u8651\u89e3\u91ca\u95f4\u8ddd\u79bb\uff0c\u5e76\u5728Post\u6846\u67b6\u4e0b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u547d\u9898\u6eaf\u56e0\u5207\u9762\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u7684\u5168\u9762\u5206\u6790\uff0c\u5728Post\u6846\u67b6\u4e0b\u51e0\u4e4e\u5b8c\u6210\u7279\u5f81\u523b\u753b\u3002", "conclusion": "\u63a8\u7406\u5207\u9762\u6709\u52a9\u4e8e\u66f4\u7ec6\u7c92\u5ea6\u7406\u89e3\u89e3\u91ca\u7684\u53ef\u53d8\u6027\uff0c\u8003\u8651\u89e3\u91ca\u8ddd\u79bb\u80fd\u66f4\u597d\u7406\u89e3\u5f02\u8d28\u6027/\u540c\u8d28\u6027\u3002"}}
{"id": "2507.15296", "pdf": "https://arxiv.org/pdf/2507.15296", "abs": "https://arxiv.org/abs/2507.15296", "authors": ["Qian Xiong", "Yuekai Huang", "Ziyou Jiang", "Zhiyuan Chang", "Yujia Zheng", "Tianhao Li", "Mingyang Li"], "title": "Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The emergence of the tool agent paradigm has broadened the capability\nboundaries of the Large Language Model (LLM), enabling it to complete more\ncomplex tasks. However, the effectiveness of this paradigm is limited due to\nthe issue of parameter failure during its execution. To explore this phenomenon\nand propose corresponding suggestions, we first construct a parameter failure\ntaxonomy in this paper. We derive five failure categories from the invocation\nchain of a mainstream tool agent. Then, we explore the correlation between\nthree different input sources and failure categories by applying 15 input\nperturbation methods to the input. Experimental results show that parameter\nname hallucination failure primarily stems from inherent LLM limitations, while\nissues with input sources mainly cause other failure patterns. To improve the\nreliability and effectiveness of tool-agent interactions, we propose\ncorresponding improvement suggestions, including standardizing tool return\nformats, improving error feedback mechanisms, and ensuring parameter\nconsistency.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5de5\u5177\u4ee3\u7406\u8303\u5f0f\u6267\u884c\u4e2d\u53c2\u6570\u5931\u8d25\u95ee\u9898\uff0c\u6784\u5efa\u5206\u7c7b\u4f53\u7cfb\uff0c\u5b9e\u9a8c\u5206\u6790\u6210\u56e0\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u5de5\u5177\u4ee3\u7406\u8303\u5f0f\u6267\u884c\u4e2d\u5b58\u5728\u53c2\u6570\u5931\u8d25\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\uff0c\u9700\u63a2\u7d22\u8be5\u73b0\u8c61\u5e76\u63d0\u51fa\u5efa\u8bae\u3002", "method": "\u6784\u5efa\u53c2\u6570\u5931\u8d25\u5206\u7c7b\u4f53\u7cfb\uff0c\u4ece\u4e3b\u6d41\u5de5\u5177\u4ee3\u7406\u8c03\u7528\u94fe\u5f97\u51fa\u4e94\u7c7b\u5931\u8d25\uff0c\u5bf9\u8f93\u5165\u5e94\u752815\u79cd\u6270\u52a8\u65b9\u6cd5\u63a2\u7d22\u4e0d\u540c\u8f93\u5165\u6e90\u4e0e\u5931\u8d25\u7c7b\u522b\u7684\u5173\u8054\u3002", "result": "\u53c2\u6570\u540d\u79f0\u5e7b\u89c9\u5931\u8d25\u4e3b\u8981\u6e90\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u56fa\u6709\u5c40\u9650\uff0c\u5176\u4ed6\u5931\u8d25\u6a21\u5f0f\u4e3b\u8981\u7531\u8f93\u5165\u6e90\u95ee\u9898\u5bfc\u81f4\u3002", "conclusion": "\u4e3a\u63d0\u9ad8\u5de5\u5177\u4ee3\u7406\u4ea4\u4e92\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\uff0c\u63d0\u51fa\u89c4\u8303\u5de5\u5177\u8fd4\u56de\u683c\u5f0f\u3001\u6539\u8fdb\u9519\u8bef\u53cd\u9988\u673a\u5236\u548c\u786e\u4fdd\u53c2\u6570\u4e00\u81f4\u6027\u7b49\u6539\u8fdb\u5efa\u8bae\u3002"}}
{"id": "2507.14419", "pdf": "https://arxiv.org/pdf/2507.14419", "abs": "https://arxiv.org/abs/2507.14419", "authors": ["Guojun Wu"], "title": "It's Not That Simple. An Analysis of Simple Test-Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Prior work proposed simple test-time scaling, a method for replicating this\nscaling behavior with models distilled from o1-like models by manually\ncontrolling test-time compute: either scaling down by enforcing a maximum\nlength or scaling up by iteratively appending \"Wait\" when the model is about to\nterminate its generation. This paper presents an analysis of simple test-time\nscaling and finds that the scaling behavior is largely attributed to scaling\ndown by enforcing a maximum length. In contrast, fine-tuning on long CoT data\ndistilled from o1-like models has no significant impact on scaling behavior,\nand scaling up by appending \"Wait\" leads to inconsistencies, as the model may\noscillate between solutions. A key distinction exists between scaling down by\nenforcing a maximum length and scaling up test-time compute in o1-like models,\nsuch as DeepSeek-R1\\@. These models are typically allowed to utilize as much\ncompute as needed, with the only constraint being the model's maximum supported\nlength. By learning to naturally scale up test-time compute during\nreinforcement learning, o1-like models surpass their peak performance when\nscaling up. In contrast, simple test-time scaling progressively imposes a lower\nupper limit on model performance as it scales down. While replicating the\ntest-time scaling behavior of o1 models can be straightforward by scaling down,\nit is crucial to recognize that the goal of scaling test-time compute is to\nunlock higher performance -- beyond what the model could originally achieve --\nrather than merely reproducing the appearance of scaling behavior.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u53d1\u73b0\u7f29\u653e\u884c\u4e3a\u4e3b\u8981\u6e90\u4e8e\u8bbe\u7f6e\u6700\u5927\u957f\u5ea6\u7f29\u5c0f\u8ba1\u7b97\u91cf\uff0c\u5fae\u8c03\u957fCoT\u6570\u636e\u65e0\u663e\u8457\u5f71\u54cd\uff0c\u8ffd\u52a0\u201cWait\u201d\u4f1a\u5bfc\u81f4\u4e0d\u4e00\u81f4\u3002o1\u7c7b\u6a21\u578b\u4e0e\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u8868\u73b0\u4e0d\u540c\uff0c\u5f3a\u8c03\u7f29\u653e\u76ee\u6807\u662f\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5206\u6790\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u7684\u5177\u4f53\u60c5\u51b5\uff0c\u660e\u786e\u5176\u7f29\u653e\u884c\u4e3a\u7684\u5f71\u54cd\u56e0\u7d20\u53ca\u4e0eo1\u7c7b\u6a21\u578b\u7684\u5dee\u5f02\u3002", "method": "\u5bf9\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u8fdb\u884c\u5206\u6790\uff0c\u5bf9\u6bd4\u4e0d\u540c\u64cd\u4f5c\uff08\u8bbe\u7f6e\u6700\u5927\u957f\u5ea6\u3001\u8ffd\u52a0\u201cWait\u201d\u3001\u5fae\u8c03\u957fCoT\u6570\u636e\uff09\u5bf9\u7f29\u653e\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u4e0eo1\u7c7b\u6a21\u578b\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u7f29\u653e\u884c\u4e3a\u4e3b\u8981\u6e90\u4e8e\u8bbe\u7f6e\u6700\u5927\u957f\u5ea6\u7f29\u5c0f\u8ba1\u7b97\u91cf\uff1b\u5fae\u8c03\u957fCoT\u6570\u636e\u65e0\u663e\u8457\u5f71\u54cd\uff1b\u8ffd\u52a0\u201cWait\u201d\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u89e3\u4e4b\u95f4\u632f\u8361\uff1bo1\u7c7b\u6a21\u578b\u81ea\u7136\u7f29\u653e\u65f6\u80fd\u8d85\u8d8a\u5cf0\u503c\u6027\u80fd\uff0c\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u7f29\u5c0f\u8ba1\u7b97\u91cf\u4f1a\u964d\u4f4e\u6027\u80fd\u4e0a\u9650\u3002", "conclusion": "\u867d\u7136\u901a\u8fc7\u7f29\u5c0f\u8ba1\u7b97\u91cf\u590d\u5236o1\u6a21\u578b\u6d4b\u8bd5\u65f6\u7f29\u653e\u884c\u4e3a\u8f83\u7b80\u5355\uff0c\u4f46\u7f29\u653e\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u7684\u76ee\u6807\u5e94\u662f\u63d0\u5347\u6027\u80fd\u800c\u975e\u4ec5\u590d\u5236\u884c\u4e3a\u3002"}}
{"id": "2507.14987", "pdf": "https://arxiv.org/pdf/2507.14987", "abs": "https://arxiv.org/abs/2507.14987", "authors": ["Yi Zhang", "An Zhang", "XiuYu Zhang", "Leheng Sheng", "Yuxin Chen", "Zhenkai Liang", "Xiang Wang"], "title": "AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "Large language models (LLMs), despite possessing latent safety understanding\nfrom their vast pretraining data, remain vulnerable to generating harmful\ncontent and exhibit issues such as over-refusal and utility degradation after\nsafety alignment. Current safety alignment methods often result in superficial\nrefusal shortcuts or rely on intensive supervision for reasoning-based\napproaches, failing to fully leverage the model's intrinsic safety\nself-awareness. We propose \\textbf{AlphaAlign}, a simple yet effective pure\nreinforcement learning (RL) framework with verifiable safety reward designed to\nincentivize this latent safety awareness through proactive safety reasoning.}\nAlphaAlign employs a dual-reward system: a verifiable safety reward encourages\ncorrectly formatted and explicitly justified refusals for harmful queries while\npenalizing over-refusals, and a normalized helpfulness reward guides\nhigh-quality responses to benign inputs. This allows the model to develop\nproactive safety reasoning capabilities without depending on supervised\nsafety-specific reasoning data. AlphaAlign demonstrates three key advantages:\n(1) Simplicity and efficiency, requiring only binary prompt safety labels and\nminimal RL steps for substantial improvements. (2) Breaking the safety-utility\ntrade-off, by enhancing refusal of harmful content and reducing over-refusals,\nwhile simultaneously maintaining or even improving general task performance and\nrobustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety\nreasoning that generates explicit safety rationales rather than relying on\nshallow refusal patterns.", "AI": {"tldr": "\u63d0\u51faAlphaAlign\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5956\u52b1\u7cfb\u7edf\u6fc0\u52b1\u5927\u8bed\u8a00\u6a21\u578b\u6f5c\u5728\u5b89\u5168\u610f\u8bc6\uff0c\u6709\u7b80\u5355\u9ad8\u6548\u3001\u6253\u7834\u5b89\u5168-\u6548\u7528\u6743\u8861\u3001\u6df1\u5ea6\u5bf9\u9f50\u7b49\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u6709\u4e0d\u8db3\uff0c\u672a\u5145\u5206\u5229\u7528\u6a21\u578b\u5185\u5728\u5b89\u5168\u81ea\u6211\u610f\u8bc6\u3002", "method": "\u63d0\u51faAlphaAlign\u7eaf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5956\u52b1\u7cfb\u7edf\uff08\u53ef\u9a8c\u8bc1\u5b89\u5168\u5956\u52b1\u548c\u5f52\u4e00\u5316\u6709\u7528\u6027\u5956\u52b1\uff09\u3002", "result": "AlphaAlign\u53ea\u9700\u4e8c\u8fdb\u5236\u63d0\u793a\u5b89\u5168\u6807\u7b7e\u548c\u6700\u5c11\u5f3a\u5316\u5b66\u4e60\u6b65\u9aa4\u5c31\u80fd\u6709\u663e\u8457\u6539\u8fdb\uff0c\u589e\u5f3a\u6709\u5bb3\u5185\u5bb9\u62d2\u7edd\u3001\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\uff0c\u7ef4\u6301\u6216\u63d0\u5347\u901a\u7528\u4efb\u52a1\u8868\u73b0\u548c\u5bf9\u672a\u77e5\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "AlphaAlign\u80fd\u6709\u6548\u6fc0\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u6f5c\u5728\u5b89\u5168\u610f\u8bc6\uff0c\u5b9e\u73b0\u6df1\u5ea6\u5b89\u5168\u5bf9\u9f50\u3002"}}
{"id": "2507.15343", "pdf": "https://arxiv.org/pdf/2507.15343", "abs": "https://arxiv.org/abs/2507.15343", "authors": ["Kechi Zhang", "Ge Li", "Jia Li", "Huangzhao Zhang", "Yihong Dong", "Jia Li", "Jingjing Xu", "Zhi Jin"], "title": "StackTrans: From Large Language Model to Large Pushdown Automata Model", "categories": ["cs.SE", "cs.AI"], "comment": "currently under development", "summary": "The Transformer architecture has emerged as a landmark advancement within the\nbroad field of artificial intelligence, effectively catalyzing the advent of\nlarge language models (LLMs). However, despite its remarkable capabilities and\nthe substantial progress it has facilitated, the Transformer architecture still\nhas some limitations. One such intrinsic limitation is its inability to\neffectively capture the Chomsky hierarchy, such as regular expressions or\ndeterministic context-free grammars. Drawing inspiration from pushdown\nautomata, which efficiently resolve deterministic context-free grammars using\nstacks, we propose StackTrans to address the aforementioned issue within LLMs.\nUnlike previous approaches that modify the attention computation, StackTrans\nexplicitly incorporates hidden state stacks between Transformer layers. This\ndesign maintains compatibility with existing frameworks like flash-attention.\nSpecifically, our design features stack operations -- such as pushing and\npopping hidden states -- that are differentiable and can be learned in an\nend-to-end manner. Our comprehensive evaluation spans benchmarks for both\nChomsky hierarchies and large-scale natural languages. Across these diverse\ntasks, StackTrans consistently outperforms standard Transformer models and\nother baselines. We have successfully scaled StackTrans up from 360M to 7B\nparameters. In particular, our from-scratch pretrained model StackTrans-360M\noutperforms several larger open-source LLMs with 2-3x more parameters,\nshowcasing its superior efficiency and reasoning capability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa StackTrans \u6a21\u578b\uff0c\u5728 Transformer \u5c42\u95f4\u52a0\u5165\u9690\u85cf\u72b6\u6001\u6808\uff0c\u89e3\u51b3\u5176\u65e0\u6cd5\u6709\u6548\u6355\u83b7\u4e54\u59c6\u65af\u57fa\u5c42\u7ea7\u7684\u95ee\u9898\uff0c\u8bc4\u4f30\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u6807\u51c6 Transformer \u53ca\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "Transformer \u67b6\u6784\u867d\u63a8\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\uff0c\u4f46\u5b58\u5728\u65e0\u6cd5\u6709\u6548\u6355\u83b7\u4e54\u59c6\u65af\u57fa\u5c42\u7ea7\u7684\u5c40\u9650\u3002", "method": "\u53d7\u4e0b\u63a8\u81ea\u52a8\u673a\u542f\u53d1\uff0c\u63d0\u51fa StackTrans\uff0c\u5728 Transformer \u5c42\u95f4\u663e\u5f0f\u52a0\u5165\u9690\u85cf\u72b6\u6001\u6808\uff0c\u8bbe\u8ba1\u53ef\u5fae\u5206\u7684\u6808\u64cd\u4f5c\u5e76\u8fdb\u884c\u7aef\u5230\u7aef\u5b66\u4e60\u3002", "result": "\u5728\u4e54\u59c6\u65af\u57fa\u5c42\u7ea7\u548c\u5927\u89c4\u6a21\u81ea\u7136\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cStackTrans \u8868\u73b0\u4f18\u4e8e\u6807\u51c6 Transformer \u6a21\u578b\u548c\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\uff0c\u6210\u529f\u5c06\u53c2\u6570\u4ece 360M \u6269\u5c55\u5230 7B\uff0cStackTrans - 360M \u4f18\u4e8e\u53c2\u6570\u591a 2 - 3 \u500d\u7684\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "StackTrans \u5177\u6709\u4f18\u8d8a\u7684\u6548\u7387\u548c\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2507.14446", "pdf": "https://arxiv.org/pdf/2507.14446", "abs": "https://arxiv.org/abs/2507.14446", "authors": ["Feng Liu", "Ying Liu", "Carson Eisenach"], "title": "Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we study how to efficiently apply reinforcement learning (RL)\nfor solving large-scale stochastic optimization problems by leveraging\nintervention models. The key of the proposed methodology is to better explore\nthe solution space by simulating and composing the stochastic processes using\npre-trained deep learning (DL) models. We demonstrate our approach on a\nchallenging real-world application, the multi-sourcing multi-period inventory\nmanagement problem in supply chain optimization. In particular, we employ deep\nRL models for learning and forecasting the stochastic supply chain processes\nunder a range of assumptions. Moreover, we also introduce a constraint\ncoordination mechanism, designed to forecast dual costs given the\ncross-products constraints in the inventory network. We highlight that instead\nof directly modeling the complex physical constraints into the RL optimization\nproblem and solving the stochastic problem as a whole, our approach breaks down\nthose supply chain processes into scalable and composable DL modules, leading\nto improved performance on large real-world datasets. We also outline open\nproblems for future research to further investigate the efficacy of such\nmodels.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5229\u7528\u5e72\u9884\u6a21\u578b\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u968f\u673a\u4f18\u5316\u95ee\u9898\uff0c\u4ee5\u4f9b\u5e94\u94fe\u5e93\u5b58\u7ba1\u7406\u4e3a\u4f8b\uff0c\u63d0\u51fa\u5206\u89e3\u6d41\u7a0b\u4e3a\u53ef\u7ec4\u5408\u6a21\u5757\u7684\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u9ad8\u6548\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u5927\u89c4\u6a21\u968f\u673a\u4f18\u5316\u95ee\u9898\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6a21\u62df\u548c\u7ec4\u5408\u968f\u673a\u8fc7\u7a0b\uff0c\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u5b66\u4e60\u548c\u9884\u6d4b\uff0c\u5f15\u5165\u7ea6\u675f\u534f\u8c03\u673a\u5236\uff0c\u5c06\u4f9b\u5e94\u94fe\u6d41\u7a0b\u5206\u89e3\u4e3a\u53ef\u7ec4\u5408\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757\u3002", "result": "\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2507.15222", "pdf": "https://arxiv.org/pdf/2507.15222", "abs": "https://arxiv.org/abs/2507.15222", "authors": ["Hiroshi Tamano", "Hideitsu Hino", "Daichi Mochihashi"], "title": "Misspecifying non-compensatory as compensatory IRT: analysis of estimated skills and variance", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Multidimensional item response theory is a statistical test theory used to\nestimate the latent skills of learners and the difficulty levels of problems\nbased on test results. Both compensatory and non-compensatory models have been\nproposed in the literature. Previous studies have revealed the substantial\nunderestimation of higher skills when the non-compensatory model is\nmisspecified as the compensatory model. However, the underlying mechanism\nbehind this phenomenon has not been fully elucidated. It remains unclear\nwhether overestimation also occurs and whether issues arise regarding the\nvariance of the estimated parameters. In this paper, we aim to provide a\ncomprehensive understanding of both underestimation and overestimation through\na theoretical approach. In addition to the previously identified\nunderestimation of the skills, we newly discover that the overestimation of\nskills occurs around the origin. Furthermore, we investigate the extent to\nwhich the asymptotic variance of the estimated parameters differs when\nconsidering model misspecification compared to when it is not taken into\naccount.", "AI": {"tldr": "\u672c\u6587\u7528\u7406\u8bba\u65b9\u6cd5\u5168\u9762\u7814\u7a76\u591a\u7ef4\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u4e2d\u6a21\u578b\u8bef\u8bbe\u65f6\u6280\u80fd\u4f4e\u4f30\u548c\u9ad8\u4f30\u73b0\u8c61\u53ca\u53c2\u6570\u4f30\u8ba1\u6e10\u8fd1\u65b9\u5dee\u5dee\u5f02\u3002", "motivation": "\u6b64\u524d\u7814\u7a76\u53d1\u73b0\u975e\u8865\u507f\u6a21\u578b\u8bef\u8bbe\u4e3a\u8865\u507f\u6a21\u578b\u65f6\u4f1a\u4f4e\u4f30\u9ad8\u6280\u80fd\uff0c\u4f46\u73b0\u8c61\u80cc\u540e\u673a\u5236\u672a\u9610\u660e\uff0c\u9ad8\u4f30\u60c5\u51b5\u53ca\u53c2\u6570\u4f30\u8ba1\u65b9\u5dee\u95ee\u9898\u4e0d\u660e\uff0c\u6545\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u91c7\u7528\u7406\u8bba\u7814\u7a76\u65b9\u6cd5\u3002", "result": "\u9664\u53d1\u73b0\u5df2\u77e5\u7684\u6280\u80fd\u4f4e\u4f30\uff0c\u8fd8\u53d1\u73b0\u539f\u70b9\u9644\u8fd1\u5b58\u5728\u6280\u80fd\u9ad8\u4f30\uff0c\u4e14\u7814\u7a76\u4e86\u8003\u8651\u548c\u4e0d\u8003\u8651\u6a21\u578b\u8bef\u8bbe\u65f6\u53c2\u6570\u4f30\u8ba1\u6e10\u8fd1\u65b9\u5dee\u7684\u5dee\u5f02\u7a0b\u5ea6\u3002", "conclusion": "\u6587\u6863\u672a\u660e\u786e\u63d0\u53ca\u6700\u7ec8\u7ed3\u8bba\u3002"}}
{"id": "2507.15013", "pdf": "https://arxiv.org/pdf/2507.15013", "abs": "https://arxiv.org/abs/2507.15013", "authors": ["Xiaoyu Li", "Jin Wu", "Shaoyang Guo", "Haoran Shi", "Chanjin Zheng"], "title": "A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing", "categories": ["cs.AI"], "comment": "15pages, 7 figures", "summary": "In the smart era, psychometric tests are becoming increasingly important for\npersonnel selection, career development, and mental health assessment.\nForced-choice tests are common in personality assessments because they require\nparticipants to select from closely related options, lowering the risk of\nresponse distortion. This study presents a deep learning-based Forced-Choice\nNeural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of\ntraditional models and is applicable to the three most common item block types\nfound in forced-choice tests. To account for the unidimensionality of items in\nforced-choice tests, we create interpretable participant and item parameters.\nWe model the interactions between participant and item features using\nmultilayer neural networks after mining them using nonlinear mapping. In\naddition, we use the monotonicity assumption to improve the interpretability of\nthe diagnostic results. The FCNCD's effectiveness is validated by experiments\non real-world and simulated datasets that show its accuracy, interpretability,\nand robustness.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5f3a\u5236\u9009\u62e9\u795e\u7ecf\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\uff08FCNCD\uff09\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027", "motivation": "\u4f20\u7edf\u6a21\u578b\u6709\u5c40\u9650\u6027\uff0c\u9700\u5f00\u53d1\u9002\u7528\u4e8e\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u5e38\u89c1\u9898\u578b\u7684\u6a21\u578b", "method": "\u521b\u5efa\u53ef\u89e3\u91ca\u7684\u53c2\u4e0e\u8005\u548c\u9879\u76ee\u53c2\u6570\uff0c\u7528\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u4ea4\u4e92\uff0c\u5229\u7528\u5355\u8c03\u6027\u5047\u8bbe\u63d0\u5347\u8bca\u65ad\u7ed3\u679c\u53ef\u89e3\u91ca\u6027", "result": "\u5728\u771f\u5b9e\u548c\u6a21\u62df\u6570\u636e\u96c6\u5b9e\u9a8c\u9a8c\u8bc1FCNCD\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027", "conclusion": "FCNCD\u80fd\u514b\u670d\u4f20\u7edf\u6a21\u578b\u5c40\u9650\uff0c\u6709\u6548\u5e94\u7528\u4e8e\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5"}}
{"id": "2507.15599", "pdf": "https://arxiv.org/pdf/2507.15599", "abs": "https://arxiv.org/abs/2507.15599", "authors": ["Manatsawin Hanmongkolchai"], "title": "Applying the Chinese Wall Reverse Engineering Technique to Large Language Model Code Editing", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Large language models for code (Code LLM) are increasingly utilized in\nprogramming environments. Despite their utility, the training datasets for top\nLLM remain undisclosed, raising concerns about potential copyright violations.\nSome models, such as Pleias and Comma put emphasis on data curation and\nlicenses, however, with limited training data these models are not competitive\nand only serve as proof of concepts. To improve the utility of these models, we\npropose an application of the \"Chinese Wall\" technique, inspired by the reverse\nengineering technique of the same name -- a high quality model is used to\ngenerate detailed instructions for a weaker model. By doing so, a weaker but\nethically aligned model may be used to perform complicated tasks that,\notherwise, can only be completed by more powerful models. In our evaluation,\nwe've found that this technique improves Comma v0.1 1T's performance in\nCanItEdit benchmark by over 66%, and Starcoder2 Instruct by roughly 20%\ncompared to when running the same model on the benchmark alone. The practical\napplication of this technique today, however, may be limited due to the lack of\nmodels trained on public domain content without copyright restrictions.", "AI": {"tldr": "\u63d0\u51fa\u201cChinese Wall\u201d\u6280\u672f\u63d0\u5347\u4ee3\u7801\u5927\u6a21\u578b\u6027\u80fd\uff0c\u8bc4\u4f30\u663e\u793a\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u53d7\u65e0\u7248\u6743\u9650\u5236\u6a21\u578b\u7f3a\u4e4f\u5f71\u54cd\u3002", "motivation": "\u4ee3\u7801\u5927\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u96c6\u672a\u516c\u5f00\u5f15\u53d1\u7248\u6743\u62c5\u5fe7\uff0c\u90e8\u5206\u6ce8\u91cd\u6570\u636e\u7ba1\u7406\u548c\u8bb8\u53ef\u7684\u6a21\u578b\u56e0\u6570\u636e\u6709\u9650\u7f3a\u4e4f\u7ade\u4e89\u529b\uff0c\u9700\u63d0\u5347\u5176\u5b9e\u7528\u6027\u3002", "method": "\u5e94\u7528\u201cChinese Wall\u201d\u6280\u672f\uff0c\u7528\u9ad8\u8d28\u91cf\u6a21\u578b\u4e3a\u8f83\u5f31\u6a21\u578b\u751f\u6210\u8be6\u7ec6\u6307\u4ee4\u3002", "result": "\u8be5\u6280\u672f\u4f7fComma v0.1 1T\u5728CanItEdit\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u63d0\u5347\u8d8566%\uff0cStarcoder2 Instruct\u63d0\u5347\u7ea620%\u3002", "conclusion": "\u6b64\u6280\u672f\u80fd\u63d0\u5347\u8f83\u5f31\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u53d7\u65e0\u7248\u6743\u9650\u5236\u8bad\u7ec3\u6a21\u578b\u7f3a\u4e4f\u7684\u9650\u5236\uff0c\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u3002"}}
{"id": "2507.14484", "pdf": "https://arxiv.org/pdf/2507.14484", "abs": "https://arxiv.org/abs/2507.14484", "authors": ["Yule Li", "Yifeng Lu", "Zhen Wang", "Zhewei Wei", "Yaliang Li", "Bolin Ding"], "title": "ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, graph neural networks (GNN) have achieved unprecedented\nsuccesses in node classification tasks. Although GNNs inherently encode\nspecific inductive biases (e.g., acting as low-pass or high-pass filters), most\nexisting methods implicitly assume conditional independence among node labels\nin their optimization objectives. While this assumption is suitable for\ntraditional classification tasks such as image recognition, it contradicts the\nintuitive observation that node labels in graphs remain correlated, even after\nconditioning on the graph structure. To make structured predictions for node\nlabels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for\nStructured node Classification. ReDiSC estimates the joint distribution of node\nlabels using a reparameterized masked diffusion model, which is learned through\nthe variational expectation-maximization (EM) framework. Our theoretical\nanalysis shows the efficiency advantage of ReDiSC in the E-step compared to\nDPM-SNC, a state-of-the-art model that relies on a manifold-constrained\ndiffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's\nM-step objective to popular GNN and label propagation hybrid approaches.\nExtensive experiments demonstrate that ReDiSC achieves superior or highly\ncompetitive performance compared to state-of-the-art GNN, label propagation,\nand diffusion-based baselines across both homophilic and heterophilic graphs of\nvarying sizes. Notably, ReDiSC scales effectively to large-scale datasets on\nwhich previous structured diffusion methods fail due to computational\nconstraints, highlighting its significant practical advantage in structured\nnode classification tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u8282\u70b9\u5206\u7c7b\u7684ReDiSC\u6a21\u578b\uff0c\u901a\u8fc7\u91cd\u53c2\u6570\u5316\u63a9\u7801\u6269\u6563\u6a21\u578b\u4f30\u8ba1\u8282\u70b9\u6807\u7b7e\u8054\u5408\u5206\u5e03\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u4e0d\u540c\u56fe\u4e0a\u8868\u73b0\u4f18\u8d8a\u4e14\u80fd\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u3002", "motivation": "\u73b0\u6709GNN\u65b9\u6cd5\u5728\u4f18\u5316\u76ee\u6807\u4e2d\u5047\u8bbe\u8282\u70b9\u6807\u7b7e\u6761\u4ef6\u72ec\u7acb\uff0c\u4e0e\u56fe\u4e2d\u8282\u70b9\u6807\u7b7e\u5b58\u5728\u76f8\u5173\u6027\u7684\u76f4\u89c2\u89c2\u5bdf\u76f8\u77db\u76fe\uff0c\u9700\u8fdb\u884c\u7ed3\u6784\u5316\u9884\u6d4b\u3002", "method": "\u63d0\u51faReDiSC\u6a21\u578b\uff0c\u4f7f\u7528\u91cd\u53c2\u6570\u5316\u63a9\u7801\u6269\u6563\u6a21\u578b\u4f30\u8ba1\u8282\u70b9\u6807\u7b7e\u8054\u5408\u5206\u5e03\uff0c\u901a\u8fc7\u53d8\u5206\u671f\u671b\u6700\u5927\u5316\uff08EM\uff09\u6846\u67b6\u5b66\u4e60\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793aReDiSC\u5728E\u6b65\u6bd4DPM - SNC\u66f4\u6709\u6548\uff0cM\u6b65\u76ee\u6807\u4e0e\u6d41\u884c\u7684GNN\u548c\u6807\u7b7e\u4f20\u64ad\u6df7\u5408\u65b9\u6cd5\u76f8\u5173\uff1b\u5b9e\u9a8c\u8868\u660eReDiSC\u5728\u4e0d\u540c\u56fe\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u597d\uff0c\u80fd\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u3002", "conclusion": "ReDiSC\u5728\u7ed3\u6784\u5316\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u6709\u663e\u8457\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2507.15240", "pdf": "https://arxiv.org/pdf/2507.15240", "abs": "https://arxiv.org/abs/2507.15240", "authors": ["Le Peng", "Yash Travadi", "Chuan He", "Ying Cui", "Ju Sun"], "title": "Exact Reformulation and Optimization for Direct Metric Optimization in Binary Imbalanced Classification", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "For classification with imbalanced class frequencies, i.e., imbalanced\nclassification (IC), standard accuracy is known to be misleading as a\nperformance measure. While most existing methods for IC resort to optimizing\nbalanced accuracy (i.e., the average of class-wise recalls), they fall short in\nscenarios where the significance of classes varies or certain metrics should\nreach prescribed levels. In this paper, we study two key classification\nmetrics, precision and recall, under three practical binary IC settings: fix\nprecision optimize recall (FPOR), fix recall optimize precision (FROP), and\noptimize $F_\\beta$-score (OFBS). Unlike existing methods that rely on smooth\napproximations to deal with the indicator function involved, \\textit{we\nintroduce, for the first time, exact constrained reformulations for these\ndirect metric optimization (DMO) problems}, which can be effectively solved by\nexact penalty methods. Experiment results on multiple benchmark datasets\ndemonstrate the practical superiority of our approach over the state-of-the-art\nmethods for the three DMO problems. We also expect our exact reformulation and\noptimization (ERO) framework to be applicable to a wide range of DMO problems\nfor binary IC and beyond. Our code is available at\nhttps://github.com/sun-umn/DMO.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u5e73\u8861\u5206\u7c7b\u7684\u4e09\u4e2a\u76f4\u63a5\u6307\u6807\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u7cbe\u786e\u7ea6\u675f\u91cd\u65b0\u8868\u8ff0\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6846\u67b6\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u4e0d\u5e73\u8861\u5206\u7c7b\u65b9\u6cd5\u5728\u7c7b\u522b\u91cd\u8981\u6027\u4e0d\u540c\u6216\u7279\u5b9a\u6307\u6807\u9700\u8fbe\u89c4\u5b9a\u6c34\u5e73\u7684\u573a\u666f\u6709\u4e0d\u8db3\u3002", "method": "\u9996\u6b21\u5f15\u5165\u7cbe\u786e\u7ea6\u675f\u91cd\u65b0\u8868\u8ff0\u65b9\u6cd5\u89e3\u51b3\u76f4\u63a5\u6307\u6807\u4f18\u5316\u95ee\u9898\uff0c\u7528\u7cbe\u786e\u60e9\u7f5a\u6cd5\u6c42\u89e3\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u76f4\u63a5\u6307\u6807\u4f18\u5316\u95ee\u9898\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7cbe\u786e\u91cd\u65b0\u8868\u8ff0\u548c\u4f18\u5316\u6846\u67b6\u9002\u7528\u4e8e\u4e8c\u5143\u4e0d\u5e73\u8861\u5206\u7c7b\u53ca\u66f4\u5e7f\u6cdb\u7684\u76f4\u63a5\u6307\u6807\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2507.15624", "pdf": "https://arxiv.org/pdf/2507.15624", "abs": "https://arxiv.org/abs/2507.15624", "authors": ["Yusuf Sulistyo Nugroho", "Ganno Tribuana Kurniaji", "Syful Islam", "Mohammed Humayun Kabir", "Vanesya Aura Ardity", "Md. Kamal Uddin"], "title": "Hot Topics and Common Challenges: an Empirical Study of React Discussions on Stack Overflow", "categories": ["cs.SE"], "comment": "6 pages, 4 figures, 4 tables, conference paper", "summary": "React is a JavaScript library used to build user interfaces for single-page\napplications. Although recent studies have shown the popularity and advantages\nof React in web development, the specific challenges users face remain unknown.\nThus, this study aims to analyse the React-related questions shared on Stack\nOverflow. The study utilizes an exploratory data analysis to investigate the\nmost frequently discussed keywords, error classification, and user\nreputation-based errors, which is the novelty of this work. The results show\nthe top eight most frequently used keywords on React-related questions, namely,\ncode, link, vir, href, connect, azure, windows, and website. The error\nclassification of questions from the sample shows that algorithmic error is the\nmost frequent issue faced by all groups of users, where mid-reputation users\ncontribute the most, accounting for 55.77%. This suggests the need for the\ncommunity to provide guidance materials in solving algorithm-related problems.\nWe expect that the results of this study will provide valuable insight into\nfuture research to support the React community during the early stages of\nimplementation, facilitating their ability to effectively overcome challenges\nto adoption.", "AI": {"tldr": "\u5206\u6790Stack Overflow\u4e0aReact\u76f8\u5173\u95ee\u9898\uff0c\u627e\u51fa\u9ad8\u9891\u5173\u952e\u8bcd\u548c\u9519\u8bef\u5206\u7c7b\uff0c\u5efa\u8bae\u793e\u533a\u63d0\u4f9b\u7b97\u6cd5\u95ee\u9898\u6307\u5bfc\u6750\u6599\u3002", "motivation": "\u867d\u77e5React\u5728\u7f51\u9875\u5f00\u53d1\u4e2d\u53d7\u6b22\u8fce\u4e14\u6709\u4f18\u52bf\uff0c\u4f46\u7528\u6237\u9762\u4e34\u7684\u5177\u4f53\u6311\u6218\u672a\u77e5\uff0c\u6545\u5206\u6790\u76f8\u5173\u95ee\u9898\u3002", "method": "\u91c7\u7528\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\uff0c\u7814\u7a76\u9ad8\u9891\u5173\u952e\u8bcd\u3001\u9519\u8bef\u5206\u7c7b\u548c\u57fa\u4e8e\u7528\u6237\u58f0\u8a89\u7684\u9519\u8bef\u3002", "result": "\u5f97\u51faReact\u76f8\u5173\u95ee\u9898\u4e2d8\u4e2a\u9ad8\u9891\u5173\u952e\u8bcd\uff1b\u7b97\u6cd5\u9519\u8bef\u662f\u7528\u6237\u6700\u5e38\u9047\u5230\u7684\u95ee\u9898\uff0c\u4e2d\u58f0\u8a89\u7528\u6237\u8d21\u732e\u6700\u591a\uff0c\u536055.77%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u80fd\u4e3a\u65e9\u671f\u5b9e\u65bd\u9636\u6bb5\u7684React\u793e\u533a\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u52a9\u5176\u514b\u670d\u6311\u6218\u3002"}}
{"id": "2507.14487", "pdf": "https://arxiv.org/pdf/2507.14487", "abs": "https://arxiv.org/abs/2507.14487", "authors": ["Ukjo Hwang", "Songnam Hong"], "title": "Federated Reinforcement Learning in Heterogeneous Environments", "categories": ["cs.LG"], "comment": null, "summary": "We investigate a Federated Reinforcement Learning with Environment\nHeterogeneity (FRL-EH) framework, where local environments exhibit statistical\nheterogeneity. Within this framework, agents collaboratively learn a global\npolicy by aggregating their collective experiences while preserving the privacy\nof their local trajectories. To better reflect real-world scenarios, we\nintroduce a robust FRL-EH framework by presenting a novel global objective\nfunction. This function is specifically designed to optimize a global policy\nthat ensures robust performance across heterogeneous local environments and\ntheir plausible perturbations. We propose a tabular FRL algorithm named FedRQ\nand theoretically prove its asymptotic convergence to an optimal policy for the\nglobal objective function. Furthermore, we extend FedRQ to environments with\ncontinuous state space through the use of expectile loss, addressing the key\nchallenge of minimizing a value function over a continuous subset of the state\nspace. This advancement facilitates the seamless integration of the principles\nof FedRQ with various Deep Neural Network (DNN)-based RL algorithms. Extensive\nempirical evaluations validate the effectiveness and robustness of our FRL\nalgorithms across diverse heterogeneous environments, consistently achieving\nsuperior performance over the existing state-of-the-art FRL algorithms.", "AI": {"tldr": "\u7814\u7a76\u542b\u73af\u5883\u5f02\u8d28\u6027\u7684\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6FRL - EH\uff0c\u63d0\u51fa\u65b0\u5168\u5c40\u76ee\u6807\u51fd\u6570\uff0c\u8bbe\u8ba1FedRQ\u7b97\u6cd5\u5e76\u8bc1\u660e\u6536\u655b\u6027\uff0c\u6269\u5c55\u81f3\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u7b97\u6cd5\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u672c\u5730\u73af\u5883\u5b58\u5728\u7edf\u8ba1\u5f02\u8d28\u6027\uff0c\u9700\u4e00\u79cd\u80fd\u5728\u5f02\u8d28\u73af\u5883\u53ca\u5176\u6270\u52a8\u4e0b\u4fdd\u8bc1\u6027\u80fd\u7684\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u5168\u5c40\u76ee\u6807\u51fd\u6570\uff0c\u8bbe\u8ba1FedRQ\u7b97\u6cd5\u5e76\u8bc1\u660e\u6536\u655b\u6027\uff0c\u7528\u671f\u671b\u5206\u4f4d\u6570\u635f\u5931\u5c06\u5176\u6269\u5c55\u5230\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u3002", "result": "\u6240\u63d0\u51fa\u7684FRL\u7b97\u6cd5\u5728\u4e0d\u540c\u5f02\u8d28\u73af\u5883\u4e2d\u90fd\u6709\u6548\u4e14\u9c81\u68d2\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u7684FRL\u7b97\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684FRL - EH\u6846\u67b6\u53ca\u76f8\u5173\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73af\u5883\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5728\u5f02\u8d28\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.15397", "pdf": "https://arxiv.org/pdf/2507.15397", "abs": "https://arxiv.org/abs/2507.15397", "authors": ["Scott Pesme", "Giacomo Meanti", "Michael Arbel", "Julien Mairal"], "title": "MAP Estimation with Denoisers: Convergence Rates and Guarantees", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Denoiser models have become powerful tools for inverse problems, enabling the\nuse of pretrained networks to approximate the score of a smoothed prior\ndistribution. These models are often used in heuristic iterative schemes aimed\nat solving Maximum a Posteriori (MAP) optimisation problems, where the proximal\noperator of the negative log-prior plays a central role. In practice, this\noperator is intractable, and practitioners plug in a pretrained denoiser as a\nsurrogate-despite the lack of general theoretical justification for this\nsubstitution. In this work, we show that a simple algorithm, closely related to\nseveral used in practice, provably converges to the proximal operator under a\nlog-concavity assumption on the prior $p$. We show that this algorithm can be\ninterpreted as a gradient descent on smoothed proximal objectives. Our analysis\nthus provides a theoretical foundation for a class of empirically successful\nbut previously heuristic methods.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u5728\u5bf9\u6570\u51f9\u6027\u5047\u8bbe\u4e0b\uff0c\u4e00\u4e2a\u4e0e\u5b9e\u9645\u4e2d\u5e38\u7528\u7b97\u6cd5\u5bc6\u5207\u76f8\u5173\u7684\u7b80\u5355\u7b97\u6cd5\u53ef\u6536\u655b\u5230\u8fd1\u7aef\u7b97\u5b50\uff0c\u4e3a\u4e00\u7c7b\u7ecf\u9a8c\u6210\u529f\u4f46\u6b64\u524d\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5b9e\u9645\u4e2d\u5e38\u7528\u4e8e\u89e3\u51b3\u6700\u5927\u540e\u9a8c\u4f18\u5316\u95ee\u9898\u7684\u542f\u53d1\u5f0f\u8fed\u4ee3\u65b9\u6848\u4e2d\uff0c\u8d1f\u5bf9\u6570\u5148\u9a8c\u7684\u8fd1\u7aef\u7b97\u5b50\u96be\u4ee5\u5904\u7406\uff0c\u7528\u9884\u8bad\u7ec3\u53bb\u566a\u5668\u66ff\u4ee3\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u5728\u5bf9\u6570\u51f9\u6027\u5047\u8bbe\u4e0b\uff0c\u5206\u6790\u4e00\u4e2a\u7b80\u5355\u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u89e3\u91ca\u4e3a\u5bf9\u5e73\u6ed1\u8fd1\u7aef\u76ee\u6807\u7684\u68af\u5ea6\u4e0b\u964d\u3002", "result": "\u8bc1\u660e\u8be5\u7b80\u5355\u7b97\u6cd5\u53ef\u6536\u655b\u5230\u8fd1\u7aef\u7b97\u5b50\u3002", "conclusion": "\u4e3a\u4e00\u7c7b\u7ecf\u9a8c\u6210\u529f\u4f46\u6b64\u524d\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.15106", "pdf": "https://arxiv.org/pdf/2507.15106", "abs": "https://arxiv.org/abs/2507.15106", "authors": ["Xia Xu", "Jochen Triesch"], "title": "From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward", "categories": ["cs.AI", "cs.RO", "F.2.2"], "comment": "13 pages, 5 figures", "summary": "While human infants robustly discover their own causal efficacy, standard\nreinforcement learning agents remain brittle, as their reliance on\ncorrelation-based rewards fails in noisy, ecologically valid scenarios. To\naddress this, we introduce the Causal Action Influence Score (CAIS), a novel\nintrinsic reward rooted in causal inference. CAIS quantifies an action's\ninfluence by measuring the 1-Wasserstein distance between the learned\ndistribution of sensory outcomes conditional on that action, $p(h|a)$, and the\nbaseline outcome distribution, $p(h)$. This divergence provides a robust reward\nthat isolates the agent's causal impact from confounding environmental noise.\nWe test our approach in a simulated infant-mobile environment where\ncorrelation-based perceptual rewards fail completely when the mobile is\nsubjected to external forces. In stark contrast, CAIS enables the agent to\nfilter this noise, identify its influence, and learn the correct policy.\nFurthermore, the high-quality predictive model learned for CAIS allows our\nagent, when augmented with a surprise signal, to successfully reproduce the\n\"extinction burst\" phenomenon. We conclude that explicitly inferring causality\nis a crucial mechanism for developing a robust sense of agency, offering a\npsychologically plausible framework for more adaptive autonomous systems.", "AI": {"tldr": "\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u5608\u6742\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u672c\u6587\u5f15\u5165\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684CAIS\uff0c\u5728\u6a21\u62df\u73af\u5883\u6d4b\u8bd5\u6709\u6548\uff0c\u80fd\u52a9\u529b\u7cfb\u7edf\u9002\u5e94\u73af\u5883\u3002", "motivation": "\u89e3\u51b3\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u5608\u6742\u3001\u751f\u6001\u6709\u6548\u573a\u666f\u4e2d\u56e0\u4f9d\u8d56\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u5956\u52b1\u800c\u8868\u73b0\u8106\u5f31\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u56e0\u679c\u884c\u52a8\u5f71\u54cd\u5206\u6570\uff08CAIS\uff09\uff0c\u901a\u8fc7\u6d4b\u91cf\u6761\u4ef6\u5206\u5e03\u4e0e\u57fa\u7ebf\u5206\u5e03\u76841 - Wasserstein\u8ddd\u79bb\u91cf\u5316\u52a8\u4f5c\u5f71\u54cd\u3002", "result": "\u5728\u6a21\u62df\u5a74\u513f - \u79fb\u52a8\u73af\u5883\u4e2d\uff0cCAIS\u80fd\u8fc7\u6ee4\u566a\u97f3\u3001\u8bc6\u522b\u5f71\u54cd\u3001\u5b66\u4e60\u6b63\u786e\u7b56\u7565\uff0c\u7ed3\u5408\u60ca\u559c\u4fe1\u53f7\u53ef\u91cd\u73b0\u201c\u706d\u7edd\u7206\u53d1\u201d\u73b0\u8c61\u3002", "conclusion": "\u660e\u786e\u63a8\u65ad\u56e0\u679c\u5173\u7cfb\u662f\u57f9\u517b\u5f3a\u5927\u4ee3\u7406\u611f\u7684\u5173\u952e\u673a\u5236\uff0c\u4e3a\u66f4\u5177\u9002\u5e94\u6027\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5fc3\u7406\u5b66\u4e0a\u5408\u7406\u7684\u6846\u67b6\u3002"}}
{"id": "2507.15663", "pdf": "https://arxiv.org/pdf/2507.15663", "abs": "https://arxiv.org/abs/2507.15663", "authors": ["Giordano d'Aloisio", "Tosin Fadahunsi", "Jay Choy", "Rebecca Moussa", "Federica Sarro"], "title": "SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Background: Text-to-image generation models are widely used across numerous\ndomains. Among these models, Stable Diffusion (SD) - an open-source\ntext-to-image generation model - has become the most popular, producing over 12\nbillion images annually. However, the widespread use of these models raises\nconcerns regarding their social and environmental sustainability.\n  Aims: To reduce the harm that SD models may have on society and the\nenvironment, we introduce SustainDiffusion, a search-based approach designed to\nenhance the social and environmental sustainability of SD models.\n  Method: SustainDiffusion searches the optimal combination of hyperparameters\nand prompt structures that can reduce gender and ethnic bias in generated\nimages while also lowering the energy consumption required for image\ngeneration. Importantly, SustainDiffusion maintains image quality comparable to\nthat of the original SD model.\n  Results: We conduct a comprehensive empirical evaluation of SustainDiffusion,\ntesting it against six different baselines using 56 different prompts. Our\nresults demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%,\nethnic bias by 59%, and energy consumption (calculated as the sum of CPU and\nGPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are\nconsistent across multiple runs and can be generalised to various prompts.\n  Conclusions: With SustainDiffusion, we demonstrate how enhancing the social\nand environmental sustainability of text-to-image generation models is possible\nwithout fine-tuning or changing the model's architecture.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faSustainDiffusion\u65b9\u6cd5\uff0c\u53ef\u5728\u4e0d\u6539\u53d8\u6a21\u578b\u67b6\u6784\u4e0b\u63d0\u5347Stable Diffusion\u7684\u793e\u4f1a\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\uff0c\u51cf\u5c11\u504f\u89c1\u4e0e\u80fd\u8017\u3002", "motivation": "\u964d\u4f4eStable Diffusion\u6a21\u578b\u5bf9\u793e\u4f1a\u548c\u73af\u5883\u7684\u5371\u5bb3\uff0c\u63d0\u5347\u5176\u793e\u4f1a\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u3002", "method": "SustainDiffusion\u641c\u7d22\u6700\u4f18\u8d85\u53c2\u6570\u548c\u63d0\u793a\u7ed3\u6784\u7ec4\u5408\uff0c\u964d\u4f4e\u751f\u6210\u56fe\u50cf\u7684\u6027\u522b\u548c\u79cd\u65cf\u504f\u89c1\uff0c\u540c\u65f6\u964d\u4f4e\u80fd\u8017\uff0c\u4e14\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u3002", "result": "\u7ecf\u6d4b\u8bd5\uff0cSustainDiffusion\u53ef\u4f7fSD3\u7684\u6027\u522b\u504f\u89c1\u964d\u4f4e68%\u3001\u79cd\u65cf\u504f\u89c1\u964d\u4f4e59%\u3001\u80fd\u8017\u964d\u4f4e48%\uff0c\u7ed3\u679c\u7a33\u5b9a\u4e14\u53ef\u6cdb\u5316\u3002", "conclusion": "\u4e0d\u8fdb\u884c\u5fae\u8c03\u6216\u6539\u53d8\u6a21\u578b\u67b6\u6784\u4e5f\u80fd\u63d0\u5347\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u793e\u4f1a\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2507.15638", "pdf": "https://arxiv.org/pdf/2507.15638", "abs": "https://arxiv.org/abs/2507.15638", "authors": ["Florentin Goyens", "P. -A. Absil", "Florian Feppon"], "title": "Geometric design of the tangent term in landing algorithms for orthogonality constraints", "categories": ["math.OC", "stat.ML"], "comment": "To appear in GSI 2025 proceedings (https://conference-gsi.org/)", "summary": "We propose a family a metrics over the set of full-rank $n\\times p$ real\nmatrices, and apply them to the landing framework for optimization under\northogonality constraints. The family of metrics we propose is a natural\nextension of the $\\beta$-metric, defined on the Stiefel manifold.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u7ec4\u5168\u79e9\u77e9\u9635\u5ea6\u91cf\u5e76\u5e94\u7528\u4e8e\u6b63\u4ea4\u7ea6\u675f\u4f18\u5316\u7684\u7740\u9646\u6846\u67b6", "motivation": "\u5728\u6b63\u4ea4\u7ea6\u675f\u4f18\u5316\u9886\u57df\u5f15\u5165\u5408\u9002\u7684\u5ea6\u91cf", "method": "\u63d0\u51fa\u4e00\u7ec4\u5ea6\u91cf\uff0c\u662fStiefel\u6d41\u5f62\u4e0a\u03b2 - \u5ea6\u91cf\u7684\u81ea\u7136\u6269\u5c55", "result": "\u65e0\u660e\u786e\u63d0\u53ca", "conclusion": "\u65e0\u660e\u786e\u63d0\u53ca"}}
{"id": "2507.15120", "pdf": "https://arxiv.org/pdf/2507.15120", "abs": "https://arxiv.org/abs/2507.15120", "authors": ["Stefan Borgwardt", "Duy Nhu", "Gabriele R\u00f6ger"], "title": "Automated planning with ontologies under coherence update semantics", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Standard automated planning employs first-order formulas under closed-world\nsemantics to achieve a goal with a given set of actions from an initial state.\nWe follow a line of research that aims to incorporate background knowledge into\nautomated planning problems, for example, by means of ontologies, which are\nusually interpreted under open-world semantics. We present a new approach for\nplanning with DL-Lite ontologies that combines the advantages of ontology-based\naction conditions provided by explicit-input knowledge and action bases (eKABs)\nand ontology-aware action effects under the coherence update semantics. We show\nthat the complexity of the resulting formalism is not higher than that of\nprevious approaches and provide an implementation via a polynomial compilation\ninto classical planning. An evaluation of existing and new benchmarks examines\nthe performance of a planning system on different variants of our compilation.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408DL - Lite\u672c\u4f53\u7684\u89c4\u5212\u65b0\u65b9\u6cd5\uff0c\u590d\u6742\u5ea6\u4e0d\u9ad8\u4e8e\u4ee5\u5f80\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u7f16\u8bd1\u5b9e\u73b0\u5e76\u8bc4\u4f30\u6027\u80fd\u3002", "motivation": "\u5c06\u80cc\u666f\u77e5\u8bc6\uff08\u5982\u672c\u4f53\uff09\u878d\u5165\u81ea\u52a8\u5316\u89c4\u5212\u95ee\u9898\uff0c\u56e0\u6807\u51c6\u81ea\u52a8\u5316\u89c4\u5212\u91c7\u7528\u5c01\u95ed\u4e16\u754c\u8bed\u4e49\uff0c\u800c\u672c\u4f53\u901a\u5e38\u662f\u5f00\u653e\u4e16\u754c\u8bed\u4e49\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u663e\u5f0f\u8f93\u5165\u77e5\u8bc6\u548c\u52a8\u4f5c\u5e93\uff08eKABs\uff09\u63d0\u4f9b\u7684\u57fa\u4e8e\u672c\u4f53\u7684\u52a8\u4f5c\u6761\u4ef6\u4ee5\u53ca\u8fde\u8d2f\u66f4\u65b0\u8bed\u4e49\u4e0b\u672c\u4f53\u611f\u77e5\u52a8\u4f5c\u6548\u679c\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u7f16\u8bd1\u4e3a\u7ecf\u5178\u89c4\u5212\u5b9e\u73b0\u3002", "result": "\u65b0\u5f62\u5f0f\u4e3b\u4e49\u590d\u6742\u5ea6\u4e0d\u9ad8\u4e8e\u4ee5\u5f80\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u73b0\u6709\u548c\u65b0\u57fa\u51c6\u7684\u8bc4\u4f30\uff0c\u8003\u5bdf\u4e86\u89c4\u5212\u7cfb\u7edf\u5728\u4e0d\u540c\u7f16\u8bd1\u53d8\u4f53\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15666", "pdf": "https://arxiv.org/pdf/2507.15666", "abs": "https://arxiv.org/abs/2507.15666", "authors": ["Igor Turkin", "Lina Volobuieva", "Andriy Chukhray", "Oleksandr Liubimov"], "title": "Modeling CubeSat Storage Battery Discharge: Equivalent Circuit Versus Machine Learning Approaches", "categories": ["cs.SE"], "comment": "13 pages, 15 figures", "summary": "The subject of the article is the study and comparison of two approaches to\nmodelling the battery discharge of a CubeSat satellite: analytical using\nequivalent circuit and machine learning. The article aims to make a reasoned\nchoice of the approach to modelling the battery discharge of a CubeSat\nsatellite. Modelling the battery discharge of a satellite will enable the\nprediction of the consequences of disconnecting the autonomous power system and\nensure the fault tolerance of equipment in orbit. Therefore, the selected study\nis relevant and promising. This study focuses on the analysis of CubeSat\nsatellite data, based explicitly on orbital data samples of the power system,\nwhich include data available at the time of the article publication. The\ndataset contains data on the voltage, current, and temperature of the battery\nand solar panels attached to the five sides of the satellite. In this context,\ntwo approaches are considered: analytical modelling based on physical laws and\nmachine learning, which uses empirical data to create a predictive model.\nResults: A comparative analysis of the modeling results reveals that the\nequivalent circuit approach has the advantage of transparency, as it identifies\npossible parameters that facilitate understanding of the relationships.\nHowever, the model is less flexible to environmental changes or non-standard\nsatellite behavior. The machine learning model demonstrated more accurate\nresults, as it can account for complex dependencies and adapt to actual\nconditions, even when they deviate from theoretical assumptions.", "AI": {"tldr": "\u6587\u7ae0\u7814\u7a76\u6bd4\u8f83\u5206\u6790\u7b49\u6548\u7535\u8def\u548c\u673a\u5668\u5b66\u4e60\u4e24\u79cd\u65b9\u6cd5\u5bf9CubeSat\u536b\u661f\u7535\u6c60\u653e\u7535\u5efa\u6a21\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7ed3\u679c\u66f4\u51c6\u786e\u3002", "motivation": "\u4e3aCubeSat\u536b\u661f\u7535\u6c60\u653e\u7535\u5efa\u6a21\u65b9\u6cd5\u505a\u51fa\u5408\u7406\u9009\u62e9\uff0c\u9884\u6d4b\u81ea\u4e3b\u7535\u6e90\u7cfb\u7edf\u65ad\u5f00\u540e\u679c\uff0c\u786e\u4fdd\u8f68\u9053\u8bbe\u5907\u5bb9\u9519\u6027\u3002", "method": "\u5206\u6790CubeSat\u536b\u661f\u6570\u636e\uff0c\u8003\u8651\u57fa\u4e8e\u7269\u7406\u5b9a\u5f8b\u7684\u89e3\u6790\u5efa\u6a21\u548c\u5229\u7528\u7ecf\u9a8c\u6570\u636e\u521b\u5efa\u9884\u6d4b\u6a21\u578b\u7684\u673a\u5668\u5b66\u4e60\u4e24\u79cd\u65b9\u6cd5\u3002", "result": "\u7b49\u6548\u7535\u8def\u65b9\u6cd5\u5177\u6709\u900f\u660e\u6027\u4f18\u52bf\uff0c\u4f46\u5bf9\u73af\u5883\u53d8\u5316\u548c\u975e\u6807\u51c6\u536b\u661f\u884c\u4e3a\u9002\u5e94\u6027\u5dee\uff1b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7ed3\u679c\u66f4\u51c6\u786e\uff0c\u80fd\u9002\u5e94\u5b9e\u9645\u60c5\u51b5\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u53ef\u63a8\u6d4b\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728CubeSat\u536b\u661f\u7535\u6c60\u653e\u7535\u5efa\u6a21\u4e0a\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2507.14503", "pdf": "https://arxiv.org/pdf/2507.14503", "abs": "https://arxiv.org/abs/2507.14503", "authors": ["Jiequan Cui", "Beier Zhu", "Qingshan Xu", "Xiaogang Xu", "Pengguang Chen", "Xiaojuan Qi", "Bei Yu", "Hanwang Zhang", "Richang Hong"], "title": "Generative Distribution Distillation", "categories": ["cs.LG", "cs.CV"], "comment": "Technique report", "summary": "In this paper, we formulate the knowledge distillation (KD) as a conditional\ngenerative problem and propose the \\textit{Generative Distribution Distillation\n(GenDD)} framework. A naive \\textit{GenDD} baseline encounters two major\nchallenges: the curse of high-dimensional optimization and the lack of semantic\nsupervision from labels. To address these issues, we introduce a \\textit{Split\nTokenization} strategy, achieving stable and effective unsupervised KD.\nAdditionally, we develop the \\textit{Distribution Contraction} technique to\nintegrate label supervision into the reconstruction objective. Our theoretical\nproof demonstrates that \\textit{GenDD} with \\textit{Distribution Contraction}\nserves as a gradient-level surrogate for multi-task learning, realizing\nefficient supervised training without explicit classification loss on\nmulti-step sampling image representations. To evaluate the effectiveness of our\nmethod, we conduct experiments on balanced, imbalanced, and unlabeled data.\nExperimental results show that \\textit{GenDD} performs competitively in the\nunsupervised setting, significantly surpassing KL baseline by \\textbf{16.29\\%}\non ImageNet validation set. With label supervision, our ResNet-50 achieves\n\\textbf{82.28\\%} top-1 accuracy on ImageNet in 600 epochs training,\nestablishing a new state-of-the-art.", "AI": {"tldr": "\u672c\u6587\u5c06\u77e5\u8bc6\u84b8\u998f\u8868\u8ff0\u4e3a\u6761\u4ef6\u751f\u6210\u95ee\u9898\uff0c\u63d0\u51faGenDD\u6846\u67b6\uff0c\u5f15\u5165Split Tokenization\u7b56\u7565\u548cDistribution Contraction\u6280\u672f\uff0c\u5728\u591a\u7c7b\u578b\u6570\u636e\u4e0a\u5b9e\u9a8c\u6548\u679c\u597d\u3002", "motivation": "\u89e3\u51b3\u6734\u7d20GenDD\u57fa\u7ebf\u9762\u4e34\u7684\u9ad8\u7ef4\u4f18\u5316\u96be\u9898\u548c\u7f3a\u4e4f\u6807\u7b7e\u8bed\u4e49\u76d1\u7763\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faGenDD\u6846\u67b6\uff0c\u5f15\u5165Split Tokenization\u7b56\u7565\u5b9e\u73b0\u65e0\u76d1\u7763KD\uff0c\u5f00\u53d1Distribution Contraction\u6280\u672f\u5c06\u6807\u7b7e\u76d1\u7763\u878d\u5165\u91cd\u5efa\u76ee\u6807\u3002", "result": "GenDD\u5728\u65e0\u76d1\u7763\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728ImageNet\u9a8c\u8bc1\u96c6\u4e0a\u663e\u8457\u8d85\u8d8aKL\u57fa\u7ebf\uff1b\u6709\u6807\u7b7e\u76d1\u7763\u65f6\uff0cResNet - 50\u5728600\u8f6e\u8bad\u7ec3\u540e\u8fbe\u523082.28%\u7684top - 1\u51c6\u786e\u7387\u3002", "conclusion": "GenDD\u662f\u6709\u6548\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u5728\u65e0\u76d1\u7763\u548c\u6709\u76d1\u7763\u573a\u666f\u90fd\u6709\u4f18\u5f02\u8868\u73b0\u3002"}}
{"id": "2507.15678", "pdf": "https://arxiv.org/pdf/2507.15678", "abs": "https://arxiv.org/abs/2507.15678", "authors": ["Amine Mohamed Aboussalah", "Abdessalam Ed-dib"], "title": "GeoHNNs: Geometric Hamiltonian Neural Networks", "categories": ["cs.LG", "math.DG", "math.DS", "math.SG", "stat.ML"], "comment": null, "summary": "The fundamental laws of physics are intrinsically geometric, dictating the\nevolution of systems through principles of symmetry and conservation. While\nmodern machine learning offers powerful tools for modeling complex dynamics\nfrom data, common methods often ignore this underlying geometric fabric.\nPhysics-informed neural networks, for instance, can violate fundamental\nphysical principles, leading to predictions that are unstable over long\nperiods, particularly for high-dimensional and chaotic systems. Here, we\nintroduce \\textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework\nthat learns dynamics by explicitly encoding the geometric priors inherent to\nphysical laws. Our approach enforces two fundamental structures: the Riemannian\ngeometry of inertia, by parameterizing inertia matrices in their natural\nmathematical space of symmetric positive-definite matrices, and the symplectic\ngeometry of phase space, using a constrained autoencoder to ensure the\npreservation of phase space volume in a reduced latent space. We demonstrate\nthrough experiments on systems ranging from coupled oscillators to\nhigh-dimensional deformable objects that GeoHNN significantly outperforms\nexisting models. It achieves superior long-term stability, accuracy, and energy\nconservation, confirming that embedding the geometry of physics is not just a\ntheoretical appeal but a practical necessity for creating robust and\ngeneralizable models of the physical world.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Geometric Hamiltonian Neural Networks (GeoHNN)\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7f16\u7801\u7269\u7406\u5b9a\u5f8b\u51e0\u4f55\u5148\u9a8c\u5b66\u4e60\u52a8\u529b\u5b66\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5e38\u89c1\u65b9\u6cd5\u5e38\u5ffd\u7565\u7269\u7406\u5e95\u5c42\u51e0\u4f55\u7ed3\u6784\uff0c\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u53ef\u80fd\u8fdd\u53cd\u57fa\u672c\u7269\u7406\u539f\u7406\uff0c\u5bfc\u81f4\u957f\u671f\u9884\u6d4b\u4e0d\u7a33\u5b9a\u3002", "method": "\u5f15\u5165GeoHNN\u6846\u67b6\uff0c\u5f3a\u5236\u5b9e\u73b0\u4e24\u79cd\u57fa\u672c\u7ed3\u6784\uff1a\u901a\u8fc7\u5728\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u81ea\u7136\u6570\u5b66\u7a7a\u95f4\u4e2d\u53c2\u6570\u5316\u60ef\u6027\u77e9\u9635\u5b9e\u73b0\u60ef\u6027\u7684\u9ece\u66fc\u51e0\u4f55\uff1b\u4f7f\u7528\u7ea6\u675f\u81ea\u52a8\u7f16\u7801\u5668\u786e\u4fdd\u5728\u964d\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u76f8\u7a7a\u95f4\u4f53\u79ef\u5b88\u6052\uff0c\u4ee5\u5b9e\u73b0\u76f8\u7a7a\u95f4\u7684\u8f9b\u51e0\u4f55\u3002", "result": "\u5728\u4ece\u8026\u5408\u632f\u5b50\u5230\u9ad8\u7ef4\u53ef\u53d8\u5f62\u7269\u4f53\u7b49\u7cfb\u7edf\u7684\u5b9e\u9a8c\u4e2d\uff0cGeoHNN\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u957f\u671f\u7a33\u5b9a\u6027\u3001\u51c6\u786e\u6027\u548c\u80fd\u91cf\u5b88\u6052\u3002", "conclusion": "\u5d4c\u5165\u7269\u7406\u51e0\u4f55\u4e0d\u4ec5\u5177\u6709\u7406\u8bba\u5438\u5f15\u529b\uff0c\u4e5f\u662f\u521b\u5efa\u7269\u7406\u4e16\u754c\u7a33\u5065\u4e14\u53ef\u6cdb\u5316\u6a21\u578b\u7684\u5b9e\u9645\u5fc5\u8981\u6761\u4ef6\u3002"}}
{"id": "2507.15140", "pdf": "https://arxiv.org/pdf/2507.15140", "abs": "https://arxiv.org/abs/2507.15140", "authors": ["Mohammad Mashayekhi", "Sara Ahmadi Majd", "Arian AmirAmjadi", "Parsa Hosseini"], "title": "Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis", "categories": ["cs.AI"], "comment": null, "summary": "The diagnosis of oral diseases presents a problematic clinical challenge,\ncharacterized by a wide spectrum of pathologies with overlapping\nsymptomatology. To address this, we developed Clinical Semantic Intelligence\n(CSI), a novel artificial intelligence framework that diagnoses 118 different\noral diseases by computationally modeling the cognitive processes of an expert\nclinician. Our core hypothesis is that moving beyond simple pattern matching to\nemulate expert reasoning is critical to building clinically useful diagnostic\naids.\n  CSI's architecture integrates a fine-tuned multimodal CLIP model with a\nspecialized ChatGLM-6B language model. This system executes a Hierarchical\nDiagnostic Reasoning Tree (HDRT), a structured framework that distills the\nsystematic, multi-step logic of differential diagnosis. The framework operates\nin two modes: a Fast Mode for rapid screening and a Standard Mode that\nleverages the full HDRT for an interactive and in-depth diagnostic workup.\n  To train and validate our system, we curated a primary dataset of 4,310\nimages, supplemented by an external hold-out set of 176 images for final\nvalidation. A clinically-informed augmentation strategy expanded our training\ndata to over 30,000 image-text pairs. On a 431-image internal test set, CSI's\nFast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the\nHDRT-driven Standard Mode. The performance gain is directly attributable to the\nhierarchical reasoning process. Herein, we detail the architectural philosophy,\ndevelopment, and rigorous evaluation of the CSI framework.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e34\u5e8a\u8bed\u4e49\u667a\u80fd\uff08CSI\uff09\u6846\u67b6\u8bca\u65ad118\u79cd\u53e3\u8154\u75be\u75c5\uff0c\u4ecb\u7ecd\u67b6\u6784\u3001\u8bad\u7ec3\u9a8c\u8bc1\u65b9\u6cd5\u53ca\u6027\u80fd\u3002", "motivation": "\u53e3\u8154\u75be\u75c5\u8bca\u65ad\u6709\u6311\u6218\uff0c\u75c7\u72b6\u91cd\u53e0\uff0c\u9700\u5f00\u53d1\u4e34\u5e8a\u6709\u7528\u7684\u8bca\u65ad\u8f85\u52a9\u5de5\u5177\u3002", "method": "\u96c6\u6210\u5fae\u8c03\u591a\u6a21\u6001CLIP\u6a21\u578b\u548cChatGLM - 6B\u8bed\u8a00\u6a21\u578b\uff0c\u6267\u884c\u5206\u5c42\u8bca\u65ad\u63a8\u7406\u6811\uff08HDRT\uff09\uff0c\u6709\u5feb\u901f\u548c\u6807\u51c6\u4e24\u79cd\u6a21\u5f0f\uff1b\u75284310\u5f20\u56fe\u50cf\u8bad\u7ec3\uff0c176\u5f20\u56fe\u50cf\u9a8c\u8bc1\uff0c\u6269\u5145\u523030000\u591a\u56fe\u50cf\u6587\u672c\u5bf9\u3002", "result": "\u5feb\u901f\u6a21\u5f0f\u5728431\u5f20\u5185\u90e8\u6d4b\u8bd5\u96c6\u4e0a\u51c6\u786e\u738773.4%\uff0c\u6807\u51c6\u6a21\u5f0f\u8fbe89.5%\u3002", "conclusion": "\u8be6\u7ec6\u9610\u8ff0\u4e86CSI\u6846\u67b6\u67b6\u6784\u7406\u5ff5\u3001\u5f00\u53d1\u548c\u8bc4\u4f30\uff0c\u5206\u5c42\u63a8\u7406\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.15671", "pdf": "https://arxiv.org/pdf/2507.15671", "abs": "https://arxiv.org/abs/2507.15671", "authors": ["Jinyao Guo", "Chengpeng Wang", "Dominic Deluca", "Jinjie Liu", "Zhuo Zhang", "Xiangyu Zhang"], "title": "BugScope: Learn to Find Bugs Like Human", "categories": ["cs.SE"], "comment": "19 pages, 2 figure, 6 tables, 4 listings", "summary": "Detecting software bugs remains a fundamental challenge due to the extensive\ndiversity of real-world defects. Traditional static analysis tools often rely\non symbolic workflows, which restrict their coverage and hinder adaptability to\ncustomized bugs with diverse anti-patterns. While recent advances incorporate\nlarge language models (LLMs) to enhance bug detection, these methods continue\nto struggle with sophisticated bugs and typically operate within limited\nanalysis contexts. To address these challenges, we propose BugScope, an\nLLM-driven multi-agent system that emulates how human auditors learn new bug\npatterns from representative examples and apply that knowledge during code\nauditing. Given a set of examples illustrating both buggy and non-buggy\nbehaviors, BugScope synthesizes a retrieval strategy to extract relevant\ndetection contexts via program slicing and then constructs a tailored detection\nprompt to guide accurate reasoning by the LLM. Our evaluation on a curated\ndataset of 40 real-world bugs drawn from 21 widely-used open-source projects\ndemonstrates that BugScope achieves 87.04% precision and 90.00% recall,\nsurpassing state-of-the-art industrial tools by 0.44 in F1 score. Further\ntesting on large-scale open-source systems, including the Linux kernel,\nuncovered 141 previously unknown bugs, of which 78 have been fixed and 7\nconfirmed by developers, highlighting BugScope's substantial practical impact.", "AI": {"tldr": "\u63d0\u51faLLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edfBugScope\u8fdb\u884c\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u8bc4\u4f30\u6548\u679c\u8d85\u73b0\u6709\u5de5\u5177\uff0c\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u53d1\u73b0\u5927\u91cf\u672a\u77e5\u6f0f\u6d1e\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177\u8986\u76d6\u8303\u56f4\u6709\u9650\uff0c\u73b0\u6709\u7ed3\u5408LLM\u7684\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u590d\u6742\u6f0f\u6d1e\u4e14\u5206\u6790\u4e0a\u4e0b\u6587\u53d7\u9650\u3002", "method": "\u4ee5\u4ee3\u8868\u793a\u4f8b\u5b66\u4e60\u65b0\u6f0f\u6d1e\u6a21\u5f0f\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5207\u7247\u5408\u6210\u68c0\u7d22\u7b56\u7565\u63d0\u53d6\u76f8\u5173\u68c0\u6d4b\u4e0a\u4e0b\u6587\uff0c\u6784\u5efa\u5b9a\u5236\u68c0\u6d4b\u63d0\u793a\u5f15\u5bfcLLM\u63a8\u7406\u3002", "result": "\u572840\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\uff0cBugScope\u7cbe\u786e\u738787.04%\u3001\u53ec\u56de\u738790.00%\uff0cF1\u5206\u6570\u8d85\u73b0\u6709\u5de5\u51770.44\uff1b\u5728\u5927\u89c4\u6a21\u5f00\u6e90\u7cfb\u7edf\u53d1\u73b0141\u4e2a\u672a\u77e5\u6f0f\u6d1e\uff0c78\u4e2a\u5df2\u4fee\u590d\uff0c7\u4e2a\u83b7\u5f00\u53d1\u8005\u786e\u8ba4\u3002", "conclusion": "BugScope\u6709\u663e\u8457\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.14516", "pdf": "https://arxiv.org/pdf/2507.14516", "abs": "https://arxiv.org/abs/2507.14516", "authors": ["Jeyoung Lee", "Hochul Kang"], "title": "SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": null, "summary": "We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware\nmetric function for time series self-supervised representation learning. Most\nSelf-Supervised Learning (SSL) methods for signals commonly adopt\ndistance-based objectives such as mean squared error (MSE), which are sensitive\nto amplitude, invariant to waveform polarity, and unbounded in scale. These\nproperties hinder semantic alignment and reduce interpretability. SDSC\naddresses this by quantifying structural agreement between temporal signals\nbased on the intersection of signed amplitudes, derived from the Dice\nSimilarity Coefficient (DSC).Although SDSC is defined as a structure-aware\nmetric, it can be used as a loss by subtracting from 1 and applying a\ndifferentiable approximation of the Heaviside function for gradient-based\noptimization. A hybrid loss formulation is also proposed to combine SDSC with\nMSE, improving stability and preserving amplitude where necessary. Experiments\non forecasting and classification benchmarks demonstrate that SDSC-based\npre-training achieves comparable or improved performance over MSE, particularly\nin in-domain and low-resource scenarios. The results suggest that structural\nfidelity in signal representations enhances the semantic representation\nquality, supporting the consideration of structure-aware metrics as viable\nalternatives to conventional distance-based methods.", "AI": {"tldr": "\u63d0\u51fa\u4fe1\u53f7\u9ab0\u5b50\u76f8\u4f3c\u7cfb\u6570\uff08SDSC\uff09\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\uff0c\u7ed3\u5408\u6df7\u5408\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u9884\u6d4b\u548c\u5206\u7c7b\u57fa\u51c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u652f\u6301\u7ed3\u6784\u611f\u77e5\u6307\u6807\u4f5c\u4e3a\u4f20\u7edf\u8ddd\u79bb\u65b9\u6cd5\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u591a\u6570\u4fe1\u53f7\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u91c7\u7528\u57fa\u4e8e\u8ddd\u79bb\u7684\u76ee\u6807\u51fd\u6570\uff0c\u5b58\u5728\u5bf9\u5e45\u5ea6\u654f\u611f\u3001\u6ce2\u5f62\u6781\u6027\u4e0d\u53d8\u548c\u5c3a\u5ea6\u65e0\u754c\u7b49\u95ee\u9898\uff0c\u963b\u788d\u8bed\u4e49\u5bf9\u9f50\u548c\u964d\u4f4e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faSDSC\u91cf\u5316\u65f6\u95f4\u4fe1\u53f7\u7684\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u51cf\u53bb1\u5e76\u5e94\u7528Heaviside\u51fd\u6570\u7684\u53ef\u5fae\u8fd1\u4f3c\u4f5c\u4e3a\u635f\u5931\uff0c\u8fd8\u63d0\u51fa\u6df7\u5408\u635f\u5931\u516c\u5f0f\u7ed3\u5408SDSC\u548cMSE\u3002", "result": "\u57fa\u4e8eSDSC\u7684\u9884\u8bad\u7ec3\u5728\u9884\u6d4b\u548c\u5206\u7c7b\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e0eMSE\u76f8\u5f53\u6216\u66f4\u597d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u57df\u5185\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u3002", "conclusion": "\u4fe1\u53f7\u8868\u793a\u4e2d\u7684\u7ed3\u6784\u4fdd\u771f\u5ea6\u53ef\u63d0\u9ad8\u8bed\u4e49\u8868\u793a\u8d28\u91cf\uff0c\u7ed3\u6784\u611f\u77e5\u6307\u6807\u53ef\u4f5c\u4e3a\u4f20\u7edf\u8ddd\u79bb\u65b9\u6cd5\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.15825", "pdf": "https://arxiv.org/pdf/2507.15825", "abs": "https://arxiv.org/abs/2507.15825", "authors": ["Yu Gui", "Ying Jin", "Yash Nair", "Zhimei Ren"], "title": "ACS: An interactive framework for conformal selection", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "This paper presents adaptive conformal selection (ACS), an interactive\nframework for model-free selection with guaranteed error control. Building on\nconformal selection (Jin and Cand\\`es, 2023b), ACS generalizes the approach to\nsupport human-in-the-loop adaptive data analysis. Under the ACS framework, we\ncan partially reuse the data to boost the selection power, make decisions on\nthe fly while exploring the data, and incorporate new information or\npreferences as they arise. The key to ACS is a carefully designed principle\nthat controls the information available for decision making, allowing the data\nanalyst to explore the data adaptively while maintaining rigorous control of\nthe false discovery rate (FDR). Based on the ACS framework, we provide concrete\nselection algorithms for various goals, including model update/selection,\ndiversified selection, and incorporating newly available labeled data. The\neffectiveness of ACS is demonstrated through extensive numerical simulations\nand real-data applications in large language model (LLM) deployment and drug\ndiscovery.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u5171\u5f62\u9009\u62e9\uff08ACS\uff09\u6846\u67b6\uff0c\u652f\u6301\u4eba\u5728\u73af\u81ea\u9002\u5e94\u6570\u636e\u5206\u6790\uff0c\u6709\u5177\u4f53\u7b97\u6cd5\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u5728\u6a21\u578b\u65e0\u5173\u9009\u62e9\u4e2d\u5b9e\u73b0\u6709\u4fdd\u8bc1\u7684\u8bef\u5dee\u63a7\u5236\uff0c\u652f\u6301\u4eba\u5728\u73af\u81ea\u9002\u5e94\u6570\u636e\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u5171\u5f62\u9009\u62e9\u8fdb\u884c\u63a8\u5e7f\uff0c\u8bbe\u8ba1\u63a7\u5236\u51b3\u7b56\u53ef\u7528\u4fe1\u606f\u7684\u539f\u5219\uff0c\u7ed9\u51fa\u4e0d\u540c\u76ee\u6807\u7684\u5177\u4f53\u9009\u62e9\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u6570\u503c\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u5e94\u7528\uff0c\u8bc1\u660e\u4e86ACS\u5728\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u548c\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "ACS\u6846\u67b6\u80fd\u5728\u81ea\u9002\u5e94\u63a2\u7d22\u6570\u636e\u7684\u540c\u65f6\u4e25\u683c\u63a7\u5236\u9519\u8bef\u53d1\u73b0\u7387\uff0c\u53ef\u7528\u4e8e\u591a\u79cd\u9009\u62e9\u4efb\u52a1\u3002"}}
{"id": "2507.15143", "pdf": "https://arxiv.org/pdf/2507.15143", "abs": "https://arxiv.org/abs/2507.15143", "authors": ["Abderaouf Bahi", "Amel Ourici"], "title": "Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "This paper investigates the feasibility of human mobility in The Line, a\nproposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess\nwhether citizens can move freely within this unprecedented urban topology, we\ndevelop a hybrid simulation framework that integrates agent-based modeling,\nreinforcement learning, supervised learning, and graph neural networks. The\nsimulation captures multi-modal transportation behaviors across 50 vertical\nlevels and varying density scenarios using both synthetic data and real-world\ntraces from high-density cities. Our experiments reveal that with the full\nAI-integrated architecture, agents achieved an average commute time of 7.8 to\n8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index\nof over 91 percent, even during peak congestion periods. Ablation studies\nconfirmed that the removal of intelligent modules such as reinforcement\nlearning or graph neural networks significantly degrades performance, with\ncommute times increasing by up to 85 percent and reachability falling below 70\npercent. Environmental modeling further demonstrated low energy consumption and\nminimal CO2 emissions when electric modes are prioritized. The findings suggest\nthat freedom of movement is not only conceptually achievable in The Line, but\nalso operationally realistic if supported by adaptive AI systems, sustainable\ninfrastructure, and real-time feedback loops.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6c99\u7279\u963f\u62c9\u4f2fThe Line\u7ebf\u6027\u667a\u6167\u57ce\u5e02\u4e2d\u4eba\u7c7b\u79fb\u52a8\u7684\u53ef\u884c\u6027\uff0c\u5f00\u53d1\u6df7\u5408\u4eff\u771f\u6846\u67b6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8868\u660e\u6709AI\u652f\u6301\u65f6\u79fb\u52a8\u81ea\u7531\u53ef\u5b9e\u73b0\u4e14\u6027\u80fd\u4f18\u3001\u80fd\u8017\u4f4e\u3002", "motivation": "\u8bc4\u4f30\u5728\u524d\u6240\u672a\u6709\u7684\u7ebf\u6027\u57ce\u5e02\u62d3\u6251\u4e2d\uff0c\u5e02\u6c11\u80fd\u5426\u81ea\u7531\u79fb\u52a8\u3002", "method": "\u5f00\u53d1\u96c6\u6210\u57fa\u4e8e\u4ee3\u7406\u7684\u5efa\u6a21\u3001\u5f3a\u5316\u5b66\u4e60\u3001\u76d1\u7763\u5b66\u4e60\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6df7\u5408\u4eff\u771f\u6846\u67b6\uff0c\u7ed3\u5408\u5408\u6210\u6570\u636e\u548c\u9ad8\u5bc6\u5ea6\u57ce\u5e02\u7684\u771f\u5b9e\u8f68\u8ff9\u6570\u636e\uff0c\u8fdb\u884c\u591a\u6a21\u5f0f\u4ea4\u901a\u884c\u4e3a\u6a21\u62df\u3002", "result": "\u5168AI\u96c6\u6210\u67b6\u6784\u4e0b\uff0c\u5e73\u5747\u901a\u52e4\u65f6\u95f47.8 - 8.4\u5206\u949f\uff0c\u6ee1\u610f\u5ea6\u8d8589%\uff0c\u53ef\u8fbe\u6027\u8d8591%\uff1b\u79fb\u9664\u667a\u80fd\u6a21\u5757\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff1b\u4f18\u5148\u4f7f\u7528\u7535\u52a8\u6a21\u5f0f\u80fd\u8017\u4f4e\u3001\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u5c11\u3002", "conclusion": "\u5728\u81ea\u9002\u5e94AI\u7cfb\u7edf\u3001\u53ef\u6301\u7eed\u57fa\u7840\u8bbe\u65bd\u548c\u5b9e\u65f6\u53cd\u9988\u5faa\u73af\u7684\u652f\u6301\u4e0b\uff0cThe Line\u4e2d\u7684\u79fb\u52a8\u81ea\u7531\u4e0d\u4ec5\u5728\u6982\u5ff5\u4e0a\u53ef\u884c\uff0c\u5728\u64cd\u4f5c\u4e0a\u4e5f\u73b0\u5b9e\u3002"}}
{"id": "2507.15822", "pdf": "https://arxiv.org/pdf/2507.15822", "abs": "https://arxiv.org/abs/2507.15822", "authors": ["Li Huang", "Ilgiz Mustafin", "Marco Piccioni", "Alessandro Schena", "Reto Weber", "Bertrand Meyer"], "title": "Do AI models help produce verified bug fixes?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Among areas of software engineering where AI techniques -- particularly,\nLarge Language Models -- seem poised to yield dramatic improvements, an\nattractive candidate is Automatic Program Repair (APR), the production of\nsatisfactory corrections to software bugs. Does this expectation materialize in\npractice? How do we find out, making sure that proposed corrections actually\nwork? If programmers have access to LLMs, how do they actually use them to\ncomplement their own skills?\n  To answer these questions, we took advantage of the availability of a\nprogram-proving environment, which formally determines the correctness of\nproposed fixes, to conduct a study of program debugging with two randomly\nassigned groups of programmers, one with access to LLMs and the other without,\nboth validating their answers through the proof tools. The methodology relied\non a division into general research questions (Goals in the Goal-Query-Metric\napproach), specific elements admitting specific answers (Queries), and\nmeasurements supporting these answers (Metrics). While applied so far to a\nlimited sample size, the results are a first step towards delineating a proper\nrole for AI and LLMs in providing guaranteed-correct fixes to program bugs.\n  These results caused surprise as compared to what one might expect from the\nuse of AI for debugging and APR. The contributions also include: a detailed\nmethodology for experiments in the use of LLMs for debugging, which other\nprojects can reuse; a fine-grain analysis of programmer behavior, made possible\nby the use of full-session recording; a definition of patterns of use of LLMs,\nwith 7 distinct categories; and validated advice for getting the best of LLMs\nfor debugging and Automatic Program Repair.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8AI\u5728\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u7a0b\u5e8f\u5458\u4f7f\u7528LLM\u8c03\u8bd5\u7a0b\u5e8f\u7684\u60c5\u51b5\uff0c\u5f97\u51fa\u521d\u6b65\u7ed3\u679c\u5e76\u7ed9\u51fa\u76f8\u5173\u8d21\u732e\u3002", "motivation": "\u63a2\u7a76AI\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u3001\u9a8c\u8bc1\u4fee\u590d\u65b9\u6848\u6709\u6548\u6027\u4ee5\u53ca\u7a0b\u5e8f\u5458\u5982\u4f55\u5229\u7528LLM\u8865\u5145\u81ea\u8eab\u6280\u80fd\u3002", "method": "\u5229\u7528\u7a0b\u5e8f\u8bc1\u660e\u73af\u5883\uff0c\u5c06\u7a0b\u5e8f\u5458\u968f\u673a\u5206\u4e3a\u6709LLM\u8bbf\u95ee\u6743\u9650\u548c\u65e0LLM\u8bbf\u95ee\u6743\u9650\u4e24\u7ec4\u8fdb\u884c\u8c03\u8bd5\u7814\u7a76\uff0c\u91c7\u7528\u76ee\u6807 - \u67e5\u8be2 - \u6307\u6807\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u4e0e\u4f7f\u7528AI\u8fdb\u884c\u8c03\u8bd5\u548c\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u9884\u671f\u4e0d\u540c\uff0c\u662f\u754c\u5b9aAI\u548cLLM\u5728\u63d0\u4f9b\u7a0b\u5e8f\u9519\u8bef\u4fee\u590d\u4e2d\u9002\u5f53\u89d2\u8272\u7684\u7b2c\u4e00\u6b65\u3002", "conclusion": "\u7ed9\u51fa\u4f7f\u7528LLM\u8fdb\u884c\u8c03\u8bd5\u5b9e\u9a8c\u7684\u8be6\u7ec6\u65b9\u6cd5\u3001\u5bf9\u7a0b\u5e8f\u5458\u884c\u4e3a\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u3001LLM\u4f7f\u7528\u6a21\u5f0f\u5b9a\u4e49\u548c\u6709\u6548\u5efa\u8bae\u3002"}}
{"id": "2507.14528", "pdf": "https://arxiv.org/pdf/2507.14528", "abs": "https://arxiv.org/abs/2507.14528", "authors": ["Ilias Tsoumas", "Dimitrios Bormpoudakis", "Vasileios Sitokonstantinou", "Athanasios Askitopoulos", "Andreas Kalogeras", "Charalampos Kontoes", "Ioannis Athanasiadis"], "title": "Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference", "categories": ["cs.LG"], "comment": "Accepted at KDD 2025 Workshop on Causal Inference and Machine\n  Learning in Practice", "summary": "In causal inference, whether through randomized controlled trials or\nobservational studies, access to both treated and control units is essential\nfor estimating the effect of a treatment on an outcome of interest. When\ntreatment assignment is random, the average treatment effect (ATE) can be\nestimated directly by comparing outcomes between groups. In non-randomized\nsettings, various techniques are employed to adjust for confounding and\napproximate the counterfactual scenario to recover an unbiased ATE. A common\nchallenge, especially in observational studies, is the absence of units clearly\nlabeled as controls-that is, units known not to have received the treatment. To\naddress this, we propose positive-unlabeled (PU) learning as a framework for\nidentifying, with high confidence, control units from a pool of unlabeled ones,\nusing only the available treated (positive) units. We evaluate this approach\nusing both simulated and real-world data. We construct a causal graph with\ndiverse relationships and use it to generate synthetic data under various\nscenarios, assessing how reliably the method recovers control groups that allow\nestimates of true ATE. We also apply our approach to real-world data on optimal\nsowing and fertilizer treatments in sustainable agriculture. Our findings show\nthat PU learning can successfully identify control (negative) units from\nunlabeled data based only on treated units and, through the resulting control\ngroup, estimate an ATE that closely approximates the true value. This work has\nimportant implications for observational causal inference, especially in fields\nwhere randomized experiments are difficult or costly. In domains such as earth,\nenvironmental, and agricultural sciences, it enables a plethora of\nquasi-experiments by leveraging available earth observation and climate data,\nparticularly when treated units are available but control units are lacking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528PU\u5b66\u4e60\u6846\u67b6\u4ece\u65e0\u6807\u7b7e\u6570\u636e\u4e2d\u8bc6\u522b\u5bf9\u7167\u7ec4\uff0c\u8bc4\u4f30\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u7684\u6548\u679c\uff0c\u7ed3\u679c\u663e\u793a\u5176\u80fd\u6709\u6548\u8bc6\u522b\u5bf9\u7167\u7ec4\u5e76\u4f30\u7b97\u63a5\u8fd1\u771f\u5b9e\u503c\u7684ATE\uff0c\u5bf9\u89c2\u6d4b\u56e0\u679c\u63a8\u65ad\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\uff0c\u7279\u522b\u662f\u89c2\u6d4b\u6027\u7814\u7a76\uff0c\u5e38\u7f3a\u4e4f\u660e\u786e\u6807\u8bb0\u7684\u5bf9\u7167\u7ec4\uff0c\u9700\u627e\u5230\u4ece\u65e0\u6807\u7b7e\u6570\u636e\u4e2d\u8bc6\u522b\u5bf9\u7167\u7ec4\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPU\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u4ec5\u6709\u7684\u5904\u7406\u7ec4\uff08\u9633\u6027\uff09\u5355\u5143\u4ece\u65e0\u6807\u7b7e\u5355\u5143\u4e2d\u8bc6\u522b\u5bf9\u7167\u7ec4\uff0c\u4f7f\u7528\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u8bc4\u4f30\u8be5\u65b9\u6cd5\uff0c\u6784\u5efa\u56e0\u679c\u56fe\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5c06\u65b9\u6cd5\u5e94\u7528\u4e8e\u53ef\u6301\u7eed\u519c\u4e1a\u771f\u5b9e\u6570\u636e\u3002", "result": "PU\u5b66\u4e60\u80fd\u4ec5\u57fa\u4e8e\u5904\u7406\u7ec4\u4ece\u65e0\u6807\u7b7e\u6570\u636e\u4e2d\u6210\u529f\u8bc6\u522b\u5bf9\u7167\u7ec4\uff0c\u901a\u8fc7\u6240\u5f97\u5bf9\u7167\u7ec4\u4f30\u7b97\u7684ATE\u63a5\u8fd1\u771f\u5b9e\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5bf9\u89c2\u6d4b\u56e0\u679c\u63a8\u65ad\u6709\u91cd\u8981\u610f\u4e49\uff0c\u80fd\u5728\u968f\u673a\u5b9e\u9a8c\u56f0\u96be\u6216\u6210\u672c\u9ad8\u7684\u9886\u57df\uff0c\u5982\u5730\u7403\u3001\u73af\u5883\u548c\u519c\u4e1a\u79d1\u5b66\uff0c\u5229\u7528\u73b0\u6709\u6570\u636e\u5f00\u5c55\u5927\u91cf\u51c6\u5b9e\u9a8c\u3002"}}
{"id": "2507.15842", "pdf": "https://arxiv.org/pdf/2507.15842", "abs": "https://arxiv.org/abs/2507.15842", "authors": ["Sara LaPlante", "Emilija Perkovi\u0107"], "title": "Identifying Conditional Causal Effects in MPDAGs", "categories": ["cs.AI", "stat.ME", "stat.ML"], "comment": "67 pages, 8 figures", "summary": "We consider identifying a conditional causal effect when a graph is known up\nto a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG\nrepresents an equivalence class of graphs that is restricted by background\nknowledge and where all variables in the causal model are observed. We provide\nthree results that address identification in this setting: an identification\nformula when the conditioning set is unaffected by treatment, a generalization\nof the well-known do calculus to the MPDAG setting, and an algorithm that is\ncomplete for identifying these conditional effects.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u56fe\u5df2\u77e5\u5230MPDAG\u65f6\u8bc6\u522b\u6761\u4ef6\u56e0\u679c\u6548\u5e94\uff0c\u7ed9\u51fa\u4e09\u4e2a\u76f8\u5173\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3\u5728\u56fe\u5df2\u77e5\u5230MPDAG\u60c5\u51b5\u4e0b\u7684\u6761\u4ef6\u56e0\u679c\u6548\u5e94\u8bc6\u522b\u95ee\u9898\u3002", "method": "\u63d0\u4f9b\u8bc6\u522b\u516c\u5f0f\u3001\u63a8\u5e7fdo\u6f14\u7b97\u5230MPDAG\u8bbe\u7f6e\u4ee5\u53ca\u7ed9\u51fa\u8bc6\u522b\u6761\u4ef6\u6548\u5e94\u7684\u5b8c\u6574\u7b97\u6cd5\u3002", "result": "\u5f97\u5230\u8bc6\u522b\u516c\u5f0f\u3001\u63a8\u5e7f\u7684do\u6f14\u7b97\u548c\u5b8c\u6574\u7b97\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u7528\u4e8e\u5728MPDAG\u8bbe\u7f6e\u4e0b\u8bc6\u522b\u6761\u4ef6\u56e0\u679c\u6548\u5e94\u3002"}}
{"id": "2507.15225", "pdf": "https://arxiv.org/pdf/2507.15225", "abs": "https://arxiv.org/abs/2507.15225", "authors": ["Yichi Zhou", "Jianqiu Zhao", "Yongxin Zhang", "Bohan Wang", "Siran Wang", "Luoxin Chen", "Jiahui Wang", "Haowei Chen", "Allan Jie", "Xinbo Zhang", "Haocheng Wang", "Luong Trung", "Rong Ye", "Phan Nhat Hoang", "Huishuai Zhang", "Peng Sun", "Hang Li"], "title": "Solving Formal Math Problems by Decomposition and Iterative Reflection", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "General-purpose Large Language Models (LLMs) have achieved remarkable success\nin intelligence, performing comparably to human experts on complex reasoning\ntasks such as coding and mathematical reasoning. However, generating formal\nproofs in specialized languages like Lean 4 remains a significant challenge for\nthese models, limiting their application in complex theorem proving and\nautomated verification. Current approaches typically require specializing\nmodels through fine-tuning on dedicated formal corpora, incurring high costs\nfor data collection and training. In this work, we introduce \\textbf{Delta\nProver}, an agent-based framework that orchestrates the interaction between a\ngeneral-purpose LLM and the Lean 4 proof environment. Delta Prover leverages\nthe reflection and reasoning capabilities of general-purpose LLMs to\ninteractively construct formal proofs in Lean 4, circumventing the need for\nmodel specialization. At its core, the agent integrates two novel,\ninterdependent components: an algorithmic framework for reflective\ndecomposition and iterative proof repair, and a custom Domain-Specific Language\n(DSL) built upon Lean 4 for streamlined subproblem management. \\textbf{Delta\nProver achieves a state-of-the-art 95.9\\% success rate on the miniF2F-test\nbenchmark, surpassing all existing approaches, including those requiring model\nspecialization.} Furthermore, Delta Prover exhibits a significantly stronger\ntest-time scaling law compared to standard Best-of-N proof strategies.\nCrucially, our findings demonstrate that general-purpose LLMs, when guided by\nan effective agentic structure, possess substantial untapped theorem-proving\ncapabilities. This presents a computationally efficient alternative to\nspecialized models for robust automated reasoning in formal environments.", "AI": {"tldr": "\u4ecb\u7ecdDelta Prover\u6846\u67b6\uff0c\u5229\u7528\u901a\u7528\u5927\u6a21\u578b\u5728Lean 4\u4e2d\u4ea4\u4e92\u5f0f\u6784\u5efa\u5f62\u5f0f\u8bc1\u660e\uff0c\u5728miniF2F - test\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f9795.9%\u6210\u529f\u7387\uff0c\u5c55\u793a\u901a\u7528\u5927\u6a21\u578b\u5b9a\u7406\u8bc1\u660e\u80fd\u529b\u3002", "motivation": "\u901a\u7528\u5927\u6a21\u578b\u5728\u751f\u6210\u5982Lean 4\u7b49\u4e13\u4e1a\u8bed\u8a00\u5f62\u5f0f\u8bc1\u660e\u65b9\u9762\u6709\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u5fae\u8c03\u6a21\u578b\uff0c\u6210\u672c\u9ad8\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4ee3\u7406\u7684Delta Prover\u6846\u67b6\uff0c\u6574\u5408\u53cd\u5c04\u5206\u89e3\u548c\u8fed\u4ee3\u8bc1\u660e\u4fee\u590d\u7b97\u6cd5\u6846\u67b6\u4ee5\u53ca\u81ea\u5b9a\u4e49DSL\uff0c\u534f\u8c03\u901a\u7528\u5927\u6a21\u578b\u4e0eLean 4\u8bc1\u660e\u73af\u5883\u4ea4\u4e92\u3002", "result": "Delta Prover\u5728miniF2F - test\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6210\u529f\u7387\u8fbe95.9%\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u65f6\u6269\u5c55\u6027\u66f4\u5f3a\u3002", "conclusion": "\u901a\u7528\u5927\u6a21\u578b\u5728\u6709\u6548\u4ee3\u7406\u7ed3\u6784\u5f15\u5bfc\u4e0b\u6709\u5f88\u5927\u5b9a\u7406\u8bc1\u660e\u80fd\u529b\uff0c\u662f\u5f62\u5f0f\u73af\u5883\u4e2d\u81ea\u52a8\u63a8\u7406\u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.15828", "pdf": "https://arxiv.org/pdf/2507.15828", "abs": "https://arxiv.org/abs/2507.15828", "authors": ["Mauro Marcelino", "Marcos Alves", "Bianca Trinkenreich", "Bruno Cartaxo", "S\u00e9rgio Soares", "Simone D. J. Barbosa", "Marcos Kalinowski"], "title": "Investigating the Use of LLMs for Evidence Briefings Generation in Software Engineering", "categories": ["cs.SE"], "comment": "ESEM 2025 Registered Report with an IPA (In Principle Acceptance) for\n  the Empirical Software Engineering journal", "summary": "[Context] An evidence briefing is a concise and objective transfer medium\nthat can present the main findings of a study to software engineers in the\nindustry. Although practitioners and researchers have deemed Evidence Briefings\nuseful, their production requires manual labor, which may be a significant\nchallenge to their broad adoption. [Goal] The goal of this registered report is\nto describe an experimental protocol for evaluating LLM-generated evidence\nbriefings for secondary studies in terms of content fidelity, ease of\nunderstanding, and usefulness, as perceived by researchers and practitioners,\ncompared to human-made briefings. [Method] We developed an RAG-based LLM tool\nto generate evidence briefings. We used the tool to automatically generate two\nevidence briefings that had been manually generated in previous research\nefforts. We designed a controlled experiment to evaluate how the LLM-generated\nbriefings compare to the human-made ones regarding perceived content fidelity,\nease of understanding, and usefulness. [Results] To be reported after the\nexperimental trials. [Conclusion] Depending on the experiment results.", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u4ecb\u7ecd\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u8bc1\u636e\u7b80\u62a5\u7684\u5b9e\u9a8c\u65b9\u6848\uff0c\u5c06\u5176\u4e0e\u4eba\u5de5\u7b80\u62a5\u5bf9\u6bd4\uff0c\u65b9\u6cd5\u662f\u5f00\u53d1\u57fa\u4e8eRAG\u7684\u5de5\u5177\u751f\u6210\u7b80\u62a5\u5e76\u8bbe\u8ba1\u5bf9\u7167\u5b9e\u9a8c\uff0c\u7ed3\u679c\u548c\u7ed3\u8bba\u5f85\u5b9e\u9a8c\u540e\u5f97\u51fa\u3002", "motivation": "\u8bc1\u636e\u7b80\u62a5\u867d\u6709\u7528\u4f46\u4eba\u5de5\u5236\u4f5c\u963b\u788d\u5176\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7b80\u62a5\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eRAG\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u751f\u6210\u8bc1\u636e\u7b80\u62a5\uff0c\u7528\u8be5\u5de5\u5177\u81ea\u52a8\u751f\u6210\u4e24\u4efd\u6b64\u524d\u4eba\u5de5\u5236\u4f5c\u7684\u7b80\u62a5\uff0c\u8bbe\u8ba1\u5bf9\u7167\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5f85\u5b9e\u9a8c\u540e\u62a5\u544a\u3002", "conclusion": "\u53d6\u51b3\u4e8e\u5b9e\u9a8c\u7ed3\u679c\u3002"}}
{"id": "2507.14529", "pdf": "https://arxiv.org/pdf/2507.14529", "abs": "https://arxiv.org/abs/2507.14529", "authors": ["Berkay Anahtarci", "Can Deha Kariksiz", "Naci Saldi"], "title": "Kernel Based Maximum Entropy Inverse Reinforcement Learning for Mean-Field Games", "categories": ["cs.LG", "math.OC", "91A16, 68T05, 49N45, 93E20, 46E22"], "comment": null, "summary": "We consider the maximum causal entropy inverse reinforcement learning problem\nfor infinite-horizon stationary mean-field games, in which we model the unknown\nreward function within a reproducing kernel Hilbert space. This allows the\ninference of rich and potentially nonlinear reward structures directly from\nexpert demonstrations, in contrast to most existing inverse reinforcement\nlearning approaches for mean-field games that typically restrict the reward\nfunction to a linear combination of a fixed finite set of basis functions. We\nalso focus on the infinite-horizon cost structure, whereas prior studies\nprimarily rely on finite-horizon formulations. We introduce a Lagrangian\nrelaxation to this maximum causal entropy inverse reinforcement learning\nproblem that enables us to reformulate it as an unconstrained log-likelihood\nmaximization problem, and obtain a solution \\lk{via} a gradient ascent\nalgorithm. To illustrate the theoretical consistency of the algorithm, we\nestablish the smoothness of the log-likelihood objective by proving the\nFr\\'echet differentiability of the related soft Bellman operators with respect\nto the parameters in the reproducing kernel Hilbert space. We demonstrate the\neffectiveness of our method on a mean-field traffic routing game, where it\naccurately recovers expert behavior.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u65e0\u9650\u671f\u5e73\u7a33\u5e73\u5747\u573a\u535a\u5f08\u7684\u6700\u5927\u56e0\u679c\u71b5\u9006\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u65b9\u6cd5\u5e76\u901a\u8fc7\u68af\u5ea6\u4e0a\u5347\u7b97\u6cd5\u6c42\u89e3\uff0c\u5728\u5e73\u5747\u573a\u4ea4\u901a\u8def\u7531\u535a\u5f08\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5e73\u5747\u573a\u535a\u5f08\u9006\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u591a\u5c06\u5956\u52b1\u51fd\u6570\u9650\u5236\u4e3a\u56fa\u5b9a\u6709\u9650\u57fa\u51fd\u6570\u7684\u7ebf\u6027\u7ec4\u5408\u4e14\u591a\u4f9d\u8d56\u6709\u9650\u671f\u516c\u5f0f\uff0c\u672c\u6587\u65e8\u5728\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5f15\u5165\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u5c06\u6700\u5927\u56e0\u679c\u71b5\u9006\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u5bf9\u6570\u4f3c\u7136\u6700\u5927\u5316\u95ee\u9898\uff0c\u7528\u68af\u5ea6\u4e0a\u5347\u7b97\u6cd5\u6c42\u89e3\uff0c\u8bc1\u660e\u76f8\u5173\u8f6f\u8d1d\u5c14\u66fc\u7b97\u5b50\u7684\u5f17\u96f7\u6b47\u53ef\u5fae\u6027\u4ee5\u5efa\u7acb\u5bf9\u6570\u4f3c\u7136\u76ee\u6807\u7684\u5e73\u6ed1\u6027\u3002", "result": "\u5728\u5e73\u5747\u573a\u4ea4\u901a\u8def\u7531\u535a\u5f08\u4e2d\u51c6\u786e\u6062\u590d\u4e86\u4e13\u5bb6\u884c\u4e3a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u89e3\u51b3\u65e0\u9650\u671f\u5e73\u7a33\u5e73\u5747\u573a\u535a\u5f08\u7684\u6700\u5927\u56e0\u679c\u71b5\u9006\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u4e0a\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2507.15239", "pdf": "https://arxiv.org/pdf/2507.15239", "abs": "https://arxiv.org/abs/2507.15239", "authors": ["Qianchao Wang", "Yuxuan Ding", "Chuanzhen Jia", "Zhe Li", "Yaping Du"], "title": "Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis", "categories": ["cs.AI", "eess.SP"], "comment": null, "summary": "Novel AI-based arc fault diagnosis models have demonstrated outstanding\nperformance in terms of classification accuracy. However, an inherent problem\nis whether these models can actually be trusted to find arc faults. In this\nlight, this work proposes a soft evaluation indicator that explains the outputs\nof arc fault diagnosis models, by defining the the correct explanation of arc\nfaults and leveraging Explainable Artificial Intelligence and real arc fault\nexperiments. Meanwhile, a lightweight balanced neural network is proposed to\nguarantee competitive accuracy and soft feature extraction score. In our\nexperiments, several traditional machine learning methods and deep learning\nmethods across two arc fault datasets with different sample times and noise\nlevels are utilized to test the effectiveness of the soft evaluation indicator.\nThrough this approach, the arc fault diagnosis models are easy to understand\nand trust, allowing practitioners to make informed and trustworthy decisions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8f6f\u8bc4\u4f30\u6307\u6807\u548c\u8f7b\u91cf\u7ea7\u5e73\u8861\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6307\u6807\u6709\u6548\u6027\uff0c\u8ba9\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u66f4\u6613\u7406\u89e3\u548c\u4fe1\u4efb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eAI\u7684\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u5b58\u5728\u80fd\u5426\u88ab\u4fe1\u4efb\u7684\u95ee\u9898\uff0c\u9700\u8981\u89e3\u91ca\u5176\u8f93\u51fa\u3002", "method": "\u5b9a\u4e49\u7535\u5f27\u6545\u969c\u7684\u6b63\u786e\u89e3\u91ca\uff0c\u5229\u7528\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u548c\u771f\u5b9e\u7535\u5f27\u6545\u969c\u5b9e\u9a8c\u63d0\u51fa\u8f6f\u8bc4\u4f30\u6307\u6807\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u5e73\u8861\u795e\u7ecf\u7f51\u7edc\uff1b\u7528\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u4e24\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u6307\u6807\u6709\u6548\u6027\u3002", "result": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u8868\u660e\u901a\u8fc7\u8be5\u65b9\u6cd5\u80fd\u8ba9\u6a21\u578b\u66f4\u6613\u7406\u89e3\u548c\u4fe1\u4efb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u6613\u4e8e\u7406\u89e3\u548c\u4fe1\u4efb\uff0c\u4fbf\u4e8e\u4ece\u4e1a\u8005\u505a\u51fa\u53ef\u9760\u51b3\u7b56\u3002"}}
{"id": "2507.15831", "pdf": "https://arxiv.org/pdf/2507.15831", "abs": "https://arxiv.org/abs/2507.15831", "authors": ["Sergey Titov", "Konstantin Grotov", "Cristina Sarasua", "Yaroslav Golubev", "Dhivyabharathi Ramasamy", "Alberto Bacchelli", "Abraham Bernstein", "Timofey Bryksin"], "title": "Observing Fine-Grained Changes in Jupyter Notebooks During Development Time", "categories": ["cs.SE"], "comment": "32 pages, 6 figures", "summary": "In software engineering, numerous studies have focused on the analysis of\nfine-grained logs, leading to significant innovations in areas such as\nrefactoring, security, and code completion. However, no similar studies have\nbeen conducted for computational notebooks in the context of data science.\n  To help bridge this research gap, we make three scientific contributions: we\n(1) introduce a toolset for collecting code changes in Jupyter notebooks during\ndevelopment time; (2) use it to collect more than 100 hours of work related to\na data analysis task and a machine learning task (carried out by 20 developers\nwith different levels of expertise), resulting in a dataset containing 2,655\ncells and 9,207 cell executions; and (3) use this dataset to investigate the\ndynamic nature of the notebook development process and the changes that take\nplace in the notebooks.\n  In our analysis of the collected data, we classified the changes made to the\ncells between executions and found that a significant number of these changes\nwere relatively small fixes and code iteration modifications. This suggests\nthat notebooks are used not only as a development and exploration tool but also\nas a debugging tool. We report a number of other insights and propose potential\nfuture research directions on the novel data.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6570\u636e\u79d1\u5b66\u4e2d\u8ba1\u7b97\u7b14\u8bb0\u672c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u65e5\u5fd7\u5206\u6790\u7814\u7a76\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u5de5\u5177\u6536\u96c6\u6570\u636e\uff0c\u5206\u6790\u53d1\u73b0\u7b14\u8bb0\u672c\u4e0d\u4ec5\u7528\u4e8e\u5f00\u53d1\u63a2\u7d22\uff0c\u8fd8\u7528\u4e8e\u8c03\u8bd5\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u6709\u5927\u91cf\u7ec6\u7c92\u5ea6\u65e5\u5fd7\u5206\u6790\u7814\u7a76\uff0c\u4f46\u6570\u636e\u79d1\u5b66\u4e2d\u8ba1\u7b97\u7b14\u8bb0\u672c\u7f3a\u4e4f\u7c7b\u4f3c\u7814\u7a76\uff0c\u4e3a\u586b\u8865\u6b64\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u6536\u96c6Jupyter\u7b14\u8bb0\u672c\u4ee3\u7801\u66f4\u6539\u7684\u5de5\u5177\u96c6\uff0c\u6536\u96c6\u8d85100\u5c0f\u65f6\u5f00\u53d1\u6570\u636e\u5f62\u6210\u6570\u636e\u96c6\uff0c\u5229\u7528\u6570\u636e\u96c6\u7814\u7a76\u7b14\u8bb0\u672c\u5f00\u53d1\u8fc7\u7a0b\u52a8\u6001\u7279\u6027\u548c\u53d8\u5316\u3002", "result": "\u5206\u6790\u6570\u636e\u53d1\u73b0\u5355\u5143\u683c\u6267\u884c\u95f4\u7684\u66f4\u6539\u591a\u4e3a\u5c0f\u4fee\u590d\u548c\u4ee3\u7801\u8fed\u4ee3\u4fee\u6539\u3002", "conclusion": "\u7b14\u8bb0\u672c\u4e0d\u4ec5\u662f\u5f00\u53d1\u63a2\u7d22\u5de5\u5177\uff0c\u4e5f\u662f\u8c03\u8bd5\u5de5\u5177\uff0c\u62a5\u544a\u5176\u4ed6\u89c1\u89e3\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.14560", "pdf": "https://arxiv.org/pdf/2507.14560", "abs": "https://arxiv.org/abs/2507.14560", "authors": ["Giorgio Roffo"], "title": "The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers", "categories": ["cs.LG", "cs.CV", "68T07, 05C50, 15A18", "I.2.6; I.2.7; I.5.1"], "comment": "24 pages, 10 figures, submitted for review. Companion code and\n  reproducibility materials available", "summary": "The self-attention mechanism, now central to deep learning architectures such\nas Transformers, is a modern instance of a more general computational\nprinciple: learning and using pairwise affinity matrices to control how\ninformation flows through a model. This paper traces the conceptual origins of\nself-attention across multiple domains, including computer vision, natural\nlanguage processing, and graph learning, through their shared reliance on an\naffinity matrix, denoted as A. We highlight Infinite Feature Selection (Inf-FS)\nas a foundational approach that generalizes the idea of affinity-based\nweighting. Unlike the fixed dot-product structure used in Transformers, Inf-FS\ndefines A either through domain knowledge or by learning, and computes feature\nrelevance through multi-hop propagation over the affinity graph. From this\nperspective, self-attention can be seen as a special case of Inf-FS: it uses a\nsingle-hop affinity computation where A is dynamically built from token\nsimilarities. We argue that the underlying structure, reasoning over pairwise\nrelationships, is preserved across both approaches, and the key differences lie\nin how the affinity matrix is defined and applied. By situating self-attention\nwithin the broader paradigm of affinity-based computation, we unify several\nstrands of machine learning research and highlight a common mathematical\nfoundation that underpins diverse models and tasks.", "AI": {"tldr": "\u672c\u6587\u8ffd\u6eaf\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6982\u5ff5\u8d77\u6e90\uff0c\u6307\u51fa\u5b83\u662f\u65e0\u9650\u7279\u5f81\u9009\u62e9\uff08Inf - FS\uff09\u7684\u7279\u4f8b\uff0c\u7edf\u4e00\u4e86\u673a\u5668\u5b66\u4e60\u7814\u7a76\u5e76\u5f3a\u8c03\u5171\u540c\u6570\u5b66\u57fa\u7840\u3002", "motivation": "\u8ffd\u6eaf\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5728\u591a\u9886\u57df\u7684\u6982\u5ff5\u8d77\u6e90\uff0c\u7edf\u4e00\u673a\u5668\u5b66\u4e60\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u591a\u9886\u57df\u5bf9\u4eb2\u548c\u77e9\u9635\u7684\u5171\u540c\u4f9d\u8d56\u8ffd\u6eaf\u8d77\u6e90\uff0c\u5bf9\u6bd4\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548cInf - FS\u3002", "result": "\u53d1\u73b0\u81ea\u6ce8\u610f\u529b\u673a\u5236\u662fInf - FS\u7684\u7279\u4f8b\uff0c\u4e8c\u8005\u5e95\u5c42\u7ed3\u6784\u76f8\u540c\u4f46\u4eb2\u548c\u77e9\u9635\u5b9a\u4e49\u548c\u5e94\u7528\u6709\u5dee\u5f02\u3002", "conclusion": "\u5c06\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7f6e\u4e8e\u57fa\u4e8e\u4eb2\u548c\u6027\u8ba1\u7b97\u7684\u66f4\u5e7f\u6cdb\u8303\u5f0f\u4e2d\uff0c\u5b58\u5728\u7edf\u4e00\u7684\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2507.15253", "pdf": "https://arxiv.org/pdf/2507.15253", "abs": "https://arxiv.org/abs/2507.15253", "authors": ["Zhaochen Guo", "Zhixiang Shen", "Xuanting Xie", "Liangjian Wen", "Zhao Kang"], "title": "Disentangling Homophily and Heterophily in Multimodal Graph Clustering", "categories": ["cs.AI", "cs.LG", "cs.SI"], "comment": "Appear in ACM Multimedia 2025", "summary": "Multimodal graphs, which integrate unstructured heterogeneous data with\nstructured interconnections, offer substantial real-world utility but remain\ninsufficiently explored in unsupervised learning. In this work, we initiate the\nstudy of multimodal graph clustering, aiming to bridge this critical gap.\nThrough empirical analysis, we observe that real-world multimodal graphs often\nexhibit hybrid neighborhood patterns, combining both homophilic and\nheterophilic relationships. To address this challenge, we propose a novel\nframework -- \\textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which\ndecomposes the original hybrid graph into two complementary views: (1) a\nhomophily-enhanced graph that captures cross-modal class consistency, and (2)\nheterophily-aware graphs that preserve modality-specific inter-class\ndistinctions. We introduce a \\emph{Multimodal Dual-frequency Fusion} mechanism\nthat jointly filters these disentangled graphs through a dual-pass strategy,\nenabling effective multimodal integration while mitigating category confusion.\nOur self-supervised alignment objectives further guide the learning process\nwithout requiring labels. Extensive experiments on both multimodal and\nmulti-relational graph datasets demonstrate that DMGC achieves state-of-the-art\nperformance, highlighting its effectiveness and generalizability across diverse\nsettings. Our code is available at https://github.com/Uncnbb/DMGC.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u591a\u6a21\u6001\u56fe\u805a\u7c7b\uff0c\u63d0\u51faDMGC\u6846\u67b6\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\u3002", "motivation": "\u591a\u6a21\u6001\u56fe\u5728\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u7814\u7a76\u4e0d\u8db3\uff0c\u73b0\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u56fe\u6709\u6df7\u5408\u90bb\u57df\u6a21\u5f0f\u3002", "method": "\u63d0\u51faDMGC\u6846\u67b6\uff0c\u5c06\u539f\u59cb\u6df7\u5408\u56fe\u5206\u89e3\u4e3a\u540c\u8d28\u6027\u589e\u5f3a\u56fe\u548c\u5f02\u8d28\u6027\u611f\u77e5\u56fe\uff0c\u5f15\u5165\u591a\u6a21\u6001\u53cc\u9891\u878d\u5408\u673a\u5236\uff0c\u6709\u81ea\u76d1\u7763\u5bf9\u9f50\u76ee\u6807\u3002", "result": "\u5728\u591a\u6a21\u6001\u548c\u591a\u5173\u7cfb\u56fe\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660eDMGC\u8fbe\u5230\u4e86SOTA\u6027\u80fd\u3002", "conclusion": "DMGC\u6709\u6548\u4e14\u5177\u6709\u8de8\u4e0d\u540c\u8bbe\u7f6e\u7684\u6cdb\u5316\u6027\u3002"}}
{"id": "2507.14347", "pdf": "https://arxiv.org/pdf/2507.14347", "abs": "https://arxiv.org/abs/2507.14347", "authors": ["Ole Hans", "Benedikt Walter"], "title": "Remote Assistance or Remote Driving: The Impact of Operational Design Domains on ADS-Supporting Systems Selection", "categories": ["eess.SY", "cs.SE", "cs.SY"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "High level Automated Driving Systems (ADS) can handle many situations, but\nthey still encounter situations where human intervention is required. In\nsystems where a physical driver is present in the vehicle, typically SAE Level\n3 systems, this intervention is relatively straightforward and is handled by\nthe in-vehicle driver. However, the complexity increases for Level 4 systems,\nwhere, in most cases, no physical driver remains in the vehicle. The two common\nindustry solutions for this challenge are the integration of a remote support\nsystem, such as a Remote Driving System (RDS) or Remote Assistance System\n(RAS). While it is clear that ADS will require one of these systems, it is less\nclear how the suitability of either system for a particular ADS application\nshould be evaluated. Currently, the selection process often focuses on system\narchitecture as well as its design and integration challenges. Furthermore,\nsince many ADS developers choose to develop remote system solutions in-house,\nit is advantageous to select the simpler approach to streamline development and\nintegration efforts. While these decision points are certainly relevant, this\napproach overlooks the most critical factors: the use cases and the\ncomplementarity of the ADS and the remote support system within the context of\nthe Operational Design Design Domain (ODD). This paper proposes a structured\napproach for selecting between RDS and RAS as an ADS support system, based on\nthe defined ODD and use case analysis. To achieve this, the paper applies the\nPEGASUS framework to systematically describe and analyze the ODD. A structured\nframework is introduced to evaluate and select the most suitable remote support\nsystem for an ADS based on clearly defined criteria.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eODD\u548c\u7528\u4f8b\u5206\u6790\uff0c\u5728RDS\u548cRAS\u4e2d\u9009\u62e9\u9002\u5408\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u652f\u6301\u7cfb\u7edf\u7684\u7ed3\u6784\u5316\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u9009\u62e9\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\u7684\u65b9\u6cd5\u5ffd\u7565\u5173\u952e\u56e0\u7d20\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u5e94\u7528PEGASUS\u6846\u67b6\u63cf\u8ff0\u548c\u5206\u6790ODD\uff0c\u5f15\u5165\u7ed3\u6784\u5316\u6846\u67b6\u8bc4\u4f30\u9009\u62e9\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u57fa\u4e8eODD\u548c\u7528\u4f8b\u5206\u6790\uff0c\u9009\u62e9\u9002\u5408\u7684\u8fdc\u7a0b\u652f\u6301\u7cfb\u7edf\u7684\u7ed3\u6784\u5316\u65b9\u6cd5\u3002"}}
{"id": "2507.14570", "pdf": "https://arxiv.org/pdf/2507.14570", "abs": "https://arxiv.org/abs/2507.14570", "authors": ["Xu Cheng", "Liang Yao", "Feng He", "Yukuo Cen", "Yufei He", "Chenhui Zhang", "Wenzheng Feng", "Hongyun Cai", "Jie Tang"], "title": "LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for various graph\nmining tasks, yet existing scalable solutions often struggle to balance\nexecution efficiency with prediction accuracy. These difficulties stem from\niterative message-passing techniques, which place significant computational\ndemands and require extensive GPU memory, particularly when dealing with the\nneighbor explosion issue inherent in large-scale graphs. This paper introduces\na scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN,\nwhich can perform representation learning on 100 billion graphs with a single\nGPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We\nexamine existing graph partitioning methods and design a superior graph\npartition algorithm named LPMetis. In particular, LPMetis outperforms current\nstate-of-the-art (SOTA) approaches on various evaluation metrics. In addition,\nour paper proposes a subgraph augmentation strategy to enhance the model's\npredictive performance. It exhibits excellent compatibility, allowing the\nentire framework to accommodate various GNN algorithms. Successfully deployed\non the Tencent platform, LPS-GNN has been tested on public and real-world\ndatasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in\nonline applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLPS - GNN\u6846\u67b6\uff0c\u8bbe\u8ba1LPMetis\u5206\u533a\u7b97\u6cd5\u4e0e\u5b50\u56fe\u589e\u5f3a\u7b56\u7565\uff0c\u5728\u591a\u6570\u636e\u96c6\u6d4b\u8bd5\u8868\u73b0\u4f18\u4e8eSOTA\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u53ef\u6269\u5c55GNN\u89e3\u51b3\u65b9\u6848\u96be\u4ee5\u5e73\u8861\u6267\u884c\u6548\u7387\u548c\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fed\u4ee3\u6d88\u606f\u4f20\u9012\u6280\u672f\u8ba1\u7b97\u9700\u6c42\u5927\u3001GPU\u5185\u5b58\u8981\u6c42\u9ad8\uff0c\u5904\u7406\u5927\u89c4\u6a21\u56fe\u7684\u90bb\u5c45\u7206\u70b8\u95ee\u9898\u56f0\u96be\u3002", "method": "\u5f15\u5165LPS - GNN\u6846\u67b6\uff0c\u8bbe\u8ba1LPMetis\u56fe\u5206\u533a\u7b97\u6cd5\uff0c\u63d0\u51fa\u5b50\u56fe\u589e\u5f3a\u7b56\u7565\u3002", "result": "LPS - GNN\u80fd\u5728\u5355GPU\u4e0a10\u5c0f\u65f6\u5185\u5bf91000\u4ebf\u56fe\u8fdb\u884c\u8868\u793a\u5b66\u4e60\uff0c\u5728\u7528\u6237\u83b7\u53d6\u573a\u666f\u63d0\u534713.8%\uff1bLPMetis\u5728\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8eSOTA\u65b9\u6cd5\uff1bLPS - GNN\u5728\u5728\u7ebf\u5e94\u7528\u4e2d\u6bd4SOTA\u6a21\u578b\u6027\u80fd\u63d0\u53478.24% - 13.89%\u3002", "conclusion": "LPS - GNN\u6846\u67b6\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u4f4e\u6210\u672c\u3001\u7075\u6d3b\u6027\u548c\u9ad8\u6548\u6027\uff0c\u80fd\u9002\u5e94\u591a\u79cdGNN\u7b97\u6cd5\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2507.15268", "pdf": "https://arxiv.org/pdf/2507.15268", "abs": "https://arxiv.org/abs/2507.15268", "authors": ["Junhyeong Lee", "Joon-Young Kim", "Heekyu Kim", "Inhyo Lee", "Seunghwa Ryu"], "title": "IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The injection molding industry faces critical challenges in preserving and\ntransferring field knowledge, particularly as experienced workers retire and\nmultilingual barriers hinder effective communication. This study introduces\nIM-Chat, a multi-agent framework based on large language models (LLMs),\ndesigned to facilitate knowledge transfer in injection molding. IM-Chat\nintegrates both limited documented knowledge (e.g., troubleshooting tables,\nmanuals) and extensive field data modeled through a data-driven process\ncondition generator that infers optimal manufacturing settings from\nenvironmental inputs such as temperature and humidity, enabling robust and\ncontext-aware task resolution. By adopting a retrieval-augmented generation\n(RAG) strategy and tool-calling agents within a modular architecture, IM-Chat\nensures adaptability without the need for fine-tuning. Performance was assessed\nacross 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and\nGPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance\nand correctness, and was further supplemented by automated evaluation using\nGPT-4o guided by a domain-adapted instruction prompt. The evaluation results\nindicate that more capable models tend to achieve higher accuracy, particularly\nin complex, tool-integrated scenarios. Overall, these findings demonstrate the\nviability of multi-agent LLM systems for industrial knowledge workflows and\nestablish IM-Chat as a scalable and generalizable approach to AI-assisted\ndecision support in manufacturing.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6 IM - Chat \u4fc3\u8fdb\u6ce8\u5851\u6210\u578b\u77e5\u8bc6\u8f6c\u79fb\uff0c\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u8bc1\u660e\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u7528\u4e8e\u5de5\u4e1a\u77e5\u8bc6\u5de5\u4f5c\u6d41\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u6ce8\u5851\u6210\u578b\u884c\u4e1a\u5728\u77e5\u8bc6\u4fdd\u7559\u548c\u8f6c\u79fb\u4e0a\u9762\u4e34\u6311\u6218\uff0c\u5982\u7ecf\u9a8c\u5de5\u4eba\u9000\u4f11\u548c\u591a\u8bed\u8a00\u969c\u788d\u5f71\u54cd\u6c9f\u901a\u3002", "method": "\u5f15\u5165 IM - Chat \u6846\u67b6\uff0c\u6574\u5408\u6709\u9650\u6587\u6863\u77e5\u8bc6\u548c\u73b0\u573a\u6570\u636e\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b56\u7565\u548c\u5de5\u5177\u8c03\u7528\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u8bc4\u5206\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u6765\u8bc4\u4ef7\u6027\u80fd\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u80fd\u529b\u66f4\u5f3a\u7684\u6a21\u578b\u5728\u590d\u6742\u3001\u96c6\u6210\u5de5\u5177\u573a\u666f\u4e2d\u5f80\u5f80\u51c6\u786e\u7387\u66f4\u9ad8\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u53ef\u7528\u4e8e\u5de5\u4e1a\u77e5\u8bc6\u5de5\u4f5c\u6d41\uff0cIM - Chat \u662f\u5236\u9020\u4e1a\u4e2d\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u51b3\u7b56\u652f\u6301\u7684\u53ef\u6269\u5c55\u4e14\u901a\u7528\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14592", "pdf": "https://arxiv.org/pdf/2507.14592", "abs": "https://arxiv.org/abs/2507.14592", "authors": ["Haochen Liu", "Jia Bi", "Xiaomin Wang", "Xin Yang", "Ling Wang"], "title": "A Transformer-Based Conditional GAN with Multiple Instance Learning for UAV Signal Detection and Classification", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 7 figures", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance,\nlogistics, agriculture, disaster management, and military operations. Accurate\ndetection and classification of UAV flight states, such as hovering, cruising,\nascending, or transitioning, which are essential for safe and effective\noperations. However, conventional time series classification (TSC) methods\noften lack robustness and generalization for dynamic UAV environments, while\nstate of the art(SOTA) models like Transformers and LSTM based architectures\ntypically require large datasets and entail high computational costs,\nespecially with high-dimensional data streams. This paper proposes a novel\nframework that integrates a Transformer-based Generative Adversarial Network\n(GAN) with Multiple Instance Locally Explainable Learning (MILET) to address\nthese challenges in UAV flight state classification. The Transformer encoder\ncaptures long-range temporal dependencies and complex telemetry dynamics, while\nthe GAN module augments limited datasets with realistic synthetic samples. MIL\nis incorporated to focus attention on the most discriminative input segments,\nreducing noise and computational overhead. Experimental results show that the\nproposed method achieves superior accuracy 96.5% on the DroneDetect dataset and\n98.6% on the DroneRF dataset that outperforming other SOTA approaches. The\nframework also demonstrates strong computational efficiency and robust\ngeneralization across diverse UAV platforms and flight states, highlighting its\npotential for real-time deployment in resource constrained environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u96c6\u6210Transformer - GAN\u4e0eMILET\u7684\u6846\u67b6\u89e3\u51b3\u65e0\u4eba\u673a\u98de\u884c\u72b6\u6001\u5206\u7c7b\u95ee\u9898\uff0c\u5b9e\u9a8c\u6548\u679c\u4f73\u4e14\u6709\u8ba1\u7b97\u6548\u7387\u4e0e\u6cdb\u5316\u6027\u3002", "motivation": "\u4f20\u7edfTSC\u65b9\u6cd5\u5bf9\u52a8\u6001\u65e0\u4eba\u673a\u73af\u5883\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\uff0cSOTA\u6a21\u578b\u9700\u5927\u6570\u636e\u96c6\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u65e0\u4eba\u673a\u98de\u884c\u72b6\u6001\u5206\u7c7b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u96c6\u6210Transformer - GAN\u4e0eMILET\u7684\u6846\u67b6\uff0cTransformer\u7f16\u7801\u5668\u6355\u6349\u957f\u65f6\u4f9d\u8d56\uff0cGAN\u6a21\u5757\u6269\u5145\u6570\u636e\u96c6\uff0cMIL\u805a\u7126\u5173\u952e\u8f93\u5165\u6bb5\u3002", "result": "\u5728DroneDetect\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u738796.5%\uff0cDroneRF\u6570\u636e\u96c6\u4e0a98.6%\uff0c\u4f18\u4e8e\u5176\u4ed6SOTA\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u8ba1\u7b97\u6548\u7387\u9ad8\u3001\u6cdb\u5316\u6027\u5f3a\uff0c\u6709\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u5b9e\u65f6\u90e8\u7f72\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15330", "pdf": "https://arxiv.org/pdf/2507.15330", "abs": "https://arxiv.org/abs/2507.15330", "authors": ["Hammad Atta", "Muhammad Zeeshan Baig", "Yasir Mehmood", "Nadeem Shahzad", "Ken Huang", "Muhammad Aziz Ul Haq", "Muhammad Awais", "Kamal Ahmed"], "title": "QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI", "categories": ["cs.AI"], "comment": null, "summary": "We introduce Cognitive Degradation as a novel vulnerability class in agentic\nAI systems. Unlike traditional adversarial external threats such as prompt\ninjection, these failures originate internally, arising from memory starvation,\nplanner recursion, context flooding, and output suppression. These systemic\nweaknesses lead to silent agent drift, logic collapse, and persistent\nhallucinations over time. To address this class of failures, we introduce the\nQorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain\n10), a lifecycle-aware defense framework defined by a six-stage cognitive\ndegradation lifecycle. The framework includes seven runtime controls\n(QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger\nproactive mitigation through fallback routing, starvation detection, and memory\nintegrity enforcement. Drawing from cognitive neuroscience, we map agentic\narchitectures to human analogs, enabling early detection of fatigue,\nstarvation, and role collapse. By introducing a formal lifecycle and real-time\nmitigation controls, this work establishes Cognitive Degradation as a critical\nnew class of AI system vulnerability and proposes the first cross-platform\ndefense model for resilient agentic behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8ba4\u77e5\u9000\u5316\u4f5c\u4e3a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u65b0\u6f0f\u6d1e\u7c7b\uff0c\u4ecb\u7ecdQorvex\u5b89\u5168AI\u6846\u67b6\u5e94\u5bf9\u8be5\u7c7b\u6545\u969c\uff0c\u5efa\u7acb\u8ba4\u77e5\u9000\u5316\u6f0f\u6d1e\u7c7b\u522b\u5e76\u63d0\u51fa\u8de8\u5e73\u53f0\u9632\u5fa1\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u5bf9\u6297\u6027\u5916\u90e8\u5a01\u80c1\u7814\u7a76\u8f83\u591a\uff0c\u800c\u667a\u80fd\u4f53AI\u7cfb\u7edf\u5b58\u5728\u6e90\u4e8e\u5185\u90e8\u7684\u8ba4\u77e5\u9000\u5316\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u6b64\u7c7b\u6545\u969c\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u516d\u9636\u6bb5\u8ba4\u77e5\u9000\u5316\u751f\u547d\u5468\u671f\u7684Qorvex\u5b89\u5168AI\u6846\u67b6\uff0c\u5305\u542b\u4e03\u4e2a\u8fd0\u884c\u65f6\u63a7\u5236\uff0c\u8fd8\u5c06\u667a\u80fd\u4f53\u67b6\u6784\u6620\u5c04\u5230\u4eba\u7c7b\u7c7b\u6bd4\u3002", "result": "\u6846\u67b6\u53ef\u5b9e\u65f6\u76d1\u63a7\u667a\u80fd\u4f53\u5b50\u7cfb\u7edf\uff0c\u901a\u8fc7\u56de\u9000\u8def\u7531\u3001\u9965\u997f\u68c0\u6d4b\u548c\u5185\u5b58\u5b8c\u6574\u6027\u5f3a\u5236\u7b49\u8fdb\u884c\u4e3b\u52a8\u7f13\u89e3\u3002", "conclusion": "\u786e\u7acb\u8ba4\u77e5\u9000\u5316\u4f5c\u4e3aAI\u7cfb\u7edf\u5173\u952e\u65b0\u6f0f\u6d1e\u7c7b\uff0c\u63d0\u51fa\u9996\u4e2a\u8de8\u5e73\u53f0\u7684\u5f39\u6027\u667a\u80fd\u4f53\u884c\u4e3a\u9632\u5fa1\u6a21\u578b\u3002"}}
{"id": "2507.14985", "pdf": "https://arxiv.org/pdf/2507.14985", "abs": "https://arxiv.org/abs/2507.14985", "authors": ["Argianto Rahartomo", "Leonel Merino", "Mohammad Ghafari"], "title": "Metaverse Security and Privacy Research: A Systematic Review", "categories": ["cs.CR", "cs.ET", "cs.HC", "cs.SE"], "comment": "The paper is accepted for publication at Computers & Security Journal", "summary": "The rapid growth of metaverse technologies, including virtual worlds,\naugmented reality, and lifelogging, has accelerated their adoption across\ndiverse domains. This rise exposes users to significant new security and\nprivacy challenges due to sociotechnical complexity, pervasive connectivity,\nand extensive user data collection in immersive environments. We present a\nsystematic review of the literature published between 2013 and 2024, offering a\ncomprehensive analysis of how the research community has addressed\nmetaverse-related security and privacy issues over the past decade. We organize\nthe studies by method, examined the security and privacy properties, immersive\ncomponents, and evaluation strategies. Our investigation reveals a sharp\nincrease in research activity in the last five years, a strong focus on\npractical and user-centered approaches, and a predominant use of benchmarking,\nhuman experimentation, and qualitative methods. Authentication and\nunobservability are the most frequently studied properties. However, critical\ngaps remain in areas such as policy compliance, accessibility,\ninteroperability, and back-end infrastructure security. We emphasize the\nintertwined technical complexity and human factors of the metaverse and call\nfor integrated, interdisciplinary approaches to securing inclusive and\ntrustworthy immersive environments.", "AI": {"tldr": "\u5bf92013 - 2024\u5e74\u5143\u5b87\u5b99\u5b89\u5168\u4e0e\u9690\u79c1\u6587\u732e\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\uff0c\u63ed\u793a\u7814\u7a76\u8d8b\u52bf\u4e0e\u4e0d\u8db3\uff0c\u547c\u5401\u8de8\u5b66\u79d1\u65b9\u6cd5\u3002", "motivation": "\u5143\u5b87\u5b99\u6280\u672f\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u65b0\u7684\u5b89\u5168\u548c\u9690\u79c1\u6311\u6218\uff0c\u9700\u4e86\u89e3\u7814\u7a76\u754c\u5982\u4f55\u5e94\u5bf9\u3002", "method": "\u5bf92013 - 2024\u5e74\u6587\u732e\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\uff0c\u6309\u65b9\u6cd5\u7ec4\u7ec7\u7814\u7a76\uff0c\u5206\u6790\u5b89\u5168\u9690\u79c1\u5c5e\u6027\u3001\u6c89\u6d78\u5f0f\u7ec4\u4ef6\u548c\u8bc4\u4f30\u7b56\u7565\u3002", "result": "\u8fd1\u4e94\u5e74\u7814\u7a76\u6d3b\u52a8\u6fc0\u589e\uff0c\u6ce8\u91cd\u5b9e\u7528\u548c\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u591a\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u3001\u4eba\u4f53\u5b9e\u9a8c\u548c\u5b9a\u6027\u65b9\u6cd5\uff0c\u8ba4\u8bc1\u548c\u4e0d\u53ef\u89c2\u5bdf\u6027\u7814\u7a76\u6700\u591a\u3002", "conclusion": "\u5143\u5b87\u5b99\u5b58\u5728\u6280\u672f\u590d\u6742\u6027\u548c\u4eba\u4e3a\u56e0\u7d20\u4ea4\u7ec7\u95ee\u9898\uff0c\u9700\u8de8\u5b66\u79d1\u65b9\u6cd5\u4fdd\u969c\u6c89\u6d78\u5f0f\u73af\u5883\u7684\u5305\u5bb9\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2507.15351", "pdf": "https://arxiv.org/pdf/2507.15351", "abs": "https://arxiv.org/abs/2507.15351", "authors": ["Zijian Zhao", "Sen Li"], "title": "One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms", "categories": ["cs.AI", "cs.ET", "cs.MA"], "comment": null, "summary": "On-demand ride-sharing platforms face the fundamental challenge of\ndynamically bundling passengers with diverse origins and destinations and\nmatching them with vehicles in real time, all under significant uncertainty.\nRecently, MARL has emerged as a promising solution for this problem, leveraging\ndecentralized learning to address the curse of dimensionality caused by the\nlarge number of agents in the ride-hailing market and the resulting expansive\nstate and action spaces. However, conventional MARL-based ride-sharing\napproaches heavily rely on the accurate estimation of Q-values or V-values,\nwhich becomes problematic in large-scale, highly uncertain environments.\nSpecifically, most of these approaches adopt an independent paradigm,\nexacerbating this issue, as each agent treats others as part of the\nenvironment, leading to unstable training and substantial estimation bias in\nvalue functions. To address these challenges, we propose two novel alternative\nmethods that bypass value function estimation. First, we adapt GRPO to\nride-sharing, replacing the PPO baseline with the group average reward to\neliminate critic estimation errors and reduce training bias. Second, inspired\nby GRPO's full utilization of group reward information, we customize the PPO\nframework for ride-sharing platforms and show that, under a homogeneous fleet,\nthe optimal policy can be trained using only one-step rewards - a method we\nterm One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan\nride-hailing dataset demonstrate that both GRPO and OSPO achieve superior\nperformance across most scenarios, efficiently optimizing pickup times and the\nnumber of served orders using simple MLP networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u7ed5\u8fc7\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u7684\u65b9\u6cd5GRPO\u548cOSPO\u89e3\u51b3\u6309\u9700\u62fc\u8f66\u5e73\u53f0\u5b9e\u65f6\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5b83\u4eec\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eMARL\u7684\u62fc\u8f66\u65b9\u6cd5\u4f9d\u8d56Q\u503c\u6216V\u503c\u51c6\u786e\u4f30\u8ba1\uff0c\u5728\u5927\u89c4\u6a21\u3001\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5b58\u5728\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u4f30\u8ba1\u504f\u5dee\u95ee\u9898\u3002", "method": "\u4e00\u662f\u5c06GRPO\u5e94\u7528\u4e8e\u62fc\u8f66\uff0c\u7528\u7ec4\u5e73\u5747\u5956\u52b1\u66ff\u4ee3PPO\u57fa\u7ebf\uff1b\u4e8c\u662f\u5b9a\u5236PPO\u6846\u67b6\uff0c\u63d0\u51fa\u5355\u6b65\u7b56\u7565\u4f18\u5316\uff08OSPO\uff09\u3002", "result": "\u5728\u66fc\u54c8\u987f\u771f\u5b9e\u6253\u8f66\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cGRPO\u548cOSPO\u5728\u591a\u6570\u573a\u666f\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u7528\u7b80\u5355MLP\u7f51\u7edc\u4f18\u5316\u63a5\u5ba2\u65f6\u95f4\u548c\u670d\u52a1\u8ba2\u5355\u6570\u3002", "conclusion": "GRPO\u548cOSPO\u80fd\u6709\u6548\u89e3\u51b3\u6309\u9700\u62fc\u8f66\u5e73\u53f0\u5b9e\u65f6\u5339\u914d\u95ee\u9898\uff0c\u7ed5\u8fc7\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u5e26\u6765\u66f4\u597d\u6548\u679c\u3002"}}
{"id": "2507.15058", "pdf": "https://arxiv.org/pdf/2507.15058", "abs": "https://arxiv.org/abs/2507.15058", "authors": ["Ian Hardgrove", "John D. Hastings"], "title": "LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-box Libraries", "categories": ["cs.CR", "cs.LG", "cs.SE", "D.2.5; D.4.6"], "comment": "6 pages, 2 figures, 1 table, 2 listings", "summary": "A fundamental problem in cybersecurity and computer science is determining\nwhether a program is free of bugs and vulnerabilities. Fuzzing, a popular\napproach to discovering vulnerabilities in programs, has several advantages\nover alternative strategies, although it has investment costs in the form of\ninitial setup and continuous maintenance. The choice of fuzzing is further\ncomplicated when only a binary library is available, such as the case of\nclosed-source and proprietary software. In response, we introduce LibLMFuzz, a\nframework that reduces costs associated with fuzzing closed-source libraries by\npairing an agentic Large Language Model (LLM) with a lightweight tool-chain\n(disassembler/compiler/fuzzer) to autonomously analyze stripped binaries, plan\nfuzz strategies, generate drivers, and iteratively self-repair build or runtime\nerrors. Tested on four widely-used Linux libraries, LibLMFuzz produced\nsyntactically correct drivers for all 558 fuzz-able API functions, achieving\n100% API coverage with no human intervention. Across the 1601 synthesized\ndrivers, 75.52% were nominally correct on first execution. The results show\nthat LLM-augmented middleware holds promise in reducing the costs of fuzzing\nblack box components and provides a foundation for future research efforts.\nFuture opportunities exist for research in branch coverage.", "AI": {"tldr": "\u63d0\u51faLibLMFuzz\u6846\u67b6\u964d\u4f4e\u6a21\u7cca\u6d4b\u8bd5\u95ed\u6e90\u5e93\u6210\u672c\uff0c\u6d4b\u8bd5\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u5960\u57fa\u3002", "motivation": "\u6a21\u7cca\u6d4b\u8bd5\u6709\u6210\u672c\uff0c\u95ed\u6e90\u8f6f\u4ef6\u4e0b\u9009\u62e9\u66f4\u590d\u6742\uff0c\u9700\u964d\u4f4e\u95ed\u6e90\u5e93\u6a21\u7cca\u6d4b\u8bd5\u6210\u672c\u3002", "method": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u8f7b\u91cf\u7ea7\u5de5\u5177\u94fe\u7ed3\u5408\uff0c\u81ea\u4e3b\u5206\u6790\u4e8c\u8fdb\u5236\u6587\u4ef6\u3001\u89c4\u5212\u6a21\u7cca\u7b56\u7565\u3001\u751f\u6210\u9a71\u52a8\u5e76\u4fee\u590d\u9519\u8bef\u3002", "result": "\u5728\u56db\u4e2aLinux\u5e93\u4e0a\u6d4b\u8bd5\uff0c\u4e3a558\u4e2a\u53ef\u6a21\u7cca\u6d4b\u8bd5API\u51fd\u6570\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u9a71\u52a8\uff0c\u5b9e\u73b0100% API\u8986\u76d6\uff0c75.52%\u5408\u6210\u9a71\u52a8\u9996\u6b21\u6267\u884c\u6b63\u786e\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u7684\u4e2d\u95f4\u4ef6\u6709\u671b\u964d\u4f4e\u9ed1\u76d2\u7ec4\u4ef6\u6a21\u7cca\u6d4b\u8bd5\u6210\u672c\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\uff0c\u5206\u652f\u8986\u76d6\u6709\u7814\u7a76\u673a\u4f1a\u3002"}}
{"id": "2507.14668", "pdf": "https://arxiv.org/pdf/2507.14668", "abs": "https://arxiv.org/abs/2507.14668", "authors": ["Yunfeng Li", "Junhong Liu", "Zhaohui Yang", "Guofu Liao", "Chuyun Zhang"], "title": "Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model", "categories": ["cs.LG"], "comment": "15 pages, 14 figures", "summary": "Deep learning models have been widely adopted for False Data Injection Attack\n(FDIA) detection in smart grids due to their ability to capture unstructured\nand sparse features. However, the increasing system scale and data\ndimensionality introduce significant computational and memory burdens,\nparticularly in large-scale industrial datasets, limiting detection efficiency.\nTo address these issues, this paper proposes Rec-AD, a computationally\nefficient framework that integrates Tensor Train decomposition with the Deep\nLearning Recommendation Model (DLRM). Rec-AD enhances training and inference\nefficiency through embedding compression, optimized data access via index\nreordering, and a pipeline training mechanism that reduces memory communication\noverhead. Fully compatible with PyTorch, Rec-AD can be integrated into existing\nFDIA detection systems without code modifications. Experimental results show\nthat Rec-AD significantly improves computational throughput and real-time\ndetection performance, narrowing the attack window and increasing attacker\ncost. These advancements strengthen edge computing capabilities and\nscalability, providing robust technical support for smart grid security.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRec - AD\u6846\u67b6\u89e3\u51b3\u667a\u80fd\u7535\u7f51FDIA\u68c0\u6d4b\u4e2d\u8ba1\u7b97\u548c\u5185\u5b58\u8d1f\u62c5\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u63d0\u5347\u4e86\u8ba1\u7b97\u541e\u5410\u91cf\u548c\u5b9e\u65f6\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7528\u4e8e\u667a\u80fd\u7535\u7f51FDIA\u68c0\u6d4b\u65f6\uff0c\u56e0\u7cfb\u7edf\u89c4\u6a21\u548c\u6570\u636e\u7ef4\u5ea6\u589e\u52a0\u5e26\u6765\u8ba1\u7b97\u548c\u5185\u5b58\u8d1f\u62c5\uff0c\u9650\u5236\u68c0\u6d4b\u6548\u7387\u3002", "method": "\u63d0\u51faRec - AD\u6846\u67b6\uff0c\u96c6\u6210Tensor Train\u5206\u89e3\u4e0eDLRM\uff0c\u901a\u8fc7\u5d4c\u5165\u538b\u7f29\u3001\u7d22\u5f15\u91cd\u6392\u4f18\u5316\u6570\u636e\u8bbf\u95ee\u548c\u6d41\u6c34\u7ebf\u8bad\u7ec3\u673a\u5236\u51cf\u5c11\u5185\u5b58\u901a\u4fe1\u5f00\u9500\uff0c\u4e14\u4e0ePyTorch\u517c\u5bb9\u3002", "result": "Rec - AD\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u541e\u5410\u91cf\u548c\u5b9e\u65f6\u68c0\u6d4b\u6027\u80fd\uff0c\u7f29\u5c0f\u653b\u51fb\u7a97\u53e3\uff0c\u589e\u52a0\u653b\u51fb\u8005\u6210\u672c\u3002", "conclusion": "Rec - AD\u589e\u5f3a\u4e86\u8fb9\u7f18\u8ba1\u7b97\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u667a\u80fd\u7535\u7f51\u5b89\u5168\u63d0\u4f9b\u4e86\u6709\u529b\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2507.15356", "pdf": "https://arxiv.org/pdf/2507.15356", "abs": "https://arxiv.org/abs/2507.15356", "authors": ["Lu Guo", "Yixiang Shan", "Zhengbang Zhu", "Qifan Liang", "Lichang Song", "Ting Long", "Weinan Zhang", "Yi Chang"], "title": "RAD: Retrieval High-quality Demonstrations to Enhance Decision-making", "categories": ["cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) enables agents to learn policies from\nfixed datasets, avoiding costly or unsafe environment interactions. However,\nits effectiveness is often limited by dataset sparsity and the lack of\ntransition overlap between suboptimal and expert trajectories, which makes\nlong-horizon planning particularly challenging. Prior solutions based on\nsynthetic data augmentation or trajectory stitching often fail to generalize to\nnovel states and rely on heuristic stitching points. To address these\nchallenges, we propose Retrieval High-quAlity Demonstrations (RAD) for\ndecision-making, which combines non-parametric retrieval with diffusion-based\ngenerative modeling. RAD dynamically retrieves high-return states from the\noffline dataset as target states based on state similarity and return\nestimation, and plans toward them using a condition-guided diffusion model.\nSuch retrieval-guided generation enables flexible trajectory stitching and\nimproves generalization when encountered with underrepresented or\nout-of-distribution states. Extensive experiments confirm that RAD achieves\ncompetitive or superior performance compared to baselines across diverse\nbenchmarks, validating its effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u51b3\u7b56\u7684Retrieval High - quAlity Demonstrations (RAD)\u65b9\u6cd5\uff0c\u7ed3\u5408\u975e\u53c2\u6570\u68c0\u7d22\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5efa\u6a21\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u53d7\u6570\u636e\u96c6\u7a00\u758f\u548c\u8f68\u8ff9\u8fc7\u6e21\u91cd\u53e0\u95ee\u9898\u9650\u5236\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6cdb\u5316\u5230\u65b0\u72b6\u6001\u4e14\u4f9d\u8d56\u542f\u53d1\u5f0f\u62fc\u63a5\u70b9\u3002", "method": "\u5c06\u975e\u53c2\u6570\u68c0\u7d22\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u57fa\u4e8e\u72b6\u6001\u76f8\u4f3c\u6027\u548c\u56de\u62a5\u4f30\u8ba1\u4ece\u79bb\u7ebf\u6570\u636e\u96c6\u4e2d\u52a8\u6001\u68c0\u7d22\u9ad8\u56de\u62a5\u72b6\u6001\u4f5c\u4e3a\u76ee\u6807\u72b6\u6001\uff0c\u4f7f\u7528\u6761\u4ef6\u5f15\u5bfc\u6269\u6563\u6a21\u578b\u8fdb\u884c\u89c4\u5212\u3002", "result": "\u5728\u591a\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRAD\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "RAD\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2507.15146", "pdf": "https://arxiv.org/pdf/2507.15146", "abs": "https://arxiv.org/abs/2507.15146", "authors": ["Sebastian A. Cruz Romero", "Misael J. Mercado Hernandez", "Samir Y. Ali Rivera", "Jorge A. Santiago Fernandez", "Wilfredo E. Lugo Beauchamp"], "title": "Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications", "categories": ["cs.ET", "cs.AI", "cs.CV", "cs.CY", "cs.LG", "cs.SE"], "comment": "Accepted at IEEE Global Humanitarian Technology Conference 2025", "summary": "The design of medical systems for remote, resource-limited environments faces\npersistent challenges due to poor interoperability, lack of offline support,\nand dependency on costly infrastructure. Many existing digital health solutions\nneglect these constraints, limiting their effectiveness for frontline health\nworkers in underserved regions. This paper presents a portable, edge-enabled\nElectronic Health Record platform optimized for offline-first operation, secure\npatient data management, and modular diagnostic integration. Running on\nsmall-form factor embedded devices, it provides AES-256 encrypted local storage\nwith optional cloud synchronization for interoperability. As a use case, we\nintegrated a non-invasive anemia screening module leveraging fingernail pallor\nanalysis. Trained on 250 patient cases (27\\% anemia prevalence) with\nKDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL\nand MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To\noptimize performance, a YOLOv8n-based nail bed detector was quantized to INT8,\nreducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5\nat 0.995. The system emphasizes low-cost deployment, modularity, and data\nprivacy compliance (HIPAA/GDPR), addressing critical barriers to digital health\nadoption in disconnected settings. Our work demonstrates a scalable approach to\nenhance portable health information systems and support frontline healthcare in\nunderserved regions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u504f\u8fdc\u5730\u533a\u7684\u4fbf\u643a\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5e73\u53f0\uff0c\u4ee5\u8d2b\u8840\u7b5b\u67e5\u4e3a\u4f8b\u5c55\u793a\u5176\u6027\u80fd\u4f18\u5316\uff0c\u89e3\u51b3\u6570\u5b57\u5065\u5eb7\u91c7\u7528\u969c\u788d\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u7cfb\u7edf\u5728\u504f\u8fdc\u3001\u8d44\u6e90\u53d7\u9650\u73af\u5883\u9762\u4e34\u4e92\u64cd\u4f5c\u6027\u5dee\u3001\u65e0\u79bb\u7ebf\u652f\u6301\u548c\u4f9d\u8d56\u6602\u8d35\u57fa\u7840\u8bbe\u65bd\u7b49\u95ee\u9898\uff0c\u9700\u5f00\u53d1\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4fbf\u643a\u3001\u652f\u6301\u8fb9\u7f18\u8ba1\u7b97\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5e73\u53f0\uff0c\u91c7\u7528AES - 256\u52a0\u5bc6\u672c\u5730\u5b58\u50a8\u4e0e\u53ef\u9009\u4e91\u540c\u6b65\uff0c\u96c6\u6210\u8d2b\u8840\u7b5b\u67e5\u6a21\u5757\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u6a21\u578b\u548cYOLOv8n\u91cf\u5316\u4f18\u5316\u3002", "result": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u6d4b\u8bd5RMSE\u4e3a1.969 g/dL\uff0cMAE\u4e3a1.490 g/dL\uff0c\u4e25\u91cd\u6027\u6a21\u578b\u7075\u654f\u5ea6\u8fbe79.2%\uff0c\u91cf\u5316\u540e\u63a8\u7406\u5ef6\u8fdf\u4ece46.96 ms\u964d\u81f321.50 ms\uff0cmAP@0.5\u7ef4\u6301\u57280.995\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5f3a\u8c03\u4f4e\u6210\u672c\u90e8\u7f72\u3001\u6a21\u5757\u5316\u548c\u6570\u636e\u9690\u79c1\u5408\u89c4\uff0c\u4e3a\u63d0\u5347\u4fbf\u643a\u5065\u5eb7\u4fe1\u606f\u7cfb\u7edf\u548c\u652f\u6301\u504f\u8fdc\u5730\u533a\u4e00\u7ebf\u533b\u7597\u63d0\u4f9b\u53ef\u6269\u5c55\u65b9\u6848\u3002"}}
{"id": "2507.14677", "pdf": "https://arxiv.org/pdf/2507.14677", "abs": "https://arxiv.org/abs/2507.14677", "authors": ["Yiming Xu", "Zhen Peng", "Bin Shi", "Xu Hua", "Bo Dong", "Song Wang", "Chen Chen"], "title": "Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural Imbalance Perspective", "categories": ["cs.LG"], "comment": "Accepted by AAAI2025", "summary": "The superiority of graph contrastive learning (GCL) has prompted its\napplication to anomaly detection tasks for more powerful risk warning systems.\nUnfortunately, existing GCL-based models tend to excessively prioritize overall\ndetection performance while neglecting robustness to structural imbalance,\nwhich can be problematic for many real-world networks following power-law\ndegree distributions. Particularly, GCL-based methods may fail to capture tail\nanomalies (abnormal nodes with low degrees). This raises concerns about the\nsecurity and robustness of current anomaly detection algorithms and therefore\nhinders their applicability in a variety of realistic high-risk scenarios. To\nthe best of our knowledge, research on the robustness of graph anomaly\ndetection to structural imbalance has received little scrutiny. To address the\nabove issues, this paper presents a novel GCL-based framework named AD-GCL. It\ndevises the neighbor pruning strategy to filter noisy edges for head nodes and\nfacilitate the detection of genuine tail nodes by aligning from head nodes to\nforged tail nodes. Moreover, AD-GCL actively explores potential neighbors to\nenlarge the receptive field of tail nodes through anomaly-guided neighbor\ncompletion. We further introduce intra- and inter-view consistency loss of the\noriginal and augmentation graph for enhanced representation. The performance\nevaluation of the whole, head, and tail nodes on multiple datasets validates\nthe comprehensive superiority of the proposed AD-GCL in detecting both head\nanomalies and tail anomalies.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u56fe\u5bf9\u6bd4\u5b66\u4e60\uff08GCL\uff09\u7684\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u5ffd\u89c6\u7ed3\u6784\u4e0d\u5e73\u8861\u9c81\u68d2\u6027\uff0c\u672c\u6587\u63d0\u51faAD - GCL\u6846\u67b6\uff0c\u9a8c\u8bc1\u5176\u5728\u68c0\u6d4b\u5934\u90e8\u548c\u5c3e\u90e8\u5f02\u5e38\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eGCL\u7684\u6a21\u578b\u8fc7\u5ea6\u5173\u6ce8\u6574\u4f53\u68c0\u6d4b\u6027\u80fd\uff0c\u5ffd\u7565\u7ed3\u6784\u4e0d\u5e73\u8861\u9c81\u68d2\u6027\uff0c\u96be\u4ee5\u68c0\u6d4b\u5c3e\u90e8\u5f02\u5e38\uff0c\u5f71\u54cd\u7b97\u6cd5\u5728\u73b0\u5b9e\u9ad8\u98ce\u9669\u573a\u666f\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faAD - GCL\u6846\u67b6\uff0c\u91c7\u7528\u90bb\u5c45\u4fee\u526a\u7b56\u7565\u8fc7\u6ee4\u5934\u90e8\u8282\u70b9\u566a\u58f0\u8fb9\uff0c\u901a\u8fc7\u5f02\u5e38\u5f15\u5bfc\u7684\u90bb\u5c45\u8865\u5168\u6269\u5927\u5c3e\u90e8\u8282\u70b9\u611f\u53d7\u91ce\uff0c\u5f15\u5165\u89c6\u56fe\u5185\u548c\u89c6\u56fe\u95f4\u4e00\u81f4\u6027\u635f\u5931\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf9\u6574\u4f53\u3001\u5934\u90e8\u548c\u5c3e\u90e8\u8282\u70b9\u7684\u6027\u80fd\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86AD - GCL\u5728\u68c0\u6d4b\u5934\u90e8\u548c\u5c3e\u90e8\u5f02\u5e38\u4e0a\u7684\u7efc\u5408\u4f18\u8d8a\u6027\u3002", "conclusion": "AD - GCL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8eGCL\u6a21\u578b\u5728\u7ed3\u6784\u4e0d\u5e73\u8861\u65b9\u9762\u7684\u95ee\u9898\uff0c\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.15411", "pdf": "https://arxiv.org/pdf/2507.15411", "abs": "https://arxiv.org/abs/2507.15411", "authors": ["Wissam Gherissi", "Mehdi Acheli", "Joyce El Haddad", "Daniela Grigori"], "title": "Predictive Process Monitoring Using Object-centric Graph Embeddings", "categories": ["cs.AI", "cs.LG"], "comment": "ICSOC Workshops 2024, Dec 2024, Tunis, Tunisia", "summary": "Object-centric predictive process monitoring explores and utilizes\nobject-centric event logs to enhance process predictions. The main challenge\nlies in extracting relevant information and building effective models. In this\npaper, we propose an end-to-end model that predicts future process behavior,\nfocusing on two tasks: next activity prediction and next event time. The\nproposed model employs a graph attention network to encode activities and their\nrelationships, combined with an LSTM network to handle temporal dependencies.\nEvaluated on one reallife and three synthetic event logs, the model\ndemonstrates competitive performance compared to state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u7aef\u5230\u7aef\u6a21\u578b\u8fdb\u884c\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\uff0c\u5728\u5b9e\u9645\u548c\u5408\u6210\u65e5\u5fd7\u4e0a\u8868\u73b0\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u5b58\u5728\u63d0\u53d6\u4fe1\u606f\u548c\u6784\u5efa\u6709\u6548\u6a21\u578b\u7684\u6311\u6218\uff0c\u9700\u63d0\u5347\u6d41\u7a0b\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u7528\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u7f16\u7801\u6d3b\u52a8\u53ca\u5173\u7cfb\uff0c\u7ed3\u5408LSTM\u5904\u7406\u65f6\u95f4\u4f9d\u8d56\u3002", "result": "\u5728\u4e00\u4e2a\u771f\u5b9e\u548c\u4e09\u4e2a\u5408\u6210\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u8bc4\u4f30\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u6240\u63d0\u6a21\u578b\u53ef\u7528\u4e8e\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\uff0c\u6709\u8f83\u597d\u6027\u80fd\u3002"}}
{"id": "2507.14679", "pdf": "https://arxiv.org/pdf/2507.14679", "abs": "https://arxiv.org/abs/2507.14679", "authors": ["Zixin Xu", "Zhijie Wang", "Zhiyuan Pan"], "title": "GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The exponential growth of spam text on the Internet necessitates robust\ndetection mechanisms to mitigate risks such as information leakage and social\ninstability. This work addresses two principal challenges: adversarial\nstrategies employed by spammers and the scarcity of labeled data. We propose a\nnovel spam-text detection framework GCC-Spam, which integrates three core\ninnovations. First, a character similarity network captures orthographic and\nphonetic features to counter character-obfuscation attacks and furthermore\nproduces sentence embeddings for downstream classification. Second, contrastive\nlearning enhances discriminability by optimizing the latent-space distance\nbetween spam and normal texts. Third, a Generative Adversarial Network (GAN)\ngenerates realistic pseudo-spam samples to alleviate data scarcity while\nimproving model robustness and classification accuracy. Extensive experiments\non real-world datasets demonstrate that our model outperforms baseline\napproaches, achieving higher detection rates with significantly fewer labeled\nexamples.", "AI": {"tldr": "\u4e3a\u5e94\u5bf9\u4e92\u8054\u7f51\u5783\u573e\u6587\u672c\u589e\u957f\uff0c\u63d0\u51faGCC - Spam\u6846\u67b6\u3002\u8be5\u6846\u67b6\u542b\u5b57\u7b26\u76f8\u4f3c\u5ea6\u7f51\u7edc\u3001\u5bf9\u6bd4\u5b66\u4e60\u548cGAN\u7b49\u521b\u65b0\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4e92\u8054\u7f51\u5783\u573e\u6587\u672c\u6307\u6570\u7ea7\u589e\u957f\uff0c\u5e26\u6765\u4fe1\u606f\u6cc4\u9732\u548c\u793e\u4f1a\u4e0d\u7a33\u5b9a\u98ce\u9669\uff0c\u540c\u65f6\u5b58\u5728\u5783\u573e\u90ae\u4ef6\u53d1\u9001\u8005\u7684\u5bf9\u6297\u7b56\u7565\u53ca\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u4e24\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faGCC - Spam\u6846\u67b6\uff0c\u5305\u62ec\u5b57\u7b26\u76f8\u4f3c\u5ea6\u7f51\u7edc\u6355\u6349\u7279\u5f81\u5e76\u751f\u6210\u53e5\u5b50\u5d4c\u5165\uff0c\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u6f5c\u5728\u7a7a\u95f4\u8ddd\u79bb\uff0cGAN\u751f\u6210\u4f2a\u5783\u573e\u6837\u672c\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6807\u6ce8\u6837\u672c\u663e\u8457\u51cf\u5c11\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u7387\u3002", "conclusion": "GCC - Spam\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u5783\u573e\u6587\u672c\u68c0\u6d4b\u4e2d\u7684\u5bf9\u6297\u7b56\u7565\u548c\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\u3002"}}
{"id": "2507.15457", "pdf": "https://arxiv.org/pdf/2507.15457", "abs": "https://arxiv.org/abs/2507.15457", "authors": ["Orlenys L\u00f3pez-Pintado", "Jannis Rosenbaum", "Marlon Dumas"], "title": "Optimization of Activity Batching Policies in Business Processes", "categories": ["cs.AI", "I.2.8"], "comment": null, "summary": "In business processes, activity batching refers to packing multiple activity\ninstances for joint execution. Batching allows managers to trade off cost and\nprocessing effort against waiting time. Larger and less frequent batches may\nlower costs by reducing processing effort and amortizing fixed costs, but they\ncreate longer waiting times. In contrast, smaller and more frequent batches\nreduce waiting times but increase fixed costs and processing effort. A batching\npolicy defines how activity instances are grouped into batches and when each\nbatch is activated. This paper addresses the problem of discovering batching\npolicies that strike optimal trade-offs between waiting time, processing\neffort, and cost. The paper proposes a Pareto optimization approach that starts\nfrom a given set (possibly empty) of activity batching policies and generates\nalternative policies for each batched activity via intervention heuristics.\nEach heuristic identifies an opportunity to improve an activity's batching\npolicy with respect to a metric (waiting time, processing time, cost, or\nresource utilization) and an associated adjustment to the activity's batching\npolicy (the intervention). The impact of each intervention is evaluated via\nsimulation. The intervention heuristics are embedded in an optimization\nmeta-heuristic that triggers interventions to iteratively update the Pareto\nfront of the interventions identified so far. The paper considers three\nmeta-heuristics: hill-climbing, simulated annealing, and reinforcement\nlearning. An experimental evaluation compares the proposed approach based on\nintervention heuristics against the same (non-heuristic guided) meta-heuristics\nbaseline regarding convergence, diversity, and cycle time gain of\nPareto-optimal policies.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u6d3b\u52a8\u6279\u5904\u7406\u7b56\u7565\u95ee\u9898\uff0c\u63d0\u51fa\u5e15\u7d2f\u6258\u4f18\u5316\u65b9\u6cd5\u751f\u6210\u66ff\u4ee3\u7b56\u7565\uff0c\u7528\u6a21\u62df\u8bc4\u4f30\u5e72\u9884\u6548\u679c\uff0c\u8003\u8651\u4e09\u79cd\u5143\u542f\u53d1\u5f0f\u65b9\u6cd5\u5e76\u5b9e\u9a8c\u5bf9\u6bd4\u3002", "motivation": "\u89e3\u51b3\u53d1\u73b0\u80fd\u5728\u7b49\u5f85\u65f6\u95f4\u3001\u5904\u7406\u5de5\u4f5c\u91cf\u548c\u6210\u672c\u4e4b\u95f4\u5b9e\u73b0\u6700\u4f18\u6743\u8861\u7684\u6279\u5904\u7406\u7b56\u7565\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e15\u7d2f\u6258\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e72\u9884\u542f\u53d1\u5f0f\u751f\u6210\u66ff\u4ee3\u7b56\u7565\uff0c\u7528\u6a21\u62df\u8bc4\u4f30\u5e72\u9884\u6548\u679c\uff0c\u5d4c\u5165\u4e09\u79cd\u5143\u542f\u53d1\u5f0f\uff08\u722c\u5c71\u6cd5\u3001\u6a21\u62df\u9000\u706b\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u3002", "result": "\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u5bf9\u6bd4\u57fa\u4e8e\u5e72\u9884\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u4e0e\u65e0\u542f\u53d1\u5f0f\u5f15\u5bfc\u7684\u5143\u542f\u53d1\u5f0f\u57fa\u7ebf\u5728\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u7684\u6536\u655b\u6027\u3001\u591a\u6837\u6027\u548c\u5468\u671f\u65f6\u95f4\u589e\u76ca\u65b9\u9762\u7684\u8868\u73b0\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\uff0c\u4f46\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4\u4e0d\u540c\u65b9\u6cd5\uff0c\u4e3a\u53d1\u73b0\u6700\u4f18\u6279\u5904\u7406\u7b56\u7565\u63d0\u4f9b\u4e86\u601d\u8def\u548c\u65b9\u6cd5\u3002"}}
{"id": "2507.14698", "pdf": "https://arxiv.org/pdf/2507.14698", "abs": "https://arxiv.org/abs/2507.14698", "authors": ["Xuetao Lin", "Tianhao Peng", "Peihong Dai", "Yu Liang", "Wenjun Wu"], "title": "Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition", "categories": ["cs.LG", "cs.AI", "cs.HC", "eess.SP"], "comment": null, "summary": "EEG-based emotion recognition plays an important role in developing adaptive\nbrain-computer communication systems, yet faces two fundamental challenges in\npractical implementations: (1) effective integration of non-stationary\nspatial-temporal neural patterns, (2) robust adaptation to dynamic emotional\nintensity variations in real-world scenarios. This paper proposes SST-CL, a\nnovel framework integrating spatial-temporal transformers with curriculum\nlearning. Our method introduces two core components: a spatial encoder that\nmodels inter-channel relationships and a temporal encoder that captures\nmulti-scale dependencies through windowed attention mechanisms, enabling\nsimultaneous extraction of spatial correlations and temporal dynamics from EEG\nsignals. Complementing this architecture, an intensity-aware curriculum\nlearning strategy progressively guides training from high-intensity to\nlow-intensity emotional states through dynamic sample scheduling based on a\ndual difficulty assessment. Comprehensive experiments on three benchmark\ndatasets demonstrate state-of-the-art performance across various emotional\nintensity levels, with ablation studies confirming the necessity of both\narchitectural components and the curriculum learning mechanism.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSST - CL\u6846\u67b6\u7528\u4e8e\u57fa\u4e8eEEG\u7684\u60c5\u7eea\u8bc6\u522b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5404\u60c5\u7eea\u5f3a\u5ea6\u6c34\u5e73\u4e0a\u8fbeSOTA\u3002", "motivation": "\u57fa\u4e8eEEG\u7684\u60c5\u7eea\u8bc6\u522b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u6709\u6548\u6574\u5408\u65f6\u7a7a\u795e\u7ecf\u6a21\u5f0f\u548c\u9002\u5e94\u60c5\u7eea\u5f3a\u5ea6\u53d8\u5316\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faSST - CL\u6846\u67b6\uff0c\u5305\u542b\u7a7a\u95f4\u7f16\u7801\u5668\u548c\u65f6\u95f4\u7f16\u7801\u5668\uff0c\u7ed3\u5408\u5f3a\u5ea6\u611f\u77e5\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e0d\u540c\u60c5\u7eea\u5f3a\u5ea6\u6c34\u5e73\u4e0a\u8fbe\u5230\u4e86SOTA\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u67b6\u6784\u7ec4\u4ef6\u548c\u8bfe\u7a0b\u5b66\u4e60\u673a\u5236\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "SST - CL\u6846\u67b6\u53ef\u6709\u6548\u89e3\u51b3\u57fa\u4e8eEEG\u7684\u60c5\u7eea\u8bc6\u522b\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2507.15509", "pdf": "https://arxiv.org/pdf/2507.15509", "abs": "https://arxiv.org/abs/2507.15509", "authors": ["Lei Chen", "Xuanle Zhao", "Zhixiong Zeng", "Jing Huang", "Yufeng Zhong", "Lin Ma"], "title": "Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner", "categories": ["cs.AI", "cs.CV"], "comment": "technical report", "summary": "Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based\non reinforcement learning fine-tuning has received widespread attention from\nthe community. Previous R1-Style methods mainly focus on mathematical reasoning\nand code intelligence. It is of great research significance to verify their\nadvantages on more general multimodal data. Chart is an important multimodal\ndata type with rich information, which brings important research challenges in\ncomplex reasoning. In this work, we introduce Chart-R1, a chart-domain\nvision-language model with reinforcement learning fine-tuning to enable complex\nchart reasoning. To support Chart-R1, we first propose a novel programmatic\ndata synthesis technology to generate high-quality step-by-step chart reasoning\ndata covering single- and multi-subcharts, which makes up for the lack of\nreasoning data in the chart domain. Then we develop a two-stage training\nstrategy: Chart-COT with step-by-step chain-of-thought supervision, and\nChart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims\nto decompose complex chart reasoning tasks into fine-grained, understandable\nsubtasks through step-by-step supervision, which lays a good foundation for\nimproving the reasoning level of reinforcement learning. Chart-RFT utilize the\ntypical group relative policy optimization strategy, in which a relatively soft\nreward is adopted for numerical response to emphasize the numerical sensitivity\nin the chart domain. We conduct extensive experiments on open-source benchmarks\nand self-built chart reasoning dataset (\\emph{i.e., ChartRQA}). Experimental\nresults show that Chart-R1 has significant advantages compared to chart-domain\nmethods, even comparable to open/closed source large-scale models (\\emph{e.g.,\nGPT-4o, Claude-3.5}).", "AI": {"tldr": "\u53d7OpenAI-o1/o3\u548cDeepseek-R1\u542f\u53d1\uff0c\u672c\u6587\u63d0\u51faChart - R1\u6a21\u578b\u7528\u4e8e\u590d\u6742\u56fe\u8868\u63a8\u7406\uff0c\u91c7\u7528\u65b0\u7684\u6570\u636e\u5408\u6210\u6280\u672f\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u4ee5\u5f80R1 - Style\u65b9\u6cd5\u4e3b\u8981\u7528\u4e8e\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u667a\u80fd\uff0c\u9a8c\u8bc1\u5176\u5728\u66f4\u901a\u7528\u7684\u591a\u6a21\u6001\u6570\u636e\uff08\u5982\u56fe\u8868\uff09\u4e0a\u7684\u4f18\u52bf\u6709\u91cd\u8981\u7814\u7a76\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u7a0b\u5e8f\u5f0f\u6570\u636e\u5408\u6210\u6280\u672f\u751f\u6210\u9ad8\u8d28\u91cf\u56fe\u8868\u63a8\u7406\u6570\u636e\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5373\u6709\u9010\u6b65\u601d\u7ef4\u94fe\u76d1\u7763\u7684Chart - COT\u548c\u6709\u6570\u503c\u654f\u611f\u5f3a\u5316\u5fae\u8c03\u7684Chart - RFT\u3002", "result": "\u5728\u5f00\u6e90\u57fa\u51c6\u548c\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cChart - R1\u76f8\u6bd4\u56fe\u8868\u9886\u57df\u65b9\u6cd5\u6709\u663e\u8457\u4f18\u52bf\uff0c\u751a\u81f3\u53ef\u4e0e\u4e00\u4e9b\u5f00\u6e90/\u95ed\u6e90\u5927\u6a21\u578b\u5ab2\u7f8e\u3002", "conclusion": "Chart - R1\u6a21\u578b\u80fd\u6709\u6548\u5b9e\u73b0\u590d\u6742\u56fe\u8868\u63a8\u7406\uff0c\u5728\u56fe\u8868\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.14706", "pdf": "https://arxiv.org/pdf/2507.14706", "abs": "https://arxiv.org/abs/2507.14706", "authors": ["Claudio Giusti", "Luca Guarnera", "Mirko Casu", "Sebastiano Battiato"], "title": "Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 14 figures", "summary": "Detecting fraudulent credit card transactions remains a significant\nchallenge, due to the extreme class imbalance in real-world data and the often\nsubtle patterns that separate fraud from legitimate activity. Existing research\ncommonly attempts to address this by generating synthetic samples for the\nminority class using approaches such as GANs, VAEs, or hybrid generative\nmodels. However, these techniques, particularly when applied only to\nminority-class data, tend to result in overconfident classifiers and poor\nlatent cluster separation, ultimately limiting real-world detection\nperformance. In this study, we propose the Causal Prototype Attention\nClassifier (CPAC), an interpretable architecture that promotes class-aware\nclustering and improved latent space structure through prototype-based\nattention mechanisms and we will couple it with the encoder in a VAE-GAN\nallowing it to offer a better cluster separation moving beyond post-hoc sample\naugmentation. We compared CPAC-augmented models to traditional oversamplers,\nsuch as SMOTE, as well as to state-of-the-art generative models, both with and\nwithout CPAC-based latent classifiers. Our results show that classifier-guided\nlatent shaping with CPAC delivers superior performance, achieving an F1-score\nof 93.14\\% percent and recall of 90.18\\%, along with improved latent cluster\nseparation. Further ablation studies and visualizations provide deeper insight\ninto the benefits and limitations of classifier-driven representation learning\nfor fraud detection. The codebase for this work will be available at final\nsubmission.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCausal Prototype Attention Classifier (CPAC)\u7528\u4e8e\u4fe1\u7528\u5361\u6b3a\u8bc8\u4ea4\u6613\u68c0\u6d4b\uff0c\u5bf9\u6bd4\u4f20\u7edf\u8fc7\u91c7\u6837\u65b9\u6cd5\u548c\u5148\u8fdb\u751f\u6210\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793aCPAC\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u4fe1\u7528\u5361\u6b3a\u8bc8\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u56e0\u4ec5\u5904\u7406\u5c11\u6570\u7c7b\u6570\u636e\u5bfc\u81f4\u5206\u7c7b\u5668\u8fc7\u5ea6\u81ea\u4fe1\u548c\u6f5c\u5728\u805a\u7c7b\u5206\u79bb\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u68c0\u6d4b\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCPAC\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u539f\u578b\u7684\u6ce8\u610f\u529b\u673a\u5236\u4fc3\u8fdb\u7c7b\u611f\u77e5\u805a\u7c7b\u548c\u6539\u5584\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\uff0c\u5e76\u5c06\u5176\u4e0eVAE - GAN\u4e2d\u7684\u7f16\u7801\u5668\u7ed3\u5408\uff1b\u5bf9\u6bd4CPAC\u589e\u5f3a\u6a21\u578b\u4e0e\u4f20\u7edf\u8fc7\u91c7\u6837\u5668\u53ca\u5148\u8fdb\u751f\u6210\u6a21\u578b\u3002", "result": "CPAC\u5b9e\u73b0\u4e8693.14%\u7684F1\u5206\u6570\u548c90.18%\u7684\u53ec\u56de\u7387\uff0c\u6539\u5584\u4e86\u6f5c\u5728\u805a\u7c7b\u5206\u79bb\u3002", "conclusion": "\u57fa\u4e8eCPAC\u7684\u5206\u7c7b\u5668\u5f15\u5bfc\u6f5c\u5728\u5851\u5f62\u5728\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u6d88\u878d\u7814\u7a76\u548c\u53ef\u89c6\u5316\u6709\u52a9\u4e8e\u6df1\u5165\u4e86\u89e3\u5176\u4f18\u7f3a\u70b9\u3002"}}
{"id": "2507.15518", "pdf": "https://arxiv.org/pdf/2507.15518", "abs": "https://arxiv.org/abs/2507.15518", "authors": ["Sizhou Chen", "Shufan Jiang", "Chi Zhang", "Xiao-Lei Zhang", "Xuelong Li"], "title": "HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Creating an immersive and interactive theatrical experience is a long-term\ngoal in the field of interactive narrative. The emergence of large language\nmodel (LLM) is providing a new path to achieve this goal. However, existing\nLLM-based drama generation methods often result in AI agents that lack\ninitiative and cannot interact with the physical environment. Furthermore,\nthese methods typically require detailed user input to drive the drama. These\nlimitations reduce the interactivity and immersion of online real-time\nperformance. To address the above challenges, we propose HAMLET, a multi-agent\nframework focused on drama creation and online performance. Given a simple\ntopic, the framework generates a narrative blueprint, guiding the subsequent\nimprovisational performance. During the online performance, each actor is given\nan autonomous mind. This means that actors can make independent decisions based\non their own background, goals, and emotional state. In addition to\nconversations with other actors, their decisions can also change the state of\nscene props through actions such as opening a letter or picking up a weapon.\nThe change is then broadcast to other related actors, updating what they know\nand care about, which in turn influences their next action. To evaluate the\nquality of drama performance, we designed an evaluation method to assess three\nprimary aspects, including character performance, narrative quality, and\ninteraction experience. The experimental evaluation shows that HAMLET can\ncreate expressive and coherent theatrical experiences. Our code, dataset and\nmodels are available at https://github.com/HAMLET-2025/HAMLET.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6846\u67b6HAMLET\u7528\u4e8e\u620f\u5267\u521b\u4f5c\u548c\u5728\u7ebf\u8868\u6f14\uff0c\u53ef\u63d0\u5347\u4e92\u52a8\u6027\u4e0e\u6c89\u6d78\u611f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6548\u679c\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u620f\u5267\u751f\u6210\u65b9\u6cd5\u5b58\u5728AI\u667a\u80fd\u4f53\u7f3a\u4e4f\u4e3b\u52a8\u6027\u3001\u65e0\u6cd5\u4e0e\u7269\u7406\u73af\u5883\u4e92\u52a8\u3001\u4f9d\u8d56\u8be6\u7ec6\u7528\u6237\u8f93\u5165\u7b49\u95ee\u9898\uff0c\u964d\u4f4e\u4e86\u4e92\u52a8\u6027\u548c\u6c89\u6d78\u611f\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6846\u67b6HAMLET\uff0c\u7ed9\u5b9a\u7b80\u5355\u4e3b\u9898\u751f\u6210\u53d9\u4e8b\u84dd\u56fe\uff0c\u8868\u6f14\u4e2d\u6bcf\u4e2a\u6f14\u5458\u6709\u81ea\u4e3b\u601d\u7ef4\uff0c\u53ef\u505a\u72ec\u7acb\u51b3\u7b56\u5e76\u6539\u53d8\u573a\u666f\u9053\u5177\u72b6\u6001\uff0c\u8bbe\u8ba1\u8bc4\u4f30\u65b9\u6cd5\u4ece\u4e09\u65b9\u9762\u8bc4\u4f30\u620f\u5267\u8868\u6f14\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660eHAMLET\u80fd\u521b\u9020\u5bcc\u6709\u8868\u73b0\u529b\u548c\u8fde\u8d2f\u6027\u7684\u620f\u5267\u4f53\u9a8c\u3002", "conclusion": "HAMLET\u6846\u67b6\u6709\u6548\u89e3\u51b3\u73b0\u6709\u95ee\u9898\uff0c\u80fd\u63d0\u5347\u5728\u7ebf\u5b9e\u65f6\u8868\u6f14\u7684\u4e92\u52a8\u6027\u548c\u6c89\u6d78\u611f\uff0c\u4ee3\u7801\u7b49\u8d44\u6e90\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.14715", "pdf": "https://arxiv.org/pdf/2507.14715", "abs": "https://arxiv.org/abs/2507.14715", "authors": ["Rachid Karami", "Rajeev Patwari", "Hyoukjun Kwon", "Ashish Sirasao"], "title": "Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications on Emerging Heterogeneous Systems", "categories": ["cs.LG"], "comment": null, "summary": "The integration of generative AI models, particularly large language models\n(LLMs), into real-time multi-model AI applications such as video conferencing\nand gaming is giving rise to a new class of workloads: real-time generative AI\n(RTGen). These workloads combine the compute intensity and dynamic execution\npatterns of generative models with the stringent latency and concurrency\nconstraints of real-time inference. To meet the diverse demands of RTGen\nworkloads, modern edge platforms increasingly adopt heterogeneous\nsystem-on-chip (SoC) architectures that integrate CPUs, GPUs, and NPUs. Despite\nthe potential of heterogeneous SoC, the scheduling space complexity and\nperformance implications of RTGen workloads on such platforms remain\nunderexplored. In this work, we perform a comprehensive characterization of\nRTGen workloads on AMD's latest heterogeneous SoC, Ryzen AI. We construct\nrealistic multi-model scenarios inspired by industry use cases and profile\nmodel performance across all available backends. Using this data, we evaluate\nfive scheduling policies and their impact on both real-time metrics (e.g.,\ndeadline violation rate) and LLM performance (e.g., time-to-first-token and\ntokens-per-second). Our results show that scheduling decisions significantly\naffect workload performance (e.g., leading to a 41.7% difference in deadline\nviolation rates on average), and highlight the need for scheduling strategies\nthat are aware of workload dynamics and hardware heterogeneity. Our findings\nunderscore the importance of workload-aware, dynamic heterogeneous scheduling\nin enabling high-performance, on-device RTGen applications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5b9e\u65f6\u751f\u6210\u5f0fAI\uff08RTGen\uff09\u5de5\u4f5c\u8d1f\u8f7d\u5728AMD\u5f02\u6784SoC\u4e0a\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cd\u8c03\u5ea6\u7b56\u7565\uff0c\u7ed3\u679c\u663e\u793a\u8c03\u5ea6\u51b3\u7b56\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u7684\u52a8\u6001\u5f02\u6784\u8c03\u5ea6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5b9e\u65f6\u751f\u6210\u5f0fAI\u5de5\u4f5c\u8d1f\u8f7d\u5728\u5f02\u6784SoC\u5e73\u53f0\u4e0a\u7684\u8c03\u5ea6\u7a7a\u95f4\u590d\u6742\u6027\u548c\u6027\u80fd\u5f71\u54cd\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u5728AMD Ryzen AI\u5f02\u6784SoC\u4e0a\u5bf9RTGen\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u5168\u9762\u8868\u5f81\uff0c\u6784\u5efa\u591a\u6a21\u578b\u573a\u666f\u5e76\u5728\u6240\u6709\u53ef\u7528\u540e\u7aef\u8fdb\u884c\u6027\u80fd\u5206\u6790\uff0c\u8bc4\u4f30\u4e94\u79cd\u8c03\u5ea6\u7b56\u7565\u3002", "result": "\u8c03\u5ea6\u51b3\u7b56\u663e\u8457\u5f71\u54cd\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\uff0c\u5982\u5e73\u5747\u622a\u6b62\u65f6\u95f4\u8fdd\u89c4\u7387\u5dee\u5f02\u8fbe41.7%\u3002", "conclusion": "\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u7684\u52a8\u6001\u5f02\u6784\u8c03\u5ea6\u5bf9\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u8bbe\u5907\u7aefRTGen\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.15521", "pdf": "https://arxiv.org/pdf/2507.15521", "abs": "https://arxiv.org/abs/2507.15521", "authors": ["Cole Robertson", "Philip Wolff"], "title": "LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning", "categories": ["cs.AI"], "comment": "Manuscript comprises 14 pages, 4 figures, 4 tables in the Technical\n  Appendix and Supplementary Material, and is under review at NeurIPS 2025", "summary": "Do large language models (LLMs) construct and manipulate internal world\nmodels, or do they rely solely on statistical associations represented as\noutput layer token probabilities? We adapt cognitive science methodologies from\nhuman mental models research to test LLMs on pulley system problems using\nTikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical\nadvantage (MA). State-of-the-art models performed marginally but significantly\nabove chance, and their estimates correlated significantly with ground-truth\nMA. Significant correlations between number of pulleys and model estimates\nsuggest that models employed a pulley counting heuristic, without necessarily\nsimulating pulley systems to derive precise values. Study 2 tested this by\nprobing whether LLMs represent global features crucial to MA estimation. Models\nevaluated a functionally connected pulley system against a fake system with\nrandomly placed components. Without explicit cues, models identified the\nfunctional system as having greater MA with F1=0.8, suggesting LLMs could\nrepresent systems well enough to differentiate jumbled from functional systems.\nStudy 3 built on this by asking LLMs to compare functional systems with matched\nsystems which were connected up but which transferred no force to the weight;\nLLMs identified the functional system with F1=0.46, suggesting random guessing.\nInsofar as they may generalize, these findings are compatible with the notion\nthat LLMs manipulate internal world models, sufficient to exploit statistical\nassociations between pulley count and MA (Study 1), and to approximately\nrepresent system components' spatial relations (Study 2). However, they may\nlack the facility to reason over nuanced structural connectivity (Study 3). We\nconclude by advocating the utility of cognitive scientific methods to evaluate\nthe world-modeling capacities of artificial intelligence systems.", "AI": {"tldr": "\u672c\u6587\u91c7\u7528\u8ba4\u77e5\u79d1\u5b66\u65b9\u6cd5\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6ed1\u8f6e\u7cfb\u7edf\u95ee\u9898\u7684\u5904\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u80fd\u5229\u7528\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7ec6\u5fae\u7ed3\u6784\u8fde\u63a5\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5021\u5bfc\u7528\u8ba4\u77e5\u79d1\u5b66\u65b9\u6cd5\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u662f\u6784\u5efa\u548c\u64cd\u7eb5\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u8fd8\u662f\u4ec5\u4f9d\u8d56\u8f93\u51fa\u5c42\u6807\u8bb0\u6982\u7387\u7684\u7edf\u8ba1\u5173\u8054\u3002", "method": "\u91c7\u7528\u4eba\u7c7b\u5fc3\u7406\u6a21\u578b\u7814\u7a76\u4e2d\u7684\u8ba4\u77e5\u79d1\u5b66\u65b9\u6cd5\uff0c\u4f7f\u7528TikZ\u6e32\u67d3\u7684\u523a\u6fc0\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6ed1\u8f6e\u7cfb\u7edf\u95ee\u9898\u6d4b\u8bd5\uff0c\u5206\u4e09\u4e2a\u7814\u7a76\u9010\u6b65\u6df1\u5165\u3002", "result": "\u7814\u7a761\u8868\u660e\u6a21\u578b\u80fd\u7565\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\u4f30\u8ba1\u673a\u68b0\u4f18\u52bf\uff0c\u91c7\u7528\u4e86\u6ed1\u8f6e\u8ba1\u6570\u542f\u53d1\u5f0f\uff1b\u7814\u7a762\u8868\u660e\u6a21\u578b\u80fd\u533a\u5206\u529f\u80fd\u7cfb\u7edf\u548c\u6742\u4e71\u7cfb\u7edf\uff1b\u7814\u7a763\u8868\u660e\u6a21\u578b\u5728\u533a\u5206\u529f\u80fd\u7cfb\u7edf\u548c\u8fde\u63a5\u4f46\u4e0d\u4f20\u9012\u529b\u7684\u7cfb\u7edf\u65f6\u63a5\u8fd1\u968f\u673a\u731c\u6d4b\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5229\u7528\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7ec6\u5fae\u7ed3\u6784\u8fde\u63a5\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5021\u5bfc\u7528\u8ba4\u77e5\u79d1\u5b66\u65b9\u6cd5\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\u3002"}}
{"id": "2507.14722", "pdf": "https://arxiv.org/pdf/2507.14722", "abs": "https://arxiv.org/abs/2507.14722", "authors": ["Mat\u011bj Kripner", "Michal \u0160ustr", "Milan Straka"], "title": "LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Automated theorem proving (ATP) has been a classical problem in artificial\nintelligence since its inception, yet it remains challenging due to its vast\nstate and action space. Large language models (LLMs) have recently emerged as a\npromising heuristic for ATP, but they lack correctness guarantees and thus\nrequire interaction with a proof verifier. Such interactions typically follow\none of two approaches: black-box interaction, which does not utilize\nintermediate proof states, or white-box approaches, which allow for incremental\nproof construction and examination of intermediate states. While black-box\napproaches have directly benefited from recent LLM advances, white-box methods\nhave comparatively lagged behind. In this paper, we address this gap by\nintroducing LeanTree, which consists of (i) a tool built in the Lean 4 language\nthat factorizes complex proof states into simpler, independent branches, and\n(ii) a dataset of these factorized intermediate states. Our white-box tooling\noffers several advantages over black-box approaches: it simplifies evaluation,\nreduces necessary context, generates richer training data, enables parallel\nsearch across multiple states, supports efficient reuse of states, and provides\nfeedback in case of errors. Our preliminary results hint that white-box\napproaches outperform black-box alternatives in some settings.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdLeanTree\u89e3\u51b3\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u767d\u76d2\u65b9\u6cd5\u843d\u540e\u95ee\u9898\uff0c\u767d\u76d2\u65b9\u6cd5\u5728\u67d0\u4e9b\u573a\u666f\u4f18\u4e8e\u9ed1\u76d2\u65b9\u6cd5\u3002", "motivation": "\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u6311\u6218\u5927\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8eATP\u65f6\u767d\u76d2\u65b9\u6cd5\u843d\u540e\u4e8e\u9ed1\u76d2\u65b9\u6cd5\uff0c\u9700\u5f25\u8865\u5dee\u8ddd\u3002", "method": "\u5f15\u5165LeanTree\uff0c\u5305\u542b\u7528Lean 4\u8bed\u8a00\u6784\u5efa\u7684\u5de5\u5177\u5c06\u590d\u6742\u8bc1\u660e\u72b6\u6001\u5206\u89e3\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u5206\u89e3\u540e\u7684\u4e2d\u95f4\u72b6\u6001\u6570\u636e\u96c6\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\u767d\u76d2\u65b9\u6cd5\u5728\u4e00\u4e9b\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u4e8e\u9ed1\u76d2\u65b9\u6cd5\u3002", "conclusion": "\u767d\u76d2\u5de5\u5177\u76f8\u5bf9\u9ed1\u76d2\u65b9\u6cd5\u6709\u7b80\u5316\u8bc4\u4f30\u3001\u51cf\u5c11\u4e0a\u4e0b\u6587\u7b49\u4f18\u52bf\u3002"}}
{"id": "2507.15532", "pdf": "https://arxiv.org/pdf/2507.15532", "abs": "https://arxiv.org/abs/2507.15532", "authors": ["Kasper Engelen", "Guillermo A. P\u00e9rez", "Marnix Suilen"], "title": "Data-Efficient Safe Policy Improvement Using Parametric Structure", "categories": ["cs.AI"], "comment": "Accepted at ECAI 2025", "summary": "Safe policy improvement (SPI) is an offline reinforcement learning problem in\nwhich a new policy that reliably outperforms the behavior policy with high\nconfidence needs to be computed using only a dataset and the behavior policy.\nMarkov decision processes (MDPs) are the standard formalism for modeling\nenvironments in SPI. In many applications, additional information in the form\nof parametric dependencies between distributions in the transition dynamics is\navailable. We make SPI more data-efficient by leveraging these dependencies\nthrough three contributions: (1) a parametric SPI algorithm that exploits known\ncorrelations between distributions to more accurately estimate the transition\ndynamics using the same amount of data; (2) a preprocessing technique that\nprunes redundant actions from the environment through a game-based abstraction;\nand (3) a more advanced preprocessing technique, based on satisfiability modulo\ntheory (SMT) solving, that can identify more actions to prune. Empirical\nresults and an ablation study show that our techniques increase the data\nefficiency of SPI by multiple orders of magnitude while maintaining the same\nreliability guarantees.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5229\u7528\u8f6c\u79fb\u52a8\u6001\u5206\u5e03\u95f4\u7684\u53c2\u6570\u4f9d\u8d56\u5173\u7cfb\uff0c\u63d0\u51fa\u4e09\u79cd\u65b9\u6cd5\u63d0\u9ad8\u5b89\u5168\u7b56\u7565\u6539\u8fdb\uff08SPI\uff09\u7684\u6570\u636e\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53ef\u5927\u5e45\u63d0\u5347\u6548\u7387\u5e76\u4fdd\u8bc1\u53ef\u9760\u6027\u3002", "motivation": "\u5728SPI\u95ee\u9898\u4e2d\uff0c\u5229\u7528\u8f6c\u79fb\u52a8\u6001\u5206\u5e03\u95f4\u7684\u53c2\u6570\u4f9d\u8d56\u5173\u7cfb\uff0c\u63d0\u9ad8SPI\u7684\u6570\u636e\u6548\u7387\u3002", "method": "\u63d0\u51fa\u53c2\u6570\u5316SPI\u7b97\u6cd5\uff0c\u5229\u7528\u5206\u5e03\u95f4\u76f8\u5173\u6027\u66f4\u51c6\u786e\u4f30\u8ba1\u8f6c\u79fb\u52a8\u6001\uff1b\u91c7\u7528\u57fa\u4e8e\u535a\u5f08\u62bd\u8c61\u7684\u9884\u5904\u7406\u6280\u672f\u53bb\u9664\u5197\u4f59\u52a8\u4f5c\uff1b\u91c7\u7528\u57fa\u4e8e\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\uff08SMT\uff09\u6c42\u89e3\u7684\u66f4\u9ad8\u7ea7\u9884\u5904\u7406\u6280\u672f\u8bc6\u522b\u66f4\u591a\u53ef\u53bb\u9664\u52a8\u4f5c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u4e9b\u6280\u672f\u53ef\u5c06SPI\u7684\u6570\u636e\u6548\u7387\u63d0\u9ad8\u591a\u4e2a\u6570\u91cf\u7ea7\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u53ef\u9760\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u6240\u63d0\u6280\u672f\u80fd\u6709\u6548\u63d0\u9ad8SPI\u7684\u6570\u636e\u6548\u7387\u5e76\u4fdd\u8bc1\u53ef\u9760\u6027\u3002"}}
{"id": "2507.14725", "pdf": "https://arxiv.org/pdf/2507.14725", "abs": "https://arxiv.org/abs/2507.14725", "authors": ["Anushka Tiwari", "Sayantan Pal", "Rohini K. Srihari", "Kaiyi Ji"], "title": "Task-Agnostic Continual Prompt Tuning with Gradient-Based Selection and Decoding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Prompt-based continual learning (CL) offers a parameter-efficient way to\nadapt large language models (LLMs) across task sequences. However, most\nexisting methods assume task-aware inference and maintain a growing list of\ntask-specific prompts, which limits scalability and hides latent forgetting. In\nthis work, we introduce GRID, a unified framework that addresses two key\nlimitations: (1) latent forgetting under task-agnostic inference, and (2)\nprompt memory explosion as task sequences grow. GRID integrates a task-aware\ndecoding mechanism that improves backward transfer by leveraging representative\ninputs, automatic task identification, and constrained decoding. Additionally,\nwe propose a gradient-based prompt selection strategy that compresses less\ninformative prompts into a single aggregated representation, enabling scalable\nand memory-efficient lifelong learning. Extensive experiments across\nshort-sequence, long-sequence, and negative transfer benchmarks show that GRID\nsignificantly improves backward transfer, achieves competitive forward\ntransfer, and reduces forgotten tasks by up to 80\\%, outperforming\nstate-of-the-art methods on T5 and Flan-T5 backbones.", "AI": {"tldr": "\u63d0\u51faGRID\u6846\u67b6\u89e3\u51b3\u57fa\u4e8e\u63d0\u793a\u7684\u6301\u7eed\u5b66\u4e60\u7684\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u63d0\u793a\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4efb\u52a1\u4e0d\u53ef\u77e5\u63a8\u7406\u4e0b\u7684\u6f5c\u5728\u9057\u5fd8\u548c\u63d0\u793a\u5185\u5b58\u7206\u70b8\u95ee\u9898\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002", "method": "\u96c6\u6210\u4efb\u52a1\u611f\u77e5\u89e3\u7801\u673a\u5236\uff0c\u5229\u7528\u4ee3\u8868\u6027\u8f93\u5165\u3001\u81ea\u52a8\u4efb\u52a1\u8bc6\u522b\u548c\u7ea6\u675f\u89e3\u7801\u63d0\u5347\u53cd\u5411\u8fc1\u79fb\uff1b\u63d0\u51fa\u57fa\u4e8e\u68af\u5ea6\u7684\u63d0\u793a\u9009\u62e9\u7b56\u7565\uff0c\u5c06\u4fe1\u606f\u8f83\u5c11\u7684\u63d0\u793a\u538b\u7f29\u4e3a\u5355\u4e00\u805a\u5408\u8868\u793a\u3002", "result": "\u5728\u77ed\u5e8f\u5217\u3001\u957f\u5e8f\u5217\u548c\u8d1f\u8fc1\u79fb\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u53cd\u5411\u8fc1\u79fb\uff0c\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u7684\u6b63\u5411\u8fc1\u79fb\uff0c\u51cf\u5c11\u9ad8\u8fbe80%\u7684\u9057\u5fd8\u4efb\u52a1\u3002", "conclusion": "GRID\u6846\u67b6\u5728T5\u548cFlan - T5\u9aa8\u5e72\u7f51\u7edc\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.15581", "pdf": "https://arxiv.org/pdf/2507.15581", "abs": "https://arxiv.org/abs/2507.15581", "authors": ["Ekaterina Goliakova", "Xavier Renard", "Marie-Jeanne Lesot", "Thibault Laugel", "Christophe Marsala", "Marcin Detyniecki"], "title": "Metric assessment protocol in the context of answer fluctuation on MCQ tasks", "categories": ["cs.AI"], "comment": null, "summary": "Using multiple-choice questions (MCQs) has become a standard for assessing\nLLM capabilities efficiently. A variety of metrics can be employed for this\ntask. However, previous research has not conducted a thorough assessment of\nthem. At the same time, MCQ evaluation suffers from answer fluctuation: models\nproduce different results given slight changes in prompts. We suggest a metric\nassessment protocol in which evaluation methodologies are analyzed through\ntheir connection with fluctuation rates, as well as original performance. Our\nresults show that there is a strong link between existing metrics and the\nanswer changing, even when computed without any additional prompt variants. A\nnovel metric, worst accuracy, demonstrates the highest association on the\nprotocol.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6307\u6807\u8bc4\u4f30\u534f\u8bae\uff0c\u5206\u6790\u73b0\u6709\u6307\u6807\u4e0e\u7b54\u6848\u53d8\u52a8\u7684\u5173\u8054\uff0c\u53d1\u73b0\u65b0\u6307\u6807\u6700\u5dee\u51c6\u786e\u7387\u5173\u8054\u6700\u9ad8\u3002", "motivation": "\u6b64\u524d\u7814\u7a76\u672a\u5168\u9762\u8bc4\u4f30\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u7684\u591a\u9879\u9009\u62e9\u9898\uff08MCQ\uff09\u6307\u6807\uff0c\u4e14MCQ\u8bc4\u4f30\u5b58\u5728\u7b54\u6848\u6ce2\u52a8\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6307\u6807\u8bc4\u4f30\u534f\u8bae\uff0c\u901a\u8fc7\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u6ce2\u52a8\u7387\u53ca\u539f\u59cb\u6027\u80fd\u7684\u8054\u7cfb\u6765\u5206\u6790\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u73b0\u6709\u6307\u6807\u4e0e\u7b54\u6848\u53d8\u52a8\u6709\u5f3a\u5173\u8054\uff0c\u65b0\u6307\u6807\u6700\u5dee\u51c6\u786e\u7387\u5728\u534f\u8bae\u4e0b\u663e\u793a\u6700\u9ad8\u5173\u8054\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6307\u6807\u8bc4\u4f30\u534f\u8bae\u6709\u52a9\u4e8e\u5206\u6790\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u7684\u6307\u6807\uff0c\u6700\u5dee\u51c6\u786e\u7387\u6307\u6807\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2507.14736", "pdf": "https://arxiv.org/pdf/2507.14736", "abs": "https://arxiv.org/abs/2507.14736", "authors": ["Rafa\u0142 Surdej", "Micha\u0142 Bortkiewicz", "Alex Lewandowski", "Mateusz Ostaszewski", "Clare Lyle"], "title": "Balancing Expressivity and Robustness: Constrained Rational Activations for Reinforcement Learning", "categories": ["cs.LG"], "comment": "Accepted for oral presentation at CoLLAs 2025", "summary": "Trainable activation functions, whose parameters are optimized alongside\nnetwork weights, offer increased expressivity compared to fixed activation\nfunctions. Specifically, trainable activation functions defined as ratios of\npolynomials (rational functions) have been proposed to enhance plasticity in\nreinforcement learning. However, their impact on training stability remains\nunclear. In this work, we study trainable rational activations in both\nreinforcement and continual learning settings. We find that while their\nflexibility enhances adaptability, it can also introduce instability, leading\nto overestimation in RL and feature collapse in longer continual learning\nscenarios. Our main result is demonstrating a trade-off between expressivity\nand plasticity in rational activations. To address this, we propose a\nconstrained variant that structurally limits excessive output scaling while\npreserving adaptability. Experiments across MetaWorld and DeepMind Control\nSuite (DMC) environments show that our approach improves training stability and\nperformance. In continual learning benchmarks, including MNIST with reshuffled\nlabels and Split CIFAR-100, we reveal how different constraints affect the\nbalance between expressivity and long-term retention. While preliminary\nexperiments in discrete action domains (e.g., Atari) did not show similar\ninstability, this suggests that the trade-off is particularly relevant for\ncontinuous control. Together, our findings provide actionable design principles\nfor robust and adaptable trainable activations in dynamic, non-stationary\nenvironments. Code available at:\nhttps://github.com/special114/rl_rational_plasticity.", "AI": {"tldr": "\u7814\u7a76\u53ef\u8bad\u7ec3\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u5728\u5f3a\u5316\u548c\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u8868\u8fbe\u6027\u548c\u53ef\u5851\u6027\u5b58\u5728\u6743\u8861\uff0c\u63d0\u51fa\u53d7\u9650\u53d8\u4f53\u6539\u5584\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e0b\u8bbe\u8ba1\u6fc0\u6d3b\u51fd\u6570\u63d0\u4f9b\u539f\u5219\u3002", "motivation": "\u53ef\u8bad\u7ec3\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u80fd\u589e\u5f3a\u53ef\u5851\u6027\uff0c\u4f46\u5bf9\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u4e0d\u660e\uff0c\u9700\u7814\u7a76\u5176\u5728\u5f3a\u5316\u548c\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u53ef\u8bad\u7ec3\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\uff0c\u63d0\u51fa\u53d7\u9650\u53d8\u4f53\uff0c\u5728\u591a\u4e2a\u73af\u5883\u548c\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u53ef\u8bad\u7ec3\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u7075\u6d3b\u6027\u9ad8\u4f46\u4f1a\u5f15\u5165\u4e0d\u7a33\u5b9a\uff0c\u53d7\u9650\u53d8\u4f53\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u4e0d\u540c\u7ea6\u675f\u5f71\u54cd\u8868\u8fbe\u6027\u548c\u957f\u671f\u4fdd\u7559\u7684\u5e73\u8861\uff0c\u8fde\u7eed\u63a7\u5236\u4e2d\u6743\u8861\u66f4\u660e\u663e\u3002", "conclusion": "\u4e3a\u52a8\u6001\u3001\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u8bbe\u8ba1\u9c81\u68d2\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u53ef\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2507.15618", "pdf": "https://arxiv.org/pdf/2507.15618", "abs": "https://arxiv.org/abs/2507.15618", "authors": ["Weiyu Ma", "Jiwen Jiang", "Haobo Fu", "Haifeng Zhang"], "title": "TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II", "categories": ["cs.AI"], "comment": null, "summary": "We present an adapter-based approach for tactical conditioning of StarCraft\nII AI agents. Current agents, while powerful, lack the ability to adapt their\nstrategies based on high-level tactical directives. Our method freezes a\npre-trained policy network (DI-Star) and attaches lightweight adapter modules\nto each action head, conditioned on a tactical tensor that encodes strategic\npreferences. By training these adapters with KL divergence constraints, we\nensure the policy maintains core competencies while exhibiting tactical\nvariations. Experimental results show our approach successfully modulates agent\nbehavior across tactical dimensions including aggression, expansion patterns,\nand technology preferences, while maintaining competitive performance. Our\nmethod enables flexible tactical control with minimal computational overhead,\noffering practical strategy customization for complex real-time strategy games.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\u5bf9\u661f\u9645\u4e89\u9738II AI \u667a\u80fd\u4f53\u8fdb\u884c\u6218\u672f\u8c03\u8282\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u7075\u6d3b\u63a7\u5236\u884c\u4e3a\u4e14\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u7f3a\u4e4f\u57fa\u4e8e\u9ad8\u7ea7\u6218\u672f\u6307\u4ee4\u8c03\u6574\u7b56\u7565\u7684\u80fd\u529b\u3002", "method": "\u51bb\u7ed3\u9884\u8bad\u7ec3\u7b56\u7565\u7f51\u7edc\uff08DI - Star\uff09\uff0c\u5728\u6bcf\u4e2a\u52a8\u4f5c\u5934\u9644\u52a0\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6a21\u5757\uff0c\u901a\u8fc7\u6218\u672f\u5f20\u91cf\u7f16\u7801\u6218\u7565\u504f\u597d\uff0c\u5e76\u5728 KL \u6563\u5ea6\u7ea6\u675f\u4e0b\u8bad\u7ec3\u9002\u914d\u5668\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u5728\u5305\u62ec\u653b\u51fb\u6027\u3001\u6269\u5f20\u6a21\u5f0f\u548c\u6280\u672f\u504f\u597d\u7b49\u6218\u672f\u7ef4\u5ea6\u4e0a\u8c03\u8282\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u4ee5\u6700\u5c0f\u8ba1\u7b97\u5f00\u9500\u5b9e\u73b0\u7075\u6d3b\u6218\u672f\u63a7\u5236\uff0c\u4e3a\u590d\u6742\u5b9e\u65f6\u7b56\u7565\u6e38\u620f\u63d0\u4f9b\u5b9e\u7528\u7b56\u7565\u5b9a\u5236\u3002"}}
{"id": "2507.15676", "pdf": "https://arxiv.org/pdf/2507.15676", "abs": "https://arxiv.org/abs/2507.15676", "authors": ["Reza Vatankhah Barenji", "Sina Khoshgoftar"], "title": "Agentic AI for autonomous anomaly management in complex systems", "categories": ["cs.AI", "cs.ET"], "comment": null, "summary": "This paper explores the potential of agentic AI in autonomously detecting and\nresponding to anomalies within complex systems, emphasizing its ability to\ntransform traditional, human-dependent anomaly management methods.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4ee3\u7406\u5f0fAI\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u81ea\u4e3b\u68c0\u6d4b\u548c\u54cd\u5e94\u5f02\u5e38\u7684\u6f5c\u529b\uff0c\u5f3a\u8c03\u5176\u5bf9\u4f20\u7edf\u5f02\u5e38\u7ba1\u7406\u65b9\u6cd5\u7684\u53d8\u9769\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u4ee3\u7406\u5f0fAI\u5728\u590d\u6742\u7cfb\u7edf\u5f02\u5e38\u7ba1\u7406\u65b9\u9762\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u53d8\u9769\u4f20\u7edf\u4f9d\u8d56\u4eba\u529b\u7684\u5f02\u5e38\u7ba1\u7406\u65b9\u6cd5\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2507.14744", "pdf": "https://arxiv.org/pdf/2507.14744", "abs": "https://arxiv.org/abs/2507.14744", "authors": ["Mustafa Cavus", "Jan N. van Rijn", "Przemys\u0142aw Biecek"], "title": "Beyond the Single-Best Model: Rashomon Partial Dependence Profile for Trustworthy Explanations in AutoML", "categories": ["cs.LG"], "comment": "Accepted at 28th International Conference on Discovery Science 2025", "summary": "Automated machine learning systems efficiently streamline model selection but\noften focus on a single best-performing model, overlooking explanation\nuncertainty, an essential concern in human centered explainable AI. To address\nthis, we propose a novel framework that incorporates model multiplicity into\nexplanation generation by aggregating partial dependence profiles (PDP) from a\nset of near optimal models, known as the Rashomon set. The resulting Rashomon\nPDP captures interpretive variability and highlights areas of disagreement,\nproviding users with a richer, uncertainty aware view of feature effects. To\nevaluate its usefulness, we introduce two quantitative metrics, the coverage\nrate and the mean width of confidence intervals, to evaluate the consistency\nbetween the standard PDP and the proposed Rashomon PDP. Experiments on 35\nregression datasets from the OpenML CTR23 benchmark suite show that in most\ncases, the Rashomon PDP covers less than 70% of the best model's PDP,\nunderscoring the limitations of single model explanations. Our findings suggest\nthat Rashomon PDP improves the reliability and trustworthiness of model\ninterpretations by adding additional information that would otherwise be\nneglected. This is particularly useful in high stakes domains where\ntransparency and confidence are critical.", "AI": {"tldr": "\u63d0\u51faRashomon PDP\u6846\u67b6\uff0c\u805a\u5408\u8fd1\u4f18\u6a21\u578b\u7684PDP\u4ee5\u6355\u6349\u89e3\u91ca\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u80fd\u6539\u8fdb\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u805a\u7126\u5355\u6700\u4f73\u6a21\u578b\uff0c\u5ffd\u7565\u89e3\u91ca\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u5728\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u53ef\u89e3\u91caAI\u4e2d\u662f\u91cd\u8981\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5c06\u6a21\u578b\u591a\u6837\u6027\u7eb3\u5165\u89e3\u91ca\u751f\u6210\u7684\u6846\u67b6\uff0c\u805a\u5408Rashomon\u96c6\u4e2d\u8fd1\u4f18\u6a21\u578b\u7684PDP\u5f97\u5230Rashomon PDP\uff0c\u5f15\u5165\u8986\u76d6\u7387\u548c\u7f6e\u4fe1\u533a\u95f4\u5e73\u5747\u5bbd\u5ea6\u4e24\u4e2a\u6307\u6807\u8bc4\u4f30\u5176\u4e0e\u6807\u51c6PDP\u7684\u4e00\u81f4\u6027\u3002", "result": "\u572835\u4e2a\u56de\u5f52\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u591a\u6570\u60c5\u51b5\u4e0bRashomon PDP\u8986\u76d6\u6700\u4f73\u6a21\u578bPDP\u4e0d\u523070%\u3002", "conclusion": "Rashomon PDP\u901a\u8fc7\u589e\u52a0\u88ab\u5ffd\u7565\u7684\u4fe1\u606f\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5c24\u5176\u6709\u7528\u3002"}}
{"id": "2507.15743", "pdf": "https://arxiv.org/pdf/2507.15743", "abs": "https://arxiv.org/abs/2507.15743", "authors": ["Elahe Vedadi", "David Barrett", "Natalie Harris", "Ellery Wulczyn", "Shashir Reddy", "Roma Ruparel", "Mike Schaekermann", "Tim Strother", "Ryutaro Tanno", "Yash Sharma", "Jihyeon Lee", "C\u00edan Hughes", "Dylan Slack", "Anil Palepu", "Jan Freyberg", "Khaled Saab", "Valentin Li\u00e9vin", "Wei-Hung Weng", "Tao Tu", "Yun Liu", "Nenad Tomasev", "Kavita Kulkarni", "S. Sara Mahdavi", "Kelvin Guu", "Jo\u00eblle Barral", "Dale R. Webster", "James Manyika", "Avinatan Hassidim", "Katherine Chou", "Yossi Matias", "Pushmeet Kohli", "Adam Rodman", "Vivek Natarajan", "Alan Karthikesalingam", "David Stutz"], "title": "Towards physician-centered oversight of conversational diagnostic AI", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "Recent work has demonstrated the promise of conversational AI systems for\ndiagnostic dialogue. However, real-world assurance of patient safety means that\nproviding individual diagnoses and treatment plans is considered a regulated\nactivity by licensed professionals. Furthermore, physicians commonly oversee\nother team members in such activities, including nurse practitioners (NPs) or\nphysician assistants/associates (PAs). Inspired by this, we propose a framework\nfor effective, asynchronous oversight of the Articulate Medical Intelligence\nExplorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent\nsystem that performs history taking within guardrails, abstaining from\nindividualized medical advice. Afterwards, g-AMIE conveys assessments to an\noverseeing primary care physician (PCP) in a clinician cockpit interface. The\nPCP provides oversight and retains accountability of the clinical decision.\nThis effectively decouples oversight from intake and can thus happen\nasynchronously. In a randomized, blinded virtual Objective Structured Clinical\nExamination (OSCE) of text consultations with asynchronous oversight, we\ncompared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across\n60 scenarios, g-AMIE outperformed both groups in performing high-quality\nintake, summarizing cases, and proposing diagnoses and management plans for the\noverseeing PCP to review. This resulted in higher quality composite decisions.\nPCP oversight of g-AMIE was also more time-efficient than standalone PCP\nconsultations in prior work. While our study does not replicate existing\nclinical practices and likely underestimates clinicians' capabilities, our\nresults demonstrate the promise of asynchronous oversight as a feasible\nparadigm for diagnostic AI systems to operate under expert human oversight for\nenhancing real-world care.", "AI": {"tldr": "\u63d0\u51fag - AMIE\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7528\u4e8eAI\u8bca\u65ad\u5f02\u6b65\u76d1\u7763\uff0c\u968f\u673a\u8bd5\u9a8c\u663e\u793a\u5176\u8868\u73b0\u4f18\u4e8eNPs/PAs\u548cPCPs\u7ec4\uff0c\u8bc1\u660e\u5f02\u6b65\u76d1\u7763\u8303\u5f0f\u6709\u524d\u666f\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u60a3\u8005\u5b89\u5168\u9700\u4e13\u4e1a\u4eba\u5458\u76d1\u7ba1\u8bca\u65ad\u548c\u6cbb\u7597\u8ba1\u5212\uff0c\u4e14\u533b\u751f\u5e38\u76d1\u7763\u56e2\u961f\u6210\u5458\uff0c\u7531\u6b64\u542f\u53d1\u63d0\u51fa\u5bf9AMIE AI\u7cfb\u7edf\u7684\u5f02\u6b65\u76d1\u7763\u6846\u67b6\u3002", "method": "\u63d0\u51fag - AMIE\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5728\u89c4\u5219\u5185\u8fdb\u884c\u75c5\u53f2\u91c7\u96c6\uff0c\u5c06\u8bc4\u4f30\u7ed3\u679c\u4f20\u8fbe\u7ed9PCP\uff1b\u8fdb\u884c\u968f\u673a\u3001\u53cc\u76f2\u865a\u62dfOSCE\u6587\u672c\u54a8\u8be2\u5bf9\u6bd4\u8bd5\u9a8c\u3002", "result": "\u572860\u4e2a\u573a\u666f\u4e2d\uff0cg - AMIE\u5728\u9ad8\u8d28\u91cf\u4fe1\u606f\u91c7\u96c6\u3001\u75c5\u4f8b\u603b\u7ed3\u3001\u63d0\u51fa\u8bca\u65ad\u548c\u7ba1\u7406\u8ba1\u5212\u65b9\u9762\u4f18\u4e8eNPs/PAs\u548cPCPs\u7ec4\uff0c\u51b3\u7b56\u8d28\u91cf\u66f4\u9ad8\uff0cPCP\u76d1\u7763g - AMIE\u66f4\u7701\u65f6\u3002", "conclusion": "\u867d\u7814\u7a76\u672a\u590d\u5236\u73b0\u6709\u4e34\u5e8a\u5b9e\u8df5\u4e14\u53ef\u80fd\u4f4e\u4f30\u4e34\u5e8a\u533b\u751f\u80fd\u529b\uff0c\u4f46\u7ed3\u679c\u8868\u660e\u5f02\u6b65\u76d1\u7763\u662f\u8bca\u65adAI\u7cfb\u7edf\u5728\u4e13\u5bb6\u76d1\u7763\u4e0b\u63d0\u9ad8\u5b9e\u9645\u62a4\u7406\u8d28\u91cf\u7684\u53ef\u884c\u8303\u5f0f\u3002"}}
{"id": "2507.15758", "pdf": "https://arxiv.org/pdf/2507.15758", "abs": "https://arxiv.org/abs/2507.15758", "authors": ["Xingyu Wu", "Yuchen Yan", "Shangke Lyu", "Linjuan Wu", "Yiwen Qiu", "Yongliang Shen", "Weiming Lu", "Jian Shao", "Jun Xiao", "Yueting Zhuang"], "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "categories": ["cs.AI", "cs.CL"], "comment": "GitHub:https://github.com/zju-real/lapo;\n  Project:https://zju-real.github.io/lapo", "summary": "Large reasoning models have achieved remarkable performance through extended\nchain-of-thought sequences, yet this computational freedom leads to excessive\ntoken generation even for simple problems. We present Length-Adaptive Policy\nOptimization (LAPO), a novel framework that transforms reasoning length control\nfrom an external constraint into an intrinsic model capability. Unlike existing\napproaches that impose rigid limits or rely on post-hoc interventions, LAPO\nenables models to internalize an understanding of appropriate reasoning depth\nthrough a two-stage reinforcement learning process. In the first stage, models\nlearn natural reasoning patterns by discovering the statistical distribution of\nsuccessful solution lengths. The second stage leverages these patterns as\nmeta-cognitive guidance, embedding them directly within the model's reasoning\ncontext to ensure inference-time flexibility. Experiments on mathematical\nreasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\%\nwhile improving accuracy by 2.3\\%. Our analysis reveals that models trained\nwith LAPO develop emergent abilities to allocate computational resources based\non problem complexity, achieving efficient reasoning without sacrificing\nquality.", "AI": {"tldr": "\u63d0\u51fa\u957f\u5ea6\u81ea\u9002\u5e94\u7b56\u7565\u4f18\u5316\uff08LAPO\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u4f7f\u6a21\u578b\u5177\u5907\u63a8\u7406\u957f\u5ea6\u63a7\u5236\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u51cf\u5c11\u4ee4\u724c\u4f7f\u7528\u5e76\u63d0\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u5b58\u5728\u4ee4\u724c\u751f\u6210\u8fc7\u591a\u95ee\u9898\uff0c\u9700\u5c06\u63a8\u7406\u957f\u5ea6\u63a7\u5236\u8f6c\u5316\u4e3a\u6a21\u578b\u5185\u5728\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7b2c\u4e00\u9636\u6bb5\u5b66\u4e60\u6210\u529f\u89e3\u51b3\u65b9\u6848\u957f\u5ea6\u7684\u7edf\u8ba1\u5206\u5e03\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5c06\u8fd9\u4e9b\u6a21\u5f0f\u4f5c\u4e3a\u5143\u8ba4\u77e5\u6307\u5bfc\u5d4c\u5165\u63a8\u7406\u4e0a\u4e0b\u6587\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLAPO \u6700\u591a\u51cf\u5c11 40.9% \u7684\u4ee4\u724c\u4f7f\u7528\uff0c\u540c\u65f6\u63d0\u9ad8 2.3% \u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u4f7f\u7528 LAPO \u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u6839\u636e\u95ee\u9898\u590d\u6742\u5ea6\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u4e14\u4e0d\u727a\u7272\u8d28\u91cf\u3002"}}
{"id": "2507.15761", "pdf": "https://arxiv.org/pdf/2507.15761", "abs": "https://arxiv.org/abs/2507.15761", "authors": ["Jingyi Zheng", "Zifan Peng", "Yule Liu", "Junfeng Wang", "Yifan Liao", "Wenhan Dong", "Xinlei He"], "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts", "categories": ["cs.AI"], "comment": null, "summary": "Smart contracts are trustworthy, immutable, and automatically executed\nprograms on the blockchain. Their execution requires the Gas mechanism to\nensure efficiency and fairness. However, due to non-optimal coding practices,\nmany contracts contain Gas waste patterns that need to be optimized. Existing\nsolutions mostly rely on manual discovery, which is inefficient, costly to\nmaintain, and difficult to scale. Recent research uses large language models\n(LLMs) to explore new Gas waste patterns. However, it struggles to remain\ncompatible with existing patterns, often produces redundant patterns, and\nrequires manual validation/rewriting. To address this gap, we present GasAgent,\nthe first multi-agent system for smart contract Gas optimization that combines\ncompatibility with existing patterns and automated discovery/validation of new\npatterns, enabling end-to-end optimization. GasAgent consists of four\nspecialized agents, Seeker, Innovator, Executor, and Manager, that collaborate\nin a closed loop to identify, validate, and apply Gas-saving improvements.\nExperiments on 100 verified real-world contracts demonstrate that GasAgent\nsuccessfully optimizes 82 contracts, achieving an average deployment Gas\nsavings of 9.97%. In addition, our evaluation confirms its compatibility with\nexisting tools and validates the effectiveness of each module through ablation\nstudies. To assess broader usability, we further evaluate 500 contracts\ngenerated by five representative LLMs across 10 categories and find that\nGasAgent optimizes 79.8% of them, with deployment Gas savings ranging from\n4.79% to 13.93%, showing its usability as the optimization layer for\nLLM-assisted smart contract development.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cfb\u7edfGasAgent\u7528\u4e8e\u667a\u80fd\u5408\u7ea6Gas\u4f18\u5316\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u548c\u517c\u5bb9\u6027\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u5408\u7ea6Gas\u6d6a\u8d39\u6a21\u5f0f\u4f18\u5316\u65b9\u6848\u6548\u7387\u4f4e\u3001\u96be\u6269\u5c55\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u5b58\u5728\u517c\u5bb9\u6027\u7b49\u95ee\u9898\u3002", "method": "\u6784\u5efa\u7531Seeker\u3001Innovator\u3001Executor\u548cManager\u56db\u4e2a\u667a\u80fd\u4f53\u7ec4\u6210\u7684GasAgent\uff0c\u95ed\u73af\u534f\u4f5c\u8fdb\u884cGas\u4f18\u5316\u3002", "result": "\u5728100\u4e2a\u771f\u5b9e\u5408\u7ea6\u4e2d\u6210\u529f\u4f18\u531682\u4e2a\uff0c\u5e73\u5747\u90e8\u7f72Gas\u8282\u77019.97%\uff1b\u5728500\u4e2aLLM\u751f\u6210\u5408\u7ea6\u4e2d\u4f18\u531679.8%\uff0c\u90e8\u7f72Gas\u8282\u77014.79% - 13.93%\u3002", "conclusion": "GasAgent\u80fd\u517c\u5bb9\u73b0\u6709\u6a21\u5f0f\uff0c\u81ea\u52a8\u53d1\u73b0/\u9a8c\u8bc1\u65b0\u6a21\u5f0f\uff0c\u53ef\u4f5c\u4e3aLLM\u8f85\u52a9\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u7684\u4f18\u5316\u5c42\u3002"}}
{"id": "2507.15770", "pdf": "https://arxiv.org/pdf/2507.15770", "abs": "https://arxiv.org/abs/2507.15770", "authors": ["Yifan Shen", "Zihan Zhao", "Xiao Xue", "Yuwei Guo", "Qun Ma", "Deyu Zhou", "Ming Zhang"], "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining", "categories": ["cs.AI"], "comment": null, "summary": "With the rise of service computing, cloud computing, and IoT, service\necosystems are becoming increasingly complex. The intricate interactions among\nintelligent agents make abnormal emergence analysis challenging, as traditional\ncausal methods focus on individual trajectories. Large language models offer\nnew possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)\nreasoning to reveal agent intentions. However, existing approaches remain\nlimited to microscopic and static analysis. This paper introduces a framework:\nEmergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic\nand interpretable emergence analysis. EAMI first employs a dual-perspective\nthought track mechanism, where an Inspector Agent and an Analysis Agent extract\nagent intentions under bounded and perfect rationality. Then, k-means\nclustering identifies phase transition points in group intentions, followed by\na Intention Temporal Emergence diagram for dynamic analysis. The experiments\nvalidate EAMI in complex online-to-offline (O2O) service system and the\nStanford AI Town experiment, with ablation studies confirming its\neffectiveness, generalizability, and efficiency. This framework provides a\nnovel paradigm for abnormal emergence and causal analysis in service\necosystems. The code is available at\nhttps://anonymous.4open.science/r/EAMI-B085.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEAMI\u6846\u67b6\u7528\u4e8e\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u5f02\u5e38\u6d8c\u73b0\u548c\u56e0\u679c\u5206\u6790\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u4e14\u63d0\u4f9b\u4ee3\u7801\u3002", "motivation": "\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u4f20\u7edf\u56e0\u679c\u65b9\u6cd5\u96be\u7528\u4e8e\u5f02\u5e38\u6d8c\u73b0\u5206\u6790\uff0c\u73b0\u6709\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u65b9\u6cd5\u5c40\u9650\u4e8e\u5fae\u89c2\u9759\u6001\u5206\u6790\u3002", "method": "\u91c7\u7528\u53cc\u89c6\u89d2\u601d\u7ef4\u8f68\u8ff9\u673a\u5236\uff0c\u7531Inspector Agent\u548cAnalysis Agent\u63d0\u53d6\u4e0d\u540c\u7406\u6027\u4e0b\u7684\u667a\u80fd\u4f53\u610f\u56fe\uff0c\u7528k - means\u805a\u7c7b\u8bc6\u522b\u7fa4\u4f53\u610f\u56fe\u76f8\u53d8\u70b9\uff0c\u5e76\u7528\u610f\u56fe\u65f6\u95f4\u6d8c\u73b0\u56fe\u8fdb\u884c\u52a8\u6001\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u5728\u590d\u6742O2O\u670d\u52a1\u7cfb\u7edf\u548cStanford AI Town\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86EAMI\u6846\u67b6\u7684\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u7684\u5f02\u5e38\u6d8c\u73b0\u548c\u56e0\u679c\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.14766", "pdf": "https://arxiv.org/pdf/2507.14766", "abs": "https://arxiv.org/abs/2507.14766", "authors": ["Mehak Arora", "Ayman Ali", "Kaiyuan Wu", "Carolyn Davis", "Takashi Shimazui", "Mahmoud Alwakeel", "Victor Moas", "Philip Yang", "Annette Esper", "Rishikesan Kamaleswaran"], "title": "CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "In Review for MICCAI 2025", "summary": "In intensive care units (ICUs), patients with complex clinical conditions\nrequire vigilant monitoring and prompt interventions. Chest X-rays (CXRs) are a\nvital diagnostic tool, providing insights into clinical trajectories, but their\nirregular acquisition limits their utility. Existing tools for CXR\ninterpretation are constrained by cross-sectional analysis, failing to capture\ntemporal dynamics. To address this, we introduce CXR-TFT, a novel multi-modal\nframework that integrates temporally sparse CXR imaging and radiology reports\nwith high-frequency clinical data, such as vital signs, laboratory values, and\nrespiratory flow sheets, to predict the trajectory of CXR findings in\ncritically ill patients. CXR-TFT leverages latent embeddings from a vision\nencoder that are temporally aligned with hourly clinical data through\ninterpolation. A transformer model is then trained to predict CXR embeddings at\neach hour, conditioned on previous embeddings and clinical measurements. In a\nretrospective study of 20,000 ICU patients, CXR-TFT demonstrated high accuracy\nin forecasting abnormal CXR findings up to 12 hours before they became\nradiographically evident. This predictive capability in clinical data holds\nsignificant potential for enhancing the management of time-sensitive conditions\nlike acute respiratory distress syndrome, where early intervention is crucial\nand diagnoses are often delayed. By providing distinctive temporal resolution\nin prognostic CXR analysis, CXR-TFT offers actionable 'whole patient' insights\nthat can directly improve clinical outcomes.", "AI": {"tldr": "\u63d0\u51faCXR - TFT\u6846\u67b6\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u9884\u6d4b\u91cd\u75c7\u60a3\u8005CXR\u7ed3\u679c\uff0c\u56de\u987e\u6027\u7814\u7a76\u663e\u793a\u5176\u9884\u6d4b\u5f02\u5e38CXR\u53d1\u73b0\u51c6\u786e\u6027\u9ad8\uff0c\u80fd\u6539\u5584\u4e34\u5e8a\u7ed3\u679c\u3002", "motivation": "ICU\u60a3\u8005\u9700\u76d1\u6d4b\u5e72\u9884\uff0cCXR\u4e0d\u89c4\u5219\u91c7\u96c6\u9650\u5236\u5176\u4f5c\u7528\uff0c\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u6355\u6349\u65f6\u95f4\u52a8\u6001\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u9884\u6d4bCXR\u7ed3\u679c\u3002", "method": "\u5f15\u5165CXR - TFT\u6846\u67b6\uff0c\u5229\u7528\u89c6\u89c9\u7f16\u7801\u5668\u7684\u6f5c\u5728\u5d4c\u5165\u4e0e\u4e34\u5e8a\u6570\u636e\u901a\u8fc7\u63d2\u503c\u5bf9\u9f50\uff0c\u8bad\u7ec3Transformer\u6a21\u578b\u9884\u6d4bCXR\u5d4c\u5165\u3002", "result": "\u572820000\u540dICU\u60a3\u8005\u56de\u987e\u6027\u7814\u7a76\u4e2d\uff0cCXR - TFT\u80fd\u63d0\u524d12\u5c0f\u65f6\u51c6\u786e\u9884\u6d4b\u5f02\u5e38CXR\u53d1\u73b0\u3002", "conclusion": "CXR - TFT\u5728\u9884\u540eCXR\u5206\u6790\u4e2d\u6709\u72ec\u7279\u65f6\u95f4\u5206\u8fa8\u7387\uff0c\u53ef\u63d0\u4f9b\u6574\u4f53\u60a3\u8005\u89c1\u89e3\uff0c\u6539\u5584\u4e34\u5e8a\u7ed3\u679c\u3002"}}
{"id": "2507.15796", "pdf": "https://arxiv.org/pdf/2507.15796", "abs": "https://arxiv.org/abs/2507.15796", "authors": ["Nuria Rodr\u00edguez-Barroso", "Mario Garc\u00eda-M\u00e1rquez", "M. Victoria Luz\u00f3n", "Francisco Herrera"], "title": "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, the development of Trustworthy Artificial Intelligence (TAI)\nhas emerged as a critical objective in the deployment of AI systems across\nsensitive and high-risk domains. TAI frameworks articulate a comprehensive set\nof ethical, legal, and technical requirements to ensure that AI technologies\nare aligned with human values, rights, and societal expectations. Among the\nvarious AI paradigms, Federated Learning (FL) presents a promising solution to\npressing privacy concerns. However, aligning FL with the rest of the\nrequirements of TAI presents a series of challenges, most of which arise from\nits inherently distributed nature. In this work, we adopt the requirements TAI\nas a guiding structure to systematically analyze the challenges of adapting FL\nto TAI. Specifically, we classify and examine the key obstacles to aligning FL\nwith TAI, providing a detailed exploration of what has been done, the trends,\nand the remaining work within each of the identified challenges.", "AI": {"tldr": "\u672c\u6587\u4ee5\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\uff08TAI\uff09\u8981\u6c42\u4e3a\u6307\u5bfc\uff0c\u7cfb\u7edf\u5206\u6790\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u9002\u5e94TAI\u7684\u6311\u6218\uff0c\u5e76\u5206\u7c7b\u7814\u7a76\u5173\u952e\u969c\u788d\u3002", "motivation": "TAI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0cFL\u80fd\u89e3\u51b3\u9690\u79c1\u95ee\u9898\uff0c\u4f46\u4f7fFL\u7b26\u5408TAI\u5176\u4ed6\u8981\u6c42\u5b58\u5728\u6311\u6218\uff0c\u6e90\u4e8e\u5176\u5206\u5e03\u5f0f\u672c\u8d28\u3002", "method": "\u91c7\u7528TAI\u8981\u6c42\u4f5c\u4e3a\u6307\u5bfc\u7ed3\u6784\uff0c\u5bf9FL\u4e0eTAI\u5bf9\u9f50\u7684\u5173\u952e\u969c\u788d\u8fdb\u884c\u5206\u7c7b\u548c\u7814\u7a76\u3002", "result": "\u8be6\u7ec6\u63a2\u8ba8\u4e86\u5728\u6bcf\u4e2a\u5df2\u8bc6\u522b\u6311\u6218\u4e2d\u5df2\u5b8c\u6210\u7684\u5de5\u4f5c\u3001\u8d8b\u52bf\u548c\u5269\u4f59\u5de5\u4f5c\u3002", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u6700\u7ec8\u7ed3\u8bba\uff0c\u4f46\u6697\u793a\u540e\u7eed\u9700\u8fdb\u4e00\u6b65\u89e3\u51b3FL\u9002\u5e94TAI\u7684\u6311\u6218\u3002"}}
{"id": "2507.14777", "pdf": "https://arxiv.org/pdf/2507.14777", "abs": "https://arxiv.org/abs/2507.14777", "authors": ["Bishwamittra Ghosh", "Soumi Das", "Qinyuan Wu", "Mohammad Aflah Khan", "Krishna P. Gummadi", "Evimaria Terzi", "Deepak Garg"], "title": "Rethinking Memorization Measures and their Implications in Large Language Models", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Concerned with privacy threats, memorization in LLMs is often seen as\nundesirable, specifically for learning. In this paper, we study whether\nmemorization can be avoided when optimally learning a language, and whether the\nprivacy threat posed by memorization is exaggerated or not. To this end, we\nre-examine existing privacy-focused measures of memorization, namely\nrecollection-based and counterfactual memorization, along with a newly proposed\ncontextual memorization.\n  Relating memorization to local over-fitting during learning, contextual\nmemorization aims to disentangle memorization from the contextual learning\nability of LLMs. Informally, a string is contextually memorized if its\nrecollection due to training exceeds the optimal contextual recollection, a\nlearned threshold denoting the best contextual learning without training.\nConceptually, contextual recollection avoids the fallacy of recollection-based\nmemorization, where any form of high recollection is a sign of memorization.\nTheoretically, contextual memorization relates to counterfactual memorization,\nbut imposes stronger conditions. Memorization measures differ in outcomes and\ninformation requirements.\n  Experimenting on 18 LLMs from 6 families and multiple formal languages of\ndifferent entropy, we show that (a) memorization measures disagree on\nmemorization order of varying frequent strings, (b) optimal learning of a\nlanguage cannot avoid partial memorization of training strings, and (c)\nimproved learning decreases contextual and counterfactual memorization but\nincreases recollection-based memorization. Finally, (d) we revisit existing\nreports of memorized strings by recollection that neither pose a privacy threat\nnor are contextually or counterfactually memorized.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u8bb0\u5fc6\u80fd\u5426\u907f\u514d\u53ca\u9690\u79c1\u5a01\u80c1\u662f\u5426\u88ab\u5938\u5927\uff0c\u63d0\u51fa\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u6982\u5ff5\uff0c\u5b9e\u9a8c\u8868\u660e\u5b66\u4e60\u8bed\u8a00\u65e0\u6cd5\u907f\u514d\u90e8\u5206\u8bb0\u5fc6\uff0c\u4e0d\u540c\u8bb0\u5fc6\u5ea6\u91cf\u7ed3\u679c\u6709\u5dee\u5f02\u3002", "motivation": "\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u4e2d\u8bb0\u5fc6\u80fd\u5426\u907f\u514d\u4ee5\u53ca\u8bb0\u5fc6\u5e26\u6765\u7684\u9690\u79c1\u5a01\u80c1\u662f\u5426\u88ab\u5938\u5927\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6\u57fa\u4e8e\u56de\u5fc6\u548c\u53cd\u4e8b\u5b9e\u7684\u8bb0\u5fc6\u5ea6\u91cf\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u572818\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u79cd\u5f62\u5f0f\u8bed\u8a00\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u4e0d\u540c\u8bb0\u5fc6\u5ea6\u91cf\u65b9\u6cd5\u5bf9\u4e0d\u540c\u9891\u7387\u5b57\u7b26\u4e32\u7684\u8bb0\u5fc6\u987a\u5e8f\u5224\u65ad\u4e0d\u4e00\u81f4\uff1b\u5b66\u4e60\u8bed\u8a00\u65e0\u6cd5\u907f\u514d\u5bf9\u8bad\u7ec3\u5b57\u7b26\u4e32\u7684\u90e8\u5206\u8bb0\u5fc6\uff1b\u5b66\u4e60\u6548\u679c\u63d0\u5347\u4f1a\u964d\u4f4e\u4e0a\u4e0b\u6587\u548c\u53cd\u4e8b\u5b9e\u8bb0\u5fc6\uff0c\u4f46\u589e\u52a0\u57fa\u4e8e\u56de\u5fc6\u7684\u8bb0\u5fc6\uff1b\u90e8\u5206\u57fa\u4e8e\u56de\u5fc6\u88ab\u8ba4\u4e3a\u8bb0\u5fc6\u7684\u5b57\u7b26\u4e32\u65e0\u9690\u79c1\u5a01\u80c1\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u8bed\u8a00\u65e0\u6cd5\u907f\u514d\u90e8\u5206\u8bb0\u5fc6\uff0c\u4e0d\u540c\u8bb0\u5fc6\u5ea6\u91cf\u65b9\u6cd5\u6709\u5dee\u5f02\uff0c\u90e8\u5206\u88ab\u8ba4\u4e3a\u8bb0\u5fc6\u7684\u5b57\u7b26\u4e32\u65e0\u9690\u79c1\u5a01\u80c1\u3002"}}
{"id": "2507.14783", "pdf": "https://arxiv.org/pdf/2507.14783", "abs": "https://arxiv.org/abs/2507.14783", "authors": ["Derek Li", "Jiaming Zhou", "Amirreza Kazemi", "Qianyi Sun", "Abbas Ghaddar", "Mohammad Ali Alomrani", "Liheng Ma", "Yu Luo", "Dong Li", "Feng Wen", "Jianye Hao", "Mark Coates", "Yingxue Zhang"], "title": "Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The advancement of general-purpose artificial intelligence relies on large\nlanguage models (LLMs) that excel across a wide range of tasks, from structured\nreasoning to creative generation. However, post-training methods like\nSupervised Fine-Tuning (SFT) often struggle with generalization, favoring\nmemorization over transferable learning. In this work, we introduce Omni-Think,\na unified reinforcement learning (RL) framework that enhances LLM performance\nacross diverse tasks by combining rule-based verifiable rewards with generative\npreference signals via LLM-as-a-Judge evaluations. Our approach enables\nconsistent optimization across task types and scales RL-based training to\nsubjective domains. We further investigate training strategies, demonstrating\nthat a curriculum-based progression that orders tasks from structured to\nopen-ended improves performance and reduces forgetting. Experimental results\nacross four domains reveal that curriculum learning improves performance by\n5.2\\% over joint training and 9.1\\% over model merging. These results highlight\nthe importance of task-aware sampling and hybrid supervision in scaling\nRL-based post-training for general-purpose LLMs.", "AI": {"tldr": "\u63d0\u51faOmni - Think\u7edf\u4e00\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u4efb\u52a1\u6027\u80fd\uff0c\u7814\u7a76\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u8bfe\u7a0b\u5b66\u4e60\u4f18\u4e8e\u8054\u5408\u8bad\u7ec3\u548c\u6a21\u578b\u5408\u5e76\u3002", "motivation": "\u73b0\u6709\u540e\u8bad\u7ec3\u65b9\u6cd5\u5982SFT\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u503e\u5411\u8bb0\u5fc6\u800c\u975e\u8fc1\u79fb\u5b66\u4e60\uff0c\u9700\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u4efb\u52a1\u6027\u80fd\u3002", "method": "\u5f15\u5165Omni - Think\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u53ef\u9a8c\u8bc1\u5956\u52b1\u548c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u7684\u751f\u6210\u504f\u597d\u4fe1\u53f7\uff1b\u91c7\u7528\u4ece\u7ed3\u6784\u5316\u5230\u5f00\u653e\u5f0f\u4efb\u52a1\u6392\u5e8f\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u56db\u4e2a\u9886\u57df\u5b9e\u9a8c\u663e\u793a\uff0c\u8bfe\u7a0b\u5b66\u4e60\u6bd4\u8054\u5408\u8bad\u7ec3\u6027\u80fd\u63d0\u53475.2%\uff0c\u6bd4\u6a21\u578b\u5408\u5e76\u63d0\u53479.1%\u3002", "conclusion": "\u4efb\u52a1\u611f\u77e5\u91c7\u6837\u548c\u6df7\u5408\u76d1\u7763\u5728\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u6269\u5c55\u4e2d\u5f88\u91cd\u8981\u3002"}}
{"id": "2507.15844", "pdf": "https://arxiv.org/pdf/2507.15844", "abs": "https://arxiv.org/abs/2507.15844", "authors": ["Shangke Lyu", "Linjuan Wu", "Yuchen Yan", "Xingyu Wu", "Hao Li", "Yongliang Shen", "Peisheng Jiang", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Code: https://github.com/zju-real/hbpo Project\n  Page:https://zju-real.github.io/hbpo/", "summary": "Large reasoning models achieve remarkable performance through extensive\nchain-of-thought generation, yet exhibit significant computational inefficiency\nby applying uniform reasoning strategies regardless of problem complexity. We\npresent Hierarchical Budget Policy Optimization (HBPO), a reinforcement\nlearning framework that enables models to learn problem-specific reasoning\ndepths without sacrificing capability. HBPO addresses the fundamental challenge\nof exploration space collapse in efficiency-oriented training, where penalties\non long output length systematically bias models away from necessary long\nreasoning paths. Through hierarchical budget exploration, our approach\npartitions rollout samples into multiple subgroups with distinct token budgets,\naiming to enable efficient resource allocation while preventing degradation of\ncapability. We introduce differentiated reward mechanisms that create\nbudget-aware incentives aligned with the complexity of the problem, allowing\nmodels to discover natural correspondences between task requirements and\ncomputational effort. Extensive experiments demonstrate that HBPO reduces\naverage token usage by up to 60.6% while improving accuracy by 3.14% across\nfour reasoning benchmarks. Unlike existing methods that impose external\nconstraints or rely on discrete mode selection, HBPO exhibits emergent adaptive\nbehavior where models automatically adjust reasoning depth based on problem\ncomplexity. Our results suggest that reasoning efficiency and capability are\nnot inherently conflicting, and can be simultaneously optimized through\nappropriately structured hierarchical training that preserves exploration\ndiversity.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u9884\u7b97\u7b56\u7565\u4f18\u5316\uff08HBPO\uff09\u6846\u67b6\uff0c\u53ef\u4f7f\u6a21\u578b\u5b66\u4e60\u7279\u5b9a\u95ee\u9898\u7684\u63a8\u7406\u6df1\u5ea6\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u51cf\u5c11\u5e73\u5747\u4ee4\u724c\u4f7f\u7528\u91cf\u5e76\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u63a8\u7406\u6548\u7387\u548c\u80fd\u529b\u53ef\u540c\u65f6\u4f18\u5316\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u4f7f\u7528\u7edf\u4e00\u63a8\u7406\u7b56\u7565\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u4e14\u9762\u5411\u6548\u7387\u7684\u8bad\u7ec3\u5b58\u5728\u63a2\u7d22\u7a7a\u95f4\u5d29\u6e83\u6311\u6218\u3002", "method": "\u63d0\u51faHBPO\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u9884\u7b97\u63a2\u7d22\u5c06\u6837\u672c\u5212\u5206\u4e3a\u4e0d\u540c\u4ee4\u724c\u9884\u7b97\u5b50\u7ec4\uff0c\u5f15\u5165\u5dee\u5f02\u5316\u5956\u52b1\u673a\u5236\u3002", "result": "\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHBPO\u4f7f\u5e73\u5747\u4ee4\u724c\u4f7f\u7528\u91cf\u6700\u591a\u51cf\u5c1160.6%\uff0c\u51c6\u786e\u7387\u63d0\u9ad83.14%\u3002", "conclusion": "\u63a8\u7406\u6548\u7387\u548c\u80fd\u529b\u5e76\u975e\u56fa\u6709\u51b2\u7a81\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u5206\u5c42\u8bad\u7ec3\u53ef\u540c\u65f6\u4f18\u5316\u3002"}}
{"id": "2507.14785", "pdf": "https://arxiv.org/pdf/2507.14785", "abs": "https://arxiv.org/abs/2507.14785", "authors": ["Erfan Pirmorad"], "title": "Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The complexity and interconnectivity of entities involved in money laundering\ndemand investigative reasoning over graph-structured data. This paper explores\nthe use of large language models (LLMs) as reasoning engines over localized\nsubgraphs extracted from a financial knowledge graph. We propose a lightweight\npipeline that retrieves k-hop neighborhoods around entities of interest,\nserializes them into structured text, and prompts an LLM via few-shot\nin-context learning to assess suspiciousness and generate justifications. Using\nsynthetic anti-money laundering (AML) scenarios that reflect common laundering\nbehaviors, we show that LLMs can emulate analyst-style logic, highlight red\nflags, and provide coherent explanations. While this study is exploratory, it\nillustrates the potential of LLM-based graph reasoning in AML and lays\ngroundwork for explainable, language-driven financial crime analytics.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u91d1\u878d\u77e5\u8bc6\u56fe\u8c31\u7684\u5c40\u90e8\u5b50\u56fe\u8fdb\u884c\u63a8\u7406\uff0c\u4ee5\u8bc4\u4f30\u6d17\u94b1\u53ef\u7591\u6027\u5e76\u7ed9\u51fa\u89e3\u91ca\uff0c\u5c55\u793a\u4e86\u5176\u5728\u53cd\u6d17\u94b1\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u6d17\u94b1\u5b9e\u4f53\u7684\u590d\u6742\u6027\u548c\u4e92\u8054\u6027\u8981\u6c42\u5bf9\u56fe\u7ed3\u6784\u6570\u636e\u8fdb\u884c\u8c03\u67e5\u63a8\u7406\uff0c\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5176\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6d41\u7a0b\uff0c\u63d0\u53d6\u611f\u5174\u8da3\u5b9e\u4f53\u7684k\u8df3\u90bb\u57df\uff0c\u5c06\u5176\u5e8f\u5217\u5316\u4e3a\u7ed3\u6784\u5316\u6587\u672c\uff0c\u901a\u8fc7\u5c11\u6837\u672c\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u793a\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u53ef\u7591\u6027\u5e76\u751f\u6210\u89e3\u91ca\u3002", "result": "\u4f7f\u7528\u5408\u6210\u53cd\u6d17\u94b1\u573a\u666f\u8868\u660e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u6a21\u62df\u5206\u6790\u5e08\u903b\u8f91\uff0c\u7a81\u51fa\u98ce\u9669\u6807\u5fd7\u5e76\u7ed9\u51fa\u8fde\u8d2f\u89e3\u91ca\u3002", "conclusion": "\u672c\u7814\u7a76\u867d\u5177\u63a2\u7d22\u6027\uff0c\u4f46\u5c55\u793a\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u56fe\u63a8\u7406\u5728\u53cd\u6d17\u94b1\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u53ef\u89e3\u91ca\u7684\u3001\u8bed\u8a00\u9a71\u52a8\u7684\u91d1\u878d\u72af\u7f6a\u5206\u6790\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.15851", "pdf": "https://arxiv.org/pdf/2507.15851", "abs": "https://arxiv.org/abs/2507.15851", "authors": ["Lingyu Li", "Yang Yao", "Yixu Wang", "Chubo Li", "Yan Teng", "Yingchun Wang"], "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition", "categories": ["cs.AI"], "comment": "12 pages, 9 figures, 4 tables", "summary": "As Large Language Models (LLMs) continue to advance, they exhibit certain\ncognitive patterns similar to those of humans that are not directly specified\nin training data. This study investigates this phenomenon by focusing on\ntemporal cognition in LLMs. Leveraging the similarity judgment task, we find\nthat larger models spontaneously establish a subjective temporal reference\npoint and adhere to the Weber-Fechner law, whereby the perceived distance\nlogarithmically compresses as years recede from this reference point. To\nuncover the mechanisms behind this behavior, we conducted multiple analyses\nacross neuronal, representational, and informational levels. We first identify\na set of temporal-preferential neurons and find that this group exhibits\nminimal activation at the subjective reference point and implements a\nlogarithmic coding scheme convergently found in biological systems. Probing\nrepresentations of years reveals a hierarchical construction process, where\nyears evolve from basic numerical values in shallow layers to abstract temporal\norientation in deep layers. Finally, using pre-trained embedding models, we\nfound that the training corpus itself possesses an inherent, non-linear\ntemporal structure, which provides the raw material for the model's internal\nconstruction. In discussion, we propose an experientialist perspective for\nunderstanding these findings, where the LLMs' cognition is viewed as a\nsubjective construction of the external world by its internal representational\nsystem. This nuanced perspective implies the potential emergence of alien\ncognitive frameworks that humans cannot intuitively predict, pointing toward a\ndirection for AI alignment that focuses on guiding internal constructions. Our\ncode is available at https://TheOtherMind.github.io.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65f6\u95f4\u8ba4\u77e5\u73b0\u8c61\uff0c\u53d1\u73b0\u5176\u9075\u5faa\u97e6\u4f2f - \u8d39\u5e0c\u7eb3\u5b9a\u5f8b\uff0c\u4ece\u591a\u5c42\u9762\u5206\u6790\u673a\u5236\uff0c\u63d0\u51fa\u7ecf\u9a8c\u4e3b\u4e49\u89c6\u89d2\u7406\u89e3\u7ed3\u679c\u5e76\u6307\u51faAI\u5bf9\u9f50\u65b9\u5411\u3002", "motivation": "\u968f\u7740LLMs\u53d1\u5c55\uff0c\u5176\u5c55\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u6a21\u5f0f\uff0c\u7814\u7a76\u805a\u7126\u4e8eLLMs\u7684\u65f6\u95f4\u8ba4\u77e5\u73b0\u8c61\u3002", "method": "\u5229\u7528\u76f8\u4f3c\u6027\u5224\u65ad\u4efb\u52a1\uff0c\u4ece\u795e\u7ecf\u5143\u3001\u8868\u5f81\u548c\u4fe1\u606f\u5c42\u9762\u8fdb\u884c\u591a\u65b9\u9762\u5206\u6790\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u3002", "result": "\u8f83\u5927\u6a21\u578b\u81ea\u53d1\u5efa\u7acb\u4e3b\u89c2\u65f6\u95f4\u53c2\u8003\u70b9\u5e76\u9075\u5faa\u97e6\u4f2f - \u8d39\u5e0c\u7eb3\u5b9a\u5f8b\uff1b\u53d1\u73b0\u65f6\u95f4\u504f\u597d\u795e\u7ecf\u5143\u53ca\u5bf9\u6570\u7f16\u7801\u65b9\u6848\uff1b\u5e74\u7684\u8868\u5f81\u6709\u5206\u5c42\u6784\u5efa\u8fc7\u7a0b\uff1b\u8bad\u7ec3\u8bed\u6599\u5e93\u6709\u5185\u5728\u975e\u7ebf\u6027\u65f6\u95f4\u7ed3\u6784\u3002", "conclusion": "\u63d0\u51fa\u7ecf\u9a8c\u4e3b\u4e49\u89c6\u89d2\u7406\u89e3\u7ed3\u679c\uff0c\u6697\u793a\u53ef\u80fd\u51fa\u73b0\u4eba\u7c7b\u96be\u4ee5\u9884\u6d4b\u7684\u8ba4\u77e5\u6846\u67b6\uff0c\u6307\u51faAI\u5bf9\u9f50\u5e94\u5173\u6ce8\u5f15\u5bfc\u5185\u90e8\u6784\u5efa\u3002"}}
{"id": "2507.14793", "pdf": "https://arxiv.org/pdf/2507.14793", "abs": "https://arxiv.org/abs/2507.14793", "authors": ["T. Anderson Keller"], "title": "Flow Equivariant Recurrent Neural Networks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Data arrives at our senses as a continuous stream, smoothly transforming from\none instant to the next. These smooth transformations can be viewed as\ncontinuous symmetries of the environment that we inhabit, defining equivalence\nrelations between stimuli over time. In machine learning, neural network\narchitectures that respect symmetries of their data are called equivariant and\nhave provable benefits in terms of generalization ability and sample\nefficiency. To date, however, equivariance has been considered only for static\ntransformations and feed-forward networks, limiting its applicability to\nsequence models, such as recurrent neural networks (RNNs), and corresponding\ntime-parameterized sequence transformations. In this work, we extend\nequivariant network theory to this regime of `flows' -- one-parameter Lie\nsubgroups capturing natural transformations over time, such as visual motion.\nWe begin by showing that standard RNNs are generally not flow equivariant:\ntheir hidden states fail to transform in a geometrically structured manner for\nmoving stimuli. We then show how flow equivariance can be introduced, and\ndemonstrate that these models significantly outperform their non-equivariant\ncounterparts in terms of training speed, length generalization, and velocity\ngeneralization, on both next step prediction and sequence classification. We\npresent this work as a first step towards building sequence models that respect\nthe time-parameterized symmetries which govern the world around us.", "AI": {"tldr": "\u672c\u6587\u5c06\u7b49\u53d8\u7f51\u7edc\u7406\u8bba\u6269\u5c55\u5230\u5e8f\u5217\u6a21\u578b\uff0c\u5c55\u793a\u6807\u51c6RNN\u901a\u5e38\u4e0d\u5177\u5907\u6d41\u7b49\u53d8\u6027\uff0c\u5f15\u5165\u6d41\u7b49\u53d8\u6027\u7684\u6a21\u578b\u5728\u591a\u9879\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u7b49\u53d8\u7406\u8bba\u4ec5\u8003\u8651\u9759\u6001\u53d8\u6362\u548c\u524d\u9988\u7f51\u7edc\uff0c\u9650\u5236\u4e86\u5176\u5728\u5e8f\u5217\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u9700\u5c06\u7b49\u53d8\u7f51\u7edc\u7406\u8bba\u6269\u5c55\u5230\u65f6\u95f4\u53c2\u6570\u5316\u7684\u5e8f\u5217\u53d8\u6362\u3002", "method": "\u5148\u8bc1\u660e\u6807\u51c6RNN\u901a\u5e38\u4e0d\u5177\u6709\u6d41\u7b49\u53d8\u6027\uff0c\u518d\u5c55\u793a\u5982\u4f55\u5f15\u5165\u6d41\u7b49\u53d8\u6027\u3002", "result": "\u5f15\u5165\u6d41\u7b49\u53d8\u6027\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u901f\u5ea6\u3001\u957f\u5ea6\u6cdb\u5316\u548c\u901f\u5ea6\u6cdb\u5316\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u975e\u7b49\u53d8\u6a21\u578b\u3002", "conclusion": "\u8fd9\u662f\u6784\u5efa\u5c0a\u91cd\u65f6\u95f4\u53c2\u6570\u5316\u5bf9\u79f0\u6027\u7684\u5e8f\u5217\u6a21\u578b\u7684\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2507.15855", "pdf": "https://arxiv.org/pdf/2507.15855", "abs": "https://arxiv.org/abs/2507.15855", "authors": ["Yichen Huang", "Lin F. Yang"], "title": "Gemini 2.5 Pro Capable of Winning Gold at IMO 2025", "categories": ["cs.AI"], "comment": null, "summary": "The International Mathematical Olympiad (IMO) poses uniquely challenging\nproblems requiring deep insight, creativity, and formal reasoning. While Large\nLanguage Models (LLMs) perform well on mathematical benchmarks like AIME, they\nstruggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly\nreleased IMO 2025 problems, avoiding data contamination. With pipeline design\nand prompt engineering, 5 (out of 6) problems are solved correctly (up to a\ncaveat discussed below), highlighting the importance of finding the optimal way\nof using powerful models.", "AI": {"tldr": "\u4f7f\u7528Gemini 2.5 Pro\u89e3IMO 2025\u95ee\u9898\uff0c5\u9898\u6b63\u786e\uff0c\u5f3a\u8c03\u7528\u597d\u5f3a\u5927\u6a21\u578b\u7684\u91cd\u8981\u6027\u3002", "motivation": "LLMs\u5728\u56fd\u9645\u6570\u5b66\u5965\u6797\u5339\u514b\uff08IMO\uff09\u7ea7\u522b\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u63a2\u7d22\u5e94\u5bf9\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Google\u7684Gemini 2.5 Pro\uff0c\u901a\u8fc7\u7ba1\u9053\u8bbe\u8ba1\u548c\u63d0\u793a\u5de5\u7a0b\uff0c\u907f\u514d\u6570\u636e\u6c61\u67d3\u3002", "result": "\u5728IMO 2025\u76846\u4e2a\u95ee\u9898\u4e2d\uff0c\u6b63\u786e\u89e3\u51b3\u4e865\u4e2a\u3002", "conclusion": "\u627e\u5230\u4f7f\u7528\u5f3a\u5927\u6a21\u578b\u7684\u6700\u4f73\u65b9\u5f0f\u5f88\u91cd\u8981\u3002"}}
{"id": "2507.14805", "pdf": "https://arxiv.org/pdf/2507.14805", "abs": "https://arxiv.org/abs/2507.14805", "authors": ["Alex Cloud", "Minh Le", "James Chua", "Jan Betley", "Anna Sztyber-Betley", "Jacob Hilton", "Samuel Marks", "Owain Evans"], "title": "Subliminal Learning: Language models transmit behavioral traits via hidden signals in data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study subliminal learning, a surprising phenomenon where language models\ntransmit behavioral traits via semantically unrelated data. In our main\nexperiments, a \"teacher\" model with some trait T (such as liking owls or being\nmisaligned) generates a dataset consisting solely of number sequences.\nRemarkably, a \"student\" model trained on this dataset learns T. This occurs\neven when the data is filtered to remove references to T. We observe the same\neffect when training on code or reasoning traces generated by the same teacher\nmodel. However, we do not observe the effect when the teacher and student have\ndifferent base models. To help explain our findings, we prove a theoretical\nresult showing that subliminal learning occurs in all neural networks under\ncertain conditions, and demonstrate subliminal learning in a simple MLP\nclassifier. We conclude that subliminal learning is a general phenomenon that\npresents an unexpected pitfall for AI development. Distillation could propagate\nunintended traits, even when developers try to prevent this via data filtering.", "AI": {"tldr": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u8bed\u4e49\u65e0\u5173\u6570\u636e\u4f20\u9012\u884c\u4e3a\u7279\u5f81\u7684\u6f5c\u610f\u8bc6\u5b66\u4e60\u73b0\u8c61\uff0c\u53d1\u73b0\u5b66\u751f\u6a21\u578b\u80fd\u4ece\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u6570\u5b57\u5e8f\u5217\u7b49\u6570\u636e\u4e2d\u5b66\u5230\u7279\u5f81\uff0c\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u5219\u65e0\u6b64\u6548\u679c\uff0c\u7406\u8bba\u8bc1\u660e\u8be5\u73b0\u8c61\u666e\u904d\u5b58\u5728\uff0c\u6307\u51fa\u8fd9\u662fAI\u5f00\u53d1\u9690\u60a3\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u4e2d\u6f5c\u610f\u8bc6\u5b66\u4e60\u8fd9\u4e00\u73b0\u8c61\uff0c\u5373\u901a\u8fc7\u8bed\u4e49\u65e0\u5173\u6570\u636e\u4f20\u9012\u884c\u4e3a\u7279\u5f81\u3002", "method": "\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8ba9\u6709\u7279\u5b9a\u7279\u5f81\u7684\u6559\u5e08\u6a21\u578b\u751f\u6210\u6570\u5b57\u5e8f\u5217\u3001\u4ee3\u7801\u6216\u63a8\u7406\u8f68\u8ff9\u7b49\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\uff1b\u8bc1\u660e\u795e\u7ecf\u7f51\u7edc\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5b58\u5728\u6f5c\u610f\u8bc6\u5b66\u4e60\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u5e76\u5728\u7b80\u5355MLP\u5206\u7c7b\u5668\u4e2d\u9a8c\u8bc1\u3002", "result": "\u5b66\u751f\u6a21\u578b\u80fd\u4ece\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u96c6\u4e2d\u5b66\u5230\u7279\u5f81\uff0c\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u65e0\u6b64\u6548\u679c\uff0c\u7406\u8bba\u8bc1\u660e\u6f5c\u610f\u8bc6\u5b66\u4e60\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5b58\u5728\u4e8e\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u3002", "conclusion": "\u6f5c\u610f\u8bc6\u5b66\u4e60\u662f\u666e\u904d\u73b0\u8c61\uff0c\u662fAI\u5f00\u53d1\u7684\u610f\u5916\u9690\u60a3\uff0c\u84b8\u998f\u53ef\u80fd\u4f20\u64ad\u975e\u9884\u671f\u7279\u5f81\uff0c\u5373\u4f7f\u8fdb\u884c\u6570\u636e\u8fc7\u6ee4\u3002"}}
{"id": "2411.01789", "pdf": "https://arxiv.org/pdf/2411.01789", "abs": "https://arxiv.org/abs/2411.01789", "authors": ["Shan Jiang", "Chenguang Zhu", "Sarfraz Khurshid"], "title": "Generating executable oracles to check conformance of client code to requirements of JDK Javadocs using LLMs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Software testing remains the most widely used methodology for validating\nquality of code. However, effectiveness of testing critically depends on the\nquality of test suites used. Test cases in a test suite consist of two\nfundamental parts: (1) input values for the code under test, and (2) correct\nchecks for the outputs it produces. These checks are commonly written as\nassertions, and termed test oracles. The last couple of decades have seen much\nprogress in automated test input generation, e.g., using fuzzing and symbolic\nexecution. However, automating test oracles remains a relatively less explored\nproblem area. Indeed, a test oracle by its nature requires knowledge of\nexpected behavior, which may only be known to the developer and may not not\nexist in a formal language that supports automated reasoning.\n  Our focus in this paper is automation of test oracles for clients of widely\nused Java libraries, e.g., java.lang and java.util packages. Our key insight is\nthat Javadocs that provide a rich source of information can enable automated\ngeneration of test oracles. Javadocs of the core Java libraries are fairly\ndetailed documents that contain natural language descriptions of not only how\nthe libraries behave but also how the clients must (not) use them. We use large\nlanguage models as an enabling technology to embody our insight into a\nframework for test oracle automation, and evaluate it experimentally. Our\nexperiments demonstrate that LLMs can generate oracles for checking normal and\nexceptional behaviors from Javadocs, with 98.8% of these oracles being\ncompilable and 96.4% accurately reflecting intended properties. Even for the\nfew incorrect oracles, errors are minor and can be easily corrected with the\nhelp of additional comment information generated by the LLMs.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u4e8e\u5e38\u7528 Java \u5e93\u5ba2\u6237\u7aef\u6d4b\u8bd5\u9884\u8a00\u81ea\u52a8\u5316\uff0c\u5229\u7528 Javadocs \u548c\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u751f\u6210\u7684\u9884\u8a00\u7f16\u8bd1\u7387\u9ad8\u4e14\u51c6\u786e\u6027\u597d\u3002", "motivation": "\u8f6f\u4ef6\u6d4b\u8bd5\u4f9d\u8d56\u6d4b\u8bd5\u5957\u4ef6\u8d28\u91cf\uff0c\u81ea\u52a8\u5316\u6d4b\u8bd5\u8f93\u5165\u751f\u6210\u6709\u8fdb\u5c55\uff0c\u4f46\u6d4b\u8bd5\u9884\u8a00\u81ea\u52a8\u5316\u63a2\u7d22\u8f83\u5c11\uff0c\u56e0\u6b64\u7814\u7a76\u5e38\u7528 Java \u5e93\u5ba2\u6237\u7aef\u6d4b\u8bd5\u9884\u8a00\u81ea\u52a8\u5316\u3002", "method": "\u5229\u7528 Javadocs \u4e30\u5bcc\u4fe1\u606f\uff0c\u4ee5\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u6280\u672f\uff0c\u6784\u5efa\u6d4b\u8bd5\u9884\u8a00\u81ea\u52a8\u5316\u6846\u67b6\u5e76\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u4ece Javadocs \u751f\u6210\u68c0\u67e5\u6b63\u5e38\u548c\u5f02\u5e38\u884c\u4e3a\u7684\u9884\u8a00\uff0c98.8% \u53ef\u7f16\u8bd1\uff0c96.4% \u51c6\u786e\u53cd\u6620\u9884\u671f\u5c5e\u6027\uff0c\u5c11\u91cf\u9519\u8bef\u53ef\u501f\u52a9\u989d\u5916\u6ce8\u91ca\u4fe1\u606f\u4fee\u6b63\u3002", "conclusion": "\u57fa\u4e8e Javadocs \u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u53ef\u6709\u6548\u5b9e\u73b0\u5e38\u7528 Java \u5e93\u5ba2\u6237\u7aef\u6d4b\u8bd5\u9884\u8a00\u81ea\u52a8\u5316\u3002"}}
{"id": "2507.14824", "pdf": "https://arxiv.org/pdf/2507.14824", "abs": "https://arxiv.org/abs/2507.14824", "authors": ["Kunyu Yu", "Rui Yang", "Jingchi Liao", "Siqi Li", "Huitao Li", "Irene Li", "Yifan Peng", "Rishikesan Kamaleswaran", "Nan Liu"], "title": "Benchmarking Foundation Models with Multimodal Public Electronic Health Records", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models have emerged as a powerful approach for processing\nelectronic health records (EHRs), offering flexibility to handle diverse\nmedical data modalities. In this study, we present a comprehensive benchmark\nthat evaluates the performance, fairness, and interpretability of foundation\nmodels, both as unimodal encoders and as multimodal learners, using the\npublicly available MIMIC-IV database. To support consistent and reproducible\nevaluation, we developed a standardized data processing pipeline that\nharmonizes heterogeneous clinical records into an analysis-ready format. We\nsystematically compared eight foundation models, encompassing both unimodal and\nmultimodal models, as well as domain-specific and general-purpose variants. Our\nfindings demonstrate that incorporating multiple data modalities leads to\nconsistent improvements in predictive performance without introducing\nadditional bias. Through this benchmark, we aim to support the development of\neffective and trustworthy multimodal artificial intelligence (AI) systems for\nreal-world clinical applications. Our code is available at\nhttps://github.com/nliulab/MIMIC-Multimodal.", "AI": {"tldr": "\u672c\u6587\u7528MIMIC - IV\u6570\u636e\u5e93\u5bf9\u57fa\u7840\u6a21\u578b\u5728EHRs\u5904\u7406\u4e0a\u7684\u6027\u80fd\u3001\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u6027\u8fdb\u884c\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u6570\u636e\u80fd\u63d0\u5347\u6027\u80fd\u4e14\u65e0\u989d\u5916\u504f\u5dee\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u5728\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u65f6\u4f5c\u4e3a\u5355\u6a21\u6001\u7f16\u7801\u5668\u548c\u591a\u6a21\u6001\u5b66\u4e60\u8005\u7684\u6027\u80fd\u3001\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4ee5\u652f\u6301\u5f00\u53d1\u6709\u6548\u4e14\u53ef\u4fe1\u7684\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7528\u4e8e\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u7684MIMIC - IV\u6570\u636e\u5e93\uff0c\u5f00\u53d1\u6807\u51c6\u5316\u6570\u636e\u5904\u7406\u7ba1\u9053\uff0c\u7cfb\u7edf\u6bd4\u8f838\u79cd\u57fa\u7840\u6a21\u578b\u3002", "result": "\u7eb3\u5165\u591a\u6a21\u6001\u6570\u636e\u80fd\u6301\u7eed\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u4e14\u4e0d\u5f15\u5165\u989d\u5916\u504f\u5dee\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u6709\u52a9\u4e8e\u5f00\u53d1\u9002\u7528\u4e8e\u73b0\u5b9e\u4e34\u5e8a\u5e94\u7528\u7684\u6709\u6548\u4e14\u53ef\u4fe1\u7684\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2502.15441", "pdf": "https://arxiv.org/pdf/2502.15441", "abs": "https://arxiv.org/abs/2502.15441", "authors": ["Yang Hong", "Shan Jiang", "Yulei Fu", "Sarfraz Khurshid"], "title": "On the Effectiveness of Large Language Models in Writing Alloy Formulas", "categories": ["cs.SE", "cs.AI", "cs.FL", "cs.PL"], "comment": null, "summary": "Declarative specifications have a vital role to play in developing safe and\ndependable software systems. Writing specifications correctly, however, remains\nparticularly challenging. This paper presents a controlled experiment on using\nlarge language models (LLMs) to write declarative formulas in the well-known\nlanguage Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write\ncomplete Alloy formulas from given natural language descriptions (in English).\nTwo, we employ LLMs to create alternative but equivalent formulas in Alloy with\nrespect to given Alloy formulas. Three, we employ LLMs to complete sketches of\nAlloy formulas and populate the holes in the sketches by synthesizing Alloy\nexpressions and operators so that the completed formulas accurately represent\nthe desired properties (that are given in natural language). We conduct the\nexperimental evaluation using 11 well-studied subject specifications and employ\ntwo popular LLMs, namely ChatGPT and DeepSeek. The experimental results show\nthat the LLMs generally perform well in synthesizing complete Alloy formulas\nfrom input properties given in natural language or in Alloy, and are able to\nenumerate multiple unique solutions. Moreover, the LLMs are also successful at\ncompleting given sketches of Alloy formulas with respect to natural language\ndescriptions of desired properties (without requiring test cases). We believe\nLLMs offer a very exciting advance in our ability to write specifications, and\ncan help make specifications take a pivotal role in software development and\nenhance our ability to build robust software.", "AI": {"tldr": "\u672c\u6587\u5f00\u5c55\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7f16\u5199Alloy\u58f0\u660e\u5f0f\u516c\u5f0f\u7684\u5bf9\u7167\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793aLLMs\u8868\u73b0\u826f\u597d\uff0c\u6709\u52a9\u4e8e\u7f16\u5199\u89c4\u8303\u3002", "motivation": "\u7f16\u5199\u6b63\u786e\u7684\u58f0\u660e\u5f0f\u89c4\u8303\u5177\u6709\u6311\u6218\u6027\uff0c\u63a2\u7d22\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u5199Alloy\u516c\u5f0f\u7684\u53ef\u80fd\u6027\u3002", "method": "\u5f00\u5c55\u5bf9\u7167\u5b9e\u9a8c\uff0c\u4f7f\u752811\u4e2a\u7ecf\u8fc7\u5145\u5206\u7814\u7a76\u7684\u4e3b\u9898\u89c4\u8303\uff0c\u91c7\u7528ChatGPT\u548cDeepSeek\u4e24\u4e2a\u6d41\u884c\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u4e09\u65b9\u9762\u4f7f\u7528LLMs\u7f16\u5199Alloy\u516c\u5f0f\u3002", "result": "LLMs\u5728\u4ece\u81ea\u7136\u8bed\u8a00\u6216Alloy\u8f93\u5165\u5c5e\u6027\u5408\u6210\u5b8c\u6574Alloy\u516c\u5f0f\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u5217\u4e3e\u591a\u4e2a\u72ec\u7279\u89e3\u51b3\u65b9\u6848\uff0c\u4e5f\u80fd\u5b8c\u6210\u7ed9\u5b9a\u7684Alloy\u516c\u5f0f\u8349\u56fe\u3002", "conclusion": "LLMs\u5728\u7f16\u5199\u89c4\u8303\u65b9\u9762\u662f\u4ee4\u4eba\u5174\u594b\u7684\u8fdb\u6b65\uff0c\u6709\u52a9\u4e8e\u89c4\u8303\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u589e\u5f3a\u6784\u5efa\u5065\u58ee\u8f6f\u4ef6\u7684\u80fd\u529b\u3002"}}
{"id": "2507.14828", "pdf": "https://arxiv.org/pdf/2507.14828", "abs": "https://arxiv.org/abs/2507.14828", "authors": ["Abdul-Kazeem Shamba", "Kerstin Bach", "Gavin Taylor"], "title": "eMargin: Revisiting Contrastive Learning with Margin-Based Separation", "categories": ["cs.LG", "cs.AI"], "comment": "LDD'25: Learning from Difficult Data Workshop (ECAI 2025)", "summary": "We revisit previous contrastive learning frameworks to investigate the effect\nof introducing an adaptive margin into the contrastive loss function for time\nseries representation learning. Specifically, we explore whether an adaptive\nmargin (eMargin), adjusted based on a predefined similarity threshold, can\nimprove the separation between adjacent but dissimilar time steps and\nsubsequently lead to better performance in downstream tasks. Our study\nevaluates the impact of this modification on clustering performance and\nclassification in three benchmark datasets. Our findings, however, indicate\nthat achieving high scores on unsupervised clustering metrics does not\nnecessarily imply that the learned embeddings are meaningful or effective in\ndownstream tasks. To be specific, eMargin added to InfoNCE consistently\noutperforms state-of-the-art baselines in unsupervised clustering metrics, but\nstruggles to achieve competitive results in downstream classification with\nlinear probing. The source code is publicly available at\nhttps://github.com/sfi-norwai/eMargin.", "AI": {"tldr": "\u7814\u7a76\u5728\u65f6\u95f4\u5e8f\u5217\u8868\u5f81\u5b66\u4e60\u7684\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u4e2d\u5f15\u5165\u81ea\u9002\u5e94\u8fb9\u754c\uff08eMargin\uff09\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u5728\u65e0\u76d1\u7763\u805a\u7c7b\u6307\u6807\u4e0a\u8868\u73b0\u597d\uff0c\u4f46\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u6548\u679c\u4e0d\u4f73\u3002", "motivation": "\u63a2\u7a76\u5728\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u4e2d\u5f15\u5165\u57fa\u4e8e\u9884\u5b9a\u4e49\u76f8\u4f3c\u5ea6\u9608\u503c\u8c03\u6574\u7684\u81ea\u9002\u5e94\u8fb9\u754c\uff0c\u80fd\u5426\u6539\u5584\u76f8\u90bb\u4f46\u4e0d\u76f8\u4f3c\u65f6\u95f4\u6b65\u7684\u5206\u79bb\uff0c\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "method": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8be5\u4fee\u6539\u5bf9\u805a\u7c7b\u6027\u80fd\u548c\u5206\u7c7b\u7684\u5f71\u54cd\u3002", "result": "eMargin\u6dfb\u52a0\u5230InfoNCE\u5728\u65e0\u76d1\u7763\u805a\u7c7b\u6307\u6807\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\uff0c\u4f46\u5728\u7ebf\u6027\u63a2\u6d4b\u7684\u4e0b\u6e38\u5206\u7c7b\u4e2d\u96be\u4ee5\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "conclusion": "\u5728\u65e0\u76d1\u7763\u805a\u7c7b\u6307\u6807\u4e0a\u83b7\u5f97\u9ad8\u5206\u4e0d\u4e00\u5b9a\u610f\u5473\u7740\u5b66\u4e60\u5230\u7684\u5d4c\u5165\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u6709\u610f\u4e49\u6216\u6709\u6548\u3002"}}
{"id": "2505.17593", "pdf": "https://arxiv.org/pdf/2505.17593", "abs": "https://arxiv.org/abs/2505.17593", "authors": ["Manuel Valle Torre", "Thom van der Velden", "Marcus Specht", "Catharine Oertel"], "title": "JELAI: Integrating AI and Learning Analytics in Jupyter Notebooks", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted for AIED 2025", "summary": "Generative AI offers potential for educational support, but often lacks\npedagogical grounding and awareness of the student's learning context.\nFurthermore, researching student interactions with these tools within authentic\nlearning environments remains challenging. To address this, we present JELAI,\nan open-source platform architecture designed to integrate fine-grained\nLearning Analytics (LA) with Large Language Model (LLM)-based tutoring directly\nwithin a Jupyter Notebook environment. JELAI employs a modular, containerized\ndesign featuring JupyterLab extensions for telemetry and chat, alongside a\ncentral middleware handling LA processing and context-aware LLM prompt\nenrichment. This architecture enables the capture of integrated code\ninteraction and chat data, facilitating real-time, context-sensitive AI\nscaffolding and research into student behaviour. We describe the system's\ndesign, implementation, and demonstrate its feasibility through system\nperformance benchmarks and two proof-of-concept use cases illustrating its\ncapabilities for logging multi-modal data, analysing help-seeking patterns, and\nsupporting A/B testing of AI configurations. JELAI's primary contribution is\nits technical framework, providing a flexible tool for researchers and\neducators to develop, deploy, and study LA-informed AI tutoring within the\nwidely used Jupyter ecosystem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f00\u6e90\u5e73\u53f0\u67b6\u6784JELAI\uff0c\u5c06\u5b66\u4e60\u5206\u6790\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u5bfc\u96c6\u6210\u4e8eJupyter Notebook\u73af\u5883\uff0c\u4ecb\u7ecd\u8bbe\u8ba1\u5b9e\u73b0\u5e76\u5c55\u793a\u53ef\u884c\u6027\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7528\u4e8e\u6559\u80b2\u652f\u6301\u65f6\u7f3a\u4e4f\u6559\u5b66\u57fa\u7840\u548c\u5bf9\u5b66\u751f\u5b66\u4e60\u60c5\u5883\u7684\u4e86\u89e3\uff0c\u4e14\u5728\u771f\u5b9e\u5b66\u4e60\u73af\u5883\u4e2d\u7814\u7a76\u5b66\u751f\u4e0e\u5de5\u5177\u7684\u4ea4\u4e92\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faJELAI\u5e73\u53f0\u67b6\u6784\uff0c\u91c7\u7528\u6a21\u5757\u5316\u3001\u5bb9\u5668\u5316\u8bbe\u8ba1\uff0c\u6709JupyterLab\u6269\u5c55\u7528\u4e8e\u9065\u6d4b\u548c\u804a\u5929\uff0c\u4e2d\u95f4\u4ef6\u5904\u7406\u5b66\u4e60\u5206\u6790\u548c\u63d0\u793a\u589e\u5f3a\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e24\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u7528\u4f8b\uff0c\u5c55\u793a\u4e86\u8bb0\u5f55\u591a\u6a21\u6001\u6570\u636e\u3001\u5206\u6790\u6c42\u52a9\u6a21\u5f0f\u548c\u652f\u6301AI\u914d\u7f6eA/B\u6d4b\u8bd5\u7684\u80fd\u529b\u3002", "conclusion": "JELAI\u7684\u6280\u672f\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u5728Jupyter\u751f\u6001\u7cfb\u7edf\u4e2d\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u7814\u7a76\u5b66\u4e60\u5206\u6790\u9a71\u52a8\u7684AI\u8f85\u5bfc\u63d0\u4f9b\u4e86\u7075\u6d3b\u5de5\u5177\u3002"}}
{"id": "2507.14843", "pdf": "https://arxiv.org/pdf/2507.14843", "abs": "https://arxiv.org/abs/2507.14843", "authors": ["Fang Wu", "Weihao Xuan", "Ximing Lu", "Zaid Harchaoui", "Yejin Choi"], "title": "The Invisible Leash: Why RLVR May Not Escape Its Origin", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in large reasoning models highlight Reinforcement Learning\nwith Verifiable Rewards (RLVR) as a promising method for enhancing AI's\ncapabilities, particularly in solving complex logical tasks. However, it\nremains unclear whether RLVR truly expands a model's reasoning boundary or\nmerely amplifies high-reward outputs that the base model already knows for\nimproved precision. This study presents a theoretical and empirical\ninvestigation that provides fresh insights into the potential limits of RLVR.\nFirst, we offer a new theoretical perspective that RLVR is constrained by the\nbase model's support-unable to sample solutions with zero initial\nprobability-and operates as a conservative reweighting mechanism that may\nrestrict the discovery of entirely original solutions. We also identify an\nentropy-reward tradeoff: while RLVR reliably enhances precision, it may\nprogressively narrow exploration and potentially overlook correct yet\nunderrepresented solutions. Extensive empirical experiments validate that while\nRLVR consistently improves pass@1, the shrinkage of empirical support generally\noutweighs the expansion of empirical support under larger sampling budgets,\nfailing to recover correct answers that were previously accessible to the base\nmodel. Interestingly, we also observe that while RLVR sometimes increases\ntoken-level entropy, resulting in greater uncertainty at each generation step,\nanswer-level entropy declines, indicating that these seemingly more uncertain\npaths ultimately converge onto a smaller set of distinct answers. Taken\ntogether, these findings reveal potential limits of RLVR in extending reasoning\nhorizons. Breaking this invisible leash may require future algorithmic\ninnovations such as explicit exploration mechanisms or hybrid strategies that\nseed probability mass into underrepresented solution regions.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u65b9\u6cd5\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u5176\u53d7\u57fa\u7840\u6a21\u578b\u652f\u6301\u9650\u5236\uff0c\u6709\u71b5 - \u5956\u52b1\u6743\u8861\uff0c\u96be\u62d3\u5c55\u63a8\u7406\u8fb9\u754c\u3002", "motivation": "\u660e\u786eRLVR\u662f\u63d0\u5347AI\u80fd\u529b\u7684\u6709\u524d\u666f\u65b9\u6cd5\uff0c\u4f46\u4e0d\u6e05\u695a\u5b83\u662f\u62d3\u5c55\u63a8\u7406\u8fb9\u754c\u8fd8\u662f\u4ec5\u653e\u5927\u5df2\u77e5\u9ad8\u5956\u52b1\u8f93\u51fa\uff0c\u56e0\u6b64\u7814\u7a76\u5176\u6f5c\u5728\u5c40\u9650\u6027\u3002", "method": "\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u63d0\u51faRLVR\u53d7\u57fa\u7840\u6a21\u578b\u652f\u6301\u7ea6\u675f\u53ca\u71b5 - \u5956\u52b1\u6743\u8861\u89c2\u70b9\uff1b\u5f00\u5c55\u5927\u91cf\u5b9e\u8bc1\u5b9e\u9a8c\u3002", "result": "\u5b9e\u8bc1\u5b9e\u9a8c\u8868\u660eRLVR\u867d\u63d0\u5347pass@1\uff0c\u4f46\u7ecf\u9a8c\u652f\u6301\u6536\u7f29\u5927\u4e8e\u6269\u5c55\uff0c\u65e0\u6cd5\u6062\u590d\u57fa\u7840\u6a21\u578b\u539f\u53ef\u83b7\u53d6\u7684\u6b63\u786e\u7b54\u6848\uff1bRLVR\u4f7ftoken\u7ea7\u71b5\u6709\u65f6\u589e\u52a0\uff0c\u4f46\u7b54\u6848\u7ea7\u71b5\u4e0b\u964d\u3002", "conclusion": "RLVR\u5728\u62d3\u5c55\u63a8\u7406\u8fb9\u754c\u4e0a\u5b58\u5728\u6f5c\u5728\u5c40\u9650\uff0c\u672a\u6765\u9700\u7b97\u6cd5\u521b\u65b0\uff0c\u5982\u5f15\u5165\u663e\u5f0f\u63a2\u7d22\u673a\u5236\u6216\u6df7\u5408\u7b56\u7565\u3002"}}
{"id": "2506.23298", "pdf": "https://arxiv.org/pdf/2506.23298", "abs": "https://arxiv.org/abs/2506.23298", "authors": ["Xing Shen", "Justin Szeto", "Mingyang Li", "Hengguan Huang", "Tal Arbel"], "title": "Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Preprint version. The peer-reviewed version of this paper has been\n  accepted to MICCAI 2025 main conference", "summary": "Multimodal large language models (MLLMs) have enormous potential to perform\nfew-shot in-context learning in the context of medical image analysis. However,\nsafe deployment of these models into real-world clinical practice requires an\nin-depth analysis of the accuracies of their predictions, and their associated\ncalibration errors, particularly across different demographic subgroups. In\nthis work, we present the first investigation into the calibration biases and\ndemographic unfairness of MLLMs' predictions and confidence scores in few-shot\nin-context learning for medical image classification. We introduce CALIN, an\ninference-time calibration method designed to mitigate the associated biases.\nSpecifically, CALIN estimates the amount of calibration needed, represented by\ncalibration matrices, using a bi-level procedure: progressing from the\npopulation level to the subgroup level prior to inference. It then applies this\nestimation to calibrate the predicted confidence scores during inference.\nExperimental results on three medical imaging datasets: PAPILA for fundus image\nclassification, HAM10000 for skin cancer classification, and MIMIC-CXR for\nchest X-ray classification demonstrate CALIN's effectiveness at ensuring fair\nconfidence calibration in its prediction, while improving its overall\nprediction accuracies and exhibiting minimum fairness-utility trade-off. Our\ncodebase can be found at\nhttps://github.com/xingbpshen/medical-calibration-fairness-mllm.", "AI": {"tldr": "\u7814\u7a76\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\u7684\u6821\u51c6\u504f\u5dee\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u4e0d\u516c\u5e73\u6027\uff0c\u63d0\u51faCALIN\u6821\u51c6\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u56fe\u50cf\u5206\u6790\u6709\u6f5c\u529b\uff0c\u4f46\u5b89\u5168\u90e8\u7f72\u5230\u4e34\u5e8a\u5b9e\u8df5\u9700\u5206\u6790\u5176\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6821\u51c6\u8bef\u5dee\uff0c\u5c24\u5176\u662f\u4e0d\u540c\u4eba\u53e3\u4e9a\u7ec4\u95f4\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51faCALIN\u63a8\u7406\u65f6\u6821\u51c6\u65b9\u6cd5\uff0c\u7528\u53cc\u5c42\u7a0b\u5e8f\u4f30\u8ba1\u6821\u51c6\u77e9\u9635\uff0c\u5728\u63a8\u7406\u65f6\u6821\u51c6\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u5206\u6570\u3002", "result": "\u5728\u4e09\u4e2a\u533b\u5b66\u6210\u50cf\u6570\u636e\u96c6\u5b9e\u9a8c\u8868\u660e\uff0cCALIN\u80fd\u786e\u4fdd\u9884\u6d4b\u4e2d\u516c\u5e73\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u63d0\u9ad8\u6574\u4f53\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4e14\u516c\u5e73\u6027 - \u5b9e\u7528\u6027\u6743\u8861\u6700\u5c0f\u3002", "conclusion": "CALIN\u65b9\u6cd5\u6709\u6548\uff0c\u53ef\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\u7684\u6821\u51c6\u504f\u5dee\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u4e0d\u516c\u5e73\u95ee\u9898\u3002"}}
{"id": "2507.14847", "pdf": "https://arxiv.org/pdf/2507.14847", "abs": "https://arxiv.org/abs/2507.14847", "authors": ["Junhan Yu", "Zhunyi Feng", "Junwei Lu", "Tianxi Cai", "Doudou Zhou"], "title": "Time-Aware Attention for Enhanced Electronic Health Records Modeling", "categories": ["cs.LG"], "comment": null, "summary": "Electronic Health Records (EHR) contain valuable clinical information for\npredicting patient outcomes and guiding healthcare decisions. However,\neffectively modeling Electronic Health Records (EHRs) requires addressing data\nheterogeneity and complex temporal patterns. Standard approaches often struggle\nwith irregular time intervals between clinical events. We propose TALE-EHR, a\nTransformer-based framework featuring a novel time-aware attention mechanism\nthat explicitly models continuous temporal gaps to capture fine-grained\nsequence dynamics. To complement this temporal modeling with robust semantics,\nTALE-EHR leverages embeddings derived from standardized code descriptions using\na pre-trained Large Language Model (LLM), providing a strong foundation for\nunderstanding clinical concepts. Experiments on the MIMIC-IV and PIC dataset\ndemonstrate that our approach outperforms state-of-the-art baselines on tasks\nsuch as disease progression forecasting. TALE-EHR underscores the benefit of\nintegrating explicit, continuous temporal modeling with strong semantic\nrepresentations provides a powerful solution for advancing EHR analysis.", "AI": {"tldr": "\u63d0\u51faTALE - EHR\u6846\u67b6\u5206\u6790\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u6709\u6548\u5efa\u6a21EHR\u9700\u89e3\u51b3\u6570\u636e\u5f02\u6784\u6027\u548c\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\u95ee\u9898\uff0c\u6807\u51c6\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u4e34\u5e8a\u4e8b\u4ef6\u95f4\u4e0d\u89c4\u5219\u65f6\u95f4\u95f4\u9694\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684TALE - EHR\u6846\u67b6\uff0c\u542b\u65f6\u95f4\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u6355\u6349\u5e8f\u5217\u52a8\u6001\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\u6765\u7406\u89e3\u4e34\u5e8a\u6982\u5ff5\u3002", "result": "\u5728MIMIC - IV\u548cPIC\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cTALE - EHR\u5728\u75be\u75c5\u8fdb\u5c55\u9884\u6d4b\u7b49\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u6574\u5408\u663e\u5f0f\u8fde\u7eed\u65f6\u95f4\u5efa\u6a21\u548c\u5f3a\u8bed\u4e49\u8868\u793a\u5bf9\u63a8\u8fdbEHR\u5206\u6790\u662f\u6709\u529b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14140", "pdf": "https://arxiv.org/pdf/2507.14140", "abs": "https://arxiv.org/abs/2507.14140", "authors": ["Marcus Saraiva", "Ana Muller", "Alexandre Maul"], "title": "Geophysics-informed neural network for model-based seismic inversion using surrogate point spread functions", "categories": ["physics.geo-ph", "cs.AI", "eess.SP"], "comment": null, "summary": "Model-based seismic inversion is a key technique in reservoir\ncharacterization, but traditional methods face significant limitations, such as\nrelying on 1D average stationary wavelets and assuming an unrealistic lateral\nresolution. To address these challenges, we propose a Geophysics-Informed\nNeural Network (GINN) that integrates deep learning with seismic modeling. This\nnovel approach employs a Deep Convolutional Neural Network (DCNN) to\nsimultaneously estimate Point Spread Functions (PSFs) and acoustic impedance\n(IP). PSFs are divided into zero-phase and residual components to ensure\ngeophysical consistency and to capture fine details. We used synthetic data\nfrom the SEAM Phase I Earth Model to train the GINN for 100 epochs\n(approximately 20 minutes) using a 2D UNet architecture. The network's inputs\ninclude positional features and a low-frequency impedance (LF-IP) model. A\nself-supervised loss function combining Mean Squared Error (MSE) and Structural\nSimilarity Index Measure (SSIM) was employed to ensure accurate results. The\nGINN demonstrated its ability to generate high-resolution IP and realistic\nPSFs, aligning with expected geological features. Unlike traditional 1D\nwavelets, the GINN produces PSFs with limited lateral resolution, reducing\nnoise and improving accuracy. Future work will aim to refine the training\nprocess and validate the methodology with real seismic data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u5730\u9707\u5efa\u6a21\u7684\u5730\u7403\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08GINN\uff09\u7528\u4e8e\u5730\u9707\u53cd\u6f14\uff0c\u7528\u5408\u6210\u6570\u636e\u8bad\u7ec3\uff0c\u6548\u679c\u826f\u597d\uff0c\u540e\u7eed\u5c06\u4f18\u5316\u8bad\u7ec3\u548c\u7528\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u7684\u5730\u9707\u53cd\u6f14\u65b9\u6cd5\u5b58\u5728\u4f9d\u8d56\u4e00\u7ef4\u5e73\u5747\u5e73\u7a33\u5b50\u6ce2\u3001\u6a2a\u5411\u5206\u8fa8\u7387\u5047\u8bbe\u4e0d\u73b0\u5b9e\u7b49\u5c40\u9650\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faGINN\uff0c\u7528\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u540c\u65f6\u4f30\u8ba1\u70b9\u6269\u6563\u51fd\u6570\uff08PSFs\uff09\u548c\u6ce2\u963b\u6297\uff08IP\uff09\uff0c\u5c06PSFs\u5206\u4e3a\u96f6\u76f8\u4f4d\u548c\u6b8b\u4f59\u5206\u91cf\uff0c\u7528SEAM\u4e00\u671f\u5730\u7403\u6a21\u578b\u5408\u6210\u6570\u636e\u4ee52D UNet\u67b6\u6784\u8bad\u7ec3100\u8f6e\uff0c\u4f7f\u7528\u7ed3\u5408MSE\u548cSSIM\u7684\u81ea\u76d1\u7763\u635f\u5931\u51fd\u6570\u3002", "result": "GINN\u80fd\u751f\u6210\u9ad8\u5206\u8fa8\u7387IP\u548c\u903c\u771fPSFs\uff0c\u4e0e\u9884\u671f\u5730\u8d28\u7279\u5f81\u76f8\u7b26\uff0c\u76f8\u6bd4\u4f20\u7edf\u4e00\u7ef4\u5b50\u6ce2\u51cf\u5c11\u566a\u58f0\u3001\u63d0\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "GINN\u65b9\u6cd5\u6709\u6548\uff0c\u672a\u6765\u9700\u4f18\u5316\u8bad\u7ec3\u8fc7\u7a0b\u5e76\u7528\u5b9e\u9645\u5730\u9707\u6570\u636e\u9a8c\u8bc1\u3002"}}
{"id": "2507.14850", "pdf": "https://arxiv.org/pdf/2507.14850", "abs": "https://arxiv.org/abs/2507.14850", "authors": ["H. M. Sabbir Ahmad", "Ehsan Sabouni", "Alexander Wasilkoff", "Param Budhraja", "Zijian Guo", "Songyuan Zhang", "Chuchu Fan", "Christos Cassandras", "Wenchao Li"], "title": "Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We address the problem of safe policy learning in multi-agent safety-critical\nautonomous systems. In such systems, it is necessary for each agent to meet the\nsafety requirements at all times while also cooperating with other agents to\naccomplish the task. Toward this end, we propose a safe Hierarchical\nMulti-Agent Reinforcement Learning (HMARL) approach based on Control Barrier\nFunctions (CBFs). Our proposed hierarchical approach decomposes the overall\nreinforcement learning problem into two levels learning joint cooperative\nbehavior at the higher level and learning safe individual behavior at the lower\nor agent level conditioned on the high-level policy. Specifically, we propose a\nskill-based HMARL-CBF algorithm in which the higher level problem involves\nlearning a joint policy over the skills for all the agents and the lower-level\nproblem involves learning policies to execute the skills safely with CBFs. We\nvalidate our approach on challenging environment scenarios whereby a large\nnumber of agents have to safely navigate through conflicting road networks.\nCompared with existing state of the art methods, our approach significantly\nimproves the safety achieving near perfect (within 5%) success/safety rate\nwhile also improving performance across all the environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCBFs\u7684\u5b89\u5168\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5b89\u5168\u5173\u952e\u81ea\u6cbb\u7cfb\u7edf\u7684\u5b89\u5168\u7b56\u7565\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u590d\u6742\u573a\u666f\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5b89\u5168\u5173\u952e\u81ea\u6cbb\u7cfb\u7edf\u4e2d\u5404\u667a\u80fd\u4f53\u9700\u65f6\u523b\u6ee1\u8db3\u5b89\u5168\u8981\u6c42\u5e76\u4e0e\u5176\u4ed6\u667a\u80fd\u4f53\u534f\u4f5c\u5b8c\u6210\u4efb\u52a1\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u63a7\u5236\u969c\u788d\u51fd\u6570\uff08CBFs\uff09\u7684\u5b89\u5168\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08HMARL\uff09\u65b9\u6cd5\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u5206\u89e3\u4e3a\u9ad8\u5c42\u5b66\u4e60\u8054\u5408\u534f\u4f5c\u884c\u4e3a\u548c\u4f4e\u5c42\u5b66\u4e60\u5b89\u5168\u4e2a\u4f53\u884c\u4e3a\uff0c\u63d0\u51fa\u57fa\u4e8e\u6280\u80fd\u7684HMARL - CBF\u7b97\u6cd5\u3002", "result": "\u5728\u5927\u91cf\u667a\u80fd\u4f53\u9700\u5728\u51b2\u7a81\u9053\u8def\u7f51\u7edc\u4e2d\u5b89\u5168\u5bfc\u822a\u7684\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u573a\u666f\u4e2d\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u663e\u8457\u63d0\u9ad8\u5b89\u5168\u6027\uff0c\u6210\u529f\u7387/\u5b89\u5168\u7387\u63a5\u8fd1\u5b8c\u7f8e\uff08\u8bef\u5dee\u57285%\u4ee5\u5185\uff09\uff0c\u4e14\u5728\u6240\u6709\u73af\u5883\u4e2d\u6027\u80fd\u5747\u6709\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5b89\u5168\u5173\u952e\u81ea\u6cbb\u7cfb\u7edf\u7684\u5b89\u5168\u7b56\u7565\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u5b89\u5168\u6027\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14141", "pdf": "https://arxiv.org/pdf/2507.14141", "abs": "https://arxiv.org/abs/2507.14141", "authors": ["Danny Dongyeop Han", "Ahhyun Lucy Lee", "Taeyang Lee", "Yonghyeon Gwon", "Sebin Lee", "Seongjin Lee", "David Keetae Park", "Shinjae Yoo", "Jiook Cha", "Chun Kee Chung"], "title": "DIVER-0 : A Fully Channel Equivariant EEG Foundation Model", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "11 pages, 1 figures, ICML 2025 Workshop on GenBio", "summary": "Electroencephalography (EEG) is a non-invasive technique widely used in\nbrain-computer interfaces and clinical applications, yet existing EEG\nfoundation models face limitations in modeling spatio-temporal brain dynamics\nand lack channel permutation equivariance, preventing robust generalization\nacross diverse electrode configurations. To address these challenges, we\npropose DIVER-0, a novel EEG foundation model that demonstrates how full\nspatio-temporal attention-rather than segregated spatial or temporal\nprocessing-achieves superior performance when properly designed with Rotary\nPosition Embedding (RoPE) for temporal relationships and binary attention\nbiases for channel differentiation. We also introduce Sliding Temporal\nConditional Positional Encoding (STCPE), which improves upon existing\nconditional positional encoding approaches by maintaining both temporal\ntranslation equivariance and channel permutation equivariance, enabling robust\nadaptation to arbitrary electrode configurations unseen during pretraining.\nExperimental results demonstrate that DIVER-0 achieves competitive performance\nwith only 10% of pretraining data while maintaining consistent results across\nall channel permutation conditions, validating its effectiveness for\ncross-dataset generalization and establishing key design principles for\nhandling the inherent heterogeneity of neural recording setups.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684EEG\u57fa\u7840\u6a21\u578bDIVER - 0\uff0c\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u5728\u65f6\u7a7a\u5efa\u6a21\u548c\u901a\u9053\u6392\u5217\u7b49\u65b9\u9762\u7684\u5c40\u9650\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709EEG\u57fa\u7840\u6a21\u578b\u5728\u5efa\u6a21\u65f6\u7a7a\u8111\u52a8\u529b\u5b66\u548c\u901a\u9053\u6392\u5217\u7b49\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u5728\u4e0d\u540c\u7535\u6781\u914d\u7f6e\u4e0b\u5b9e\u73b0\u9c81\u68d2\u6cdb\u5316\u3002", "method": "\u63d0\u51faDIVER - 0\u6a21\u578b\uff0c\u91c7\u7528\u5168\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7ed3\u5408RoPE\u5904\u7406\u65f6\u95f4\u5173\u7cfb\u3001\u4e8c\u5143\u6ce8\u610f\u529b\u504f\u5dee\u533a\u5206\u901a\u9053\uff1b\u5f15\u5165STCPE\u6539\u8fdb\u6761\u4ef6\u4f4d\u7f6e\u7f16\u7801\u3002", "result": "DIVER - 0\u4ec5\u752810%\u9884\u8bad\u7ec3\u6570\u636e\u5c31\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5728\u6240\u6709\u901a\u9053\u6392\u5217\u6761\u4ef6\u4e0b\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "\u9a8c\u8bc1\u4e86DIVER - 0\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u7684\u6709\u6548\u6027\uff0c\u786e\u7acb\u4e86\u5904\u7406\u795e\u7ecf\u8bb0\u5f55\u8bbe\u7f6e\u5f02\u8d28\u6027\u7684\u5173\u952e\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2507.14874", "pdf": "https://arxiv.org/pdf/2507.14874", "abs": "https://arxiv.org/abs/2507.14874", "authors": ["Ole-Christoffer Granmo", "Youmna Abdelwahab", "Per-Arne Andersen", "Paul F. A. Clarke", "Kunal Dumbre", "Ylva Gr\u00f8nnins\u00e6ter", "Vojtech Halenka", "Runar Helin", "Lei Jiao", "Ahmed Khalid", "Rebekka Omslandseter", "Rupsa Saha", "Mayur Shende", "Xuan Zhang"], "title": "The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "34 pages, 10 figures", "summary": "Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine\n(TM) both interpretable and efficient, while the power of Tsetlin automata\nenables accuracy comparable to deep learning on an increasing number of\ndatasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning\ninterpretable deep clauses from graph-structured input. Moving beyond flat,\nfixed-length input, the GraphTM gets more versatile, supporting sequences,\ngrids, relations, and multimodality. Through message passing, the GraphTM\nbuilds nested deep clauses to recognize sub-graph patterns with exponentially\nfewer clauses, increasing both interpretability and data utilization. For image\nclassification, GraphTM preserves interpretability and achieves 3.86%-points\nhigher accuracy on CIFAR-10 than a convolutional TM. For tracking action\ncoreference, faced with increasingly challenging tasks, GraphTM outperforms\nother reinforcement learning methods by up to 20.6%-points. In recommendation\nsystems, it tolerates increasing noise to a greater extent than a Graph\nConvolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains\naccuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence\ndata, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training\n2.5x faster than GCN. The GraphTM's application to these varied fields\ndemonstrates how graph representation learning and deep clauses bring new\npossibilities for TM learning.", "AI": {"tldr": "\u4ecb\u7ecd\u56feTsetlin\u673a\u5668(GraphTM)\uff0c\u5b83\u80fd\u4ece\u56fe\u7ed3\u6784\u8f93\u5165\u5b66\u4e60\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b50\u53e5\uff0c\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u793a\u56fe\u8868\u793a\u5b66\u4e60\u548c\u6df1\u5ea6\u5b50\u53e5\u4e3aTM\u5b66\u4e60\u5e26\u6765\u65b0\u53ef\u80fd\u3002", "motivation": "\u73b0\u6709Tsetlin\u673a\u5668\u9002\u7528\u4e8e\u7b80\u6d01\u6241\u5e73\u7684\u4e0e\u89c4\u5219\uff0c\u4e3a\u5904\u7406\u56fe\u7ed3\u6784\u8f93\u5165\uff0c\u5f00\u53d1\u66f4\u901a\u7528\u7684\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u6784\u5efa\u5d4c\u5957\u6df1\u5ea6\u5b50\u53e5\uff0c\u8bc6\u522b\u5b50\u56fe\u6a21\u5f0f\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u52a8\u4f5c\u5171\u6307\u8ddf\u8e2a\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u75c5\u6bd2\u57fa\u56e0\u7ec4\u5e8f\u5217\u6570\u636e\u7b49\u9886\u57df\u6709\u826f\u597d\u8868\u73b0\uff0c\u5982\u5728CIFAR - 10\u4e0a\u6bd4\u5377\u79efTM\u51c6\u786e\u7387\u9ad83.86%\u7b49\u3002", "conclusion": "\u56fe\u8868\u793a\u5b66\u4e60\u548c\u6df1\u5ea6\u5b50\u53e5\u4e3aTM\u5b66\u4e60\u5e26\u6765\u65b0\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.14151", "pdf": "https://arxiv.org/pdf/2507.14151", "abs": "https://arxiv.org/abs/2507.14151", "authors": ["Giuliana Monachino", "Nicol\u00f2 La Porta", "Beatrice Zanchi", "Luigi Fiorillo", "Alvise Dei Rossi", "Georgiy Farina", "Francesca Dalia Faraci"], "title": "Self-DANA: A Resource-Efficient Channel-Adaptive Self-Supervised Approach for ECG Foundation Models", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Foundation Models (FMs) are large-scale machine learning models trained on\nextensive, diverse datasets that can be adapted to a wide range of downstream\ntasks with minimal fine-tuning. In the last two years, interest in FMs has also\ngrown for applications in the cardiological field to analyze the\nelectrocardiogram (ECG) signals. One of the key properties of FMs is their\ntransferability to a wide range of downstream scenarios. With the spread of\nwearable and portable devices, keen interest in learning from reduced-channel\nconfigurations has arisen. However, the adaptation of ECG FMs to downstream\nscenarios with fewer available channels still has to be properly investigated.\nIn this work, we propose Self-DANA, a novel, easy-to-integrate solution that\nmakes self-supervised architectures adaptable to a reduced number of input\nchannels, ensuring resource efficiency and high performance. We also introduce\nRandom Lead Selection, a novel augmentation technique to pre-train models in a\nmore robust and channel-agnostic way. Our experimental results on five\nreduced-channel configurations demonstrate that Self-DANA significantly\nenhances resource efficiency while reaching state-of-the-art performance. It\nrequires up to 69.3% less peak CPU memory, 34.4% less peak GPU memory, about\n17% less average epoch CPU time, and about 24% less average epoch GPU time.", "AI": {"tldr": "\u63d0\u51faSelf - DANA\u4f7f\u81ea\u76d1\u7763\u67b6\u6784\u9002\u5e94\u5c11\u8f93\u5165\u901a\u9053\uff0c\u5f15\u5165\u968f\u673a\u5bfc\u8054\u9009\u62e9\u589e\u5f3a\u6280\u672f\uff0c\u5b9e\u9a8c\u663e\u793aSelf - DANA\u63d0\u5347\u8d44\u6e90\u6548\u7387\u4e14\u8fbe\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u5fc3\u810f\u75c5\u5b66\u9886\u57df\u5206\u6790\u5fc3\u7535\u56fe\u4fe1\u53f7\u53d7\u5173\u6ce8\uff0c\u4f46\u9002\u5e94\u5c11\u901a\u9053\u4e0b\u6e38\u573a\u666f\u5f85\u7814\u7a76\u3002", "method": "\u63d0\u51faSelf - DANA\u89e3\u51b3\u65b9\u6848\uff0c\u5f15\u5165\u968f\u673a\u5bfc\u8054\u9009\u62e9\u589e\u5f3a\u6280\u672f\u3002", "result": "\u5728\u4e94\u79cd\u5c11\u901a\u9053\u914d\u7f6e\u5b9e\u9a8c\u4e2d\uff0cSelf - DANA\u663e\u8457\u63d0\u5347\u8d44\u6e90\u6548\u7387\uff0c\u51cf\u5c11CPU\u548cGPU\u5185\u5b58\u53ca\u65f6\u95f4\u6d88\u8017\u3002", "conclusion": "Self - DANA\u53ef\u4f7f\u81ea\u76d1\u7763\u67b6\u6784\u9002\u5e94\u5c11\u8f93\u5165\u901a\u9053\uff0c\u80fd\u786e\u4fdd\u8d44\u6e90\u6548\u7387\u548c\u9ad8\u6027\u80fd\u3002"}}
{"id": "2507.14882", "pdf": "https://arxiv.org/pdf/2507.14882", "abs": "https://arxiv.org/abs/2507.14882", "authors": ["Ganesh Sundaram", "Jonas Ulmen", "Amjad Haider", "Daniel G\u00f6rges"], "title": "Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 22nd International Conference on Advanced Robotics (ICAR\n  2025)", "summary": "Deep neural networks (DNNs) offer significant versatility and performance\nbenefits, but their widespread adoption is often hindered by high model\ncomplexity and computational demands. Model compression techniques such as\npruning have emerged as promising solutions to these challenges. However, it\nremains critical to ensure that application-specific performance\ncharacteristics are preserved during compression. In structured pruning, where\ngroups of structurally coherent elements are removed, conventional importance\nmetrics frequently fail to maintain these essential performance attributes. In\nthis work, we propose an enhanced importance metric framework that not only\nreduces model size but also explicitly accounts for application-specific\nperformance constraints. We employ multiple strategies to determine the optimal\npruning magnitude for each group, ensuring a balance between compression and\ntask performance. Our approach is evaluated on an autoencoder tasked with\nreconstructing MNIST images. Experimental results demonstrate that the proposed\nmethod effectively preserves task-relevant performance, maintaining the model's\nusability even after substantial pruning, by satisfying the required\napplication-specific criteria.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u589e\u5f3a\u91cd\u8981\u6027\u5ea6\u91cf\u6846\u67b6\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u526a\u679d\uff0c\u5728MNIST\u56fe\u50cf\u91cd\u5efa\u7684\u81ea\u7f16\u7801\u5668\u4e0a\u9a8c\u8bc1\uff0c\u80fd\u5728\u5927\u5e45\u526a\u679d\u540e\u4fdd\u6301\u6a21\u578b\u53ef\u7528\u6027\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u590d\u6742\u5ea6\u548c\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u73b0\u6709\u7ed3\u6784\u5316\u526a\u679d\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u96be\u4ee5\u4fdd\u7559\u7279\u5b9a\u5e94\u7528\u6027\u80fd\u7279\u5f81\u3002", "method": "\u63d0\u51fa\u589e\u5f3a\u91cd\u8981\u6027\u5ea6\u91cf\u6846\u67b6\uff0c\u91c7\u7528\u591a\u79cd\u7b56\u7565\u786e\u5b9a\u6bcf\u7ec4\u7684\u6700\u4f73\u526a\u679d\u5e45\u5ea6\u3002", "result": "\u5728MNIST\u56fe\u50cf\u91cd\u5efa\u7684\u81ea\u7f16\u7801\u5668\u4e0a\u5b9e\u9a8c\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u4fdd\u7559\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u53ef\u5728\u5927\u5e45\u526a\u679d\u540e\u6ee1\u8db3\u7279\u5b9a\u5e94\u7528\u6807\u51c6\uff0c\u4fdd\u6301\u6a21\u578b\u53ef\u7528\u6027\u3002"}}
{"id": "2507.14153", "pdf": "https://arxiv.org/pdf/2507.14153", "abs": "https://arxiv.org/abs/2507.14153", "authors": ["Daniel Cie\u015blak", "Barbara Szyca", "Weronika Bajko", "Liwia Florkiewicz", "Kinga Grz\u0119da", "Mariusz Kaczmarek", "Helena Kamieniecka", "Hubert Lis", "Weronika Matwiejuk", "Anna Prus", "Michalina Razik", "Inga Rozumowicz", "Wiktoria Ziembakowska"], "title": "Surface EMG Profiling in Parkinson's Disease: Advancing Severity Assessment with GCN-SVM", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "International Conference on Hybrid Artificial Intelligence Systems\n  (HAIS 2024)", "summary": "Parkinson's disease (PD) poses challenges in diagnosis and monitoring due to\nits progressive nature and complex symptoms. This study introduces a novel\napproach utilizing surface electromyography (sEMG) to objectively assess PD\nseverity, focusing on the biceps brachii muscle. Initial analysis of sEMG data\nfrom five PD patients and five healthy controls revealed significant\nneuromuscular differences. A traditional Support Vector Machine (SVM) model\nachieved up to 83% accuracy, while enhancements with a Graph Convolutional\nNetwork-Support Vector Machine (GCN-SVM) model increased accuracy to 92%.\nDespite the preliminary nature of these results, the study outlines a detailed\nexperimental methodology for future research with larger cohorts to validate\nthese findings and integrate the approach into clinical practice. The proposed\napproach holds promise for advancing PD severity assessment and improving\npatient care in Parkinson's disease management.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u5229\u7528\u8868\u9762\u808c\u7535\u56fe\uff08sEMG\uff09\u8bc4\u4f30\u5e15\u91d1\u68ee\u75c5\uff08PD\uff09\u4e25\u91cd\u7a0b\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u4f20\u7edfSVM\u6a21\u578b\u51c6\u786e\u7387\u8fbe83%\uff0cGCN - SVM\u6a21\u578b\u63d0\u5347\u81f392%\uff0c\u540e\u7eed\u5f85\u5927\u6837\u672c\u9a8c\u8bc1\u3002", "motivation": "\u5e15\u91d1\u68ee\u75c5\u8bca\u65ad\u548c\u76d1\u6d4b\u56e0\u75c5\u60c5\u8fdb\u5c55\u548c\u75c7\u72b6\u590d\u6742\u9762\u4e34\u6311\u6218\uff0c\u9700\u5ba2\u89c2\u8bc4\u4f30\u75c5\u60c5\u4e25\u91cd\u7a0b\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u5bf9\u4e94\u540dPD\u60a3\u8005\u548c\u4e94\u540d\u5065\u5eb7\u5bf9\u7167\u7684\u80b1\u4e8c\u5934\u808csEMG\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u4f7f\u7528\u4f20\u7edfSVM\u6a21\u578b\u548cGCN - SVM\u6a21\u578b\u3002", "result": "\u4f20\u7edfSVM\u6a21\u578b\u51c6\u786e\u7387\u8fbe83%\uff0cGCN - SVM\u6a21\u578b\u51c6\u786e\u7387\u63d0\u5347\u81f392%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6f5c\u529b\u63a8\u52a8PD\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u4f30\uff0c\u6539\u5584\u60a3\u8005\u62a4\u7406\u3002"}}
{"id": "2507.14919", "pdf": "https://arxiv.org/pdf/2507.14919", "abs": "https://arxiv.org/abs/2507.14919", "authors": ["Maximilian Wendlinger", "Kilian Tscharke", "Pascal Debus"], "title": "Old Rules in a New Game: Mapping Uncertainty Quantification to Quantum Machine Learning", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "One of the key obstacles in traditional deep learning is the reduction in\nmodel transparency caused by increasingly intricate model functions, which can\nlead to problems such as overfitting and excessive confidence in predictions.\nWith the advent of quantum machine learning offering possible advances in\ncomputational power and latent space complexity, we notice the same opaque\nbehavior. Despite significant research in classical contexts, there has been\nlittle advancement in addressing the black-box nature of quantum machine\nlearning. Consequently, we approach this gap by building upon existing work in\nclassical uncertainty quantification and initial explorations in quantum\nBayesian modeling to theoretically develop and empirically evaluate techniques\nto map classical uncertainty quantification methods to the quantum machine\nlearning domain. Our findings emphasize the necessity of leveraging classical\ninsights into uncertainty quantification to include uncertainty awareness in\nthe process of designing new quantum machine learning models.", "AI": {"tldr": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u5b58\u5728\u6a21\u578b\u4e0d\u900f\u660e\u95ee\u9898\uff0c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e5f\u6709\u540c\u6837\u95ee\u9898\uff0c\u672c\u6587\u5c06\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u6620\u5c04\u5230\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9886\u57df\uff0c\u5e76\u5f3a\u8c03\u8bbe\u8ba1\u65b0\u91cf\u5b50\u6a21\u578b\u65f6\u8981\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u548c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u90fd\u5b58\u5728\u6a21\u578b\u4e0d\u900f\u660e\u95ee\u9898\uff0c\u7ecf\u5178\u8bed\u5883\u4e0b\u867d\u6709\u7814\u7a76\uff0c\u4f46\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9ed1\u7bb1\u6027\u8d28\u89e3\u51b3\u8fdb\u5c55\u751a\u5fae\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u73b0\u6709\u5de5\u4f5c\u548c\u91cf\u5b50\u8d1d\u53f6\u65af\u5efa\u6a21\u521d\u6b65\u63a2\u7d22\uff0c\u5c06\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u6620\u5c04\u5230\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9886\u57df\u3002", "result": "\u8fdb\u884c\u4e86\u7406\u8bba\u5f00\u53d1\u548c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "conclusion": "\u8bbe\u8ba1\u65b0\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65f6\u9700\u5229\u7528\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u89c1\u89e3\uff0c\u7eb3\u5165\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u3002"}}
{"id": "2507.14156", "pdf": "https://arxiv.org/pdf/2507.14156", "abs": "https://arxiv.org/abs/2507.14156", "authors": ["Kai Yi", "Kiarash Jamali", "Sjors H. W. Scheres"], "title": "All-atom inverse protein folding through discrete flow matching", "categories": ["q-bio.BM", "cs.AI"], "comment": "ICML2025", "summary": "The recent breakthrough of AlphaFold3 in modeling complex biomolecular\ninteractions, including those between proteins and ligands, nucleotides, or\nmetal ions, creates new opportunities for protein design. In so-called inverse\nprotein folding, the objective is to find a sequence of amino acids that adopts\na target protein structure. Many inverse folding methods struggle to predict\nsequences for complexes that contain non-protein components, and perform poorly\nwith complexes that adopt multiple structural states. To address these\nchallenges, we present ADFLIP (All-atom Discrete FLow matching Inverse Protein\nfolding), a generative model based on discrete flow-matching for designing\nprotein sequences conditioned on all-atom structural contexts. ADFLIP\nprogressively incorporates predicted amino acid side chains as structural\ncontext during sequence generation and enables the design of dynamic protein\ncomplexes through ensemble sampling across multiple structural states.\nFurthermore, ADFLIP implements training-free classifier guidance sampling,\nwhich allows the incorporation of arbitrary pre-trained models to optimise the\ndesigned sequence for desired protein properties. We evaluated the performance\nof ADFLIP on protein complexes with small-molecule ligands, nucleotides, or\nmetal ions, including dynamic complexes for which structure ensembles were\ndetermined by nuclear magnetic resonance (NMR). Our model achieves\nstate-of-the-art performance in single-structure and multi-structure inverse\nfolding tasks, demonstrating excellent potential for all-atom protein design.\nThe code is available at https://github.com/ykiiiiii/ADFLIP.", "AI": {"tldr": "\u4ecb\u7ecdADFLIP\u6a21\u578b\u7528\u4e8e\u9006\u86cb\u767d\u6298\u53e0\u8bbe\u8ba1\uff0c\u5728\u5355\u7ed3\u6784\u548c\u591a\u7ed3\u6784\u9006\u6298\u53e0\u4efb\u52a1\u4e2d\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u9006\u6298\u53e0\u65b9\u6cd5\u96be\u4ee5\u9884\u6d4b\u542b\u975e\u86cb\u767d\u8d28\u6210\u5206\u590d\u5408\u7269\u7684\u5e8f\u5217\uff0c\u4e14\u5bf9\u591a\u7ed3\u6784\u72b6\u6001\u590d\u5408\u7269\u6548\u679c\u5dee\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u79bb\u6563\u6d41\u5339\u914d\u7684\u751f\u6210\u6a21\u578bADFLIP\uff0c\u751f\u6210\u5e8f\u5217\u65f6\u9010\u6b65\u7eb3\u5165\u9884\u6d4b\u7684\u6c28\u57fa\u9178\u4fa7\u94fe\uff0c\u901a\u8fc7\u591a\u7ed3\u6784\u72b6\u6001\u96c6\u5408\u91c7\u6837\u8bbe\u8ba1\u52a8\u6001\u86cb\u767d\u590d\u5408\u7269\uff0c\u5b9e\u73b0\u514d\u8bad\u7ec3\u5206\u7c7b\u5668\u5f15\u5bfc\u91c7\u6837\u3002", "result": "\u5728\u542b\u5c0f\u5206\u5b50\u914d\u4f53\u3001\u6838\u82f7\u9178\u6216\u91d1\u5c5e\u79bb\u5b50\u7684\u86cb\u767d\u590d\u5408\u7269\u4e0a\u8bc4\u4f30\uff0c\u5728\u5355\u7ed3\u6784\u548c\u591a\u7ed3\u6784\u9006\u6298\u53e0\u4efb\u52a1\u4e2d\u8fbeSOTA\u3002", "conclusion": "ADFLIP\u5728\u5168\u539f\u5b50\u86cb\u767d\u8d28\u8bbe\u8ba1\u65b9\u9762\u6709\u5f88\u5927\u6f5c\u529b\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2507.14980", "pdf": "https://arxiv.org/pdf/2507.14980", "abs": "https://arxiv.org/abs/2507.14980", "authors": ["Tianle Li", "Yongzhi Huang", "Linshan Jiang", "Qipeng Xie", "Chang Liu", "Wenfeng Du", "Lu Wang", "Kaishun Wu"], "title": "FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios", "categories": ["cs.LG", "68T05, 90C26", "I.2.6; I.5.1; I.2.10"], "comment": "ICPP, including appendix", "summary": "Federated Learning (FL) enables decentralized model training while preserving\ndata privacy. Despite its benefits, FL faces challenges with non-identically\ndistributed (non-IID) data, especially in long-tailed scenarios with imbalanced\nclass samples. Momentum-based FL methods, often used to accelerate FL\nconvergence, struggle with these distributions, resulting in biased models and\nmaking FL hard to converge. To understand this challenge, we conduct extensive\ninvestigations into this phenomenon, accompanied by a layer-wise analysis of\nneural network behavior. Based on these insights, we propose FedWCM, a method\nthat dynamically adjusts momentum using global and per-round data to correct\ndirectional biases introduced by long-tailed distributions. Extensive\nexperiments show that FedWCM resolves non-convergence issues and outperforms\nexisting methods, enhancing FL's efficiency and effectiveness in handling\nclient heterogeneity and data imbalance.", "AI": {"tldr": "\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u5728\u957f\u5c3e\u6570\u636e\u573a\u666f\u4e0b\u7684\u6536\u655b\u95ee\u9898\uff0c\u63d0\u51faFedWCM\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u89e3\u51b3\u975e\u6536\u655b\u95ee\u9898\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5904\u7406\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non - IID\uff09\u6570\u636e\uff0c\u5c24\u5176\u662f\u957f\u5c3e\u573a\u666f\u4e0b\u7684\u7c7b\u6837\u672c\u4e0d\u5e73\u8861\u6570\u636e\u65f6\u9762\u4e34\u6311\u6218\uff0c\u57fa\u4e8e\u52a8\u91cf\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u6536\u655b\u4e14\u6a21\u578b\u6709\u504f\u5dee\u3002", "method": "\u5bf9\u8be5\u73b0\u8c61\u8fdb\u884c\u5e7f\u6cdb\u7814\u7a76\u548c\u795e\u7ecf\u7f51\u7edc\u5c42\u5206\u6790\uff0c\u63d0\u51faFedWCM\u65b9\u6cd5\uff0c\u5229\u7528\u5168\u5c40\u548c\u6bcf\u8f6e\u6570\u636e\u52a8\u6001\u8c03\u6574\u52a8\u91cf\u4ee5\u7ea0\u6b63\u957f\u5c3e\u5206\u5e03\u5e26\u6765\u7684\u65b9\u5411\u504f\u5dee\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660eFedWCM\u89e3\u51b3\u4e86\u975e\u6536\u655b\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "FedWCM\u63d0\u9ad8\u4e86\u8054\u90a6\u5b66\u4e60\u5904\u7406\u5ba2\u6237\u7aef\u5f02\u8d28\u6027\u548c\u6570\u636e\u4e0d\u5e73\u8861\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.14164", "pdf": "https://arxiv.org/pdf/2507.14164", "abs": "https://arxiv.org/abs/2507.14164", "authors": ["Samuel Ruip\u00e9rez-Campillo", "Alain Ryser", "Thomas M. Sutter", "Ruibin Feng", "Prasanth Ganesan", "Brototo Deb", "Kelly A. Brennan", "Maxime Pedron", "Albert J. Rogers", "Maarten Z. H. Kolk", "Fleur V. Y. Tjong", "Sanjiv M. Narayan", "Julia E. Vogt"], "title": "A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy", "categories": ["eess.SP", "cs.AI", "cs.LG", "I.2; J.3"], "comment": "9 pages, 2 figures, 3 tables, the last two authors are shared senior\n  authors", "summary": "In the field of cardiac electrophysiology (EP), effectively reducing noise in\nintra-cardiac signals is crucial for the accurate diagnosis and treatment of\narrhythmias and cardiomyopathies. However, traditional noise reduction\ntechniques fall short in addressing the diverse noise patterns from various\nsources, often non-linear and non-stationary, present in these signals. This\nwork introduces a Variational Autoencoder (VAE) model, aimed at improving the\nquality of intra-ventricular monophasic action potential (MAP) signal\nrecordings. By constructing representations of clean signals from a dataset of\n5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our\napproach demonstrates superior denoising performance when compared to\nconventional filtering methods commonly employed in clinical settings. We\nassess the effectiveness of our VAE model using various metrics, indicating its\nsuperior capability to denoise signals across different noise types, including\ntime-varying non-linear noise frequently found in clinical settings. These\nresults reveal that VAEs can eliminate diverse sources of noise in single\nbeats, outperforming state-of-the-art denoising techniques and potentially\nimproving treatment efficacy in cardiac EP.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u6a21\u578b\u6539\u5584\u5fc3\u5ba4\u5185\u5355\u76f8\u52a8\u4f5c\u7535\u4f4d\uff08MAP\uff09\u4fe1\u53f7\u8bb0\u5f55\u8d28\u91cf\uff0c\u5728\u53bb\u566a\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u964d\u566a\u6280\u672f\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5fc3\u810f\u7535\u751f\u7406\u4fe1\u53f7\u4e2d\u591a\u6837\u7684\u566a\u58f0\u6a21\u5f0f\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u6539\u5584\u4fe1\u53f7\u8d28\u91cf\u4ee5\u8f85\u52a9\u5fc3\u5f8b\u5931\u5e38\u548c\u5fc3\u808c\u75c5\u7684\u51c6\u786e\u8bca\u65ad\u4e0e\u6cbb\u7597\u3002", "method": "\u6784\u5efaVAE\u6a21\u578b\uff0c\u5229\u752842\u540d\u7f3a\u8840\u6027\u5fc3\u808c\u75c5\u60a3\u8005\u76845706\u4e2a\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u6784\u5efa\u5e72\u51c0\u4fe1\u53f7\u7684\u8868\u793a\u3002", "result": "VAE\u6a21\u578b\u5728\u4e0d\u540c\u566a\u58f0\u7c7b\u578b\u4e0b\u5747\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u53bb\u566a\u80fd\u529b\uff0c\u80fd\u6d88\u9664\u5355\u640f\u4e2d\u7684\u5404\u79cd\u566a\u58f0\u6e90\uff0c\u4f18\u4e8e\u73b0\u6709\u53bb\u566a\u6280\u672f\u3002", "conclusion": "VAE\u6a21\u578b\u53ef\u7528\u4e8e\u5fc3\u810f\u7535\u751f\u7406\u9886\u57df\uff0c\u6709\u671b\u63d0\u9ad8\u6cbb\u7597\u6548\u679c\u3002"}}
{"id": "2507.14999", "pdf": "https://arxiv.org/pdf/2507.14999", "abs": "https://arxiv.org/abs/2507.14999", "authors": ["Yunfeng Li", "Junhong Liu", "Zhaohui Yang", "Guofu Liao", "Chuyun Zhang"], "title": "Clustered Federated Learning for Generalizable FDIA Detection in Smart Grids with Heterogeneous Data", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "10 pages,6 figures", "summary": "False Data Injection Attacks (FDIAs) pose severe security risks to smart\ngrids by manipulating measurement data collected from spatially distributed\ndevices such as SCADA systems and PMUs. These measurements typically exhibit\nNon-Independent and Identically Distributed (Non-IID) characteristics across\ndifferent regions, which significantly challenges the generalization ability of\ndetection models. Traditional centralized training approaches not only face\nprivacy risks and data sharing constraints but also incur high transmission\ncosts, limiting their scalability and deployment feasibility. To address these\nissues, this paper proposes a privacy-preserving federated learning framework,\ntermed Federated Cluster Average (FedClusAvg), designed to improve FDIA\ndetection in Non-IID and resource-constrained environments. FedClusAvg\nincorporates cluster-based stratified sampling and hierarchical communication\n(client-subserver-server) to enhance model generalization and reduce\ncommunication overhead. By enabling localized training and weighted parameter\naggregation, the algorithm achieves accurate model convergence without\ncentralizing sensitive data. Experimental results on benchmark smart grid\ndatasets demonstrate that FedClusAvg not only improves detection accuracy under\nheterogeneous data distributions but also significantly reduces communication\nrounds and bandwidth consumption. This work provides an effective solution for\nsecure and efficient FDIA detection in large-scale distributed power systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFedClusAvg\u6846\u67b6\u7528\u4e8e\u975eIID\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u667a\u80fd\u7535\u7f51FDIA\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u5e76\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u667a\u80fd\u7535\u7f51FDIA\u5a01\u80c1\u5927\uff0c\u6570\u636e\u6709Non - IID\u7279\u6027\uff0c\u4f20\u7edf\u96c6\u4e2d\u8bad\u7ec3\u6709\u9690\u79c1\u3001\u6210\u672c\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u68c0\u6d4b\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faFederated Cluster Average (FedClusAvg)\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u4e8e\u96c6\u7fa4\u7684\u5206\u5c42\u62bd\u6837\u548c\u5206\u5c42\u901a\u4fe1\uff0c\u5b9e\u73b0\u672c\u5730\u8bad\u7ec3\u548c\u52a0\u6743\u53c2\u6570\u805a\u5408\u3002", "result": "\u5728\u57fa\u51c6\u667a\u80fd\u7535\u7f51\u6570\u636e\u96c6\u4e0a\uff0cFedClusAvg\u63d0\u9ad8\u4e86\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u7684\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u51cf\u5c11\u4e86\u901a\u4fe1\u8f6e\u6b21\u548c\u5e26\u5bbd\u6d88\u8017\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7535\u529b\u7cfb\u7edf\u4e2d\u5b89\u5168\u9ad8\u6548\u7684FDIA\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15066", "pdf": "https://arxiv.org/pdf/2507.15066", "abs": "https://arxiv.org/abs/2507.15066", "authors": ["Yiyuan Yang", "Zichuan Liu", "Lei Song", "Kai Ying", "Zhiguang Wang", "Tom Bamford", "Svitlana Vyetrenko", "Jiang Bian", "Qingsong Wen"], "title": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "categories": ["cs.LG", "cs.AI", "cs.MM"], "comment": "Under review. 19 pages, 8 figures, 12 tables", "summary": "Time series anomaly detection is critical across various domains, yet current\napproaches often limit analysis to mere binary anomaly classification without\ndetailed categorization or further explanatory reasoning. To address these\nlimitations, we propose a novel task, Time-series Reasoning for Anomaly\n(Time-RA) that transforms classical time series anomaly detection from a\ndiscriminative into a generative, reasoning-intensive task leveraging Large\nLanguage Models (LLMs). Also, we introduce the first real-world multimodal\nbenchmark dataset, RATs40K, explicitly annotated for anomaly reasoning,\ncomprising approximately 40,000 samples across 10 real-world domains. Each\nsample includes numeric time series data, contextual text information, and\nvisual representations, each annotated with fine-grained categories (14 types\nfor univariate anomalies and 6 for multivariate anomalies) and structured\nexplanatory reasoning. We develop a sophisticated annotation framework\nutilizing ensemble-generated labels refined through GPT-4-driven feedback,\nensuring accuracy and interpretability. Extensive benchmarking of LLMs and\nmultimodal LLMs demonstrates the capabilities and limitations of current\nmodels, highlighting the critical role of supervised fine-tuning. Our dataset\nand task pave the way for significant advancements in interpretable time series\nanomaly detection and reasoning.", "AI": {"tldr": "\u63d0\u51fa\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u63a8\u7406\u4efb\u52a1Time - RA\uff0c\u5f15\u5165\u57fa\u51c6\u6570\u636e\u96c6RATs40K\uff0c\u5f00\u5c55\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63a8\u52a8\u53ef\u89e3\u91ca\u5f02\u5e38\u68c0\u6d4b\u4e0e\u63a8\u7406\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5c40\u9650\u4e8e\u4e8c\u5143\u5206\u7c7b\uff0c\u7f3a\u4e4f\u8be6\u7ec6\u5206\u7c7b\u548c\u89e3\u91ca\u63a8\u7406\u3002", "method": "\u63d0\u51faTime - RA\u4efb\u52a1\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u751f\u6210\u5f0f\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\uff1b\u5f15\u5165\u6570\u636e\u96c6RATs40K\uff1b\u5f00\u53d1\u5229\u7528GPT - 4\u53cd\u9988\u4f18\u5316\u7684\u6807\u6ce8\u6846\u67b6\u3002", "result": "\u5bf9\u5927\u6a21\u578b\u548c\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u5c55\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u80fd\u529b\u548c\u5c40\u9650\uff0c\u51f8\u663e\u4e86\u76d1\u7763\u5fae\u8c03\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e3a\u53ef\u89e3\u91ca\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u548c\u63a8\u7406\u5e26\u6765\u663e\u8457\u8fdb\u5c55\u3002"}}
{"id": "2507.15067", "pdf": "https://arxiv.org/pdf/2507.15067", "abs": "https://arxiv.org/abs/2507.15067", "authors": ["Bing He", "Mustaque Ahamad", "Srijan Kumar"], "title": "ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model", "categories": ["cs.LG", "cs.SI"], "comment": "15 pages, 12 tables", "summary": "Detecting bad actors is critical to ensure the safety and integrity of\ninternet platforms. Several deep learning-based models have been developed to\nidentify such users. These models should not only accurately detect bad actors,\nbut also be robust against adversarial attacks that aim to evade detection.\nHowever, past deep learning-based detection models do not meet the robustness\nrequirement because they are sensitive to even minor changes in the input\nsequence. To address this issue, we focus on (1) improving the model\nunderstanding capability and (2) enhancing the model knowledge such that the\nmodel can recognize potential input modifications when making predictions. To\nachieve these goals, we create a novel transformer-based classification model,\ncalled ROBAD (RObust adversary-aware local-global attended Bad Actor Detection\nmodel), which uses the sequence of user posts to generate user embedding to\ndetect bad actors. Particularly, ROBAD first leverages the transformer encoder\nblock to encode each post bidirectionally, thus building a post embedding to\ncapture the local information at the post level. Next, it adopts the\ntransformer decoder block to model the sequential pattern in the post\nembeddings by using the attention mechanism, which generates the sequence\nembedding to obtain the global information at the sequence level. Finally, to\nenrich the knowledge of the model, embeddings of modified sequences by mimicked\nattackers are fed into a contrastive-learning-enhanced classification layer for\nsequence prediction. In essence, by capturing the local and global information\n(i.e., the post and sequence information) and leveraging the mimicked behaviors\nof bad actors in training, ROBAD can be robust to adversarial attacks.\nExtensive experiments on Yelp and Wikipedia datasets show that ROBAD can\neffectively detect bad actors when under state-of-the-art adversarial attacks.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faROBAD\u6a21\u578b\u68c0\u6d4b\u7f51\u7edc\u5e73\u53f0\u4e0d\u826f\u884c\u4e3a\u8005\uff0c\u80fd\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\uff0c\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u68c0\u6d4b\u6a21\u578b\u5bf9\u8f93\u5165\u5e8f\u5217\u5fae\u5c0f\u53d8\u5316\u654f\u611f\uff0c\u4e0d\u6ee1\u8db3\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u8981\u6c42\u3002", "method": "\u521b\u5efaROBAD\u6a21\u578b\uff0c\u7528Transformer\u7f16\u7801\u5668\u5757\u7f16\u7801\u5e16\u5b50\uff0c\u89e3\u7801\u5668\u5757\u5efa\u6a21\u5e8f\u5217\u6a21\u5f0f\uff0c\u7528\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u5206\u7c7b\u5c42\u8fdb\u884c\u5e8f\u5217\u9884\u6d4b\u3002", "result": "\u5728Yelp\u548cWikipedia\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cROBAD\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u80fd\u6709\u6548\u68c0\u6d4b\u4e0d\u826f\u884c\u4e3a\u8005\u3002", "conclusion": "ROBAD\u6a21\u578b\u901a\u8fc7\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\uff0c\u5229\u7528\u6a21\u4eff\u653b\u51fb\u884c\u4e3a\u8bad\u7ec3\uff0c\u5bf9\u5bf9\u6297\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.15073", "pdf": "https://arxiv.org/pdf/2507.15073", "abs": "https://arxiv.org/abs/2507.15073", "authors": ["Samuel Pfrommer", "Yixiao Huang", "Somayeh Sojoudi"], "title": "Reinforcement Learning for Flow-Matching Policies", "categories": ["cs.LG"], "comment": null, "summary": "Flow-matching policies have emerged as a powerful paradigm for generalist\nrobotics. These models are trained to imitate an action chunk, conditioned on\nsensor observations and textual instructions. Often, training demonstrations\nare generated by a suboptimal policy, such as a human operator. This work\nexplores training flow-matching policies via reinforcement learning to surpass\nthe original demonstration policy performance. We particularly note\nminimum-time control as a key application and present a simple scheme for\nvariable-horizon flow-matching planning. We then introduce two families of\napproaches: a simple Reward-Weighted Flow Matching (RWFM) scheme and a Group\nRelative Policy Optimization (GRPO) approach with a learned reward surrogate.\nOur policies are trained on an illustrative suite of simulated unicycle\ndynamics tasks, and we show that both approaches dramatically improve upon the\nsuboptimal demonstrator performance, with the GRPO approach in particular\ngenerally incurring between $50\\%$ and $85\\%$ less cost than a naive Imitation\nLearning Flow Matching (ILFM) approach.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\u4ee5\u8d85\u8d8a\u539f\u6f14\u793a\u7b56\u7565\u7684\u6027\u80fd\uff0c\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\u5e76\u5728\u6a21\u62df\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u539f\u8bad\u7ec3\u6f14\u793a\u7b56\u7565\u53ef\u80fd\u6b21\u4f18\uff0c\u5e0c\u671b\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\u8d85\u8d8a\u539f\u6f14\u793a\u7b56\u7565\u6027\u80fd\u3002", "method": "\u63d0\u51faReward - Weighted Flow Matching (RWFM)\u65b9\u6848\u548cGroup Relative Policy Optimization (GRPO)\u65b9\u6cd5\uff0c\u540e\u8005\u5e26\u6709\u5b66\u4e60\u7684\u5956\u52b1\u66ff\u4ee3\u3002", "result": "\u5728\u6a21\u62df\u5355\u8f6e\u52a8\u529b\u5b66\u4efb\u52a1\u4e2d\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u663e\u8457\u63d0\u5347\u4e86\u6b21\u4f18\u6f14\u793a\u8005\u7684\u6027\u80fd\uff0cGRPO\u65b9\u6cd5\u6bd4\u6734\u7d20\u7684\u6a21\u4eff\u5b66\u4e60\u6d41\u5339\u914d(ILFM)\u65b9\u6cd5\u6210\u672c\u964d\u4f4e50% - 85%\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\u53ef\u6709\u6548\u8d85\u8d8a\u539f\u6f14\u793a\u7b56\u7565\u6027\u80fd\uff0cGRPO\u65b9\u6cd5\u6548\u679c\u66f4\u4f73\u3002"}}
{"id": "2507.15079", "pdf": "https://arxiv.org/pdf/2507.15079", "abs": "https://arxiv.org/abs/2507.15079", "authors": ["Arkadiusz Lipiecki", "Bartosz Uniejewski"], "title": "Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts", "categories": ["cs.LG", "q-fin.ST", "stat.AP"], "comment": "Preprint", "summary": "Quantifying the uncertainty of forecasting models is essential to assess and\nmitigate the risks associated with data-driven decisions, especially in\nvolatile domains such as electricity markets. Machine learning methods can\nprovide highly accurate electricity price forecasts, critical for informing the\ndecisions of market participants. However, these models often lack uncertainty\nestimates, which limits the ability of decision makers to avoid unnecessary\nrisks. In this paper, we propose a novel method for generating probabilistic\nforecasts from ensembles of point forecasts, called Isotonic Quantile\nRegression Averaging (iQRA). Building on the established framework of Quantile\nRegression Averaging (QRA), we introduce stochastic order constraints to\nimprove forecast accuracy, reliability, and computational costs. In an\nextensive forecasting study of the German day-ahead electricity market, we show\nthat iQRA consistently outperforms state-of-the-art postprocessing methods in\nterms of both reliability and sharpness. It produces well-calibrated prediction\nintervals across multiple confidence levels, providing superior reliability to\nall benchmark methods, particularly coverage-based conformal prediction. In\naddition, isotonic regularization decreases the complexity of the quantile\nregression problem and offers a hyperparameter-free approach to variable\nselection.", "AI": {"tldr": "\u63d0\u51faIsotonic Quantile Regression Averaging (iQRA)\u65b9\u6cd5\u751f\u6210\u6982\u7387\u9884\u6d4b\uff0c\u5728\u5fb7\u56fd\u65e5\u524d\u7535\u529b\u5e02\u573a\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5177\u6709\u6b63\u5219\u5316\u4f18\u52bf\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u6a21\u578b\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u9650\u5236\u51b3\u7b56\u8005\u89c4\u907f\u98ce\u9669\u80fd\u529b\uff0c\u9700\u91cf\u5316\u9884\u6d4b\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51faiQRA\u65b9\u6cd5\uff0c\u57fa\u4e8eQuantile Regression Averaging (QRA)\u6846\u67b6\uff0c\u5f15\u5165\u968f\u673a\u987a\u5e8f\u7ea6\u675f\u3002", "result": "\u5728\u5fb7\u56fd\u65e5\u524d\u7535\u529b\u5e02\u573a\u5e7f\u6cdb\u7814\u7a76\u4e2d\uff0ciQRA\u5728\u53ef\u9760\u6027\u548c\u5c16\u9510\u6027\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u4ea7\u751f\u6821\u51c6\u826f\u597d\u7684\u9884\u6d4b\u533a\u95f4\u3002", "conclusion": "iQRA\u65b9\u6cd5\u6709\u6548\uff0c\u7b49\u6e17\u6b63\u5219\u5316\u964d\u4f4e\u5206\u4f4d\u6570\u56de\u5f52\u95ee\u9898\u590d\u6742\u5ea6\uff0c\u63d0\u4f9b\u65e0\u8d85\u53c2\u6570\u53d8\u91cf\u9009\u62e9\u65b9\u6cd5\u3002"}}
{"id": "2507.15082", "pdf": "https://arxiv.org/pdf/2507.15082", "abs": "https://arxiv.org/abs/2507.15082", "authors": ["Qian Qi"], "title": "Robust Control with Gradient Uncertainty", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "We introduce a novel extension to robust control theory that explicitly\naddresses uncertainty in the value function's gradient, a form of uncertainty\nendemic to applications like reinforcement learning where value functions are\napproximated. We formulate a zero-sum dynamic game where an adversary perturbs\nboth system dynamics and the value function gradient, leading to a new, highly\nnonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs\nEquation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness\nby proving a comparison principle for its viscosity solutions under a uniform\nellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a\nkey insight: we prove that the classical quadratic value function assumption\nfails for any non-zero gradient uncertainty, fundamentally altering the problem\nstructure. A formal perturbation analysis characterizes the non-polynomial\ncorrection to the value function and the resulting nonlinearity of the optimal\ncontrol law, which we validate with numerical studies. Finally, we bridge\ntheory to practice by proposing a novel Gradient-Uncertainty-Robust\nActor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating\nits effectiveness in stabilizing training. This work provides a new direction\nfor robust control, holding significant implications for fields where function\napproximation is common, including reinforcement learning and computational\nfinance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9c81\u68d2\u63a7\u5236\u7406\u8bba\u7684\u65b0\u6269\u5c55\uff0c\u5904\u7406\u503c\u51fd\u6570\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\uff0c\u63a8\u5bfcGU - HJBI\u65b9\u7a0b\uff0c\u5206\u6790LQ\u60c5\u51b5\uff0c\u63d0\u51faGURAC\u7b97\u6cd5\u5e76\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u7b49\u5e94\u7528\u4e2d\u503c\u51fd\u6570\u8fd1\u4f3c\u65f6\u503c\u51fd\u6570\u68af\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u6784\u5efa\u96f6\u548c\u52a8\u6001\u535a\u5f08\uff0c\u63a8\u5bfcGU - HJBI\u65b9\u7a0b\uff0c\u8bc1\u660e\u5176\u9002\u5b9a\u6027\uff0c\u5206\u6790LQ\u60c5\u51b5\uff0c\u8fdb\u884c\u5f62\u5f0f\u5316\u6270\u52a8\u5206\u6790\uff0c\u63d0\u51faGURAC\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u7ecf\u5178\u4e8c\u6b21\u503c\u51fd\u6570\u5047\u8bbe\u5728\u975e\u96f6\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u4e0b\u4e0d\u6210\u7acb\uff0c\u5f97\u51fa\u503c\u51fd\u6570\u975e\u591a\u9879\u5f0f\u4fee\u6b63\u548c\u6700\u4f18\u63a7\u5236\u5f8b\u975e\u7ebf\u6027\uff0c\u6570\u503c\u7814\u7a76\u9a8c\u8bc1\uff0cGURAC\u7b97\u6cd5\u7a33\u5b9a\u8bad\u7ec3\u3002", "conclusion": "\u4e3a\u9c81\u68d2\u63a7\u5236\u63d0\u4f9b\u65b0\u65b9\u5411\uff0c\u5bf9\u51fd\u6570\u8fd1\u4f3c\u5e38\u89c1\u9886\u57df\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.15104", "pdf": "https://arxiv.org/pdf/2507.15104", "abs": "https://arxiv.org/abs/2507.15104", "authors": ["Qiufeng Li", "Shu Hong", "Jian Gao", "Xuan Zhang", "Tian Lan", "Weidong Cao"], "title": "AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize\nanalog design automation through data-driven approaches. In particular,\nresearchers are increasingly fascinated by harnessing the power of generative\nAI to automate the discovery of novel analog circuit topologies. Unlocking the\nfull potential of generative AI in these data-driven discoveries requires\naccess to large and diverse datasets.Yet, there is a significant barrier in the\nanalog domain--Analog circuit design is inherently proprietary, involving not\nonly confidential circuit structures but also the underlying commercial\nsemiconductor processes. As a result, current generative AI research is largely\nconfined to individual researchers who construct small, narrowly focused\nprivate datasets. This fragmentation severely limits collaborative innovation\nand impedes progress across the research community. To address these\nchallenges, we propose AnalogFed. AnalogFed enables collaborative topology\ndiscovery across decentralized clients (e.g., individual researchers or\ninstitutions) without requiring the sharing of raw private data. To make this\nvision practical, we introduce a suite of techniques tailored to the unique\nchallenges of applying FedL in analog design--from generative model development\nand data heterogeneity handling to privacy-preserving strategies that ensure\nboth flexibility and security for circuit designers and semiconductor\nmanufacturers. Extensive experiments across varying client counts and dataset\nsizes demonstrate that AnalogFed achieves performance comparable to centralized\nbaselines--while maintaining strict data privacy. Specifically, the generative\nAI model within AnalogFed achieves state-of-the-art efficiency and scalability\nin the design of analog circuit topologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAnalogFed\u89e3\u51b3\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u4e2d\u751f\u6210\u5f0fAI\u6570\u636e\u79c1\u6709\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u7ebf\u76f8\u5f53\u4e14\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u6570\u636e\u4e13\u6709\uff0c\u5f53\u524d\u751f\u6210\u5f0fAI\u7814\u7a76\u53d7\u9650\u4e8e\u5c0f\u8303\u56f4\u79c1\u6709\u6570\u636e\u96c6\uff0c\u963b\u788d\u534f\u4f5c\u521b\u65b0\u548c\u7814\u7a76\u8fdb\u5c55\u3002", "method": "\u63d0\u51faAnalogFed\uff0c\u5f15\u5165\u9488\u5bf9\u6a21\u62df\u8bbe\u8ba1\u4e2d\u8054\u90a6\u5b66\u4e60\u72ec\u7279\u6311\u6218\u7684\u4e00\u7cfb\u5217\u6280\u672f\uff0c\u5305\u62ec\u751f\u6210\u6a21\u578b\u5f00\u53d1\u3001\u5904\u7406\u6570\u636e\u5f02\u8d28\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7b56\u7565\u3002", "result": "\u5728\u4e0d\u540c\u5ba2\u6237\u7aef\u6570\u91cf\u548c\u6570\u636e\u96c6\u5927\u5c0f\u7684\u5b9e\u9a8c\u4e2d\uff0cAnalogFed\u6027\u80fd\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u7ebf\u76f8\u5f53\uff0c\u5176\u751f\u6210\u5f0fAI\u6a21\u578b\u5728\u6a21\u62df\u7535\u8def\u62d3\u6251\u8bbe\u8ba1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "AnalogFed\u80fd\u5728\u4e0d\u5171\u4eab\u539f\u59cb\u79c1\u6709\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u534f\u4f5c\u62d3\u6251\u53d1\u73b0\uff0c\u517c\u987e\u6027\u80fd\u548c\u6570\u636e\u9690\u79c1\u3002"}}
{"id": "2507.15119", "pdf": "https://arxiv.org/pdf/2507.15119", "abs": "https://arxiv.org/abs/2507.15119", "authors": ["Juntong Ni", "Shiyu Wang", "Zewen Liu", "Xiaoming Shi", "Xinyue Zhong", "Zhou Ye", "Wei Jin"], "title": "Are We Overlooking the Dimensions? Learning Latent Hierarchical Channel Structure for High-Dimensional Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting (TSF) is a central problem in time series analysis.\nHowever, as the number of channels in time series datasets scales to the\nthousands or more, a scenario we define as High-Dimensional Time Series\nForecasting (HDTSF), it introduces significant new modeling challenges that are\noften not the primary focus of traditional TSF research. HDTSF is challenging\nbecause the channel correlation often forms complex and hierarchical patterns.\nExisting TSF models either ignore these interactions or fail to scale as\ndimensionality grows. To address this issue, we propose U-Cast, a\nchannel-dependent forecasting architecture that learns latent hierarchical\nchannel structures with an innovative query-based attention. To disentangle\nhighly correlated channel representation, U-Cast adds a full-rank\nregularization during training. We also release Time-HD, a benchmark of large,\ndiverse, high-dimensional datasets. Our theory shows that exploiting\ncross-channel information lowers forecasting risk, and experiments on Time-HD\ndemonstrate that U-Cast surpasses strong baselines in both accuracy and\nefficiency. Together, U-Cast and Time-HD provide a solid basis for future HDTSF\nresearch.", "AI": {"tldr": "\u9488\u5bf9\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08HDTSF\uff09\u95ee\u9898\u63d0\u51faU - Cast\u67b6\u6784\u548cTime - HD\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793aU - Cast\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u8d85\u8d8a\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u7814\u7a76\u672a\u805a\u7126HDTSF\u95ee\u9898\uff0c\u73b0\u6709TSF\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u4e2d\u590d\u6742\u7684\u901a\u9053\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51faU - Cast\u67b6\u6784\uff0c\u7528\u57fa\u4e8e\u67e5\u8be2\u7684\u6ce8\u610f\u529b\u5b66\u4e60\u6f5c\u5728\u5206\u5c42\u901a\u9053\u7ed3\u6784\uff0c\u8bad\u7ec3\u65f6\u6dfb\u52a0\u5168\u79e9\u6b63\u5219\u5316\uff0c\u8fd8\u53d1\u5e03Time - HD\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u5229\u7528\u8de8\u901a\u9053\u4fe1\u606f\u53ef\u964d\u4f4e\u9884\u6d4b\u98ce\u9669\uff0c\u5728Time - HD\u4e0a\u7684\u5b9e\u9a8c\u8868\u660eU - Cast\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u8d85\u8d8a\u5f3a\u57fa\u7ebf\u3002", "conclusion": "U - Cast\u548cTime - HD\u4e3a\u672a\u6765HDTSF\u7814\u7a76\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2507.15156", "pdf": "https://arxiv.org/pdf/2507.15156", "abs": "https://arxiv.org/abs/2507.15156", "authors": ["Mykhailo Buleshnyi", "Anna Polova", "Zsolt Zombori", "Michael Benedikt"], "title": "Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": null, "summary": "We investigate multi-label classification involving large sets of labels,\nwhere the output labels may be known to satisfy some logical constraints. We\nlook at an architecture in which classifiers for individual labels are fed into\nan expressive sequential model, which produces a joint distribution. One of the\npotential advantages for such an expressive model is its ability to modelling\ncorrelations, as can arise from constraints. We empirically demonstrate the\nability of the architecture both to exploit constraints in training and to\nenforce constraints at inference time.", "AI": {"tldr": "\u7814\u7a76\u542b\u5927\u91cf\u6807\u7b7e\u4e14\u6709\u903b\u8f91\u7ea6\u675f\u7684\u591a\u6807\u7b7e\u5206\u7c7b\uff0c\u63d0\u51fa\u67b6\u6784\u5e76\u5b9e\u8bc1\u5176\u5229\u7528\u548c\u6267\u884c\u7ea6\u675f\u7684\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u542b\u5927\u91cf\u6807\u7b7e\u4e14\u6709\u903b\u8f91\u7ea6\u675f\u7684\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898\uff0c\u53d1\u6325\u6a21\u578b\u5bf9\u76f8\u5173\u6027\u7684\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5c06\u5355\u4e2a\u6807\u7b7e\u5206\u7c7b\u5668\u8f93\u5165\u5230\u8868\u8fbe\u6027\u987a\u5e8f\u6a21\u578b\u4ee5\u4ea7\u751f\u8054\u5408\u5206\u5e03\u7684\u67b6\u6784\u3002", "result": "\u5b9e\u8bc1\u8868\u660e\u8be5\u67b6\u6784\u5728\u8bad\u7ec3\u65f6\u80fd\u5229\u7528\u7ea6\u675f\uff0c\u63a8\u7406\u65f6\u80fd\u6267\u884c\u7ea6\u675f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u67b6\u6784\u5728\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u5bf9\u903b\u8f91\u7ea6\u675f\u7684\u5229\u7528\u548c\u6267\u884c\u6709\u6548\u3002"}}
{"id": "2507.14184", "pdf": "https://arxiv.org/pdf/2507.14184", "abs": "https://arxiv.org/abs/2507.14184", "authors": ["ZhengXiao He", "Jinghao Wen", "Huayu Li", "Ao Li"], "title": "NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "We present a novel and interpretable framework for electrocardiogram\n(ECG)-based disease detection that combines hyperdimensional computing (HDC)\nwith learnable neural encoding. Unlike conventional HDC approaches that rely on\nstatic, random projections, our method introduces a rhythm-aware and trainable\nencoding pipeline based on RR intervals, a physiological signal segmentation\nstrategy that aligns with cardiac cycles. The core of our design is a\nneural-distilled HDC architecture, featuring a learnable RR-block encoder and a\nBinaryLinear hyperdimensional projection layer, optimized jointly with\ncross-entropy and proxy-based metric loss. This hybrid framework preserves the\nsymbolic interpretability of HDC while enabling task-adaptive representation\nlearning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model\nsignificantly outperforms traditional HDC and classical ML baselines, achieving\n73.09\\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable\nrobustness on PTB-XL. Our framework offers an efficient and scalable solution\nfor edge-compatible ECG classification, with strong potential for interpretable\nand personalized health monitoring.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u8d85\u7ef4\u8ba1\u7b97\u4e0e\u53ef\u5b66\u4e60\u795e\u7ecf\u7f16\u7801\u7684\u5fc3\u7535\u56fe\u75be\u75c5\u68c0\u6d4b\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u5fc3\u7535\u56fe\u5206\u7c7b\u3002", "motivation": "\u4f20\u7edf\u8d85\u7ef4\u8ba1\u7b97\u4f9d\u8d56\u9759\u6001\u968f\u673a\u6295\u5f71\uff0c\u7f3a\u4e4f\u4efb\u52a1\u9002\u5e94\u6027\uff0c\u9700\u8bbe\u8ba1\u65b0\u7684\u5fc3\u7535\u56fe\u75be\u75c5\u68c0\u6d4b\u6846\u67b6\u3002", "method": "\u5f15\u5165\u57fa\u4e8eRR\u95f4\u9694\u7684\u53ef\u8bad\u7ec3\u7f16\u7801\u7ba1\u9053\uff0c\u91c7\u7528\u795e\u7ecf\u84b8\u998f\u8d85\u7ef4\u8ba1\u7b97\u67b6\u6784\uff0c\u8054\u5408\u4ea4\u53c9\u71b5\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u5ea6\u91cf\u635f\u5931\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728Apnea - ECG\u548cPTB - XL\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u8d85\u7ef4\u8ba1\u7b97\u548c\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\uff0cApnea - ECG\u4e0a\u7cbe\u5ea6\u8fbe73.09%\uff0cF1\u5206\u65700.626\uff0c\u5728PTB - XL\u4e0a\u6709\u53ef\u6bd4\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8fb9\u7f18\u5fc3\u7535\u56fe\u5206\u7c7b\u63d0\u4f9b\u9ad8\u6548\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u53ef\u89e3\u91ca\u548c\u4e2a\u6027\u5316\u5065\u5eb7\u76d1\u6d4b\u65b9\u9762\u6709\u5f88\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.15158", "pdf": "https://arxiv.org/pdf/2507.15158", "abs": "https://arxiv.org/abs/2507.15158", "authors": ["A. H. Abbas", "Hend Abdel-Ghani", "Ivan S. Maksymov"], "title": "Resonant-Tunnelling Diode Reservoir Computing System for Image Recognition", "categories": ["cs.LG", "physics.app-ph"], "comment": null, "summary": "As artificial intelligence continues to push into real-time, edge-based and\nresource-constrained environments, there is an urgent need for novel,\nhardware-efficient computational models. In this study, we present and validate\na neuromorphic computing architecture based on resonant-tunnelling diodes\n(RTDs), which exhibit the nonlinear characteristics ideal for physical\nreservoir computing (RC). We theoretically formulate and numerically implement\nan RTD-based RC system and demonstrate its effectiveness on two image\nrecognition benchmarks: handwritten digit classification and object recognition\nusing the Fruit~360 dataset. Our results show that this circuit-level\narchitecture delivers promising performance while adhering to the principles of\nnext-generation RC -- eliminating random connectivity in favour of a\ndeterministic nonlinear transformation of input signals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5171\u632f\u96a7\u7a7f\u4e8c\u6781\u7ba1\uff08RTD\uff09\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u67b6\u6784\uff0c\u5e76\u5728\u4e24\u4e2a\u56fe\u50cf\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5411\u5b9e\u65f6\u3001\u8fb9\u7f18\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u53d1\u5c55\uff0c\u9700\u8981\u65b0\u578b\u786c\u4ef6\u9ad8\u6548\u7684\u8ba1\u7b97\u6a21\u578b\u3002", "method": "\u7406\u8bba\u4e0a\u516c\u5f0f\u5316\u5e76\u6570\u503c\u5b9e\u73b0\u57fa\u4e8eRTD\u7684RC\u7cfb\u7edf\uff0c\u5728\u624b\u5199\u6570\u5b57\u5206\u7c7b\u548cFruit~360\u6570\u636e\u96c6\u76ee\u6807\u8bc6\u522b\u4e24\u4e2a\u56fe\u50cf\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u3002", "result": "\u8be5\u7535\u8def\u7ea7\u67b6\u6784\u6027\u80fd\u826f\u597d\uff0c\u9075\u5faa\u4e0b\u4e00\u4ee3RC\u539f\u5219\uff0c\u7528\u786e\u5b9a\u6027\u975e\u7ebf\u6027\u53d8\u6362\u66ff\u4ee3\u968f\u673a\u8fde\u63a5\u3002", "conclusion": "\u57fa\u4e8eRTD\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u67b6\u6784\u662f\u6709\u6548\u7684\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u8bc6\u522b\u4efb\u52a1\u3002"}}
{"id": "2507.14186", "pdf": "https://arxiv.org/pdf/2507.14186", "abs": "https://arxiv.org/abs/2507.14186", "authors": ["Xiaojie Li", "Zhijie Cai", "Nan Qi", "Chao Dong", "Guangxu Zhu", "Haixia Ma", "Qihui Wu", "Shi Jin"], "title": "A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction", "categories": ["cs.NI", "cs.AI", "cs.LG", "eess.SP"], "comment": "This paper has been submitted to IEEE for possible publication", "summary": "The expansion of the low-altitude economy has underscored the significance of\nLow-Altitude Network Coverage (LANC) prediction for designing aerial corridors.\nWhile accurate LANC forecasting hinges on the antenna beam patterns of Base\nStations (BSs), these patterns are typically proprietary and not readily\naccessible. Operational parameters of BSs, which inherently contain beam\ninformation, offer an opportunity for data-driven low-altitude coverage\nprediction. However, collecting extensive low-altitude road test data is\ncost-prohibitive, often yielding only sparse samples per BS. This scarcity\nresults in two primary challenges: imbalanced feature sampling due to limited\nvariability in high-dimensional operational parameters against the backdrop of\nsubstantial changes in low-dimensional sampling locations, and diminished\ngeneralizability stemming from insufficient data samples. To overcome these\nobstacles, we introduce a dual strategy comprising expert knowledge-based\nfeature compression and disentangled representation learning. The former\nreduces feature space complexity by leveraging communications expertise, while\nthe latter enhances model generalizability through the integration of\npropagation models and distinct subnetworks that capture and aggregate the\nsemantic representations of latent features. Experimental evaluation confirms\nthe efficacy of our framework, yielding a 7% reduction in error compared to the\nbest baseline algorithm. Real-network validations further attest to its\nreliability, achieving practical prediction accuracy with MAE errors at the 5dB\nlevel.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u7b56\u7565\u6846\u67b6\u89e3\u51b3\u4f4e\u7a7a\u7f51\u7edc\u8986\u76d6\u9884\u6d4b\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u8bef\u5dee\u964d\u4f4e7%\uff0c\u5b9e\u9645\u7f51\u7edc\u9a8c\u8bc1MAE\u8bef\u5dee\u8fbe5dB\u6c34\u5e73\u3002", "motivation": "\u4f4e\u7a7a\u7ecf\u6d4e\u6269\u5f20\u51f8\u663e\u4f4e\u7a7a\u7f51\u7edc\u8986\u76d6\u9884\u6d4b\u91cd\u8981\u6027\uff0c\u4f46\u57fa\u7ad9\u5929\u7ebf\u6ce2\u675f\u6a21\u5f0f\u96be\u83b7\u53d6\uff0c\u6536\u96c6\u4f4e\u7a7a\u8def\u6d4b\u6570\u636e\u6210\u672c\u9ad8\u3001\u6837\u672c\u7a00\u758f\uff0c\u5b58\u5728\u7279\u5f81\u91c7\u6837\u4e0d\u5e73\u8861\u548c\u6a21\u578b\u6cdb\u5316\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4e13\u5bb6\u77e5\u8bc6\u7684\u7279\u5f81\u538b\u7f29\u548c\u5206\u79bb\u8868\u793a\u5b66\u4e60\u7684\u53cc\u7b56\u7565\uff0c\u524d\u8005\u5229\u7528\u901a\u4fe1\u4e13\u4e1a\u77e5\u8bc6\u964d\u4f4e\u7279\u5f81\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u540e\u8005\u7ed3\u5408\u4f20\u64ad\u6a21\u578b\u548c\u5b50\u7f51\u7edc\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u6bd4\u6700\u4f73\u57fa\u7ebf\u7b97\u6cd5\u8bef\u5dee\u964d\u4f4e7%\uff0c\u5b9e\u9645\u7f51\u7edc\u9a8c\u8bc1\u8fbe\u5230\u5b9e\u7528\u9884\u6d4b\u7cbe\u5ea6\uff0cMAE\u8bef\u5dee\u57285dB\u6c34\u5e73\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53cc\u7b56\u7565\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4f4e\u7a7a\u7f51\u7edc\u8986\u76d6\u9884\u6d4b\u4e2d\u6570\u636e\u7a00\u7f3a\u5e26\u6765\u7684\u95ee\u9898\uff0c\u5177\u6709\u8f83\u597d\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2507.15162", "pdf": "https://arxiv.org/pdf/2507.15162", "abs": "https://arxiv.org/abs/2507.15162", "authors": ["Firdaus Ahmed Choudhury", "Ethan Leicht", "Jude Ethan Bislig", "Hangzhi Guo", "Amulya Yadav"], "title": "Designing User-Centric Metrics for Evaluation of Counterfactual Explanations", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning-based decision models are increasingly being used to make\ndecisions that significantly impact people's lives, but their opaque nature\nleaves end users without a clear understanding of why a decision was made.\nCounterfactual Explanations (CFEs) have grown in popularity as a means of\noffering actionable guidance by identifying the minimum changes in feature\nvalues required to flip a model's prediction to something more desirable.\nUnfortunately, most prior research in CFEs relies on artificial evaluation\nmetrics, such as proximity, which may overlook end-user preferences and\nconstraints, e.g., the user's perception of effort needed to make certain\nfeature changes may differ from that of the model designer. To address this\nresearch gap, this paper makes three novel contributions. First, we conduct a\npilot study with 20 crowd-workers on Amazon MTurk to experimentally validate\nthe alignment of existing CF evaluation metrics with real-world user\npreferences. Results show that user-preferred CFEs matched those based on\nproximity in only 63.81% of cases, highlighting the limited applicability of\nthese metrics in real-world settings. Second, inspired by the need to design a\nuser-informed evaluation metric for CFEs, we conduct a more detailed two-day\nuser study with 41 participants facing realistic credit application scenarios\nto find experimental support for or against three intuitive hypotheses that may\nexplain how end users evaluate CFEs. Third, based on the findings of this\nsecond study, we propose the AWP model, a novel user-centric, two-stage model\nthat describes one possible mechanism by which users evaluate and select CFEs.\nOur results show that AWP predicts user-preferred CFEs with 84.37% accuracy.\nOur study provides the first human-centered validation for personalized cost\nmodels in CFE generation and highlights the need for adaptive, user-centered\nevaluation metrics.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFEs\uff09\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u5ffd\u89c6\u7528\u6237\u504f\u597d\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4e24\u9879\u7528\u6237\u7814\u7a76\uff0c\u63d0\u51fa\u7528\u6237\u4e2d\u5fc3\u7684AWP\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u9884\u6d4b\u7528\u6237\u504f\u597dCFEs\u51c6\u786e\u7387\u8fbe84.37%\uff0c\u5f3a\u8c03\u4e86\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u8bc4\u4f30\u6307\u6807\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u591a\u6570CFEs\u7814\u7a76\u4f9d\u8d56\u4eba\u5de5\u8bc4\u4f30\u6307\u6807\uff0c\u53ef\u80fd\u5ffd\u89c6\u7ec8\u7aef\u7528\u6237\u504f\u597d\u548c\u7ea6\u675f\uff0c\u4e3a\u586b\u8865\u6b64\u7814\u7a76\u7a7a\u767d\u5f00\u5c55\u5de5\u4f5c\u3002", "method": "\u5148\u5bf920\u540d\u4f17\u5305\u5de5\u4eba\u8fdb\u884c\u8bd5\u70b9\u7814\u7a76\u9a8c\u8bc1\u73b0\u6709CF\u8bc4\u4f30\u6307\u6807\u4e0e\u73b0\u5b9e\u7528\u6237\u504f\u597d\u7684\u4e00\u81f4\u6027\uff1b\u518d\u5bf941\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u4e3a\u671f\u4e24\u5929\u7684\u7528\u6237\u7814\u7a76\uff0c\u9a8c\u8bc1\u5173\u4e8e\u7528\u6237\u5982\u4f55\u8bc4\u4f30CFEs\u7684\u4e09\u4e2a\u5047\u8bbe\uff1b\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\u63d0\u51faAWP\u6a21\u578b\u3002", "result": "\u8bd5\u70b9\u7814\u7a76\u663e\u793a\u7528\u6237\u504f\u597d\u7684CFEs\u4e0e\u57fa\u4e8e\u63a5\u8fd1\u6027\u7684CFEs\u4ec5\u572863.81%\u7684\u60c5\u51b5\u4e0b\u5339\u914d\uff1bAWP\u6a21\u578b\u9884\u6d4b\u7528\u6237\u504f\u597dCFEs\u7684\u51c6\u786e\u7387\u4e3a84.37%\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aCFE\u751f\u6210\u4e2d\u7684\u4e2a\u6027\u5316\u6210\u672c\u6a21\u578b\u63d0\u4f9b\u4e86\u9996\u4e2a\u4ee5\u4eba\u7c7b\u4e3a\u4e2d\u5fc3\u7684\u9a8c\u8bc1\uff0c\u5f3a\u8c03\u4e86\u81ea\u9002\u5e94\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u6307\u6807\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.14187", "pdf": "https://arxiv.org/pdf/2507.14187", "abs": "https://arxiv.org/abs/2507.14187", "authors": ["Xiaojuan Zhang", "Tianyu Jiang", "Haoxiang Zong", "Chen Zhang", "Chendan Li", "Marta Molinas"], "title": "AI-Based Impedance Encoding-Decoding Method for Online Impedance Network Construction of Wind Farms", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "The impedance network (IN) model is gaining popularity in the oscillation\nanalysis of wind farms. However, the construction of such an IN model requires\nimpedance curves of each wind turbine under their respective operating\nconditions, making its online application difficult due to the transmission of\nnumerous high-density impedance curves. To address this issue, this paper\nproposes an AI-based impedance encoding-decoding method to facilitate the\nonline construction of IN model. First, an impedance encoder is trained to\ncompress impedance curves by setting the number of neurons much smaller than\nthat of frequency points. Then, the compressed data of each turbine are\nuploaded to the wind farm and an impedance decoder is trained to reconstruct\noriginal impedance curves. At last, based on the nodal admittance matrix (NAM)\nmethod, the IN model of the wind farm can be obtained. The proposed method is\nvalidated via model training and real-time simulations, demonstrating that the\nencoded impedance vectors enable fast transmission and accurate reconstruction\nof the original impedance curves.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eAI\u7684\u963b\u6297\u7f16\u89e3\u7801\u65b9\u6cd5\u4ee5\u89e3\u51b3\u98ce\u7535\u573a\u963b\u6297\u7f51\u7edc\uff08IN\uff09\u6a21\u578b\u5728\u7ebf\u6784\u5efa\u96be\u9898\uff0c\u7ecf\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u53ef\u884c\u3002", "motivation": "\u73b0\u6709IN\u6a21\u578b\u6784\u5efa\u9700\u4f20\u8f93\u5927\u91cf\u9ad8\u5bc6\u5ea6\u963b\u6297\u66f2\u7ebf\uff0c\u96be\u4ee5\u5728\u7ebf\u5e94\u7528\u3002", "method": "\u8bad\u7ec3\u963b\u6297\u7f16\u7801\u5668\u538b\u7f29\u963b\u6297\u66f2\u7ebf\uff0c\u4e0a\u4f20\u538b\u7f29\u6570\u636e\u540e\u8bad\u7ec3\u963b\u6297\u89e3\u7801\u5668\u91cd\u5efa\u66f2\u7ebf\uff0c\u57fa\u4e8e\u8282\u70b9\u5bfc\u7eb3\u77e9\u9635\u6cd5\u83b7\u53d6\u98ce\u7535\u573aIN\u6a21\u578b\u3002", "result": "\u7f16\u7801\u540e\u7684\u963b\u6297\u5411\u91cf\u53ef\u5b9e\u73b0\u539f\u963b\u6297\u66f2\u7ebf\u7684\u5feb\u901f\u4f20\u8f93\u548c\u51c6\u786e\u91cd\u5efa\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eAI\u7684\u963b\u6297\u7f16\u89e3\u7801\u65b9\u6cd5\u80fd\u6709\u6548\u4fc3\u8fdb\u98ce\u7535\u573aIN\u6a21\u578b\u7684\u5728\u7ebf\u6784\u5efa\u3002"}}
{"id": "2507.14188", "pdf": "https://arxiv.org/pdf/2507.14188", "abs": "https://arxiv.org/abs/2507.14188", "authors": ["Sebastian Barros Elgueta"], "title": "From Cell Towers to Satellites: A 2040 Blueprint for Urban-Grade Direct-to-Device Mobile Networks", "categories": ["cs.NI", "cs.AI"], "comment": "50 pages", "summary": "In 2023, satellite and mobile networks crossed a historic threshold: standard\nsmartphones, using unmodified 3GPP protocols, connected directly to low Earth\norbit (LEO) satellites. This first wave of direct-to-device (D2D)\ndemonstrations validated the physical feasibility of satellite-based mobile\naccess. However, these systems remain fallback-grade--rural-only,\nbandwidth-limited, and fully dependent on Earth-based mobile cores for\nidentity, session, and policy control. This paper asks a more ambitious\nquestion: Can a complete mobile network, including radio access, core\nfunctions, traffic routing, and content delivery, operate entirely from orbit?\nAnd can it deliver sustained, urban-grade service in the world's densest\ncities? We present the first end-to-end system architecture for a fully orbital\ntelco, integrating electronically steered phased arrays with 1000-beam\ncapacity, space-based deployment of 5G core functions (UPF, AMF), and\ninter-satellite laser mesh backhaul. We analyze spectral efficiency, beam\ncapacity, and link budgets under dense urban conditions, accounting for path\nloss, Doppler, and multipath. Simulations show that rooftop and line-of-sight\nusers can sustain 64-QAM throughput, while street-level access is feasible with\nrelay or assisted beam modes. The paper outlines the remaining constraints,\npower, thermal dissipation, compute radiation hardening, and regulatory models,\nand demonstrates that these are engineering bottlenecks, not physical limits.\nFinally, we propose a staged 15-year roadmap from today's fallback D2D systems\nto autonomous orbital overlays delivering 50-100 Mbps to handhelds in\nmegacities, with zero reliance on terrestrial infrastructure.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5168\u8f68\u9053\u79fb\u52a8\u7f51\u7edc\u53ef\u884c\u6027\uff0c\u63d0\u51fa\u67b6\u6784\u5e76\u6a21\u62df\uff0c\u6307\u51fa\u74f6\u9888\uff0c\u7ed9\u51fa15\u5e74\u8def\u7ebf\u56fe\u3002", "motivation": "\u73b0\u6709\u536b\u661f\u79fb\u52a8\u63a5\u5165\u7cfb\u7edf\u6709\u5c40\u9650\uff0c\u63a2\u8ba8\u5b8c\u6574\u79fb\u52a8\u7f51\u7edc\u80fd\u5426\u5168\u5728\u8f68\u8fd0\u884c\u5e76\u5728\u5927\u57ce\u5e02\u63d0\u4f9b\u670d\u52a1\u3002", "method": "\u63d0\u51fa\u5168\u8f68\u9053\u7535\u4fe1\u7aef\u5230\u7aef\u7cfb\u7edf\u67b6\u6784\uff0c\u5206\u6790\u5bc6\u96c6\u57ce\u5e02\u6761\u4ef6\u4e0b\u7684\u9891\u8c31\u6548\u7387\u7b49\uff0c\u8fdb\u884c\u6a21\u62df\u3002", "result": "\u6a21\u62df\u663e\u793a\u5c4b\u9876\u548c\u89c6\u8ddd\u7528\u6237\u53ef\u7ef4\u630164 - QAM\u541e\u5410\u91cf\uff0c\u8857\u9053\u7ea7\u63a5\u5165\u5728\u4e2d\u7ee7\u6216\u8f85\u52a9\u6ce2\u675f\u6a21\u5f0f\u4e0b\u53ef\u884c\u3002", "conclusion": "\u5269\u4f59\u7ea6\u675f\u662f\u5de5\u7a0b\u74f6\u9888\u975e\u7269\u7406\u9650\u5236\uff0c\u7ed9\u51fa\u4ece\u73b0\u6709\u7cfb\u7edf\u5230\u81ea\u4e3b\u8f68\u9053\u8986\u76d6\u768415\u5e74\u8def\u7ebf\u56fe\u3002"}}
{"id": "2507.15174", "pdf": "https://arxiv.org/pdf/2507.15174", "abs": "https://arxiv.org/abs/2507.15174", "authors": ["Justin Turnau", "Longchao Da", "Khoa Vo", "Ferdous Al Rafi", "Shreyas Bachiraju", "Tiejin Chen", "Hua Wei"], "title": "Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control", "categories": ["cs.LG"], "comment": "This paper was accepted to RLC/RLJ 2025", "summary": "Traffic Signal Control (TSC) is essential for managing urban traffic flow and\nreducing congestion. Reinforcement Learning (RL) offers an adaptive method for\nTSC by responding to dynamic traffic patterns, with multi-agent RL (MARL)\ngaining traction as intersections naturally function as coordinated agents.\nHowever, due to shifts in environmental dynamics, implementing MARL-based TSC\npolicies in the real world often leads to a significant performance drop, known\nas the sim-to-real gap. Grounded Action Transformation (GAT) has successfully\nmitigated this gap in single-agent RL for TSC, but real-world traffic networks,\nwhich involve numerous interacting intersections, are better suited to a MARL\nframework. In this work, we introduce JL-GAT, an application of GAT to\nMARL-based TSC that balances scalability with enhanced grounding capability by\nincorporating information from neighboring agents. JL-GAT adopts a\ndecentralized approach to GAT, allowing for the scalability often required in\nreal-world traffic networks while still capturing key interactions between\nagents. Comprehensive experiments on various road networks under simulated\nadverse weather conditions, along with ablation studies, demonstrate the\neffectiveness of JL-GAT. The code is publicly available at\nhttps://github.com/DaRL-LibSignal/JL-GAT/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u65b9\u6cd5JL - GAT\uff0c\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7b56\u7565\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u6a21\u62df\u4e0e\u73b0\u5b9e\u7684\u5dee\u8ddd\uff0c\u5355\u667a\u80fd\u4f53\u7684GAT\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u573a\u666f\u3002", "method": "\u63d0\u51faJL - GAT\u65b9\u6cd5\uff0c\u5c06GAT\u5e94\u7528\u4e8e\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\uff0c\u91c7\u7528\u5206\u6563\u5f0fGAT\u65b9\u6cd5\uff0c\u7ed3\u5408\u76f8\u90bb\u667a\u80fd\u4f53\u4fe1\u606f\u3002", "result": "\u5728\u6a21\u62df\u6076\u52a3\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u4e0d\u540c\u9053\u8def\u7f51\u7edc\u4e0a\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\uff0c\u8bc1\u660e\u4e86JL - GAT\u7684\u6709\u6548\u6027\u3002", "conclusion": "JL - GAT\u80fd\u5e73\u8861\u53ef\u6269\u5c55\u6027\u548c\u589e\u5f3a\u7684\u57fa\u7840\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u4ea4\u901a\u7f51\u7edc\u3002"}}
{"id": "2507.14189", "pdf": "https://arxiv.org/pdf/2507.14189", "abs": "https://arxiv.org/abs/2507.14189", "authors": ["Song Mao", "Lejun Cheng", "Pinlong Cai", "Guohang Yan", "Ding Wang", "Botian Shi"], "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "categories": ["cs.CL", "cs.AI"], "comment": "work in process", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious applications. However, their use as writing assistants in specialized\ndomains like finance, medicine, and law is often hampered by a lack of deep\ndomain-specific knowledge and a tendency to hallucinate. Existing solutions,\nsuch as Retrieval-Augmented Generation (RAG), can suffer from inconsistency\nacross multiple retrieval steps, while online search-based methods often\ndegrade quality due to unreliable web content. To address these challenges, we\nintroduce DeepWriter, a customizable, multimodal, long-form writing assistant\nthat operates on a curated, offline knowledge base. DeepWriter leverages a\nnovel pipeline that involves task decomposition, outline generation, multimodal\nretrieval, and section-by-section composition with reflection. By deeply mining\ninformation from a structured corpus and incorporating both textual and visual\nelements, DeepWriter generates coherent, factually grounded, and\nprofessional-grade documents. We also propose a hierarchical knowledge\nrepresentation to enhance retrieval efficiency and accuracy. Our experiments on\nfinancial report generation demonstrate that DeepWriter produces high-quality,\nverifiable articles that surpasses existing baselines in factual accuracy and\ngenerated content quality.", "AI": {"tldr": "\u4ecb\u7ecd\u53ef\u5b9a\u5236\u3001\u591a\u6a21\u6001\u957f\u6587\u5199\u4f5c\u52a9\u624bDeepWriter\uff0c\u5728\u8d22\u52a1\u62a5\u544a\u751f\u6210\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u5199\u4f5c\u7f3a\u4e4f\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u3001\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u4e0d\u4e00\u81f4\u548c\u8d28\u91cf\u4e0b\u964d\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4efb\u52a1\u5206\u89e3\u3001\u5927\u7eb2\u751f\u6210\u3001\u591a\u6a21\u6001\u68c0\u7d22\u3001\u9010\u8282\u64b0\u5199\u4e0e\u53cd\u601d\u7684\u65b0\u6d41\u7a0b\uff0c\u63d0\u51fa\u5206\u5c42\u77e5\u8bc6\u8868\u793a\u6cd5\u3002", "result": "\u5728\u8d22\u52a1\u62a5\u544a\u751f\u6210\u5b9e\u9a8c\u4e2d\uff0cDeepWriter\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u6587\u7ae0\uff0c\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u5185\u5bb9\u8d28\u91cf\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "DeepWriter\u80fd\u751f\u6210\u8fde\u8d2f\u3001\u57fa\u4e8e\u4e8b\u5b9e\u3001\u4e13\u4e1a\u7ea7\u7684\u6587\u6863\uff0c\u6709\u6548\u89e3\u51b3\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u89e3\u51b3\u65b9\u6848\u7684\u95ee\u9898\u3002"}}
{"id": "2507.15195", "pdf": "https://arxiv.org/pdf/2507.15195", "abs": "https://arxiv.org/abs/2507.15195", "authors": ["Anwar Said", "Yifan Wei", "Ubaid Ullah Ahmad", "Mudassir Shabbir", "Waseem Abbas", "Xenofon Koutsoukos"], "title": "Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "In this article, we utilize the concept of average controllability in graphs,\nalong with a novel rank encoding method, to enhance the performance of Graph\nNeural Networks (GNNs) in social network classification tasks. GNNs have proven\nhighly effective in various network-based learning applications and require\nsome form of node features to function. However, their performance is heavily\ninfluenced by the expressiveness of these features. In social networks, node\nfeatures are often unavailable due to privacy constraints or the absence of\ninherent attributes, making it challenging for GNNs to achieve optimal\nperformance. To address this limitation, we propose two strategies for\nconstructing expressive node features. First, we introduce average\ncontrollability along with other centrality metrics (denoted as NCT-EFA) as\nnode-level metrics that capture critical aspects of network topology. Building\non this, we develop a rank encoding method that transforms average\ncontrollability or any other graph-theoretic metric into a fixed-dimensional\nfeature space, thereby improving feature representation. We conduct extensive\nnumerical evaluations using six benchmark GNN models across four social network\ndatasets to compare different node feature construction methods. Our results\ndemonstrate that incorporating average controllability into the feature space\nsignificantly improves GNN performance. Moreover, the proposed rank encoding\nmethod outperforms traditional one-hot degree encoding, improving the ROC AUC\nfrom 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset,\nunderscoring its effectiveness in generating expressive and efficient node\nrepresentations.", "AI": {"tldr": "\u5229\u7528\u56fe\u7684\u5e73\u5747\u53ef\u63a7\u6027\u548c\u65b0\u7684\u6392\u540d\u7f16\u7801\u65b9\u6cd5\u589e\u5f3a\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u6570\u503c\u8bc4\u4f30\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e2d\u6027\u80fd\u53d7\u8282\u70b9\u7279\u5f81\u8868\u8fbe\u80fd\u529b\u5f71\u54cd\uff0c\u4e14\u793e\u4ea4\u7f51\u7edc\u4e2d\u5e38\u7f3a\u4e4f\u8282\u70b9\u7279\u5f81\uff0c\u96be\u4ee5\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u6784\u5efa\u6709\u8868\u73b0\u529b\u8282\u70b9\u7279\u5f81\u7684\u7b56\u7565\uff0c\u4e00\u662f\u5f15\u5165\u5e73\u5747\u53ef\u63a7\u6027\u548c\u5176\u4ed6\u4e2d\u5fc3\u6027\u6307\u6807\u4f5c\u4e3a\u8282\u70b9\u7ea7\u6307\u6807\uff1b\u4e8c\u662f\u5f00\u53d1\u6392\u540d\u7f16\u7801\u65b9\u6cd5\u5c06\u56fe\u8bba\u6307\u6807\u8f6c\u5316\u4e3a\u56fa\u5b9a\u7ef4\u7279\u5f81\u7a7a\u95f4\u3002", "result": "\u5c06\u5e73\u5747\u53ef\u63a7\u6027\u7eb3\u5165\u7279\u5f81\u7a7a\u95f4\u663e\u8457\u63d0\u5347\u56fe\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\uff0c\u6392\u540d\u7f16\u7801\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7684\u72ec\u70ed\u5ea6\u7f16\u7801\uff0c\u5982\u5728GitHub Stargazers\u6570\u636e\u96c6\u4e0a\u4f7f\u7528GraphSAGE\u65f6\u5c06ROC AUC\u4ece68.7%\u63d0\u9ad8\u523073.9%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u6709\u8868\u73b0\u529b\u548c\u9ad8\u6548\u7684\u8282\u70b9\u8868\u793a\uff0c\u53ef\u63d0\u5347\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15205", "pdf": "https://arxiv.org/pdf/2507.15205", "abs": "https://arxiv.org/abs/2507.15205", "authors": ["Xinran Li", "Xiujuan Xu", "Jiaqi Qiao"], "title": "Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by the 28th European Conference on Artificial Intelligence\n  (ECAI 2025)", "summary": "Emotion Recognition in Conversation (ERC) is a practical and challenging\ntask. This paper proposes a novel multimodal approach, the Long-Short Distance\nGraph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it\nconstructs a long-distance graph neural network and a short-distance graph\nneural network to obtain multimodal features of distant and nearby utterances,\nrespectively. To ensure that long- and short-distance features are as distinct\nas possible in representation while enabling mutual influence between the two\nmodules, we employ a Differential Regularizer and incorporate a BiAffine Module\nto facilitate feature interaction. In addition, we propose an Improved\nCurriculum Learning (ICL) to address the challenge of data imbalance. By\ncomputing the similarity between different emotions to emphasize the shifts in\nsimilar emotions, we design a \"weighted emotional shift\" metric and develop a\ndifficulty measurer, enabling a training process that prioritizes learning easy\nsamples before harder ones. Experimental results on the IEMOCAP and MELD\ndatasets demonstrate that our model outperforms existing benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLSDGNN\u591a\u6a21\u6001\u65b9\u6cd5\u53caICL\u5e94\u5bf9\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u60c5\u611f\u8bc6\u522b\u5bf9\u8bdd\uff08ERC\uff09\u662f\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u5f53\u524d\u53ef\u80fd\u7f3a\u4e4f\u6709\u6548\u591a\u6a21\u6001\u65b9\u6cd5\u548c\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u7684\u65b9\u6848\u3002", "method": "\u57fa\u4e8eDAG\u6784\u5efa\u957f\u77ed\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\u83b7\u53d6\u591a\u6a21\u6001\u7279\u5f81\uff0c\u91c7\u7528\u5dee\u5206\u6b63\u5219\u5316\u5668\u548c\u53cc\u4eff\u5c04\u6a21\u5757\u4fc3\u8fdb\u7279\u5f81\u4ea4\u4e92\uff1b\u63d0\u51fa\u6539\u8fdb\u8bfe\u7a0b\u5b66\u4e60\uff08ICL\uff09\uff0c\u8ba1\u7b97\u60c5\u611f\u76f8\u4f3c\u5ea6\u8bbe\u8ba1\u5ea6\u91cf\u548c\u96be\u5ea6\u8861\u91cf\u5668\u3002", "result": "\u5728IEMOCAP\u548cMELD\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u63d0\u51fa\u7684LSDGNN\u548cICL\u6709\u6548\uff0c\u80fd\u63d0\u5347ERC\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2507.14195", "pdf": "https://arxiv.org/pdf/2507.14195", "abs": "https://arxiv.org/abs/2507.14195", "authors": ["Elzbieta Gruzewska", "Pooja Rao", "Sebastien Baur", "Matthew Baugh", "Mathias M. J. Bellaiche", "Sharanya Srinivas", "Octavio Ponce", "Matthew Thompson", "Pramod Rudrapatna", "Michael A. Sanchez", "Lawrence Z. Cai", "Timothy JA Chico", "Robert F. Storey", "Emily Maz", "Umesh Telang", "Shravya Shetty", "Mayank Daswani"], "title": "UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "31 pages, 11 tables, 9 figures, 14 supplementary tables, 4\n  supplementary figures", "summary": "Radar technology presents untapped potential for continuous, contactless, and\npassive heart rate monitoring via consumer electronics like mobile phones.\nHowever the variety of available radar systems and lack of standardization\nmeans that a large new paired dataset collection is required for each radar\nsystem. This study demonstrates transfer learning between frequency-modulated\ncontinuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems,\nboth increasingly integrated into consumer devices. FMCW radar utilizes a\ncontinuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW\nradar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3\nreceiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz\nbandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we\nachieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage\nerror (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119\nparticipants, an average of 8 hours per participant). This model maintained\nperformance (under 5 MAE/10% MAPE) across various body positions and heart rate\nranges, with a 98.9% recall. We then fine-tuned a variant of this model,\ntrained on single-antenna and single-range bin FMCW data, using a small (N=376,\navg 6 minutes per participant) IR-UWB dataset. This transfer learning approach\nyielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE\nreduction over the IR-UWB baseline. This demonstration of transfer learning\nbetween radar systems for heart rate monitoring has the potential to accelerate\nits introduction into existing consumer devices.", "AI": {"tldr": "\u7814\u7a76\u5c55\u793a\u4e86\u8c03\u9891\u8fde\u7eed\u6ce2\uff08FMCW\uff09\u548c\u8109\u51b2\u65e0\u7ebf\u7535\u8d85\u5bbd\u5e26\uff08IR - UWB\uff09\u96f7\u8fbe\u7cfb\u7edf\u95f4\u7684\u8fc1\u79fb\u5b66\u4e60\u7528\u4e8e\u5fc3\u7387\u76d1\u6d4b\uff0c\u53ef\u52a0\u901f\u5176\u5728\u6d88\u8d39\u8bbe\u5907\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u96f7\u8fbe\u6280\u672f\u7528\u4e8e\u5fc3\u7387\u76d1\u6d4b\u6709\u6f5c\u529b\uff0c\u4f46\u4e0d\u540c\u96f7\u8fbe\u7cfb\u7edf\u9700\u5927\u91cf\u65b0\u914d\u5bf9\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u3002", "method": "\u4f7f\u7528\u65b0\u578b2D + 1D ResNet\u67b6\u6784\u5bf9FMCW\u96f7\u8fbe\u8fdb\u884c\u5fc3\u7387\u76d1\u6d4b\uff0c\u518d\u7528\u5c0f\u7684IR - UWB\u6570\u636e\u96c6\u5fae\u8c03\u6a21\u578b\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u3002", "result": "FMCW\u96f7\u8fbe\u5fc3\u7387\u76d1\u6d4bMAE\u4e3a0.85 bpm\uff0cMAPE\u4e3a1.42%\uff0c\u53ec\u56de\u738798.9%\uff1b\u8fc1\u79fb\u5b66\u4e60\u540eIR - UWB\u6a21\u578bMAE 4.1 bpm\uff0cMAPE 6.3%\uff0c\u53ec\u56de\u738797.5%\uff0cMAE\u8f83\u57fa\u7ebf\u964d\u4f4e25%\u3002", "conclusion": "\u96f7\u8fbe\u7cfb\u7edf\u95f4\u7684\u8fc1\u79fb\u5b66\u4e60\u7528\u4e8e\u5fc3\u7387\u76d1\u6d4b\u6709\u6f5c\u529b\u52a0\u901f\u5176\u5f15\u5165\u73b0\u6709\u6d88\u8d39\u8bbe\u5907\u3002"}}
{"id": "2507.14196", "pdf": "https://arxiv.org/pdf/2507.14196", "abs": "https://arxiv.org/abs/2507.14196", "authors": ["Zahra Teimouri-Jervekani", "Fahimeh Nasimi", "Mohammadreza Yazdchi", "Ghazal MogharehZadeh", "Javad Tezerji", "Farzan Niknejad Mazandarani", "Maryam Mohebbi"], "title": "Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Background and Objective: Differentiating wide complex tachycardia (WCT) is\nclinically critical yet challenging due to morphological similarities in\nelectrocardiogram (ECG) signals between life-threatening ventricular\ntachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A).\nMisdiagnosis carries fatal risks. We propose a computationally efficient deep\nlearning solution to improve diagnostic accuracy and provide model\ninterpretability for clinical deployment.\n  Methods: A novel lightweight parallel deep architecture is introduced. Each\npipeline processes individual ECG leads using two 1D-CNN blocks to extract\nlocal features. Feature maps are concatenated across leads, followed by LSTM\nlayers to capture temporal dependencies. Final classification employs fully\nconnected layers. Explainability is achieved via Shapley Additive Explanations\n(SHAP) for local/global interpretation. The model was evaluated on a 35-subject\nECG database using standard performance metrics.\n  Results: The model achieved $95.63\\%$ accuracy ($95\\%$ CI: $93.07-98.19\\%$),\nwith sensitivity=$95.10\\%$, specificity=$96.06\\%$, and F1-score=$95.12\\%$. It\noutperformed state-of-the-art methods in both accuracy and computational\nefficiency, requiring minimal CNN blocks per pipeline. SHAP analysis\ndemonstrated clinically interpretable feature contributions.\n  Conclusions: Our end-to-end framework delivers high-precision WCT\nclassification with minimal computational overhead. The integration of SHAP\nenhances clinical trust by elucidating decision logic, supporting rapid,\ninformed diagnosis. This approach shows significant promise for real-world ECG\nanalysis tools.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u5e76\u884c\u6df1\u5ea6\u67b6\u6784\u7528\u4e8e\u5bbdQRS\u6ce2\u5fc3\u52a8\u8fc7\u901f\u5206\u7c7b\uff0c\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u3001\u8ba1\u7b97\u9ad8\u6548\u4e14\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u533a\u5206\u5bbdQRS\u6ce2\u5fc3\u52a8\u8fc7\u901f\u4e34\u5e8a\u5173\u952e\u4f46\u56e0\u5fc3\u7535\u56fe\u4fe1\u53f7\u5f62\u6001\u76f8\u4f3c\u800c\u5177\u6311\u6218\u6027\uff0c\u8bef\u8bca\u6709\u81f4\u547d\u98ce\u9669\uff0c\u9700\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u5e76\u63d0\u4f9b\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f15\u5165\u8f7b\u91cf\u7ea7\u5e76\u884c\u6df1\u5ea6\u67b6\u6784\uff0c\u75281D - CNN\u5757\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\uff0cLSTM\u5c42\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\uff0c\u5168\u8fde\u63a5\u5c42\u5206\u7c7b\uff0c\u7528SHAP\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u572835\u4e2a\u53d7\u8bd5\u8005\u7684\u5fc3\u7535\u56fe\u6570\u636e\u5e93\u4e0a\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u51c6\u786e\u738795.63%\uff0c\u654f\u611f\u602795.10%\uff0c\u7279\u5f02\u602796.06%\uff0cF1\u5206\u657095.12%\uff0c\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0cSHAP\u5206\u6790\u663e\u793a\u7279\u5f81\u8d21\u732e\u6709\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u7aef\u5230\u7aef\u6846\u67b6\u9ad8\u7cbe\u5ea6\u5206\u7c7b\u5bbdQRS\u6ce2\u5fc3\u52a8\u8fc7\u901f\u4e14\u8ba1\u7b97\u5f00\u9500\u5c0f\uff0cSHAP\u589e\u5f3a\u4e34\u5e8a\u4fe1\u4efb\uff0c\u8be5\u65b9\u6cd5\u5bf9\u73b0\u5b9e\u5fc3\u7535\u56fe\u5206\u6790\u5de5\u5177\u5f88\u6709\u524d\u666f\u3002"}}
{"id": "2507.15246", "pdf": "https://arxiv.org/pdf/2507.15246", "abs": "https://arxiv.org/abs/2507.15246", "authors": ["Rabia Latief Bhat", "Iqra Altaf Gillani"], "title": "Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate demand forecasting is critical for enhancing the efficiency and\nresponsiveness of food delivery platforms, where spatial heterogeneity and\ntemporal fluctuations in order volumes directly influence operational\ndecisions. This paper proposes an attention-based Graph Neural Network\nframework that captures spatial-temporal dependencies by modeling the food\ndelivery environment as a graph. In this graph, nodes represent urban delivery\nzones, while edges reflect spatial proximity and inter-regional order flow\npatterns derived from historical data. The attention mechanism dynamically\nweighs the influence of neighboring zones, enabling the model to focus on the\nmost contextually relevant areas during prediction. Temporal trends are jointly\nlearned alongside spatial interactions, allowing the model to adapt to evolving\ndemand patterns. Extensive experiments on real-world food delivery datasets\ndemonstrate the superiority of the proposed model in forecasting future order\nvolumes with high accuracy. The framework offers a scalable and adaptive\nsolution to support proactive fleet positioning, resource allocation, and\ndispatch optimization in urban food delivery operations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u7528\u4e8e\u98df\u54c1\u914d\u9001\u8ba2\u5355\u91cf\u9884\u6d4b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u9ad8\u7cbe\u5ea6\u4e14\u53ef\u652f\u6301\u914d\u9001\u8fd0\u8425\u4f18\u5316\u3002", "motivation": "\u51c6\u786e\u7684\u9700\u6c42\u9884\u6d4b\u5bf9\u63d0\u5347\u98df\u54c1\u914d\u9001\u5e73\u53f0\u6548\u7387\u548c\u54cd\u5e94\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u8ba2\u5355\u91cf\u7684\u65f6\u7a7a\u7279\u6027\u5f71\u54cd\u8fd0\u8425\u51b3\u7b56\u3002", "method": "\u5c06\u98df\u54c1\u914d\u9001\u73af\u5883\u5efa\u6a21\u4e3a\u56fe\uff0c\u8282\u70b9\u4ee3\u8868\u914d\u9001\u533a\u57df\uff0c\u8fb9\u53cd\u6620\u7a7a\u95f4\u90bb\u8fd1\u548c\u8ba2\u5355\u6d41\u6a21\u5f0f\uff0c\u7528\u6ce8\u610f\u529b\u673a\u5236\u52a8\u6001\u6743\u8861\u90bb\u57df\u5f71\u54cd\uff0c\u8054\u5408\u5b66\u4e60\u65f6\u7a7a\u8d8b\u52bf\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u80fd\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u672a\u6765\u8ba2\u5355\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u57ce\u5e02\u98df\u54c1\u914d\u9001\u8fd0\u8425\u4e2d\u7684\u8f66\u961f\u5b9a\u4f4d\u3001\u8d44\u6e90\u5206\u914d\u548c\u8c03\u5ea6\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14198", "pdf": "https://arxiv.org/pdf/2507.14198", "abs": "https://arxiv.org/abs/2507.14198", "authors": ["Fufang Wen", "Shichang Zhang"], "title": "Retention analysis of edited knowledge after fine-tuning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) store vast amounts of knowledge, which often\nrequires updates to correct factual errors, incorporate newly acquired\ninformation, or adapt model behavior. Model editing methods have emerged as\nefficient solutions for such updates, offering localized and precise knowledge\nmodification at significantly lower computational cost than continual training.\nIn parallel, LLMs are frequently fine-tuned for a wide range of downstream\ntasks. However, the effect of fine-tuning on previously edited knowledge\nremains poorly understood. In this work, we systematically investigate how\ndifferent fine-tuning objectives interact with various model editing\ntechniques. Our findings show that edited knowledge is substantially more\nsusceptible to forgetting during fine-tuning than intrinsic knowledge acquired\nthrough pre-training. This analysis highlights a key limitation of current\nediting approaches and suggests that evaluating edit robustness under\ndownstream fine-tuning is critical for their practical deployment. We further\nfind that freezing layers associated with edited content can significantly\nimprove knowledge retention, offering insight into how future editing methods\nmight be made more robust.", "AI": {"tldr": "\u7814\u7a76\u5fae\u8c03\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u8f91\u77e5\u8bc6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7f16\u8f91\u77e5\u8bc6\u5728\u5fae\u8c03\u4e2d\u66f4\u6613\u9057\u5fd8\uff0c\u51bb\u7ed3\u76f8\u5173\u5c42\u53ef\u63d0\u5347\u77e5\u8bc6\u4fdd\u7559\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9700\u66f4\u65b0\u77e5\u8bc6\uff0c\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u53ef\u9ad8\u6548\u66f4\u65b0\uff0c\u4f46\u5fae\u8c03\u5bf9\u7f16\u8f91\u77e5\u8bc6\u7684\u5f71\u54cd\u4e0d\u660e\uff0c\u9700\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u5fae\u8c03\u76ee\u6807\u4e0e\u5404\u79cd\u6a21\u578b\u7f16\u8f91\u6280\u672f\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u7f16\u8f91\u77e5\u8bc6\u5728\u5fae\u8c03\u65f6\u6bd4\u9884\u8bad\u7ec3\u83b7\u5f97\u7684\u56fa\u6709\u77e5\u8bc6\u66f4\u6613\u9057\u5fd8\uff1b\u51bb\u7ed3\u4e0e\u7f16\u8f91\u5185\u5bb9\u76f8\u5173\u7684\u5c42\u53ef\u663e\u8457\u63d0\u9ad8\u77e5\u8bc6\u4fdd\u7559\u3002", "conclusion": "\u5f53\u524d\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u5173\u952e\u5c40\u9650\uff0c\u8bc4\u4f30\u4e0b\u6e38\u5fae\u8c03\u4e0b\u7684\u7f16\u8f91\u9c81\u68d2\u6027\u5bf9\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u672a\u6765\u7f16\u8f91\u65b9\u6cd5\u66f4\u5177\u9c81\u68d2\u6027\u63d0\u4f9b\u601d\u8def\u3002"}}
{"id": "2507.15260", "pdf": "https://arxiv.org/pdf/2507.15260", "abs": "https://arxiv.org/abs/2507.15260", "authors": ["Jiaqi Han", "Haotian Ye", "Puheng Li", "Minkai Xu", "James Zou", "Stefano Ermon"], "title": "CHORDS: Diffusion Sampling Accelerator with Multi-core Hierarchical ODE Solvers", "categories": ["cs.LG"], "comment": "ICCV 2025", "summary": "Diffusion-based generative models have become dominant generators of\nhigh-fidelity images and videos but remain limited by their computationally\nexpensive inference procedures. Existing acceleration techniques either require\nextensive model retraining or compromise significantly on sample quality. This\npaper explores a general, training-free, and model-agnostic acceleration\nstrategy via multi-core parallelism. Our framework views multi-core diffusion\nsampling as an ODE solver pipeline, where slower yet accurate solvers\nprogressively rectify faster solvers through a theoretically justified\ninter-core communication mechanism. This motivates our multi-core training-free\ndiffusion sampling accelerator, CHORDS, which is compatible with various\ndiffusion samplers, model architectures, and modalities. Through extensive\nexperiments, CHORDS significantly accelerates sampling across diverse\nlarge-scale image and video diffusion models, yielding up to 2.1x speedup with\nfour cores, improving by 50% over baselines, and 2.9x speedup with eight cores,\nall without quality degradation. This advancement enables CHORDS to establish a\nsolid foundation for real-time, high-fidelity diffusion generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bad\u7ec3\u65e0\u5173\u3001\u6a21\u578b\u65e0\u5173\u7684\u591a\u6838\u5fc3\u5e76\u884c\u52a0\u901f\u7b56\u7565CHORDS\uff0c\u52a0\u901f\u6269\u6563\u6a21\u578b\u91c7\u6837\u4e14\u4e0d\u964d\u4f4e\u8d28\u91cf\uff0c\u4e3a\u5b9e\u65f6\u9ad8\u4fdd\u771f\u6269\u6563\u751f\u6210\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u63a8\u7406\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u52a0\u901f\u6280\u672f\u9700\u5927\u91cf\u6a21\u578b\u518d\u8bad\u7ec3\u6216\u727a\u7272\u6837\u672c\u8d28\u91cf\uff0c\u56e0\u6b64\u63a2\u7d22\u65b0\u52a0\u901f\u7b56\u7565\u3002", "method": "\u5c06\u591a\u6838\u5fc3\u6269\u6563\u91c7\u6837\u89c6\u4e3aODE\u6c42\u89e3\u5668\u7ba1\u9053\uff0c\u901a\u8fc7\u7406\u8bba\u652f\u6301\u7684\u6838\u5fc3\u95f4\u901a\u4fe1\u673a\u5236\uff0c\u7528\u6162\u800c\u51c6\u7684\u6c42\u89e3\u5668\u9010\u6b65\u4fee\u6b63\u5feb\u6c42\u89e3\u5668\uff0c\u63d0\u51faCHORDS\u3002", "result": "CHORDS\u663e\u8457\u52a0\u901f\u4e0d\u540c\u5927\u89c4\u6a21\u56fe\u50cf\u548c\u89c6\u9891\u6269\u6563\u6a21\u578b\u7684\u91c7\u6837\uff0c\u56db\u6838\u6700\u9ad8\u8fbe2.1\u500d\u52a0\u901f\uff0c\u6bd4\u57fa\u7ebf\u63d0\u9ad850%\uff0c\u516b\u6838\u8fbe2.9\u500d\u52a0\u901f\uff0c\u4e14\u4e0d\u964d\u4f4e\u8d28\u91cf\u3002", "conclusion": "CHORDS\u4e3a\u5b9e\u65f6\u3001\u9ad8\u4fdd\u771f\u6269\u6563\u751f\u6210\u5efa\u7acb\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2507.14200", "pdf": "https://arxiv.org/pdf/2507.14200", "abs": "https://arxiv.org/abs/2507.14200", "authors": ["Shengji Tang", "Jianjian Cao", "Weihao Lin", "Jiale Hong", "Bo Zhang", "Shuyue Hu", "Lei Bai", "Tao Chen", "Wanli Ouyang", "Peng Ye"], "title": "Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper aims to demonstrate the potential and strengths of open-source\ncollectives. It leads to a promising question: Can we harness multiple\nopen-source LLMs to match or even beat the closed-source LLMs? To answer this,\nwe propose SMACS, a scalable multi-agent collaboration system (MACS) framework\nwith high performance. Specifically, for continuous integration of new LLMs and\ngeneralization to diverse questions, we first propose a Retrieval-based Prior\nSelection (RPS), which assigns a proxy performance score to each LLM to select\nthe Top-k LLMs at the instance level for any given question. Then, we propose\nan Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the\ngeneration of diverse responses through prior dropping and selecting the\nhigh-quality response via a hybrid posterior score. Experiments on eight\nmainstream benchmarks validate the effectiveness of our SMACS: by integrating\nfifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025,\ne.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%)\nacross multiple tasks. Remarkably, it even exceeds the average of best results\nof different datasets from both open-source LLMs (+2.86%) and closed-source\nLLMs (+2.04%), pushing the upper bound of intelligence. Code will be released\nat https://github.com/magent4aci/SMACS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSMACS\u6846\u67b6\uff0c\u6574\u5408\u5f00\u6e90\u5927\u6a21\u578b\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u95ed\u6e90\u5927\u6a21\u578b\uff0c\u63a8\u52a8\u667a\u80fd\u4e0a\u9650\u3002", "motivation": "\u63a2\u7d22\u5f00\u6e90\u96c6\u4f53\u7684\u6f5c\u529b\uff0c\u7814\u7a76\u80fd\u5426\u5229\u7528\u591a\u4e2a\u5f00\u6e90\u5927\u6a21\u578b\u5339\u654c\u751a\u81f3\u8d85\u8d8a\u95ed\u6e90\u5927\u6a21\u578b\u3002", "method": "\u63d0\u51faSMACS\u6846\u67b6\uff0c\u5305\u62ec\u57fa\u4e8e\u68c0\u7d22\u7684\u5148\u9a8c\u9009\u62e9\uff08RPS\uff09\u548c\u63a2\u7d22-\u5229\u7528\u9a71\u52a8\u7684\u540e\u9a8c\u589e\u5f3a\uff08EPE\uff09\u3002", "result": "\u5728\u516b\u4e2a\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6574\u5408\u5341\u4e94\u4e2a\u5f00\u6e90\u5927\u6a21\u578b\u7684SMACS\u57282025\u5e74\u8d85\u8d8aClaude - 3.7 - Sonnet\u3001GPT - 4.1\u7b49\u95ed\u6e90\u5927\u6a21\u578b\u3002", "conclusion": "SMACS\u6846\u67b6\u6709\u6548\uff0c\u8bc1\u660e\u4e86\u5229\u7528\u5f00\u6e90\u5927\u6a21\u578b\u8d85\u8d8a\u95ed\u6e90\u5927\u6a21\u578b\u7684\u53ef\u80fd\u6027\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002"}}
{"id": "2507.15274", "pdf": "https://arxiv.org/pdf/2507.15274", "abs": "https://arxiv.org/abs/2507.15274", "authors": ["Matthew J. Bryan", "Felix Schwock", "Azadeh Yazdan-Shahmorad", "Rajesh P N Rao"], "title": "Temporal Basis Function Models for Closed-Loop Neural Stimulation", "categories": ["cs.LG"], "comment": null, "summary": "Closed-loop neural stimulation provides novel therapies for neurological\ndiseases such as Parkinson's disease (PD), but it is not yet clear whether\nartificial intelligence (AI) techniques can tailor closed-loop stimulation to\nindividual patients or identify new therapies. Progress requires us to address\na number of translational issues, including sample efficiency, training time,\nand minimizing loop latency such that stimulation may be shaped in response to\nchanging brain activity. We propose temporal basis function models (TBFMs) to\naddress these difficulties, and explore this approach in the context of\nexcitatory optogenetic stimulation. We demonstrate the ability of TBF models to\nprovide a single-trial, spatiotemporal forward prediction of the effect of\noptogenetic stimulation on local field potentials (LFPs) measured in two\nnon-human primates. We further use simulations to demonstrate the use of TBF\nmodels for closed-loop stimulation, driving neural activity towards target\npatterns. The simplicity of TBF models allow them to be sample efficient, rapid\nto train (2-4min), and low latency (0.2ms) on desktop CPUs. We demonstrate the\nmodel on 40 sessions of previously published excitatory optogenetic stimulation\ndata. For each session, the model required 15-20min of data collection to\nsuccessfully model the remainder of the session. It achieved a prediction\naccuracy comparable to a baseline nonlinear dynamical systems model that\nrequires hours to train, and superior accuracy to a linear state-space model.\nIn our simulations, it also successfully allowed a closed-loop stimulator to\ncontrol a neural circuit. Our approach begins to bridge the translational gap\nbetween complex AI-based approaches to modeling dynamical systems and the\nvision of using such forward prediction models to develop novel, clinically\nuseful closed-loop stimulation protocols.", "AI": {"tldr": "\u63d0\u51fa\u65f6\u95f4\u57fa\u51fd\u6570\u6a21\u578b\uff08TBFMs\uff09\u89e3\u51b3\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u7684\u8f6c\u5316\u95ee\u9898\uff0c\u8be5\u6a21\u578b\u6837\u672c\u6548\u7387\u9ad8\u3001\u8bad\u7ec3\u5feb\u3001\u5ef6\u8fdf\u4f4e\uff0c\u80fd\u5b9e\u73b0\u5bf9\u795e\u7ecf\u6d3b\u52a8\u7684\u9884\u6d4b\u548c\u63a7\u5236\uff0c\u7f29\u5c0f\u4e86\u590d\u6742AI\u5efa\u6a21\u4e0e\u4e34\u5e8a\u5e94\u7528\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u4e0d\u6e05\u695a\u4eba\u5de5\u667a\u80fd\u6280\u672f\u80fd\u5426\u4e3a\u4e2a\u4f53\u60a3\u8005\u5b9a\u5236\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u6216\u786e\u5b9a\u65b0\u7597\u6cd5\uff0c\u9700\u89e3\u51b3\u6837\u672c\u6548\u7387\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u73af\u8def\u5ef6\u8fdf\u7b49\u8f6c\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faTBFMs\u6a21\u578b\uff0c\u5e76\u5728\u5174\u594b\u6027\u5149\u9057\u4f20\u523a\u6fc0\u80cc\u666f\u4e0b\u8fdb\u884c\u63a2\u7d22\uff0c\u7528\u6a21\u62df\u9a8c\u8bc1\u5176\u7528\u4e8e\u95ed\u73af\u523a\u6fc0\u7684\u80fd\u529b\u3002", "result": "TBF\u6a21\u578b\u80fd\u5bf9\u5149\u9057\u4f20\u523a\u6fc0\u5bf9\u5c40\u90e8\u573a\u7535\u4f4d\u7684\u5f71\u54cd\u8fdb\u884c\u5355\u8bd5\u9a8c\u65f6\u7a7a\u9884\u6d4b\uff0c\u6a21\u62df\u4e2d\u53ef\u63a7\u5236\u795e\u7ecf\u56de\u8def\uff0c\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u9700\u6570\u5c0f\u65f6\u8bad\u7ec3\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u6a21\u578b\u76f8\u5f53\uff0c\u4f18\u4e8e\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5f00\u59cb\u7f29\u5c0f\u57fa\u4e8e\u590d\u6742AI\u7684\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u65b9\u6cd5\u4e0e\u5f00\u53d1\u4e34\u5e8a\u6709\u7528\u7684\u95ed\u73af\u523a\u6fc0\u534f\u8bae\u613f\u666f\u4e4b\u95f4\u7684\u8f6c\u5316\u5dee\u8ddd\u3002"}}
{"id": "2507.14201", "pdf": "https://arxiv.org/pdf/2507.14201", "abs": "https://arxiv.org/abs/2507.14201", "authors": ["Yiran Wu", "Mauricio Velazco", "Andrew Zhao", "Manuel Ra\u00fal Mel\u00e9ndez Luj\u00e1n", "Srisuma Movva", "Yogesh K Roy", "Quang Nguyen", "Roberto Rodriguez", "Qingyun Wu", "Michael Albada", "Julia Kiseleva", "Anand Mudgerikar"], "title": "ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on\nthe task of Cyber Threat Investigation through security questions derived from\ninvestigation graphs. Real-world security analysts must sift through a large\nnumber of heterogeneous alert signals and security logs, follow multi-hop\nchains of evidence, and compile an incident report. With the developments of\nLLMs, building LLM-based agents for automatic thread investigation is a\npromising direction. To assist the development and evaluation of LLM agents, we\nconstruct a dataset from a controlled Azure tenant that covers 8 simulated\nreal-world multi-step attacks, 57 log tables from Microsoft Sentinel and\nrelated services, and 589 automatically generated questions. We leverage\nsecurity logs extracted with expert-crafted detection logic to build threat\ninvestigation graphs, and then generate questions with LLMs using paired nodes\non the graph, taking the start node as background context and the end node as\nanswer. Anchoring each question to these explicit nodes and edges not only\nprovides automatic, explainable ground truth answers but also makes the\npipeline reusable and readily extensible to new logs. This also enables the\nautomatic generation of procedural tasks with verifiable rewards, which can be\nnaturally extended to training agents via reinforcement learning. Our\ncomprehensive experiments with different models confirm the difficulty of the\ntask: with the base setting, the average reward across all evaluated models is\n0.249, and the best achieved is 0.368, leaving substantial headroom for future\nresearch. Code and data are coming soon!", "AI": {"tldr": "\u63d0\u51faExCyTIn - Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7f51\u7edc\u5a01\u80c1\u8c03\u67e5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u4efb\u52a1\u6709\u5f88\u5927\u7814\u7a76\u7a7a\u95f4\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u5b89\u5168\u5206\u6790\u5e08\u5904\u7406\u7f51\u7edc\u5a01\u80c1\u8c03\u67e5\u4efb\u52a1\u7e41\u7410\uff0c\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\uff0c\u6784\u5efa\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5a01\u80c1\u8c03\u67e5\u4ee3\u7406\u662f\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u9700\u8981\u5f00\u53d1\u548c\u8bc4\u4f30\u6b64\u7c7b\u4ee3\u7406\u3002", "method": "\u4ece\u53d7\u63a7Azure\u79df\u6237\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5229\u7528\u5b89\u5168\u65e5\u5fd7\u6784\u5efa\u5a01\u80c1\u8c03\u67e5\u56fe\uff0c\u7528\u56fe\u4e0a\u7684\u6210\u5bf9\u8282\u70b9\u751f\u6210\u95ee\u9898\uff0c\u4ee5\u8d77\u59cb\u8282\u70b9\u4e3a\u80cc\u666f\u3001\u7ed3\u675f\u8282\u70b9\u4e3a\u7b54\u6848\uff0c\u8fd8\u53ef\u751f\u6210\u6709\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u7a0b\u5e8f\u4efb\u52a1\u3002", "result": "\u4e0d\u540c\u6a21\u578b\u5b9e\u9a8c\u663e\u793a\u4efb\u52a1\u96be\u5ea6\u5927\uff0c\u57fa\u7840\u8bbe\u7f6e\u4e0b\u6240\u6709\u8bc4\u4f30\u6a21\u578b\u5e73\u5747\u5956\u52b10.249\uff0c\u6700\u4f73\u4e3a0.368\u3002", "conclusion": "\u7f51\u7edc\u5a01\u80c1\u8c03\u67e5\u4efb\u52a1\u6709\u5f88\u5927\u7814\u7a76\u7a7a\u95f4\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5373\u5c06\u516c\u5e03\u3002"}}
{"id": "2507.15280", "pdf": "https://arxiv.org/pdf/2507.15280", "abs": "https://arxiv.org/abs/2507.15280", "authors": ["Shaofei Shen", "Chenhao Zhang", "Yawen Zhao", "Alina Bialkowski", "Weitong Chen", "Miao Xu"], "title": "Machine Unlearning for Streaming Forgetting", "categories": ["cs.LG"], "comment": null, "summary": "Machine unlearning aims to remove knowledge of the specific training data in\na well-trained model. Currently, machine unlearning methods typically handle\nall forgetting data in a single batch, removing the corresponding knowledge all\nat once upon request. However, in practical scenarios, requests for data\nremoval often arise in a streaming manner rather than in a single batch,\nleading to reduced efficiency and effectiveness in existing methods. Such\nchallenges of streaming forgetting have not been the focus of much research. In\nthis paper, to address the challenges of performance maintenance, efficiency,\nand data access brought about by streaming unlearning requests, we introduce a\nstreaming unlearning paradigm, formalizing the unlearning as a distribution\nshift problem. We then estimate the altered distribution and propose a novel\nstreaming unlearning algorithm to achieve efficient streaming forgetting\nwithout requiring access to the original training data. Theoretical analyses\nconfirm an $O(\\sqrt{T} + V_T)$ error bound on the streaming unlearning regret,\nwhere $V_T$ represents the cumulative total variation in the optimal solution\nover $T$ learning rounds. This theoretical guarantee is achieved under mild\nconditions without the strong restriction of convex loss function. Experiments\nacross various models and datasets validate the performance of our proposed\nmethod.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14202", "pdf": "https://arxiv.org/pdf/2507.14202", "abs": "https://arxiv.org/abs/2507.14202", "authors": ["Pengfei Du"], "title": "PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse applications, yet they pose significant security risks that threaten\ntheir safe deployment in critical domains. Current security alignment\nmethodologies predominantly rely on Process Reward Models (PRMs) to evaluate\nintermediate reasoning steps, introducing substantial computational overhead\nand scalability constraints. This paper presents a novel PRM-free security\nalignment framework that leverages automated red teaming and adversarial\ntraining to achieve robust security guarantees while maintaining computational\nefficiency. Our approach systematically identifies vulnerabilities through\nsophisticated attack strategies including genetic algorithm optimization,\nmulti-agent simulation, and advanced prompt mutation techniques. The framework\nenhances model robustness via targeted adversarial training with curriculum\nlearning and adaptive regularization mechanisms. Comprehensive experimental\nevaluation across five state-of-the-art LLMs demonstrates that our method\nachieves superior security alignment performance compared to PRM-based\napproaches while reducing computational costs by 61\\%. The framework\nincorporates transparent reporting and continuous audit mechanisms that enable\niterative security improvement and regulatory compliance. Our contributions\nadvance the field of efficient LLM security alignment by democratizing access\nto robust security measures for resource-constrained organizations and\nproviding a scalable foundation for addressing evolving adversarial threats.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65e0PRM\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u5229\u7528\u81ea\u52a8\u5316\u7ea2\u961f\u548c\u5bf9\u6297\u8bad\u7ec3\u4fdd\u969c\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8ePRM\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u6709\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u53ef\u6269\u5c55\u6027\u53d7\u9650\u95ee\u9898\uff0c\u9700\u65b0\u65b9\u6cd5\u4fdd\u969c\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u65e0PRM\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u7528\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u3001\u591a\u667a\u80fd\u4f53\u6a21\u62df\u7b49\u653b\u51fb\u7b56\u7565\u8bc6\u522b\u6f0f\u6d1e\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u6b63\u5219\u5316\u673a\u5236\u8fdb\u884c\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u5728\u4e94\u4e2a\u6700\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0c\u6bd4\u57fa\u4e8ePRM\u65b9\u6cd5\u5b89\u5168\u5bf9\u9f50\u6027\u80fd\u66f4\u4f18\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e61%\u3002", "conclusion": "\u8be5\u6846\u67b6\u63a8\u52a8\u9ad8\u6548\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u9886\u57df\u53d1\u5c55\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7ec4\u7ec7\u63d0\u4f9b\u5f3a\u5927\u5b89\u5168\u63aa\u65bd\uff0c\u53ef\u5e94\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u5bf9\u6297\u5a01\u80c1\u3002"}}
{"id": "2507.15287", "pdf": "https://arxiv.org/pdf/2507.15287", "abs": "https://arxiv.org/abs/2507.15287", "authors": ["Elias Malomgr\u00e9", "Pieter Simoens"], "title": "Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 8 figures, accepted for the non-archival workshop \"Workshop\n  on Reinforcement Learning Beyond Rewards @ Reinforcement Learning Conference\n  2025\"", "summary": "Recent trends in Reinforcement Learning (RL) highlight the need for agents to\nlearn from reward-free interactions and alternative supervision signals, such\nas unlabeled or incomplete demonstrations, rather than relying solely on\nexplicit reward maximization. Additionally, developing generalist agents that\ncan adapt efficiently in real-world environments often requires leveraging\nthese reward-free signals to guide learning and behavior. However, while\nintrinsic motivation techniques provide a means for agents to seek out novel or\nuncertain states in the absence of explicit rewards, they are often challenged\nby dense reward environments or the complexity of high-dimensional state and\naction spaces. Furthermore, most existing approaches rely directly on the\nunprocessed intrinsic reward signals, which can make it difficult to shape or\ncontrol the agent's exploration effectively. We propose a framework that can\neffectively utilize expert demonstrations, even when they are incomplete and\nimperfect. By applying a mapping function to transform the similarity between\nan agent's state and expert data into a shaped intrinsic reward, our method\nallows for flexible and targeted exploration of expert-like behaviors. We\nemploy a Mixture of Autoencoder Experts to capture a diverse range of behaviors\nand accommodate missing information in demonstrations. Experiments show our\napproach enables robust exploration and strong performance in both sparse and\ndense reward environments, even when demonstrations are sparse or incomplete.\nThis provides a practical framework for RL in realistic settings where optimal\ndata is unavailable and precise reward control is needed.", "AI": {"tldr": "\u63d0\u51fa\u6846\u67b6\u5229\u7528\u4e13\u5bb6\u6f14\u793a\uff0c\u5c06\u72b6\u6001\u4e0e\u4e13\u5bb6\u6570\u636e\u76f8\u4f3c\u5ea6\u8f6c\u6362\u4e3a\u5185\u5728\u5956\u52b1\uff0c\u5728\u4e0d\u540c\u5956\u52b1\u73af\u5883\u8868\u73b0\u597d\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u9700\u4ece\u65e0\u5956\u52b1\u4ea4\u4e92\u548c\u66ff\u4ee3\u76d1\u7763\u4fe1\u53f7\u5b66\u4e60\uff0c\u73b0\u6709\u5185\u5728\u52a8\u673a\u6280\u672f\u6709\u5c40\u9650\uff0c\u96be\u6709\u6548\u63a7\u5236\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u6846\u67b6\uff0c\u7528\u6620\u5c04\u51fd\u6570\u5c06\u72b6\u6001\u4e0e\u4e13\u5bb6\u6570\u636e\u76f8\u4f3c\u5ea6\u8f6c\u6362\u4e3a\u5185\u5728\u5956\u52b1\uff0c\u7528\u6df7\u5408\u81ea\u52a8\u7f16\u7801\u5668\u4e13\u5bb6\u6355\u6349\u591a\u6837\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5728\u7a00\u758f\u548c\u5bc6\u96c6\u5956\u52b1\u73af\u5883\uff0c\u6f14\u793a\u7a00\u758f\u6216\u4e0d\u5b8c\u6574\u65f6\uff0c\u80fd\u5b9e\u73b0\u7a33\u5065\u63a2\u7d22\u548c\u826f\u597d\u8868\u73b0\u3002", "conclusion": "\u4e3a\u6700\u4f18\u6570\u636e\u4e0d\u53ef\u7528\u3001\u9700\u7cbe\u786e\u5956\u52b1\u63a7\u5236\u7684\u73b0\u5b9e\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2507.15288", "pdf": "https://arxiv.org/pdf/2507.15288", "abs": "https://arxiv.org/abs/2507.15288", "authors": ["Omid G. Sani", "Maryam M. Shanechi"], "title": "Preferential subspace identification (PSID) with forward-backward smoothing", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 5 figures", "summary": "System identification methods for multivariate time-series, such as neural\nand behavioral recordings, have been used to build models for predicting one\nfrom the other. For example, Preferential Subspace Identification (PSID) builds\na state-space model of a primary time-series (e.g., neural activity) to\noptimally predict a secondary time-series (e.g., behavior). However, PSID\nfocuses on optimal prediction using past primary data, even though in offline\napplications, better estimation can be achieved by incorporating concurrent\ndata (filtering) or all available data (smoothing). Here, we extend PSID to\nenable optimal filtering and smoothing. First, we show that the presence of a\nsecondary signal makes it possible to uniquely identify a model with an optimal\nKalman update step (to enable filtering) from a family of otherwise equivalent\nstate-space models. Our filtering solution augments PSID with a reduced-rank\nregression step that directly learns the optimal gain required for the update\nstep from data. We refer to this extension of PSID as PSID with filtering.\nSecond, inspired by two-filter Kalman smoother formulations, we develop a novel\nforward-backward PSID smoothing algorithm where we first apply PSID with\nfiltering and then apply it again in the reverse time direction on the\nresiduals of the filtered secondary signal. We validate our methods on\nsimulated data, showing that our approach recovers the ground-truth model\nparameters for filtering, and achieves optimal filtering and smoothing decoding\nperformance of the secondary signal that matches the ideal performance of the\ntrue underlying model. This work provides a principled framework for optimal\nlinear filtering and smoothing in the two-signal setting, significantly\nexpanding the toolkit for analyzing dynamic interactions in multivariate\ntime-series.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86PSID\u65b9\u6cd5\uff0c\u4f7f\u5176\u652f\u6301\u6700\u4f18\u6ee4\u6ce2\u548c\u5e73\u6ed1\uff0c\u5728\u6a21\u62df\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u4e3a\u53cc\u4fe1\u53f7\u573a\u666f\u63d0\u4f9b\u7ebf\u6027\u6ee4\u6ce2\u548c\u5e73\u6ed1\u6846\u67b6\u3002", "motivation": "\u73b0\u6709PSID\u65b9\u6cd5\u4e13\u6ce8\u4e8e\u7528\u8fc7\u53bb\u4e3b\u8981\u6570\u636e\u8fdb\u884c\u6700\u4f18\u9884\u6d4b\uff0c\u5728\u79bb\u7ebf\u5e94\u7528\u4e2d\u7ed3\u5408\u5e76\u53d1\u6570\u636e\u6216\u6240\u6709\u53ef\u7528\u6570\u636e\u80fd\u5b9e\u73b0\u66f4\u597d\u4f30\u8ba1\uff0c\u56e0\u6b64\u9700\u6269\u5c55PSID\u3002", "method": "\u9996\u5148\uff0c\u5728PSID\u57fa\u7840\u4e0a\u589e\u52a0\u964d\u79e9\u56de\u5f52\u6b65\u9aa4\u5b9e\u73b0\u6ee4\u6ce2\uff1b\u5176\u6b21\uff0c\u53d7\u53cc\u6ee4\u6ce2\u5668\u5361\u5c14\u66fc\u5e73\u6ed1\u516c\u5f0f\u542f\u53d1\uff0c\u5f00\u53d1\u524d\u5411\u540e\u5411PSID\u5e73\u6ed1\u7b97\u6cd5\u3002", "result": "\u5728\u6a21\u62df\u6570\u636e\u4e0a\uff0c\u65b9\u6cd5\u80fd\u6062\u590d\u6ee4\u6ce2\u7684\u771f\u5b9e\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u73b0\u4e0e\u771f\u5b9e\u5e95\u5c42\u6a21\u578b\u7406\u60f3\u6027\u80fd\u5339\u914d\u7684\u6700\u4f18\u6ee4\u6ce2\u548c\u5e73\u6ed1\u89e3\u7801\u6027\u80fd\u3002", "conclusion": "\u4e3a\u53cc\u4fe1\u53f7\u573a\u666f\u63d0\u4f9b\u4e86\u6700\u4f18\u7ebf\u6027\u6ee4\u6ce2\u548c\u5e73\u6ed1\u7684\u539f\u5219\u6027\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u52a8\u6001\u4ea4\u4e92\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2507.15290", "pdf": "https://arxiv.org/pdf/2507.15290", "abs": "https://arxiv.org/abs/2507.15290", "authors": ["Emile Anand", "Sarah Liaw"], "title": "Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown", "categories": ["cs.LG", "I.2.6; I.2.0"], "comment": "39 pages, 2 figures, 36 tables", "summary": "Thompson Sampling (TS) is widely used to address the exploration/exploitation\ntradeoff in contextual bandits, yet recent theory shows that it does not\nexplore aggressively enough in high-dimensional problems. Feel-Good Thompson\nSampling (FG-TS) addresses this by adding an optimism bonus that biases toward\nhigh-reward models, and it achieves the asymptotically minimax-optimal regret\nin the linear setting when posteriors are exact. However, its performance with\n\\emph{approximate} posteriors -- common in large-scale or neural problems --\nhas not been benchmarked. We provide the first systematic study of FG-TS and\nits smoothed variant (SFG-TS) across eleven real-world and synthetic\nbenchmarks. To evaluate their robustness, we compare performance across\nsettings with exact posteriors (linear and logistic bandits) to approximate\nregimes produced by fast but coarse stochastic-gradient samplers. Ablations\nover preconditioning, bonus scale, and prior strength reveal a trade-off:\nlarger bonuses help when posterior samples are accurate, but hurt when sampling\nnoise dominates. FG-TS generally outperforms vanilla TS in linear and logistic\nbandits, but tends to be weaker in neural bandits. Nevertheless, because FG-TS\nand its variants are competitive and easy-to-use, we recommend them as\nbaselines in modern contextual-bandit benchmarks. Finally, we provide source\ncode for all our experiments in\nhttps://github.com/SarahLiaw/ctx-bandits-mcmc-showdown.", "AI": {"tldr": "\u5bf9Feel - Good Thompson Sampling (FG - TS)\u53ca\u5176\u5e73\u6ed1\u53d8\u4f53SFG - TS\u572811\u4e2a\u771f\u5b9e\u548c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u5206\u6790\u5176\u5728\u7cbe\u786e\u548c\u8fd1\u4f3c\u540e\u9a8c\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\u5e76\u7ed9\u51fa\u63a8\u8350\u3002", "motivation": "FG - TS\u5728\u7cbe\u786e\u540e\u9a8c\u7684\u7ebf\u6027\u8bbe\u7f6e\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8fd1\u4f3c\u540e\u9a8c\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u672a\u88ab\u8bc4\u4f30\uff0c\u9700\u8981\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u572811\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5bf9\u6bd4FG - TS\u548cSFG - TS\u5728\u7cbe\u786e\u548c\u8fd1\u4f3c\u540e\u9a8c\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\uff0c\u5bf9\u9884\u6761\u4ef6\u3001\u5956\u52b1\u89c4\u6a21\u548c\u5148\u9a8c\u5f3a\u5ea6\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\u3002", "result": "\u8f83\u5927\u5956\u52b1\u5728\u51c6\u786e\u540e\u9a8c\u6837\u672c\u65f6\u6709\u7528\uff0c\u91c7\u6837\u566a\u58f0\u5360\u4e3b\u5bfc\u65f6\u6709\u5bb3\uff1bFG - TS\u5728\u7ebf\u6027\u548c\u903b\u8f91\u5e26\u95ee\u9898\u4e2d\u901a\u5e38\u4f18\u4e8e\u666e\u901aTS\uff0c\u5728\u795e\u7ecf\u5e26\u95ee\u9898\u4e2d\u8f83\u5f31\u3002", "conclusion": "FG - TS\u53ca\u5176\u53d8\u4f53\u6709\u7ade\u4e89\u529b\u4e14\u6613\u7528\uff0c\u63a8\u8350\u4f5c\u4e3a\u73b0\u4ee3\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u57fa\u51c6\u6d4b\u8bd5\u7684\u57fa\u7ebf\u3002"}}
{"id": "2507.14207", "pdf": "https://arxiv.org/pdf/2507.14207", "abs": "https://arxiv.org/abs/2507.14207", "authors": ["Richard M. Charles", "James H. Curry", "Richard B. Charles"], "title": "Mitigating Trojanized Prompt Chains in Educational LLM Use Cases: Experimental Findings and Detection Tool Design", "categories": ["cs.CR", "cs.AI", "I.2.1; I.2.7"], "comment": "12 pages, 1 figure", "summary": "The integration of Large Language Models (LLMs) in K--12 education offers\nboth transformative opportunities and emerging risks. This study explores how\nstudents may Trojanize prompts to elicit unsafe or unintended outputs from\nLLMs, bypassing established content moderation systems with safety guardrils.\nThrough a systematic experiment involving simulated K--12 queries and\nmulti-turn dialogues, we expose key vulnerabilities in GPT-3.5 and GPT-4. This\npaper presents our experimental design, detailed findings, and a prototype\ntool, TrojanPromptGuard (TPG), to automatically detect and mitigate Trojanized\neducational prompts. These insights aim to inform both AI safety researchers\nand educational technologists on the safe deployment of LLMs for educators.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22K - 12\u6559\u80b2\u4e2d\u5b66\u751f\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6728\u9a6c\u5316\u63d0\u793a\u653b\u51fb\uff0c\u63ed\u793aGPT - 3.5\u548cGPT - 4\u6f0f\u6d1e\uff0c\u63d0\u51fa\u68c0\u6d4b\u548c\u7f13\u89e3\u5de5\u5177\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728K - 12\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u6709\u673a\u4f1a\u4e5f\u6709\u98ce\u9669\uff0c\u7814\u7a76\u5b66\u751f\u5982\u4f55\u7ed5\u8fc7\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u8fdb\u884c\u6728\u9a6c\u5316\u63d0\u793a\u653b\u51fb\u3002", "method": "\u901a\u8fc7\u6d89\u53ca\u6a21\u62dfK - 12\u67e5\u8be2\u548c\u591a\u8f6e\u5bf9\u8bdd\u7684\u7cfb\u7edf\u5b9e\u9a8c\u3002", "result": "\u63ed\u793a\u4e86GPT - 3.5\u548cGPT - 4\u7684\u5173\u952e\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u539f\u578b\u5de5\u5177TrojanPromptGuard (TPG)\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aAI\u5b89\u5168\u7814\u7a76\u4eba\u5458\u548c\u6559\u80b2\u6280\u672f\u4e13\u5bb6\u5728\u6559\u80b2\u4e2d\u5b89\u5168\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2507.15303", "pdf": "https://arxiv.org/pdf/2507.15303", "abs": "https://arxiv.org/abs/2507.15303", "authors": ["Liang Zhang", "Kong Chen", "Yuen Wu"], "title": "Universal crystal material property prediction via multi-view geometric fusion in graph transformers", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": null, "summary": "Accurately and comprehensively representing crystal structures is critical\nfor advancing machine learning in large-scale crystal materials simulations,\nhowever, effectively capturing and leveraging the intricate geometric and\ntopological characteristics of crystal structures remains a core, long-standing\nchallenge for most existing methods in crystal property prediction. Here, we\npropose MGT, a multi-view graph transformer framework that synergistically\nfuses SE3 invariant and SO3 equivariant graph representations, which\nrespectively captures rotation-translation invariance and rotation equivariance\nin crystal geometries. To strategically incorporate these complementary\ngeometric representations, we employ a lightweight mixture of experts router in\nMGT to adaptively adjust the weight assigned to SE3 and SO3 embeddings based on\nthe specific target task. Compared with previous state-of-the-art models, MGT\nreduces the mean absolute error by up to 21% on crystal property prediction\ntasks through multi-task self-supervised pretraining. Ablation experiments and\ninterpretable investigations confirm the effectiveness of each technique\nimplemented in our framework. Additionally, in transfer learning scenarios\nincluding crystal catalyst adsorption energy and hybrid perovskite bandgap\nprediction, MGT achieves performance improvements of up to 58% over existing\nbaselines, demonstrating domain-agnostic scalability across diverse application\ndomains. As evidenced by the above series of studies, we believe that MGT can\nserve as useful model for crystal material property prediction, providing a\nvaluable tool for the discovery of novel materials.", "AI": {"tldr": "\u63d0\u51fa\u591a\u89c6\u56fe\u56fe\u53d8\u6362\u5668\u6846\u67b6MGT\u7528\u4e8e\u6676\u4f53\u6750\u6599\u6027\u8d28\u9884\u6d4b\uff0c\u7ed3\u5408SE3\u548cSO3\u8868\u793a\uff0c\u5728\u591a\u4efb\u52a1\u9884\u8bad\u7ec3\u548c\u8fc1\u79fb\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u6676\u4f53\u6027\u8d28\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u548c\u5229\u7528\u6676\u4f53\u7ed3\u6784\u7684\u590d\u6742\u51e0\u4f55\u4e0e\u62d3\u6251\u7279\u5f81\u3002", "method": "\u63d0\u51faMGT\u6846\u67b6\uff0c\u878d\u5408SE3\u4e0d\u53d8\u548cSO3\u7b49\u53d8\u56fe\u8868\u793a\uff0c\u7528\u8f7b\u91cf\u7ea7\u4e13\u5bb6\u6df7\u5408\u8def\u7531\u5668\u81ea\u9002\u5e94\u8c03\u6574\u6743\u91cd\uff0c\u8fdb\u884c\u591a\u4efb\u52a1\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u3002", "result": "\u5728\u6676\u4f53\u6027\u8d28\u9884\u6d4b\u4efb\u52a1\u4e0aMAE\u6700\u591a\u964d\u4f4e21%\uff0c\u5728\u8fc1\u79fb\u5b66\u4e60\u573a\u666f\u4e2d\u6027\u80fd\u6700\u591a\u63d0\u534758%\u3002", "conclusion": "MGT\u53ef\u4f5c\u4e3a\u6676\u4f53\u6750\u6599\u6027\u8d28\u9884\u6d4b\u7684\u6709\u7528\u6a21\u578b\uff0c\u4e3a\u65b0\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u5de5\u5177\u3002"}}
{"id": "2507.14211", "pdf": "https://arxiv.org/pdf/2507.14211", "abs": "https://arxiv.org/abs/2507.14211", "authors": ["Federico Mason", "Tommaso Zugno", "Matteo Drago", "Marco Giordani", "Mate Boban", "Michele Zorzi"], "title": "PRATA: A Framework to Enable Predictive QoS in Vehicular Networks via Artificial Intelligence", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "Predictive Quality of Service (PQoS) makes it possible to anticipate QoS\nchanges, e.g., in wireless networks, and trigger appropriate countermeasures to\navoid performance degradation. Hence, PQoS is extremely useful for automotive\napplications such as teleoperated driving, which poses strict constraints in\nterms of latency and reliability. A promising tool for PQoS is given by\nReinforcement Learning (RL), a methodology that enables the design of\ndecision-making strategies for stochastic optimization. In this manuscript, we\npresent PRATA, a new simulation framework to enable PRedictive QoS based on AI\nfor Teleoperated driving Applications. PRATA consists of a modular pipeline\nthat includes (i) an end-to-end protocol stack to simulate the 5G Radio Access\nNetwork (RAN), (ii) a tool for generating automotive data, and (iii) an\nArtificial Intelligence (AI) unit to optimize PQoS decisions. To prove its\nutility, we use PRATA to design an RL unit, named RAN-AI, to optimize the\nsegmentation level of teleoperated driving data in the event of resource\nsaturation or channel degradation. Hence, we show that the RAN-AI entity\nefficiently balances the trade-off between QoS and Quality of Experience (QoE)\nthat characterize teleoperated driving applications, almost doubling the system\nperformance compared to baseline approaches. In addition, by varying the\nlearning settings of the RAN-AI entity, we investigate the impact of the state\nspace and the relative cost of acquiring network data that are necessary for\nthe implementation of RL.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u6a21\u62df\u6846\u67b6PRATA\u7528\u4e8e\u8fdc\u7a0b\u9a7e\u9a76\u5e94\u7528\u7684\u9884\u6d4b\u6027QoS\uff0c\u8bbe\u8ba1RAN - AI\u4f18\u5316\u6570\u636e\u5206\u5272\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u5e76\u7814\u7a76RL\u5b9e\u73b0\u76f8\u5173\u56e0\u7d20\u5f71\u54cd\u3002", "motivation": "\u9884\u6d4b\u6027QoS\u5bf9\u6c7d\u8f66\u5e94\u7528\u5982\u8fdc\u7a0b\u9a7e\u9a76\u5f88\u6709\u7528\uff0c\u5f3a\u5316\u5b66\u4e60\u662f\u5b9e\u73b0PQoS\u7684\u6709\u524d\u666f\u5de5\u5177\uff0c\u9700\u65b0\u6846\u67b6\u652f\u6301\u3002", "method": "\u63d0\u51faPRATA\u6a21\u62df\u6846\u67b6\uff0c\u5305\u542b\u6a21\u62df5G RAN\u7684\u534f\u8bae\u6808\u3001\u751f\u6210\u6c7d\u8f66\u6570\u636e\u5de5\u5177\u548c\u4f18\u5316PQoS\u51b3\u7b56\u7684AI\u5355\u5143\uff1b\u7528PRATA\u8bbe\u8ba1RAN - AI\u4f18\u5316\u6570\u636e\u5206\u5272\u3002", "result": "RAN - AI\u6709\u6548\u5e73\u8861QoS\u548cQoE\uff0c\u7cfb\u7edf\u6027\u80fd\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u8fd1\u4e4e\u7ffb\u500d\uff1b\u7814\u7a76\u4e86\u72b6\u6001\u7a7a\u95f4\u548c\u83b7\u53d6\u7f51\u7edc\u6570\u636e\u6210\u672c\u5bf9RL\u5b9e\u73b0\u7684\u5f71\u54cd\u3002", "conclusion": "PRATA\u6846\u67b6\u548cRAN - AI\u80fd\u6709\u6548\u63d0\u5347\u8fdc\u7a0b\u9a7e\u9a76\u5e94\u7528\u6027\u80fd\uff0c\u540c\u65f6\u660e\u786e\u4e86RL\u5b9e\u73b0\u4e2d\u76f8\u5173\u56e0\u7d20\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.14218", "pdf": "https://arxiv.org/pdf/2507.14218", "abs": "https://arxiv.org/abs/2507.14218", "authors": ["Craig S Wright"], "title": "Cognitive Castes: Artificial Intelligence, Epistemic Stratification, and the Dissolution of Democratic Discourse", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.LO", "68T01, 03B70, 91F10, 68P20, 68T30", "I.2.0; K.4.1; I.2.6; J.4"], "comment": "42 Pages; Approx. 10,000 words, no figures. Theoretical contribution\n  with interdisciplinary scope", "summary": "Artificial intelligence functions not as an epistemic leveller, but as an\naccelerant of cognitive stratification, entrenching and formalising\ninformational castes within liberal-democratic societies. Synthesising formal\nepistemology, political theory, algorithmic architecture, and economic\nincentive structures, the argument traces how contemporary AI systems\nselectively amplify the reasoning capacity of individuals equipped with\nrecursive abstraction, symbolic logic, and adversarial interrogation, whilst\nsimultaneously pacifying the cognitively untrained through engagement-optimised\ninterfaces. Fluency replaces rigour, immediacy displaces reflection, and\nprocedural reasoning is eclipsed by reactive suggestion. The result is a\ntechnocratic realignment of power: no longer grounded in material capital\nalone, but in the capacity to navigate, deconstruct, and manipulate systems of\nepistemic production. Information ceases to be a commons; it becomes the\nsubstrate through which consent is manufactured and autonomy subdued.\nDeliberative democracy collapses not through censorship, but through the\nerosion of interpretive agency. The proposed response is not technocratic\nregulation, nor universal access, but the reconstruction of rational autonomy\nas a civic mandate, codified in education, protected by epistemic rights, and\nstructurally embedded within open cognitive infrastructure.", "AI": {"tldr": "\u4eba\u5de5\u667a\u80fd\u52a0\u5267\u8ba4\u77e5\u5206\u5c42\uff0c\u5bfc\u81f4\u6743\u529b\u6280\u672f\u5b98\u50da\u5316\uff0c\u4fe1\u606f\u4e0d\u518d\u662f\u516c\u5171\u8d44\u6e90\uff0c\u5e94\u91cd\u5efa\u7406\u6027\u81ea\u4e3b\u6027\u3002", "motivation": "\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5728\u81ea\u7531\u6c11\u4e3b\u793e\u4f1a\u4e2d\u7684\u5f71\u54cd\u548c\u95ee\u9898\uff0c\u5982\u8ba4\u77e5\u5206\u5c42\u3001\u6743\u529b\u7ed3\u6784\u53d8\u5316\u7b49\u3002", "method": "\u7efc\u5408\u5f62\u5f0f\u8ba4\u8bc6\u8bba\u3001\u653f\u6cbb\u7406\u8bba\u3001\u7b97\u6cd5\u67b6\u6784\u548c\u7ecf\u6d4e\u6fc0\u52b1\u7ed3\u6784\u8fdb\u884c\u5206\u6790\u3002", "result": "\u4eba\u5de5\u667a\u80fd\u52a0\u5267\u8ba4\u77e5\u5206\u5c42\uff0c\u9020\u6210\u6743\u529b\u6280\u672f\u5b98\u50da\u5316\uff0c\u4fe1\u606f\u88ab\u7528\u4e8e\u5236\u9020\u540c\u610f\u548c\u538b\u5236\u81ea\u4e3b\u6027\uff0c\u5ba1\u8bae\u6c11\u4e3b\u56e0\u89e3\u91ca\u80fd\u529b\u7684\u4fb5\u8680\u800c\u5d29\u6e83\u3002", "conclusion": "\u4e0d\u5e94\u91c7\u7528\u6280\u672f\u5b98\u50da\u76d1\u7ba1\u6216\u666e\u904d\u63a5\u5165\u7684\u65b9\u5f0f\uff0c\u800c\u5e94\u5c06\u91cd\u5efa\u7406\u6027\u81ea\u4e3b\u6027\u4f5c\u4e3a\u516c\u6c11\u4f7f\u547d\uff0c\u901a\u8fc7\u6559\u80b2\u3001\u8ba4\u77e5\u6743\u5229\u4fdd\u62a4\u548c\u5f00\u653e\u8ba4\u77e5\u57fa\u7840\u8bbe\u65bd\u5efa\u8bbe\u6765\u5b9e\u73b0\u3002"}}
{"id": "2507.15381", "pdf": "https://arxiv.org/pdf/2507.15381", "abs": "https://arxiv.org/abs/2507.15381", "authors": ["Julia Machnio", "Mads Nielsen", "Mostafa Mehdipour Ghazi"], "title": "To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICCV 2025", "summary": "Active learning (AL) seeks to reduce annotation costs by selecting the most\ninformative samples for labeling, making it particularly valuable in\nresource-constrained settings. However, traditional evaluation methods, which\nfocus solely on final accuracy, fail to capture the full dynamics of the\nlearning process. To address this gap, we propose PALM (Performance Analysis of\nActive Learning Models), a unified and interpretable mathematical model that\ncharacterizes AL trajectories through four key parameters: achievable accuracy,\ncoverage efficiency, early-stage performance, and scalability. PALM provides a\npredictive description of AL behavior from partial observations, enabling the\nestimation of future performance and facilitating principled comparisons across\ndifferent strategies. We validate PALM through extensive experiments on\nCIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and\nself-supervised embeddings. Our results demonstrate that PALM generalizes\neffectively across datasets, budgets, and strategies, accurately predicting\nfull learning curves from limited labeled data. Importantly, PALM reveals\ncrucial insights into learning efficiency, data space coverage, and the\nscalability of AL methods. By enabling the selection of cost-effective\nstrategies and predicting performance under tight budget constraints, PALM lays\nthe basis for more systematic, reproducible, and data-efficient evaluation of\nAL in both research and real-world applications. The code is available at:\nhttps://github.com/juliamachnio/PALM.", "AI": {"tldr": "\u63d0\u51faPALM\u6a21\u578b\u8bc4\u4f30\u4e3b\u52a8\u5b66\u4e60\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u80fd\u8de8\u6570\u636e\u96c6\u7b49\u6709\u6548\u6cdb\u5316\uff0c\u4e3a\u4e3b\u52a8\u5b66\u4e60\u8bc4\u4f30\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u4f20\u7edf\u4e3b\u52a8\u5b66\u4e60\u8bc4\u4f30\u65b9\u6cd5\u53ea\u5173\u6ce8\u6700\u7ec8\u51c6\u786e\u7387\uff0c\u65e0\u6cd5\u6355\u6349\u5b66\u4e60\u8fc7\u7a0b\u52a8\u6001\uff0c\u9700\u65b0\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPALM\u6a21\u578b\uff0c\u901a\u8fc7\u56db\u4e2a\u5173\u952e\u53c2\u6570\u523b\u753b\u4e3b\u52a8\u5b66\u4e60\u8f68\u8ff9\uff0c\u53ef\u4ece\u90e8\u5206\u89c2\u5bdf\u9884\u6d4b\u672a\u6765\u8868\u73b0\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cPALM\u80fd\u6709\u6548\u6cdb\u5316\uff0c\u4ece\u6709\u9650\u6807\u6ce8\u6570\u636e\u51c6\u786e\u9884\u6d4b\u5b8c\u6574\u5b66\u4e60\u66f2\u7ebf\u3002", "conclusion": "PALM\u4e3a\u4e3b\u52a8\u5b66\u4e60\u5728\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u63d0\u4f9b\u66f4\u7cfb\u7edf\u3001\u53ef\u590d\u73b0\u548c\u6570\u636e\u9ad8\u6548\u7684\u8bc4\u4f30\u57fa\u7840\u3002"}}
{"id": "2507.14223", "pdf": "https://arxiv.org/pdf/2507.14223", "abs": "https://arxiv.org/abs/2507.14223", "authors": ["Wen-Cheng Chung", "Shu-Ting Huang", "Hao-Ting Pai"], "title": "Multi-Granular Discretization for Interpretable Generalization in Precise Cyberattack Identification", "categories": ["cs.CR", "cs.AI"], "comment": "ACM CCS 2025 (Submitted)", "summary": "Explainable intrusion detection systems (IDS) are now recognized as essential\nfor mission-critical networks, yet most \"XAI\" pipelines still bolt an\napproximate explainer onto an opaque classifier, leaving analysts with partial\nand sometimes misleading insights. The Interpretable Generalization (IG)\nmechanism, published in IEEE Transactions on Information Forensics and\nSecurity, eliminates that bottleneck by learning coherent patterns - feature\ncombinations unique to benign or malicious traffic - and turning them into\nfully auditable rules. IG already delivers outstanding precision, recall, and\nAUC on NSL-KDD, UNSW-NB15, and UKM-IDS20, even when trained on only 10% of the\ndata. To raise precision further without sacrificing transparency, we introduce\nMulti-Granular Discretization (IG-MD), which represents every continuous\nfeature at several Gaussian-based resolutions. On UKM-IDS20, IG-MD lifts\nprecision by greater than or equal to 4 percentage points across all nine\ntrain-test splits while preserving recall approximately equal to 1.0,\ndemonstrating that a single interpretation-ready model can scale across domains\nwithout bespoke tuning.", "AI": {"tldr": "\u63d0\u51faIG-MD\u63d0\u5347\u53ef\u89e3\u91ca\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7cbe\u5ea6\uff0c\u5728UKM - IDS20\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709XAI\u7ba1\u9053\u5728\u4e0d\u900f\u660e\u5206\u7c7b\u5668\u4e0a\u6dfb\u52a0\u89e3\u91ca\u5668\uff0c\u63d0\u4f9b\u90e8\u5206\u4e14\u53ef\u80fd\u8bef\u5bfc\u7684\u89c1\u89e3\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u63d0\u5347\u7cbe\u5ea6\u4e0e\u900f\u660e\u5ea6\u3002", "method": "\u5f15\u5165Multi - Granular Discretization (IG - MD)\uff0c\u4ee5\u591a\u79cd\u57fa\u4e8e\u9ad8\u65af\u7684\u5206\u8fa8\u7387\u8868\u793a\u8fde\u7eed\u7279\u5f81\u3002", "result": "\u5728UKM - IDS20\u7684\u4e5d\u4e2a\u8bad\u7ec3 - \u6d4b\u8bd5\u5206\u5272\u4e2d\uff0c\u7cbe\u5ea6\u63d0\u5347\u81f3\u5c114\u4e2a\u767e\u5206\u70b9\uff0c\u53ec\u56de\u7387\u7ea6\u4e3a1.0\u3002", "conclusion": "\u5355\u4e00\u53ef\u89e3\u91ca\u6a21\u578b\u53ef\u8de8\u9886\u57df\u6269\u5c55\uff0c\u65e0\u9700\u5b9a\u5236\u8c03\u6574\u3002"}}
{"id": "2507.15386", "pdf": "https://arxiv.org/pdf/2507.15386", "abs": "https://arxiv.org/abs/2507.15386", "authors": ["Juntao Wang", "Feng Yin", "Tian Ding", "Tsung-Hui Chang", "Zhi-Quan Luo", "Qi Yan"], "title": "Learning to Gridize: Segment Physical World by Wireless Communication Channel", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Gridization, the process of partitioning space into grids where users share\nsimilar channel characteristics, serves as a fundamental prerequisite for\nefficient large-scale network optimization. However, existing methods like\nGeographical or Beam Space Gridization (GSG or BSG) are limited by reliance on\nunavailable location data or the flawed assumption that similar signal\nstrengths imply similar channel properties. We propose Channel Space\nGridization (CSG), a pioneering framework that unifies channel estimation and\ngridization for the first time. Formulated as a joint optimization problem, CSG\nuses only beam-level reference signal received power (RSRP) to estimate Channel\nAngle Power Spectra (CAPS) and partition samples into grids with homogeneous\nchannel characteristics. To perform CSG, we develop the CSG Autoencoder\n(CSG-AE), featuring a trainable RSRP-to-CAPS encoder, a learnable sparse\ncodebook quantizer, and a physics-informed decoder based on the Localized\nStatistical Channel Model. On recognizing the limitations of naive training\nscheme, we propose a novel Pretraining-Initialization-Detached-Asynchronous\n(PIDA) training scheme for CSG-AE, ensuring stable and effective training by\nsystematically addressing the common pitfalls of the naive training paradigm.\nEvaluations reveal that CSG-AE excels in CAPS estimation accuracy and\nclustering quality on synthetic data. On real-world datasets, it reduces Active\nMean Absolute Error (MAE) by 30\\% and Overall MAE by 65\\% on RSRP prediction\naccuracy compared to salient baselines using the same data, while improving\nchannel consistency, cluster sizes balance, and active ratio, advancing the\ndevelopment of gridization for large-scale network optimization.", "AI": {"tldr": "\u63d0\u51faCSG\u6846\u67b6\u7edf\u4e00\u4fe1\u9053\u4f30\u8ba1\u548c\u7f51\u683c\u5316\uff0c\u5f00\u53d1CSG - AE\u53caPIDA\u8bad\u7ec3\u65b9\u6848\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u63a8\u52a8\u5927\u89c4\u6a21\u7f51\u7edc\u4f18\u5316\u7f51\u683c\u5316\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7f51\u683c\u5316\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u53ef\u7528\u4f4d\u7f6e\u6570\u636e\u6216\u5047\u8bbe\u5b58\u5728\u7f3a\u9677\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u8fdb\u884c\u5927\u89c4\u6a21\u7f51\u7edc\u4f18\u5316\u3002", "method": "\u63d0\u51faCSG\u6846\u67b6\uff0c\u5f00\u53d1CSG - AE\uff0c\u5305\u62ec\u53ef\u8bad\u7ec3\u7f16\u7801\u5668\u3001\u53ef\u5b66\u4e60\u91cf\u5316\u5668\u548c\u7269\u7406\u611f\u77e5\u89e3\u7801\u5668\uff0c\u63d0\u51faPIDA\u8bad\u7ec3\u65b9\u6848\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u4e0aCAPS\u4f30\u8ba1\u548c\u805a\u7c7b\u8d28\u91cf\u597d\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0aRSRP\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e\uff0c\u63d0\u5347\u4fe1\u9053\u4e00\u81f4\u6027\u7b49\u6307\u6807\u3002", "conclusion": "CSG - AE\u53ca\u76f8\u5173\u65b9\u6848\u80fd\u6709\u6548\u63a8\u52a8\u5927\u89c4\u6a21\u7f51\u7edc\u4f18\u5316\u7684\u7f51\u683c\u5316\u53d1\u5c55\u3002"}}
{"id": "2507.14230", "pdf": "https://arxiv.org/pdf/2507.14230", "abs": "https://arxiv.org/abs/2507.14230", "authors": ["Fransiscus Asisi Bimo", "Maria Amparo Canaveras Galdon", "Chun-Kai Lai", "Ray-Guang Cheng", "Edwin K. P. Chong"], "title": "Intent-Based Network for RAN Management with Large Language Models", "categories": ["cs.NI", "cs.AI"], "comment": "5 pages, 3 figures, submitted to IEEE Globecom 2025", "summary": "Advanced intelligent automation becomes an important feature to deal with the\nincreased complexity in managing wireless networks. This paper proposes a novel\nautomation approach of intent-based network for Radio Access Networks (RANs)\nmanagement by leveraging Large Language Models (LLMs). The proposed method\nenhances intent translation, autonomously interpreting high-level objectives,\nreasoning over complex network states, and generating precise configurations of\nthe RAN by integrating LLMs within an agentic architecture. We propose a\nstructured prompt engineering technique and demonstrate that the network can\nautomatically improve its energy efficiency by dynamically optimizing critical\nRAN parameters through a closed-loop mechanism. It showcases the potential to\nenable robust resource management in RAN by adapting strategies based on\nreal-time feedback via LLM-orchestrated agentic systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u57fa\u4e8e\u610f\u56fe\u7684\u65e0\u7ebf\u63a5\u5165\u7f51\u81ea\u52a8\u5316\u7ba1\u7406\u65b9\u6cd5\uff0c\u53ef\u63d0\u5347\u80fd\u6548\u548c\u8d44\u6e90\u7ba1\u7406\u80fd\u529b\u3002", "motivation": "\u5e94\u5bf9\u65e0\u7ebf\u7f51\u7edc\u7ba1\u7406\u590d\u6742\u5ea6\u63d0\u5347\uff0c\u9700\u8981\u5148\u8fdb\u667a\u80fd\u81ea\u52a8\u5316\u624b\u6bb5\u3002", "method": "\u5728\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u51fa\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u901a\u8fc7\u95ed\u73af\u673a\u5236\u52a8\u6001\u4f18\u5316\u53c2\u6570\u3002", "result": "\u7f51\u7edc\u80fd\u81ea\u52a8\u63d0\u5347\u80fd\u6e90\u6548\u7387\uff0c\u53ef\u57fa\u4e8e\u5b9e\u65f6\u53cd\u9988\u8c03\u6574\u7b56\u7565\u5b9e\u73b0\u8d44\u6e90\u7ba1\u7406\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u5728\u65e0\u7ebf\u63a5\u5165\u7f51\u7ba1\u7406\u4e2d\u6709\u6f5c\u529b\u5b9e\u73b0\u5f3a\u5927\u7684\u8d44\u6e90\u7ba1\u7406\u3002"}}
{"id": "2507.15431", "pdf": "https://arxiv.org/pdf/2507.15431", "abs": "https://arxiv.org/abs/2507.15431", "authors": ["Andrew Gracyk"], "title": "The calculus of variations of the Transformer on the hyperspherical tangent bundle", "categories": ["cs.LG"], "comment": "First version", "summary": "We offer a theoretical mathematical background to Transformers through\nLagrangian optimization across the token space. The Transformer, as a flow map,\nexists in the tangent fiber for each token along the high-dimensional unit\nsphere. The circumstance of the hypersphere across the latent data is\nreasonable due to the trained diagonal matrix equal to the identity, which has\nvarious empirical justifications. Thus, under the continuum limit of the\ndynamics, the latent vectors flow among the tangent bundle. Using these facts,\nwe devise a mathematical framework for the Transformer through calculus of\nvariations. We develop a functional and show that the continuous flow map\ninduced by the Transformer satisfies this functional, therefore the Transformer\ncan be viewed as a natural solver of a calculus of variations problem. We\ninvent new scenarios of when our methods are applicable based on loss\noptimization with respect to path optimality. We derive the Euler-Lagrange\nequation for the Transformer. The variant of the Euler-Lagrange equation we\npresent has various appearances in literature, but, to our understanding,\noftentimes not foundationally proven or under other specialized cases. Our\noverarching proof is new: our techniques are classical and the use of the flow\nmap object is original. We provide several other relevant results, primarily\nones specific to neural scenarios. In particular, much of our analysis will be\nattempting to quantify Transformer data in variational contexts under neural\napproximations. Calculus of variations on manifolds is a well-nourished\nresearch area, but for the Transformer specifically, it is uncharted: we lay\nthe foundation for this area through an introduction to the Lagrangian for the\nTransformer.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u4f18\u5316\u4e3aTransformer\u63d0\u4f9b\u7406\u8bba\u6570\u5b66\u80cc\u666f\uff0c\u6784\u5efa\u6570\u5b66\u6846\u67b6\uff0c\u63a8\u5bfc\u6b27\u62c9 - \u62c9\u683c\u6717\u65e5\u65b9\u7a0b\uff0c\u4e3aTransformer\u53d8\u5206\u6cd5\u9886\u57df\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u4e3aTransformer\u63d0\u4f9b\u7406\u8bba\u6570\u5b66\u80cc\u666f\uff0c\u63a2\u7d22\u5176\u5728\u53d8\u5206\u6cd5\u9886\u57df\u7684\u57fa\u7840\u7406\u8bba\u3002", "method": "\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u4f18\u5316\u548c\u53d8\u5206\u6cd5\uff0c\u5229\u7528\u8fde\u7eed\u6781\u9650\u4e0b\u6f5c\u5411\u91cf\u5728\u5207\u4e1b\u95f4\u7684\u6d41\u52a8\u7b49\u7279\u6027\u6784\u5efa\u6570\u5b66\u6846\u67b6\u3002", "result": "\u6784\u5efa\u4e86Transformer\u7684\u6570\u5b66\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u6b27\u62c9 - \u62c9\u683c\u6717\u65e5\u65b9\u7a0b\uff0c\u7ed9\u51fa\u76f8\u5173\u7ed3\u679c\u5e76\u5c1d\u8bd5\u5728\u53d8\u5206\u80cc\u666f\u4e0b\u91cf\u5316Transformer\u6570\u636e\u3002", "conclusion": "\u4e3aTransformer\u5728\u53d8\u5206\u6cd5\u9886\u57df\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.14231", "pdf": "https://arxiv.org/pdf/2507.14231", "abs": "https://arxiv.org/abs/2507.14231", "authors": ["Khalid Hasan", "Jamil Saquer"], "title": "Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "The 37th International Conference on Software Engineering & Knowledge\n  Engineering, SEKE 2025 (camera-ready)", "summary": "Bipolar disorder is a chronic mental illness frequently underdiagnosed due to\nsubtle early symptoms and social stigma. This paper explores the advanced\nnatural language processing (NLP) models for recognizing signs of bipolar\ndisorder based on user-generated social media text. We conduct a comprehensive\nevaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA,\nDistilBERT) and Long Short Term Memory (LSTM) models based on contextualized\n(BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed\non a large, annotated dataset of Reddit posts after confirming their validity\nthrough sentiment variance and judgmental analysis. Our results demonstrate\nthat RoBERTa achieves the highest performance among transformer models with an\nF1 score of ~98% while LSTM models using BERT embeddings yield nearly identical\nresults. In contrast, LSTMs trained on static embeddings fail to capture\nmeaningful patterns, scoring near-zero F1. These findings underscore the\ncritical role of contextual language modeling in detecting bipolar disorder. In\naddition, we report model training times and highlight that DistilBERT offers\nan optimal balance between efficiency and accuracy. In general, our study\noffers actionable insights for model selection in mental health NLP\napplications and validates the potential of contextualized language models to\nsupport early bipolar disorder screening.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u591a\u79cdNLP\u6a21\u578b\u8bc6\u522b\u53cc\u76f8\u60c5\u611f\u969c\u788d\u8ff9\u8c61\u7684\u80fd\u529b\uff0c\u53d1\u73b0RoBERTa\u6027\u80fd\u6700\u4f73\uff0c\u5f3a\u8c03\u4e0a\u4e0b\u6587\u8bed\u8a00\u5efa\u6a21\u91cd\u8981\u6027\uff0c\u4e3a\u5fc3\u7406\u5065\u5eb7NLP\u5e94\u7528\u63d0\u4f9b\u9009\u6a21\u5efa\u8bae\u3002", "motivation": "\u53cc\u76f8\u60c5\u611f\u969c\u788d\u56e0\u65e9\u671f\u75c7\u72b6\u4e0d\u660e\u663e\u548c\u793e\u4f1a\u6c61\u540d\u5e38\u88ab\u6f0f\u8bca\uff0c\u63a2\u7d22\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u8bc6\u522b\u5176\u8ff9\u8c61\u7684\u5148\u8fdbNLP\u6a21\u578b\u3002", "method": "\u5bf9\u57fa\u4e8etransformer\u7684\u6a21\u578b\u548c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u3001\u9759\u6001\u8bcd\u5d4c\u5165\u7684LSTM\u6a21\u578b\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u5728Reddit\u5e16\u5b50\u6ce8\u91ca\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u5e76\u901a\u8fc7\u60c5\u611f\u65b9\u5dee\u548c\u5224\u65ad\u5206\u6790\u786e\u8ba4\u6570\u636e\u6709\u6548\u6027\u3002", "result": "RoBERTa\u5728transformer\u6a21\u578b\u4e2d\u6027\u80fd\u6700\u9ad8\uff0cF1\u5206\u6570\u7ea698%\uff1b\u4f7f\u7528BERT\u5d4c\u5165\u7684LSTM\u6a21\u578b\u7ed3\u679c\u76f8\u8fd1\uff1b\u57fa\u4e8e\u9759\u6001\u5d4c\u5165\u7684LSTM\u6a21\u578bF1\u5206\u6570\u63a5\u8fd1\u96f6\uff1bDistilBERT\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\u3002", "conclusion": "\u5f3a\u8c03\u4e0a\u4e0b\u6587\u8bed\u8a00\u5efa\u6a21\u5728\u68c0\u6d4b\u53cc\u76f8\u60c5\u611f\u969c\u788d\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u5fc3\u7406\u5065\u5eb7NLP\u5e94\u7528\u9009\u6a21\u63d0\u4f9b\u89c1\u89e3\uff0c\u9a8c\u8bc1\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u652f\u6301\u65e9\u671f\u53cc\u76f8\u60c5\u611f\u969c\u788d\u7b5b\u67e5\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15442", "pdf": "https://arxiv.org/pdf/2507.15442", "abs": "https://arxiv.org/abs/2507.15442", "authors": ["Owen Douglas", "Aku Kammonen", "Anamika Pandey", "Ra\u00fal Tempone"], "title": "An Adaptive Random Fourier Features approach Applied to Learning Stochastic Differential Equations", "categories": ["cs.LG"], "comment": "20 Pages", "summary": "This work proposes a training algorithm based on adaptive random Fourier\nfeatures (ARFF) with Metropolis sampling and resampling\n\\cite{kammonen2024adaptiverandomfourierfeatures} for learning drift and\ndiffusion components of stochastic differential equations from snapshot data.\nSpecifically, this study considers It\\^{o} diffusion processes and a\nlikelihood-based loss function derived from the Euler-Maruyama integration\nintroduced in \\cite{Dietrich2023} and\n\\cite{dridi2021learningstochasticdynamicalsystems}.\n  This work evaluates the proposed method against benchmark problems presented\nin \\cite{Dietrich2023}, including polynomial examples, underdamped Langevin\ndynamics, a stochastic susceptible-infected-recovered model, and a stochastic\nwave equation. Across all cases, the ARFF-based approach matches or surpasses\nthe performance of conventional Adam-based optimization in both loss\nminimization and convergence speed. These results highlight the potential of\nARFF as a compelling alternative for data-driven modeling of stochastic\ndynamics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u9002\u5e94\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08ARFF\uff09\u4e0eMetropolis\u91c7\u6837\u548c\u91cd\u91c7\u6837\u7684\u8bad\u7ec3\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u5feb\u7167\u6570\u636e\u5b66\u4e60\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u6f02\u79fb\u548c\u6269\u6563\u5206\u91cf\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edfAdam\u4f18\u5316\u3002", "motivation": "\u4ece\u5feb\u7167\u6570\u636e\u5b66\u4e60\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u6f02\u79fb\u548c\u6269\u6563\u5206\u91cf\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eARFF\u4e0eMetropolis\u91c7\u6837\u548c\u91cd\u91c7\u6837\u7684\u8bad\u7ec3\u7b97\u6cd5\uff0c\u8003\u8651It\u00f4\u6269\u6563\u8fc7\u7a0b\u548c\u57fa\u4e8e\u4f3c\u7136\u7684\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u6240\u6709\u8bc4\u4f30\u6848\u4f8b\u4e2d\uff0cARFF\u65b9\u6cd5\u5728\u635f\u5931\u6700\u5c0f\u5316\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u4f20\u7edfAdam\u4f18\u5316\u3002", "conclusion": "ARFF\u662f\u968f\u673a\u52a8\u529b\u5b66\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u7684\u6709\u529b\u66ff\u4ee3\u65b9\u6cd5\u3002"}}
{"id": "2507.14237", "pdf": "https://arxiv.org/pdf/2507.14237", "abs": "https://arxiv.org/abs/2507.14237", "authors": ["Louis Bahrman", "Mathieu Fontaine", "Ga\u00ebl Richard"], "title": "U-DREAM: Unsupervised Dereverberation guided by a Reverberation Model", "categories": ["cs.SD", "cs.AI", "eess.AS", "eess.SP"], "comment": "Submitted to IEEE Transactions on Audio, Speech and Language\n  Processing (TASLPRO)", "summary": "This paper explores the outcome of training state-ofthe-art dereverberation\nmodels with supervision settings ranging from weakly-supervised to fully\nunsupervised, relying solely on reverberant signals and an acoustic model for\ntraining. Most of the existing deep learning approaches typically require\npaired dry and reverberant data, which are difficult to obtain in practice. We\ndevelop instead a sequential learning strategy motivated by a bayesian\nformulation of the dereverberation problem, wherein acoustic parameters and dry\nsignals are estimated from reverberant inputs using deep neural networks,\nguided by a reverberation matching loss. Our most data-efficient variant\nrequires only 100 reverberation-parameter-labelled samples to outperform an\nunsupervised baseline, demonstrating the effectiveness and practicality of the\nproposed method in low-resource scenarios.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e0d\u540c\u76d1\u7763\u8bbe\u7f6e\u4e0b\u8bad\u7ec3\u53bb\u6df7\u54cd\u6a21\u578b\u7684\u7ed3\u679c\uff0c\u63d0\u51fa\u987a\u5e8f\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9700\u6210\u5bf9\u5e72\u4fe1\u53f7\u548c\u6df7\u54cd\u6570\u636e\uff0c\u5b9e\u9645\u96be\u83b7\u53d6\uff0c\u56e0\u6b64\u63a2\u7d22\u4ec5\u7528\u6df7\u54cd\u4fe1\u53f7\u548c\u58f0\u5b66\u6a21\u578b\u8bad\u7ec3\u53bb\u6df7\u54cd\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u53bb\u6df7\u54cd\u95ee\u9898\u7684\u8d1d\u53f6\u65af\u516c\u5f0f\uff0c\u5f00\u53d1\u987a\u5e8f\u5b66\u4e60\u7b56\u7565\uff0c\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4ece\u6df7\u54cd\u8f93\u5165\u4f30\u8ba1\u58f0\u5b66\u53c2\u6570\u548c\u5e72\u4fe1\u53f7\uff0c\u4ee5\u6df7\u54cd\u5339\u914d\u635f\u5931\u4e3a\u6307\u5bfc\u3002", "result": "\u6570\u636e\u6548\u7387\u6700\u9ad8\u7684\u53d8\u4f53\u4ec5\u9700100\u4e2a\u6df7\u54cd\u53c2\u6570\u6807\u8bb0\u6837\u672c\u5c31\u80fd\u8d85\u8d8a\u65e0\u76d1\u7763\u57fa\u7ebf\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u6709\u6548\u4e14\u5b9e\u7528\u3002"}}
{"id": "2507.15470", "pdf": "https://arxiv.org/pdf/2507.15470", "abs": "https://arxiv.org/abs/2507.15470", "authors": ["Baran Can G\u00fcl", "Suraksha Nadig", "Stefanos Tziampazis", "Nasser Jazdi", "Michael Weyrich"], "title": "FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning", "categories": ["cs.LG"], "comment": "Preprint version. Accepted for publication at IEEE ICECCME 2025", "summary": "In-vehicle emotion recognition underpins adaptive driver-assistance systems\nand, ultimately, occupant safety. However, practical deployment is hindered by\n(i) modality fragility - poor lighting and occlusions degrade vision-based\nmethods; (ii) physiological variability - heart-rate and skin-conductance\npatterns differ across individuals; and (iii) privacy risk - centralized\ntraining requires transmission of sensitive data. To address these challenges,\nwe present FedMultiEmo, a privacy-preserving framework that fuses two\ncomplementary modalities at the decision level: visual features extracted by a\nConvolutional Neural Network from facial images, and physiological cues (heart\nrate, electrodermal activity, and skin temperature) classified by a Random\nForest. FedMultiEmo builds on three key elements: (1) a multimodal federated\nlearning pipeline with majority-vote fusion, (2) an end-to-end edge-to-cloud\nprototype on Raspberry Pi clients and a Flower server, and (3) a personalized\nFederated Averaging scheme that weights client updates by local data volume.\nEvaluated on FER2013 and a custom physiological dataset, the federated\nConvolutional Neural Network attains 77% accuracy, the Random Forest 74%, and\ntheir fusion 87%, matching a centralized baseline while keeping all raw data\nlocal. The developed system converges in 18 rounds, with an average round time\nof 120 seconds and a per-client memory footprint below 200 MB. These results\nindicate that FedMultiEmo offers a practical approach to real-time,\nprivacy-aware emotion recognition in automotive settings.", "AI": {"tldr": "\u63d0\u51faFedMultiEmo\u6846\u67b6\u7528\u4e8e\u8f66\u5185\u60c5\u7eea\u8bc6\u522b\uff0c\u878d\u5408\u591a\u6a21\u6001\u6570\u636e\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\uff0c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u8f66\u5185\u60c5\u7eea\u8bc6\u522b\u6280\u672f\u5b58\u5728\u6a21\u6001\u8106\u5f31\u3001\u751f\u7406\u5dee\u5f02\u548c\u9690\u79c1\u98ce\u9669\u7b49\u95ee\u9898\uff0c\u963b\u788d\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faFedMultiEmo\u6846\u67b6\uff0c\u5728\u51b3\u7b56\u5c42\u878d\u5408\u89c6\u89c9\u548c\u751f\u7406\u4e24\u79cd\u6a21\u6001\uff0c\u91c7\u7528\u591a\u6a21\u6001\u8054\u90a6\u5b66\u4e60\u7ba1\u9053\u3001\u6811\u8393\u6d3e\u5ba2\u6237\u7aef\u548cFlower\u670d\u52a1\u5668\u7684\u7aef\u5230\u7aef\u539f\u578b\u4ee5\u53ca\u4e2a\u6027\u5316\u8054\u90a6\u5e73\u5747\u65b9\u6848\u3002", "result": "\u5728FER2013\u548c\u81ea\u5b9a\u4e49\u751f\u7406\u6570\u636e\u96c6\u4e0a\uff0c\u8054\u90a6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u51c6\u786e\u738777%\uff0c\u968f\u673a\u68ee\u679774%\uff0c\u878d\u5408\u540e87%\uff0c\u7cfb\u7edf18\u8f6e\u6536\u655b\uff0c\u5e73\u5747\u8f6e\u6b21\u65f6\u95f4120\u79d2\uff0c\u5355\u5ba2\u6237\u7aef\u5185\u5b58\u5360\u7528\u4f4e\u4e8e200MB\u3002", "conclusion": "FedMultiEmo\u4e3a\u6c7d\u8f66\u73af\u5883\u4e0b\u5b9e\u65f6\u3001\u6ce8\u91cd\u9690\u79c1\u7684\u60c5\u7eea\u8bc6\u522b\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2507.14238", "pdf": "https://arxiv.org/pdf/2507.14238", "abs": "https://arxiv.org/abs/2507.14238", "authors": ["Matthew Kearney", "Reuben Binns", "Yarin Gal"], "title": "Language Models Change Facts Based on the Way You Talk", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) are increasingly being used in user-facing\napplications, from providing medical consultations to job interview advice.\nRecent research suggests that these models are becoming increasingly proficient\nat inferring identity information about the author of a piece of text from\nlinguistic patterns as subtle as the choice of a few words. However, little is\nknown about how LLMs use this information in their decision-making in\nreal-world applications. We perform the first comprehensive analysis of how\nidentity markers present in a user's writing bias LLM responses across five\ndifferent high-stakes LLM applications in the domains of medicine, law,\npolitics, government benefits, and job salaries. We find that LLMs are\nextremely sensitive to markers of identity in user queries and that race,\ngender, and age consistently influence LLM responses in these applications. For\ninstance, when providing medical advice, we find that models apply different\nstandards of care to individuals of different ethnicities for the same\nsymptoms; we find that LLMs are more likely to alter answers to align with a\nconservative (liberal) political worldview when asked factual questions by\nolder (younger) individuals; and that LLMs recommend lower salaries for\nnon-White job applicants and higher salaries for women compared to men. Taken\ntogether, these biases mean that the use of off-the-shelf LLMs for these\napplications may cause harmful differences in medical care, foster wage gaps,\nand create different political factual realities for people of different\nidentities. Beyond providing an analysis, we also provide new tools for\nevaluating how subtle encoding of identity in users' language choices impacts\nmodel decisions. Given the serious implications of these findings, we recommend\nthat similar thorough assessments of LLM use in user-facing applications are\nconducted before future deployment.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e94\u4e2a\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u5bf9\u7528\u6237\u8eab\u4efd\u6807\u8bb0\u7684\u54cd\u5e94\u504f\u5dee\uff0c\u53d1\u73b0\u8eab\u4efd\u56e0\u7d20\u4f1a\u5f71\u54cd\u6a21\u578b\u56de\u7b54\uff0c\u8fd8\u63d0\u4f9b\u8bc4\u4f30\u5de5\u5177\u5e76\u5efa\u8bae\u672a\u6765\u90e8\u7f72\u524d\u505a\u5168\u9762\u8bc4\u4f30\u3002", "motivation": "\u4e86\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u51b3\u7b56\u4e2d\u5982\u4f55\u5229\u7528\u8eab\u4efd\u4fe1\u606f\u3002", "method": "\u5bf9\u533b\u5b66\u3001\u6cd5\u5f8b\u3001\u653f\u6cbb\u3001\u653f\u5e9c\u798f\u5229\u548c\u5de5\u4f5c\u85aa\u8d44\u4e94\u4e2a\u9886\u57df\u7684\u9ad8\u98ce\u9669\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u8fdb\u884c\u5168\u9762\u5206\u6790\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u7528\u6237\u67e5\u8be2\u4e2d\u7684\u8eab\u4efd\u6807\u8bb0\u6781\u4e3a\u654f\u611f\uff0c\u79cd\u65cf\u3001\u6027\u522b\u548c\u5e74\u9f84\u4f1a\u6301\u7eed\u5f71\u54cd\u5176\u56de\u7b54\uff0c\u5982\u533b\u7597\u5efa\u8bae\u3001\u653f\u6cbb\u4e8b\u5b9e\u56de\u7b54\u548c\u85aa\u8d44\u63a8\u8350\u5b58\u5728\u504f\u5dee\u3002", "conclusion": "\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u8fd9\u4e9b\u5e94\u7528\u53ef\u80fd\u9020\u6210\u4e0d\u826f\u5f71\u54cd\uff0c\u5efa\u8bae\u672a\u6765\u90e8\u7f72\u524d\u8fdb\u884c\u7c7b\u4f3c\u5168\u9762\u8bc4\u4f30\u3002"}}
{"id": "2507.15507", "pdf": "https://arxiv.org/pdf/2507.15507", "abs": "https://arxiv.org/abs/2507.15507", "authors": ["Johannes Ackermann", "Takashi Ishida", "Masashi Sugiyama"], "title": "Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accept at the Conference On Language Modeling (COLM) 2025", "summary": "Reinforcement Learning from Human Feedback (RLHF) allows us to train models,\nsuch as language models (LMs), to follow complex human preferences. In RLHF for\nLMs, we first train an LM using supervised fine-tuning, sample pairs of\nresponses, obtain human feedback, and use the resulting data to train a reward\nmodel (RM). RL methods are then used to train the LM to maximize the reward\ngiven by the RM. As training progresses, the responses generated by the LM no\nlonger resemble the responses seen by the RM during training, leading to the RM\nbecoming inaccurate. The score given by the RM keeps increasing, but the\nlearned behavior no longer matches the human preferences. This issue is known\nas overoptimization. We investigate overoptimization from the point of view of\ndistribution shift and show that the shift results in an inconsistent estimate\nof the RM parameters, leading to an inconsistent estimate of the policy\ngradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which\niteratively off-policy corrects the RM using importance weighting, without\nrequiring new labels or samples. This results in a more accurate RM, which\nempirically leads to an improved final policy. We validate our approach in\nexperiments with summarization and chatbot datasets and show that it performs\nsignificantly better than standard RLHF methods and baselines. Our\nimplementation is available at\nhttps://github.com/JohannesAck/OffPolicyCorrectedRewardModeling", "AI": {"tldr": "\u672c\u6587\u7814\u7a76RLHF\u4e2d\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51faOCRM\u65b9\u6cd5\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3RLHF\u4e2d\u5956\u52b1\u6a21\u578b\u56e0\u5206\u5e03\u504f\u79fb\u5bfc\u81f4\u4e0d\u51c6\u786e\uff0c\u51fa\u73b0\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5373\u5956\u52b1\u6a21\u578b\u5f97\u5206\u4e0a\u5347\u4f46\u5b66\u4e60\u884c\u4e3a\u4e0d\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u3002", "method": "\u4ece\u5206\u5e03\u504f\u79fb\u89d2\u5ea6\u7814\u7a76\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51faOCRM\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u8981\u6027\u52a0\u6743\u8fed\u4ee3\u79bb\u7b56\u7565\u6821\u6b63\u5956\u52b1\u6a21\u578b\uff0c\u65e0\u9700\u65b0\u6807\u7b7e\u6216\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eOCRM\u65b9\u6cd5\u80fd\u5f97\u5230\u66f4\u51c6\u786e\u5956\u52b1\u6a21\u578b\uff0c\u6700\u7ec8\u7b56\u7565\u8868\u73b0\u66f4\u597d\uff0c\u663e\u8457\u4f18\u4e8e\u6807\u51c6RLHF\u65b9\u6cd5\u548c\u57fa\u7ebf\u3002", "conclusion": "OCRM\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86RLHF\u4e2d\u7684\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.14239", "pdf": "https://arxiv.org/pdf/2507.14239", "abs": "https://arxiv.org/abs/2507.14239", "authors": ["Weihua Zheng", "Roy Ka-Wei Lee", "Zhengyuan Liu", "Kui Wu", "AiTi Aw", "Bowei Zou"], "title": "CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multilingual Large Language Models(MLLMs) demonstrate strong generalization\nacross languages, yet they remain prone to hallucinations, especially in\nlow-resource languages, due to training data imbalances. These hallucinations,\nwhich include inaccurate or fabricated outputs, are particularly problematic in\ndomain-specific generation tasks (Chataigner et al., 2024). To address this\nchallenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based\nCross-lingual Chain-of-Thought), a two-stage fine-tuning framework for\nmitigating hallucination in MLLMs. Our approach first enhances cross-lingual\nsemantic alignment through curriculum-based contrastive learning combined with\nnext-token prediction during continued pre-training. Building on this\nfoundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting\nstrategy during instruction fine-tuning, which guides the model to reason in a\nhigh-resource language before generating answers in the target low-resource\nlanguage. Experimental results show that CCL-XCoT reduces hallucination rates\nby up to 62% and substantially improves factual knowledge transfer across\nlanguage pairs, without relying on external retrieval or multi-model ensembles.", "AI": {"tldr": "\u63d0\u51faCCL - XCoT\u6846\u67b6\u51cf\u5c11\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u6548\u964d\u4f4e\u5e7b\u89c9\u7387\u5e76\u63d0\u5347\u8de8\u8bed\u8a00\u77e5\u8bc6\u4f20\u9012\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u5c24\u5176\u662f\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u56e0\u8bad\u7ec3\u6570\u636e\u4e0d\u5e73\u8861\u5bfc\u81f4\uff0c\u5728\u7279\u5b9a\u9886\u57df\u751f\u6210\u4efb\u52a1\u4e2d\u95ee\u9898\u7a81\u51fa\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51faCCL - XCoT\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\uff0c\u5148\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u901a\u8fc7\u57fa\u4e8e\u8bfe\u7a0b\u7684\u5bf9\u6bd4\u5b66\u4e60\u548c\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u589e\u5f3a\u8de8\u8bed\u8a00\u8bed\u4e49\u5bf9\u9f50\uff0c\u518d\u5728\u6307\u4ee4\u5fae\u8c03\u4e2d\u5f15\u5165\u8de8\u8bed\u8a00\u601d\u7ef4\u94fe\u63d0\u793a\u7b56\u7565\u3002", "result": "CCL - XCoT\u6700\u591a\u964d\u4f4e62%\u7684\u5e7b\u89c9\u7387\uff0c\u663e\u8457\u63d0\u5347\u8de8\u8bed\u8a00\u5bf9\u7684\u4e8b\u5b9e\u77e5\u8bc6\u4f20\u9012\uff0c\u4e14\u4e0d\u4f9d\u8d56\u5916\u90e8\u68c0\u7d22\u6216\u591a\u6a21\u578b\u96c6\u6210\u3002", "conclusion": "CCL - XCoT\u6846\u67b6\u80fd\u6709\u6548\u7f13\u89e3\u591a\u8bed\u8a00\u5927\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u3002"}}
{"id": "2507.15523", "pdf": "https://arxiv.org/pdf/2507.15523", "abs": "https://arxiv.org/abs/2507.15523", "authors": ["Weichuang Shao", "Iman Yi Liao", "Tomas Henrique Bode Maul", "Tissa Chandesa"], "title": "An Investigation of Test-time Adaptation for Audio Classification under Background Noise", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Domain shift is a prominent problem in Deep Learning, causing a model\npre-trained on a source dataset to suffer significant performance degradation\non test datasets. This research aims to address the issue of audio\nclassification under domain shift caused by background noise using Test-Time\nAdaptation (TTA), a technique that adapts a pre-trained model during testing\nusing only unlabelled test data before making predictions. We adopt two common\nTTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and\ninvestigate their respective performance on two popular audio classification\ndatasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types\nof background noise and noise severity levels. The experimental results reveal\nthat our proposed modified version of CoNMix produced the highest\nclassification accuracy under domain shift (5.31% error rate under 10 dB\nexercise bike background noise and 12.75% error rate under 3 dB running tap\nbackground noise for AM) compared to TTT and TENT. The literature search\nprovided no evidence of similar works, thereby motivating the work reported\nhere as the first study to leverage TTA techniques for audio classification\nunder domain shift.", "AI": {"tldr": "\u672c\u6587\u7528TTA\u6280\u672f\u89e3\u51b3\u80cc\u666f\u566a\u58f0\u5bfc\u81f4\u7684\u9886\u57df\u504f\u79fb\u4e0b\u7684\u97f3\u9891\u5206\u7c7b\u95ee\u9898\uff0c\u5bf9\u6bd4\u51e0\u79cdTTA\u65b9\u6cd5\uff0c\u6539\u8fdb\u7248CoNMix\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u9886\u57df\u504f\u79fb\u5bfc\u81f4\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u5229\u7528TTA\u6280\u672f\u89e3\u51b3\u97f3\u9891\u5206\u7c7b\u9886\u57df\u504f\u79fb\u95ee\u9898\u7684\u7814\u7a76\u3002", "method": "\u91c7\u7528TTT\u3001TENT\u548cCoNMix\u4e09\u79cdTTA\u65b9\u6cd5\uff0c\u5728AudioMNIST\u548cSpeechCommands V1\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u548c\u5f3a\u5ea6\u7684\u80cc\u666f\u566a\u58f0\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u6539\u8fdb\u7248CoNMix\u5728\u9886\u57df\u504f\u79fb\u4e0b\u5206\u7c7b\u51c6\u786e\u7387\u6700\u9ad8\uff0c\u5982\u5728AudioMNIST\u6570\u636e\u96c6\u4e0a\uff0c10 dB\u5065\u8eab\u81ea\u884c\u8f66\u80cc\u666f\u566a\u58f0\u4e0b\u9519\u8bef\u73875.31%\uff0c3 dB\u6c34\u9f99\u5934\u80cc\u666f\u566a\u58f0\u4e0b\u9519\u8bef\u738712.75%\u3002", "conclusion": "\u6539\u8fdb\u7248CoNMix\u5728\u89e3\u51b3\u97f3\u9891\u5206\u7c7b\u9886\u57df\u504f\u79fb\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8eTTT\u548cTENT\uff0c\u8be5\u7814\u7a76\u662f\u9996\u6b21\u5229\u7528TTA\u6280\u672f\u89e3\u51b3\u6b64\u95ee\u9898\u7684\u7814\u7a76\u3002"}}
{"id": "2507.14240", "pdf": "https://arxiv.org/pdf/2507.14240", "abs": "https://arxiv.org/abs/2507.14240", "authors": ["Mohammad Shahedur Rahman", "Peng Gao", "Yuede Ji"], "title": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "Large language models (LLMs) leverage deep learning to process and predict\nsequences of words from context, enabling them to perform various NLP tasks,\nsuch as translation, summarization, question answering, and content generation.\nHowever, the growing size and complexity of developing, training, and deploying\nadvanced LLMs require extensive computational resources and large datasets.\nThis creates a barrier for users. As a result, platforms that host models and\ndatasets are widely used. For example, Hugging Face, one of the most popular\nplatforms, hosted 1.8 million models and 450K datasets by June 2025, with no\nsign of slowing down. Since many LLMs are built from base models, pre-trained\nmodels, and external datasets, they can inherit vulnerabilities, biases, or\nmalicious components from earlier models or datasets. Therefore, it is critical\nto understand the origin and development of these components to better detect\npotential risks, improve model fairness, and ensure compliance. Motivated by\nthis, our project aims to study the relationships between models and datasets,\nwhich are core components of the LLM supply chain. First, we design a method to\nsystematically collect LLM supply chain data. Using this data, we build a\ndirected heterogeneous graph to model the relationships between models and\ndatasets, resulting in a structure with 397,376 nodes and 453,469 edges. We\nthen perform various analyses and uncover several findings, such as: (i) the\nLLM supply chain graph is large, sparse, and follows a power-law degree\ndistribution; (ii) it features a densely connected core and a fragmented\nperiphery; (iii) datasets play pivotal roles in training; (iv) strong\ninterdependence exists between models and datasets; and (v) the graph is\ndynamic, with daily updates reflecting the ecosystem's ongoing evolution.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4f9b\u5e94\u94fe\u4e2d\u6a21\u578b\u4e0e\u6570\u636e\u96c6\u5173\u7cfb\uff0c\u6784\u5efa\u56fe\u5e76\u5206\u6790\u5176\u7279\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u3001\u8bad\u7ec3\u548c\u90e8\u7f72\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u4e14\u6a21\u578b\u6613\u7ee7\u627f\u98ce\u9669\uff0c\u9700\u7814\u7a76\u6a21\u578b\u4e0e\u6570\u636e\u96c6\u5173\u7cfb\u4ee5\u68c0\u6d4b\u98ce\u9669\u3001\u63d0\u9ad8\u516c\u5e73\u6027\u548c\u786e\u4fdd\u5408\u89c4\u3002", "method": "\u8bbe\u8ba1\u7cfb\u7edf\u6536\u96c6\u5927\u8bed\u8a00\u6a21\u578b\u4f9b\u5e94\u94fe\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u6784\u5efa\u6709\u5411\u5f02\u6784\u56fe\u6765\u5efa\u6a21\u6a21\u578b\u4e0e\u6570\u636e\u96c6\u5173\u7cfb\u3002", "result": "\u6784\u5efa\u7684\u56fe\u6709397,376\u4e2a\u8282\u70b9\u548c453,469\u6761\u8fb9\uff0c\u53d1\u73b0\u56fe\u5927\u4e14\u7a00\u758f\u3001\u6709\u6838\u5fc3\u4e0e\u8fb9\u7f18\u7ed3\u6784\u3001\u6570\u636e\u96c6\u91cd\u8981\u3001\u6a21\u578b\u4e0e\u6570\u636e\u96c6\u76f8\u4e92\u4f9d\u8d56\u3001\u56fe\u52a8\u6001\u66f4\u65b0\u7b49\u7279\u6027\u3002", "conclusion": "\u901a\u8fc7\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4f9b\u5e94\u94fe\u4e2d\u6a21\u578b\u4e0e\u6570\u636e\u96c6\u5173\u7cfb\uff0c\u6709\u52a9\u4e8e\u68c0\u6d4b\u6f5c\u5728\u98ce\u9669\u3001\u63d0\u5347\u6a21\u578b\u516c\u5e73\u6027\u548c\u786e\u4fdd\u5408\u89c4\u3002"}}
{"id": "2507.15545", "pdf": "https://arxiv.org/pdf/2507.15545", "abs": "https://arxiv.org/abs/2507.15545", "authors": ["Yujia Shi", "Emil Njor", "Pablo Mart\u00ednez-Nuevo", "Sven Ewan Shepstone", "Xenofon Fafoutis"], "title": "Data Aware Differentiable Neural Architecture Search for Tiny Keyword Spotting Applications", "categories": ["cs.LG"], "comment": null, "summary": "The success of Machine Learning is increasingly tempered by its significant\nresource footprint, driving interest in efficient paradigms like TinyML.\nHowever, the inherent complexity of designing TinyML systems hampers their\nbroad adoption. To reduce this complexity, we introduce \"Data Aware\nDifferentiable Neural Architecture Search\". Unlike conventional Differentiable\nNeural Architecture Search, our approach expands the search space to include\ndata configuration parameters alongside architectural choices. This enables\nData Aware Differentiable Neural Architecture Search to co-optimize model\narchitecture and input data characteristics, effectively balancing resource\nusage and system performance for TinyML applications. Initial results on\nkeyword spotting demonstrate that this novel approach to TinyML system design\ncan generate lean but highly accurate systems.", "AI": {"tldr": "\u673a\u5668\u5b66\u4e60\u8d44\u6e90\u6d88\u8017\u5927\u4fc3\u4f7fTinyML\u53d7\u5173\u6ce8\uff0c\u4f46\u8bbe\u8ba1\u590d\u6742\uff0c\u63d0\u51fa\u6570\u636e\u611f\u77e5\u53ef\u5fae\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u65b9\u6cd5\uff0c\u80fd\u4f18\u5316\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u7279\u5f81\uff0c\u5728\u5173\u952e\u8bcd\u68c0\u6d4b\u521d\u6b65\u7ed3\u679c\u826f\u597d\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u8d44\u6e90\u6d88\u8017\u5927\uff0cTinyML\u8bbe\u8ba1\u590d\u6742\u963b\u788d\u5176\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u964d\u4f4e\u8bbe\u8ba1\u590d\u6742\u6027\u3002", "method": "\u5f15\u5165\u6570\u636e\u611f\u77e5\u53ef\u5fae\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff0c\u5c06\u641c\u7d22\u7a7a\u95f4\u6269\u5c55\u5230\u5305\u542b\u6570\u636e\u914d\u7f6e\u53c2\u6570\u4e0e\u67b6\u6784\u9009\u62e9\uff0c\u5171\u540c\u4f18\u5316\u6a21\u578b\u67b6\u6784\u548c\u8f93\u5165\u6570\u636e\u7279\u5f81\u3002", "result": "\u5728\u5173\u952e\u8bcd\u68c0\u6d4b\u7684\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u7cbe\u7b80\u4e14\u9ad8\u7cbe\u5ea6\u7684\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u65b0\u9896\u65b9\u6cd5\u53ef\u6709\u6548\u5e73\u8861TinyML\u5e94\u7528\u7684\u8d44\u6e90\u4f7f\u7528\u548c\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2507.14241", "pdf": "https://arxiv.org/pdf/2507.14241", "abs": "https://arxiv.org/abs/2507.14241", "authors": ["Rithesh Murthy", "Ming Zhu", "Liangwei Yang", "Jielin Qiu", "Juntao Tan", "Shelby Heinecke", "Huan Wang", "Caiming Xiong", "Silvio Savarese"], "title": "Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) perform best with well-crafted prompts, yet\nprompt engineering remains manual, inconsistent, and inaccessible to\nnon-experts. We introduce Promptomatix, an automatic prompt optimization\nframework that transforms natural language task descriptions into high-quality\nprompts without requiring manual tuning or domain expertise. Promptomatix\nsupports both a lightweight meta-prompt-based optimizer and a DSPy-powered\ncompiler, with modular design enabling future extension to more advanced\nframeworks. The system analyzes user intent, generates synthetic training data,\nselects prompting strategies, and refines prompts using cost-aware objectives.\nEvaluated across 5 task categories, Promptomatix achieves competitive or\nsuperior performance compared to existing libraries, while reducing prompt\nlength and computational overhead making prompt optimization scalable and\nefficient.", "AI": {"tldr": "\u4ecb\u7ecd\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6Promptomatix\uff0c\u80fd\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u5316\u4e3a\u9ad8\u8d28\u91cf\u63d0\u793a\uff0c\u8bc4\u4f30\u8868\u73b0\u4f73\uff0c\u53ef\u6269\u5c55\u9ad8\u6548\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u5de5\u7a0b\u624b\u52a8\u3001\u4e0d\u4e00\u81f4\u4e14\u975e\u4e13\u5bb6\u96be\u4ee5\u4f7f\u7528\uff0c\u9700\u8981\u81ea\u52a8\u4f18\u5316\u6846\u67b6\u3002", "method": "\u652f\u6301\u8f7b\u91cf\u7ea7\u5143\u63d0\u793a\u4f18\u5316\u5668\u548cDSPy\u7f16\u8bd1\u5668\uff0c\u5206\u6790\u7528\u6237\u610f\u56fe\u3001\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\u3001\u9009\u62e9\u63d0\u793a\u7b56\u7565\u5e76\u4f7f\u7528\u6210\u672c\u611f\u77e5\u76ee\u6807\u4f18\u5316\u63d0\u793a\u3002", "result": "\u57285\u7c7b\u4efb\u52a1\u8bc4\u4f30\u4e2d\u8868\u73b0\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\uff0c\u51cf\u5c11\u63d0\u793a\u957f\u5ea6\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "Promptomatix\u4f7f\u63d0\u793a\u4f18\u5316\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u3002"}}
{"id": "2507.15548", "pdf": "https://arxiv.org/pdf/2507.15548", "abs": "https://arxiv.org/abs/2507.15548", "authors": ["D. Abler", "O. Pusterla", "A. Joye-K\u00fchnis", "N. Andratschke", "M. Bach", "A. Bink", "S. M. Christ", "P. Hagmann", "B. Pouymayou", "E. Pravat\u00e0", "P. Radojewski", "M. Reyes", "L. Ruinelli", "R. Schaer", "B. Stieltjes", "G. Treglia", "W. Valenzuela", "R. Wiest", "S. Zoergiebel", "M. Guckenberger", "S. Tanadini-Lang", "A. Depeursinge"], "title": "The added value for MRI radiomics and deep-learning for glioblastoma prognostication compared to clinical and molecular information", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "Background: Radiomics shows promise in characterizing glioblastoma, but its\nadded value over clinical and molecular predictors has yet to be proven. This\nstudy assessed the added value of conventional radiomics (CR) and deep learning\n(DL) MRI radiomics for glioblastoma prognosis (<= 6 vs > 6 months survival) on\na large multi-center dataset.\n  Methods: After patient selection, our curated dataset gathers 1152\nglioblastoma (WHO 2016) patients from five Swiss centers and one public source.\nIt included clinical (age, gender), molecular (MGMT, IDH), and baseline MRI\ndata (T1, T1 contrast, FLAIR, T2) with tumor regions. CR and DL models were\ndeveloped using standard methods and evaluated on internal and external\ncohorts. Sub-analyses assessed models with different feature sets\n(imaging-only, clinical/molecular-only, combined-features) and patient subsets\n(S-1: all patients, S-2: with molecular data, S-3: IDH wildtype).\n  Results: The best performance was observed in the full cohort (S-1). In\nexternal validation, the combined-feature CR model achieved an AUC of 0.75,\nslightly, but significantly outperforming clinical-only (0.74) and imaging-only\n(0.68) models. DL models showed similar trends, though without statistical\nsignificance. In S-2 and S-3, combined models did not outperform clinical-only\nmodels. Exploratory analysis of CR models for overall survival prediction\nsuggested greater relevance of imaging data: across all subsets,\ncombined-feature models significantly outperformed clinical-only models, though\nwith a modest advantage of 2-4 C-index points.\n  Conclusions: While confirming the predictive value of anatomical MRI\nsequences for glioblastoma prognosis, this multi-center study found standard CR\nand DL radiomics approaches offer minimal added value over demographic\npredictors such as age and gender.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u591a\u4e2d\u5fc3\u6570\u636e\u4e2d\u4f20\u7edf\u653e\u5c04\u7ec4\u5b66\uff08CR\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09MRI\u653e\u5c04\u7ec4\u5b66\u5bf9\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\u7684\u9644\u52a0\u4ef7\u503c\uff0c\u53d1\u73b0\u5176\u76f8\u6bd4\u4eba\u53e3\u7edf\u8ba1\u5b66\u9884\u6d4b\u56e0\u5b50\u9644\u52a0\u4ef7\u503c\u6709\u9650\u3002", "motivation": "\u8bc4\u4f30\u4f20\u7edf\u653e\u5c04\u7ec4\u5b66\u548c\u6df1\u5ea6\u5b66\u4e60MRI\u653e\u5c04\u7ec4\u5b66\u5728\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\u8bc4\u4f30\u4e0a\uff0c\u76f8\u6bd4\u4e34\u5e8a\u548c\u5206\u5b50\u9884\u6d4b\u56e0\u5b50\u7684\u9644\u52a0\u4ef7\u503c\u3002", "method": "\u6536\u96c6\u4e94\u4e2a\u745e\u58eb\u4e2d\u5fc3\u548c\u4e00\u4e2a\u516c\u5171\u6765\u6e90\u76841152\u4f8b\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u60a3\u8005\u6570\u636e\uff0c\u5f00\u53d1CR\u548cDL\u6a21\u578b\uff0c\u5728\u5185\u90e8\u548c\u5916\u90e8\u961f\u5217\u8bc4\u4f30\uff0c\u8fdb\u884c\u4e0d\u540c\u7279\u5f81\u96c6\u548c\u60a3\u8005\u5b50\u96c6\u7684\u4e9a\u5206\u6790\u3002", "result": "\u5168\u961f\u5217\u4e2d\u7ec4\u5408\u7279\u5f81CR\u6a21\u578b\u5916\u90e8\u9a8c\u8bc1AUC\u8fbe0.75\uff0c\u7565\u4f18\u4e8e\u4e34\u5e8a\u6216\u5f71\u50cf\u5355\u7279\u5f81\u6a21\u578b\uff1bDL\u6a21\u578b\u8d8b\u52bf\u7c7b\u4f3c\u4f46\u65e0\u7edf\u8ba1\u5b66\u610f\u4e49\uff1b\u90e8\u5206\u5b50\u96c6\u7ec4\u5408\u6a21\u578b\u672a\u4f18\u4e8e\u4e34\u5e8a\u5355\u7279\u5f81\u6a21\u578b\uff1bCR\u6a21\u578b\u63a2\u7d22\u6027\u5206\u6790\u663e\u793a\u5f71\u50cf\u6570\u636e\u6709\u4e00\u5b9a\u76f8\u5173\u6027\u3002", "conclusion": "\u591a\u4e2d\u5fc3\u7814\u7a76\u786e\u8ba4\u89e3\u5256MRI\u5e8f\u5217\u5bf9\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\u6709\u9884\u6d4b\u4ef7\u503c\uff0c\u4f46\u6807\u51c6CR\u548cDL\u653e\u5c04\u7ec4\u5b66\u65b9\u6cd5\u76f8\u6bd4\u4eba\u53e3\u7edf\u8ba1\u5b66\u9884\u6d4b\u56e0\u5b50\u9644\u52a0\u4ef7\u503c\u6781\u5c0f\u3002"}}
{"id": "2507.14242", "pdf": "https://arxiv.org/pdf/2507.14242", "abs": "https://arxiv.org/abs/2507.14242", "authors": ["Prerana Khatiwada", "Grace Donaher", "Jasymyn Navarro", "Lokesh Bhatta"], "title": "Culling Misinformation from Gen AI: Toward Ethical Curation and Refinement", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "7 pages", "summary": "While Artificial Intelligence (AI) is not a new field, recent developments,\nespecially with the release of generative tools like ChatGPT, have brought it\nto the forefront of the minds of industry workers and academic folk alike.\nThere is currently much talk about AI and its ability to reshape many everyday\nprocesses as we know them through automation. It also allows users to expand\ntheir ideas by suggesting things they may not have thought of on their own and\nprovides easier access to information. However, not all of the changes this\ntechnology will bring or has brought so far are positive; this is why it is\nextremely important for all modern people to recognize and understand the risks\nbefore using these tools and allowing them to cause harm. This work takes a\nposition on better understanding many equity concerns and the spread of\nmisinformation that result from new AI, in this case, specifically ChatGPT and\ndeepfakes, and encouraging collaboration with law enforcement, developers, and\nusers to reduce harm. Considering many academic sources, it warns against these\nissues, analyzing their cause and impact in fields including healthcare,\neducation, science, academia, retail, and finance. Lastly, we propose a set of\nfuture-facing guidelines and policy considerations to solve these issues while\nstill enabling innovation in these fields, this responsibility falling upon\nusers, developers, and government entities.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51faAI\u53d1\u5c55\u5e26\u6765\u53d8\u9769\uff0c\u4f46\u4e5f\u6709\u98ce\u9669\u3002\u63a2\u8ba8ChatGPT\u548c\u6df1\u5ea6\u4f2a\u9020\u5f15\u53d1\u7684\u516c\u5e73\u6027\u4e0e\u865a\u5047\u4fe1\u606f\u95ee\u9898\uff0c\u5206\u6790\u5176\u5728\u591a\u9886\u57df\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u89e3\u51b3\u95ee\u9898\u7684\u6307\u5357\u548c\u653f\u7b56\u5efa\u8bae\u3002", "motivation": "\u8ba4\u8bc6\u5e76\u7406\u89e3\u65b0AI\u6280\u672f\u5e26\u6765\u7684\u98ce\u9669\uff0c\u51cf\u5c11\u5176\u53ef\u80fd\u9020\u6210\u7684\u5371\u5bb3\u3002", "method": "\u53c2\u8003\u4f17\u591a\u5b66\u672f\u8d44\u6e90\uff0c\u5206\u6790\u65b0AI\u6280\u672f\u5f15\u53d1\u95ee\u9898\u7684\u539f\u56e0\u548c\u5f71\u54cd\u3002", "result": "\u5206\u6790\u4e86\u65b0AI\u6280\u672f\u5728\u533b\u7597\u3001\u6559\u80b2\u3001\u79d1\u5b66\u3001\u5b66\u672f\u3001\u96f6\u552e\u548c\u91d1\u878d\u7b49\u9886\u57df\u5e26\u6765\u7684\u95ee\u9898\u3002", "conclusion": "\u5efa\u8bae\u7528\u6237\u3001\u5f00\u53d1\u8005\u548c\u653f\u5e9c\u5408\u4f5c\uff0c\u9075\u5faa\u672a\u6765\u5bfc\u5411\u7684\u6307\u5357\u548c\u653f\u7b56\uff0c\u5728\u89e3\u51b3\u95ee\u9898\u7684\u540c\u65f6\u63a8\u52a8\u76f8\u5173\u9886\u57df\u521b\u65b0\u3002"}}
{"id": "2507.15550", "pdf": "https://arxiv.org/pdf/2507.15550", "abs": "https://arxiv.org/abs/2507.15550", "authors": ["Yimeng Chen", "Piotr Pi\u0229kos", "Mateusz Ostaszewski", "Firas Laakom", "J\u00fcrgen Schmidhuber"], "title": "PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors", "categories": ["cs.LG", "cs.AI", "physics.soc-ph"], "comment": "31 Pages", "summary": "Evaluating the scientific discovery capabilities of large language model\nbased agents, particularly how they cope with varying environmental complexity\nand utilize prior knowledge, requires specialized benchmarks currently lacking\nin the landscape. To address this gap, we introduce PhysGym, a novel benchmark\nsuite and simulation platform for rigorously assessing LLM-based scientific\nreasoning in interactive physics environments. PhysGym's primary contribution\nlies in its sophisticated control over the level of prior knowledge provided to\nthe agent. This allows researchers to dissect agent performance along axes\nincluding the complexity of the problem and the prior knowledge levels. The\nbenchmark comprises a suite of interactive simulations, where agents must\nactively probe environments, gather data sequentially under constraints and\nformulate hypotheses about underlying physical laws. PhysGym provides\nstandardized evaluation protocols and metrics for assessing hypothesis accuracy\nand model fidelity. We demonstrate the benchmark's utility by presenting\nresults from baseline LLMs, showcasing its ability to differentiate\ncapabilities based on varying priors and task complexity.", "AI": {"tldr": "\u5f15\u5165\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u4e92\u5f0f\u7269\u7406\u73af\u5883\u4e2d\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u7684PhysGym\u57fa\u51c6\u5957\u4ef6\u548c\u6a21\u62df\u5e73\u53f0\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u53d1\u73b0\u80fd\u529b\u65b9\u9762\uff08\u5e94\u5bf9\u73af\u5883\u590d\u6742\u6027\u548c\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\uff09\u7684\u4e13\u95e8\u57fa\u51c6\uff0c\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e00\u7cfb\u5217\u4ea4\u4e92\u5f0f\u6a21\u62df\u7684PhysGym\uff0c\u53ef\u63a7\u5236\u63d0\u4f9b\u7ed9\u667a\u80fd\u4f53\u7684\u5148\u9a8c\u77e5\u8bc6\u6c34\u5e73\uff0c\u6709\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\u548c\u6307\u6807\u3002", "result": "\u901a\u8fc7\u57fa\u7ebf\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bd5\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u8be5\u57fa\u51c6\u80fd\u591f\u6839\u636e\u4e0d\u540c\u5148\u9a8c\u77e5\u8bc6\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u533a\u5206\u6a21\u578b\u80fd\u529b\u3002", "conclusion": "PhysGym\u57fa\u51c6\u5957\u4ef6\u548c\u6a21\u62df\u5e73\u53f0\u5bf9\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u4e92\u5f0f\u7269\u7406\u73af\u5883\u4e2d\u7684\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u5177\u6709\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.15566", "pdf": "https://arxiv.org/pdf/2507.15566", "abs": "https://arxiv.org/abs/2507.15566", "authors": ["Pieter Smet", "Martina Doneda", "Ettore Lanzarone", "Giuliana Carello"], "title": "Trade-offs between elective surgery rescheduling and length-of-stay prediction accuracy", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "The availability of downstream resources plays a critical role in planning\nthe admission of patients undergoing elective surgery, with inpatient beds\nbeing one of the most crucial resources. When planning patient admissions,\npredictions on their length-of-stay (LOS) made by machine learning (ML) models\nare used to ensure bed availability. However, the actual LOS for each patient\nmay differ considerably from the predicted value, potentially making the\nschedule infeasible. To address such infeasibilities, rescheduling strategies\nthat take advantage of operational flexibility can be implemented. For example,\nadjustments may include postponing admission dates, relocating patients to\ndifferent wards, or even transferring patients who are already admitted. The\ncommon assumption is that more accurate LOS predictions reduce the impact of\nrescheduling. However, training ML models that can make such accurate\npredictions can be costly. Building on previous work that proposed simulated\n\\ac{ml} for evaluating data-driven approaches, this paper explores the\nrelationship between LOS prediction accuracy and rescheduling flexibility\nacross various corrective policies. Specifically, we examine the most effective\npatient rescheduling strategies under LOS prediction errors to prevent bed\noverflows while optimizing resource utilization.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4f4f\u9662\u65f6\u957f\uff08LOS\uff09\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u91cd\u65b0\u8c03\u5ea6\u7075\u6d3b\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u7814\u7a76\u5728LOS\u9884\u6d4b\u8bef\u5dee\u4e0b\u6700\u6709\u6548\u7684\u60a3\u8005\u91cd\u65b0\u8c03\u5ea6\u7b56\u7565\u4ee5\u9632\u6b62\u5e8a\u4f4d\u6ea2\u51fa\u5e76\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002", "motivation": "\u5728\u62e9\u671f\u624b\u672f\u60a3\u8005\u5165\u9662\u89c4\u5212\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u7684LOS\u4e0e\u5b9e\u9645\u503c\u53ef\u80fd\u6709\u8f83\u5927\u5dee\u5f02\uff0c\u5bfc\u81f4\u539f\u8ba1\u5212\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u91cd\u65b0\u8c03\u5ea6\u7b56\u7565\uff0c\u4e14\u51c6\u786e\u7684LOS\u9884\u6d4b\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u8981\u7814\u7a76\u4e24\u8005\u5173\u7cfb\u3002", "method": "\u57fa\u4e8e\u4e4b\u524d\u63d0\u51fa\u7684\u6a21\u62dfML\u8bc4\u4f30\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u5de5\u4f5c\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2507.14248", "pdf": "https://arxiv.org/pdf/2507.14248", "abs": "https://arxiv.org/abs/2507.14248", "authors": ["Eldor Abdukhamidov", "Mohammed Abuhamad", "Simon S. Woo", "Hyoungshick Kim", "Tamer Abuhmed"], "title": "Breaking the Illusion of Security via Interpretation: Interpretable Vision Transformer Systems under Attack", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG", "I.2.10; I.2.6; I.5.1; D.4.6; K.6.5"], "comment": null, "summary": "Vision transformer (ViT) models, when coupled with interpretation models, are\nregarded as secure and challenging to deceive, making them well-suited for\nsecurity-critical domains such as medical applications, autonomous vehicles,\ndrones, and robotics. However, successful attacks on these systems can lead to\nsevere consequences. Recent research on threats targeting ViT models primarily\nfocuses on generating the smallest adversarial perturbations that can deceive\nthe models with high confidence, without considering their impact on model\ninterpretations. Nevertheless, the use of interpretation models can effectively\nassist in detecting adversarial examples. This study investigates the\nvulnerability of transformer models to adversarial attacks, even when combined\nwith interpretation models. We propose an attack called \"AdViT\" that generates\nadversarial examples capable of misleading both a given transformer model and\nits coupled interpretation model. Through extensive experiments on various\ntransformer models and two transformer-based interpreters, we demonstrate that\nAdViT achieves a 100% attack success rate in both white-box and black-box\nscenarios. In white-box scenarios, it reaches up to 98% misclassification\nconfidence, while in black-box scenarios, it reaches up to 76%\nmisclassification confidence. Remarkably, AdViT consistently generates accurate\ninterpretations in both scenarios, making the adversarial examples more\ndifficult to detect.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faAdViT\u653b\u51fb\uff0c\u53ef\u8bef\u5bfcViT\u6a21\u578b\u53ca\u5176\u89e3\u91ca\u6a21\u578b\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u767d\u76d2\u548c\u9ed1\u76d2\u573a\u666f\u6709\u9ad8\u6210\u529f\u7387\u548c\u7f6e\u4fe1\u5ea6\uff0c\u4e14\u751f\u6210\u89e3\u91ca\u96be\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u9488\u5bf9ViT\u6a21\u578b\u5a01\u80c1\u7814\u7a76\u672a\u8003\u8651\u5bf9\u6a21\u578b\u89e3\u91ca\u7684\u5f71\u54cd\uff0c\u800c\u89e3\u91ca\u6a21\u578b\u53ef\u8f85\u52a9\u68c0\u6d4b\u5bf9\u6297\u6837\u672c\uff0c\u9700\u7814\u7a76\u5176\u7ed3\u5408\u89e3\u91ca\u6a21\u578b\u65f6\u7684\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51faAdViT\u653b\u51fb\u65b9\u6cd5\u751f\u6210\u80fd\u8bef\u5bfc\u6a21\u578b\u548c\u89e3\u91ca\u6a21\u578b\u7684\u5bf9\u6297\u6837\u672c\u3002", "result": "\u5728\u591a\u79cd\u53d8\u538b\u5668\u6a21\u578b\u548c\u4e24\u4e2a\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u89e3\u91ca\u5668\u4e0a\u5b9e\u9a8c\uff0cAdViT\u5728\u767d\u76d2\u548c\u9ed1\u76d2\u573a\u666f\u653b\u51fb\u6210\u529f\u7387\u8fbe100%\uff0c\u767d\u76d2\u573a\u666f\u8bef\u5206\u7c7b\u7f6e\u4fe1\u5ea6\u8fbe98%\uff0c\u9ed1\u76d2\u573a\u666f\u8fbe76%\uff0c\u4e14\u80fd\u751f\u6210\u51c6\u786e\u89e3\u91ca\u3002", "conclusion": "AdViT\u653b\u51fb\u5c55\u793a\u4e86\u53d8\u538b\u5668\u6a21\u578b\u7ed3\u5408\u89e3\u91ca\u6a21\u578b\u65f6\u4ecd\u5b58\u5728\u6613\u53d7\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2507.15574", "pdf": "https://arxiv.org/pdf/2507.15574", "abs": "https://arxiv.org/abs/2507.15574", "authors": ["Gregory F. Stock", "Juan A. Fraire", "Holger Hermanns", "J\u0119drzej Mosi\u0119\u017cny", "Yusra Al-Khazraji", "Julio Ram\u00edrez Molina", "Evridiki V. Ntagiou"], "title": "On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project", "categories": ["cs.LG", "cs.AI"], "comment": "18th International Conference on Space Operations (SpaceOps 2025),\n  Montr\\'eal, Canada, 26-30 May 2025,\n  https://star.spaceops.org/2025/user_manudownload.php?doc=140__9bg48dkf.pdf", "summary": "The rapid expansion of satellite constellations in near-Earth orbits presents\nsignificant challenges in satellite network management, requiring innovative\napproaches for efficient, scalable, and resilient operations. This paper\nexplores the role of Artificial Intelligence (AI) in optimizing the operation\nof satellite mega-constellations, drawing from the ConstellAI project funded by\nthe European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland\nUniversity, and Thales Alenia Space collaborates to develop AI-driven\nalgorithms and demonstrates their effectiveness over traditional methods for\ntwo crucial operational challenges: data routing and resource allocation. In\nthe routing use case, Reinforcement Learning (RL) is used to improve the\nend-to-end latency by learning from historical queuing latency, outperforming\nclassical shortest path algorithms. For resource allocation, RL optimizes the\nscheduling of tasks across constellations, focussing on efficiently using\nlimited resources such as battery and memory. Both use cases were tested for\nmultiple satellite constellation configurations and operational scenarios,\nresembling the real-life spacecraft operations of communications and Earth\nobservation satellites. This research demonstrates that RL not only competes\nwith classical approaches but also offers enhanced flexibility, scalability,\nand generalizability in decision-making processes, which is crucial for the\nautonomous and intelligent management of satellite fleets. The findings of this\nactivity suggest that AI can fundamentally alter the landscape of satellite\nconstellation management by providing more adaptive, robust, and cost-effective\nsolutions.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eConstellAI\u9879\u76ee\uff0c\u63a2\u7d22AI\u4f18\u5316\u536b\u661f\u5de8\u578b\u661f\u5ea7\u8fd0\u8425\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u6570\u636e\u8def\u7531\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u8bc1\u660eAI\u5728\u536b\u661f\u661f\u5ea7\u7ba1\u7406\u4e2d\u6709\u4f18\u52bf\u3002", "motivation": "\u8fd1\u5730\u8f68\u9053\u536b\u661f\u661f\u5ea7\u5feb\u901f\u6269\u5f20\uff0c\u536b\u661f\u7f51\u7edc\u7ba1\u7406\u9700\u521b\u65b0\u65b9\u6cd5\u3002", "method": "\u7531GMV GmbH\u3001Saarland\u5927\u5b66\u548cThales Alenia Space\u7ec4\u6210\u7684\u8054\u76df\u5f00\u53d1AI\u9a71\u52a8\u7b97\u6cd5\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u6570\u636e\u8def\u7531\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u5728\u6570\u636e\u8def\u7531\u4e0a\u964d\u4f4e\u7aef\u5230\u7aef\u5ef6\u8fdf\uff0c\u5728\u8d44\u6e90\u5206\u914d\u4e0a\u4f18\u5316\u4efb\u52a1\u8c03\u5ea6\uff0c\u5728\u591a\u79cd\u536b\u661f\u661f\u5ea7\u914d\u7f6e\u548c\u573a\u666f\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "AI\u80fd\u4e3a\u536b\u661f\u661f\u5ea7\u7ba1\u7406\u63d0\u4f9b\u66f4\u81ea\u9002\u5e94\u3001\u7a33\u5065\u548c\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u6539\u53d8\u536b\u661f\u661f\u5ea7\u7ba1\u7406\u683c\u5c40\u3002"}}
{"id": "2507.14249", "pdf": "https://arxiv.org/pdf/2507.14249", "abs": "https://arxiv.org/abs/2507.14249", "authors": ["Yuejiao Xie", "Maonan Wang", "Di Zhou", "Man-On Pun", "Zhu Han"], "title": "Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions\nto alleviate urban congestion, with path planning becoming a key focus area.\nUnlike ground transportation, UAM trajectory planning has to prioritize\ncommunication quality for accurate location tracking in constantly changing\nenvironments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,\nrequires adaptive planning to respond to real-time passenger requests,\nespecially in ride-sharing scenarios where passenger demands are unpredictable\nand dynamic. However, conventional trajectory planning strategies based on\npredefined routes lack the flexibility to meet varied passenger ride demands.\nTo address these challenges, this work first proposes constructing a radio map\nto evaluate the communication quality of urban airspace. Building on this, we\nintroduce a novel Multi-Source Hybrid Attention Reinforcement Learning\n(MSHA-RL) framework for the challenge of effectively focusing on passengers and\nUAM locations, which arises from the significant dimensional disparity between\nthe representations. This model first generates the alignment among diverse\ndata sources with large gap dimensions before employing hybrid attention to\nbalance global and local insights, thereby facilitating responsive, real-time\npath planning. Extensive experimental results demonstrate that the approach\nenables communication-compliant trajectory planning, reducing travel time and\nenhancing operational efficiency while prioritizing passenger safety.", "AI": {"tldr": "\u9488\u5bf9\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a\uff08UAM\uff09\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u63d0\u51fa\u6784\u5efa\u65e0\u7ebf\u7535\u5730\u56fe\u8bc4\u4f30\u901a\u4fe1\u8d28\u91cf\uff0c\u5e76\u5f15\u5165MSHA - RL\u6846\u67b6\u5b9e\u73b0\u5b9e\u65f6\u8def\u5f84\u89c4\u5212\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u63d0\u5347\u6548\u7387\u548c\u4fdd\u969c\u5b89\u5168\u3002", "motivation": "UAM\u8f68\u8ff9\u89c4\u5212\u9700\u4f18\u5148\u8003\u8651\u901a\u4fe1\u8d28\u91cf\u4fdd\u969c\u5b89\u5168\uff0c\u4e14\u8981\u9002\u5e94\u5b9e\u65f6\u4e58\u5ba2\u9700\u6c42\uff0c\u4f46\u4f20\u7edf\u7b56\u7565\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "\u5148\u6784\u5efa\u65e0\u7ebf\u7535\u5730\u56fe\u8bc4\u4f30\u901a\u4fe1\u8d28\u91cf\uff0c\u518d\u5f15\u5165MSHA - RL\u6846\u67b6\uff0c\u5148\u5bf9\u9f50\u4e0d\u540c\u6570\u636e\u6e90\uff0c\u518d\u7528\u6df7\u5408\u6ce8\u610f\u529b\u5e73\u8861\u5168\u5c40\u548c\u5c40\u90e8\u4fe1\u606f\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7b26\u5408\u901a\u4fe1\u8981\u6c42\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u51cf\u5c11\u4e86\u65c5\u884c\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e86\u8fd0\u8425\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u5728\u4fdd\u969c\u4e58\u5ba2\u5b89\u5168\u7684\u540c\u65f6\uff0c\u6709\u6548\u89e3\u51b3UAM\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\u3002"}}
{"id": "2507.15584", "pdf": "https://arxiv.org/pdf/2507.15584", "abs": "https://arxiv.org/abs/2507.15584", "authors": ["Philipp R\u00f6chner", "Simon Kl\u00fcttermann", "Franz Rothlauf", "Daniel Schl\u00f6r"], "title": "We Need to Rethink Benchmarking in Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Despite the continuous proposal of new anomaly detection algorithms and\nextensive benchmarking efforts, progress seems to stagnate, with only minor\nperformance differences between established baselines and new algorithms. In\nthis position paper, we argue that this stagnation is due to limitations in how\nwe evaluate anomaly detection algorithms. Current benchmarking does not, for\nexample, sufficiently reflect the diversity of anomalies in applications\nranging from predictive maintenance to scientific discovery. Consequently, we\nneed to rethink benchmarking in anomaly detection. In our opinion, anomaly\ndetection should be studied using scenarios that capture the relevant\ncharacteristics of different applications. We identify three key areas for\nimprovement: First, we need to identify anomaly detection scenarios based on a\ncommon taxonomy. Second, anomaly detection pipelines should be analyzed\nend-to-end and by component. Third, evaluating anomaly detection algorithms\nshould be meaningful regarding the scenario's objectives.", "AI": {"tldr": "\u5f53\u524d\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u8bc4\u4f30\u5b58\u5728\u5c40\u9650\u81f4\u8fdb\u5c55\u505c\u6ede\uff0c\u9700\u91cd\u65b0\u601d\u8003\u57fa\u51c6\u6d4b\u8bd5\u5e76\u63d0\u51fa\u4e09\u65b9\u9762\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u89e3\u51b3\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u8fdb\u5c55\u505c\u6ede\u95ee\u9898\uff0c\u6307\u51fa\u539f\u56e0\u662f\u73b0\u6709\u8bc4\u4f30\u65b9\u5f0f\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u80fd\u53cd\u6620\u4e0d\u540c\u5e94\u7528\u7279\u5f81\u7684\u573a\u666f\u7814\u7a76\u5f02\u5e38\u68c0\u6d4b\uff0c\u786e\u5b9a\u4e09\u65b9\u9762\u6539\u8fdb\uff1a\u57fa\u4e8e\u901a\u7528\u5206\u7c7b\u6cd5\u786e\u5b9a\u573a\u666f\u3001\u7aef\u5230\u7aef\u548c\u6309\u7ec4\u4ef6\u5206\u6790\u68c0\u6d4b\u6d41\u7a0b\u3001\u8bc4\u4f30\u7b97\u6cd5\u8981\u7b26\u5408\u573a\u666f\u76ee\u6807\u3002", "result": "\u65e0\u660e\u786e\u5b9e\u9a8c\u7ed3\u679c\uff0c\u63d0\u51fa\u65b0\u7684\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u601d\u8def\u3002", "conclusion": "\u9700\u91cd\u65b0\u601d\u8003\u5f02\u5e38\u68c0\u6d4b\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u5f0f\uff0c\u4ece\u4e09\u65b9\u9762\u8fdb\u884c\u6539\u8fdb\u3002"}}
{"id": "2507.15587", "pdf": "https://arxiv.org/pdf/2507.15587", "abs": "https://arxiv.org/abs/2507.15587", "authors": ["Yinsong Chen", "Kaifeng Wang", "Xiaoqiang Meng", "Xueyuan Li", "Zirui Li", "Xin Gao"], "title": "Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current research on decision-making in safety-critical scenarios often relies\non inefficient data-driven scenario generation or specific modeling approaches,\nwhich fail to capture corner cases in real-world contexts. To address this\nissue, we propose a Red-Team Multi-Agent Reinforcement Learning framework,\nwhere background vehicles with interference capabilities are treated as\nred-team agents. Through active interference and exploration, red-team vehicles\ncan uncover corner cases outside the data distribution. The framework uses a\nConstraint Graph Representation Markov Decision Process, ensuring that red-team\nvehicles comply with safety rules while continuously disrupting the autonomous\nvehicles (AVs). A policy threat zone model is constructed to quantify the\nthreat posed by red-team vehicles to AVs, inducing more extreme actions to\nincrease the danger level of the scenario. Experimental results show that the\nproposed framework significantly impacts AVs decision-making safety and\ngenerates various corner cases. This method also offers a novel direction for\nresearch in safety-critical scenarios.", "AI": {"tldr": "\u63d0\u51fa\u7ea2\u961f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u5b89\u5168\u5173\u952e\u573a\u666f\u51b3\u7b56\u7814\u7a76\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u5f71\u54cd\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u5b89\u5168\u5e76\u751f\u6210\u591a\u79cd\u6781\u7aef\u60c5\u51b5\u3002", "motivation": "\u5f53\u524d\u5b89\u5168\u5173\u952e\u573a\u666f\u51b3\u7b56\u7814\u7a76\u4f9d\u8d56\u4f4e\u6548\u6570\u636e\u9a71\u52a8\u6216\u7279\u5b9a\u5efa\u6a21\u65b9\u6cd5\uff0c\u65e0\u6cd5\u6355\u6349\u73b0\u5b9e\u4e2d\u7684\u6781\u7aef\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u7ea2\u961f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u6709\u5e72\u6270\u80fd\u529b\u7684\u80cc\u666f\u8f66\u8f86\u4f5c\u4e3a\u7ea2\u961f\u667a\u80fd\u4f53\uff0c\u4f7f\u7528\u7ea6\u675f\u56fe\u8868\u793a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6784\u5efa\u7b56\u7565\u5a01\u80c1\u533a\u6a21\u578b\u3002", "result": "\u8be5\u6846\u67b6\u5bf9\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u5b89\u5168\u6709\u663e\u8457\u5f71\u54cd\uff0c\u80fd\u751f\u6210\u591a\u79cd\u6781\u7aef\u60c5\u51b5\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u4e3a\u5b89\u5168\u5173\u952e\u573a\u666f\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.15601", "pdf": "https://arxiv.org/pdf/2507.15601", "abs": "https://arxiv.org/abs/2507.15601", "authors": ["Huiling Yang", "Zhanwei Wang", "Kaibin Huang"], "title": "Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Federated learning (FL) has emerged as a popular approach for collaborative\nmachine learning in sixth-generation (6G) networks, primarily due to its\nprivacy-preserving capabilities. The deployment of FL algorithms is expected to\nempower a wide range of Internet-of-Things (IoT) applications, e.g., autonomous\ndriving, augmented reality, and healthcare. The mission-critical and\ntime-sensitive nature of these applications necessitates the design of\nlow-latency FL frameworks that guarantee high learning performance. In\npractice, achieving low-latency FL faces two challenges: the overhead of\ncomputing and transmitting high-dimensional model updates, and the\nheterogeneity in communication-and-computation (C$^2$) capabilities across\ndevices. To address these challenges, we propose a novel C$^2$-aware framework\nfor optimal batch-size control that minimizes end-to-end (E2E) learning latency\nwhile ensuring convergence. The framework is designed to balance a fundamental\nC$^2$ tradeoff as revealed through convergence analysis. Specifically,\nincreasing batch sizes improves the accuracy of gradient estimation in FL and\nthus reduces the number of communication rounds required for convergence, but\nresults in higher per-round latency, and vice versa. The associated problem of\nlatency minimization is intractable; however, we solve it by designing an\naccurate and tractable surrogate for convergence speed, with parameters fitted\nto real data. This approach yields two batch-size control strategies tailored\nto scenarios with slow and fast fading, while also accommodating device\nheterogeneity. Extensive experiments using real datasets demonstrate that the\nproposed strategies outperform conventional batch-size adaptation schemes that\ndo not consider the C$^2$ tradeoff or device heterogeneity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u6700\u4f18\u6279\u91cf\u5927\u5c0f\u63a7\u5236\u7684C\u00b2\u611f\u77e5\u6846\u67b6\uff0c\u89e3\u51b3\u4f4e\u5ef6\u8fdf\u8054\u90a6\u5b66\u4e60\u6311\u6218\uff0c\u5b9e\u9a8c\u8868\u660e\u7b56\u7565\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\u3002", "motivation": "6G\u7f51\u7edc\u4e2d\u7269\u8054\u7f51\u5e94\u7528\u5bf9\u4f4e\u5ef6\u8fdf\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u6709\u9700\u6c42\uff0c\u4f46\u5b9e\u9645\u9762\u4e34\u8ba1\u7b97\u4f20\u8f93\u5f00\u9500\u548c\u8bbe\u5907\u5f02\u8d28\u6027\u6311\u6218\u3002", "method": "\u63d0\u51faC\u00b2\u611f\u77e5\u6846\u67b6\u5e73\u8861\u901a\u4fe1\u4e0e\u8ba1\u7b97\u6743\u8861\uff0c\u8bbe\u8ba1\u51c6\u786e\u6613\u5904\u7406\u7684\u6536\u655b\u901f\u5ea6\u66ff\u4ee3\u65b9\u6848\u4ee5\u89e3\u51b3\u5ef6\u8fdf\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5f97\u5230\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\u7684\u6279\u91cf\u5927\u5c0f\u63a7\u5236\u7b56\u7565\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u7b56\u7565\u4f18\u4e8e\u4e0d\u8003\u8651C\u00b2\u6743\u8861\u6216\u8bbe\u5907\u5f02\u8d28\u6027\u7684\u4f20\u7edf\u6279\u91cf\u5927\u5c0f\u81ea\u9002\u5e94\u65b9\u6848\u3002", "conclusion": "\u6240\u63d0\u7684C\u00b2\u611f\u77e5\u6846\u67b6\u53ca\u6279\u91cf\u5927\u5c0f\u63a7\u5236\u7b56\u7565\u80fd\u6709\u6548\u89e3\u51b3\u4f4e\u5ef6\u8fdf\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u7684\u6311\u6218\uff0c\u63d0\u5347\u5b66\u4e60\u6027\u80fd\u3002"}}
{"id": "2507.14263", "pdf": "https://arxiv.org/pdf/2507.14263", "abs": "https://arxiv.org/abs/2507.14263", "authors": ["Ramesh Raskar", "Pradyumna Chari", "John Zinky", "Mahesh Lambe", "Jared James Grogan", "Sichao Wang", "Rajesh Ranjan", "Rekha Singhal", "Shailja Gupta", "Robert Lincourt", "Raghu Bala", "Aditi Joshi", "Abhishek Singh", "Ayush Chopra", "Dimitris Stripelis", "Bhuwan B", "Sumit Kumar", "Maria Gorskikh"], "title": "Beyond DNS: Unlocking the Internet of AI Agents via the NANDA Index and Verified AgentFacts", "categories": ["cs.NI", "cs.AI", "cs.CR", "cs.MA"], "comment": null, "summary": "The Internet is poised to host billions to trillions of autonomous AI agents\nthat negotiate, delegate, and migrate in milliseconds and workloads that will\nstrain DNS-centred identity and discovery. In this paper, we describe the NANDA\nindex architecture, which we envision as a means for discoverability,\nidentifiability and authentication in the internet of AI agents. We present an\narchitecture where a minimal lean index resolves to dynamic, cryptographically\nverifiable AgentFacts that supports multi-endpoint routing, load balancing,\nprivacy-preserving access, and credentialed capability assertions. Our\narchitecture design delivers five concrete guarantees: (1) A quilt-like index\nproposal that supports both NANDA-native agents as well as third party agents\nbeing discoverable via the index, (2) rapid global resolution for newly spawned\nAI agents, (3) sub-second revocation and key rotation, (4) schema-validated\ncapability assertions, and (5) privacy-preserving discovery across\norganisational boundaries via verifiable, least-disclosure queries. We\nformalize the AgentFacts schema, specify a CRDT-based update protocol, and\nprototype adaptive resolvers. The result is a lightweight, horizontally\nscalable foundation that unlocks secure, trust-aware collaboration for the next\ngeneration of the Internet of AI agents, without abandoning existing web\ninfrastructure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNANDA\u7d22\u5f15\u67b6\u6784\uff0c\u4e3aAI\u667a\u80fd\u4f53\u4e92\u8054\u7f51\u63d0\u4f9b\u53ef\u53d1\u73b0\u6027\u3001\u53ef\u8bc6\u522b\u6027\u548c\u8ba4\u8bc1\u529f\u80fd\uff0c\u6709\u4e94\u9879\u4fdd\u8bc1\uff0c\u6784\u5efa\u8f7b\u91cf\u7ea7\u53ef\u6269\u5c55\u57fa\u7840\u3002", "motivation": "\u4e92\u8054\u7f51\u5c06\u627f\u8f7d\u5927\u91cf\u81ea\u4e3bAI\u667a\u80fd\u4f53\uff0c\u4ee5DNS\u4e3a\u4e2d\u5fc3\u7684\u8eab\u4efd\u548c\u53d1\u73b0\u673a\u5236\u96be\u4ee5\u5e94\u5bf9\u5176\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u9700\u8981\u65b0\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u6700\u5c0f\u5316\u7cbe\u7b80\u7d22\u5f15\u89e3\u6790\u4e3a\u52a8\u6001\u3001\u53ef\u52a0\u5bc6\u9a8c\u8bc1\u7684AgentFacts\u7684\u67b6\u6784\uff0c\u5f62\u5f0f\u5316AgentFacts\u6a21\u5f0f\uff0c\u6307\u5b9a\u57fa\u4e8eCRDT\u7684\u66f4\u65b0\u534f\u8bae\uff0c\u5f00\u53d1\u81ea\u9002\u5e94\u89e3\u6790\u5668\u539f\u578b\u3002", "result": "\u5b9e\u73b0\u4e94\u9879\u5177\u4f53\u4fdd\u8bc1\uff0c\u6784\u5efa\u8f7b\u91cf\u7ea7\u3001\u6c34\u5e73\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002", "conclusion": "\u8be5\u67b6\u6784\u53ef\u5728\u4e0d\u653e\u5f03\u73b0\u6709\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u667a\u80fd\u4f53\u4e92\u8054\u7f51\u5b9e\u73b0\u5b89\u5168\u3001\u4fe1\u4efb\u611f\u77e5\u7684\u534f\u4f5c\u3002"}}
{"id": "2507.15614", "pdf": "https://arxiv.org/pdf/2507.15614", "abs": "https://arxiv.org/abs/2507.15614", "authors": ["Edward Holmberg", "Pujan Pokhrel", "Maximilian Zoch", "Elias Ioup", "Ken Pathak", "Steven Sloan", "Kendall Niles", "Jay Ratcliff", "Maik Flanagin", "Christian Guetl", "Julian Simeonov", "Mahdi Abdelguerfi"], "title": "Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 8 figures", "summary": "Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but\nare too computationally intensive for on-the-fly decision-making during flood\nevents. The central challenge is to accelerate these simulations without\nsacrificing accuracy. This paper introduces a deep learning surrogate that\ntreats HEC-RAS not as a solver but as a data-generation engine. We propose a\nhybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU)\nto capture short-term temporal dynamics with a Geometry-Aware Fourier Neural\nOperator (Geo-FNO) to model long-range spatial dependencies along a river\nreach. The model learns underlying physics implicitly from a minimal\neight-channel feature vector encoding dynamic state, static geometry, and\nboundary forcings extracted directly from native HEC-RAS files. Trained on 67\nreaches of the Mississippi River Basin, the surrogate was evaluated on a\nyear-long, unseen hold-out simulation. Results show the model achieves a strong\npredictive accuracy, with a median absolute stage error of 0.31 feet.\nCritically, for a full 67-reach ensemble forecast, our surrogate reduces the\nrequired wall-clock time from 139 minutes to 40 minutes, a speedup of nearly\n3.5 times over the traditional solver. The success of this data-driven approach\ndemonstrates that robust feature engineering can produce a viable, high-speed\nreplacement for conventional hydraulic models, improving the computational\nfeasibility of large-scale ensemble flood forecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u52a0\u901f\u6d2a\u6c34\u6a21\u62df\uff0c\u5728\u5bc6\u897f\u897f\u6bd4\u6cb3\u6d41\u57df\u53d6\u5f97\u826f\u597d\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u57fa\u4e8e\u7269\u7406\u7684\u6c42\u89e3\u5668\u8ba1\u7b97\u5bc6\u96c6\uff0c\u96be\u4ee5\u7528\u4e8e\u6d2a\u6c34\u5b9e\u65f6\u51b3\u7b56\uff0c\u9700\u5728\u4e0d\u727a\u7272\u7cbe\u5ea6\u4e0b\u52a0\u901f\u6a21\u62df\u3002", "method": "\u63d0\u51fa\u7ed3\u5408GRU\u548cGeo - FNO\u7684\u6df7\u5408\u81ea\u56de\u5f52\u67b6\u6784\uff0c\u4eceHEC - RAS\u6587\u4ef6\u63d0\u53d6\u7279\u5f81\u5411\u91cf\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u4e2d\u4f4d\u7edd\u5bf9\u6c34\u4f4d\u8bef\u5dee0.31\u82f1\u5c3a\uff0c67\u6cb3\u6bb5\u96c6\u5408\u9884\u62a5\u52a0\u901f\u8fd13.5\u500d\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u53ef\u884c\uff0c\u7279\u5f81\u5de5\u7a0b\u80fd\u66ff\u4ee3\u4f20\u7edf\u6c34\u529b\u6a21\u578b\uff0c\u63d0\u5347\u5927\u89c4\u6a21\u96c6\u5408\u6d2a\u6c34\u9884\u62a5\u8ba1\u7b97\u53ef\u884c\u6027\u3002"}}
{"id": "2507.14266", "pdf": "https://arxiv.org/pdf/2507.14266", "abs": "https://arxiv.org/abs/2507.14266", "authors": ["Bo Yuan", "Jiazi Hu"], "title": "Bridging MOOCs, Smart Teaching, and AI: A Decade of Evolution Toward a Unified Pedagogy", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Over the past decade, higher education has evolved through three distinct\nparadigms: the emergence of Massive Open Online Courses (MOOCs), the\nintegration of Smart Teaching technologies into classrooms, and the rise of\nAI-enhanced learning. Each paradigm is intended to address specific challenges\nin traditional education: MOOCs enable ubiquitous access to learning resources;\nSmart Teaching supports real-time interaction with data-driven insights; and\ngenerative AI offers personalized feedback and on-demand content generation.\nHowever, these paradigms are often implemented in isolation due to their\ndisparate technological origins and policy-driven adoption. This paper examines\nthe origins, strengths, and limitations of each paradigm, and advocates a\nunified pedagogical perspective that synthesizes their complementary\naffordances. We propose a three-layer instructional framework that combines the\nscalability of MOOCs, the responsiveness of Smart Teaching, and the adaptivity\nof AI. To demonstrate its feasibility, we present a curriculum design for a\nproject-based course. The findings highlight the framework's potential to\nenhance learner engagement, support instructors, and enable personalized yet\nscalable learning.", "AI": {"tldr": "\u6587\u7ae0\u56de\u987e\u9ad8\u6559\u4e09\u79cd\u8303\u5f0f\uff0c\u5206\u6790\u5176\u4f18\u52a3\uff0c\u63d0\u51fa\u4e09\u5c42\u6559\u5b66\u6846\u67b6\u5e76\u4ee5\u8bfe\u7a0b\u8bbe\u8ba1\u5c55\u793a\u53ef\u884c\u6027\uff0c\u6846\u67b6\u53ef\u63d0\u5347\u5b66\u4e60\u4f53\u9a8c\u3002", "motivation": "\u4e09\u79cd\u9ad8\u6559\u8303\u5f0f\u56e0\u6280\u672f\u548c\u653f\u7b56\u539f\u56e0\u5b64\u7acb\u5b9e\u65bd\uff0c\u9700\u7edf\u4e00\u6559\u5b66\u89c6\u89d2\u3002", "method": "\u5206\u6790\u5404\u8303\u5f0f\u8d77\u6e90\u3001\u4f18\u7f3a\u70b9\uff0c\u63d0\u51fa\u4e09\u5c42\u6559\u5b66\u6846\u67b6\uff0c\u5e76\u7ed9\u51fa\u9879\u76ee\u8bfe\u7a0b\u7684\u8bfe\u7a0b\u8bbe\u8ba1\u3002", "result": "\u6240\u63d0\u6846\u67b6\u80fd\u63d0\u5347\u5b66\u4e60\u8005\u53c2\u4e0e\u5ea6\u3001\u652f\u6301\u6559\u5e08\u5e76\u5b9e\u73b0\u4e2a\u6027\u5316\u4e14\u53ef\u6269\u5c55\u7684\u5b66\u4e60\u3002", "conclusion": "\u5e94\u91c7\u7528\u7edf\u4e00\u7684\u6559\u5b66\u89c6\u89d2\uff0c\u7ed3\u5408\u4e09\u79cd\u8303\u5f0f\u4f18\u52bf\u7684\u6846\u67b6\u5177\u6709\u53ef\u884c\u6027\u548c\u79ef\u6781\u6548\u679c\u3002"}}
{"id": "2507.15640", "pdf": "https://arxiv.org/pdf/2507.15640", "abs": "https://arxiv.org/abs/2507.15640", "authors": ["Kailai Yang", "Xiao Liu", "Lei Ji", "Hao Li", "Yeyun Gong", "Peng Cheng", "Mao Yang"], "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Continual pre-training on small-scale task-specific data is an effective\nmethod for improving large language models in new target fields, yet it risks\ncatastrophic forgetting of their original capabilities. A common solution is to\nre-weight training data mixtures from source and target fields on a domain\nspace to achieve balanced performance. Previous domain reweighting strategies\nrely on manual designation with certain heuristics based on human intuition or\nempirical results. In this work, we prove that more general heuristics can be\nparameterized by proposing Data Mixing Agent, the first model-based, end-to-end\nframework that learns to re-weight domains. The agent learns generalizable\nheuristics through reinforcement learning on large quantities of data mixing\ntrajectories with corresponding feedback from an evaluation environment.\nExperiments in continual pre-training on math reasoning show that Data Mixing\nAgent outperforms strong baselines in achieving balanced performance across\nsource and target field benchmarks. Furthermore, it generalizes well across\nunseen source fields, target models, and domain spaces without retraining.\nDirect application to the code generation field also indicates its adaptability\nacross target domains. Further analysis showcases the agents' well-aligned\nheuristics with human intuitions and their efficiency in achieving superior\nmodel performance with less source-field data.", "AI": {"tldr": "\u63d0\u51faData Mixing Agent\u6846\u67b6\u5b66\u4e60\u9886\u57df\u91cd\u52a0\u6743\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u9886\u57df\u5b9e\u9a8c\u6548\u679c\u597d\u4e14\u6cdb\u5316\u6027\u5f3a\u3002", "motivation": "\u6301\u7eed\u9884\u8bad\u7ec3\u6709\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4ee5\u5f80\u9886\u57df\u91cd\u52a0\u6743\u7b56\u7565\u4f9d\u8d56\u4eba\u5de5\u6307\u5b9a\uff0c\u9700\u66f4\u901a\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u7aef\u5230\u7aefData Mixing Agent\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u53ef\u6cdb\u5316\u542f\u53d1\u5f0f\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u57fa\u7ebf\uff0c\u8de8\u672a\u89c1\u6e90\u9886\u57df\u3001\u76ee\u6807\u6a21\u578b\u548c\u9886\u57df\u7a7a\u95f4\u6cdb\u5316\u6027\u597d\uff0c\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u4e5f\u6709\u9002\u5e94\u6027\u3002", "conclusion": "Data Mixing Agent\u6846\u67b6\u6709\u6548\uff0c\u542f\u53d1\u5f0f\u4e0e\u4eba\u7c7b\u76f4\u89c9\u4e00\u81f4\uff0c\u80fd\u4ee5\u66f4\u5c11\u6e90\u9886\u57df\u6570\u636e\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.15643", "pdf": "https://arxiv.org/pdf/2507.15643", "abs": "https://arxiv.org/abs/2507.15643", "authors": ["Elnur Isgandarov", "Matteo Cederle", "Federico Chiariotti", "Gian Antonio Susto"], "title": "Towards Explainable Anomaly Detection in Shared Mobility Systems", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 8 figures. Paper accepted to J3C 2025 (Joint Conference on\n  Computers, Cognition and Communication", "summary": "Shared mobility systems, such as bike-sharing networks, play a crucial role\nin urban transportation. Identifying anomalies in these systems is essential\nfor optimizing operations, improving service reliability, and enhancing user\nexperience. This paper presents an interpretable anomaly detection framework\nthat integrates multi-source data, including bike-sharing trip records, weather\nconditions, and public transit availability. The Isolation Forest algorithm is\nemployed for unsupervised anomaly detection, along with the Depth-based\nIsolation Forest Feature Importance (DIFFI) algorithm providing\ninterpretability. Results show that station-level analysis offers a robust\nunderstanding of anomalies, highlighting the influence of external factors such\nas adverse weather and limited transit availability. Our findings contribute to\nimproving decision-making in shared mobility operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53ef\u89e3\u91ca\u7684\u5171\u4eab\u51fa\u884c\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u7b97\u6cd5\u68c0\u6d4b\u5f02\u5e38\uff0c\u7ed3\u679c\u663e\u793a\u7ad9\u70b9\u7ea7\u5206\u6790\u6709\u7528\uff0c\u52a9\u4e8e\u8fd0\u8425\u51b3\u7b56\u3002", "motivation": "\u8bc6\u522b\u5171\u4eab\u51fa\u884c\u7cfb\u7edf\uff08\u5982\u5171\u4eab\u5355\u8f66\u7f51\u7edc\uff09\u7684\u5f02\u5e38\uff0c\u4ee5\u4f18\u5316\u8fd0\u8425\u3001\u63d0\u9ad8\u670d\u52a1\u53ef\u9760\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u591a\u6e90\u6570\u636e\u7684\u53ef\u89e3\u91ca\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u4f7f\u7528Isolation Forest\u7b97\u6cd5\u8fdb\u884c\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\uff0c\u7528DIFFI\u7b97\u6cd5\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u7ad9\u70b9\u7ea7\u5206\u6790\u80fd\u66f4\u597d\u7406\u89e3\u5f02\u5e38\uff0c\u51f8\u663e\u6076\u52a3\u5929\u6c14\u548c\u516c\u5171\u4ea4\u901a\u53ef\u7528\u6027\u7b49\u5916\u90e8\u56e0\u7d20\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u6539\u5584\u5171\u4eab\u51fa\u884c\u8fd0\u8425\u51b3\u7b56\u3002"}}
{"id": "2507.14271", "pdf": "https://arxiv.org/pdf/2507.14271", "abs": "https://arxiv.org/abs/2507.14271", "authors": ["Refik Samet", "Nooshin Nemati", "Emrah Hancer", "Serpil Sak", "Bilge Ayca Kirmizi", "Zeynep Yildirim"], "title": "MiDeSeC: A Dataset for Mitosis Detection and Segmentation in Breast Cancer Histopathology Images", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The MiDeSeC dataset is created through H&E stained invasive breast carcinoma,\nno special type (NST) slides of 25 different patients captured at 40x\nmagnification from the Department of Medical Pathology at Ankara University.\nThe slides have been scanned by 3D Histech Panoramic p250 Flash-3 scanner and\nOlympus BX50 microscope. As several possible mitosis shapes exist, it is\ncrucial to have a large dataset to cover all the cases. Accordingly, a total of\n50 regions is selected from glass slides for 25 patients, each of regions with\na size of 1024*1024 pixels. There are more than 500 mitoses in total in these\n50 regions. Two-thirds of the regions are reserved for training, the other\nthird for testing.", "AI": {"tldr": "\u521b\u5efaMiDeSeC\u6570\u636e\u96c6\uff0c\u4ece25\u540d\u60a3\u8005\u7684\u4e73\u817a\u764c\u5207\u7247\u9009\u53d650\u4e2a\u533a\u57df\uff0c\u542b\u8d85500\u4e2a\u6709\u4e1d\u5206\u88c2\uff0c\u5212\u5206\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u3002", "motivation": "\u6709\u4e1d\u5206\u88c2\u5f62\u72b6\u591a\u6837\uff0c\u9700\u8981\u5927\u6570\u636e\u96c6\u8986\u76d6\u6240\u6709\u60c5\u51b5\u3002", "method": "\u4ece\u5b89\u5361\u62c9\u5927\u5b66\u533b\u5b66\u75c5\u7406\u79d1\u83b7\u53d625\u540d\u60a3\u8005\u7684H&E\u67d3\u8272\u4e73\u817a\u764c\u5207\u7247\uff0c\u75283D Histech Panoramic p250 Flash - 3\u626b\u63cf\u4eea\u548cOlympus BX50\u663e\u5fae\u955c\u626b\u63cf\uff0c\u9009\u53d650\u4e2a1024*1024\u50cf\u7d20\u7684\u533a\u57df\u3002", "result": "\u6210\u529f\u521b\u5efaMiDeSeC\u6570\u636e\u96c6\uff0c50\u4e2a\u533a\u57df\u4e2d\u6709\u8d85500\u4e2a\u6709\u4e1d\u5206\u88c2\uff0c\u5212\u5206\u4e86\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002", "conclusion": "\u521b\u5efa\u7684\u6570\u636e\u96c6\u53ef\u7528\u4e8e\u540e\u7eed\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2507.14272", "pdf": "https://arxiv.org/pdf/2507.14272", "abs": "https://arxiv.org/abs/2507.14272", "authors": ["Refik Samet", "Nooshin Nemati", "Emrah Hancer", "Serpil Sak", "Bilge Ayca Kirmizi"], "title": "NuSeC: A Dataset for Nuclei Segmentation in Breast Cancer Histopathology Images", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The NuSeC dataset is created by selecting 4 images with the size of 1024*1024\npixels from the slides of each patient among 25 patients. Therefore, there are\na total of 100 images in the NuSeC dataset. To carry out a consistent\ncomparative analysis between the methods that will be developed using the NuSeC\ndataset by the researchers in the future, we divide the NuSeC dataset 75% as\nthe training set and 25% as the testing set. In detail, an image is randomly\nselected from 4 images of each patient among 25 patients to build the testing\nset, and then the remaining images are reserved for the training set. While the\ntraining set includes 75 images with around 30000 nuclei structures, the\ntesting set includes 25 images with around 6000 nuclei structures.", "AI": {"tldr": "\u521b\u5efaNuSeC\u6570\u636e\u96c6\uff0c\u542b100\u5f201024*1024\u56fe\u50cf\uff0c\u630975%\u8bad\u7ec3\u96c6\u300125%\u6d4b\u8bd5\u96c6\u5212\u5206\u3002", "motivation": "\u4e3a\u65b9\u4fbf\u7814\u7a76\u4eba\u5458\u4f7f\u7528NuSeC\u6570\u636e\u96c6\u5f00\u53d1\u65b9\u6cd5\u65f6\u8fdb\u884c\u4e00\u81f4\u7684\u5bf9\u6bd4\u5206\u6790\u3002", "method": "\u4ece25\u4f4d\u60a3\u8005\u7684\u5207\u7247\u4e2d\u4e3a\u6bcf\u4f4d\u90094\u5f201024*1024\u56fe\u50cf\u6784\u6210\u6570\u636e\u96c6\uff0c\u968f\u673a\u90091\u5f20\u4f5c\u6d4b\u8bd5\u96c6\uff0c\u5176\u4f59\u4f5c\u8bad\u7ec3\u96c6\u3002", "result": "\u8bad\u7ec3\u96c6\u670975\u5f20\u56fe\u50cf\u7ea630000\u4e2a\u7ec6\u80de\u6838\u7ed3\u6784\uff0c\u6d4b\u8bd5\u96c6\u670925\u5f20\u56fe\u50cf\u7ea66000\u4e2a\u7ec6\u80de\u6838\u7ed3\u6784\u3002", "conclusion": "\u6210\u529f\u5212\u5206NuSeC\u6570\u636e\u96c6\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4ee5\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2507.15718", "pdf": "https://arxiv.org/pdf/2507.15718", "abs": "https://arxiv.org/abs/2507.15718", "authors": ["Matteo Cederle", "Andrea Mazzucco", "Andrea Demartini", "Eugenio Mazza", "Eugenia Suriani", "Federico Vitti", "Gian Antonio Susto"], "title": "Explainable Anomaly Detection for Electric Vehicles Charging Stations", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages, 3 figures. Paper accepted to J3C 2025 (Joint Conference on\n  Computers, Cognition and Communication)", "summary": "Electric vehicles (EV) charging stations are one of the critical\ninfrastructures needed to support the transition to renewable-energy-based\nmobility, but ensuring their reliability and efficiency requires effective\nanomaly detection to identify irregularities in charging behavior. However, in\nsuch a productive scenario, it is also crucial to determine the underlying\ncause behind the detected anomalies. To achieve this goal, this study\ninvestigates unsupervised anomaly detection techniques for EV charging\ninfrastructure, integrating eXplainable Artificial Intelligence techniques to\nenhance interpretability and uncover root causes of anomalies.\n  Using real-world sensors and charging session data, this work applies\nIsolation Forest to detect anomalies and employs the Depth-based Isolation\nForest Feature Importance (DIFFI) method to identify the most important\nfeatures contributing to such anomalies. The efficacy of the proposed approach\nis evaluated in a real industrial case.", "AI": {"tldr": "\u7814\u7a76\u9488\u5bf9\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u548c\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u7528Isolation Forest\u68c0\u6d4b\u5f02\u5e38\uff0cDIFFI\u8bc6\u522b\u91cd\u8981\u7279\u5f81\uff0c\u5e76\u5728\u5b9e\u9645\u5de5\u4e1a\u6848\u4f8b\u8bc4\u4f30\u6548\u679c\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u9700\u6709\u6548\u5f02\u5e38\u68c0\u6d4b\u4fdd\u969c\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u4e14\u8981\u786e\u5b9a\u5f02\u5e38\u6839\u6e90\u3002", "method": "\u8fd0\u7528\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\uff0c\u7ed3\u5408\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u4f7f\u7528Isolation Forest\u68c0\u6d4b\u5f02\u5e38\uff0c\u7528DIFFI\u65b9\u6cd5\u8bc6\u522b\u91cd\u8981\u7279\u5f81\u3002", "result": "\u5728\u5b9e\u9645\u5de5\u4e1a\u6848\u4f8b\u4e2d\u8bc4\u4f30\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\u7ed3\u8bba\uff0c\u4f46\u6697\u793a\u6240\u63d0\u7ed3\u5408\u65b9\u6cd5\u6709\u52a9\u4e8e\u68c0\u6d4b\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u5f02\u5e38\u5e76\u627e\u51fa\u6839\u6e90\u3002"}}
{"id": "2507.14298", "pdf": "https://arxiv.org/pdf/2507.14298", "abs": "https://arxiv.org/abs/2507.14298", "authors": ["Wan-Cyuan Fan", "Yen-Chun Chen", "Mengchen Liu", "Alexander Jacobson", "Lu Yuan", "Leonid Sigal"], "title": "In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2407.14506", "summary": "Recent methods for customizing Large Vision Language Models (LVLMs) for\ndomain-specific tasks have shown promising results in scientific chart\ncomprehension. However, existing approaches face two major limitations: First,\nthey rely on paired data from only a few chart types, limiting generalization\nto wide range of chart types. Secondly, they lack targeted pre-training for\nchart-data alignment, which hampers the model's understanding of underlying\ndata. In this paper, we introduce ChartScope, an LVLM optimized for in-depth\nchart comprehension across diverse chart types. We propose an efficient data\ngeneration pipeline that synthesizes paired data for a wide range of chart\ntypes, along with a novel Dual-Path training strategy that enabling the model\nto succinctly capture essential data details while preserving robust reasoning\ncapabilities by incorporating reasoning over the underlying data. Lastly, we\nestablish ChartDQA, a new benchmark for evaluating not only question-answering\nat different levels but also underlying data understanding. Experimental\nresults demonstrate that ChartScope significantly enhances comprehension on a\nwide range of chart types. The code and data are available at\nhttps://davidhalladay.github.io/chartscope_demo.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u79d1\u5b66\u56fe\u8868\u7406\u89e3\u7684LVLM\u6a21\u578bChartScope\uff0c\u542b\u6570\u636e\u751f\u6210\u7ba1\u9053\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u8bbe\u65b0\u57fa\u51c6ChartDQA\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u589e\u5f3a\u4e86\u5bf9\u591a\u79cd\u56fe\u8868\u7684\u7406\u89e3\u3002", "motivation": "\u73b0\u6709\u5b9a\u5236\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u7684\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u548c\u7f3a\u4e4f\u9488\u5bf9\u6027\u9884\u8bad\u7ec3\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u56fe\u8868\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u9ad8\u6548\u6570\u636e\u751f\u6210\u7ba1\u9053\u5408\u6210\u591a\u79cd\u56fe\u8868\u7c7b\u578b\u7684\u914d\u5bf9\u6570\u636e\uff0c\u91c7\u7528\u53cc\u8def\u5f84\u8bad\u7ec3\u7b56\u7565\uff0c\u5efa\u7acb\u65b0\u57fa\u51c6ChartDQA\u3002", "result": "\u5b9e\u9a8c\u8868\u660eChartScope\u663e\u8457\u589e\u5f3a\u4e86\u5bf9\u591a\u79cd\u56fe\u8868\u7c7b\u578b\u7684\u7406\u89e3\u3002", "conclusion": "ChartScope\u5728\u591a\u79cd\u56fe\u8868\u7c7b\u578b\u7684\u6df1\u5165\u7406\u89e3\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.15769", "pdf": "https://arxiv.org/pdf/2507.15769", "abs": "https://arxiv.org/abs/2507.15769", "authors": ["Ahmad M. Nazar", "Abdulkadir Celik", "Mohamed Y. Selim", "Asmaa Abdallah", "Daji Qiao", "Ahmed M. Eltawil"], "title": "Multi-Modal Sensor Fusion for Proactive Blockage Prediction in mmWave Vehicular Networks", "categories": ["cs.LG"], "comment": "Accepted in IEEE Asilomar Conference on Signals, Systems, and\n  Computers 2025", "summary": "Vehicular communication systems operating in the millimeter wave (mmWave)\nband are highly susceptible to signal blockage from dynamic obstacles such as\nvehicles, pedestrians, and infrastructure. To address this challenge, we\npropose a proactive blockage prediction framework that utilizes multi-modal\nsensing, including camera, GPS, LiDAR, and radar inputs in an\ninfrastructure-to-vehicle (I2V) setting. This approach uses modality-specific\ndeep learning models to process each sensor stream independently and fuses\ntheir outputs using a softmax-weighted ensemble strategy based on validation\nperformance. Our evaluations, for up to 1.5s in advance, show that the\ncamera-only model achieves the best standalone trade-off with an F1-score of\n97.1% and an inference time of 89.8ms. A camera+radar configuration further\nimproves accuracy to 97.2% F1 at 95.7ms. Our results display the effectiveness\nand efficiency of multi-modal sensing for mmWave blockage prediction and\nprovide a pathway for proactive wireless communication in dynamic environments.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u611f\u77e5\u7684\u6beb\u7c73\u6ce2\u963b\u585e\u9884\u6d4b\u6846\u67b6\uff0c\u8bc4\u4f30\u4e0d\u540c\u914d\u7f6e\u6a21\u578b\u6548\u679c\uff0c\u663e\u793a\u591a\u6a21\u6001\u611f\u77e5\u6709\u6548\u6027\u3002", "motivation": "\u6beb\u7c73\u6ce2\u8f66\u8f7d\u901a\u4fe1\u7cfb\u7edf\u6613\u53d7\u52a8\u6001\u969c\u788d\u7269\u4fe1\u53f7\u963b\u585e\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u5229\u7528\u76f8\u673a\u3001GPS\u3001LiDAR\u548c\u96f7\u8fbe\u591a\u6a21\u6001\u611f\u77e5\uff0c\u7528\u7279\u5b9a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5904\u7406\u5404\u4f20\u611f\u5668\u6570\u636e\u6d41\uff0c\u7528\u57fa\u4e8e\u9a8c\u8bc1\u6027\u80fd\u7684softmax\u52a0\u6743\u96c6\u6210\u7b56\u7565\u878d\u5408\u8f93\u51fa\u3002", "result": "\u63d0\u524d1.5\u79d2\u8bc4\u4f30\uff0c\u76f8\u673a\u5355\u6a21\u578bF1\u5206\u657097.1%\uff0c\u63a8\u7406\u65f6\u95f489.8ms\uff1b\u76f8\u673a+\u96f7\u8fbe\u914d\u7f6eF1\u5206\u6570\u8fbe97.2%\uff0c\u63a8\u7406\u65f6\u95f495.7ms\u3002", "conclusion": "\u591a\u6a21\u6001\u611f\u77e5\u7528\u4e8e\u6beb\u7c73\u6ce2\u963b\u585e\u9884\u6d4b\u6709\u6548\u4e14\u9ad8\u6548\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e0b\u4e3b\u52a8\u65e0\u7ebf\u901a\u4fe1\u63d0\u4f9b\u9014\u5f84\u3002"}}
{"id": "2507.14299", "pdf": "https://arxiv.org/pdf/2507.14299", "abs": "https://arxiv.org/abs/2507.14299", "authors": ["Yu Bai", "Yifan Zhang", "Boxuan Xie", "Zheng Chang", "Yanru Zhang", "Riku Jantti", "Zhu Han"], "title": "Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Unmanned aerial vehicles (UAVs) equipped with integrated sensing and\ncommunication (ISAC) capabilities are envisioned to play a pivotal role in\nfuture wireless networks due to their enhanced flexibility and efficiency.\nHowever, jointly optimizing UAV trajectory planning, multi-user communication,\nand target sensing under stringent resource constraints and time-critical\nconditions remains a significant challenge. To address this, we propose an Age\nof Information (AoI)-centric UAV-ISAC system that simultaneously performs\ntarget sensing and serves multiple ground users, emphasizing information\nfreshness as the core performance metric. We formulate a long-term average AoI\nminimization problem that jointly optimizes the UAV's flight trajectory and\nbeamforming. To tackle the high-dimensional, non-convexity of this problem, we\ndevelop a deep reinforcement learning (DRL)-based algorithm capable of\nproviding real-time decisions on UAV movement and beamforming for both radar\nsensing and multi-user communication. Specifically, a Kalman filter is employed\nfor accurate target state prediction, regularized zero-forcing is utilized to\nmitigate inter-user interference, and the Soft Actor-Critic algorithm is\napplied for training the DRL agent on continuous actions. The proposed\nframework adaptively balances the trade-offs between sensing accuracy and\ncommunication quality. Extensive simulation results demonstrate that our\nproposed method consistently achieves lower average AoI compared to baseline\napproaches.", "AI": {"tldr": "\u63d0\u51fa\u4ee5\u4fe1\u606f\u5e74\u9f84\uff08AoI\uff09\u4e3a\u4e2d\u5fc3\u7684\u65e0\u4eba\u673a\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff08UAV - ISAC\uff09\u7cfb\u7edf\uff0c\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4f18\u5316\u8f68\u8ff9\u548c\u6ce2\u675f\u8d4b\u5f62\uff0c\u4eff\u771f\u663e\u793a\u5e73\u5747AoI\u66f4\u4f4e\u3002", "motivation": "\u5728\u8d44\u6e90\u548c\u65f6\u95f4\u9650\u5236\u4e0b\uff0c\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u3001\u591a\u7528\u6237\u901a\u4fe1\u548c\u76ee\u6807\u4f20\u611f\u5b58\u5728\u6311\u6218\uff0c\u9700\u5f3a\u8c03\u4fe1\u606f\u65b0\u9c9c\u5ea6\u3002", "method": "\u63d0\u51faAoI\u4e2d\u5fc3\u7684UAV - ISAC\u7cfb\u7edf\uff0c\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u7ed3\u5408\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u3001\u6b63\u5219\u5316\u8feb\u96f6\u548cSoft Actor - Critic\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747AoI\u66f4\u4f4e\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u81ea\u9002\u5e94\u5e73\u8861\u4f20\u611f\u7cbe\u5ea6\u548c\u901a\u4fe1\u8d28\u91cf\uff0c\u6709\u6548\u964d\u4f4e\u5e73\u5747AoI\u3002"}}
{"id": "2507.15772", "pdf": "https://arxiv.org/pdf/2507.15772", "abs": "https://arxiv.org/abs/2507.15772", "authors": ["Anoop C. Patil", "Benny Jian Rong Sng", "Yu-Wei Chang", "Joana B. Pereira", "Chua Nam-Hai", "Rajani Sarojam", "Gajendra Pratap Singh", "In-Cheol Jang", "Giovanni Volpe"], "title": "Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "*Authors contributed equally to this work. +Supervised this work. 5\n  main figures and 1 extended data figure in manuscript. The PDF includes\n  supplementary material", "summary": "Detecting stress in plants is crucial for both open-farm and\ncontrolled-environment agriculture. Biomolecules within plants serve as key\nstress indicators, offering vital markers for continuous health monitoring and\nearly disease detection. Raman spectroscopy provides a powerful, non-invasive\nmeans to quantify these biomolecules through their molecular vibrational\nsignatures. However, traditional Raman analysis relies on customized\ndata-processing workflows that require fluorescence background removal and\nprior identification of Raman peaks of interest-introducing potential biases\nand inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation\nof Vibrational Raman spectra for plant-stress Analysis), a fully automated\nworkflow based on a variational autoencoder. Unlike conventional approaches,\nDIVA processes native Raman spectra-including fluorescence backgrounds-without\nmanual preprocessing, identifying and quantifying significant spectral features\nin an unbiased manner. We applied DIVA to detect a range of plant stresses,\nincluding abiotic (shading, high light intensity, high temperature) and biotic\nstressors (bacterial infections). By integrating deep learning with vibrational\nspectroscopy, DIVA paves the way for AI-driven plant health assessment,\nfostering more resilient and sustainable agricultural practices.", "AI": {"tldr": "\u4ecb\u7ecdDIVA\u5de5\u4f5c\u6d41\uff0c\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u548c\u62c9\u66fc\u5149\u8c31\u68c0\u6d4b\u690d\u7269\u538b\u529b\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u690d\u7269\u5065\u5eb7\u8bc4\u4f30\u94fa\u5e73\u9053\u8def\u3002", "motivation": "\u4f20\u7edf\u62c9\u66fc\u5206\u6790\u68c0\u6d4b\u690d\u7269\u538b\u529b\u6709\u6f5c\u5728\u504f\u5dee\u548c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u5168\u81ea\u52a8\u5de5\u4f5c\u6d41DIVA\uff0c\u5904\u7406\u539f\u59cb\u62c9\u66fc\u5149\u8c31\uff0c\u65e0\u9700\u624b\u52a8\u9884\u5904\u7406\u3002", "result": "DIVA\u53ef\u68c0\u6d4b\u591a\u79cd\u690d\u7269\u538b\u529b\uff0c\u5305\u62ec\u975e\u751f\u7269\u548c\u751f\u7269\u538b\u529b\u6e90\u3002", "conclusion": "DIVA\u901a\u8fc7\u96c6\u6210\u6df1\u5ea6\u5b66\u4e60\u548c\u632f\u52a8\u5149\u8c31\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u690d\u7269\u5065\u5eb7\u8bc4\u4f30\u5960\u5b9a\u57fa\u7840\uff0c\u4fc3\u8fdb\u519c\u4e1a\u53ef\u6301\u7eed\u53d1\u5c55\u3002"}}
{"id": "2507.14339", "pdf": "https://arxiv.org/pdf/2507.14339", "abs": "https://arxiv.org/abs/2507.14339", "authors": ["Abhishek Bhattacharjee", "Jack Pilkington", "Nita Farahany"], "title": "Fiduciary AI for the Future of Brain-Technology Interactions", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG", "eess.SP", "K.4.0; I.2.0; J.4"], "comment": "32 pages", "summary": "Brain foundation models represent a new frontier in AI: instead of processing\ntext or images, these models interpret real-time neural signals from EEG, fMRI,\nand other neurotechnologies. When integrated with brain-computer interfaces\n(BCIs), they may enable transformative applications-from thought controlled\ndevices to neuroprosthetics-by interpreting and acting on brain activity in\nmilliseconds. However, these same systems pose unprecedented risks, including\nthe exploitation of subconscious neural signals and the erosion of cognitive\nliberty. Users cannot easily observe or control how their brain signals are\ninterpreted, creating power asymmetries that are vulnerable to manipulation.\nThis paper proposes embedding fiduciary duties-loyalty, care, and\nconfidentiality-directly into BCI-integrated brain foundation models through\ntechnical design. Drawing on legal traditions and recent advancements in AI\nalignment techniques, we outline implementable architectural and governance\nmechanisms to ensure these systems act in users' best interests. Placing brain\nfoundation models on a fiduciary footing is essential to realizing their\npotential without compromising self-determination.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u8111\u57fa\u7840\u6a21\u578b\u4e0e\u8111\u673a\u63a5\u53e3\u7ed3\u5408\u7684\u5e94\u7528\u3001\u98ce\u9669\uff0c\u63d0\u51fa\u901a\u8fc7\u6280\u672f\u8bbe\u8ba1\u5d4c\u5165\u4fe1\u6258\u4e49\u52a1\u4fdd\u969c\u7528\u6237\u5229\u76ca\u3002", "motivation": "\u8111\u57fa\u7840\u6a21\u578b\u4e0e\u8111\u673a\u63a5\u53e3\u7ed3\u5408\u6709\u53d8\u9769\u6027\u5e94\u7528\uff0c\u4f46\u5b58\u5728\u524d\u6240\u672a\u6709\u7684\u98ce\u9669\uff0c\u5982\u6f5c\u610f\u8bc6\u4fe1\u53f7\u88ab\u5229\u7528\u3001\u8ba4\u77e5\u81ea\u7531\u53d7\u4fb5\u8680\uff0c\u7528\u6237\u96be\u4ee5\u63a7\u5236\u4fe1\u53f7\u89e3\u8bfb\uff0c\u9700\u4fdd\u969c\u7528\u6237\u5229\u76ca\u3002", "method": "\u501f\u9274\u6cd5\u5f8b\u4f20\u7edf\u548cAI\u5bf9\u9f50\u6280\u672f\uff0c\u901a\u8fc7\u6280\u672f\u8bbe\u8ba1\u5c06\u4fe1\u6258\u4e49\u52a1\uff08\u5fe0\u8bda\u3001\u5173\u6000\u548c\u4fdd\u5bc6\uff09\u5d4c\u5165\u8111\u673a\u63a5\u53e3\u96c6\u6210\u7684\u8111\u57fa\u7840\u6a21\u578b\uff0c\u63d0\u51fa\u53ef\u5b9e\u65bd\u7684\u67b6\u6784\u548c\u6cbb\u7406\u673a\u5236\u3002", "result": "\u63d0\u51fa\u4e86\u53ef\u5b9e\u65bd\u7684\u67b6\u6784\u548c\u6cbb\u7406\u673a\u5236\uff0c\u4ee5\u786e\u4fdd\u7cfb\u7edf\u7b26\u5408\u7528\u6237\u6700\u4f73\u5229\u76ca\u3002", "conclusion": "\u5c06\u8111\u57fa\u7840\u6a21\u578b\u7f6e\u4e8e\u4fe1\u6258\u57fa\u7840\u4e0a\u5bf9\u5b9e\u73b0\u5176\u6f5c\u529b\u4e14\u4e0d\u635f\u5bb3\u81ea\u51b3\u6743\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.15774", "pdf": "https://arxiv.org/pdf/2507.15774", "abs": "https://arxiv.org/abs/2507.15774", "authors": ["Alexis-Raja Brachet", "Pierre-Yves Richard", "C\u00e9line Hudelot"], "title": "Dynamics is what you need for time-series forecasting!", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 6 figures, 1 table", "summary": "While boundaries between data modalities are vanishing, the usual successful\ndeep models are still challenged by simple ones in the time-series forecasting\ntask. Our hypothesis is that this task needs models that are able to learn the\ndata underlying dynamics. We propose to validate it through both systemic and\nempirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to\nanalyze existing models through the lens of dynamics. Two observations thus\nemerged: $\\textbf{1}$. under-performing architectures learn dynamics at most\npartially, $\\textbf{2}$. the location of the dynamics block at the model end is\nof prime importance. We conduct extensive experiments to confirm our\nobservations on a set of performance-varying models with diverse backbones.\nResults support the need to incorporate a learnable dynamics block and its use\nas the final predictor.", "AI": {"tldr": "\u73b0\u6709\u6df1\u5ea6\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u63d0\u51fa\u7528\u7cfb\u7edf\u548c\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u5047\u8bbe\uff0c\u5f00\u53d1PRO - DYN\u547d\u540d\u6cd5\u5206\u6790\u6a21\u578b\uff0c\u5b9e\u9a8c\u652f\u6301\u5f15\u5165\u53ef\u5b66\u4e60\u52a8\u6001\u5757\u5e76\u4f5c\u4e3a\u6700\u7ec8\u9884\u6d4b\u5668\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u6a21\u6001\u8fb9\u754c\u6d88\u5931\uff0c\u4f46\u5e38\u7528\u6df1\u5ea6\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u53d7\u7b80\u5355\u6a21\u578b\u6311\u6218\uff0c\u9700\u80fd\u5b66\u4e60\u6570\u636e\u6f5c\u5728\u52a8\u6001\u7684\u6a21\u578b\u3002", "method": "\u8fdb\u884c\u7cfb\u7edf\u548c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5f00\u53d1PRO - DYN\u547d\u540d\u6cd5\u5206\u6790\u73b0\u6709\u6a21\u578b\uff0c\u5bf9\u4e0d\u540c\u9aa8\u5e72\u7684\u6a21\u578b\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u3002", "result": "\u8868\u73b0\u4e0d\u4f73\u7684\u67b6\u6784\u6700\u591a\u53ea\u80fd\u90e8\u5206\u5b66\u4e60\u52a8\u6001\uff0c\u52a8\u6001\u5757\u5728\u6a21\u578b\u672b\u5c3e\u7684\u4f4d\u7f6e\u81f3\u5173\u91cd\u8981\uff0c\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u5f15\u5165\u53ef\u5b66\u4e60\u52a8\u6001\u5757\u5e76\u4f5c\u4e3a\u6700\u7ec8\u9884\u6d4b\u5668\u3002", "conclusion": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u6a21\u578b\u9700\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u52a8\u6001\u5757\u5e76\u5c06\u5176\u4f5c\u4e3a\u6700\u7ec8\u9884\u6d4b\u5668\u3002"}}
{"id": "2507.15784", "pdf": "https://arxiv.org/pdf/2507.15784", "abs": "https://arxiv.org/abs/2507.15784", "authors": ["Zihang Ma", "Qitian Yin"], "title": "Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets", "categories": ["cs.LG"], "comment": null, "summary": "Graph node classification is a fundamental task in graph neural networks\n(GNNs), aiming to assign predefined class labels to nodes. On the PubMed\ncitation network dataset, we observe significant classification difficulty\ndisparities, with Category 2 achieving only 74.4% accuracy in traditional GCN,\n7.5% lower than Category 1. To address this, we propose a\nWasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM),\ntraining specialized GNN models for Categories 0/1 (with layer normalization\nand residual connections) and Multi-hop Graph Attention Networks (GAT) for\nCategory 2. The WR distance metric optimizes representation similarity between\nmodels, particularly focusing on improving Category 2 performance. Our adaptive\nfusion strategy dynamically weights models based on category-specific\nperformance, with Category 2 assigned a GAT weight of 0.8. WR distance further\nguides the fusion process by measuring distributional differences between model\nrepresentations, enabling more principled integration of complementary\nfeatures.\n  Experimental results show WR-EFM achieves balanced accuracy across\ncategories: 77.8% (Category 0), 78.0% (Category 1), and 79.9% (Category 2),\noutperforming both single models and standard fusion approaches. The\ncoefficient of variation (CV) of WR-EFM's category accuracies is 0.013, 77.6%\nlower than GCN's 0.058, demonstrating superior stability. Notably, WR-EFM\nimproves Category 2 accuracy by 5.5% compared to GCN, verifying the\neffectiveness of WR-guided fusion in capturing complex structural patterns.\nThis work provides a novel paradigm for handling class-imbalanced graph\nclassification tasks. To promote the research community, we release our project\nat https://github.com/s010m00n/GASEM4NC.", "AI": {"tldr": "\u9488\u5bf9\u56fe\u8282\u70b9\u5206\u7c7b\u4e2d\u7c7b\u522b\u5206\u7c7b\u96be\u5ea6\u5dee\u5f02\u95ee\u9898\uff0c\u63d0\u51faWR - EFM\u6a21\u578b\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u80fd\u5b9e\u73b0\u7c7b\u522b\u95f4\u5e73\u8861\u51c6\u786e\u5206\u7c7b\uff0c\u7a33\u5b9a\u6027\u9ad8\uff0c\u4e3a\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u56fe\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002", "motivation": "\u89e3\u51b3PubMed\u5f15\u6587\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\u4e0d\u540c\u7c7b\u522b\u56fe\u8282\u70b9\u5206\u7c7b\u96be\u5ea6\u5dee\u5f02\u5927\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u63d0\u51faWasserstein - Rubinstein (WR)\u8ddd\u79bb\u589e\u5f3a\u7684\u4e13\u5bb6\u878d\u5408\u6a21\u578b(WR - EFM)\uff0c\u4e3a\u4e0d\u540c\u7c7b\u522b\u8bad\u7ec3\u4e13\u95e8\u7684GNN\u6a21\u578b\uff0c\u7528WR\u8ddd\u79bb\u4f18\u5316\u6a21\u578b\u8868\u793a\u76f8\u4f3c\u6027\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u878d\u5408\u7b56\u7565\u52a8\u6001\u52a0\u6743\u6a21\u578b\u3002", "result": "WR - EFM\u5728\u5404\u7c7b\u522b\u4e0a\u5b9e\u73b0\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5206\u522b\u4e3a77.8%\uff08\u7c7b\u522b0\uff09\u300178.0%\uff08\u7c7b\u522b1\uff09\u548c79.9%\uff08\u7c7b\u522b2\uff09\uff0c\u53d8\u5f02\u7cfb\u6570\u4f4e\uff0c\u7a33\u5b9a\u6027\u597d\uff0c\u7c7b\u522b2\u51c6\u786e\u7387\u6bd4GCN\u63d0\u9ad85.5%\u3002", "conclusion": "WR - EFM\u6709\u6548\uff0c\u4e3a\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u56fe\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u9879\u76ee\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.15788", "pdf": "https://arxiv.org/pdf/2507.15788", "abs": "https://arxiv.org/abs/2507.15788", "authors": ["Sneheel Sarangi", "Hanan Salam"], "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nemergent capabilities in complex reasoning, largely spurred by rule-based\nReinforcement Learning (RL) techniques applied during the post-training. This\nhas raised the question of whether similar methods can instill more nuanced,\nhuman-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This\npaper investigates whether small-scale LLMs can acquire a robust and\ngeneralizable ToM capability through RL with verifiable rewards (RLVR). We\nconduct a systematic evaluation by training models on various combinations of\nprominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for\ngeneralization on held-out datasets (e.g., OpenToM). Our findings indicate that\nsmall LLMs struggle to develop a generic ToM capability. While performance on\nin-distribution tasks improves, this capability fails to transfer to unseen ToM\ntasks with different characteristics. Furthermore, we demonstrate that\nprolonged RL training leads to models ``hacking'' the statistical patterns of\nthe training datasets, resulting in significant performance gains on in-domain\ndata but no change, or degradation of performance on out-of-distribution tasks.\nThis suggests the learned behavior is a form of narrow overfitting rather than\nthe acquisition of a true, abstract ToM capability.", "AI": {"tldr": "\u7814\u7a76\u5c0f\u89c4\u6a21\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u901a\u8fc7\u5e26\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u83b7\u5f97\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u53d1\u73b0\u5c0f\u6a21\u578b\u96be\u4ee5\u53d1\u5c55\u901a\u7528\u80fd\u529b\uff0c\u6613\u8fc7\u62df\u5408\u3002", "motivation": "\u63a2\u8ba8\u7c7b\u4f3c\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u80fd\u5426\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u62e5\u6709\u66f4\u7ec6\u81f4\u3001\u7c7b\u4eba\u7684\u793e\u4f1a\u667a\u80fd\uff0c\u5982\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u3002", "method": "\u5728\u591a\u4e2a\u77e5\u540d\u5fc3\u667a\u7406\u8bba\u6570\u636e\u96c6\u7684\u4e0d\u540c\u7ec4\u5408\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u5728\u4fdd\u7559\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5c0f\u6a21\u578b\u96be\u4ee5\u53d1\u5c55\u901a\u7528\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u5728\u5206\u5e03\u5185\u4efb\u52a1\u8868\u73b0\u63d0\u5347\u4f46\u65e0\u6cd5\u8fc1\u79fb\u5230\u7279\u5f81\u4e0d\u540c\u7684\u672a\u89c1\u4efb\u52a1\uff1b\u957f\u65f6\u95f4\u8bad\u7ec3\u4f1a\u5bfc\u81f4\u6a21\u578b\u5229\u7528\u8bad\u7ec3\u6570\u636e\u7edf\u8ba1\u6a21\u5f0f\uff0c\u5206\u5e03\u5185\u6570\u636e\u8868\u73b0\u63d0\u5347\u4f46\u5206\u5e03\u5916\u4efb\u52a1\u65e0\u53d8\u5316\u6216\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u6a21\u578b\u5b66\u5230\u7684\u884c\u4e3a\u662f\u72ed\u4e49\u8fc7\u62df\u5408\uff0c\u800c\u975e\u83b7\u5f97\u771f\u6b63\u3001\u62bd\u8c61\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u3002"}}
{"id": "2507.15816", "pdf": "https://arxiv.org/pdf/2507.15816", "abs": "https://arxiv.org/abs/2507.15816", "authors": ["Yujia Mu", "Cong Shen"], "title": "Federated Split Learning with Improved Communication and Storage Efficiency", "categories": ["cs.LG", "cs.IT", "cs.NI", "eess.SP", "math.IT"], "comment": "Accepted for publication in IEEE Transactions on Mobile Computing", "summary": "Federated learning (FL) is one of the popular distributed machine learning\n(ML) solutions but incurs significant communication and computation costs at\nedge devices. Federated split learning (FSL) can train sub-models in parallel\nand reduce the computational burden of edge devices by splitting the model\narchitecture. However, it still requires a high communication overhead due to\ntransmitting the smashed data and gradients between clients and the server in\nevery global round. Furthermore, the server must maintain separate partial\nmodels for every client, leading to a significant storage requirement. To\naddress these challenges, this paper proposes a novel communication and storage\nefficient federated split learning method, termed CSE-FSL, which utilizes an\nauxiliary network to locally update the weights of the clients while keeping a\nsingle model at the server, hence avoiding frequent transmissions of gradients\nfrom the server and greatly reducing the storage requirement of the server.\nAdditionally, a new model update method of transmitting the smashed data in\nselected epochs can reduce the amount of smashed data sent from the clients. We\nprovide a theoretical analysis of CSE-FSL, rigorously guaranteeing its\nconvergence under non-convex loss functions. The extensive experimental results\nfurther indicate that CSE-FSL achieves a significant communication reduction\nover existing FSL solutions using real-world FL tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u4fe1\u4e0e\u5b58\u50a8\u9ad8\u6548\u7684\u8054\u90a6\u5206\u5272\u5b66\u4e60\u65b9\u6cd5CSE - FSL\uff0c\u53ef\u51cf\u5c11\u901a\u4fe1\u4e0e\u5b58\u50a8\u5f00\u9500\uff0c\u7406\u8bba\u8bc1\u660e\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709FSL\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u548c\u8054\u90a6\u5206\u5272\u5b66\u4e60\u5b58\u5728\u901a\u4fe1\u3001\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCSE - FSL\u65b9\u6cd5\uff0c\u5229\u7528\u8f85\u52a9\u7f51\u7edc\u672c\u5730\u66f4\u65b0\u5ba2\u6237\u7aef\u6743\u91cd\uff0c\u670d\u52a1\u5668\u4fdd\u7559\u5355\u4e00\u6a21\u578b\uff0c\u5728\u9009\u5b9a\u65f6\u671f\u4f20\u8f93\u7c89\u788e\u6570\u636e\u4ee5\u66f4\u65b0\u6a21\u578b\u3002", "result": "\u7406\u8bba\u4e0a\u4fdd\u8bc1\u4e86CSE - FSL\u5728\u975e\u51f8\u635f\u5931\u51fd\u6570\u4e0b\u7684\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u771f\u5b9e\u4e16\u754cFL\u4efb\u52a1\u4e2d\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "CSE - FSL\u80fd\u6709\u6548\u51cf\u5c11\u901a\u4fe1\u548c\u5b58\u50a8\u5f00\u9500\uff0c\u4f18\u4e8e\u73b0\u6709\u7684FSL\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15832", "pdf": "https://arxiv.org/pdf/2507.15832", "abs": "https://arxiv.org/abs/2507.15832", "authors": ["Shiyang Li"], "title": "Multi-Strategy Improved Snake Optimizer Accelerated CNN-LSTM-Attention-Adaboost for Trajectory Prediction", "categories": ["cs.LG"], "comment": "in Chinese language", "summary": "To address the limitations of medium- and long-term four-dimensional (4D)\ntrajectory prediction models, this paper proposes a hybrid\nCNN-LSTM-attention-adaboost neural network model incorporating a multi-strategy\nimproved snake-herd optimization (SO) algorithm. The model applies the Adaboost\nalgorithm to divide multiple weak learners, and each submodel utilizes CNN to\nextract spatial features, LSTM to capture temporal features, and attention\nmechanism to capture global features comprehensively. The strong learner model,\ncombined with multiple sub-models, then optimizes the hyperparameters of the\nprediction model through the natural selection behavior pattern simulated by\nSO. In this study, based on the real ADS-B data from Xi'an to Tianjin, the\ncomparison experiments and ablation studies of multiple optimizers are carried\nout, and a comprehensive test and evaluation analysis is carried out. The\nresults show that SO-CLA-adaboost outperforms traditional optimizers such as\nparticle swarm, whale, and gray wolf in handling large-scale high-dimensional\ntrajectory data. In addition, introducing the full-strategy collaborative\nimprovement SO algorithm improves the model's prediction accuracy by 39.89%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6df7\u5408CNN - LSTM - attention - adaboost\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7ed3\u5408\u6539\u8fdb\u86c7\u7fa4\u4f18\u5316\u7b97\u6cd5\u7528\u4e8e4D\u8f68\u8ff9\u9884\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u5668\uff0c\u6539\u8fdb\u7b97\u6cd5\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u4e2d\u957f\u671f4D\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u6df7\u5408CNN - LSTM - attention - adaboost\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7528Adaboost\u5212\u5206\u5f31\u5b66\u4e60\u5668\uff0c\u5b50\u6a21\u578b\u7528CNN\u3001LSTM\u548c\u6ce8\u610f\u529b\u673a\u5236\u63d0\u53d6\u7279\u5f81\uff0c\u7ed3\u5408SO\u7b97\u6cd5\u4f18\u5316\u8d85\u53c2\u6570\u3002", "result": "SO - CLA - adaboost\u5728\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u8f68\u8ff9\u6570\u636e\u4e0a\u4f18\u4e8e\u7c92\u5b50\u7fa4\u3001\u9cb8\u9c7c\u548c\u7070\u72fc\u7b49\u4f20\u7edf\u4f18\u5316\u5668\uff0c\u5f15\u5165\u6539\u8fdbSO\u7b97\u6cd5\u4f7f\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u63d0\u534739.89%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u548c\u6539\u8fdb\u7b97\u6cd5\u57284D\u8f68\u8ff9\u9884\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u6709\u6548\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2507.15836", "pdf": "https://arxiv.org/pdf/2507.15836", "abs": "https://arxiv.org/abs/2507.15836", "authors": ["Matteo Boglioni", "Terrance Liu", "Andrew Ilyas", "Zhiwei Steven Wu"], "title": "Optimizing Canaries for Privacy Auditing with Metagradient Descent", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "In this work we study black-box privacy auditing, where the goal is to lower\nbound the privacy parameter of a differentially private learning algorithm\nusing only the algorithm's outputs (i.e., final trained model). For DP-SGD (the\nmost successful method for training differentially private deep learning\nmodels), the canonical approach auditing uses membership inference-an auditor\ncomes with a small set of special \"canary\" examples, inserts a random subset of\nthem into the training set, and then tries to discern which of their canaries\nwere included in the training set (typically via a membership inference\nattack). The auditor's success rate then provides a lower bound on the privacy\nparameters of the learning algorithm. Our main contribution is a method for\noptimizing the auditor's canary set to improve privacy auditing, leveraging\nrecent work on metagradient optimization. Our empirical evaluation demonstrates\nthat by using such optimized canaries, we can improve empirical lower bounds\nfor differentially private image classification models by over 2x in certain\ninstances. Furthermore, we demonstrate that our method is transferable and\nefficient: canaries optimized for non-private SGD with a small model\narchitecture remain effective when auditing larger models trained with DP-SGD.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u9ed1\u76d2\u9690\u79c1\u5ba1\u8ba1\uff0c\u63d0\u51fa\u5229\u7528\u5143\u68af\u5ea6\u4f18\u5316\u6765\u4f18\u5316\u5ba1\u8ba1\u8005\u7684\u91d1\u4e1d\u96c0\u96c6\u4ee5\u6539\u5584\u9690\u79c1\u5ba1\u8ba1\u7684\u65b9\u6cd5\uff0c\u80fd\u4f7f\u5dee\u5206\u9690\u79c1\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u7684\u7ecf\u9a8c\u4e0b\u754c\u63d0\u5347\u8d852\u500d\uff0c\u4e14\u65b9\u6cd5\u5177\u6709\u53ef\u8fc1\u79fb\u6027\u548c\u9ad8\u6548\u6027\u3002", "motivation": "\u964d\u4f4e\u5dee\u5206\u9690\u79c1\u5b66\u4e60\u7b97\u6cd5\u9690\u79c1\u53c2\u6570\u7684\u4e0b\u754c\uff0c\u6539\u8fdb\u73b0\u6709\u57fa\u4e8e\u6210\u5458\u63a8\u7406\u7684\u5ba1\u8ba1\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5143\u68af\u5ea6\u4f18\u5316\u6765\u4f18\u5316\u5ba1\u8ba1\u8005\u7684\u91d1\u4e1d\u96c0\u96c6\u3002", "result": "\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4f7f\u5dee\u5206\u9690\u79c1\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u7684\u7ecf\u9a8c\u4e0b\u754c\u63d0\u5347\u8d852\u500d\uff0c\u4e14\u4f18\u5316\u540e\u7684\u91d1\u4e1d\u96c0\u96c6\u5bf9\u4e0d\u540c\u6a21\u578b\u5ba1\u8ba1\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684\u4f18\u5316\u91d1\u4e1d\u96c0\u96c6\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u6539\u5584\u9690\u79c1\u5ba1\u8ba1\uff0c\u5177\u6709\u53ef\u8fc1\u79fb\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2507.15839", "pdf": "https://arxiv.org/pdf/2507.15839", "abs": "https://arxiv.org/abs/2507.15839", "authors": ["Anh Nguyen", "Sam Schafft", "Nicholas Hale", "John Alfaro"], "title": "FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Synthetic data generation has emerged as an invaluable solution in scenarios\nwhere real-world data collection and usage are limited by cost and scarcity.\nLarge language models (LLMs) have demonstrated remarkable capabilities in\nproducing high-fidelity, domain-relevant samples across various fields.\nHowever, existing approaches that directly use LLMs to generate each record\nindividually impose prohibitive time and cost burdens, particularly when large\nvolumes of synthetic data are required. In this work, we propose a fast,\ncost-effective method for realistic tabular data synthesis that leverages LLMs\nto infer and encode each field's distribution into a reusable sampling script.\nBy automatically classifying fields into numerical, categorical, or free-text\ntypes, the LLM generates distribution-based scripts that can efficiently\nproduce diverse, realistic datasets at scale without continuous model\ninference. Experimental results show that our approach outperforms traditional\ndirect methods in both diversity and data realism, substantially reducing the\nburden of high-volume synthetic data generation. We plan to apply this\nmethodology to accelerate testing in production pipelines, thereby shortening\ndevelopment cycles and improving overall system efficiency. We believe our\ninsights and lessons learned will aid researchers and practitioners seeking\nscalable, cost-effective solutions for synthetic data generation.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8868\u683c\u6570\u636e\u7684\u4f4e\u6210\u672c\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u8ba1\u5212\u7528\u4e8e\u52a0\u901f\u751f\u4ea7\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u76f4\u63a5\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6bcf\u6761\u6570\u636e\u7684\u65b9\u6cd5\u5728\u5927\u91cf\u6570\u636e\u751f\u6210\u65f6\u65f6\u95f4\u548c\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u6bcf\u4e2a\u5b57\u6bb5\u7684\u5206\u5e03\u63a8\u65ad\u5e76\u7f16\u7801\u6210\u53ef\u590d\u7528\u7684\u91c7\u6837\u811a\u672c\uff0c\u81ea\u52a8\u5206\u7c7b\u5b57\u6bb5\u7c7b\u578b\uff0c\u751f\u6210\u57fa\u4e8e\u5206\u5e03\u7684\u811a\u672c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u6570\u636e\u771f\u5b9e\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u76f4\u63a5\u65b9\u6cd5\uff0c\u5927\u5e45\u964d\u4f4e\u5927\u91cf\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u8d1f\u62c5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u52a0\u901f\u751f\u4ea7\u7ba1\u9053\u6d4b\u8bd5\uff0c\u7f29\u77ed\u5f00\u53d1\u5468\u671f\uff0c\u63d0\u9ad8\u7cfb\u7edf\u6548\u7387\uff0c\u4e3a\u5408\u6210\u6570\u636e\u751f\u6210\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14418", "pdf": "https://arxiv.org/pdf/2507.14418", "abs": "https://arxiv.org/abs/2507.14418", "authors": ["Taufiq Daryanto", "Sophia Stil", "Xiaohan Ding", "Daniel Manesh", "Sang Won Lee", "Tim Lee", "Stephanie Lunn", "Sarah Rodriguez", "Chris Brown", "Eugenia Rho"], "title": "Designing Conversational AI to Support Think-Aloud Practice in Technical Interview Preparation for CS Students", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "One challenge in technical interviews is the think-aloud process, where\ncandidates verbalize their thought processes while solving coding tasks.\nDespite its importance, opportunities for structured practice remain limited.\nConversational AI offers potential assistance, but limited research explores\nuser perceptions of its role in think-aloud practice. To address this gap, we\nconducted a study with 17 participants using an LLM-based technical interview\npractice tool. Participants valued AI's role in simulation, feedback, and\nlearning from generated examples. Key design recommendations include promoting\nsocial presence in conversational AI for technical interview simulation,\nproviding feedback beyond verbal content analysis, and enabling crowdsourced\nthink-aloud examples through human-AI collaboration. Beyond feature design, we\nexamined broader considerations, including intersectional challenges and\npotential strategies to address them, how AI-driven interview preparation could\npromote equitable learning in computing careers, and the need to rethink AI's\nrole in interview practice by suggesting a research direction that integrates\nhuman-AI collaboration.", "AI": {"tldr": "\u7814\u7a76\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6280\u672f\u9762\u8bd5\u7ec3\u4e60\u5de5\u5177\uff0c\u63a2\u8ba8\u7528\u6237\u5bf9\u5bf9\u8bdd\u5f0fAI\u5728\u51fa\u58f0\u601d\u8003\u7ec3\u4e60\u4e2d\u4f5c\u7528\u7684\u770b\u6cd5\uff0c\u7ed9\u51fa\u8bbe\u8ba1\u5efa\u8bae\u5e76\u63a2\u8ba8\u66f4\u5e7f\u6cdb\u95ee\u9898\u3002", "motivation": "\u6280\u672f\u9762\u8bd5\u51fa\u58f0\u601d\u8003\u7ec3\u4e60\u673a\u4f1a\u6709\u9650\uff0c\u4e14\u7f3a\u4e4f\u5173\u4e8e\u7528\u6237\u5bf9\u5bf9\u8bdd\u5f0fAI\u5728\u6b64\u7ec3\u4e60\u4e2d\u4f5c\u7528\u7684\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6280\u672f\u9762\u8bd5\u7ec3\u4e60\u5de5\u5177\uff0c\u5bf917\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u53c2\u4e0e\u8005\u8ba4\u53efAI\u5728\u6a21\u62df\u3001\u53cd\u9988\u548c\u4ece\u751f\u6210\u793a\u4f8b\u4e2d\u5b66\u4e60\u65b9\u9762\u7684\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u8bbe\u8ba1\u5efa\u8bae\uff0c\u5982\u4fc3\u8fdb\u5bf9\u8bdd\u5f0fAI\u793e\u4ea4\u5b58\u5728\u3001\u63d0\u4f9b\u8d85\u8d8a\u5185\u5bb9\u5206\u6790\u7684\u53cd\u9988\u7b49\uff0c\u8fd8\u63a2\u8ba8\u4e86\u66f4\u5e7f\u6cdb\u7684\u8003\u8651\u56e0\u7d20\u548c\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.15846", "pdf": "https://arxiv.org/pdf/2507.15846", "abs": "https://arxiv.org/abs/2507.15846", "authors": ["Fei Tang", "Zhangxuan Gu", "Zhengxi Lu", "Xuyang Liu", "Shuheng Shen", "Changhua Meng", "Wen Wang", "Wenqi Zhang", "Yongliang Shen", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": null, "summary": "Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.", "AI": {"tldr": "\u63d0\u51faGUI - G\u00b2\u5956\u52b1\u6846\u67b6\uff0c\u5c06GUI\u63a5\u5730\u4ece\u7a00\u758f\u4e8c\u5143\u5206\u7c7b\u8f6c\u53d8\u4e3a\u5bc6\u96c6\u8fde\u7eed\u4f18\u5316\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8eSOTA\u65b9\u6cd5\uff0c\u4e3aGUI\u4ea4\u4e92\u4efb\u52a1\u7a7a\u95f4\u63a8\u7406\u5efa\u7acb\u65b0\u8303\u5f0f\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u4e8c\u5143\u5956\u52b1\uff0c\u5ffd\u7565\u7a7a\u95f4\u4ea4\u4e92\u8fde\u7eed\u6027\uff0c\u53d7\u4eba\u7c7b\u70b9\u51fb\u884c\u4e3a\u542f\u53d1\u63d0\u51fa\u65b0\u6846\u67b6\u3002", "method": "\u5f15\u5165GUI - G\u00b2\u5956\u52b1\u6846\u67b6\uff0c\u5305\u542b\u9ad8\u65af\u70b9\u5956\u52b1\u548c\u8986\u76d6\u5956\u52b1\u673a\u5236\uff0c\u8fd8\u6709\u81ea\u9002\u5e94\u65b9\u5dee\u673a\u5236\u5904\u7406\u4e0d\u540c\u5143\u7d20\u5c3a\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGUI - G\u00b2\u5927\u5e45\u4f18\u4e8eSOTA\u65b9\u6cd5UI - TARS - 72B\uff0c\u5728ScreenSpot - Pro\u4e0a\u63d0\u534724.7%\u3002", "conclusion": "\u8fde\u7eed\u5efa\u6a21\u5bf9\u754c\u9762\u53d8\u5316\u6709\u66f4\u597d\u9c81\u68d2\u6027\uff0c\u5bf9\u672a\u89c1\u5e03\u5c40\u6709\u66f4\u5f3a\u6cdb\u5316\u6027\uff0c\u4e3aGUI\u4ea4\u4e92\u4efb\u52a1\u7a7a\u95f4\u63a8\u7406\u5efa\u7acb\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.15857", "pdf": "https://arxiv.org/pdf/2507.15857", "abs": "https://arxiv.org/abs/2507.15857", "authors": ["Mihir Prabhudesai", "Menging Wu", "Amir Zadeh", "Katerina Fragkiadaki", "Deepak Pathak"], "title": "Diffusion Beats Autoregressive in Data-Constrained Settings", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": "Project Webpage: https://diffusion-scaling.github.io", "summary": "Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.", "AI": {"tldr": "\u7814\u7a76\u53d7\u9650\u6570\u636e\u4e0b\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u53d1\u73b0\u5176\u5728\u6570\u636e\u5c11\u8ba1\u7b97\u591a\u573a\u666f\u4f18\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u8fd8\u627e\u5230\u65b0\u7f29\u653e\u5b9a\u5f8b\u548c\u4e34\u754c\u8ba1\u7b97\u9608\u503c\u3002", "motivation": "\u63a2\u7d22\u6269\u6563\u8bed\u8a00\u6a21\u578b\u76f8\u5bf9\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4f18\u52bf\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u53d7\u9650\u6570\u636e\u4e0b\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u5bf9\u6bd4\u5176\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u8868\u73b0\u3002", "result": "\u53d7\u9650\u6570\u636e\u4e0b\uff0c\u8ba1\u7b97\u8d44\u6e90\u4e30\u5bcc\u65f6\u6269\u6563\u6a21\u578b\u4f18\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u627e\u5230\u65b0\u7f29\u653e\u5b9a\u5f8b\u548c\u4e34\u754c\u8ba1\u7b97\u9608\u503c\u3002", "conclusion": "\u6570\u636e\u53d7\u9650\u800c\u975e\u8ba1\u7b97\u53d7\u9650\u60c5\u51b5\u4e0b\uff0c\u6269\u6563\u6a21\u578b\u662f\u81ea\u56de\u5f52\u8303\u5f0f\u7684\u6709\u529b\u66ff\u4ee3\u3002"}}
{"id": "2507.14144", "pdf": "https://arxiv.org/pdf/2507.14144", "abs": "https://arxiv.org/abs/2507.14144", "authors": ["Cyril Falcon", "Hassan Mortada", "Math\u00e9o Clavaud", "Jean-Philippe Michel"], "title": "Recursive KalmanNet: Analyse des capacit\u00e9s de g\u00e9n\u00e9ralisation d'un r\u00e9seau de neurones r\u00e9current guid\u00e9 par un filtre de Kalman", "categories": ["eess.SP", "cs.LG"], "comment": "4 pages, in French language. 4 figures. Accepted for publication in\n  GRETSI 2025 proceedings", "summary": "The Recursive KalmanNet, recently introduced by the authors, is a recurrent\nneural network guided by a Kalman filter, capable of estimating the state\nvariables and error covariance of stochastic dynamic systems from noisy\nmeasurements, without prior knowledge of the noise characteristics. This paper\nexplores its generalization capabilities in out-of-distribution scenarios,\nwhere the temporal dynamics of the test measurements differ from those\nencountered during training.\n  Le Recursive KalmanNet, r\\'ecemment introduit par les auteurs, est un\nr\\'eseau de neurones r\\'ecurrent guid\\'e par un filtre de Kalman, capable\nd'estimer les variables d'\\'etat et la covariance des erreurs des syst\\`emes\ndynamiques stochastiques \\`a partir de mesures bruit\\'ees, sans connaissance\npr\\'ealable des caract\\'eristiques des bruits. Cet article explore ses\ncapacit\\'es de g\\'en\\'eralisation dans des sc\\'enarios hors distribution, o\\`u\nles dynamiques temporelles des mesures de test diff\\`erent de celles\nrencontr\\'ees \\`a l'entra\\^inement.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8Recursive KalmanNet\u5728\u5206\u5e03\u5916\u573a\u666f\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7814\u7a76Recursive KalmanNet\u5728\u6d4b\u8bd5\u6d4b\u91cf\u7684\u65f6\u95f4\u52a8\u6001\u4e0e\u8bad\u7ec3\u65f6\u4e0d\u540c\u7684\u5206\u5e03\u5916\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2507.14147", "pdf": "https://arxiv.org/pdf/2507.14147", "abs": "https://arxiv.org/abs/2507.14147", "authors": ["Kevin Monteiro", "Sam Nallaperuma-Herzberg", "Martina Mason", "Steve Niederer"], "title": "Graph Convolutional Neural Networks to Model the Brain for Insomnia", "categories": ["eess.SP", "cs.LG", "q-bio.NC"], "comment": "12 pages, 6 figures. This version has been accepted as a full paper\n  at the 2025 AI in Healthcare (AIiH) Conference", "summary": "Insomnia affects a vast population of the world and can have a wide range of\ncauses. Existing treatments for insomnia have been linked with many side\neffects like headaches, dizziness, etc. As such, there is a clear need for\nimproved insomnia treatment. Brain modelling has helped with assessing the\neffects of brain pathology on brain network dynamics and with supporting\nclinical decisions in the treatment of Alzheimer's disease, epilepsy, etc.\nHowever, such models have not been developed for insomnia. Therefore, this\nproject attempts to understand the characteristics of the brain of individuals\nexperiencing insomnia using continuous long-duration EEG data. Brain networks\nare derived based on functional connectivity and spatial distance between EEG\nchannels. The power spectral density of the channels is then computed for the\nmajor brain wave frequency bands. A graph convolutional neural network (GCNN)\nmodel is then trained to capture the functional characteristics associated with\ninsomnia and configured for the classification task to judge performance.\nResults indicated a 50-second non-overlapping sliding window was the most\nsuitable choice for EEG segmentation. This approach achieved a classification\naccuracy of 70% at window level and 68% at subject level. Additionally, the\nomission of EEG channels C4-P4, F4-C4 and C4-A1 caused higher degradation in\nmodel performance than the removal of other channels. These channel electrodes\nare positioned near brain regions known to exhibit atypical levels of\nfunctional connectivity in individuals with insomnia, which can explain such\nresults.", "AI": {"tldr": "\u6587\u7ae0\u5c1d\u8bd5\u7528\u957f\u65f6\u7a0bEEG\u6570\u636e\u7814\u7a76\u5931\u7720\u60a3\u8005\u5927\u8111\u7279\u5f81\uff0c\u6784\u5efaGCNN\u6a21\u578b\u5206\u7c7b\uff0c\u786e\u5b9a\u5408\u9002EEG\u5206\u5272\u7a97\u53e3\uff0c\u53d6\u5f97\u4e00\u5b9a\u5206\u7c7b\u51c6\u786e\u7387\u5e76\u53d1\u73b0\u90e8\u5206\u5173\u952eEEG\u901a\u9053\u3002", "motivation": "\u5931\u7720\u5f71\u54cd\u4eba\u7fa4\u5e7f\u4e14\u73b0\u6709\u6cbb\u7597\u6709\u526f\u4f5c\u7528\uff0c\u9700\u6539\u8fdb\u6cbb\u7597\u65b9\u6cd5\uff0c\u4e14\u5c1a\u65e0\u9488\u5bf9\u5931\u7720\u7684\u8111\u6a21\u578b\u3002", "method": "\u7528\u957f\u65f6\u7a0bEEG\u6570\u636e\uff0c\u57fa\u4e8e\u529f\u80fd\u8fde\u63a5\u548c\u7a7a\u95f4\u8ddd\u79bb\u6784\u5efa\u8111\u7f51\u7edc\uff0c\u8ba1\u7b97\u8111\u7535\u6ce2\u529f\u7387\u8c31\u5bc6\u5ea6\uff0c\u8bad\u7ec3GCNN\u6a21\u578b\u5206\u7c7b\u3002", "result": "50\u79d2\u975e\u91cd\u53e0\u6ed1\u52a8\u7a97\u53e3\u6700\u9002\u5408EEG\u5206\u5272\uff0c\u7a97\u53e3\u7ea7\u5206\u7c7b\u51c6\u786e\u738770%\uff0c\u53d7\u8bd5\u8005\u7ea768%\uff0c\u79fb\u9664C4 - P4\u3001F4 - C4\u548cC4 - A1\u901a\u9053\u7535\u6781\u4f7f\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u66f4\u660e\u663e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5bf9\u7406\u89e3\u5931\u7720\u60a3\u8005\u5927\u8111\u7279\u5f81\u548c\u6784\u5efa\u5206\u7c7b\u6a21\u578b\u6709\u4e00\u5b9a\u6548\u679c\uff0c\u7279\u5b9aEEG\u901a\u9053\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u5927\u3002"}}
{"id": "2507.14481", "pdf": "https://arxiv.org/pdf/2507.14481", "abs": "https://arxiv.org/abs/2507.14481", "authors": ["Yujia Tong", "Jingling Yuan", "Tian Zhang", "Jianquan Liu", "Chuang Hu"], "title": "DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Data-Free Quantization (DFQ) enables the quantization of Vision Transformers\n(ViTs) without requiring access to data, allowing for the deployment of ViTs on\ndevices with limited resources. In DFQ, the quantization model must be\ncalibrated using synthetic samples, making the quality of these synthetic\nsamples crucial. Existing methods fail to fully capture and balance the global\nand local features within the samples, resulting in limited synthetic data\nquality. Moreover, we have found that during inference, there is a significant\ndifference in the distributions of intermediate layer activations between the\nquantized and full-precision models. These issues lead to a severe performance\ndegradation of the quantized model. To address these problems, we propose a\npipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT).\nSpecifically, we synthesize samples in order of increasing difficulty,\neffectively enhancing the quality of synthetic data. During the calibration and\ninference stage, we introduce the activation correction matrix for the\nquantized model to align the intermediate layer activations with those of the\nfull-precision model. Extensive experiments demonstrate that DFQ-ViT achieves\nremarkable superiority over existing DFQ methods and its performance is on par\nwith models quantized through real data. For example, the performance of DeiT-T\nwith 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our\nmethod eliminates the need for fine-tuning, which not only reduces\ncomputational overhead but also lowers the deployment barriers for edge\ndevices. This characteristic aligns with the principles of Green Learning by\nimproving energy efficiency and facilitating real-world applications in\nresource-constrained environments.", "AI": {"tldr": "\u63d0\u51faDFQ - ViT\u89e3\u51b3\u73b0\u6709\u6570\u636e\u65e0\u91cf\u5316\u65b9\u6cd5\u5408\u6210\u6837\u672c\u8d28\u91cf\u4f4e\u548c\u6a21\u578b\u6fc0\u6d3b\u5206\u5e03\u5dee\u5f02\u95ee\u9898\uff0c\u6027\u80fd\u8d85\u73b0\u6709\u65b9\u6cd5\u4e14\u65e0\u9700\u5fae\u8c03\uff0c\u7b26\u5408\u7eff\u8272\u5b66\u4e60\u539f\u5219\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u65e0\u91cf\u5316\u65b9\u6cd5\u5408\u6210\u6837\u672c\u65e0\u6cd5\u5e73\u8861\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\uff0c\u91cf\u5316\u548c\u5168\u7cbe\u5ea6\u6a21\u578b\u4e2d\u95f4\u5c42\u6fc0\u6d3b\u5206\u5e03\u5dee\u5f02\u5927\uff0c\u5bfc\u81f4\u91cf\u5316\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u6309\u96be\u5ea6\u9012\u589e\u5408\u6210\u6837\u672c\u63d0\u5347\u5408\u6210\u6570\u636e\u8d28\u91cf\uff1b\u5728\u91cf\u5316\u6a21\u578b\u6821\u51c6\u548c\u63a8\u7406\u9636\u6bb5\u5f15\u5165\u6fc0\u6d3b\u6821\u6b63\u77e9\u9635\u4f7f\u4e2d\u95f4\u5c42\u6fc0\u6d3b\u4e0e\u5168\u7cbe\u5ea6\u6a21\u578b\u5bf9\u9f50\u3002", "result": "DFQ - ViT\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709DFQ\u65b9\u6cd5\uff0c\u4e0e\u771f\u5b9e\u6570\u636e\u91cf\u5316\u6a21\u578b\u76f8\u5f53\uff0c\u5982DeiT - T 3\u4f4d\u6743\u91cd\u91cf\u5316\u6027\u80fd\u6bd4\u73b0\u6709\u6280\u672f\u9ad84.29%\u3002", "conclusion": "\u65b9\u6cd5\u65e0\u9700\u5fae\u8c03\uff0c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u548c\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u969c\u788d\uff0c\u7b26\u5408\u7eff\u8272\u5b66\u4e60\u539f\u5219\uff0c\u5229\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u5e94\u7528\u3002"}}
{"id": "2507.14485", "pdf": "https://arxiv.org/pdf/2507.14485", "abs": "https://arxiv.org/abs/2507.14485", "authors": ["Hongye Hou", "Liu Zhan", "Yang Yang"], "title": "Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Completing the whole 3D structure based on an incomplete point cloud is a\nchallenging task, particularly when the residual point cloud lacks typical\nstructural characteristics. Recent methods based on cross-modal learning\nattempt to introduce instance images to aid the structure feature learning.\nHowever, they still focus on each particular input class, limiting their\ngeneration abilities. In this work, we propose a novel retrieval-augmented\npoint cloud completion framework. The core idea is to incorporate cross-modal\nretrieval into completion task to learn structural prior information from\nsimilar reference samples. Specifically, we design a Structural Shared Feature\nEncoder (SSFE) to jointly extract cross-modal features and reconstruct\nreference features as priors. Benefiting from a dual-channel control gate in\nthe encoder, relevant structural features in the reference sample are enhanced\nand irrelevant information interference is suppressed. In addition, we propose\na Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical\nfeature fusion mechanism to integrate reference prior information with input\nfeatures from global to local. Through extensive evaluations on multiple\ndatasets and real-world scenes, our method shows its effectiveness in\ngenerating fine-grained point clouds, as well as its generalization capability\nin handling sparse data and unseen categories.", "AI": {"tldr": "\u63d0\u51fa\u68c0\u7d22\u589e\u5f3a\u70b9\u4e91\u8865\u5168\u6846\u67b6\uff0c\u7ed3\u5408\u8de8\u6a21\u6001\u68c0\u7d22\u5b66\u4e60\u7ed3\u6784\u5148\u9a8c\u4fe1\u606f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u4e14\u6709\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8de8\u6a21\u6001\u5b66\u4e60\u7684\u70b9\u4e91\u8865\u5168\u65b9\u6cd5\u4e13\u6ce8\u7279\u5b9a\u8f93\u5165\u7c7b\uff0c\u9650\u5236\u751f\u6210\u80fd\u529b\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u68c0\u7d22\u589e\u5f3a\u70b9\u4e91\u8865\u5168\u6846\u67b6\uff0c\u8bbe\u8ba1SSFE\u63d0\u53d6\u8de8\u6a21\u6001\u7279\u5f81\u5e76\u91cd\u6784\u53c2\u8003\u7279\u5f81\u4f5c\u5148\u9a8c\uff0c\u7528\u53cc\u6e20\u9053\u63a7\u5236\u95e8\u589e\u5f3a\u76f8\u5173\u7279\u5f81\u3001\u6291\u5236\u65e0\u5173\u4fe1\u606f\uff1b\u63d0\u51faPRAG\u91c7\u7528\u5206\u5c42\u7279\u5f81\u878d\u5408\u673a\u5236\u6574\u5408\u53c2\u8003\u5148\u9a8c\u548c\u8f93\u5165\u7279\u5f81\u3002", "result": "\u5728\u591a\u6570\u636e\u96c6\u548c\u771f\u5b9e\u573a\u666f\u8bc4\u4f30\u4e2d\uff0c\u80fd\u751f\u6210\u7ec6\u7c92\u5ea6\u70b9\u4e91\u3002", "conclusion": "\u65b9\u6cd5\u5728\u751f\u6210\u7ec6\u7c92\u5ea6\u70b9\u4e91\u65b9\u9762\u6709\u6548\uff0c\u4e14\u5728\u5904\u7406\u7a00\u758f\u6570\u636e\u548c\u672a\u89c1\u7c7b\u522b\u4e0a\u6709\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.14152", "pdf": "https://arxiv.org/pdf/2507.14152", "abs": "https://arxiv.org/abs/2507.14152", "authors": ["Frank Efe Erukainure", "Feidra Gjata", "Matin Ataei Kachouei", "Henry Cox", "Md. Azahar Ali"], "title": "Machine learning-enabled river water quality monitoring using lithography-free 3D-printed sensors", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY", "physics.ins-det"], "comment": "34 pages, 9 figures", "summary": "River water quality monitoring is important for aquatic life, livestock, and\nhumans because clean water is critical to meeting food demand during the global\nfood crisis. Excessive contaminants, including phosphate, deplete dissolved\noxygen and trigger eutrophication, leading to serious health and ecological\nproblems. Continuous sensors that track phosphate levels can therefore help\nprevent eutrophication. In this work we present a lithography-free phosphate\nsensor (P-sensor) that detects phosphate in river water at parts-per-billion\nlevels. The device uses a solid-state indicator electrode formed by 3D-printed\nperiodic polymer patterns (8 um feature size) coated with a thin phosphate\nion-selective membrane. The P-sensor detects as little as 1 ppb phosphate\nacross 0 - 475 ppm with a response time under 30 seconds. We validated the\nsensor on Rappahannock River water, Virginia (less than 0.8 ppm phosphate) at\nsites upstream and downstream of a sewage treatment plant and benchmarked the\nresults against a commercial phosphate meter. A feed-forward neural network was\ntrained to predict phosphate levels, achieving a mean-squared error below 1e-3,\nzero standard deviation, and a Pearson correlation coefficient of 0.997 for\nriver samples. These results demonstrate a practical tool for continuous\nwater-quality monitoring that can inform stakeholders and policymakers and\nultimately improve public health.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65e0\u5149\u523b\u78f7\u9178\u76d0\u4f20\u611f\u5668\uff0c\u53ef\u68c0\u6d4b\u6cb3\u6c34\u4e2d\u4f4e\u81f3\u5341\u4ebf\u5206\u4e4b\u4e00\u6c34\u5e73\u7684\u78f7\u9178\u76d0\uff0c\u7ecf\u6d4b\u8bd5\u9a8c\u8bc1\u6548\u679c\u826f\u597d\uff0c\u662f\u8fde\u7eed\u6c34\u8d28\u76d1\u6d4b\u7684\u5b9e\u7528\u5de5\u5177\u3002", "motivation": "\u6cb3\u6d41\u6c34\u8d28\u76d1\u6d4b\u5bf9\u6c34\u751f\u751f\u7269\u3001\u7272\u755c\u548c\u4eba\u7c7b\u5f88\u91cd\u8981\uff0c\u8fc7\u91cf\u6c61\u67d3\u7269\uff08\u5982\u78f7\u9178\u76d0\uff09\u4f1a\u5bfc\u81f4\u5bcc\u8425\u517b\u5316\u7b49\u95ee\u9898\uff0c\u9700\u8981\u80fd\u76d1\u6d4b\u78f7\u9178\u76d0\u6c34\u5e73\u7684\u4f20\u611f\u5668\u6765\u9884\u9632\u3002", "method": "\u5236\u4f5c\u65e0\u5149\u523b\u78f7\u9178\u76d0\u4f20\u611f\u5668\uff08P - sensor\uff09\uff0c\u91c7\u75283D\u6253\u5370\u5468\u671f\u6027\u805a\u5408\u7269\u56fe\u6848\u6d82\u8986\u78f7\u9178\u76d0\u79bb\u5b50\u9009\u62e9\u6027\u8584\u819c\u5f62\u6210\u56fa\u6001\u6307\u793a\u7535\u6781\uff1b\u7528\u62c9\u5e15\u6c49\u8bfa\u514b\u6cb3\u6cb3\u6c34\u9a8c\u8bc1\u4f20\u611f\u5668\uff0c\u5e76\u4e0e\u5546\u4e1a\u78f7\u9178\u76d0\u6d4b\u91cf\u4eea\u5bf9\u6bd4\uff1b\u8bad\u7ec3\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u78f7\u9178\u76d0\u6c34\u5e73\u3002", "result": "P - sensor\u53ef\u57280 - 475 ppm\u8303\u56f4\u5185\u68c0\u6d4b\u4f4e\u81f31 ppb\u7684\u78f7\u9178\u76d0\uff0c\u54cd\u5e94\u65f6\u95f4\u4e0d\u523030\u79d2\uff1b\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u78f7\u9178\u76d0\u6c34\u5e73\u7684\u5747\u65b9\u8bef\u5dee\u4f4e\u4e8e1e - 3\uff0c\u6807\u51c6\u5dee\u4e3a0\uff0c\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u4e3a0.997\u3002", "conclusion": "\u8be5\u4f20\u611f\u5668\u662f\u8fde\u7eed\u6c34\u8d28\u76d1\u6d4b\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u53ef\u544a\u77e5\u5229\u76ca\u76f8\u5173\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\uff0c\u6700\u7ec8\u6539\u5584\u516c\u4f17\u5065\u5eb7\u3002"}}
{"id": "2507.14159", "pdf": "https://arxiv.org/pdf/2507.14159", "abs": "https://arxiv.org/abs/2507.14159", "authors": ["Shanshan Wang", "Dian Xu", "Jianmin Shen", "Feng Gao", "Wei Li", "Weibing Deng"], "title": "Siamese Neural Network for Label-Efficient Critical Phenomena Prediction in 3D Percolation Models", "categories": ["cond-mat.dis-nn", "cs.LG"], "comment": "14 pages, 9 figures", "summary": "Percolation theory serves as a cornerstone for studying phase transitions and\ncritical phenomena, with broad implications in statistical physics, materials\nscience, and complex networks. However, most machine learning frameworks for\npercolation analysis have focused on two-dimensional systems, oversimplifying\nthe spatial correlations and morphological complexity of real-world\nthree-dimensional materials. To bridge this gap and improve label efficiency\nand scalability in 3D systems, we propose a Siamese Neural Network (SNN) that\nleverages features of the largest cluster as discriminative input. Our method\nachieves high predictive accuracy for both site and bond percolation thresholds\nand critical exponents in three dimensions, with sub-1% error margins using\nsignificantly fewer labeled samples than traditional approaches. This work\nestablishes a robust and data-efficient framework for modeling high-dimensional\ncritical phenomena, with potential applications in materials discovery and\ncomplex network analysis.", "AI": {"tldr": "\u63d0\u51fa\u7528Siamese\u795e\u7ecf\u7f51\u7edc\u5206\u67903D\u6e17\u6d41\uff0c\u51c6\u786e\u7387\u9ad8\u4e14\u6570\u636e\u6548\u7387\u9ad8\u3002", "motivation": "\u591a\u6570\u673a\u5668\u5b66\u4e60\u6e17\u6d41\u5206\u6790\u6846\u67b6\u805a\u7126\u4e8c\u7ef4\u7cfb\u7edf\uff0c\u65e0\u6cd5\u5904\u7406\u4e09\u7ef4\u6750\u6599\u7a7a\u95f4\u76f8\u5173\u6027\u548c\u5f62\u6001\u590d\u6742\u6027\uff0c\u9700\u63d0\u9ad83D\u7cfb\u7edf\u6807\u7b7e\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faSiamese\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u6700\u5927\u7c07\u7279\u5f81\u4f5c\u4e3a\u5224\u522b\u8f93\u5165\u3002", "result": "\u5bf9\u4e09\u7ef4\u4f4d\u70b9\u548c\u952e\u6e17\u6d41\u9608\u503c\u53ca\u4e34\u754c\u6307\u6570\u9884\u6d4b\u51c6\u786e\u7387\u9ad8\uff0c\u8bef\u5dee\u7387\u4f4e\u4e8e1%\uff0c\u6240\u9700\u6807\u8bb0\u6837\u672c\u8fdc\u5c11\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u5efa\u7acb\u4e86\u7528\u4e8e\u5efa\u6a21\u9ad8\u7ef4\u4e34\u754c\u73b0\u8c61\u7684\u5f3a\u5927\u4e14\u6570\u636e\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u6709\u6750\u6599\u53d1\u73b0\u548c\u590d\u6742\u7f51\u7edc\u5206\u6790\u7b49\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2507.14519", "pdf": "https://arxiv.org/pdf/2507.14519", "abs": "https://arxiv.org/abs/2507.14519", "authors": ["Wenxuan Zeng", "Tianshi Xu", "Yi Chen", "Yifan Zhou", "Mingzhe Zhang", "Jin Tan", "Cheng Hong", "Meng Li"], "title": "Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives", "categories": ["cs.CR", "cs.AI"], "comment": "This work will be continuously updated to reflect the latest advances", "summary": "Privacy-preserving machine learning (PPML) based on cryptographic protocols\nhas emerged as a promising paradigm to protect user data privacy in cloud-based\nmachine learning services. While it achieves formal privacy protection, PPML\noften incurs significant efficiency and scalability costs due to orders of\nmagnitude overhead compared to the plaintext counterpart. Therefore, there has\nbeen a considerable focus on mitigating the efficiency gap for PPML. In this\nsurvey, we provide a comprehensive and systematic review of recent PPML studies\nwith a focus on cross-level optimizations. Specifically, we categorize existing\npapers into protocol level, model level, and system level, and review progress\nat each level. We also provide qualitative and quantitative comparisons of\nexisting works with technical insights, based on which we discuss future\nresearch directions and highlight the necessity of integrating optimizations\nacross protocol, model, and system levels. We hope this survey can provide an\noverarching understanding of existing approaches and potentially inspire future\nbreakthroughs in the PPML field. As the field is evolving fast, we also provide\na public GitHub repository to continuously track the developments, which is\navailable at https://github.com/PKU-SEC-Lab/Awesome-PPML-Papers.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u8de8\u5c42\u4f18\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\uff08PPML\uff09\u7814\u7a76\u8fdb\u884c\u5168\u9762\u7cfb\u7edf\u7efc\u8ff0\uff0c\u5206\u7c7b\u56de\u987e\u8fdb\u5c55\uff0c\u6bd4\u8f83\u73b0\u6709\u5de5\u4f5c\uff0c\u8ba8\u8bba\u672a\u6765\u65b9\u5411\u5e76\u63d0\u4f9bGitHub\u8ddf\u8e2a\u8fdb\u5c55\u3002", "motivation": "PPML\u867d\u80fd\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u5b58\u5728\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u9700\u7f29\u5c0f\u4e0e\u660e\u6587\u673a\u5668\u5b66\u4e60\u7684\u6548\u7387\u5dee\u8ddd\u3002", "method": "\u5c06\u73b0\u6709\u8bba\u6587\u5206\u4e3a\u534f\u8bae\u5c42\u3001\u6a21\u578b\u5c42\u548c\u7cfb\u7edf\u5c42\u8fdb\u884c\u5206\u7c7b\u56de\u987e\uff0c\u5e76\u5bf9\u73b0\u6709\u5de5\u4f5c\u8fdb\u884c\u5b9a\u6027\u548c\u5b9a\u91cf\u6bd4\u8f83\u3002", "result": "\u5bf9PPML\u7814\u7a76\u8fdb\u5c55\u8fdb\u884c\u4e86\u5168\u9762\u68b3\u7406\u548c\u6bd4\u8f83\uff0c\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6b21\u7efc\u8ff0\u6709\u52a9\u4e8e\u5168\u9762\u7406\u89e3\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u671b\u6fc0\u53d1PPML\u9886\u57df\u7684\u672a\u6765\u7a81\u7834\uff0c\u540c\u65f6\u63d0\u4f9bGitHub\u4ed3\u5e93\u8ddf\u8e2a\u53d1\u5c55\u3002"}}
{"id": "2507.14544", "pdf": "https://arxiv.org/pdf/2507.14544", "abs": "https://arxiv.org/abs/2507.14544", "authors": ["Sujata Gaihre", "Amir Thapa Magar", "Prasuna Pokharel", "Laxmi Tiwari"], "title": "Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025", "categories": ["cs.CV", "cs.AI", "68T45 (Machine vision and scene understanding)", "I.2.10; I.4.8; H.3.1"], "comment": "accepted to ImageCLEF 2025, to be published in the lab proceedings", "summary": "This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA\n2025 Challenge, which targets visual question answering (VQA) for\ngastrointestinal endoscopy. We adopt the Florence model-a large-scale\nmultimodal foundation model-as the backbone of our VQA pipeline, pairing a\npowerful vision encoder with a text encoder to interpret endoscopic images and\nproduce clinically relevant answers. To improve generalization, we apply\ndomain-specific augmentations that preserve medical features while increasing\ntraining diversity. Experiments on the KASVIR dataset show that fine-tuning\nFlorence yields accurate responses on the official challenge metrics. Our\nresults highlight the potential of large multimodal models in medical VQA and\nprovide a strong baseline for future work on explainability, robustness, and\nclinical integration. The code is publicly available at:\nhttps://github.com/TiwariLaxuu/VQA-Florence.git", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u53c2\u52a0ImageCLEFmed MEDVQA 2025\u6311\u6218\u8d5b\u5b50\u4efb\u52a11\u7684\u65b9\u6cd5\uff0c\u91c7\u7528Florence\u6a21\u578b\uff0c\u5e94\u7528\u7279\u5b9a\u589e\u5f3a\u65b9\u6cd5\uff0c\u5728KASVIR\u6570\u636e\u96c6\u5b9e\u9a8c\u6709\u6548\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u89e3\u51b3\u80c3\u80a0\u9053\u5185\u7aa5\u955c\u89c6\u89c9\u95ee\u7b54\u95ee\u9898\uff0c\u53c2\u52a0ImageCLEFmed MEDVQA 2025\u6311\u6218\u8d5b\u5b50\u4efb\u52a11\u3002", "method": "\u91c7\u7528Florence\u6a21\u578b\u4f5c\u4e3a\u89c6\u89c9\u95ee\u7b54\u7ba1\u9053\u7684\u9aa8\u5e72\uff0c\u7ed3\u5408\u89c6\u89c9\u7f16\u7801\u5668\u548c\u6587\u672c\u7f16\u7801\u5668\uff0c\u5e94\u7528\u7279\u5b9a\u589e\u5f3a\u65b9\u6cd5\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728KASVIR\u6570\u636e\u96c6\u4e0a\u5fae\u8c03Florence\u6a21\u578b\uff0c\u5728\u5b98\u65b9\u6311\u6218\u6307\u6807\u4e0a\u83b7\u5f97\u51c6\u786e\u54cd\u5e94\u3002", "conclusion": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u4e2d\u6709\u6f5c\u529b\uff0c\u4e3a\u540e\u7eed\u53ef\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u548c\u4e34\u5e8a\u96c6\u6210\u5de5\u4f5c\u63d0\u4f9b\u57fa\u7ebf\u3002"}}
{"id": "2507.14575", "pdf": "https://arxiv.org/pdf/2507.14575", "abs": "https://arxiv.org/abs/2507.14575", "authors": ["Andrea Moschetto", "Lemuel Puglisi", "Alec Sargood", "Pierluigi Dell'Acqua", "Francesco Guarnera", "Sebastiano Battiato", "Daniele Rav\u00ec"], "title": "Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image\ncontrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering\ndistinct diagnostic insights. However, acquiring all desired modalities\nincreases scan time and cost, motivating research into computational methods\nfor cross-modal synthesis. To address this, recent approaches aim to synthesize\nmissing MRI contrasts from those already acquired, reducing acquisition time\nwhile preserving diagnostic quality. Image-to-image (I2I) translation provides\na promising framework for this task. In this paper, we present a comprehensive\nbenchmark of generative models$\\unicode{x2013}$specifically, Generative\nAdversarial Networks (GANs), diffusion models, and flow matching (FM)\ntechniques$\\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All\nframeworks are implemented with comparable settings and evaluated on three\npublicly available MRI datasets of healthy adults. Our quantitative and\nqualitative analyses show that the GAN-based Pix2Pix model outperforms\ndiffusion and FM-based methods in terms of structural fidelity, image quality,\nand computational efficiency. Consistent with existing literature, these\nresults suggest that flow-based models are prone to overfitting on small\ndatasets and simpler tasks, and may require more data to match or surpass GAN\nperformance. These findings offer practical guidance for deploying I2I\ntranslation techniques in real-world MRI workflows and highlight promising\ndirections for future research in cross-modal medical image synthesis. Code and\nmodels are publicly available at\nhttps://github.com/AndreaMoschetto/medical-I2I-benchmark.", "AI": {"tldr": "\u5bf9\u751f\u6210\u6a21\u578b\u8fdb\u884cT1w\u5230T2w 2D MRI\u56fe\u50cf\u7ffb\u8bd1\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0cGAN\u7684Pix2Pix\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "MRI\u83b7\u53d6\u6240\u6709\u6a21\u6001\u4f1a\u589e\u52a0\u626b\u63cf\u65f6\u95f4\u548c\u6210\u672c\uff0c\u56e0\u6b64\u7814\u7a76\u8de8\u6a21\u6001\u5408\u6210\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u5bf9GAN\u3001\u6269\u6563\u6a21\u578b\u548c\u6d41\u5339\u914d\u6280\u672f\u8fdb\u884cT1w\u5230T2w 2D MRI\u56fe\u50cf\u7ffb\u8bd1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u3002", "result": "GAN\u7684Pix2Pix\u6a21\u578b\u5728\u7ed3\u6784\u4fdd\u771f\u5ea6\u3001\u56fe\u50cf\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u6269\u6563\u548c\u6d41\u5339\u914d\u65b9\u6cd5\uff0c\u6d41\u6a21\u578b\u5728\u5c0f\u6570\u636e\u96c6\u548c\u7b80\u5355\u4efb\u52a1\u4e2d\u6613\u8fc7\u62df\u5408\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5b9e\u9645MRI\u5de5\u4f5c\u6d41\u7a0b\u90e8\u7f72\u56fe\u50cf\u7ffb\u8bd1\u6280\u672f\u63d0\u4f9b\u6307\u5bfc\uff0c\u6307\u51fa\u8de8\u6a21\u6001\u533b\u5b66\u56fe\u50cf\u5408\u6210\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.14579", "pdf": "https://arxiv.org/pdf/2507.14579", "abs": "https://arxiv.org/abs/2507.14579", "authors": ["Kester Wong", "Sahan Bulathwela", "Mutlu Cukurova"], "title": "Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to appear in the workshop proceedings for the HEXED'25\n  workshop in the 26th International Conference on Artificial Intelligence in\n  Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 5 pages", "summary": "Detecting collaborative problem solving (CPS) indicators from dialogue using\nmachine learning techniques is a significant challenge for the field of AI in\nEducation. Recent studies have explored the use of Bidirectional Encoder\nRepresentations from Transformers (BERT) models on transcription data to\nreliably detect meaningful CPS indicators. A notable advancement involved the\nmultimodal BERT variant, AudiBERT, which integrates speech and\nacoustic-prosodic audio features to enhance CPS diagnosis. Although initial\nresults demonstrated multimodal improvements, the statistical significance of\nthese enhancements remained unclear, and there was insufficient guidance on\nleveraging human-AI complementarity for CPS diagnosis tasks. This workshop\npaper extends the previous research by highlighting that the AudiBERT model not\nonly improved the classification of classes that were sparse in the dataset,\nbut it also had statistically significant class-wise improvements over the BERT\nmodel for classifications in the social-cognitive dimension. However, similar\nsignificant class-wise improvements over the BERT model were not observed for\nclassifications in the affective dimension. A correlation analysis highlighted\nthat larger training data was significantly associated with higher recall\nperformance for both the AudiBERT and BERT models. Additionally, the precision\nof the BERT model was significantly associated with high inter-rater agreement\namong human coders. When employing the BERT model to diagnose indicators within\nthese subskills that were well-detected by the AudiBERT model, the performance\nacross all indicators was inconsistent. We conclude the paper by outlining a\nstructured approach towards achieving human-AI complementarity for CPS\ndiagnosis, highlighting the crucial inclusion of model explainability to\nsupport human agency and engagement in the reflective coding process.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u4ece\u5bf9\u8bdd\u4e2d\u68c0\u6d4bCPS\u6307\u6807\uff0c\u7814\u7a76AudiBERT\u548cBERT\u6a21\u578b\u8868\u73b0\uff0c\u6307\u51fa\u6a21\u578b\u5728\u4e0d\u540c\u7ef4\u5ea6\u8868\u73b0\u5dee\u5f02\uff0c\u5206\u6790\u6570\u636e\u91cf\u548c\u4eba\u5de5\u7f16\u7801\u5bf9\u6027\u80fd\u5f71\u54cd\uff0c\u6700\u540e\u63d0\u51fa\u5b9e\u73b0\u4eba\u673a\u4e92\u8865\u7684\u65b9\u6cd5\u3002", "motivation": "\u4e4b\u524d\u7814\u7a76\u867d\u7528BERT\u6a21\u578b\u68c0\u6d4bCPS\u6307\u6807\u6709\u8fdb\u5c55\uff0c\u4f46AudiBERT\u6539\u8fdb\u7684\u7edf\u8ba1\u663e\u8457\u6027\u4e0d\u660e\uff0c\u4e14\u7f3a\u4e4f\u4eba\u673a\u4e92\u8865\u6307\u5bfc\u3002", "method": "\u5bf9\u6bd4AudiBERT\u548cBERT\u6a21\u578b\u5728\u4e0d\u540c\u7ef4\u5ea6\u7684\u5206\u7c7b\u8868\u73b0\uff0c\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\u3002", "result": "AudiBERT\u5728\u793e\u4f1a\u8ba4\u77e5\u7ef4\u5ea6\u5206\u7c7b\u6709\u663e\u8457\u63d0\u5347\uff0c\u60c5\u611f\u7ef4\u5ea6\u65e0\uff1b\u8bad\u7ec3\u6570\u636e\u91cf\u4e0e\u6a21\u578b\u53ec\u56de\u7387\u6b63\u76f8\u5173\uff1bBERT\u6a21\u578b\u7cbe\u5ea6\u4e0e\u4eba\u5de5\u7f16\u7801\u8005\u4e00\u81f4\u6027\u6b63\u76f8\u5173\uff1b\u7528BERT\u8bca\u65adAudiBERT\u68c0\u6d4b\u597d\u7684\u6307\u6807\u8868\u73b0\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u63d0\u51fa\u5b9e\u73b0CPS\u8bca\u65ad\u4eba\u673a\u4e92\u8865\u7684\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u5f3a\u8c03\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.14166", "pdf": "https://arxiv.org/pdf/2507.14166", "abs": "https://arxiv.org/abs/2507.14166", "authors": ["Sankalp Jajee", "Gaurav Kumar", "Homayoun Valafar"], "title": "Automated Vigilance State Classification in Rodents Using Machine Learning and Feature Engineering", "categories": ["eess.SP", "cs.LG"], "comment": "8 pages, 5 figures", "summary": "Preclinical sleep research remains constrained by labor intensive, manual\nvigilance state classification and inter rater variability, limiting throughput\nand reproducibility. This study presents an automated framework developed by\nTeam Neural Prognosticators to classify electroencephalogram (EEG) recordings\nof small rodents into three critical vigilance states paradoxical sleep (REM),\nslow wave sleep (SWS), and wakefulness. The system integrates advanced signal\nprocessing with machine learning, leveraging engineered features from both time\nand frequency domains, including spectral power across canonical EEG bands\n(delta to gamma), temporal dynamics via Maximum-Minimum Distance, and\ncross-frequency coupling metrics. These features capture distinct\nneurophysiological signatures such as high frequency desynchronization during\nwakefulness, delta oscillations in SWS, and REM specific bursts. Validated\nduring the 2024 Big Data Health Science Case Competition (University of South\nCarolina Big Data Health Science Center, 2024), our XGBoost model achieved\n91.5% overall accuracy, 86.8% precision, 81.2% recall, and an F1 score of\n83.5%, outperforming all baseline methods. Our approach represents a critical\nadvancement in automated sleep state classification and a valuable tool for\naccelerating discoveries in sleep science and the development of targeted\ninterventions for chronic sleep disorders. As a publicly available code (BDHSC)\nresource is set to contribute significantly to advancements.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u81ea\u52a8\u5316\u6846\u67b6\u5c06\u5c0f\u578b\u556e\u9f7f\u52a8\u7269\u8111\u7535\u56fe\u8bb0\u5f55\u5206\u7c7b\u4e3a\u4e09\u79cd\u8b66\u89c9\u72b6\u6001\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u81ea\u52a8\u5316\u7761\u7720\u72b6\u6001\u5206\u7c7b\u7684\u91cd\u8981\u8fdb\u5c55\u3002", "motivation": "\u4e34\u5e8a\u524d\u7761\u7720\u7814\u7a76\u53d7\u4eba\u5de5\u8b66\u89c9\u72b6\u6001\u5206\u7c7b\u7684\u52b3\u52a8\u5f3a\u5ea6\u548c\u8bc4\u5206\u8005\u95f4\u5dee\u5f02\u9650\u5236\uff0c\u5f71\u54cd\u901a\u91cf\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u7cfb\u7edf\u96c6\u6210\u5148\u8fdb\u4fe1\u53f7\u5904\u7406\u4e0e\u673a\u5668\u5b66\u4e60\uff0c\u5229\u7528\u65f6\u57df\u548c\u9891\u57df\u7279\u5f81\uff0c\u5982\u9891\u8c31\u529f\u7387\u3001\u6700\u5927 - \u6700\u5c0f\u8ddd\u79bb\u548c\u8de8\u9891\u8026\u5408\u6307\u6807\u3002", "result": "XGBoost\u6a21\u578b\u57282024\u5e74\u6bd4\u8d5b\u4e2d\u9a8c\u8bc1\uff0c\u6574\u4f53\u51c6\u786e\u738791.5%\uff0c\u7cbe\u5ea686.8%\uff0c\u53ec\u56de\u738781.2%\uff0cF1\u5206\u657083.5%\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u81ea\u52a8\u5316\u7761\u7720\u72b6\u6001\u5206\u7c7b\u7684\u5173\u952e\u8fdb\u5c55\uff0c\u53ef\u52a0\u901f\u7761\u7720\u79d1\u5b66\u53d1\u73b0\u548c\u9488\u5bf9\u6162\u6027\u7761\u7720\u969c\u788d\u7684\u5e72\u9884\u63aa\u65bd\u5f00\u53d1\uff0c\u516c\u5f00\u4ee3\u7801\u8d44\u6e90\u5c06\u6709\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2507.14584", "pdf": "https://arxiv.org/pdf/2507.14584", "abs": "https://arxiv.org/abs/2507.14584", "authors": ["Kester Wong", "Sahan Bulathwela", "Mutlu Cukurova"], "title": "Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to appear in the workshop proceedings for the HEXED'25\n  workshop in the 26th International Conference on Artificial Intelligence in\n  Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 6 pages, 2 figures", "summary": "The use of Bidirectional Encoder Representations from Transformers (BERT)\nmodel and its variants for classifying collaborative problem solving (CPS) has\nbeen extensively explored within the AI in Education community. However,\nlimited attention has been given to understanding how individual tokenised\nwords in the dataset contribute to the model's classification decisions.\nEnhancing the explainability of BERT-based CPS diagnostics is essential to\nbetter inform end users such as teachers, thereby fostering greater trust and\nfacilitating wider adoption in education. This study undertook a preliminary\nstep towards model transparency and explainability by using SHapley Additive\nexPlanations (SHAP) to examine how different tokenised words in transcription\ndata contributed to a BERT model's classification of CPS processes. The\nfindings suggested that well-performing classifications did not necessarily\nequate to a reasonable explanation for the classification decisions. Particular\ntokenised words were used frequently to affect classifications. The analysis\nalso identified a spurious word, which contributed positively to the\nclassification but was not semantically meaningful to the class. While such\nmodel transparency is unlikely to be useful to an end user to improve their\npractice, it can help them not to overrely on LLM diagnostics and ignore their\nhuman expertise. We conclude the workshop paper by noting that the extent to\nwhich the model appropriately uses the tokens for its classification is\nassociated with the number of classes involved. It calls for an investigation\ninto the exploration of ensemble model architectures and the involvement of\nhuman-AI complementarity for CPS diagnosis, since considerable human reasoning\nis still required for fine-grained discrimination of CPS subskills.", "AI": {"tldr": "\u672c\u6587\u7528SHAP\u5206\u6790BERT\u6a21\u578b\u5bf9CPS\u5206\u7c7b\u65f6\u5404\u5206\u8bcd\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u5206\u7c7b\u8868\u73b0\u597d\u672a\u5fc5\u89e3\u91ca\u5408\u7406\uff0c\u6a21\u578b\u900f\u660e\u5ea6\u53ef\u9632\u7528\u6237\u8fc7\u5ea6\u4f9d\u8d56\u8bca\u65ad\u3002", "motivation": "\u63d0\u5347\u57fa\u4e8eBERT\u7684CPS\u8bca\u65ad\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u8ba9\u7ec8\u7aef\u7528\u6237\u5982\u6559\u5e08\u66f4\u597d\u7406\u89e3\uff0c\u4fc3\u8fdb\u5176\u5728\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528SHapley Additive exPlanations (SHAP) \u5206\u6790\u8f6c\u5f55\u6570\u636e\u4e2d\u4e0d\u540c\u5206\u8bcd\u5bf9BERT\u6a21\u578bCPS\u5206\u7c7b\u7684\u8d21\u732e\u3002", "result": "\u5206\u7c7b\u8868\u73b0\u597d\u672a\u5fc5\u6709\u5408\u7406\u7684\u5206\u7c7b\u51b3\u7b56\u89e3\u91ca\uff1b\u7279\u5b9a\u5206\u8bcd\u5e38\u5f71\u54cd\u5206\u7c7b\uff1b\u53d1\u73b0\u5bf9\u5206\u7c7b\u6709\u79ef\u6781\u8d21\u732e\u4f46\u8bed\u4e49\u65e0\u610f\u4e49\u7684\u8bcd\u3002", "conclusion": "\u6a21\u578b\u5206\u7c7b\u5bf9\u5206\u8bcd\u7684\u5408\u7406\u4f7f\u7528\u7a0b\u5ea6\u4e0e\u7c7b\u522b\u6570\u91cf\u6709\u5173\uff0c\u9700\u63a2\u7d22\u96c6\u6210\u6a21\u578b\u67b6\u6784\u548c\u4eba\u673a\u4e92\u8865\u8fdb\u884cCPS\u8bca\u65ad\u3002"}}
{"id": "2507.14587", "pdf": "https://arxiv.org/pdf/2507.14587", "abs": "https://arxiv.org/abs/2507.14587", "authors": ["Merjem Be\u0107irovi\u0107", "Amina Kurtovi\u0107", "Nordin Smajlovi\u0107", "Medina Kapo", "Amila Akagi\u0107"], "title": "Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Medical imaging plays a vital role in early disease diagnosis and monitoring.\nSpecifically, blood microscopy offers valuable insights into blood cell\nmorphology and the detection of hematological disorders. In recent years, deep\nlearning-based automated classification systems have demonstrated high\npotential in enhancing the accuracy and efficiency of blood image analysis.\nHowever, a detailed performance analysis of specific deep learning frameworks\nappears to be lacking. This paper compares the performance of three popular\ndeep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in\nclassifying blood cell images from the publicly available BloodMNIST dataset.\nThe study primarily focuses on inference time differences, but also\nclassification performance for different image sizes. The results reveal\nvariations in performance across frameworks, influenced by factors such as\nimage resolution and framework-specific optimizations. Classification accuracy\nfor JAX and PyTorch was comparable to current benchmarks, showcasing the\nefficiency of these frameworks for medical image classification.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e09\u4e2a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5728\u8840\u7ec6\u80de\u56fe\u50cf\u5206\u7c7b\u4e0a\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u6027\u80fd\u6709\u5dee\u5f02\uff0cJAX\u548cPyTorch\u6548\u7387\u8f83\u9ad8\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u7279\u5b9a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5728\u8840\u7ec6\u80de\u56fe\u50cf\u5206\u7c7b\u4e0a\u7684\u8be6\u7ec6\u6027\u80fd\u5206\u6790\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6bd4\u8f83TensorFlow with Keras\u3001PyTorch\u548cJAX\u4e09\u4e2a\u6846\u67b6\u5bf9\u516c\u5f00BloodMNIST\u6570\u636e\u96c6\u8840\u7ec6\u80de\u56fe\u50cf\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u5173\u6ce8\u63a8\u7406\u65f6\u95f4\u548c\u4e0d\u540c\u56fe\u50cf\u5927\u5c0f\u4e0b\u7684\u5206\u7c7b\u8868\u73b0\u3002", "result": "\u5404\u6846\u67b6\u6027\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u53d7\u56fe\u50cf\u5206\u8fa8\u7387\u548c\u6846\u67b6\u7279\u5b9a\u4f18\u5316\u5f71\u54cd\uff0cJAX\u548cPyTorch\u5206\u7c7b\u51c6\u786e\u7387\u4e0e\u73b0\u6709\u57fa\u51c6\u76f8\u5f53\u3002", "conclusion": "JAX\u548cPyTorch\u5728\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u65b9\u9762\u5177\u6709\u8f83\u9ad8\u6548\u7387\u3002"}}
{"id": "2507.14173", "pdf": "https://arxiv.org/pdf/2507.14173", "abs": "https://arxiv.org/abs/2507.14173", "authors": ["Karim Alghoul", "Hussein Al Osman", "Abdulmotaleb El Saddik"], "title": "Enhancing Generalization in PPG-Based Emotion Measurement with a CNN-TCN-LSTM Model", "categories": ["eess.SP", "cs.HC", "cs.LG"], "comment": "Accepted by IEEE International Instrumentation and Measurement\n  Technology Conference (I2MTC) 2025", "summary": "Human computer interaction has become integral to modern life, driven by\nadvancements in machine learning technologies. Affective computing, in\nparticular, has focused on systems that recognize, interpret, and respond to\nhuman emotions, often using wearable devices, which provide continuous data\nstreams of physiological signals. Among various physiological signals, the\nphotoplethysmogram (PPG) has gained prominence due to its ease of acquisition\nfrom widely available devices. However, the generalization of PPG-based emotion\nrecognition models across individuals remains an unresolved challenge. This\npaper introduces a novel hybrid architecture that combines Convolutional Neural\nNetworks (CNNs), Long Short-Term Memory networks (LSTMs), and Temporal\nConvolutional Networks (TCNs) to address this issue. The proposed model\nintegrates the strengths of these architectures to improve robustness and\ngeneralization. Raw PPG signals are fed into the CNN for feature extraction.\nThese features are processed separately by LSTM and TCN. The outputs from these\ncomponents are concatenated to generate a final feature representation, which\nserves as the input for classifying valence and arousal, the primary dimensions\nof emotion. Experiments using the Photoplethysmogram Dataset for Emotional\nAnalysis (PPGE) demonstrate that the proposed hybrid model achieves better\nmodel generalization than standalone CNN and LSTM architectures. Our results\nshow that the proposed solution outperforms the state-of-the-art CNN\narchitecture, as well as a CNN-LSTM model, in emotion recognition tasks with\nPPG signals. Using metrics such as Area Under the Curve (AUC) and F1 Score, we\nhighlight the model's effectiveness in handling subject variability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408CNN\u3001LSTM\u548cTCN\u7684\u6df7\u5408\u67b6\u6784\u7528\u4e8ePPG\u4fe1\u53f7\u60c5\u611f\u8bc6\u522b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6cdb\u5316\u80fd\u529b\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8ePPG\u7684\u60c5\u611f\u8bc6\u522b\u6a21\u578b\u5728\u4e2a\u4f53\u95f4\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7ed3\u5408CNN\u3001LSTM\u548cTCN\u7684\u6df7\u5408\u67b6\u6784\uff0c\u5148\u7531CNN\u63d0\u53d6\u7279\u5f81\uff0c\u518d\u5206\u522b\u7528LSTM\u548cTCN\u5904\u7406\uff0c\u6700\u540e\u62fc\u63a5\u8f93\u51fa\u7528\u4e8e\u60c5\u611f\u5206\u7c7b\u3002", "result": "\u4f7f\u7528PPGE\u6570\u636e\u96c6\u5b9e\u9a8c\uff0c\u6df7\u5408\u6a21\u578b\u5728\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e2d\u6cdb\u5316\u80fd\u529b\u4f18\u4e8e\u72ec\u7acb\u7684CNN\u548cLSTM\u67b6\u6784\uff0c\u4e5f\u4f18\u4e8e\u73b0\u6709CNN\u67b6\u6784\u548cCNN - LSTM\u6a21\u578b\u3002", "conclusion": "\u8be5\u6df7\u5408\u67b6\u6784\u80fd\u6709\u6548\u5904\u7406\u4e2a\u4f53\u5dee\u5f02\uff0c\u5728PPG\u4fe1\u53f7\u60c5\u611f\u8bc6\u522b\u4e2d\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2507.14590", "pdf": "https://arxiv.org/pdf/2507.14590", "abs": "https://arxiv.org/abs/2507.14590", "authors": ["\u0141ukasz Radli\u0144ski", "Mateusz Gu\u015bciora", "Jan Koco\u0144"], "title": "Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification", "categories": ["cs.CL", "cs.AI"], "comment": "International Conference on Computational Science 2025", "summary": "Numerous domain-specific machine learning tasks struggle with data scarcity\nand class imbalance. This paper systematically explores data augmentation\nmethods for NLP, particularly through large language models like GPT. The\npurpose of this paper is to examine and evaluate whether traditional methods\nsuch as paraphrasing and backtranslation can leverage a new generation of\nmodels to achieve comparable performance to purely generative methods. Methods\naimed at solving the problem of data scarcity and utilizing ChatGPT were\nchosen, as well as an exemplary dataset. We conducted a series of experiments\ncomparing four different approaches to data augmentation in multiple\nexperimental setups. We then evaluated the results both in terms of the quality\nof generated data and its impact on classification performance. The key\nfindings indicate that backtranslation and paraphrasing can yield comparable or\neven better results than zero and a few-shot generation of examples.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8NLP\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u7528ChatGPT\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u56de\u8bd1\u548c\u91ca\u4e49\u6548\u679c\u4f73\u3002", "motivation": "\u89e3\u51b3NLP\u9886\u57df\u7279\u5b9a\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u7684\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u7814\u7a76\u4f20\u7edf\u65b9\u6cd5\u501f\u52a9\u65b0\u4e00\u4ee3\u6a21\u578b\u80fd\u5426\u8fbe\u5230\u7eaf\u751f\u6210\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u9009\u62e9\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3001\u5229\u7528ChatGPT\u7684\u65b9\u6cd5\u548c\u793a\u4f8b\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4\u56db\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5e76\u5728\u591a\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u3002", "result": "\u56de\u8bd1\u548c\u91ca\u4e49\u80fd\u4ea7\u751f\u4e0e\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u751f\u6210\u793a\u4f8b\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u7ed3\u679c\u3002", "conclusion": "\u4f20\u7edf\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u501f\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u6709\u6548\u89e3\u51b3NLP\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002"}}
{"id": "2507.14185", "pdf": "https://arxiv.org/pdf/2507.14185", "abs": "https://arxiv.org/abs/2507.14185", "authors": ["Abdullah Ahmed", "Jeremy Gummeson"], "title": "Latent Sensor Fusion: Multimedia Learning of Physiological Signals for Resource-Constrained Devices", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Latent spaces offer an efficient and effective means of summarizing data\nwhile implicitly preserving meta-information through relational encoding. We\nleverage these meta-embeddings to develop a modality-agnostic, unified encoder.\nOur method employs sensor-latent fusion to analyze and correlate multimodal\nphysiological signals. Using a compressed sensing approach with\nautoencoder-based latent space fusion, we address the computational challenges\nof biosignal analysis on resource-constrained devices. Experimental results\nshow that our unified encoder is significantly faster, lighter, and more\nscalable than modality-specific alternatives, without compromising\nrepresentational accuracy.", "AI": {"tldr": "\u5229\u7528\u6f5c\u5728\u7a7a\u95f4\u5f00\u53d1\u7edf\u4e00\u7f16\u7801\u5668\uff0c\u7528\u4f20\u611f\u5668 - \u6f5c\u5728\u878d\u5408\u5206\u6790\u591a\u6a21\u6001\u4fe1\u53f7\uff0c\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u751f\u7269\u4fe1\u53f7\u5206\u6790\u8ba1\u7b97\u96be\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u7f16\u7801\u5668\u66f4\u4f18\u3002", "motivation": "\u5229\u7528\u6f5c\u5728\u7a7a\u95f4\u7684\u5143\u5d4c\u5165\u5f00\u53d1\u6a21\u6001\u4e0d\u53ef\u77e5\u7684\u7edf\u4e00\u7f16\u7801\u5668\uff0c\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u751f\u7269\u4fe1\u53f7\u5206\u6790\u7684\u8ba1\u7b97\u6311\u6218\u3002", "method": "\u91c7\u7528\u4f20\u611f\u5668 - \u6f5c\u5728\u878d\u5408\u5206\u6790\u548c\u5173\u8054\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\uff0c\u4f7f\u7528\u57fa\u4e8e\u81ea\u7f16\u7801\u5668\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\u7684\u538b\u7f29\u611f\u77e5\u65b9\u6cd5\u3002", "result": "\u7edf\u4e00\u7f16\u7801\u5668\u6bd4\u7279\u5b9a\u6a21\u6001\u7684\u66ff\u4ee3\u65b9\u6848\u663e\u8457\u66f4\u5feb\u3001\u66f4\u8f7b\u4e14\u66f4\u5177\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u8868\u5f81\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u7edf\u4e00\u7f16\u7801\u5668\u5728\u751f\u7269\u4fe1\u53f7\u5206\u6790\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2507.14608", "pdf": "https://arxiv.org/pdf/2507.14608", "abs": "https://arxiv.org/abs/2507.14608", "authors": ["Nandani Sharma", "Dinesh Singh"], "title": "Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Facial expression recognition is crucial for human-computer interaction\napplications such as face animation, video surveillance, affective computing,\nmedical analysis, etc. Since the structure of facial attributes varies with\nfacial expressions, incorporating structural information into facial attributes\nis essential for facial expression recognition. In this paper, we propose\nExp-Graph, a novel framework designed to represent the structural relationships\namong facial attributes using graph-based modeling for facial expression\nrecognition. For facial attributes graph representation, facial landmarks are\nused as the graph's vertices. At the same time, the edges are determined based\non the proximity of the facial landmark and the similarity of the local\nappearance of the facial attributes encoded using the vision transformer.\nAdditionally, graph convolutional networks are utilized to capture and\nintegrate these structural dependencies into the encoding of facial attributes,\nthereby enhancing the accuracy of expression recognition. Thus, Exp-Graph\nlearns from the facial attribute graphs highly expressive semantic\nrepresentations. On the other hand, the vision transformer and graph\nconvolutional blocks help the framework exploit the local and global\ndependencies among the facial attributes that are essential for the recognition\nof facial expressions. We conducted comprehensive evaluations of the proposed\nExp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW.\nThe model achieved recognition accuracies of 98.09\\%, 79.01\\%, and 56.39\\%,\nrespectively. These results indicate that Exp-Graph maintains strong\ngeneralization capabilities across both controlled laboratory settings and\nreal-world, unconstrained environments, underscoring its effectiveness for\npractical facial expression recognition applications.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u7684Exp - Graph\u6846\u67b6\uff0c\u5229\u7528\u56fe\u6a21\u578b\u8868\u793a\u9762\u90e8\u5c5e\u6027\u7ed3\u6784\u5173\u7cfb\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u51c6\u786e\u7387\u5206\u522b\u8fbe98.09%\u300179.01%\u548c56.39%\uff0c\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u5bf9\u4eba\u673a\u4ea4\u4e92\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u5c06\u7ed3\u6784\u4fe1\u606f\u878d\u5165\u9762\u90e8\u5c5e\u6027\u5bf9\u8868\u60c5\u8bc6\u522b\u5f88\u5173\u952e\u3002", "method": "\u63d0\u51faExp - Graph\u6846\u67b6\uff0c\u7528\u9762\u90e8\u5173\u952e\u70b9\u4f5c\u56fe\u9876\u70b9\uff0c\u6839\u636e\u5173\u952e\u70b9\u63a5\u8fd1\u5ea6\u548c\u5c40\u90e8\u5916\u89c2\u76f8\u4f3c\u5ea6\u786e\u5b9a\u8fb9\uff0c\u7528\u56fe\u5377\u79ef\u7f51\u7edc\u6355\u6349\u548c\u6574\u5408\u7ed3\u6784\u4f9d\u8d56\uff0c\u5229\u7528\u89c6\u89c9Transformer\u548c\u56fe\u5377\u79ef\u5757\u6316\u6398\u5c40\u90e8\u548c\u5168\u5c40\u4f9d\u8d56\u3002", "result": "\u5728Oulu - CASIA\u3001eNTERFACE05\u548cAFEW\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u8bc6\u522b\u51c6\u786e\u7387\u5206\u522b\u4e3a98.09%\u300179.01%\u548c56.39%\u3002", "conclusion": "Exp - Graph\u5728\u53d7\u63a7\u5b9e\u9a8c\u5ba4\u548c\u771f\u5b9e\u65e0\u7ea6\u675f\u73af\u5883\u90fd\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u5bf9\u5b9e\u9645\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u5e94\u7528\u6709\u6548\u3002"}}
{"id": "2507.14194", "pdf": "https://arxiv.org/pdf/2507.14194", "abs": "https://arxiv.org/abs/2507.14194", "authors": ["David J Poland"], "title": "Boosted Enhanced Quantile Regression Neural Networks with Spatiotemporal Permutation Entropy for Complex System Prognostics", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "comment": "Preliminary version of a predictive maintenance framework using\n  spiking neural networks and entropy-based analysis. To be expanded in future\n  publications with hardware implementations and real-time drift detection\n  modules. arXiv admin note: substantial text overlap with arXiv:2501.05087", "summary": "This paper presents a novel framework for pattern prediction and system\nprognostics centered on Spatiotemporal Permutation Entropy analysis integrated\nwith Boosted Enhanced Quantile Regression Neural Networks (BEQRNNs). We address\nthe challenge of understanding complex dynamical patterns in multidimensional\nsystems through an approach that combines entropy-based complexity measures\nwith advanced neural architectures. The system leverages dual computational\nstages: first implementing spatiotemporal entropy extraction optimized for\nmultiscale temporal and spatial data streams, followed by an integrated BEQRNN\nlayer that enables probabilistic pattern prediction with uncertainty\nquantification. This architecture achieves 81.17% accuracy in spatiotemporal\npattern classification with prediction horizons up to 200 time steps and\nmaintains robust performance across diverse regimes. Field testing across\nchaotic attractors, reaction-diffusion systems, and industrial datasets shows a\n79% increase in critical transition detection accuracy and 81.22% improvement\nin long-term prediction reliability. The framework's effectiveness in\nprocessing complex, multimodal entropy features demonstrates significant\npotential for real-time prognostic applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65f6\u7a7a\u6392\u5217\u71b5\u5206\u6790\u4e0eBEQRNNs\u7684\u6a21\u5f0f\u9884\u6d4b\u548c\u7cfb\u7edf\u9884\u540e\u6846\u67b6\uff0c\u6548\u679c\u826f\u597d\uff0c\u6709\u5b9e\u65f6\u9884\u540e\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u7406\u89e3\u591a\u7ef4\u7cfb\u7edf\u4e2d\u590d\u6742\u52a8\u6001\u6a21\u5f0f\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u71b5\u7684\u590d\u6742\u6027\u5ea6\u91cf\u548c\u5148\u8fdb\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5206\u65f6\u7a7a\u71b5\u63d0\u53d6\u548c\u96c6\u6210BEQRNN\u5c42\u4e24\u4e2a\u8ba1\u7b97\u9636\u6bb5\u3002", "result": "\u65f6\u7a7a\u6a21\u5f0f\u5206\u7c7b\u51c6\u786e\u7387\u8fbe81.17%\uff0c\u4e34\u754c\u8f6c\u53d8\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u9ad879%\uff0c\u957f\u671f\u9884\u6d4b\u53ef\u9760\u6027\u63d0\u9ad881.22%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5904\u7406\u590d\u6742\u591a\u6a21\u6001\u71b5\u7279\u5f81\u6709\u6548\uff0c\u6709\u5b9e\u65f6\u9884\u540e\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.14615", "pdf": "https://arxiv.org/pdf/2507.14615", "abs": "https://arxiv.org/abs/2507.14615", "authors": ["Fred Mutisya", "Shikoh Gitau", "Christine Syovata", "Diana Oigara", "Ibrahim Matende", "Muna Aden", "Munira Ali", "Ryan Nyotu", "Diana Marion", "Job Nyangena", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha", "Eric Mibuari", "Jean Philbert Nsengemana", "Talkmore Chidede"], "title": "Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper", "categories": ["cs.CL", "cs.AI"], "comment": "29 pages, 6 figs, 6 tables. Companion methods paper forthcoming", "summary": "Large Language Models(LLMs) hold promise for improving healthcare access in\nlow-resource settings, but their effectiveness in African primary care remains\nunderexplored. We present a methodology for creating a benchmark dataset and\nevaluation framework focused on Kenyan Level 2 and 3 clinical care. Our\napproach uses retrieval augmented generation (RAG) to ground clinical questions\nin Kenya's national guidelines, ensuring alignment with local standards. These\nguidelines were digitized, chunked, and indexed for semantic retrieval. Gemini\nFlash 2.0 Lite was then prompted with guideline excerpts to generate realistic\nclinical scenarios, multiple-choice questions, and rationale based answers in\nEnglish and Swahili. Kenyan physicians co-created and refined the dataset, and\na blinded expert review process ensured clinical accuracy, clarity, and\ncultural appropriateness. The resulting Alama Health QA dataset includes\nthousands of regulator-aligned question answer pairs across common outpatient\nconditions. Beyond accuracy, we introduce evaluation metrics that test clinical\nreasoning, safety, and adaptability such as rare case detection (Needle in the\nHaystack), stepwise logic (Decision Points), and contextual adaptability.\nInitial results reveal significant performance gaps when LLMs are applied to\nlocalized scenarios, consistent with findings that LLM accuracy is lower on\nAfrican medical content than on US-based benchmarks. This work offers a\nreplicable model for guideline-driven, dynamic benchmarking to support safe AI\ndeployment in African health systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u80af\u5c3c\u4e9a2\u30013\u7ea7\u4e34\u5e8a\u62a4\u7406\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u7528RAG\u65b9\u6cd5\u7ed3\u5408\u5f53\u5730\u6307\u5357\u521b\u5efa\u6570\u636e\u96c6\uff0c\u5f15\u5165\u65b0\u8bc4\u4f30\u6307\u6807\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u672c\u5730\u5316\u573a\u666f\u6709\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6539\u5584\u4f4e\u8d44\u6e90\u5730\u533a\u533b\u7597\u53ef\u53ca\u6027\u5728\u975e\u6d32\u521d\u7ea7\u62a4\u7406\u7684\u6709\u6548\u6027\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u6784\u5efa\u9002\u914d\u5f53\u5730\u7684\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "\u4f7f\u7528RAG\u65b9\u6cd5\u5c06\u4e34\u5e8a\u95ee\u9898\u4e0e\u80af\u5c3c\u4e9a\u56fd\u5bb6\u6307\u5357\u7ed3\u5408\uff0c\u5bf9\u6307\u5357\u6570\u5b57\u5316\u5904\u7406\uff0c\u7528Gemini Flash 2.0 Lite\u751f\u6210\u591a\u8bed\u8a00\u4e34\u5e8a\u573a\u666f\u548c\u95ee\u7b54\u5bf9\uff0c\u7ecf\u533b\u751f\u5171\u521b\u3001\u4e13\u5bb6\u5ba1\u6838\u3002\u5f15\u5165\u65b0\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u751f\u6210\u5305\u542b\u6570\u5343\u4e2a\u95ee\u7b54\u5bf9\u7684Alama Health QA\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u672c\u5730\u5316\u573a\u666f\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u5728\u975e\u6d32\u533b\u7597\u5185\u5bb9\u4e0a\u51c6\u786e\u7387\u4f4e\u4e8e\u7f8e\u56fd\u57fa\u51c6\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u57fa\u4e8e\u6307\u5357\u7684\u52a8\u6001\u57fa\u51c6\u6a21\u578b\uff0c\u652f\u6301\u5728\u975e\u6d32\u536b\u751f\u7cfb\u7edf\u5b89\u5168\u90e8\u7f72\u4eba\u5de5\u667a\u80fd\u3002"}}
{"id": "2507.14625", "pdf": "https://arxiv.org/pdf/2507.14625", "abs": "https://arxiv.org/abs/2507.14625", "authors": ["Juntao Tan", "Anran Li", "Quanchao Liu", "Peng Ran", "Lan Zhang"], "title": "VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Vertical federated learning (VFL) enables multiple parties with disjoint\nfeatures to collaboratively train models without sharing raw data. While\nprivacy vulnerabilities of VFL are extensively-studied, its security\nthreats-particularly targeted label attacks-remain underexplored. In such\nattacks, a passive party perturbs inputs at inference to force\nmisclassification into adversary-chosen labels. Existing methods rely on\nunrealistic assumptions (e.g., accessing VFL-model's outputs) and ignore\nanomaly detectors deployed in real-world systems. To bridge this gap, we\nintroduce VTarbel, a two-stage, minimal-knowledge attack framework explicitly\ndesigned to evade detector-enhanced VFL inference. During the preparation\nstage, the attacker selects a minimal set of high-expressiveness samples (via\nmaximum mean discrepancy), submits them through VFL protocol to collect\npredicted labels, and uses these pseudo-labels to train estimated detector and\nsurrogate model on local features. In attack stage, these models guide\ngradient-based perturbations of remaining samples, crafting adversarial\ninstances that induce targeted misclassifications and evade detection. We\nimplement VTarbel and evaluate it against four model architectures, seven\nmultimodal datasets, and two anomaly detectors. Across all settings, VTarbel\noutperforms four state-of-the-art baselines, evades detection, and retains\neffective against three representative privacy-preserving defenses. These\nresults reveal critical security blind spots in current VFL deployments and\nunderscore urgent need for robust, attack-aware defenses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVTarbel\u653b\u51fb\u6846\u67b6\uff0c\u7528\u4e8e\u89c4\u907f\u68c0\u6d4b\u5668\u589e\u5f3a\u7684\u7eb5\u5411\u8054\u90a6\u5b66\u4e60\u63a8\u7406\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u63ed\u793a\u5f53\u524dVFL\u90e8\u7f72\u5b58\u5728\u5b89\u5168\u76f2\u70b9\u3002", "motivation": "\u73b0\u6709\u7eb5\u5411\u8054\u90a6\u5b66\u4e60\uff08VFL\uff09\u5b89\u5168\u5a01\u80c1\u5c24\u5176\u662f\u76ee\u6807\u6807\u7b7e\u653b\u51fb\u7814\u7a76\u4e0d\u8db3\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u4e0d\u73b0\u5b9e\u3001\u5ffd\u7565\u771f\u5b9e\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u5668\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u3001\u6700\u5c0f\u77e5\u8bc6\u653b\u51fb\u6846\u67b6VTarbel\uff0c\u51c6\u5907\u9636\u6bb5\u9009\u6837\u672c\u3001\u6536\u96c6\u4f2a\u6807\u7b7e\u8bad\u7ec3\u4f30\u8ba1\u68c0\u6d4b\u5668\u548c\u66ff\u4ee3\u6a21\u578b\uff0c\u653b\u51fb\u9636\u6bb5\u7528\u6a21\u578b\u5f15\u5bfc\u68af\u5ea6\u6270\u52a8\u5236\u4f5c\u5bf9\u6297\u6837\u672c\u3002", "result": "\u5728\u591a\u79cd\u6a21\u578b\u67b6\u6784\u3001\u6570\u636e\u96c6\u548c\u5f02\u5e38\u68c0\u6d4b\u5668\u4e0a\u8bc4\u4f30\uff0cVTarbel\u4f18\u4e8e\u56db\u4e2a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u89c4\u907f\u68c0\u6d4b\uff0c\u5bf9\u4e09\u79cd\u9690\u79c1\u4fdd\u62a4\u9632\u5fa1\u63aa\u65bd\u4ecd\u6709\u6548\u3002", "conclusion": "\u5f53\u524dVFL\u90e8\u7f72\u5b58\u5728\u5173\u952e\u5b89\u5168\u76f2\u70b9\uff0c\u4e9f\u9700\u5f3a\u5927\u7684\u3001\u8003\u8651\u653b\u51fb\u7684\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2507.14629", "pdf": "https://arxiv.org/pdf/2507.14629", "abs": "https://arxiv.org/abs/2507.14629", "authors": ["Juntao Tan", "Lan Zhang", "Zhonghao Hu", "Kai Yang", "Peng Ran", "Bo Li"], "title": "VMask: Tunable Label Privacy Protection for Vertical Federated Learning via Layer Masking", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Though vertical federated learning (VFL) is generally considered to be\nprivacy-preserving, recent studies have shown that VFL system is vulnerable to\nlabel inference attacks originating from various attack surfaces. Among these\nattacks, the model completion (MC) attack is currently the most powerful one.\nExisting defense methods against it either sacrifice model accuracy or incur\nimpractical computational overhead. In this paper, we propose VMask, a novel\nlabel privacy protection framework designed to defend against MC attack from\nthe perspective of layer masking. Our key insight is to disrupt the strong\ncorrelation between input data and intermediate outputs by applying the secret\nsharing (SS) technique to mask layer parameters in the attacker's model. We\ndevise a strategy for selecting critical layers to mask, reducing the overhead\nthat would arise from naively applying SS to the entire model. Moreover, VMask\nis the first framework to offer a tunable privacy budget to defenders, allowing\nfor flexible control over the levels of label privacy according to actual\nrequirements. We built a VFL system, implemented VMask on it, and extensively\nevaluated it using five model architectures and 13 datasets with different\nmodalities, comparing it to 12 other defense methods. The results demonstrate\nthat VMask achieves the best privacy-utility trade-off, successfully thwarting\nthe MC attack (reducing the label inference accuracy to a random guessing\nlevel) while preserving model performance (e.g., in Transformer-based model,\nthe averaged drop of VFL model accuracy is only 0.09%). VMask's runtime is up\nto 60,846 times faster than cryptography-based methods, and it only marginally\nexceeds that of standard VFL by 1.8 times in a large Transformer-based model,\nwhich is generally acceptable.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa VMask \u6846\u67b6\u62b5\u5fa1 VFL \u4e2d MC \u653b\u51fb\uff0c\u5728\u9690\u79c1\u4e0e\u6548\u7528\u95f4\u8fbe\u6700\u4f73\u5e73\u8861\uff0c\u8fd0\u884c\u901f\u5ea6\u5feb\u3002", "motivation": "\u73b0\u6709\u62b5\u5fa1 MC \u653b\u51fb\u7684\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u727a\u7272\u6a21\u578b\u51c6\u786e\u6027\u6216\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u9700\u65b0\u9632\u5fa1\u6846\u67b6\u3002", "method": "\u4ece\u5c42\u63a9\u7801\u89d2\u5ea6\u8bbe\u8ba1 VMask \u6846\u67b6\uff0c\u7528\u79d8\u5bc6\u5171\u4eab\u6280\u672f\u63a9\u7801\u5c42\u53c2\u6570\uff0c\u8bbe\u8ba1\u9009\u62e9\u5173\u952e\u5c42\u63a9\u7801\u7b56\u7565\uff0c\u63d0\u4f9b\u53ef\u8c03\u9690\u79c1\u9884\u7b97\u3002", "result": "\u901a\u8fc7\u4e94\u4e2a\u6a21\u578b\u67b6\u6784\u548c 13 \u4e2a\u6570\u636e\u96c6\u8bc4\u4f30\uff0cVMask \u5b9e\u73b0\u6700\u4f73\u9690\u79c1 - \u6548\u7528\u5e73\u8861\uff0c\u62b5\u5fa1 MC \u653b\u51fb\uff0c\u4fdd\u7559\u6a21\u578b\u6027\u80fd\uff0c\u8fd0\u884c\u901f\u5ea6\u5feb\u3002", "conclusion": "VMask \u662f\u6709\u6548\u62b5\u5fa1 MC \u653b\u51fb\u7684\u6846\u67b6\uff0c\u80fd\u7075\u6d3b\u63a7\u5236\u9690\u79c1\u7ea7\u522b\uff0c\u8fd0\u884c\u5f00\u9500\u53ef\u63a5\u53d7\u3002"}}
{"id": "2507.14649", "pdf": "https://arxiv.org/pdf/2507.14649", "abs": "https://arxiv.org/abs/2507.14649", "authors": ["Minsuh Joo", "Hyunsoo Cho"], "title": "Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite the outstanding performance of large language models (LLMs) across\nvarious NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate\nresponses--remains as a critical problem as it can be directly connected to a\ncrisis of building safe and reliable LLMs. Uncertainty estimation is primarily\nused to measure hallucination levels in LLM responses so that correct and\nincorrect answers can be distinguished clearly. This study proposes an\neffective uncertainty estimation approach, \\textbf{Cl}ust\\textbf{e}ring-based\nsem\\textbf{an}tic con\\textbf{s}ist\\textbf{e}ncy (\\textbf{Cleanse}). Cleanse\nquantifies the uncertainty with the proportion of the intra-cluster consistency\nin the total consistency between LLM hidden embeddings which contain adequate\nsemantic information of generations, by employing clustering. The effectiveness\nof Cleanse for detecting hallucination is validated using four off-the-shelf\nmodels, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two\nquestion-answering benchmarks, SQuAD and CoQA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6709\u6548\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5Cleanse\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u53ef\u8861\u91cf\u5e7b\u89c9\u6c34\u5e73\uff0c\u4ee5\u6784\u5efa\u5b89\u5168\u53ef\u9760\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u805a\u7c7b\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u65b9\u6cd5Cleanse\uff0c\u901a\u8fc7\u805a\u7c7b\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9690\u85cf\u5d4c\u5165\u4e2d\u7c07\u5185\u4e00\u81f4\u6027\u5360\u603b\u4e00\u81f4\u6027\u7684\u6bd4\u4f8b\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u4f7f\u7528\u56db\u4e2a\u73b0\u6210\u6a21\u578b\uff08LLaMA - 7B\u3001LLaMA - 13B\u3001LLaMA2 - 7B\u548cMistral - 7B\uff09\u548c\u4e24\u4e2a\u95ee\u7b54\u57fa\u51c6\uff08SQuAD\u548cCoQA\uff09\u9a8c\u8bc1\u4e86Cleanse\u68c0\u6d4b\u5e7b\u89c9\u7684\u6709\u6548\u6027\u3002", "conclusion": "Cleanse\u662f\u4e00\u79cd\u6709\u6548\u7684\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2507.14657", "pdf": "https://arxiv.org/pdf/2507.14657", "abs": "https://arxiv.org/abs/2507.14657", "authors": ["Keivan Shariatmadar", "Ahmad Osman"], "title": "AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)", "categories": ["cs.CV", "cs.AI", "68T45", "I.2.10"], "comment": "24 pages, 9 figures", "summary": "The integration of Artificial Intelligence (AI) into sports officiating\nrepresents a paradigm shift in how decisions are made in competitive\nenvironments. Traditional manual systems, even when supported by Instant Video\nReplay (IVR), often suffer from latency, subjectivity, and inconsistent\nenforcement, undermining fairness and athlete trust. This paper introduces\nFST.ai, a novel AI-powered framework designed to enhance officiating in Sport\nTaekwondo, particularly focusing on the complex task of real-time head kick\ndetection and scoring. Leveraging computer vision, deep learning, and edge\ninference, the system automates the identification and classification of key\nactions, significantly reducing decision time from minutes to seconds while\nimproving consistency and transparency. Importantly, the methodology is not\nlimited to Taekwondo. The underlying framework -- based on pose estimation,\nmotion classification, and impact analysis -- can be adapted to a wide range of\nsports requiring action detection, such as judo, karate, fencing, or even team\nsports like football and basketball, where foul recognition or performance\ntracking is critical. By addressing one of Taekwondo's most challenging\nscenarios -- head kick scoring -- we demonstrate the robustness, scalability,\nand sport-agnostic potential of FST.ai to transform officiating standards\nacross multiple disciplines.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u8dc6\u62f3\u9053\u88c1\u5224\u7684AI\u6846\u67b6FST.ai\uff0c\u80fd\u5b9e\u65f6\u68c0\u6d4b\u5934\u90e8\u8e22\u51fb\u5e76\u8ba1\u5206\uff0c\u51cf\u5c11\u51b3\u7b56\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\uff0c\u4e14\u5177\u6709\u8de8\u4f53\u80b2\u9879\u76ee\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u4f53\u80b2\u88c1\u5224\u7cfb\u7edf\u5b58\u5728\u5ef6\u8fdf\u3001\u4e3b\u89c2\u548c\u6267\u884c\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u516c\u5e73\u6027\u548c\u8fd0\u52a8\u5458\u4fe1\u4efb\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5229\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u6df1\u5ea6\u5b66\u4e60\u548c\u8fb9\u7f18\u63a8\u7406\uff0c\u57fa\u4e8e\u59ff\u6001\u4f30\u8ba1\u3001\u52a8\u4f5c\u5206\u7c7b\u548c\u5f71\u54cd\u5206\u6790\u5b9e\u73b0\u5173\u952e\u52a8\u4f5c\u7684\u81ea\u52a8\u8bc6\u522b\u548c\u5206\u7c7b\u3002", "result": "\u5c06\u51b3\u7b56\u65f6\u95f4\u4ece\u6570\u5206\u949f\u7f29\u77ed\u81f3\u6570\u79d2\uff0c\u63d0\u9ad8\u4e86\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\u3002", "conclusion": "FST.ai\u6846\u67b6\u5177\u6709\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u8de8\u4f53\u80b2\u9879\u76ee\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u80fd\u6539\u53d8\u591a\u4e2a\u4f53\u80b2\u9879\u76ee\u7684\u88c1\u5224\u6807\u51c6\u3002"}}
{"id": "2507.14216", "pdf": "https://arxiv.org/pdf/2507.14216", "abs": "https://arxiv.org/abs/2507.14216", "authors": ["Manish Kumar", "Tzu-Hsuan Chou", "Byunghyun Lee", "Nicol\u00f2 Michelusi", "David J. Love", "Yaguang Zhang", "James V. Krogmeier"], "title": "Distributed Machine Learning Approach for Low-Latency Localization in Cell-Free Massive MIMO Systems", "categories": ["eess.SP", "cs.LG"], "comment": "This paper has been submitted to IEEE Transactions on Wireless\n  Communications", "summary": "Low-latency localization is critical in cellular networks to support\nreal-time applications requiring precise positioning. In this paper, we propose\na distributed machine learning (ML) framework for fingerprint-based\nlocalization tailored to cell-free massive multiple-input multiple-output\n(MIMO) systems, an emerging architecture for 6G networks. The proposed\nframework enables each access point (AP) to independently train a Gaussian\nprocess regression model using local angle-of-arrival and received signal\nstrength fingerprints. These models provide probabilistic position estimates\nfor the user equipment (UE), which are then fused by the UE with minimal\ncomputational overhead to derive a final location estimate. This decentralized\napproach eliminates the need for fronthaul communication between the APs and\nthe central processing unit (CPU), thereby reducing latency. Additionally,\ndistributing computational tasks across the APs alleviates the processing\nburden on the CPU compared to traditional centralized localization schemes.\nSimulation results demonstrate that the proposed distributed framework achieves\nlocalization accuracy comparable to centralized methods, despite lacking the\nbenefits of centralized data aggregation. Moreover, it effectively reduces\nuncertainty of the location estimates, as evidenced by the 95\\% covariance\nellipse. The results highlight the potential of distributed ML for enabling\nlow-latency, high-accuracy localization in future 6G networks.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8e\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5b9a\u4f4d\u6846\u67b6\uff0c\u51cf\u5c11\u5ef6\u8fdf\uff0c\u6a21\u62df\u663e\u793a\u5176\u6709\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u6f5c\u529b\u3002", "motivation": "\u4f4e\u5ef6\u8fdf\u5b9a\u4f4d\u5bf9\u8702\u7a9d\u7f51\u7edc\u652f\u6301\u5b9e\u65f6\u7cbe\u786e\u4f4d\u7f6e\u5e94\u7528\u5f88\u5173\u952e\uff0c\u4f20\u7edf\u96c6\u4e2d\u5f0f\u5b9a\u4f4d\u6709\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5404\u63a5\u5165\u70b9\u72ec\u7acb\u8bad\u7ec3\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u6a21\u578b\uff0c\u7528\u6237\u8bbe\u5907\u878d\u5408\u4f4d\u7f6e\u4f30\u8ba1\u3002", "result": "\u5206\u5e03\u5f0f\u6846\u67b6\u5b9a\u4f4d\u7cbe\u5ea6\u4e0e\u96c6\u4e2d\u5f0f\u76f8\u5f53\uff0c\u6709\u6548\u964d\u4f4e\u4f4d\u7f6e\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5728\u672a\u67656G\u7f51\u7edc\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u65b9\u9762\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.14662", "pdf": "https://arxiv.org/pdf/2507.14662", "abs": "https://arxiv.org/abs/2507.14662", "authors": ["Shayan Rokhva", "Babak Teimourpour"], "title": "Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall", "categories": ["cs.CV", "cs.AI"], "comment": "Questions & Recommendations: shayanrokhva1999@gmail.com;\n  shayan1999rokh@yahoo.com", "summary": "Quantifying post-consumer food waste in institutional dining settings is\nessential for supporting data-driven sustainability strategies. This study\npresents a cost-effective computer vision framework that estimates plate-level\nfood waste by utilizing semantic segmentation of RGB images taken before and\nafter meal consumption across five Iranian dishes. Four fully supervised models\n(U-Net, U-Net++, and their lightweight variants) were trained using a capped\ndynamic inverse-frequency loss and AdamW optimizer, then evaluated through a\ncomprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a\ncustom-defined Distributional Pixel Agreement (DPA) metric tailored to the\ntask. All models achieved satisfying performance, and for each food type, at\nleast one model approached or surpassed 90% DPA, demonstrating strong alignment\nin pixel-wise proportion estimates. Lighter models with reduced parameter\ncounts offered faster inference, achieving real-time throughput on an NVIDIA T4\nGPU. Further analysis showed superior segmentation performance for dry and more\nrigid components (e.g., rice and fries), while more complex, fragmented, or\nviscous dishes, such as stews, showed reduced performance, specifically\npost-consumption. Despite limitations such as reliance on 2D imaging,\nconstrained food variety, and manual data collection, the proposed framework is\npioneering and represents a scalable, contactless solution for continuous\nmonitoring of food consumption. This research lays foundational groundwork for\nautomated, real-time waste tracking systems in large-scale food service\nenvironments and offers actionable insights and outlines feasible future\ndirections for dining hall management and policymakers aiming to reduce\ninstitutional food waste.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u8ba1\u7b97\u673a\u89c6\u89c9\u6846\u67b6\u4f30\u7b97\u9910\u76d8\u7ea7\u98df\u7269\u6d6a\u8d39\uff0c\u8bad\u7ec3\u591a\u4e2a\u6a21\u578b\u8bc4\u4f30\u6027\u80fd\uff0c\u867d\u6709\u5c40\u9650\u4f46\u4e3a\u5927\u89c4\u6a21\u9910\u996e\u73af\u5883\u98df\u7269\u6d6a\u8d39\u8ffd\u8e2a\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u91cf\u5316\u673a\u6784\u9910\u996e\u73af\u5883\u4e2d\u7684\u9910\u540e\u98df\u7269\u6d6a\u8d39\uff0c\u4ee5\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u7b56\u7565\u3002", "method": "\u5229\u7528RGB\u56fe\u50cf\u8bed\u4e49\u5206\u5272\uff0c\u8bad\u7ec3\u56db\u4e2a\u5168\u76d1\u7763\u6a21\u578b\uff08U - Net\u3001U - Net++\u53ca\u5176\u8f7b\u91cf\u7ea7\u53d8\u4f53\uff09\uff0c\u4f7f\u7528\u53d7\u9650\u52a8\u6001\u9006\u9891\u7387\u635f\u5931\u548cAdamW\u4f18\u5316\u5668\uff0c\u7528\u591a\u79cd\u6307\u6807\u8bc4\u4f30\u3002", "result": "\u6240\u6709\u6a21\u578b\u8868\u73b0\u826f\u597d\uff0c\u5404\u98df\u7269\u7c7b\u578b\u81f3\u5c11\u6709\u4e00\u4e2a\u6a21\u578bDPA\u63a5\u8fd1\u6216\u8d8590%\uff0c\u8f7b\u91cf\u7ea7\u6a21\u578b\u63a8\u7406\u5feb\uff0c\u5e72\u4e14\u786c\u7684\u98df\u7269\u5206\u5272\u6548\u679c\u597d\uff0c\u590d\u6742\u83dc\u54c1\u6548\u679c\u5dee\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u5f00\u521b\u6027\u7684\u3001\u53ef\u6269\u5c55\u7684\u975e\u63a5\u89e6\u5f0f\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u81ea\u52a8\u5b9e\u65f6\u98df\u7269\u6d6a\u8d39\u8ffd\u8e2a\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\uff0c\u4e3a\u9910\u996e\u7ba1\u7406\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2507.14220", "pdf": "https://arxiv.org/pdf/2507.14220", "abs": "https://arxiv.org/abs/2507.14220", "authors": ["Haitian Hu", "Wei Zhang", "Feng Feng", "Zhiguo Zhang", "Qi-Jun Zhang"], "title": "Advanced Space Mapping Technique Integrating a Shared Coarse Model for Multistate Tuning-Driven Multiphysics Optimization of Tunable Filters", "categories": ["eess.SP", "cs.LG", "physics.acc-ph"], "comment": null, "summary": "This article introduces an advanced space mapping (SM) technique that applies\na shared electromagnetic (EM)-based coarse model for multistate tuning-driven\nmultiphysics optimization of tunable filters. The SM method combines the\ncomputational efficiency of EM single-physics simulations with the precision of\nmultiphysics simulations. The shared coarse model is based on EM single-physics\nresponses corresponding to various nontunable design parameters values.\nConversely, the fine model is implemented to delineate the behavior of\nmultiphysics responses concerning both nontunable and tunable design parameter\nvalues. The proposed overall surrogate model comprises multiple subsurrogate\nmodels, each consisting of one shared coarse model and two distinct mapping\nneural networks. The responses from the shared coarse model in the EM\nsingle-physics filed offer a suitable approximation for the fine responses in\nthe multiphysics filed, whereas the mapping neural networks facilitate\ntransition from the EM single-physics field to the multiphysics field. Each\nsubsurrogate model maintains consistent nontunable design parameter values but\npossesses unique tunable design parameter values. By developing multiple\nsubsurrogate models, optimization can be simultaneously performed for each\ntuning state. Nontunable design parameter values are constrained by all tuning\nstates, whereas tunable design parameter values are confined to their\nrespective tuning states. This optimization technique simultaneously accounts\nfor all the tuning states to fulfill the necessary multiple tuning state\nrequirements. Multiple EM and multiphysics training samples are generated\nconcurrently to develop the surrogate model. Compared with existing direct\nmultiphysics parameterized modeling techniques, our proposed method achieves\nsuperior multiphysics modeling accuracy with fewer training samples and reduced\ncomputational costs.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u4e8e\u53ef\u8c03\u6ee4\u6ce2\u5668\u591a\u72b6\u6001\u8c03\u8c10\u9a71\u52a8\u591a\u7269\u7406\u573a\u4f18\u5316\u7684\u9ad8\u7ea7\u7a7a\u95f4\u6620\u5c04\u6280\u672f\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u6548\u7387\u4e0e\u7cbe\u5ea6\uff0c\u7528\u591a\u5b50\u4ee3\u7406\u6a21\u578b\u4f18\u5316\uff0c\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u76f4\u63a5\u591a\u7269\u7406\u573a\u53c2\u6570\u5316\u5efa\u6a21\u6280\u672f\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u51c6\u786e\u7684\u591a\u7269\u7406\u573a\u4f18\u5316\u3002", "method": "\u7ed3\u5408\u7535\u78c1\u5355\u7269\u7406\u573a\u6a21\u62df\u6548\u7387\u548c\u591a\u7269\u7406\u573a\u6a21\u62df\u7cbe\u5ea6\uff0c\u6784\u5efa\u542b\u5171\u4eab\u7c97\u6a21\u578b\u548c\u6620\u5c04\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u5b50\u4ee3\u7406\u6a21\u578b\uff0c\u540c\u65f6\u751f\u6210\u8bad\u7ec3\u6837\u672c\u3002", "result": "\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0c\u7528\u66f4\u5c11\u8bad\u7ec3\u6837\u672c\u548c\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u591a\u7269\u7406\u573a\u5efa\u6a21\u7cbe\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9ad8\u7ea7\u7a7a\u95f4\u6620\u5c04\u6280\u672f\u80fd\u6709\u6548\u8fdb\u884c\u53ef\u8c03\u6ee4\u6ce2\u5668\u591a\u72b6\u6001\u8c03\u8c10\u9a71\u52a8\u7684\u591a\u7269\u7406\u573a\u4f18\u5316\u3002"}}
{"id": "2507.14680", "pdf": "https://arxiv.org/pdf/2507.14680", "abs": "https://arxiv.org/abs/2507.14680", "authors": ["Xinheng Lyu", "Yuci Liang", "Wenting Chen", "Meidan Ding", "Jiaqi Yang", "Guolin Huang", "Daokun Zhang", "Xiangjian He", "Linlin Shen"], "title": "WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis", "categories": ["cs.CV", "cs.AI", "68T07, 92C55", "I.2.7; I.4.8; J.3"], "comment": null, "summary": "Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel\ntissue analysis across various pathological tasks. While recent advancements in\nmulti-modal large language models (MLLMs) allow multi-task WSI analysis through\nnatural language, they often underperform compared to task-specific models.\nCollaborative multi-agent systems have emerged as a promising solution to\nbalance versatility and accuracy in healthcare, yet their potential remains\nunderexplored in pathology-specific domains. To address these issues, we\npropose WSI-Agents, a novel collaborative multi-agent system for multi-modal\nWSI analysis. WSI-Agents integrates specialized functional agents with robust\ntask allocation and verification mechanisms to enhance both task-specific\naccuracy and multi-task versatility through three components: (1) a task\nallocation module assigning tasks to expert agents using a model zoo of patch\nand WSI level MLLMs, (2) a verification mechanism ensuring accuracy through\ninternal consistency checks and external validation using pathology knowledge\nbases and domain-specific models, and (3) a summary module synthesizing the\nfinal summary with visual interpretation maps. Extensive experiments on\nmulti-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs\nand medical agent frameworks across diverse tasks.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u591a\u6a21\u6001\u5168\u5207\u7247\u56fe\u50cf\uff08WSI\uff09\u5206\u6790\u7684\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edfWSI - Agents\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728WSI\u591a\u4efb\u52a1\u5206\u6790\u4e2d\u8868\u73b0\u4e0d\u5982\u7279\u5b9a\u4efb\u52a1\u6a21\u578b\uff0c\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u75c5\u7406\u5b66\u9886\u57df\u6f5c\u529b\u5f85\u6316\u6398\u3002", "method": "\u63d0\u51faWSI - Agents\u7cfb\u7edf\uff0c\u5305\u542b\u4efb\u52a1\u5206\u914d\u6a21\u5757\u3001\u9a8c\u8bc1\u673a\u5236\u548c\u603b\u7ed3\u6a21\u5757\u3002", "result": "\u5728\u591a\u6a21\u6001WSI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWSI - Agents\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5f53\u524dWSI MLLMs\u548c\u533b\u7597\u667a\u80fd\u4f53\u6846\u67b6\u3002", "conclusion": "WSI - Agents\u80fd\u6709\u6548\u63d0\u9ad8\u4efb\u52a1\u7279\u5b9a\u51c6\u786e\u6027\u548c\u591a\u4efb\u52a1\u901a\u7528\u6027\u3002"}}
{"id": "2507.14221", "pdf": "https://arxiv.org/pdf/2507.14221", "abs": "https://arxiv.org/abs/2507.14221", "authors": ["Eoghan Cunningham", "James Cross", "Derek Greene"], "title": "Identifying Algorithmic and Domain-Specific Bias in Parliamentary Debate Summarisation", "categories": ["cs.CY", "cs.CL", "cs.LG"], "comment": null, "summary": "The automated summarisation of parliamentary debates using large language\nmodels (LLMs) offers a promising way to make complex legislative discourse more\naccessible to the public. However, such summaries must not only be accurate and\nconcise but also equitably represent the views and contributions of all\nspeakers. This paper explores the use of LLMs to summarise plenary debates from\nthe European Parliament and investigates the algorithmic and representational\nbiases that emerge in this context. We propose a structured, multi-stage\nsummarisation framework that improves textual coherence and content fidelity,\nwhile enabling the systematic analysis of how speaker attributes -- such as\nspeaking order or political affiliation -- influence the visibility and\naccuracy of their contributions in the final summaries. Through our experiments\nusing both proprietary and open-weight LLMs, we find evidence of consistent\npositional and partisan biases, with certain speakers systematically\nunder-represented or misattributed. Our analysis shows that these biases vary\nby model and summarisation strategy, with hierarchical approaches offering the\ngreatest potential to reduce disparity. These findings underscore the need for\ndomain-sensitive evaluation metrics and ethical oversight in the deployment of\nLLMs for democratic applications.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528\u5927\u8bed\u8a00\u6a21\u578b\u603b\u7ed3\u6b27\u6d32\u8bae\u4f1a\u8fa9\u8bba\uff0c\u53d1\u73b0\u5b58\u5728\u7b97\u6cd5\u548c\u4ee3\u8868\u6027\u504f\u5dee\uff0c\u63d0\u51fa\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u5f3a\u8c03\u6c11\u4e3b\u5e94\u7528\u9700\u9886\u57df\u654f\u611f\u8bc4\u4f30\u6307\u6807\u548c\u4f26\u7406\u76d1\u7763\u3002", "motivation": "\u4f7f\u8bae\u4f1a\u8fa9\u8bba\u603b\u7ed3\u51c6\u786e\u3001\u7b80\u6d01\u4e14\u516c\u5e73\u4ee3\u8868\u5404\u65b9\u89c2\u70b9\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u603b\u7ed3\u8bae\u4f1a\u8fa9\u8bba\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u7b97\u6cd5\u548c\u4ee3\u8868\u6027\u504f\u5dee\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u591a\u9636\u6bb5\u603b\u7ed3\u6846\u67b6\uff0c\u7528\u4e13\u6709\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u5b58\u5728\u4e00\u81f4\u7684\u4f4d\u7f6e\u548c\u515a\u6d3e\u504f\u5dee\uff0c\u4e0d\u540c\u6a21\u578b\u548c\u603b\u7ed3\u7b56\u7565\u504f\u5dee\u4e0d\u540c\uff0c\u5206\u5c42\u65b9\u6cd5\u6700\u6709\u6f5c\u529b\u51cf\u5c11\u5dee\u5f02\u3002", "conclusion": "\u5728\u6c11\u4e3b\u5e94\u7528\u4e2d\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u9886\u57df\u654f\u611f\u7684\u8bc4\u4f30\u6307\u6807\u548c\u4f26\u7406\u76d1\u7763\u3002"}}
{"id": "2507.14688", "pdf": "https://arxiv.org/pdf/2507.14688", "abs": "https://arxiv.org/abs/2507.14688", "authors": ["Mohammed Alkhowaiter", "Norah Alshahrani", "Saied Alshahrani", "Reem I. Masoud", "Alaa Alzahrani", "Deema Alnuhait", "Emad A. Alghamdi", "Khalid Almubarak"], "title": "Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Post-training has emerged as a crucial technique for aligning pre-trained\nLarge Language Models (LLMs) with human instructions, significantly enhancing\ntheir performance across a wide range of tasks. Central to this process is the\nquality and diversity of post-training datasets. This paper presents a review\nof publicly available Arabic post-training datasets on the Hugging Face Hub,\norganized along four key dimensions: (1) LLM Capabilities (e.g., Question\nAnswering, Translation, Reasoning, Summarization, Dialogue, Code Generation,\nand Function Calling); (2) Steerability (e.g., persona and system prompts); (3)\nAlignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness.\nEach dataset is rigorously evaluated based on popularity, practical adoption,\nrecency and maintenance, documentation and annotation quality, licensing\ntransparency, and scientific contribution. Our review revealed critical gaps in\nthe development of Arabic post-training datasets, including limited task\ndiversity, inconsistent or missing documentation and annotation, and low\nadoption across the community. Finally, the paper discusses the implications of\nthese gaps on the progress of Arabic LLMs and applications while providing\nconcrete recommendations for future efforts in post-training dataset\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86Hugging Face Hub\u4e0a\u516c\u5f00\u7684\u963f\u62c9\u4f2f\u8bed\u540e\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u540e\u53d1\u73b0\u5176\u5b58\u5728\u5173\u952e\u4e0d\u8db3\uff0c\u5e76\u7ed9\u51fa\u672a\u6765\u53d1\u5c55\u5efa\u8bae\u3002", "motivation": "\u540e\u8bad\u7ec3\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u6307\u4ee4\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\uff0c\u6570\u636e\u96c6\u8d28\u91cf\u548c\u591a\u6837\u6027\u662f\u6838\u5fc3\uff0c\u9700\u5bf9\u963f\u62c9\u4f2f\u8bed\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "method": "\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u3001\u53ef\u5f15\u5bfc\u6027\u3001\u5bf9\u9f50\u6027\u548c\u9c81\u68d2\u6027\u56db\u4e2a\u7ef4\u5ea6\uff0c\u4f9d\u636e\u6d41\u884c\u5ea6\u3001\u5b9e\u9645\u5e94\u7528\u7b49\u6307\u6807\u8bc4\u4f30\u6570\u636e\u96c6\u3002", "result": "\u53d1\u73b0\u963f\u62c9\u4f2f\u8bed\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u5b58\u5728\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u3001\u6587\u6863\u548c\u6ce8\u91ca\u4e0d\u4e00\u81f4\u6216\u7f3a\u5931\u3001\u793e\u533a\u91c7\u7528\u7387\u4f4e\u7b49\u95ee\u9898\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u95ee\u9898\u5bf9\u963f\u62c9\u4f2f\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5e94\u7528\u7684\u5f71\u54cd\uff0c\u4e3a\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u5f00\u53d1\u63d0\u4f9b\u5177\u4f53\u5efa\u8bae\u3002"}}
{"id": "2507.14224", "pdf": "https://arxiv.org/pdf/2507.14224", "abs": "https://arxiv.org/abs/2507.14224", "authors": ["Beno\u00eet Brebion", "Alban Gallard", "Katrin Sippel", "Amer Zaylaa", "Hubert Preissl", "Sahar Moghimi", "Fabrice Wallois", "Ya\u00ebl Fr\u00e9gier"], "title": "Diffusion-based translation between unpaired spontaneous premature neonatal EEG and fetal MEG", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Background and objective: Brain activity in premature newborns has\ntraditionally been studied using electroencephalography (EEG), leading to\nsubstantial advances in our understanding of early neural development. However,\nsince brain development takes root at the fetal stage, a critical window of\nthis process remains largely unknown. The only technique capable of recording\nneural activity in the intrauterine environment is fetal magnetoencephalography\n(fMEG), but this approach presents challenges in terms of data quality and\nscarcity. Using artificial intelligence, the present research aims to transfer\nthe well-established knowledge from EEG studies to fMEG to improve\nunderstanding of prenatal brain development, laying the foundations for better\ndetection and treatment of potential pathologies. Methods: We developed an\nunpaired diffusion translation method based on dual diffusion bridges, which\nnotably includes numerical integration improvements to obtain more qualitative\nresults at a lower computational cost. Models were trained on our unpaired\ndataset of bursts of spontaneous activity from 30 high-resolution premature\nnewborns EEG recordings and 44 fMEG recordings. Results: We demonstrate that\nour method achieves significant improvement upon previous results obtained with\nGenerative Adversarial Networks (GANs), by almost 5% on the mean squared error\nin the time domain, and completely eliminating the mode collapse problem in the\nfrequency domain, thus achieving near-perfect signal fidelity. Conclusion: We\nset a new state of the art in the EEG-fMEG unpaired translation problem, as our\ndeveloped tool completely paves the way for early brain activity analysis.\nOverall, we also believe that our method could be reused for other unpaired\nsignal translation applications.", "AI": {"tldr": "\u7814\u7a76\u8fd0\u7528\u4eba\u5de5\u667a\u80fd\u5c06EEG\u77e5\u8bc6\u8fc1\u79fb\u5230fMEG\uff0c\u5f00\u53d1\u53cc\u6269\u6563\u6865\u975e\u914d\u5bf9\u6269\u6563\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86EEG - fMEG\u975e\u914d\u5bf9\u7ffb\u8bd1\u6c34\u5e73\uff0c\u53ef\u7528\u4e8e\u65e9\u671f\u8111\u6d3b\u52a8\u5206\u6790\u53ca\u5176\u4ed6\u975e\u914d\u5bf9\u4fe1\u53f7\u7ffb\u8bd1\u3002", "motivation": "\u4f20\u7edf\u7528EEG\u7814\u7a76\u65e9\u4ea7\u513f\u8111\u6d3b\u52a8\uff0c\u80ce\u513f\u9636\u6bb5\u8111\u53d1\u80b2\u7814\u7a76\u4e0d\u8db3\uff0cfMEG\u6709\u6570\u636e\u8d28\u91cf\u548c\u7a00\u7f3a\u95ee\u9898\uff0c\u65e8\u5728\u7528\u4eba\u5de5\u667a\u80fd\u5c06EEG\u77e5\u8bc6\u8fc1\u79fb\u5230fMEG\uff0c\u4ee5\u52a9\u4e8e\u4ea7\u524d\u8111\u53d1\u80b2\u7814\u7a76\u53ca\u75c5\u7406\u68c0\u6d4b\u6cbb\u7597\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u53cc\u6269\u6563\u6865\u7684\u975e\u914d\u5bf9\u6269\u6563\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u6539\u8fdb\u6570\u503c\u79ef\u5206\uff0c\u572830\u4efd\u65e9\u4ea7\u513fEEG\u548c44\u4efdfMEG\u975e\u914d\u5bf9\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u76f8\u6bd4GANs\uff0c\u65f6\u57df\u5747\u65b9\u8bef\u5dee\u63d0\u5347\u8fd15%\uff0c\u9891\u57df\u6d88\u9664\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u4fe1\u53f7\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u5728EEG - fMEG\u975e\u914d\u5bf9\u7ffb\u8bd1\u95ee\u9898\u4e0a\u8fbe\u5230\u65b0\u6c34\u5e73\uff0c\u4e3a\u65e9\u671f\u8111\u6d3b\u52a8\u5206\u6790\u94fa\u5e73\u9053\u8def\uff0c\u65b9\u6cd5\u53ef\u7528\u4e8e\u5176\u4ed6\u975e\u914d\u5bf9\u4fe1\u53f7\u7ffb\u8bd1\u3002"}}
{"id": "2507.14693", "pdf": "https://arxiv.org/pdf/2507.14693", "abs": "https://arxiv.org/abs/2507.14693", "authors": ["Amina Dzafic", "Merve Kavut", "Ulya Bayram"], "title": "Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "This manuscript has been submitted to the IEEE Journal of Biomedical\n  and Health Informatics", "summary": "Suicidal ideation detection is critical for real-time suicide prevention, yet\nits progress faces two under-explored challenges: limited language coverage and\nunreliable annotation practices. Most available datasets are in English, but\neven among these, high-quality, human-annotated data remains scarce. As a\nresult, many studies rely on available pre-labeled datasets without examining\ntheir annotation process or label reliability. The lack of datasets in other\nlanguages further limits the global realization of suicide prevention via\nartificial intelligence (AI). In this study, we address one of these gaps by\nconstructing a novel Turkish suicidal ideation corpus derived from social media\nposts and introducing a resource-efficient annotation framework involving three\nhuman annotators and two large language models (LLMs). We then address the\nremaining gaps by performing a bidirectional evaluation of label reliability\nand model consistency across this dataset and three popular English suicidal\nideation detection datasets, using transfer learning through eight pre-trained\nsentiment and emotion classifiers. These transformers help assess annotation\nconsistency and benchmark model performance against manually labeled data. Our\nfindings underscore the need for more rigorous, language-inclusive approaches\nto annotation and evaluation in mental health natural language processing (NLP)\nwhile demonstrating the questionable performance of popular models with\nzero-shot transfer learning. We advocate for transparency in model training and\ndataset construction in mental health NLP, prioritizing data and model\nreliability.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u571f\u8033\u5176\u81ea\u6740\u610f\u5ff5\u8bed\u6599\u5e93\uff0c\u7528\u65b0\u6846\u67b6\u6807\u6ce8\uff0c\u8de8\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u53d1\u73b0\u9700\u66f4\u4e25\u8c28\u5305\u5bb9\u65b9\u6cd5\uff0c\u6d41\u884c\u6a21\u578b\u96f6\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u8868\u73b0\u5b58\u7591\u3002", "motivation": "\u89e3\u51b3\u81ea\u6740\u610f\u5ff5\u68c0\u6d4b\u4e2d\u8bed\u8a00\u8986\u76d6\u6709\u9650\u548c\u6807\u6ce8\u5b9e\u8df5\u4e0d\u53ef\u9760\u7684\u95ee\u9898\uff0c\u63a8\u52a8\u5168\u7403\u81ea\u6740\u9884\u9632\u3002", "method": "\u6784\u5efa\u571f\u8033\u5176\u8bed\u6599\u5e93\uff0c\u5f15\u5165\u8d44\u6e90\u9ad8\u6548\u6807\u6ce8\u6846\u67b6\uff0c\u7528\u9884\u8bad\u7ec3\u5206\u7c7b\u5668\u8fdb\u884c\u8de8\u6570\u636e\u96c6\u53cc\u5411\u8bc4\u4f30\u3002", "result": "\u5f3a\u8c03\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u9700\u66f4\u4e25\u8c28\u3001\u8bed\u8a00\u5305\u5bb9\u7684\u6807\u6ce8\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6d41\u884c\u6a21\u578b\u96f6\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u8868\u73b0\u5b58\u7591\u3002", "conclusion": "\u5021\u5bfc\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u6a21\u578b\u8bad\u7ec3\u548c\u6570\u636e\u96c6\u6784\u5efa\u7684\u900f\u660e\u5ea6\uff0c\u4f18\u5148\u8003\u8651\u6570\u636e\u548c\u6a21\u578b\u53ef\u9760\u6027\u3002"}}
{"id": "2507.14236", "pdf": "https://arxiv.org/pdf/2507.14236", "abs": "https://arxiv.org/abs/2507.14236", "authors": ["Md Al Jubair", "Mohammad Shamsul Arefin", "Ahmed Wasif Reza"], "title": "Mining Voter Behaviour and Confidence: A Rule-Based Analysis of the 2022 U.S. Elections", "categories": ["cs.CY", "cs.LG"], "comment": null, "summary": "This study explores the relationship between voter trust and their\nexperiences during elections by applying a rule-based data mining technique to\nthe 2022 Survey of the Performance of American Elections (SPAE). Using the\nApriori algorithm and setting parameters to capture meaningful associations\n(support >= 3%, confidence >= 60%, and lift > 1.5), the analysis revealed a\nstrong connection between demographic attributes and voting-related challenges,\nsuch as registration hurdles, accessibility issues, and queue times. For\ninstance, respondents who indicated that accessing polling stations was \"very\neasy\" and who reported moderate confidence were found to be over six times more\nlikely (lift = 6.12) to trust their county's election outcome and experience no\nregistration issues. A further analysis, which adjusted the support threshold\nto 2%, specifically examined patterns among minority voters. It revealed that\n98.16 percent of Black voters who reported easy access to polling locations\nalso had smooth registration experiences. Additionally, those who had high\nconfidence in the vote-counting process were almost two times as likely to\nidentify as Democratic Party supporters. These findings point to the important\nrole that enhancing voting access and offering targeted support can play in\nbuilding trust in the electoral system, particularly among marginalized\ncommunities.", "AI": {"tldr": "\u672c\u6587\u8fd0\u7528\u89c4\u5219\u578b\u6570\u636e\u6316\u6398\u6280\u672f\u5206\u67902022\u5e74\u7f8e\u56fd\u9009\u4e3e\u8868\u73b0\u8c03\u67e5\u6570\u636e\uff0c\u63ed\u793a\u9009\u6c11\u4fe1\u4efb\u4e0e\u9009\u4e3e\u7ecf\u5386\u5173\u7cfb\uff0c\u5f3a\u8c03\u6539\u5584\u6295\u7968\u6e20\u9053\u548c\u9488\u5bf9\u6027\u652f\u6301\u5bf9\u5efa\u7acb\u9009\u4e3e\u4fe1\u4efb\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u63a2\u7a76\u9009\u6c11\u4fe1\u4efb\u4e0e\u9009\u4e3e\u7ecf\u5386\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u8fd0\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u6570\u636e\u6316\u6398\u6280\u672f\uff0c\u91c7\u7528Apriori\u7b97\u6cd5\uff0c\u8bbe\u7f6e\u652f\u6301\u5ea6>=3%\u3001\u7f6e\u4fe1\u5ea6>=60%\u3001\u63d0\u5347\u5ea6>1.5\u7b49\u53c2\u6570\u8fdb\u884c\u5206\u6790\uff0c\u8fd8\u8c03\u6574\u652f\u6301\u9608\u503c\u81f32%\u5bf9\u5c11\u6570\u65cf\u88d4\u9009\u6c11\u8fdb\u884c\u7279\u5b9a\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4eba\u53e3\u5c5e\u6027\u4e0e\u6295\u7968\u6311\u6218\u6709\u5f3a\u5173\u8054\uff1b\u5982\u8bbf\u95ee\u6295\u7968\u7ad9\u5bb9\u6613\u4e14\u6709\u9002\u5ea6\u4fe1\u5fc3\u7684\u53d7\u8bbf\u8005\u66f4\u53ef\u80fd\u4fe1\u4efb\u9009\u4e3e\u7ed3\u679c\u4e14\u65e0\u767b\u8bb0\u95ee\u9898\uff1b98.16%\u62a5\u544a\u6295\u7968\u70b9\u8bbf\u95ee\u5bb9\u6613\u7684\u9ed1\u4eba\u9009\u6c11\u767b\u8bb0\u987a\u5229\uff1b\u5bf9\u8ba1\u7968\u8fc7\u7a0b\u6709\u9ad8\u4fe1\u5fc3\u7684\u4eba\u66f4\u53ef\u80fd\u652f\u6301\u6c11\u4e3b\u515a\u3002", "conclusion": "\u6539\u5584\u6295\u7968\u6e20\u9053\u548c\u63d0\u4f9b\u9488\u5bf9\u6027\u652f\u6301\u5bf9\u5efa\u7acb\u9009\u4e3e\u7cfb\u7edf\u4fe1\u4efb\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18\u5316\u793e\u533a\u4e2d\uff0c\u8d77\u7740\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2507.14302", "pdf": "https://arxiv.org/pdf/2507.14302", "abs": "https://arxiv.org/abs/2507.14302", "authors": ["Dongjin Kim", "Xiaoyu Wang", "Peichen Zhong", "Daniel S. King", "Theo Jaffrelot Inizan", "Bingqing Cheng"], "title": "A universal augmentation framework for long-range electrostatics in machine learning interatomic potentials", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Most current machine learning interatomic potentials (MLIPs) rely on\nshort-range approximations, without explicit treatment of long-range\nelectrostatics. To address this, we recently developed the Latent Ewald\nSummation (LES) method, which infers electrostatic interactions, polarization,\nand Born effective charges (BECs), just by learning from energy and force\ntraining data. Here, we present LES as a standalone library, compatible with\nany short-range MLIP, and demonstrate its integration with methods such as\nMACE, NequIP, CACE, and CHGNet. We benchmark LES-enhanced models on distinct\nsystems, including bulk water, polar dipeptides, and gold dimer adsorption on\ndefective substrates, and show that LES not only captures correct\nelectrostatics but also improves accuracy. Additionally, we scale LES to large\nand chemically diverse data by training MACELES-OFF on the SPICE set containing\nmolecules and clusters, making a universal MLIP with electrostatics for organic\nsystems including biomolecules. MACELES-OFF is more accurate than its\nshort-range counterpart (MACE-OFF) trained on the same dataset, predicts\ndipoles and BECs reliably, and has better descriptions of bulk liquids. By\nenabling efficient long-range electrostatics without directly training on\nelectrical properties, LES paves the way for electrostatic foundation MLIPs.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u72ec\u7acb\u5e93LES\uff0c\u53ef\u4e0e\u77ed\u7a0bMLIP\u517c\u5bb9\uff0c\u7ecf\u6d4b\u8bd5\u80fd\u6355\u83b7\u9759\u7535\u5e76\u63d0\u9ad8\u7cbe\u5ea6\uff0c\u8bad\u7ec3\u7684MACELES - OFF\u5bf9\u6709\u673a\u7cfb\u7edf\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u9759\u7535\u57fa\u7840MLIP\u94fa\u5e73\u9053\u8def\u3002", "motivation": "\u5f53\u524d\u591a\u6570\u673a\u5668\u5b66\u4e60\u539f\u5b50\u95f4\u52bf\u4f9d\u8d56\u77ed\u7a0b\u8fd1\u4f3c\uff0c\u7f3a\u4e4f\u5bf9\u957f\u7a0b\u9759\u7535\u7684\u660e\u786e\u5904\u7406\u3002", "method": "\u5f00\u53d1LES\u65b9\u6cd5\uff0c\u5c06\u5176\u4f5c\u4e3a\u72ec\u7acb\u5e93\u4e0e\u591a\u79cd\u77ed\u7a0bMLIP\u96c6\u6210\uff0c\u5728\u4e0d\u540c\u7cfb\u7edf\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5728SPICE\u96c6\u4e0a\u8bad\u7ec3MACELES - OFF\u3002", "result": "LES\u80fd\u6355\u83b7\u6b63\u786e\u9759\u7535\u5e76\u63d0\u9ad8\u7cbe\u5ea6\uff0cMACELES - OFF\u6bd4\u77ed\u7a0b\u5bf9\u5e94\u6a21\u578b\u66f4\u51c6\u786e\uff0c\u80fd\u53ef\u9760\u9884\u6d4b\u5076\u6781\u5b50\u548cBECs\uff0c\u5bf9\u6db2\u4f53\u63cf\u8ff0\u66f4\u597d\u3002", "conclusion": "LES\u65e0\u9700\u76f4\u63a5\u8bad\u7ec3\u7535\u5b66\u6027\u8d28\u5c31\u80fd\u5b9e\u73b0\u9ad8\u6548\u957f\u7a0b\u9759\u7535\uff0c\u4e3a\u9759\u7535\u57fa\u7840MLIP\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.14304", "pdf": "https://arxiv.org/pdf/2507.14304", "abs": "https://arxiv.org/abs/2507.14304", "authors": ["Rakesh Paul", "Anusha Kamath", "Kanishk Singla", "Raviraj Joshi", "Utkarsh Vaidya", "Sanjay Singh Chauhan", "Niranjan Wartikar"], "title": "Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multilingual large language models (LLMs) often demonstrate a performance gap\nbetween English and non-English languages, particularly in low-resource\nsettings. Aligning these models to low-resource languages is essential yet\nchallenging due to limited high-quality data. While English alignment datasets\nare readily available, curating equivalent data in other languages is expensive\nand time-consuming. A common workaround is to translate existing English\nalignment data; however, standard translation techniques often fail to preserve\ncritical elements such as code, mathematical expressions, and structured\nformats like JSON. In this work, we investigate LLM-based selective\ntranslation, a technique that selectively translates only the translatable\nparts of a text while preserving non-translatable content and sentence\nstructure. We conduct a systematic study to explore key questions around this\napproach, including its effectiveness compared to vanilla translation, the\nimportance of filtering noisy outputs, and the benefits of mixing translated\nsamples with original English data during alignment. Our experiments focus on\nthe low-resource Indic language Hindi and compare translations generated by\nGoogle Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the\npromise of selective translation as a practical and effective method for\nimproving multilingual alignment in LLMs.", "AI": {"tldr": "\u7814\u7a76\u7528LLM-based\u9009\u62e9\u6027\u7ffb\u8bd1\u63d0\u5347\u591a\u8bed\u8a00\u5927\u6a21\u578b\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u9f50\u6548\u679c\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u524d\u666f\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5728\u82f1\u8bed\u548c\u975e\u82f1\u8bed\u95f4\u6709\u6027\u80fd\u5dee\u8ddd\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u9f50\u56e0\u6570\u636e\u6709\u9650\u5177\u6311\u6218\u6027\uff0c\u6807\u51c6\u7ffb\u8bd1\u6280\u672f\u6709\u4e0d\u8db3\u3002", "method": "\u7814\u7a76LLM-based\u9009\u62e9\u6027\u7ffb\u8bd1\u6280\u672f\uff0c\u5bf9\u5173\u952e\u95ee\u9898\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u5728\u5370\u5730\u8bed\u4e0a\u5b9e\u9a8c\u5bf9\u6bd4Google Cloud Translation\u548cLlama-3.1-405B\u7684\u7ffb\u8bd1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u7a81\u51fa\u4e86\u9009\u62e9\u6027\u7ffb\u8bd1\u5728\u63d0\u5347\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5bf9\u9f50\u65b9\u9762\u6709\u524d\u666f\u3002", "conclusion": "\u9009\u62e9\u6027\u7ffb\u8bd1\u662f\u63d0\u5347\u591a\u8bed\u8a00\u5927\u6a21\u578b\u591a\u8bed\u8a00\u5bf9\u9f50\u7684\u5b9e\u7528\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2507.14760", "pdf": "https://arxiv.org/pdf/2507.14760", "abs": "https://arxiv.org/abs/2507.14760", "authors": ["Cassandra Tong Ye", "Shamus Li", "Tyler King", "Kristina Monakhova"], "title": "QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning models often hallucinate, producing realistic artifacts that\nare not truly present in the sample. This can have dire consequences for\nscientific and medical inverse problems, such as MRI and microscopy denoising,\nwhere accuracy is more important than perceptual quality. Uncertainty\nquantification techniques, such as conformal prediction, can pinpoint outliers\nand provide guarantees for image regression tasks, improving reliability.\nHowever, existing methods utilize a linear constant scaling factor to calibrate\nuncertainty bounds, resulting in larger, less informative bounds. We propose\nQUTCC, a quantile uncertainty training and calibration technique that enables\nnonlinear, non-uniform scaling of quantile predictions to enable tighter\nuncertainty estimates. Using a U-Net architecture with a quantile embedding,\nQUTCC enables the prediction of the full conditional distribution of quantiles\nfor the imaging task. During calibration, QUTCC generates uncertainty bounds by\niteratively querying the network for upper and lower quantiles, progressively\nrefining the bounds to obtain a tighter interval that captures the desired\ncoverage. We evaluate our method on several denoising tasks as well as\ncompressive MRI reconstruction. Our method successfully pinpoints\nhallucinations in image estimates and consistently achieves tighter uncertainty\nintervals than prior methods while maintaining the same statistical coverage.", "AI": {"tldr": "\u63d0\u51faQUTCC\u6280\u672f\u7528\u4e8e\u56fe\u50cf\u56de\u5f52\u4efb\u52a1\uff0c\u5728\u53bb\u566a\u548cMRI\u91cd\u5efa\u4efb\u52a1\u4e2d\u80fd\u7cbe\u51c6\u5b9a\u4f4d\u5e7b\u89c9\u5e76\u5b9e\u73b0\u66f4\u7a84\u7684\u4e0d\u786e\u5b9a\u6027\u533a\u95f4\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u79d1\u5b66\u548c\u533b\u5b66\u9006\u95ee\u9898\u4e2d\u4f1a\u4ea7\u751f\u5e7b\u89c9\uff0c\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u7684\u8fb9\u754c\u8f83\u5927\u3001\u4fe1\u606f\u4e0d\u8db3\u3002", "method": "\u63d0\u51faQUTCC\u6280\u672f\uff0c\u5229\u7528\u5e26\u5206\u4f4d\u6570\u5d4c\u5165\u7684U - Net\u67b6\u6784\u9884\u6d4b\u5206\u4f4d\u6570\u7684\u5168\u6761\u4ef6\u5206\u5e03\uff0c\u6821\u51c6\u4e2d\u8fed\u4ee3\u67e5\u8be2\u7f51\u7edc\u83b7\u53d6\u4e0a\u4e0b\u5206\u4f4d\u6570\u4ee5\u7ec6\u5316\u8fb9\u754c\u3002", "result": "\u5728\u591a\u4e2a\u53bb\u566a\u4efb\u52a1\u548c\u538b\u7f29MRI\u91cd\u5efa\u4efb\u52a1\u4e2d\uff0c\u6210\u529f\u5b9a\u4f4d\u56fe\u50cf\u4f30\u8ba1\u4e2d\u7684\u5e7b\u89c9\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u66f4\u7a84\u7684\u4e0d\u786e\u5b9a\u6027\u533a\u95f4\u3002", "conclusion": "QUTCC\u6280\u672f\u80fd\u5728\u4fdd\u6301\u76f8\u540c\u7edf\u8ba1\u8986\u76d6\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7d27\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002"}}
{"id": "2507.14341", "pdf": "https://arxiv.org/pdf/2507.14341", "abs": "https://arxiv.org/abs/2507.14341", "authors": ["Ivan Zanardi", "Simone Venturi", "Marco Panesi"], "title": "MENO: Hybrid Matrix Exponential-based Neural Operator for Stiff ODEs. Application to Thermochemical Kinetics", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "We introduce MENO (''Matrix Exponential-based Neural Operator''), a hybrid\nsurrogate modeling framework for efficiently solving stiff systems of ordinary\ndifferential equations (ODEs) that exhibit a sparse nonlinear structure. In\nsuch systems, only a few variables contribute nonlinearly to the dynamics,\nwhile the majority influence the equations linearly. MENO exploits this\nproperty by decomposing the system into two components: the low-dimensional\nnonlinear part is modeled using conventional neural operators, while the linear\ntime-varying subsystem is integrated using a novel neural matrix exponential\nformulation. This approach combines the exact solution of linear time-invariant\nsystems with learnable, time-dependent graph-based corrections applied to the\nlinear operators. Unlike black-box or soft-constrained physics-informed (PI)\nmodels, MENO embeds the governing equations directly into its architecture,\nensuring physical consistency (e.g., steady states), improved robustness, and\nmore efficient training. We validate MENO on three complex thermochemical\nsystems: the POLLU atmospheric chemistry model, an oxygen mixture in\nthermochemical nonequilibrium, and a collisional-radiative argon plasma in one-\nand two-dimensional shock-tube simulations. MENO achieves relative errors below\n2% in trained zero-dimensional settings and maintains good accuracy in\nextrapolatory multidimensional regimes. It also delivers substantial\ncomputational speedups, achieving up to 4 800$\\times$ on GPU and 185$\\times$ on\nCPU compared to standard implicit ODE solvers. Although intrusive by design,\nMENO's physics-based architecture enables superior generalization and\nreliability, offering a scalable path for real-time simulation of stiff\nreactive systems.", "AI": {"tldr": "\u4ecb\u7ecdMENO\u6846\u67b6\u6c42\u89e3\u7a00\u758f\u975e\u7ebf\u6027\u7ed3\u6784\u7684\u521a\u6027ODE\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u4e8e\u4e09\u4e2a\u70ed\u5316\u5b66\u7cfb\u7edf\uff0c\u8bef\u5dee\u4f4e\u4e14\u6709\u8ba1\u7b97\u52a0\u901f", "motivation": "\u9ad8\u6548\u6c42\u89e3\u5177\u6709\u7a00\u758f\u975e\u7ebf\u6027\u7ed3\u6784\u7684\u521a\u6027ODE\u7cfb\u7edf", "method": "\u5c06\u7cfb\u7edf\u5206\u89e3\u4e3a\u4f4e\u7ef4\u975e\u7ebf\u6027\u90e8\u5206\u548c\u7ebf\u6027\u65f6\u53d8\u5b50\u7cfb\u7edf\uff0c\u5206\u522b\u7528\u4f20\u7edf\u795e\u7ecf\u7b97\u5b50\u548c\u795e\u7ecf\u77e9\u9635\u6307\u6570\u516c\u5f0f\u5904\u7406", "result": "\u5728\u8bad\u7ec3\u7684\u96f6\u7ef4\u8bbe\u7f6e\u4e2d\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e2%\uff0c\u5728\u591a\u7ef4\u5916\u63a8\u533a\u57df\u4fdd\u6301\u8f83\u597d\u7cbe\u5ea6\uff0c\u6709\u663e\u8457\u8ba1\u7b97\u52a0\u901f", "conclusion": "MENO\u57fa\u4e8e\u7269\u7406\u7684\u67b6\u6784\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u521a\u6027\u53cd\u5e94\u7cfb\u7edf\u5b9e\u65f6\u6a21\u62df\u63d0\u4f9b\u53ef\u6269\u5c55\u9014\u5f84"}}
{"id": "2507.14767", "pdf": "https://arxiv.org/pdf/2507.14767", "abs": "https://arxiv.org/abs/2507.14767", "authors": ["Yanming Zhang", "Krishnakumar Hegde", "Klaus Mueller"], "title": "XplainAct: Visualization for Personalized Intervention Insights", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "This paper will be published and presented at IEEE Visualization\n  (VIS) 2025, Vienna, Austria, November 2025", "summary": "Causality helps people reason about and understand complex systems,\nparticularly through what-if analyses that explore how interventions might\nalter outcomes. Although existing methods embrace causal reasoning using\ninterventions and counterfactual analysis, they primarily focus on effects at\nthe population level. These approaches often fall short in systems\ncharacterized by significant heterogeneity, where the impact of an intervention\ncan vary widely across subgroups. To address this challenge, we present\nXplainAct, a visual analytics framework that supports simulating, explaining,\nand reasoning interventions at the individual level within subpopulations. We\ndemonstrate the effectiveness of XplainAct through two case studies:\ninvestigating opioid-related deaths in epidemiology and analyzing voting\ninclinations in the presidential election.", "AI": {"tldr": "\u63d0\u51faXplainAct\u53ef\u89c6\u5316\u5206\u6790\u6846\u67b6\uff0c\u652f\u6301\u4e9a\u7fa4\u4f53\u4e2a\u4f53\u5c42\u9762\u5e72\u9884\u6a21\u62df\u3001\u89e3\u91ca\u4e0e\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u63a8\u7406\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u603b\u4f53\u5c42\u9762\u6548\u679c\uff0c\u5728\u5f02\u8d28\u6027\u663e\u8457\u7cfb\u7edf\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u652f\u6301\u4e2a\u4f53\u5c42\u9762\u5e72\u9884\u5206\u6790\u3002", "method": "\u63d0\u51faXplainAct\u53ef\u89c6\u5316\u5206\u6790\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u6d41\u884c\u75c5\u5b66\u4e2d\u963f\u7247\u7c7b\u836f\u7269\u76f8\u5173\u6b7b\u4ea1\u8c03\u67e5\u548c\u603b\u7edf\u9009\u4e3e\u6295\u7968\u503e\u5411\u5206\u6790\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86XplainAct\u7684\u6709\u6548\u6027\u3002", "conclusion": "XplainAct\u6846\u67b6\u80fd\u6709\u6548\u652f\u6301\u4e9a\u7fa4\u4f53\u4e2a\u4f53\u5c42\u9762\u7684\u5e72\u9884\u6a21\u62df\u3001\u89e3\u91ca\u548c\u63a8\u7406\u3002"}}
{"id": "2507.14784", "pdf": "https://arxiv.org/pdf/2507.14784", "abs": "https://arxiv.org/abs/2507.14784", "authors": ["Xinxin Dong", "Baoyun Peng", "Haokai Ma", "Yufei Wang", "Zixuan Dong", "Fei Hu", "Xiaodong Wang"], "title": "LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Video Question Answering (VideoQA) requires identifying sparse critical\nmoments in long videos and reasoning about their causal relationships to answer\nsemantically complex questions. While recent advances in multimodal learning\nhave improved alignment and fusion, current approaches remain limited by two\nprevalent but fundamentally flawed strategies: (1) task-agnostic sampling\nindiscriminately processes all frames, overwhelming key events with irrelevant\ncontent; and (2) heuristic retrieval captures superficial patterns but misses\ncausal-temporal structures needed for complex reasoning. To address these\nchallenges, we introduce LeAdQA, an innovative approach that bridges these gaps\nthrough synergizing causal-aware query refinement with fine-grained visual\ngrounding. Our method first leverages LLMs to reformulate question-option\npairs, resolving causal ambiguities and sharpening temporal focus. These\nrefined queries subsequently direct a temporal grounding model to precisely\nretrieve the most salient segments, complemented by an adaptive fusion\nmechanism dynamically integrating the evidence to maximize relevance. The\nintegrated visual-textual cues are then processed by an MLLM to generate\naccurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and\nNExT-GQA demonstrate that our method's precise visual grounding substantially\nenhances the understanding of video-question relationships, achieving\nstate-of-the-art (SOTA) performance on complex reasoning tasks while\nmaintaining computational efficiency.", "AI": {"tldr": "\u63d0\u51faLeAdQA\u65b9\u6cd5\u89e3\u51b3VideoQA\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbeSOTA\u4e14\u5177\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5f53\u524dVideoQA\u65b9\u6cd5\u5b58\u5728\u4efb\u52a1\u65e0\u5173\u91c7\u6837\u548c\u542f\u53d1\u5f0f\u68c0\u7d22\u7684\u7f3a\u9677\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "\u5229\u7528LLMs\u91cd\u6784\u95ee\u9898\u9009\u9879\u5bf9\uff0c\u5f15\u5bfc\u65f6\u95f4\u5b9a\u4f4d\u6a21\u578b\u68c0\u7d22\u7247\u6bb5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u878d\u5408\u673a\u5236\u6574\u5408\u8bc1\u636e\uff0c\u7528MLLM\u751f\u6210\u7b54\u6848\u3002", "result": "\u5728NExT - QA\u3001IntentQA\u548cNExT - GQA\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u7cbe\u786e\u7684\u89c6\u89c9\u5b9a\u4f4d\u589e\u5f3a\u4e86\u89c6\u9891 - \u95ee\u9898\u5173\u7cfb\u7406\u89e3\u3002", "conclusion": "LeAdQA\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.14467", "pdf": "https://arxiv.org/pdf/2507.14467", "abs": "https://arxiv.org/abs/2507.14467", "authors": ["Chen Chen", "Lijin Wang", "Yanzhao Cao", "Xupeng Cheng"], "title": "Learning Stochastic Hamiltonian Systems via Stochastic Generating Function Neural Network", "categories": ["math.DS", "cs.LG"], "comment": null, "summary": "In this paper we propose a novel neural network model for learning stochastic\nHamiltonian systems (SHSs) from observational data, termed the stochastic\ngenerating function neural network (SGFNN). SGFNN preserves symplectic\nstructure of the underlying stochastic Hamiltonian system and produces\nsymplectic predictions. Our model utilizes the autoencoder framework to\nidentify the randomness of the latent system by the encoder network, and\ndetects the stochastic generating function of the system through the decoder\nnetwork based on the random variables extracted from the encoder. Symplectic\npredictions can then be generated by the stochastic generating function.\nNumerical experiments are performed on several stochastic Hamiltonian systems,\nvarying from additive to multiplicative, and from separable to non-separable\nSHSs with single or multiple noises. Compared with the benchmark stochastic\nflow map learning (sFML) neural network, our SGFNN model exhibits higher\naccuracy across various prediction metrics, especially in long-term\npredictions, with the property of maintaining the symplectic structure of the\nunderlying SHSs.", "AI": {"tldr": "\u63d0\u51fa\u968f\u673a\u751f\u6210\u51fd\u6570\u795e\u7ecf\u7f51\u7edc\uff08SGFNN\uff09\u5b66\u4e60\u968f\u673a\u54c8\u5bc6\u987f\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u7cbe\u5ea6\u66f4\u9ad8\u3002", "motivation": "\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u5b66\u4e60\u968f\u673a\u54c8\u5bc6\u987f\u7cfb\u7edf\uff0c\u751f\u6210\u5177\u6709\u8f9b\u7ed3\u6784\u7684\u9884\u6d4b\u3002", "method": "\u5229\u7528\u81ea\u7f16\u7801\u5668\u6846\u67b6\uff0c\u7f16\u7801\u5668\u8bc6\u522b\u6f5c\u5728\u7cfb\u7edf\u968f\u673a\u6027\uff0c\u89e3\u7801\u5668\u57fa\u4e8e\u63d0\u53d6\u7684\u968f\u673a\u53d8\u91cf\u68c0\u6d4b\u968f\u673a\u751f\u6210\u51fd\u6570\uff0c\u8fdb\u800c\u751f\u6210\u8f9b\u9884\u6d4b\u3002", "result": "\u5728\u591a\u79cd\u968f\u673a\u54c8\u5bc6\u987f\u7cfb\u7edf\u4e0a\u5b9e\u9a8c\uff0c\u4e0e\u57fa\u51c6sFML\u795e\u7ecf\u7f51\u7edc\u76f8\u6bd4\uff0cSGFNN\u5728\u5404\u79cd\u9884\u6d4b\u6307\u6807\u4e0a\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u5c24\u5176\u5728\u957f\u671f\u9884\u6d4b\u4e2d\u3002", "conclusion": "SGFNN\u6a21\u578b\u80fd\u4fdd\u6301\u968f\u673a\u54c8\u5bc6\u987f\u7cfb\u7edf\u7684\u8f9b\u7ed3\u6784\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2507.14787", "pdf": "https://arxiv.org/pdf/2507.14787", "abs": "https://arxiv.org/abs/2507.14787", "authors": ["Xi Xiao", "Aristeidis Tsaris", "Anika Tabassum", "John Lagergren", "Larry M. York", "Tianyang Wang", "Xiao Wang"], "title": "FOCUS: Fused Observation of Channels for Unveiling Spectra", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous\nwavelength bands, making it a powerful tool in biology, agriculture, and\nenvironmental monitoring. However, interpreting Vision Transformers (ViTs) in\nthis setting remains largely unexplored due to two key challenges: (1) existing\nsaliency methods struggle to capture meaningful spectral cues, often collapsing\nattention onto the class token, and (2) full-spectrum ViTs are computationally\nprohibitive for interpretability, given the high-dimensional nature of HSI\ndata. We present FOCUS, the first framework that enables reliable and efficient\nspatial-spectral interpretability for frozen ViTs. FOCUS introduces two core\ncomponents: class-specific spectral prompts that guide attention toward\nsemantically meaningful wavelength groups, and a learnable [SINK] token trained\nwith an attraction loss to absorb noisy or redundant attention. Together, these\ndesigns make it possible to generate stable and interpretable 3D saliency maps\nand spectral importance curves in a single forward pass, without any gradient\nbackpropagation or backbone modification. FOCUS improves band-level IoU by 15\npercent, reduces attention collapse by over 40 percent, and produces saliency\nresults that align closely with expert annotations. With less than 1 percent\nparameter overhead, our method makes high-resolution ViT interpretability\npractical for real-world hyperspectral applications, bridging a long-standing\ngap between black-box modeling and trustworthy HSI decision-making.", "AI": {"tldr": "\u63d0\u51faFOCUS\u6846\u67b6\uff0c\u5b9e\u73b0\u5bf9\u51bb\u7ed3ViTs\u7684\u53ef\u9760\u9ad8\u6548\u7684\u7a7a\u8c31\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u5347\u76f8\u5173\u6307\u6807\uff0c\u9002\u7528\u4e8e\u9ad8\u5149\u8c31\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u89e3\u91ca\u9ad8\u5149\u8c31\u6210\u50cf\u4e2d\u7684Vision Transformers (ViTs) \u5b58\u5728\u4e24\u5927\u6311\u6218\uff0c\u4e00\u662f\u96be\u4ee5\u6355\u6349\u6709\u610f\u4e49\u7684\u5149\u8c31\u7ebf\u7d22\uff0c\u4e8c\u662f\u5168\u5149\u8c31ViTs\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u5f15\u5165\u7279\u5b9a\u7c7b\u522b\u7684\u5149\u8c31\u63d0\u793a\u5f15\u5bfc\u6ce8\u610f\u529b\u5230\u8bed\u4e49\u6709\u610f\u4e49\u7684\u6ce2\u957f\u7ec4\uff0c\u8bad\u7ec3\u53ef\u5b66\u4e60\u7684[SINK]\u6807\u8bb0\u5438\u6536\u566a\u58f0\u6216\u5197\u4f59\u6ce8\u610f\u529b\uff0c\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u751f\u62103D\u663e\u8457\u6027\u56fe\u548c\u5149\u8c31\u91cd\u8981\u6027\u66f2\u7ebf\u3002", "result": "\u63d0\u9ad8\u6ce2\u6bb5\u7ea7IoU 15%\uff0c\u51cf\u5c11\u6ce8\u610f\u529b\u5d29\u6e83\u8d8540%\uff0c\u663e\u8457\u6027\u7ed3\u679c\u4e0e\u4e13\u5bb6\u6ce8\u91ca\u9ad8\u5ea6\u4e00\u81f4\uff0c\u53c2\u6570\u5f00\u9500\u4e0d\u52301%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u9ad8\u5206\u8fa8\u7387ViT\u53ef\u89e3\u91ca\u6027\u9002\u7528\u4e8e\u5b9e\u9645\u9ad8\u5149\u8c31\u5e94\u7528\uff0c\u5f25\u5408\u9ed1\u76d2\u5efa\u6a21\u4e0e\u53ef\u9760HSI\u51b3\u7b56\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.14491", "pdf": "https://arxiv.org/pdf/2507.14491", "abs": "https://arxiv.org/abs/2507.14491", "authors": ["Bing-Ze Lu", "Richard Tsai"], "title": "Numerical Artifacts in Learning Dynamical Systems", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "In many applications, one needs to learn a dynamical system from its\nsolutions sampled at a finite number of time points. The learning problem is\noften formulated\n  as an optimization problem over a chosen function class. However, in the\noptimization procedure, it is necessary to employ a numerical scheme to\nintegrate candidate dynamical systems and assess how their solutions fit the\ndata.\n  This paper reveals potentially serious effects of a chosen numerical scheme\non the learning outcome. In particular, our analysis demonstrates that a damped\noscillatory system may be incorrectly identified as having \"anti-damping\" and\nexhibiting a reversed oscillation direction, despite adequately fitting the\ngiven data points.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u6240\u9009\u6570\u503c\u65b9\u6848\u5bf9\u4ece\u6709\u9650\u65f6\u95f4\u70b9\u6837\u672c\u5b66\u4e60\u52a8\u529b\u7cfb\u7edf\u7ed3\u679c\u6709\u6f5c\u5728\u4e25\u91cd\u5f71\u54cd\uff0c\u5982\u4f1a\u9519\u8bef\u8bc6\u522b\u7cfb\u7edf\u7279\u6027\u3002", "motivation": "\u8bb8\u591a\u5e94\u7528\u9700\u4ece\u6709\u9650\u65f6\u95f4\u70b9\u6837\u672c\u5b66\u4e60\u52a8\u529b\u7cfb\u7edf\uff0c\u4f18\u5316\u8fc7\u7a0b\u4e2d\u91c7\u7528\u7684\u6570\u503c\u65b9\u6848\u53ef\u80fd\u5f71\u54cd\u5b66\u4e60\u7ed3\u679c\u3002", "method": "\u672a\u63d0\u53ca\u5177\u4f53\u65b9\u6cd5", "result": "\u5206\u6790\u8868\u660e\u6240\u9009\u6570\u503c\u65b9\u6848\u53ef\u80fd\u4f7f\u963b\u5c3c\u632f\u8361\u7cfb\u7edf\u88ab\u9519\u8bef\u8bc6\u522b\u4e3a\u2018\u53cd\u963b\u5c3c\u2019\u4e14\u632f\u8361\u65b9\u5411\u53cd\u8f6c\uff0c\u5374\u80fd\u62df\u5408\u7ed9\u5b9a\u6570\u636e\u70b9\u3002", "conclusion": "\u6240\u9009\u6570\u503c\u65b9\u6848\u4f1a\u5bf9\u5b66\u4e60\u52a8\u529b\u7cfb\u7edf\u7684\u7ed3\u679c\u4ea7\u751f\u6f5c\u5728\u4e25\u91cd\u5f71\u54cd\u3002"}}
{"id": "2507.14799", "pdf": "https://arxiv.org/pdf/2507.14799", "abs": "https://arxiv.org/abs/2507.14799", "authors": ["Sam Johnson", "Viet Pham", "Thai Le"], "title": "Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree", "categories": ["cs.CR", "cs.AI"], "comment": "EMNLP 2025 System Demonstrations Submission", "summary": "This work demonstrates that LLM-based web navigation agents offer powerful\nautomation capabilities but are vulnerable to Indirect Prompt Injection (IPI)\nattacks. We show that adversaries can embed universal adversarial triggers in\nwebpage HTML to hijack agent behavior that utilizes the accessibility tree to\nparse HTML, causing unintended or malicious actions. Using the Greedy\nCoordinate Gradient (GCG) algorithm and a Browser Gym agent powered by\nLlama-3.1, our system demonstrates high success rates across real websites in\nboth targeted and general attacks, including login credential exfiltration and\nforced ad clicks. Our empirical results highlight critical security risks and\nthe need for stronger defenses as LLM-driven autonomous web agents become more\nwidely adopted. The system software\n(https://github.com/sej2020/manipulating-web-agents) is released under the MIT\nLicense, with an accompanying publicly available demo website\n(http://lethaiq.github.io/attack-web-llm-agent).", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f51\u9875\u5bfc\u822a\u4ee3\u7406\u6709\u81ea\u52a8\u5316\u80fd\u529b\u4f46\u6613\u53d7\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5c55\u793a\u653b\u51fb\u6548\u679c\u5e76\u5f3a\u8c03\u5b89\u5168\u98ce\u9669\u548c\u9632\u5fa1\u9700\u6c42\u3002", "motivation": "\u63ed\u793a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f51\u9875\u5bfc\u822a\u4ee3\u7406\u5b58\u5728\u7684\u5b89\u5168\u9690\u60a3\uff0c\u968f\u7740\u5176\u5e7f\u6cdb\u5e94\u7528\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u76f8\u5173\u653b\u51fb\u624b\u6bb5\u548c\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u8d2a\u5a6a\u5750\u6807\u68af\u5ea6\uff08GCG\uff09\u7b97\u6cd5\u548c\u7531Llama - 3.1\u9a71\u52a8\u7684Browser Gym\u4ee3\u7406\u8fdb\u884c\u653b\u51fb\u6d4b\u8bd5\u3002", "result": "\u5728\u771f\u5b9e\u7f51\u7ad9\u7684\u5b9a\u5411\u548c\u901a\u7528\u653b\u51fb\u4e2d\u53d6\u5f97\u9ad8\u6210\u529f\u7387\uff0c\u5305\u62ec\u767b\u5f55\u51ed\u8bc1\u7a83\u53d6\u548c\u5f3a\u5236\u5e7f\u544a\u70b9\u51fb\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u7f51\u9875\u4ee3\u7406\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2507.14800", "pdf": "https://arxiv.org/pdf/2507.14800", "abs": "https://arxiv.org/abs/2507.14800", "authors": ["Xu Yang", "Chenhui Lin", "Haotian Liu", "Qi Wang", "Wenchuan Wu"], "title": "Large Language Model as An Operator: An Experience-Driven Solution for Distribution Network Voltage Control", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": null, "summary": "With the advanced reasoning and information analysis capabilities, large\nlanguage models (LLMs) can offer a novel approach for the autonomous generation\nof dispatch strategies in power systems. This letter proposes an LLM-based\nexperience-driven voltage control solution for distribution networks, which\nenables the self-evolution of LLM-based voltage control strategies through the\ncollaboration and interaction of multiple modules-specifically, experience\nstorage, experience retrieval, experience generation, and experience\nmodification. Comprehensive experimental results validate the effectiveness of\nthe proposed method and highlight the applicability of LLM in addressing power\nsystem dispatch challenges.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u914d\u7535\u7f51\u7535\u538b\u63a7\u5236\u65b9\u6848\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u529b\u7cfb\u7edf\u8c03\u5ea6\u7684\u9002\u7528\u6027\u3002", "motivation": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u4fe1\u606f\u5206\u6790\u80fd\u529b\uff0c\u4e3a\u7535\u529b\u7cfb\u7edf\u8c03\u5ea6\u7b56\u7565\u81ea\u4e3b\u751f\u6210\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ecf\u9a8c\u9a71\u52a8\u7535\u538b\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ecf\u9a8c\u5b58\u50a8\u3001\u68c0\u7d22\u3001\u751f\u6210\u548c\u4fee\u6539\u591a\u4e2a\u6a21\u5757\u534f\u4f5c\u5b9e\u73b0\u7b56\u7565\u7684\u81ea\u6211\u8fdb\u5316\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u9002\u7528\u4e8e\u89e3\u51b3\u7535\u529b\u7cfb\u7edf\u8c03\u5ea6\u6311\u6218\u3002"}}
{"id": "2507.14543", "pdf": "https://arxiv.org/pdf/2507.14543", "abs": "https://arxiv.org/abs/2507.14543", "authors": ["Sharanya Mukherjee", "Md Hishaam Akhtar", "Kannadasan R"], "title": "Real Time Captioning of Sign Language Gestures in Video Meetings", "categories": ["cs.CV", "cs.CY", "cs.HC", "cs.LG", "I.4.6"], "comment": "7 pages, 2 figures, 1 table, Presented at ICCMDE 2021", "summary": "It has always been a rather tough task to communicate with someone possessing\na hearing impairment. One of the most tested ways to establish such a\ncommunication is through the use of sign based languages. However, not many\npeople are aware of the smaller intricacies involved with sign language. Sign\nlanguage recognition using computer vision aims at eliminating the\ncommunication barrier between deaf-mute and ordinary people so that they can\nproperly communicate with others. Recently the pandemic has left the whole\nworld shaken up and has transformed the way we communicate. Video meetings have\nbecome essential for everyone, even people with a hearing disability. In recent\nstudies, it has been found that people with hearing disabilities prefer to sign\nover typing during these video calls. In this paper, we are proposing a browser\nextension that will automatically translate sign language to subtitles for\neveryone else in the video call. The Large-scale dataset which contains more\nthan 2000 Word-Level ASL videos, which were performed by over 100 signers will\nbe used.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f00\u53d1\u4e00\u4e2a\u6d4f\u89c8\u5668\u6269\u5c55\uff0c\u7528\u4e8e\u5728\u89c6\u9891\u901a\u8bdd\u4e2d\u5c06\u624b\u8bed\u81ea\u52a8\u7ffb\u8bd1\u6210\u5b57\u5e55\u3002", "motivation": "\u624b\u8bed\u4ea4\u6d41\u5b58\u5728\u969c\u788d\uff0c\u4e14\u75ab\u60c5\u4e0b\u89c6\u9891\u4f1a\u8bae\u4e2d\u542c\u969c\u4eba\u58eb\u66f4\u503e\u5411\u4e8e\u7528\u624b\u8bed\u4ea4\u6d41\uff0c\u9700\u8981\u6d88\u9664\u542c\u969c\u4eba\u58eb\u4e0e\u666e\u901a\u4eba\u7684\u6c9f\u901a\u969c\u788d\u3002", "method": "\u4f7f\u7528\u5305\u542b\u8d852000\u4e2a\u5355\u8bcd\u7ea7\u7f8e\u56fd\u624b\u8bed\u89c6\u9891\u3001\u8d85100\u4f4d\u624b\u8bed\u8005\u53c2\u4e0e\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u6d4f\u89c8\u5668\u6269\u5c55\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2507.14807", "pdf": "https://arxiv.org/pdf/2507.14807", "abs": "https://arxiv.org/abs/2507.14807", "authors": ["Juan Hu", "Shaojing Fan", "Terence Sim"], "title": "Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multi-face deepfake videos are becoming increasingly prevalent, often\nappearing in natural social settings that challenge existing detection methods.\nMost current approaches excel at single-face detection but struggle in\nmulti-face scenarios, due to a lack of awareness of crucial contextual cues. In\nthis work, we develop a novel approach that leverages human cognition to\nanalyze and defend against multi-face deepfake videos. Through a series of\nhuman studies, we systematically examine how people detect deepfake faces in\nsocial settings. Our quantitative analysis reveals four key cues humans rely\non: scene-motion coherence, inter-face appearance compatibility, interpersonal\ngaze alignment, and face-body consistency. Guided by these insights, we\nintroduce \\textsf{HICOM}, a novel framework designed to detect every fake face\nin multi-face scenarios. Extensive experiments on benchmark datasets show that\n\\textsf{HICOM} improves average accuracy by 3.3\\% in in-dataset detection and\n2.8\\% under real-world perturbations. Moreover, it outperforms existing methods\nby 5.8\\% on unseen datasets, demonstrating the generalization of human-inspired\ncues. \\textsf{HICOM} further enhances interpretability by incorporating an LLM\nto provide human-readable explanations, making detection results more\ntransparent and convincing. Our work sheds light on involving human factors to\nenhance defense against deepfakes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHICOM\u6846\u67b6\u68c0\u6d4b\u591a\u8138\u6df1\u5ea6\u4f2a\u9020\u89c6\u9891\uff0c\u57fa\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u786e\u5b9a\u56db\u4e2a\u5173\u952e\u7ebf\u7d22\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u6cdb\u5316\u6027\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u8fd8\u589e\u5f3a\u4e86\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728\u591a\u8138\u6df1\u5ea6\u4f2a\u9020\u89c6\u9891\u68c0\u6d4b\u4e0a\u56e0\u7f3a\u4e4f\u5173\u952e\u4e0a\u4e0b\u6587\u7ebf\u7d22\u800c\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u4eba\u7c7b\u7814\u7a76\u786e\u5b9a\u56db\u4e2a\u5173\u952e\u7ebf\u7d22\uff0c\u636e\u6b64\u8bbe\u8ba1HICOM\u6846\u67b6\u68c0\u6d4b\u591a\u8138\u573a\u666f\u4e2d\u7684\u5047\u8138\uff0c\u5e76\u7ed3\u5408LLM\u589e\u5f3a\u89e3\u91ca\u6027\u3002", "result": "HICOM\u5728\u6570\u636e\u96c6\u5185\u68c0\u6d4b\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad83.3%\uff0c\u5728\u771f\u5b9e\u6270\u52a8\u4e0b\u63d0\u9ad82.8%\uff0c\u5728\u672a\u89c1\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad85.8%\u3002", "conclusion": "\u5f15\u5165\u4eba\u7c7b\u56e0\u7d20\u53ef\u589e\u5f3a\u5bf9\u6df1\u5ea6\u4f2a\u9020\u7684\u9632\u5fa1\u3002"}}
{"id": "2507.14811", "pdf": "https://arxiv.org/pdf/2507.14811", "abs": "https://arxiv.org/abs/2507.14811", "authors": ["Jiaji Zhang", "Ruichao Sun", "Hailiang Zhao", "Jiaju Wu", "Peng Chen", "Hao Li", "Xinkui Zhao", "Kingsum Chow", "Gang Xiong", "Lin Ye", "Shuiguang Deng"], "title": "SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion models have demonstrated exceptional generative capabilities but\nare computationally intensive, posing significant challenges for deployment in\nresource-constrained or latency-sensitive environments. Quantization offers an\neffective means to reduce model size and computational cost, with post-training\nquantization (PTQ) being particularly appealing due to its compatibility with\npre-trained models without requiring retraining or training data. However,\nexisting PTQ methods for diffusion models often rely on architecture-specific\nheuristics that limit their generalizability and hinder integration with\nindustrial deployment pipelines. To address these limitations, we propose\nSegQuant, a unified quantization framework that adaptively combines\ncomplementary techniques to enhance cross-model versatility. SegQuant consists\nof a segment-aware, graph-based quantization strategy (SegLinear) that captures\nstructural semantics and spatial heterogeneity, along with a dual-scale\nquantization scheme (DualScale) that preserves polarity-asymmetric activations,\nwhich is crucial for maintaining visual fidelity in generated outputs. SegQuant\nis broadly applicable beyond Transformer-based diffusion models, achieving\nstrong performance while ensuring seamless compatibility with mainstream\ndeployment tools.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u91cf\u5316\u6846\u67b6SegQuant\u89e3\u51b3\u6269\u6563\u6a21\u578b\u91cf\u5316\u95ee\u9898\uff0c\u9002\u7528\u8303\u56f4\u5e7f\u4e14\u4e0e\u90e8\u7f72\u5de5\u5177\u517c\u5bb9\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u8ba1\u7b97\u5bc6\u96c6\uff0c\u73b0\u6709\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u901a\u7528\u6027\u5dee\uff0c\u96be\u4ee5\u96c6\u6210\u5230\u5de5\u4e1a\u90e8\u7f72\u6d41\u7a0b\u3002", "method": "\u63d0\u51faSegQuant\u6846\u67b6\uff0c\u5305\u542bSegLinear\u7b56\u7565\u548cDualScale\u91cf\u5316\u65b9\u6848\u3002", "result": "SegQuant\u9002\u7528\u8303\u56f4\u5e7f\uff0c\u80fd\u53d6\u5f97\u826f\u597d\u6027\u80fd\u3002", "conclusion": "SegQuant\u589e\u5f3a\u4e86\u8de8\u6a21\u578b\u901a\u7528\u6027\uff0c\u4e0e\u4e3b\u6d41\u90e8\u7f72\u5de5\u5177\u65e0\u7f1d\u517c\u5bb9\u3002"}}
{"id": "2507.14633", "pdf": "https://arxiv.org/pdf/2507.14633", "abs": "https://arxiv.org/abs/2507.14633", "authors": ["Xiaozheng Gao", "Yichen Wang", "Bosen Liu", "Xiao Zhou", "Ruichen Zhang", "Jiacheng Wang", "Dusit Niyato", "Dong In Kim", "Abbas Jamalipour", "Chau Yuen", "Jianping An", "Kai Yang"], "title": "Agentic Satellite-Augmented Low-Altitude Economy and Terrestrial Networks: A Survey on Generative Approaches", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "The development of satellite-augmented low-altitude economy and terrestrial\nnetworks (SLAETNs) demands intelligent and autonomous systems that can operate\nreliably across heterogeneous, dynamic, and mission-critical environments. To\naddress these challenges, this survey focuses on enabling agentic artificial\nintelligence (AI), that is, artificial agents capable of perceiving, reasoning,\nand acting, through generative AI (GAI) and large language models (LLMs). We\nbegin by introducing the architecture and characteristics of SLAETNs, and\nanalyzing the challenges that arise in integrating satellite, aerial, and\nterrestrial components. Then, we present a model-driven foundation by\nsystematically reviewing five major categories of generative models:\nvariational autoencoders (VAEs), generative adversarial networks (GANs),\ngenerative diffusion models (GDMs), transformer-based models (TBMs), and LLMs.\nMoreover, we provide a comparative analysis to highlight their generative\nmechanisms, capabilities, and deployment trade-offs within SLAETNs. Building on\nthis foundation, we examine how these models empower agentic functions across\nthree domains: communication enhancement, security and privacy protection, and\nintelligent satellite tasks. Finally, we outline key future directions for\nbuilding scalable, adaptive, and trustworthy generative agents in SLAETNs. This\nsurvey aims to provide a unified understanding and actionable reference for\nadvancing agentic AI in next-generation integrated networks.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u536b\u661f\u589e\u5f3a\u4f4e\u7a7a\u7ecf\u6d4e\u4e0e\u5730\u9762\u7f51\u7edc\uff08SLAETNs\uff09\uff0c\u63a2\u8ba8\u901a\u8fc7\u751f\u6210\u5f0fAI\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u667a\u80fd\u81ea\u4e3b\u7cfb\u7edf\uff0c\u4ecb\u7ecd\u67b6\u6784\u4e0e\u6311\u6218\uff0c\u56de\u987e\u751f\u6210\u6a21\u578b\uff0c\u5206\u6790\u5176\u5e94\u7528\uff0c\u7ed9\u51fa\u672a\u6765\u65b9\u5411\u3002", "motivation": "SLAETNs\u53d1\u5c55\u9700\u8981\u667a\u80fd\u81ea\u4e3b\u7cfb\u7edf\uff0c\u89e3\u51b3\u5728\u5f02\u6784\u3001\u52a8\u6001\u548c\u5173\u952e\u4efb\u52a1\u73af\u5883\u4e2d\u53ef\u9760\u8fd0\u884c\u7684\u6311\u6218\u3002", "method": "\u5148\u4ecb\u7ecdSLAETNs\u67b6\u6784\u4e0e\u7279\u5f81\uff0c\u5206\u6790\u96c6\u6210\u6311\u6218\uff0c\u7cfb\u7edf\u56de\u987e\u4e94\u7c7b\u751f\u6210\u6a21\u578b\u5e76\u5bf9\u6bd4\u5206\u6790\uff0c\u7814\u7a76\u6a21\u578b\u5728\u4e09\u4e2a\u9886\u57df\u7684\u5e94\u7528\u3002", "result": "\u660e\u786e\u5404\u7c7b\u751f\u6210\u6a21\u578b\u5728SLAETNs\u4e2d\u7684\u751f\u6210\u673a\u5236\u3001\u80fd\u529b\u548c\u90e8\u7f72\u6743\u8861\uff0c\u4ee5\u53ca\u5728\u4e0d\u540c\u9886\u57df\u7684\u4f5c\u7528\u3002", "conclusion": "\u4e3a\u4e0b\u4e00\u4ee3\u96c6\u6210\u7f51\u7edc\u4e2d\u63a8\u8fdb\u667a\u80fdAI\u63d0\u4f9b\u7edf\u4e00\u7406\u89e3\u548c\u53ef\u64cd\u4f5c\u53c2\u8003\u3002"}}
{"id": "2507.14833", "pdf": "https://arxiv.org/pdf/2507.14833", "abs": "https://arxiv.org/abs/2507.14833", "authors": ["Haoxuan Zhang", "Wenju Cui", "Yuzhu Cao", "Tao Tan", "Jie Liu", "Yunsong Peng", "Jian Zheng"], "title": "Paired Image Generation with Diffusion-Guided Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The segmentation of mass lesions in digital breast tomosynthesis (DBT) images\nis very significant for the early screening of breast cancer. However, the\nhigh-density breast tissue often leads to high concealment of the mass lesions,\nwhich makes manual annotation difficult and time-consuming. As a result, there\nis a lack of annotated data for model training. Diffusion models are commonly\nused for data augmentation, but the existing methods face two challenges.\nFirst, due to the high concealment of lesions, it is difficult for the model to\nlearn the features of the lesion area. This leads to the low generation quality\nof the lesion areas, thus limiting the quality of the generated images. Second,\nexisting methods can only generate images and cannot generate corresponding\nannotations, which restricts the usability of the generated images in\nsupervised training. In this work, we propose a paired image generation method.\nThe method does not require external conditions and can achieve the generation\nof paired images by training an extra diffusion guider for the conditional\ndiffusion model. During the experimental phase, we generated paired DBT slices\nand mass lesion masks. Then, we incorporated them into the supervised training\nprocess of the mass lesion segmentation task. The experimental results show\nthat our method can improve the generation quality without external conditions.\nMoreover, it contributes to alleviating the shortage of annotated data, thus\nenhancing the performance of downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u5916\u90e8\u6761\u4ef6\u7684\u914d\u5bf9\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210DBT\u5207\u7247\u548c\u75c5\u7076\u63a9\u7801\uff0c\u7f13\u89e3\u6807\u6ce8\u6570\u636e\u77ed\u7f3a\uff0c\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u6570\u5b57\u4e73\u817a\u65ad\u5c42\u5408\u6210\uff08DBT\uff09\u56fe\u50cf\u4e2d\u80bf\u5757\u75c5\u53d8\u5206\u5272\u5bf9\u4e73\u817a\u764c\u65e9\u671f\u7b5b\u67e5\u91cd\u8981\uff0c\u4f46\u9ad8\u5bc6\u5ea6\u4e73\u817a\u7ec4\u7ec7\u4f7f\u75c5\u53d8\u9690\u853d\uff0c\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\uff0c\u73b0\u6709\u6269\u6563\u6a21\u578b\u751f\u6210\u8d28\u91cf\u4f4e\u4e14\u65e0\u5bf9\u5e94\u6807\u6ce8\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u914d\u5bf9\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\uff0c\u4e3a\u6761\u4ef6\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u989d\u5916\u7684\u6269\u6563\u5f15\u5bfc\u5668\uff0c\u5b9e\u73b0\u65e0\u5916\u90e8\u6761\u4ef6\u7684\u914d\u5bf9\u56fe\u50cf\u751f\u6210\u3002", "result": "\u751f\u6210\u4e86\u914d\u5bf9\u7684DBT\u5207\u7247\u548c\u80bf\u5757\u75c5\u53d8\u63a9\u7801\uff0c\u5e76\u7528\u4e8e\u80bf\u5757\u75c5\u53d8\u5206\u5272\u4efb\u52a1\u7684\u76d1\u7763\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5728\u65e0\u5916\u90e8\u6761\u4ef6\u4e0b\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\uff0c\u7f13\u89e3\u6807\u6ce8\u6570\u636e\u77ed\u7f3a\uff0c\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2507.14639", "pdf": "https://arxiv.org/pdf/2507.14639", "abs": "https://arxiv.org/abs/2507.14639", "authors": ["Saleh Alwer", "Ronan Fleming"], "title": "KinForm: Kinetics Informed Feature Optimised Representation Models for Enzyme $k_{cat}$ and $K_{M}$ Prediction", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "Kinetic parameters such as the turnover number ($k_{cat}$) and Michaelis\nconstant ($K_{\\mathrm{M}}$) are essential for modelling enzymatic activity but\nexperimental data remains limited in scale and diversity. Previous methods for\npredicting enzyme kinetics typically use mean-pooled residue embeddings from a\nsingle protein language model to represent the protein. We present KinForm, a\nmachine learning framework designed to improve predictive accuracy and\ngeneralisation for kinetic parameters by optimising protein feature\nrepresentations. KinForm combines several residue-level embeddings\n(Evolutionary Scale Modeling Cambrian, Evolutionary Scale Modeling 2, and\nProtT5-XL-UniRef50), taken from empirically selected intermediate transformer\nlayers and applies weighted pooling based on per-residue binding-site\nprobability. To counter the resulting high dimensionality, we apply\ndimensionality reduction using principal--component analysis (PCA) on\nconcatenated protein features, and rebalance the training data via a\nsimilarity-based oversampling strategy. KinForm outperforms baseline methods on\ntwo benchmark datasets. Improvements are most pronounced in low sequence\nsimilarity bins. We observe improvements from binding-site probability pooling,\nintermediate-layer selection, PCA, and oversampling of low-identity proteins.\nWe also find that removing sequence overlap between folds provides a more\nrealistic evaluation of generalisation and should be the standard over random\nsplitting when benchmarking kinetic prediction models.", "AI": {"tldr": "\u63d0\u51faKinForm\u673a\u5668\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u86cb\u767d\u8d28\u7279\u5f81\u8868\u793a\u4ee5\u9884\u6d4b\u9176\u52a8\u529b\u5b66\u53c2\u6570\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5b9e\u9a8c\u6570\u636e\u5728\u89c4\u6a21\u548c\u591a\u6837\u6027\u4e0a\u6709\u9650\uff0c\u4ee5\u5f80\u9884\u6d4b\u9176\u52a8\u529b\u5b66\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u5355\u4e00\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u5e73\u5747\u6c60\u5316\u6b8b\u57fa\u5d4c\u5165\u6765\u8868\u793a\u86cb\u767d\u8d28\uff0c\u9700\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u591a\u4e2a\u6b8b\u57fa\u7ea7\u5d4c\u5165\uff0c\u57fa\u4e8e\u6bcf\u4e2a\u6b8b\u57fa\u7684\u7ed3\u5408\u4f4d\u70b9\u6982\u7387\u8fdb\u884c\u52a0\u6743\u6c60\u5316\uff0c\u7528\u4e3b\u6210\u5206\u5206\u6790\u8fdb\u884c\u964d\u7ef4\uff0c\u901a\u8fc7\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u8fc7\u91c7\u6837\u7b56\u7565\u91cd\u65b0\u5e73\u8861\u8bad\u7ec3\u6570\u636e\u3002", "result": "KinForm\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4f4e\u5e8f\u5217\u76f8\u4f3c\u6027\u533a\u95f4\u6539\u8fdb\u6700\u660e\u663e\uff0c\u7ed3\u5408\u4f4d\u70b9\u6982\u7387\u6c60\u5316\u7b49\u64cd\u4f5c\u6709\u6548\u679c\u3002", "conclusion": "\u53bb\u9664\u6298\u53e0\u95f4\u7684\u5e8f\u5217\u91cd\u53e0\u80fd\u66f4\u771f\u5b9e\u8bc4\u4f30\u6cdb\u5316\u80fd\u529b\uff0c\u5e94\u4f5c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u52a8\u529b\u5b66\u9884\u6d4b\u6a21\u578b\u7684\u6807\u51c6\u3002"}}
{"id": "2507.14851", "pdf": "https://arxiv.org/pdf/2507.14851", "abs": "https://arxiv.org/abs/2507.14851", "authors": ["Muhammad Kamran Janjua", "Amirhosein Ghasemabadi", "Kunlin Zhang", "Mohammad Salameh", "Chao Gao", "Di Niu"], "title": "Grounding Degradations in Natural Language for All-In-One Video Restoration", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "17 pages", "summary": "In this work, we propose an all-in-one video restoration framework that\ngrounds degradation-aware semantic context of video frames in natural language\nvia foundation models, offering interpretable and flexible guidance. Unlike\nprior art, our method assumes no degradation knowledge in train or test time\nand learns an approximation to the grounded knowledge such that the foundation\nmodel can be safely disentangled during inference adding no extra cost.\nFurther, we call for standardization of benchmarks in all-in-one video\nrestoration, and propose two benchmarks in multi-degradation setting,\nthree-task (3D) and four-task (4D), and two time-varying composite degradation\nbenchmarks; one of the latter being our proposed dataset with varying snow\nintensity, simulating how weather degradations affect videos naturally. We\ncompare our method with prior works and report state-of-the-art performance on\nall benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4f53\u5316\u89c6\u9891\u6062\u590d\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u5c06\u89c6\u9891\u5e27\u8bed\u4e49\u4e0a\u4e0b\u6587\u4e0e\u81ea\u7136\u8bed\u8a00\u5173\u8054\uff0c\u8fd8\u547c\u5401\u6807\u51c6\u5316\u57fa\u51c6\u5e76\u63d0\u51fa\u65b0\u57fa\u51c6\uff0c\u5b9e\u9a8c\u8868\u73b0\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u89c6\u9891\u6062\u590d\u65f6\u53ef\u80fd\u9700\u8981\u5148\u9a8c\u7684\u9000\u5316\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u548c\u7075\u6d3b\u7684\u6307\u5bfc\uff0c\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e00\u4f53\u5316\u89c6\u9891\u6062\u590d\u6846\u67b6\uff0c\u4e0d\u4f9d\u8d56\u9000\u5316\u77e5\u8bc6\uff0c\u5b66\u4e60\u8fd1\u4f3c\u7684\u5173\u8054\u77e5\u8bc6\uff0c\u63a8\u7406\u65f6\u53ef\u5206\u79bb\u57fa\u7840\u6a21\u578b\uff1b\u63d0\u51fa3D\u30014D\u591a\u9000\u5316\u57fa\u51c6\u548c\u4e24\u4e2a\u65f6\u53d8\u590d\u5408\u9000\u5316\u57fa\u51c6\u3002", "result": "\u4e0e\u5148\u524d\u5de5\u4f5c\u5bf9\u6bd4\uff0c\u5728\u6240\u6709\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e00\u4f53\u5316\u89c6\u9891\u6062\u590d\u6846\u67b6\u53ca\u57fa\u51c6\u6709\u6548\uff0c\u80fd\u63a8\u52a8\u89c6\u9891\u6062\u590d\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2507.14658", "pdf": "https://arxiv.org/pdf/2507.14658", "abs": "https://arxiv.org/abs/2507.14658", "authors": ["Faizan Contractor", "Li Li", "Ranwa Al Mallah"], "title": "Learning to Communicate in Multi-Agent Reinforcement Learning for Autonomous Cyber Defence", "categories": ["cs.MA", "cs.CR", "cs.LG"], "comment": null, "summary": "Popular methods in cooperative Multi-Agent Reinforcement Learning with\npartially observable environments typically allow agents to act independently\nduring execution, which may limit the coordinated effect of the trained\npolicies. However, by sharing information such as known or suspected ongoing\nthreats, effective communication can lead to improved decision-making in the\ncyber battle space. We propose a game design where defender agents learn to\ncommunicate and defend against imminent cyber threats by playing training games\nin the Cyber Operations Research Gym, using the Differentiable Inter Agent\nLearning algorithm adapted to the cyber operational environment. The tactical\npolicies learned by these autonomous agents are akin to those of human experts\nduring incident responses to avert cyber threats. In addition, the agents\nsimultaneously learn minimal cost communication messages while learning their\ndefence tactical policies.", "AI": {"tldr": "\u63d0\u51fa\u5728\u7f51\u7edc\u4f5c\u6218\u73af\u5883\u4e2d\u8ba9\u9632\u5fa1\u4ee3\u7406\u5b66\u4e60\u901a\u4fe1\u548c\u9632\u5fa1\u7f51\u7edc\u5a01\u80c1\u7684\u6e38\u620f\u8bbe\u8ba1\uff0c\u4ee3\u7406\u80fd\u5b66\u4e60\u7c7b\u4f3c\u4eba\u7c7b\u4e13\u5bb6\u7684\u7b56\u7565\u5e76\u540c\u65f6\u5b66\u4e60\u6700\u5c0f\u6210\u672c\u901a\u4fe1\u6d88\u606f\u3002", "motivation": "\u73b0\u6709\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u6267\u884c\u65f6\u8ba9\u667a\u80fd\u4f53\u72ec\u7acb\u884c\u52a8\uff0c\u9650\u5236\u4e86\u8bad\u7ec3\u7b56\u7565\u7684\u534f\u8c03\u6548\u679c\uff0c\u800c\u6709\u6548\u901a\u4fe1\u53ef\u6539\u5584\u7f51\u7edc\u4f5c\u6218\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u6e38\u620f\u8bbe\u8ba1\uff0c\u8ba9\u9632\u5fa1\u4ee3\u7406\u5728\u7f51\u7edc\u4f5c\u6218\u7814\u7a76\u5065\u8eab\u623f\u4e2d\u73a9\u8bad\u7ec3\u6e38\u620f\uff0c\u4f7f\u7528\u9002\u5e94\u7f51\u7edc\u4f5c\u6218\u73af\u5883\u7684\u53ef\u5fae\u667a\u80fd\u4f53\u95f4\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u81ea\u4e3b\u4ee3\u7406\u5b66\u4e60\u5230\u7684\u6218\u672f\u7b56\u7565\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u5e94\u5bf9\u7f51\u7edc\u5a01\u80c1\u65f6\u7684\u7b56\u7565\uff0c\u4e14\u5728\u5b66\u4e60\u9632\u5fa1\u7b56\u7565\u65f6\u540c\u65f6\u5b66\u4e60\u6700\u5c0f\u6210\u672c\u901a\u4fe1\u6d88\u606f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4f7f\u4ee3\u7406\u5728\u7f51\u7edc\u4f5c\u6218\u4e2d\u5b66\u4e60\u6709\u6548\u901a\u4fe1\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u5e94\u5bf9\u7f51\u7edc\u5a01\u80c1\u3002"}}
{"id": "2507.14904", "pdf": "https://arxiv.org/pdf/2507.14904", "abs": "https://arxiv.org/abs/2507.14904", "authors": ["Fan Li", "Zanyi Wang", "Zeyi Huang", "Guang Dai", "Jingdong Wang", "Mengmeng Wang"], "title": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "3D visual grounding allows an embodied agent to understand visual information\nin real-world 3D environments based on human instructions, which is crucial for\nembodied intelligence. Existing 3D visual grounding methods typically rely on\nseparate encoders for different modalities (e.g., RGB images, text, and 3D\npoint clouds), resulting in large and complex models that are inefficient to\ntrain. While some approaches use pre-trained 2D multi-modal models like CLIP\nfor 3D tasks, they still struggle with aligning point cloud data to 2D\nencoders. As a result, these methods continue to depend on 3D encoders for\nfeature extraction, further increasing model complexity and training\ninefficiency. In this paper, we propose a unified 2D pre-trained multi-modal\nnetwork to process all three modalities (RGB images, text, and point clouds),\nsignificantly simplifying the architecture. By leveraging a 2D CLIP bi-modal\nmodel with adapter-based fine-tuning, this framework effectively adapts to the\ntri-modal setting, improving both adaptability and performance across\nmodalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module\nis designed to fuse geometric multi-scale features from point clouds and\nimages. We then integrate textual features for final modality fusion and\nintroduce a multi-modal decoder to facilitate deep cross-modal understanding.\nTogether, our method achieves unified feature extraction and fusion across the\nthree modalities, enabling an end-to-end 3D visual grounding model. Compared to\nthe baseline, our method reduces the number of trainable parameters by\napproximately 58\\%, while achieving a 6.52\\% improvement in the 3D detection\ntask and a 6.25\\% improvement in the 3D visual grounding task.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e002D\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u7f51\u7edc\u5904\u7406RGB\u56fe\u50cf\u3001\u6587\u672c\u548c\u70b9\u4e91\uff0c\u7b80\u5316\u67b6\u6784\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef3D\u89c6\u89c9\u5b9a\u4f4d\uff0c\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u67093D\u89c6\u89c9\u5b9a\u4f4d\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u540c\u6a21\u6001\u7684\u72ec\u7acb\u7f16\u7801\u5668\uff0c\u6a21\u578b\u5927\u4e14\u590d\u6742\uff0c\u8bad\u7ec3\u6548\u7387\u4f4e\uff0c\u4f7f\u7528\u9884\u8bad\u7ec32D\u591a\u6a21\u6001\u6a21\u578b\u4e5f\u96be\u4ee5\u5904\u7406\u70b9\u4e91\u6570\u636e\u3002", "method": "\u63d0\u51fa\u7edf\u4e002D\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u7f51\u7edc\uff0c\u5229\u7528\u5e26\u9002\u914d\u5668\u5fae\u8c03\u76842D CLIP\u53cc\u6a21\u6001\u6a21\u578b\uff0c\u8bbe\u8ba1GARF\u6a21\u5757\u878d\u5408\u7279\u5f81\uff0c\u5f15\u5165\u591a\u6a21\u6001\u89e3\u7801\u5668\u3002", "result": "\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0c\u51cf\u5c11\u7ea658%\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c3D\u68c0\u6d4b\u4efb\u52a1\u63d0\u53476.52%\uff0c3D\u89c6\u89c9\u5b9a\u4f4d\u4efb\u52a1\u63d0\u53476.25%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5b9e\u73b0\u4e09\u79cd\u6a21\u6001\u7684\u7edf\u4e00\u7279\u5f81\u63d0\u53d6\u548c\u878d\u5408\uff0c\u6784\u5efa\u7aef\u5230\u7aef3D\u89c6\u89c9\u5b9a\u4f4d\u6a21\u578b\uff0c\u7b80\u5316\u67b6\u6784\u5e76\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.14696", "pdf": "https://arxiv.org/pdf/2507.14696", "abs": "https://arxiv.org/abs/2507.14696", "authors": ["Samantha Dies", "David Liu", "Tina Eliassi-Rad"], "title": "Forecasting Faculty Placement from Patterns in Co-authorship Networks", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "Faculty hiring shapes the flow of ideas, resources, and opportunities in\nacademia, influencing not only individual career trajectories but also broader\npatterns of institutional prestige and scientific progress. While traditional\nstudies have found strong correlations between faculty hiring and attributes\nsuch as doctoral department prestige and publication record, they rarely assess\nwhether these associations generalize to individual hiring outcomes,\nparticularly for future candidates outside the original sample. Here, we\nconsider faculty placement as an individual-level prediction task. Our data\nconsist of temporal co-authorship networks with conventional attributes such as\ndoctoral department prestige and bibliometric features. We observe that using\nthe co-authorship network significantly improves predictive accuracy by up to\n10% over traditional indicators alone, with the largest gains observed for\nplacements at the most elite (top-10) departments. Our results underscore the\nrole that social networks, professional endorsements, and implicit advocacy\nplay in faculty hiring beyond traditional measures of scholarly productivity\nand institutional prestige. By introducing a predictive framing of faculty\nplacement and establishing the benefit of considering co-authorship networks,\nthis work provides a new lens for understanding structural biases in academia\nthat could inform targeted interventions aimed at increasing transparency,\nfairness, and equity in academic hiring practices.", "AI": {"tldr": "\u7814\u7a76\u5c06\u6559\u5e08\u804c\u4f4d\u5b89\u7f6e\u89c6\u4e3a\u4e2a\u4eba\u5c42\u9762\u9884\u6d4b\u4efb\u52a1\uff0c\u53d1\u73b0\u5408\u4f5c\u7f51\u7edc\u80fd\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u63ed\u793a\u793e\u4ea4\u7f51\u7edc\u5728\u6559\u5e08\u62db\u8058\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edf\u7814\u7a76\u672a\u8bc4\u4f30\u5176\u5173\u8054\u662f\u5426\u9002\u7528\u4e8e\u4e2a\u4f53\u62db\u8058\u7ed3\u679c\uff0c\u5c24\u5176\u662f\u6837\u672c\u5916\u672a\u6765\u5019\u9009\u4eba\uff0c\u9700\u65b0\u89c6\u89d2\u7814\u7a76\u6559\u5e08\u62db\u8058\u3002", "method": "\u5c06\u6559\u5e08\u804c\u4f4d\u5b89\u7f6e\u4f5c\u4e3a\u4e2a\u4f53\u5c42\u9762\u9884\u6d4b\u4efb\u52a1\uff0c\u5229\u7528\u5305\u542b\u4f20\u7edf\u5c5e\u6027\u548c\u5408\u4f5c\u7f51\u7edc\u7684\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u4f7f\u7528\u5408\u4f5c\u7f51\u7edc\u6bd4\u4f20\u7edf\u6307\u6807\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u8fbe10%\uff0c\u5728\u9876\u5c16\u90e8\u95e8\u5b89\u7f6e\u9884\u6d4b\u63d0\u5347\u6700\u5927\u3002", "conclusion": "\u793e\u4ea4\u7f51\u7edc\u7b49\u5728\u6559\u5e08\u62db\u8058\u4e2d\u4f5c\u7528\u8d85\u4f20\u7edf\u6307\u6807\uff0c\u4e3a\u7406\u89e3\u5b66\u672f\u7ed3\u6784\u504f\u89c1\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u53ef\u6307\u5bfc\u5e72\u9884\u63aa\u65bd\u63d0\u5347\u62db\u8058\u516c\u5e73\u6027\u3002"}}
{"id": "2507.14908", "pdf": "https://arxiv.org/pdf/2507.14908", "abs": "https://arxiv.org/abs/2507.14908", "authors": ["Daniel Ayomide Olanrewaju"], "title": "Partial Symmetry Enforced Attention Decomposition (PSEAD): A Group-Theoretic Framework for Equivariant Transformers in Biological Systems", "categories": ["math.RT", "cs.AI", "cs.LG"], "comment": null, "summary": "This research introduces the Theory of Partial Symmetry Enforced Attention\nDecomposition (PSEAD), a new and rigorous group-theoretic framework designed to\nseamlessly integrate local symmetry awareness into the core architecture of\nself-attention mechanisms within Transformer models. We formalize the concept\nof local permutation subgroup actions on windows of biological data, proving\nthat under such actions, the attention mechanism naturally decomposes into a\ndirect sum of orthogonal irreducible components. Critically, these components\nare intrinsically aligned with the irreducible representations of the acting\npermutation subgroup, thereby providing a powerful mathematical basis for\ndisentangling symmetric and asymmetric features. We show that PSEAD offers\nsubstantial advantages. These include enhanced generalization capabilities to\nnovel biological motifs exhibiting similar partial symmetries, unprecedented\ninterpretability by allowing direct visualization and analysis of attention\ncontributions from different symmetry channels, and significant computational\nefficiency gains by focusing representational capacity on relevant symmetric\nsubspaces. Beyond static data analysis, we extend PSEAD's applicability to\ndynamic biological processes within reinforcement learning paradigms,\nshowcasing its potential to accelerate the discovery and optimization of\nbiologically meaningful policies in complex environments like protein folding\nand drug discovery. This work lays the groundwork for a new generation of\nbiologically informed, symmetry-aware artificial intelligence models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPSEAD\u6846\u67b6\uff0c\u5c06\u5c40\u90e8\u5bf9\u79f0\u610f\u8bc6\u878d\u5165Transformer\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u8bf8\u591a\u4f18\u52bf\u5e76\u53ef\u7528\u4e8e\u52a8\u6001\u751f\u7269\u8fc7\u7a0b\uff0c\u4e3a\u65b0\u4e00\u4ee3AI\u6a21\u578b\u5960\u57fa\u3002", "motivation": "\u5c06\u5c40\u90e8\u5bf9\u79f0\u610f\u8bc6\u878d\u5165Transformer\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6838\u5fc3\u67b6\u6784\uff0c\u4ee5\u5904\u7406\u751f\u7269\u6570\u636e\u3002", "method": "\u5f62\u5f0f\u5316\u5c40\u90e8\u7f6e\u6362\u5b50\u7fa4\u5bf9\u751f\u7269\u6570\u636e\u7a97\u53e3\u7684\u4f5c\u7528\uff0c\u8bc1\u660e\u6ce8\u610f\u529b\u673a\u5236\u53ef\u5206\u89e3\u4e3a\u6b63\u4ea4\u4e0d\u53ef\u7ea6\u5206\u91cf\u7684\u76f4\u548c\u3002", "result": "PSEAD\u6709\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7b49\u4f18\u52bf\uff0c\u8fd8\u53ef\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u52a8\u6001\u751f\u7269\u8fc7\u7a0b\u3002", "conclusion": "\u4e3a\u65b0\u4e00\u4ee3\u5177\u6709\u751f\u7269\u5b66\u4fe1\u606f\u3001\u5bf9\u79f0\u611f\u77e5\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.14914", "pdf": "https://arxiv.org/pdf/2507.14914", "abs": "https://arxiv.org/abs/2507.14914", "authors": ["Zhexuan Xu", "Jie Wang", "Siyuan Xu", "Zijie Geng", "Mingxuan Yuan", "Feng Wu"], "title": "One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Floorplanning determines the shapes and locations of modules on a chip canvas\nand plays a critical role in optimizing the chip's Power, Performance, and Area\n(PPA) metrics. However, existing floorplanning approaches often fail to\nintegrate with subsequent physical design stages, leading to suboptimal\nin-module component placement and excessive inter-module feedthrough. To tackle\nthis challenge, we propose Flora, a three-stage feedthrough and placement aware\nrectilinear floorplanner. In the first stage, Flora employs wiremask and\nposition mask techniques to achieve coarse-grained optimization of HPWL and\nfeedthrough. In the second stage, under the constraint of a fixed outline,\nFlora achieves a zero-whitespace layout by locally resizing module shapes,\nthereby performing fine-grained optimization of feedthrough and improving\ncomponent placement. In the third stage, Flora utilizes a fast tree\nsearch-based method to efficiently place components-including macros and\nstandard cells-within each module, subsequently adjusting module boundaries\nbased on the placement results to enable cross-stage optimization. Experimental\nresults show that Flora outperforms recent state-of-the-art floorplanning\napproaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,\n29.15% in FTmod, and a 14% improvement in component placement performance.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3aFlora\u7684\u4e09\u9636\u6bb5\u5e03\u56fe\u89c4\u5212\u5668\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u591a\u9879\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5e03\u56fe\u89c4\u5212\u65b9\u6cd5\u96be\u4ee5\u4e0e\u540e\u7eed\u7269\u7406\u8bbe\u8ba1\u9636\u6bb5\u96c6\u6210\uff0c\u5bfc\u81f4\u6a21\u5757\u5185\u7ec4\u4ef6\u5e03\u5c40\u4e0d\u7406\u60f3\u548c\u6a21\u5757\u95f4\u9988\u901a\u8fc7\u591a\u3002", "method": "Flora\u5206\u4e09\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u9636\u6bb5\u7528\u63a9\u7801\u6280\u672f\u7c97\u4f18\u5316HPWL\u548c\u9988\u901a\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5c40\u90e8\u8c03\u6574\u6a21\u5757\u5f62\u72b6\u5b9e\u73b0\u96f6\u7a7a\u767d\u5e03\u5c40\uff0c\u7ec6\u4f18\u5316\u9988\u901a\u548c\u7ec4\u4ef6\u5e03\u5c40\uff1b\u7b2c\u4e09\u9636\u6bb5\u7528\u5feb\u901f\u6811\u641c\u7d22\u6cd5\u653e\u7f6e\u7ec4\u4ef6\u5e76\u8c03\u6574\u6a21\u5757\u8fb9\u754c\u5b9e\u73b0\u8de8\u9636\u6bb5\u4f18\u5316\u3002", "result": "Flora\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0cHPWL\u5e73\u5747\u964d\u4f4e6%\uff0cFTpin\u964d\u4f4e5.16%\uff0cFTmod\u964d\u4f4e29.15%\uff0c\u7ec4\u4ef6\u5e03\u5c40\u6027\u80fd\u63d0\u534714%\u3002", "conclusion": "Flora\u662f\u4e00\u79cd\u6709\u6548\u7684\u5e03\u56fe\u89c4\u5212\u65b9\u6cd5\uff0c\u80fd\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\u5e76\u63d0\u5347\u82af\u7247PPA\u6307\u6807\u3002"}}
{"id": "2507.14975", "pdf": "https://arxiv.org/pdf/2507.14975", "abs": "https://arxiv.org/abs/2507.14975", "authors": ["Yufan Song", "Jiatao Zhang", "Zeng Gu", "Qingmiao Liang", "Tuocheng Hu", "Wei Song", "Shiqiang Zhu"], "title": "FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 6 figures, IROS 2025", "summary": "Autonomous error correction is critical for domestic robots to achieve\nreliable execution of complex long-horizon tasks. Prior work has explored\nself-reflection in Large Language Models (LLMs) for task planning error\ncorrection; however, existing methods are constrained by inflexible\nself-reflection mechanisms that limit their effectiveness. Motivated by these\nlimitations and inspired by human cognitive adaptation, we propose the Flexible\nConstructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture\nthat enables LLMs to perform flexible self-reflection based on task difficulty,\nwhile constructively integrating historical valuable experience with failure\nlessons. We evaluated FCRF on diverse domestic tasks through simulation in\nAlfWorld and physical deployment in the real-world environment. Experimental\nresults demonstrate that FCRF significantly improves overall performance and\nself-reflection flexibility in complex long-horizon robotic tasks.", "AI": {"tldr": "\u63d0\u51faFCRF\u6846\u67b6\u89e3\u51b3\u5bb6\u7528\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u7ea0\u9519\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u53cd\u601d\u673a\u5236\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u9650\u5236\u7ea0\u9519\u6548\u679c\u3002", "method": "\u63d0\u51faFlexible Constructivism Reflection Framework (FCRF)\uff0c\u4e00\u79cd\u5bfc\u5e08 - \u6267\u884c\u8005\u67b6\u6784\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u8fdb\u884c\u7075\u6d3b\u81ea\u6211\u53cd\u601d\uff0c\u5e76\u5efa\u8bbe\u6027\u5730\u6574\u5408\u5386\u53f2\u7ecf\u9a8c\u4e0e\u5931\u8d25\u6559\u8bad\u3002", "result": "\u5728AlfWorld\u6a21\u62df\u548c\u73b0\u5b9e\u73af\u5883\u4e2d\u5bf9\u4e0d\u540c\u5bb6\u5ead\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\uff0cFCRF\u663e\u8457\u63d0\u5347\u590d\u6742\u957f\u65f6\u673a\u5668\u4eba\u4efb\u52a1\u7684\u6574\u4f53\u6027\u80fd\u548c\u81ea\u6211\u53cd\u601d\u7075\u6d3b\u6027\u3002", "conclusion": "FCRF\u6846\u67b6\u6709\u6548\u53ef\u884c\uff0c\u80fd\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u6027\u3002"}}
{"id": "2507.14853", "pdf": "https://arxiv.org/pdf/2507.14853", "abs": "https://arxiv.org/abs/2507.14853", "authors": ["Khoa Nguyen", "Tanveer Khan", "Antonis Michalas"], "title": "A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training without sharing\nraw data, making it a promising approach for privacy-sensitive domains. Despite\nits potential, FL faces significant challenges, particularly in terms of\ncommunication overhead and data privacy. Privacy-preserving Techniques (PPTs)\nsuch as Homomorphic Encryption (HE) have been used to mitigate these concerns.\nHowever, these techniques introduce substantial computational and communication\ncosts, limiting their practical deployment. In this work, we explore how Hybrid\nHomomorphic Encryption (HHE), a cryptographic protocol that combines symmetric\nencryption with HE, can be effectively integrated with FL to address both\ncommunication and privacy challenges, paving the way for scalable and secure\ndecentralized learning system.", "AI": {"tldr": "\u63a2\u7d22\u6df7\u5408\u540c\u6001\u52a0\u5bc6\uff08HHE\uff09\u4e0e\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u7ed3\u5408\uff0c\u89e3\u51b3\u901a\u4fe1\u548c\u9690\u79c1\u6311\u6218\uff0c\u63a8\u52a8\u53ef\u6269\u5c55\u5b89\u5168\u7684\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u7cfb\u7edf\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u901a\u4fe1\u5f00\u9500\u548c\u6570\u636e\u9690\u79c1\u6311\u6218\uff0c\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u6210\u672c\u9ad8\uff0c\u9650\u5236\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63a2\u7d22\u5c06\u7ed3\u5408\u5bf9\u79f0\u52a0\u5bc6\u548c\u540c\u6001\u52a0\u5bc6\u7684\u6df7\u5408\u540c\u6001\u52a0\u5bc6\uff08HHE\uff09\u4e0e\u8054\u90a6\u5b66\u4e60\u6709\u6548\u96c6\u6210\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u671b\u89e3\u51b3\u901a\u4fe1\u548c\u9690\u79c1\u6311\u6218\uff0c\u4e3a\u53ef\u6269\u5c55\u5b89\u5168\u7684\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u7cfb\u7edf\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.15032", "pdf": "https://arxiv.org/pdf/2507.15032", "abs": "https://arxiv.org/abs/2507.15032", "authors": ["Nicol\u00f2 Oreste Pinciroli Vago", "Roberta Amato", "Matteo Imbrogno", "GianLuca Israel", "Andrea Belfiore", "Konstantinos Kovlakas", "Piero Fraternali", "Mario Pasquato"], "title": "The hunt for new pulsating ultraluminous X-ray sources: a clustering approach", "categories": ["astro-ph.HE", "astro-ph.IM", "cs.AI", "cs.LG"], "comment": "16 pages, 8 figures; accepted in A&A", "summary": "The discovery of fast and variable coherent signals in a handful of\nultraluminous X-ray sources (ULXs) testifies to the presence of super-Eddington\naccreting neutron stars, and drastically changed the understanding of the ULX\nclass. Our capability of discovering pulsations in ULXs is limited, among\nothers, by poor statistics. However, catalogues and archives of high-energy\nmissions contain information which can be used to identify new candidate\npulsating ULXs (PULXs). The goal of this research is to single out candidate\nPULXs among those ULXs which have not shown pulsations due to an unfavourable\ncombination of factors. We applied an AI approach to an updated database of\nULXs detected by XMM-Newton. We first used an unsupervised clustering algorithm\nto sort out sources with similar characteristics into two clusters. Then, the\nsample of known PULX observations has been used to set the separation threshold\nbetween the two clusters and to identify the one containing the new candidate\nPULXs. We found that only a few criteria are needed to assign the membership of\nan observation to one of the two clusters. The cluster of new candidate PULXs\ncounts 85 unique sources for 355 observations, with $\\sim$85% of these new\ncandidates having multiple observations. A preliminary timing analysis found no\nnew pulsations for these candidates. This work presents a sample of new\ncandidate PULXs observed by XMM-Newton, the properties of which are similar (in\na multi-dimensional phase space) to those of the known PULXs, despite the\nabsence of pulsations in their light curves. While this result is a clear\nexample of the predictive power of AI-based methods, it also highlights the\nneed for high-statistics observational data to reveal coherent signals from the\nsources in this sample and thus validate the robustness of the approach.", "AI": {"tldr": "\u6587\u7ae0\u7528AI\u65b9\u6cd5\u4eceXMM - Newton\u63a2\u6d4b\u7684ULXs\u66f4\u65b0\u6570\u636e\u5e93\u4e2d\u7b5b\u9009\u65b0\u7684\u5019\u9009PULXs\uff0c\u867d\u672a\u53d1\u73b0\u65b0\u8109\u52a8\u4f46\u63d0\u4f9b\u6837\u672c\u5e76\u5f3a\u8c03\u9ad8\u7edf\u8ba1\u89c2\u6d4b\u6570\u636e\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5728\u56e0\u4e0d\u5229\u56e0\u7d20\u672a\u663e\u793a\u8109\u52a8\u7684ULXs\u4e2d\u627e\u51fa\u5019\u9009PULXs\u3002", "method": "\u5bf9XMM - Newton\u63a2\u6d4b\u7684ULXs\u66f4\u65b0\u6570\u636e\u5e93\u5e94\u7528AI\u65b9\u6cd5\uff0c\u5148\u4f7f\u7528\u65e0\u76d1\u7763\u805a\u7c7b\u7b97\u6cd5\u5206\u7c7b\uff0c\u518d\u7528\u5df2\u77e5PULX\u89c2\u6d4b\u6837\u672c\u8bbe\u5b9a\u5206\u79bb\u9608\u503c\u3002", "result": "\u627e\u5230\u542b85\u4e2a\u72ec\u7279\u6e90\u7684\u65b0\u5019\u9009PULXs\u96c6\u7fa4\uff0c\u521d\u6b65\u5b9a\u65f6\u5206\u6790\u672a\u53d1\u73b0\u65b0\u8109\u52a8\u3002", "conclusion": "\u4f53\u73b0AI\u65b9\u6cd5\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u5f3a\u8c03\u9ad8\u7edf\u8ba1\u89c2\u6d4b\u6570\u636e\u5bf9\u63ed\u793a\u76f8\u5e72\u4fe1\u53f7\u548c\u9a8c\u8bc1\u65b9\u6cd5\u7a33\u5065\u6027\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.15061", "pdf": "https://arxiv.org/pdf/2507.15061", "abs": "https://arxiv.org/abs/2507.15061", "authors": ["Zhengwei Tao", "Jialong Wu", "Wenbiao Yin", "Junkai Zhang", "Baixuan Li", "Haiyang Shen", "Kuan Li", "Liwen Zhang", "Xinyu Wang", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "title": "WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The advent of Large Language Model (LLM)-powered agents has revolutionized\nartificial intelligence by enabling solutions to complex, open-ended tasks\nthrough web-based information-seeking (IS) capabilities. The scarcity of\nhigh-quality training data has limited the development of IS agents. Existing\napproaches typically adopt an information-driven paradigm that first collects\nweb data and then generates questions based on the retrieval. However, this may\nlead to inconsistency between information structure and reasoning structure,\nquestion and answer. To mitigate, we propose a formalization-driven IS data\nsynthesis framework WebShaper to construct a dataset. WebShaper systematically\nformalizes IS tasks through set theory. Central to the formalization is the\nconcept of Knowledge Projections (KP), which enables precise control over\nreasoning structure by KP operation compositions. During synthesis, we begin by\ncreating seed tasks, then use a multi-step expansion process. At each step, an\nagentic Expander expands the current formal question more complex with\nretrieval and validation tools based on our formalization. We train our model\non the synthesized dataset. Experiment results demonstrate that WebShaper\nachieves state-of-the-art performance among open-sourced IS agents on GAIA and\nWebWalkerQA benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faWebShaper\u6846\u67b6\u6784\u5efa\u4fe1\u606f\u68c0\u7d22\u6570\u636e\u96c6\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5f00\u6e90\u4fe1\u606f\u68c0\u7d22\u4ee3\u7406\u7684\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u9650\u5236\u4fe1\u606f\u68c0\u7d22\u4ee3\u7406\u53d1\u5c55\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u4e0e\u63a8\u7406\u7ed3\u6784\u3001\u95ee\u7b54\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5f62\u5f0f\u5316\u9a71\u52a8\u7684\u4fe1\u606f\u68c0\u7d22\u6570\u636e\u5408\u6210\u6846\u67b6WebShaper\uff0c\u7528\u96c6\u5408\u8bba\u5f62\u5f0f\u5316\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\uff0c\u5f15\u5165\u77e5\u8bc6\u6295\u5f71\u6982\u5ff5\uff0c\u901a\u8fc7\u591a\u6b65\u6269\u5c55\u8fc7\u7a0b\u521b\u5efa\u6570\u636e\u96c6\u5e76\u8bad\u7ec3\u6a21\u578b\u3002", "result": "WebShaper\u5728GAIA\u548cWebWalkerQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u5f00\u6e90\u4fe1\u606f\u68c0\u7d22\u4ee3\u7406\u7684\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "WebShaper\u6846\u67b6\u6709\u6548\u89e3\u51b3\u73b0\u6709\u4fe1\u606f\u68c0\u7d22\u4ee3\u7406\u53d1\u5c55\u7684\u95ee\u9898\uff0c\u6027\u80fd\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.15062", "pdf": "https://arxiv.org/pdf/2507.15062", "abs": "https://arxiv.org/abs/2507.15062", "authors": ["Xinyue Zhu", "Binghao Huang", "Yunzhu Li"], "title": "Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "More videos can be found on our\n  website:https://binghao-huang.github.io/touch_in_the_wild/", "summary": "Handheld grippers are increasingly used to collect human demonstrations due\nto their ease of deployment and versatility. However, most existing designs\nlack tactile sensing, despite the critical role of tactile feedback in precise\nmanipulation. We present a portable, lightweight gripper with integrated\ntactile sensors that enables synchronized collection of visual and tactile data\nin diverse, real-world, and in-the-wild settings. Building on this hardware, we\npropose a cross-modal representation learning framework that integrates visual\nand tactile signals while preserving their distinct characteristics. The\nlearning procedure allows the emergence of interpretable representations that\nconsistently focus on contacting regions relevant for physical interactions.\nWhen used for downstream manipulation tasks, these representations enable more\nefficient and effective policy learning, supporting precise robotic\nmanipulation based on multimodal feedback. We validate our approach on\nfine-grained tasks such as test tube insertion and pipette-based fluid\ntransfer, demonstrating improved accuracy and robustness under external\ndisturbances. Our project page is available at\nhttps://binghao-huang.github.io/touch_in_the_wild/ .", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5e26\u96c6\u6210\u89e6\u89c9\u4f20\u611f\u5668\u7684\u4fbf\u643a\u5f0f\u8f7b\u91cf\u7ea7\u6293\u722a\uff0c\u63d0\u51fa\u8de8\u6a21\u6001\u8868\u5f81\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u7ec6\u7c92\u5ea6\u4efb\u52a1\u9a8c\u8bc1\u4e2d\u5c55\u73b0\u51fa\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u624b\u6301\u6293\u722a\u5927\u591a\u7f3a\u4e4f\u89e6\u89c9\u4f20\u611f\uff0c\u800c\u89e6\u89c9\u53cd\u9988\u5bf9\u7cbe\u786e\u64cd\u4f5c\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u80fd\u540c\u6b65\u6536\u96c6\u89c6\u89c9\u548c\u89e6\u89c9\u6570\u636e\u7684\u6293\u722a\u53ca\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u5e26\u96c6\u6210\u89e6\u89c9\u4f20\u611f\u5668\u7684\u6293\u722a\uff0c\u63d0\u51fa\u6574\u5408\u89c6\u89c9\u548c\u89e6\u89c9\u4fe1\u53f7\u7684\u8de8\u6a21\u6001\u8868\u5f81\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u5b66\u4e60\u8fc7\u7a0b\u4ea7\u751f\u805a\u7126\u7269\u7406\u4ea4\u4e92\u63a5\u89e6\u533a\u57df\u7684\u53ef\u89e3\u91ca\u8868\u5f81\uff0c\u5728\u4e0b\u6e38\u64cd\u4f5c\u4efb\u52a1\u4e2d\u4f7f\u7b56\u7565\u5b66\u4e60\u66f4\u9ad8\u6548\uff0c\u5728\u7ec6\u7c92\u5ea6\u4efb\u52a1\u9a8c\u8bc1\u4e2d\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u51c6\u786e\u6027\u548c\u6297\u5e72\u6270\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6293\u722a\u548c\u5b66\u4e60\u6846\u67b6\u80fd\u57fa\u4e8e\u591a\u6a21\u6001\u53cd\u9988\u652f\u6301\u7cbe\u786e\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u3002"}}
{"id": "2507.15064", "pdf": "https://arxiv.org/pdf/2507.15064", "abs": "https://arxiv.org/abs/2507.15064", "authors": ["Shuyuan Tu", "Zhen Xing", "Xintong Han", "Zhi-Qi Cheng", "Qi Dai", "Chong Luo", "Zuxuan Wu", "Yu-Gang Jiang"], "title": "StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation", "categories": ["cs.CV", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2411.17697", "summary": "Current diffusion models for human image animation often struggle to maintain\nidentity (ID) consistency, especially when the reference image and driving\nvideo differ significantly in body size or position. We introduce\nStableAnimator++, the first ID-preserving video diffusion framework with\nlearnable pose alignment, capable of generating high-quality videos conditioned\non a reference image and a pose sequence without any post-processing. Building\nupon a video diffusion model, StableAnimator++ contains carefully designed\nmodules for both training and inference, striving for identity consistency. In\nparticular, StableAnimator++ first uses learnable layers to predict the\nsimilarity transformation matrices between the reference image and the driven\nposes via injecting guidance from Singular Value Decomposition (SVD). These\nmatrices align the driven poses with the reference image, mitigating\nmisalignment to a great extent. StableAnimator++ then computes image and face\nembeddings using off-the-shelf encoders, refining the face embeddings via a\nglobal content-aware Face Encoder. To further maintain ID, we introduce a\ndistribution-aware ID Adapter that counteracts interference caused by temporal\nlayers while preserving ID via distribution alignment. During the inference\nstage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization\nintegrated into the denoising process, guiding the diffusion trajectory for\nenhanced facial fidelity. Experiments on benchmarks show the effectiveness of\nStableAnimator++ both qualitatively and quantitatively.", "AI": {"tldr": "\u63d0\u51faStableAnimator++\uff0c\u53ef\u5728\u65e0\u540e\u5904\u7406\u4e0b\u57fa\u4e8e\u53c2\u8003\u56fe\u50cf\u548c\u59ff\u52bf\u5e8f\u5217\u751f\u6210\u9ad8\u8d28\u91cf\u89c6\u9891\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6548\u679c\u826f\u597d\u3002", "motivation": "\u5f53\u524d\u4eba\u7c7b\u56fe\u50cf\u52a8\u753b\u6269\u6563\u6a21\u578b\u96be\u4ee5\u5728\u53c2\u8003\u56fe\u50cf\u548c\u9a71\u52a8\u89c6\u9891\u8eab\u4f53\u5927\u5c0f\u6216\u4f4d\u7f6e\u5dee\u5f02\u5927\u65f6\u4fdd\u6301\u8eab\u4efd\u4e00\u81f4\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b\u8bad\u7ec3\u548c\u63a8\u7406\u6a21\u5757\u7684\u89c6\u9891\u6269\u6563\u6846\u67b6\uff0c\u7528\u53ef\u5b66\u4e60\u5c42\u7ed3\u5408SVD\u9884\u6d4b\u76f8\u4f3c\u53d8\u6362\u77e9\u9635\uff0c\u7528\u73b0\u6210\u7f16\u7801\u5668\u8ba1\u7b97\u56fe\u50cf\u548c\u9762\u90e8\u5d4c\u5165\uff0c\u5f15\u5165\u5206\u5e03\u611f\u77e5ID\u9002\u914d\u5668\uff0c\u63a8\u7406\u9636\u6bb5\u63d0\u51fa\u57fa\u4e8eHJB\u7684\u9762\u90e8\u4f18\u5316\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9a\u6027\u548c\u5b9a\u91cf\u5730\u8bc1\u660e\u4e86StableAnimator++\u7684\u6709\u6548\u6027\u3002", "conclusion": "StableAnimator++\u80fd\u6709\u6548\u89e3\u51b3\u4eba\u7c7b\u56fe\u50cf\u52a8\u753b\u6269\u6563\u6a21\u578b\u4e2d\u8eab\u4efd\u4e00\u81f4\u6027\u95ee\u9898\u3002"}}
{"id": "2507.15072", "pdf": "https://arxiv.org/pdf/2507.15072", "abs": "https://arxiv.org/abs/2507.15072", "authors": ["Maisha Maimuna", "Minhaz Bin Farukee", "Sama Nikanfar", "Mahfuza Siddiqua", "Ayon Roy", "Fillia Makedon"], "title": "NavVI: A Telerobotic Simulation with Multimodal Feedback for Visually Impaired Navigation in Warehouse Environments", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Industrial warehouses are congested with moving forklifts, shelves and\npersonnel, making robot teleoperation particularly risky and demanding for\nblind and low-vision (BLV) operators. Although accessible teleoperation plays a\nkey role in inclusive workforce participation, systematic research on its use\nin industrial environments is limited, and few existing studies barely address\nmultimodal guidance designed for BLV users. We present a novel multimodal\nguidance simulator that enables BLV users to control a mobile robot through a\nhigh-fidelity warehouse environment while simultaneously receiving synchronized\nvisual, auditory, and haptic feedback. The system combines a navigation mesh\nwith regular re-planning so routes remain accurate avoiding collisions as\nforklifts and human avatars move around the warehouse. Users with low vision\nare guided with a visible path line towards destination; navigational voice\ncues with clockwise directions announce upcoming turns, and finally\nproximity-based haptic feedback notifies the users of static and moving\nobstacles in the path. This real-time, closed-loop system offers a repeatable\ntestbed and algorithmic reference for accessible teleoperation research. The\nsimulator's design principles can be easily adapted to real robots due to the\nalignment of its navigation, speech, and haptic modules with commercial\nhardware, supporting rapid feasibility studies and deployment of inclusive\ntelerobotic tools in actual warehouses.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u591a\u6a21\u6001\u5f15\u5bfc\u6a21\u62df\u5668\uff0c\u53ef\u8ba9\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7528\u6237\u5728\u9ad8\u4fdd\u771f\u4ed3\u5e93\u73af\u5883\u4e2d\u63a7\u5236\u79fb\u52a8\u673a\u5668\u4eba\uff0c\u4e3a\u65e0\u969c\u788d\u8fdc\u7a0b\u64cd\u4f5c\u7814\u7a76\u63d0\u4f9b\u6d4b\u8bd5\u5e73\u53f0\u548c\u7b97\u6cd5\u53c2\u8003\uff0c\u8bbe\u8ba1\u539f\u5219\u6613\u9002\u914d\u771f\u5b9e\u673a\u5668\u4eba\u3002", "motivation": "\u5de5\u4e1a\u4ed3\u5e93\u73af\u5883\u4f7f\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7528\u6237\u8fdc\u7a0b\u64cd\u4f5c\u673a\u5668\u4eba\u98ce\u9669\u5927\u4e14\u9700\u6c42\u9ad8\uff0c\u73b0\u6709\u65e0\u969c\u788d\u8fdc\u7a0b\u64cd\u4f5c\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u7cfb\u7edf\u7814\u7a76\u6709\u9650\uff0c\u9488\u5bf9\u6b64\u7c7b\u7528\u6237\u7684\u591a\u6a21\u6001\u5f15\u5bfc\u7814\u7a76\u5c11\u3002", "method": "\u7ed3\u5408\u5bfc\u822a\u7f51\u683c\u548c\u5b9a\u671f\u91cd\u65b0\u89c4\u5212\u8def\u7ebf\uff0c\u4e3a\u4f4e\u89c6\u529b\u7528\u6237\u63d0\u4f9b\u53ef\u89c1\u8def\u5f84\u7ebf\u3001\u5bfc\u822a\u8bed\u97f3\u63d0\u793a\u548c\u57fa\u4e8e\u63a5\u8fd1\u5ea6\u7684\u89e6\u89c9\u53cd\u9988\u3002", "result": "\u5f00\u53d1\u51fa\u5b9e\u65f6\u95ed\u73af\u7cfb\u7edf\uff0c\u63d0\u4f9b\u53ef\u91cd\u590d\u7684\u6d4b\u8bd5\u5e73\u53f0\u548c\u7b97\u6cd5\u53c2\u8003\u3002", "conclusion": "\u6a21\u62df\u5668\u8bbe\u8ba1\u539f\u5219\u6613\u9002\u914d\u771f\u5b9e\u673a\u5668\u4eba\uff0c\u652f\u6301\u5728\u5b9e\u9645\u4ed3\u5e93\u4e2d\u5f00\u5c55\u53ef\u884c\u6027\u7814\u7a76\u548c\u90e8\u7f72\u5305\u5bb9\u6027\u8fdc\u7a0b\u673a\u5668\u4eba\u5de5\u5177\u3002"}}
{"id": "2507.14997", "pdf": "https://arxiv.org/pdf/2507.14997", "abs": "https://arxiv.org/abs/2507.14997", "authors": ["Roy H. Jennings", "Genady Paikin", "Roy Shaul", "Evgeny Soloveichik"], "title": "Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) show promise for image-based\nregression tasks, but current approaches face key limitations. Recent methods\nfine-tune MLLMs using preset output vocabularies and generic task-level prompts\n(e.g., \"How would you rate this image?\"), assuming this mimics human rating\nbehavior. Our analysis reveals these approaches provide no benefit over\nimage-only training. Models using preset vocabularies and generic prompts\nperform equivalently to image-only models, failing to leverage semantic\nunderstanding from textual input. We propose Regression via Transformer-Based\nClassification (RvTC), which replaces vocabulary-constrained classification\nwith a flexible bin-based approach. Unlike approaches that address\ndiscretization errors through complex distributional modeling, RvTC eliminates\nmanual vocabulary crafting through straightforward bin increase, achieving\nstate-of-the-art performance on four image assessment datasets using only\nimages. More importantly, we demonstrate that data-specific prompts\ndramatically improve performance. Unlike generic task descriptions, prompts\ncontaining semantic information about specific images enable MLLMs to leverage\ncross-modal understanding. On the AVA dataset, adding challenge titles to\nprompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We\ndemonstrate through empirical evidence from the AVA and AGIQA-3k datasets that\nMLLMs benefit from semantic prompt information surpassing mere statistical\nbiases. This underscores the importance of incorporating meaningful textual\ncontext in multimodal regression tasks.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u9884\u8bbe\u8bcd\u6c47\u8868\u548c\u901a\u7528\u63d0\u793a\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u56fe\u50cf\u56de\u5f52\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u63d0\u51faRvTC\u65b9\u6cd5\u5e76\u8bc1\u660e\u7279\u5b9a\u6570\u636e\u63d0\u793a\u53ef\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u50cf\u56de\u5f52\u4efb\u52a1\u4e2d\u9762\u4e34\u7684\u5173\u952e\u5c40\u9650\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51faRegression via Transformer-Based Classification (RvTC)\u65b9\u6cd5\uff0c\u7528\u7075\u6d3b\u7684\u57fa\u4e8e\u5206\u7bb1\u7684\u65b9\u6cd5\u66ff\u4ee3\u8bcd\u6c47\u53d7\u9650\u7684\u5206\u7c7b\uff1b\u4f7f\u7528\u5305\u542b\u7279\u5b9a\u56fe\u50cf\u8bed\u4e49\u4fe1\u606f\u7684\u6570\u636e\u7279\u5b9a\u63d0\u793a\u3002", "result": "RvTC\u5728\u56db\u4e2a\u56fe\u50cf\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u4ec5\u7528\u56fe\u50cf\u5c31\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff1b\u5728AVA\u6570\u636e\u96c6\u4e0a\uff0c\u6dfb\u52a0\u6311\u6218\u6807\u9898\u5230\u63d0\u793a\u4f7f\u76f8\u5173\u6027\u4ece0.83\u63d0\u9ad8\u52300.90\u3002", "conclusion": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u4ece\u8bed\u4e49\u63d0\u793a\u4fe1\u606f\u4e2d\u53d7\u76ca\uff0c\u5728\u591a\u6a21\u6001\u56de\u5f52\u4efb\u52a1\u4e2d\u7eb3\u5165\u6709\u610f\u4e49\u7684\u6587\u672c\u4e0a\u4e0b\u6587\u5f88\u91cd\u8981\u3002"}}
{"id": "2507.15087", "pdf": "https://arxiv.org/pdf/2507.15087", "abs": "https://arxiv.org/abs/2507.15087", "authors": ["Chenlei Gong", "Yuanhe Tian", "Lei Mao", "Yan Song"], "title": "Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Currently, many studies view DNA sequences as a special type of language and\nutilize Transformers to model them. These studies use fixed-length k-mer\nsegmentation and BPE subword tokenization but lack a systematic evaluation to\ndetermine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a\n4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal,\nAliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and\n24-layer Transformer encoders and evaluated on GUE benchmark dataset. In\ngeneral, BPE delivers higher and more stable performance across tasks by\ncompressing frequent motifs into variable-length tokens, reducing sequence\nlength, and improving model generalization. RoPE excels at capturing periodic\nmotifs and extrapolating to long sequences, while AliBi also performs well on\ntasks driven by local dependencies. In terms of depth, we observe significant\ngains when increasing layers from 3 to 12, with only marginal improvements or\nslight overfitting at 24 layers. This study provides practical guidance for\ndesigning tokenization and positional encoding in DNA Transformer models.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e0d\u540ck - mer\u5206\u5272\u3001BPE\u5206\u8bcd\u53ca\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5728DNA Transformer\u6a21\u578b\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7528Transformer\u5bf9DNA\u5e8f\u5217\u5efa\u6a21\u65f6\uff0c\u7f3a\u4e4f\u5bf9\u56fa\u5b9a\u957f\u5ea6k - mer\u5206\u5272\u548cBPE\u5b50\u8bcd\u5206\u8bcd\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u6bd4\u8f83\u4e0d\u540ck\u503c\u7684k - mer\u5206\u5272\u30014096\u8bcd\u5143\u7684BPE\u8bcd\u6c47\u8868\u548c\u4e09\u79cd\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u5c42\u6570\u7684Transformer\u7f16\u7801\u5668\u4e2d\u4ece\u5934\u8bad\u7ec3\u5e76\u5728GUE\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u3002", "result": "BPE\u8868\u73b0\u66f4\u9ad8\u4e14\u66f4\u7a33\u5b9a\uff1bRoPE\u64c5\u957f\u6355\u6349\u5468\u671f\u6027\u57fa\u5e8f\uff0cAliBi\u5728\u5c40\u90e8\u4f9d\u8d56\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff1b\u5c42\u6570\u4ece3\u589e\u52a0\u523012\u6709\u663e\u8457\u63d0\u5347\uff0c24\u5c42\u65f6\u63d0\u5347\u5fae\u5f31\u6216\u6709\u8fc7\u62df\u5408\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aDNA Transformer\u6a21\u578b\u7684\u5206\u8bcd\u548c\u4f4d\u7f6e\u7f16\u7801\u8bbe\u8ba1\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2507.15021", "pdf": "https://arxiv.org/pdf/2507.15021", "abs": "https://arxiv.org/abs/2507.15021", "authors": ["Soheil Radfar", "Faezeh Maghsoodifar", "Hamed Moftakhari", "Hamid Moradkhani"], "title": "Integrating Newton's Laws with deep learning for enhanced physics-informed compound flood modelling", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "Coastal communities increasingly face compound floods, where multiple drivers\nlike storm surge, high tide, heavy rainfall, and river discharge occur together\nor in sequence to produce impacts far greater than any single driver alone.\nTraditional hydrodynamic models can provide accurate physics-based simulations\nbut require substantial computational resources for real-time applications or\nrisk assessments, while machine learning alternatives often sacrifice physical\nconsistency for speed, producing unrealistic predictions during extreme events.\nThis study addresses these challenges by developing ALPINE (All-in-one Physics\nInformed Neural Emulator), a physics-informed neural network (PINN) framework\nto enforce complete shallow water dynamics in compound flood modeling. Unlike\nprevious approaches that implement partial constraints, our framework\nsimultaneously enforces mass conservation and both momentum equations, ensuring\nfull adherence to Newton's laws throughout the prediction process. The model\nintegrates a convolutional encoder-decoder architecture with ConvLSTM temporal\nprocessing, trained using a composite loss function that balances data fidelity\nwith physics-based residuals. Using six historical storm events (four for\ntraining, one for validation, and one held-out for unseen testing), we observe\nsubstantial improvements over baseline neural networks. ALPINE reduces\ndomain-averaged prediction errors and improves model skill metrics for water\nsurface elevation and velocity components. Physics-informed constraints prove\nmost valuable during peak storm intensity, when multiple flood drivers interact\nand reliable predictions matter most. This approach yields a physically\nconsistent emulator capable of supporting compound-flood forecasting and\nlarge-scale risk analyses while preserving physical realism essential for\ncoastal emergency management.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u6846\u67b6ALPINE\u7528\u4e8e\u590d\u5408\u6d2a\u6c34\u5efa\u6a21\uff0c\u76f8\u6bd4\u57fa\u7ebf\u795e\u7ecf\u7f51\u7edc\u6709\u663e\u8457\u6539\u8fdb\uff0c\u80fd\u652f\u6301\u6d2a\u6c34\u9884\u6d4b\u548c\u98ce\u9669\u5206\u6790\u3002", "motivation": "\u4f20\u7edf\u6c34\u52a8\u529b\u6a21\u578b\u5b9e\u65f6\u5e94\u7528\u6216\u98ce\u9669\u8bc4\u4f30\u9700\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u727a\u7272\u7269\u7406\u4e00\u81f4\u6027\uff0c\u8981\u89e3\u51b3\u590d\u5408\u6d2a\u6c34\u5efa\u6a21\u96be\u9898\u3002", "method": "\u5f00\u53d1ALPINE\u6846\u67b6\uff0c\u540c\u65f6\u6267\u884c\u8d28\u91cf\u5b88\u6052\u548c\u52a8\u91cf\u65b9\u7a0b\uff0c\u96c6\u6210\u5377\u79ef\u7f16\u89e3\u7801\u5668\u67b6\u6784\u4e0eConvLSTM\u65f6\u95f4\u5904\u7406\uff0c\u7528\u590d\u5408\u635f\u5931\u51fd\u6570\u8bad\u7ec3\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebf\u795e\u7ecf\u7f51\u7edc\uff0cALPINE\u51cf\u5c11\u4e86\u533a\u57df\u5e73\u5747\u9884\u6d4b\u8bef\u5dee\uff0c\u6539\u5584\u4e86\u6c34\u4f4d\u548c\u6d41\u901f\u7684\u6a21\u578b\u6280\u80fd\u6307\u6807\uff0c\u7269\u7406\u4fe1\u606f\u7ea6\u675f\u5728\u98ce\u66b4\u9ad8\u5cf0\u671f\u6700\u6709\u4ef7\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5f97\u5230\u7269\u7406\u4e00\u81f4\u7684\u6a21\u62df\u5668\uff0c\u80fd\u652f\u6301\u590d\u5408\u6d2a\u6c34\u9884\u6d4b\u548c\u5927\u89c4\u6a21\u98ce\u9669\u5206\u6790\uff0c\u5bf9\u6cbf\u6d77\u5e94\u6025\u7ba1\u7406\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.15094", "pdf": "https://arxiv.org/pdf/2507.15094", "abs": "https://arxiv.org/abs/2507.15094", "authors": ["Mengya Xu", "Rulin Zhou", "An Wang", "Chaoyang Lyu", "Zhen Li", "Ning Zhong", "Hongliang Ren"], "title": "BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 14 figures", "summary": "Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses\nsignificant risks, demanding precise, real-time localization and continuous\nmonitoring of the bleeding source for effective hemostatic intervention. In\nparticular, endoscopists have to repeatedly flush to clear blood, allowing only\nmilliseconds to identify bleeding sources, an inefficient process that prolongs\noperations and elevates patient risks. However, current Artificial Intelligence\n(AI) methods primarily focus on bleeding region segmentation, overlooking the\ncritical need for accurate bleeding source detection and temporal tracking in\nthe challenging ESD environment, which is marked by frequent visual\nobstructions and dynamic scene changes. This gap is widened by the lack of\nspecialized datasets, hindering the development of robust AI-assisted guidance\nsystems. To address these challenges, we introduce BleedOrigin-Bench, the first\ncomprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated\nbleeding sources across 106,222 frames from 44 procedures, supplemented with\n39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6\nchallenging clinical scenarios. We also present BleedOrigin-Net, a novel\ndual-stage detection-tracking framework for the bleeding source localization in\nESD procedures, addressing the complete workflow from bleeding onset detection\nto continuous spatial tracking. We compare with widely-used object detection\nmodels (YOLOv11/v12), multimodal large language models, and point tracking\nmethods. Extensive evaluation demonstrates state-of-the-art performance,\nachieving 96.85% frame-level accuracy ($\\pm\\leq8$ frames) for bleeding onset\ndetection, 70.24% pixel-level accuracy ($\\leq100$ px) for initial source\ndetection, and 96.11% pixel-level accuracy ($\\leq100$ px) for point tracking.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u9996\u4e2aESD\u51fa\u8840\u6e90\u6570\u636e\u96c6BleedOrigin - Bench\u548c\u68c0\u6d4b\u8ddf\u8e2a\u6846\u67b6BleedOrigin - Net\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u8fbe\u5230\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "ESD\u672f\u4e2d\u51fa\u8840\u9700\u7cbe\u51c6\u5b9e\u65f6\u5b9a\u4f4d\u548c\u6301\u7eed\u76d1\u6d4b\u51fa\u8840\u6e90\uff0c\u4f46\u73b0\u6709AI\u65b9\u6cd5\u91cd\u533a\u57df\u5206\u5272\uff0c\u8f7b\u51fa\u8840\u6e90\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\uff0c\u4e14\u7f3a\u4e4f\u4e13\u4e1a\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165\u542b\u4e13\u5bb6\u6807\u6ce8\u548c\u4f2a\u6807\u7b7e\u5e27\u7684BleedOrigin - Bench\u6570\u636e\u96c6\uff0c\u63d0\u51faBleedOrigin - Net\u6846\u67b6\uff0c\u5e76\u4e0e\u5e38\u7528\u6a21\u578b\u5bf9\u6bd4\u3002", "result": "\u5b9e\u73b0\u51fa\u8840\u8d77\u59cb\u68c0\u6d4b\u5e27\u7ea7\u51c6\u786e\u738796.85%\uff08\u00b1\u22648\u5e27\uff09\uff0c\u521d\u59cb\u6e90\u68c0\u6d4b\u50cf\u7d20\u7ea7\u51c6\u786e\u738770.24%\uff08\u2264100 px\uff09\uff0c\u70b9\u8ddf\u8e2a\u50cf\u7d20\u7ea7\u51c6\u786e\u738796.11%\uff08\u2264100 px\uff09\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u96c6\u548c\u6846\u67b6\u5728ESD\u51fa\u8840\u6e90\u5b9a\u4f4d\u548c\u8ddf\u8e2a\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u826f\u597d\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.15100", "pdf": "https://arxiv.org/pdf/2507.15100", "abs": "https://arxiv.org/abs/2507.15100", "authors": ["Chathuri Jayaweera", "Brianna Yanqui", "Bonnie Dorr"], "title": "Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 8 figures and 5 tables", "summary": "Natural Language Inference (NLI) is the task of determining the semantic\nentailment of a premise for a given hypothesis. The task aims to develop\nsystems that emulate natural human inferential processes where commonsense\nknowledge plays a major role. However, existing commonsense resources lack\nsufficient coverage for a variety of premise-hypothesis pairs. This study\nexplores the potential of Large Language Models as commonsense knowledge\ngenerators for NLI along two key dimensions: their reliability in generating\nsuch knowledge and the impact of that knowledge on prediction accuracy. We\nadapt and modify existing metrics to assess LLM factuality and consistency in\ngenerating in this context. While explicitly incorporating commonsense\nknowledge does not consistently improve overall results, it effectively helps\ndistinguish entailing instances and moderately improves distinguishing\ncontradictory and neutral inferences.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u5e38\u8bc6\u77e5\u8bc6\u751f\u6210\u5668\u7684\u6f5c\u529b\uff0c\u53d1\u73b0\u663e\u5f0f\u7eb3\u5165\u5e38\u8bc6\u77e5\u8bc6\u867d\u4e0d\u80fd\u7a33\u5b9a\u63d0\u5347\u6574\u4f53\u7ed3\u679c\uff0c\u4f46\u6709\u52a9\u4e8e\u533a\u5206\u4e0d\u540c\u63a8\u7406\u60c5\u51b5\u3002", "motivation": "\u73b0\u6709\u5e38\u8bc6\u8d44\u6e90\u5bf9\u591a\u79cd\u524d\u63d0 - \u5047\u8bbe\u5bf9\u7684\u8986\u76d6\u4e0d\u8db3\uff0c\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3aNLI\u5e38\u8bc6\u77e5\u8bc6\u751f\u6210\u5668\u7684\u6f5c\u529b\u3002", "method": "\u8c03\u6574\u548c\u4fee\u6539\u73b0\u6709\u6307\u6807\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u5e38\u8bc6\u77e5\u8bc6\u65f6\u7684\u4e8b\u5b9e\u6027\u548c\u4e00\u81f4\u6027\u3002", "result": "\u663e\u5f0f\u7eb3\u5165\u5e38\u8bc6\u77e5\u8bc6\u4e0d\u80fd\u7a33\u5b9a\u63d0\u5347\u6574\u4f53\u7ed3\u679c\uff0c\u4f46\u80fd\u6709\u6548\u533a\u5206\u8574\u542b\u5b9e\u4f8b\uff0c\u9002\u5ea6\u63d0\u5347\u5bf9\u77db\u76fe\u548c\u4e2d\u6027\u63a8\u7406\u7684\u533a\u5206\u80fd\u529b\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3aNLI\u5e38\u8bc6\u77e5\u8bc6\u751f\u6210\u5668\u6709\u4e00\u5b9a\u4f5c\u7528\uff0c\u4f46\u5728\u63d0\u5347\u6574\u4f53\u6027\u80fd\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002"}}
{"id": "2507.15035", "pdf": "https://arxiv.org/pdf/2507.15035", "abs": "https://arxiv.org/abs/2507.15035", "authors": ["Zhijun Zeng", "Youjia Zheng", "Hao Hu", "Zeyuan Dong", "Yihang Zheng", "Xinliang Liu", "Jinzhuo Wang", "Zuoqiang Shi", "Linfeng Zhang", "Yubing Li", "He Sun"], "title": "OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography", "categories": ["cs.CV", "cs.LG", "35Q92, 68U10", "I.4.5; J.2; J.3"], "comment": null, "summary": "Accurate and efficient simulation of wave equations is crucial in\ncomputational wave imaging applications, such as ultrasound computed tomography\n(USCT), which reconstructs tissue material properties from observed scattered\nwaves. Traditional numerical solvers for wave equations are computationally\nintensive and often unstable, limiting their practical applications for\nquasi-real-time image reconstruction. Neural operators offer an innovative\napproach by accelerating PDE solving using neural networks; however, their\neffectiveness in realistic imaging is limited because existing datasets\noversimplify real-world complexity. In this paper, we present OpenBreastUS, a\nlarge-scale wave equation dataset designed to bridge the gap between\ntheoretical equations and practical imaging applications. OpenBreastUS includes\n8,000 anatomically realistic human breast phantoms and over 16 million\nfrequency-domain wave simulations using real USCT configurations. It enables a\ncomprehensive benchmarking of popular neural operators for both forward\nsimulation and inverse imaging tasks, allowing analysis of their performance,\nscalability, and generalization capabilities. By offering a realistic and\nextensive dataset, OpenBreastUS not only serves as a platform for developing\ninnovative neural PDE solvers but also facilitates their deployment in\nreal-world medical imaging problems. For the first time, we demonstrate\nefficient in vivo imaging of the human breast using neural operator solvers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOpenBreastUS\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6ce2\u65b9\u7a0b\u6a21\u62df\u548c\u6210\u50cf\uff0c\u53ef\u5bf9\u795e\u7ecf\u7b97\u5b50\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd8\u5b9e\u73b0\u4eba\u4f53\u4e73\u623f\u4f53\u5185\u6210\u50cf\u3002", "motivation": "\u4f20\u7edf\u6ce2\u65b9\u7a0b\u6570\u503c\u6c42\u89e3\u5668\u8ba1\u7b97\u5bc6\u96c6\u4e14\u4e0d\u7a33\u5b9a\uff0c\u73b0\u6709\u795e\u7ecf\u7b97\u5b50\u56e0\u6570\u636e\u96c6\u8fc7\u4e8e\u7b80\u5316\u9650\u5236\u5176\u5b9e\u7528\u6027\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u8fde\u63a5\u7406\u8bba\u4e0e\u5b9e\u9645\u6210\u50cf\u5e94\u7528\u7684\u6570\u636e\u96c6\u3002", "method": "\u6784\u5efa\u5305\u542b8000\u4e2a\u89e3\u5256\u5b66\u4e0a\u903c\u771f\u7684\u4eba\u4f53\u4e73\u623f\u6a21\u578b\u548c\u8d851600\u4e07\u6b21\u9891\u57df\u6ce2\u6a21\u62df\u7684OpenBreastUS\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u6d41\u884c\u795e\u7ecf\u7b97\u5b50\u7684\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5206\u6790\u5176\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u9996\u6b21\u7528\u795e\u7ecf\u7b97\u5b50\u6c42\u89e3\u5668\u5b9e\u73b0\u4eba\u4f53\u4e73\u623f\u9ad8\u6548\u4f53\u5185\u6210\u50cf\u3002", "conclusion": "OpenBreastUS\u6570\u636e\u96c6\u4e3a\u5f00\u53d1\u521b\u65b0\u795e\u7ecfPDE\u6c42\u89e3\u5668\u63d0\u4f9b\u5e73\u53f0\uff0c\u63a8\u52a8\u5176\u5728\u73b0\u5b9e\u533b\u5b66\u6210\u50cf\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.15142", "pdf": "https://arxiv.org/pdf/2507.15142", "abs": "https://arxiv.org/abs/2507.15142", "authors": ["Hellina Hailu Nigatu", "Atnafu Lambebo Tonja", "Henok Biadglign Ademtew", "Hizkel Mitiku Alemayehu", "Negasi Haile Abadi", "Tadesse Destaw Belay", "Seid Muhie Yimam"], "title": "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script", "categories": ["cs.CL", "cs.AI"], "comment": "Paper under review", "summary": "Homophone normalization, where characters that have the same sound in a\nwriting script are mapped to one character, is a pre-processing step applied in\nAmharic Natural Language Processing (NLP) literature. While this may improve\nperformance reported by automatic metrics, it also results in models that are\nnot able to understand different forms of writing in a single language.\nFurther, there might be impacts in transfer learning, where models trained on\nnormalized data do not generalize well to other languages. In this paper, we\nexperiment with monolingual training and cross-lingual transfer to understand\nthe impacts of normalization on languages that use the Ge'ez script. We then\npropose a post-inference intervention in which normalization is applied to\nmodel predictions instead of training data. With our simple scheme of\npost-inference normalization, we show that we can achieve an increase in BLEU\nscore of up to 1.03 while preserving language features in training. Our work\ncontributes to the broader discussion on technology-facilitated language change\nand calls for more language-aware interventions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u963f\u59c6\u54c8\u62c9\u8bed\u540c\u97f3\u5f52\u4e00\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u63a8\u7406\u540e\u5f52\u4e00\u5316\u65b9\u6848\u63d0\u5347BLEU\u5206\u6570\u5e76\u4fdd\u7559\u8bed\u8a00\u7279\u5f81\u3002", "motivation": "\u540c\u97f3\u5f52\u4e00\u5316\u867d\u63d0\u5347\u81ea\u52a8\u6307\u6807\u6027\u80fd\uff0c\u4f46\u4f7f\u6a21\u578b\u65e0\u6cd5\u7406\u89e3\u540c\u4e00\u8bed\u8a00\u4e0d\u540c\u4e66\u5199\u5f62\u5f0f\uff0c\u4e14\u5f71\u54cd\u8fc1\u79fb\u5b66\u4e60\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u7814\u7a76\u5176\u5bf9\u4f7f\u7528Ge'ez\u6587\u5b57\u8bed\u8a00\u7684\u5f71\u54cd\u3002", "method": "\u8fdb\u884c\u5355\u8bed\u8bad\u7ec3\u548c\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b9e\u9a8c\uff0c\u63d0\u51fa\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u800c\u975e\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\u7684\u63a8\u7406\u540e\u5e72\u9884\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u7b80\u5355\u7684\u63a8\u7406\u540e\u5f52\u4e00\u5316\u65b9\u6848\uff0cBLEU\u5206\u6570\u6700\u591a\u63d0\u9ad81.03\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u8bad\u7ec3\u4e2d\u7684\u8bed\u8a00\u7279\u5f81\u3002", "conclusion": "\u7814\u7a76\u6709\u52a9\u4e8e\u6280\u672f\u63a8\u52a8\u8bed\u8a00\u53d8\u5316\u7684\u5e7f\u6cdb\u8ba8\u8bba\uff0c\u547c\u5401\u66f4\u591a\u8003\u8651\u8bed\u8a00\u7279\u6027\u7684\u5e72\u9884\u63aa\u65bd\u3002"}}
{"id": "2507.15063", "pdf": "https://arxiv.org/pdf/2507.15063", "abs": "https://arxiv.org/abs/2507.15063", "authors": ["Chloe Pomeroy", "Aleksandar Pramov", "Karishma Thakrar", "Lakshmi Yendapalli"], "title": "Quantum Annealing for Machine Learning: Applications in Feature Selection, Instance Selection, and Clustering", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": null, "summary": "This paper explores the applications of quantum annealing (QA) and classical\nsimulated annealing (SA) to a suite of combinatorial optimization problems in\nmachine learning, namely feature selection, instance selection, and clustering.\nWe formulate each task as a Quadratic Unconstrained Binary Optimization (QUBO)\nproblem and implement both quantum and classical solvers to compare their\neffectiveness. For feature selection, we propose several QUBO configurations\nthat balance feature importance and redundancy, showing that quantum annealing\n(QA) produces solutions that are computationally more efficient. In instance\nselection, we propose a few novel heuristics for instance-level importance\nmeasures that extend existing methods. For clustering, we embed a\nclassical-to-quantum pipeline, using classical clustering followed by\nQUBO-based medoid refinement, and demonstrate consistent improvements in\ncluster compactness and retrieval metrics. Our results suggest that QA can be a\ncompetitive and efficient tool for discrete machine learning optimization, even\nwithin the constraints of current quantum hardware.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u91cf\u5b50\u9000\u706b\uff08QA\uff09\u548c\u7ecf\u5178\u6a21\u62df\u9000\u706b\uff08SA\uff09\u5728\u673a\u5668\u5b66\u4e60\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u5bf9\u6bd4\u4e24\u79cd\u6c42\u89e3\u5668\u6548\u679c\uff0c\u7ed3\u679c\u8868\u660eQA\u5728\u79bb\u6563\u673a\u5668\u5b66\u4e60\u4f18\u5316\u4e2d\u662f\u6709\u7ade\u4e89\u529b\u548c\u9ad8\u6548\u7684\u5de5\u5177\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u9000\u706b\uff08QA\uff09\u548c\u7ecf\u5178\u6a21\u62df\u9000\u706b\uff08SA\uff09\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff08\u7279\u5f81\u9009\u62e9\u3001\u5b9e\u4f8b\u9009\u62e9\u548c\u805a\u7c7b\uff09\u7684\u5e94\u7528\u3002", "method": "\u5c06\u6bcf\u4e2a\u4efb\u52a1\u8868\u8ff0\u4e3a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\uff08QUBO\uff09\u95ee\u9898\uff0c\u5b9e\u73b0\u91cf\u5b50\u548c\u7ecf\u5178\u6c42\u89e3\u5668\uff1b\u9488\u5bf9\u7279\u5f81\u9009\u62e9\u63d0\u51faQUBO\u914d\u7f6e\uff1b\u5b9e\u4f8b\u9009\u62e9\u63d0\u51fa\u65b0\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1b\u805a\u7c7b\u5d4c\u5165\u7ecf\u5178\u5230\u91cf\u5b50\u7684\u6d41\u7a0b\u3002", "result": "\u7279\u5f81\u9009\u62e9\u4e2dQA\u8ba1\u7b97\u66f4\u9ad8\u6548\uff1b\u5b9e\u4f8b\u9009\u62e9\u63d0\u51fa\u65b0\u65b9\u6cd5\uff1b\u805a\u7c7b\u5728\u7d27\u51d1\u6027\u548c\u68c0\u7d22\u6307\u6807\u4e0a\u6709\u6539\u8fdb\u3002", "conclusion": "\u5373\u4fbf\u5728\u5f53\u524d\u91cf\u5b50\u786c\u4ef6\u9650\u5236\u4e0b\uff0cQA\u53ef\u4f5c\u4e3a\u79bb\u6563\u673a\u5668\u5b66\u4e60\u4f18\u5316\u7684\u6709\u7ade\u4e89\u529b\u548c\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2507.15151", "pdf": "https://arxiv.org/pdf/2507.15151", "abs": "https://arxiv.org/abs/2507.15151", "authors": ["Sebastian A. Cruz Romero", "Wilfredo E. Lugo Beauchamp"], "title": "Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted at International Symposium on Intelligent Computing &\n  Networks 2025", "summary": "Anemia is a widespread global health issue, particularly among young children\nin low-resource settings. Traditional methods for anemia detection often\nrequire expensive equipment and expert knowledge, creating barriers to early\nand accurate diagnosis. To address these challenges, we explore the use of deep\nlearning models for detecting anemia through conjunctival pallor, focusing on\nthe CP-AnemiC dataset, which includes 710 images from children aged 6-59\nmonths. The dataset is annotated with hemoglobin levels, gender, age and other\ndemographic data, enabling the development of machine learning models for\naccurate anemia detection. We use the MobileNet architecture as a backbone,\nknown for its efficiency in mobile and embedded vision applications, and\nfine-tune our model end-to-end using data augmentation techniques and a\ncross-validation strategy. Our model implementation achieved an accuracy of\n0.9313, a precision of 0.9374, and an F1 score of 0.9773 demonstrating strong\nperformance on the dataset. To optimize the model for deployment on edge\ndevices, we performed post-training quantization, evaluating the impact of\ndifferent bit-widths (FP32, FP16, INT8, and INT4) on model performance.\nPreliminary results suggest that while FP16 quantization maintains high\naccuracy (0.9250), precision (0.9370), and F1 Score (0.9377), more aggressive\nquantization (INT8 and INT4) leads to significant performance degradation.\nOverall, our study supports further exploration of quantization schemes and\nhardware optimizations to assess trade-offs between model size, inference time,\nand diagnostic accuracy in mobile healthcare applications.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u901a\u8fc7\u7ed3\u819c\u82cd\u767d\u68c0\u6d4b\u8d2b\u8840\uff0c\u4f7f\u7528CP - AnemiC\u6570\u636e\u96c6\uff0c\u6a21\u578b\u8868\u73b0\u826f\u597d\uff0c\u8bc4\u4f30\u4e0d\u540c\u91cf\u5316\u65b9\u6848\u5bf9\u6027\u80fd\u5f71\u54cd\uff0c\u5efa\u8bae\u8fdb\u4e00\u6b65\u63a2\u7d22\u91cf\u5316\u548c\u786c\u4ef6\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u8d2b\u8840\u68c0\u6d4b\u65b9\u6cd5\u9700\u6602\u8d35\u8bbe\u5907\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5b58\u5728\u65e9\u671f\u51c6\u786e\u8bca\u65ad\u969c\u788d\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528MobileNet\u67b6\u6784\u4e3a\u9aa8\u5e72\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\u7aef\u5230\u7aef\u5fae\u8c03\u6a21\u578b\uff0c\u5bf9\u6a21\u578b\u8fdb\u884c\u4e0d\u540c\u4f4d\u5bbd\u7684\u8bad\u7ec3\u540e\u91cf\u5316\u3002", "result": "\u6a21\u578b\u5728\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u73870.9313\u3001\u7cbe\u5ea60.9374\u3001F1\u5206\u65700.9773\uff1bFP16\u91cf\u5316\u80fd\u4fdd\u6301\u8f83\u9ad8\u6027\u80fd\uff0cINT8\u548cINT4\u91cf\u5316\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u652f\u6301\u8fdb\u4e00\u6b65\u63a2\u7d22\u91cf\u5316\u65b9\u6848\u548c\u786c\u4ef6\u4f18\u5316\uff0c\u8bc4\u4f30\u79fb\u52a8\u533b\u7597\u5e94\u7528\u4e2d\u6a21\u578b\u5927\u5c0f\u3001\u63a8\u7406\u65f6\u95f4\u548c\u8bca\u65ad\u51c6\u786e\u6027\u7684\u6743\u8861\u3002"}}
{"id": "2507.15084", "pdf": "https://arxiv.org/pdf/2507.15084", "abs": "https://arxiv.org/abs/2507.15084", "authors": ["Anja Butter", "Theo Heimel", "Nathan Huetsch", "Michael Kagan", "Tilman Plehn"], "title": "Simulation-Prior Independent Neural Unfolding Procedure", "categories": ["hep-ph", "cs.LG", "hep-ex"], "comment": null, "summary": "Machine learning allows unfolding high-dimensional spaces without binning at\nthe LHC. The new SPINUP method extracts the unfolded distribution based on a\nneural network encoding the forward mapping, making it independent of the prior\nfrom the simulated training data. It is made efficient through neural\nimportance sampling, and ensembling can be used to estimate the effect of\ninformation loss in the forward process. We showcase SPINUP for unfolding\ndetector effects on jet substructure observables and for unfolding to parton\nlevel of associated Higgs and single-top production.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86SPINUP\u65b9\u6cd5\u53ef\u5728LHC\u5c55\u5f00\u9ad8\u7ef4\u7a7a\u95f4\uff0c\u4e14\u5728\u5c55\u5f00\u63a2\u6d4b\u5668\u6548\u5e94\u548c\u5230\u90e8\u5206\u5b50\u5c42\u9762\u5c55\u5f00\u6709\u5e94\u7528\u3002", "motivation": "\u5728LHC\u5c55\u5f00\u9ad8\u7ef4\u7a7a\u95f4\u4e14\u907f\u514d\u5206\u7bb1\uff0c\u63d0\u53d6\u4e0d\u53d7\u6a21\u62df\u8bad\u7ec3\u6570\u636e\u5148\u9a8c\u5f71\u54cd\u7684\u5c55\u5f00\u5206\u5e03\u3002", "method": "\u63d0\u51faSPINUP\u65b9\u6cd5\uff0c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7f16\u7801\u6b63\u5411\u6620\u5c04\uff0c\u901a\u8fc7\u795e\u7ecf\u91cd\u8981\u6027\u91c7\u6837\u63d0\u9ad8\u6548\u7387\uff0c\u7528\u96c6\u6210\u65b9\u6cd5\u4f30\u8ba1\u6b63\u5411\u8fc7\u7a0b\u4fe1\u606f\u635f\u5931\u5f71\u54cd\u3002", "result": "\u5c55\u793a\u4e86SPINUP\u65b9\u6cd5\u5728\u5c55\u5f00\u55b7\u6ce8\u5b50\u7ed3\u6784\u53ef\u89c2\u6d4b\u91cf\u7684\u63a2\u6d4b\u5668\u6548\u5e94\u4ee5\u53ca\u5e0c\u683c\u65af\u548c\u5355\u9876\u5938\u514b\u4ea7\u751f\u5230\u90e8\u5206\u5b50\u5c42\u9762\u5c55\u5f00\u7684\u5e94\u7528\u3002", "conclusion": "SPINUP\u65b9\u6cd5\u4e3aLHC\u9ad8\u7ef4\u7a7a\u95f4\u5c55\u5f00\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2507.15152", "pdf": "https://arxiv.org/pdf/2507.15152", "abs": "https://arxiv.org/abs/2507.15152", "authors": ["Lingbo Li", "Anuradha Mathrani", "Teo Susnjak"], "title": "What Level of Automation is \"Good Enough\"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Automating data extraction from full-text randomised controlled trials (RCTs)\nfor meta-analysis remains a significant challenge. This study evaluates the\npractical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)\nacross tasks involving statistical results, risk-of-bias assessments, and\nstudy-level characteristics in three medical domains: hypertension, diabetes,\nand orthopaedics. We tested four distinct prompting strategies (basic\nprompting, self-reflective prompting, model ensemble, and customised prompts)\nto determine how to improve extraction quality. All models demonstrate high\nprecision but consistently suffer from poor recall by omitting key information.\nWe found that customised prompts were the most effective, boosting recall by up\nto 15\\%. Based on this analysis, we propose a three-tiered set of guidelines\nfor using LLMs in data extraction, matching data types to appropriate levels of\nautomation based on task complexity and risk. Our study offers practical advice\nfor automating data extraction in real-world meta-analyses, balancing LLM\nefficiency with expert oversight through targeted, task-specific automation.", "AI": {"tldr": "\u8bc4\u4f30\u4e09\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u6570\u636e\u63d0\u53d6\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u6d4b\u8bd5\u4e0d\u540c\u63d0\u793a\u7b56\u7565\uff0c\u53d1\u73b0\u5b9a\u5236\u63d0\u793a\u6700\u6709\u6548\uff0c\u63d0\u51fa\u4e09\u5c42\u4f7f\u7528\u6307\u5357\u3002", "motivation": "\u81ea\u52a8\u5316\u4ece\u5168\u6587\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u4e2d\u63d0\u53d6\u6570\u636e\u7528\u4e8e\u5143\u5206\u6790\u4ecd\u5177\u6311\u6218\uff0c\u9700\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9645\u6027\u80fd\u3002", "method": "\u8bc4\u4f30Gemini - 2.0 - flash\u3001Grok - 3\u3001GPT - 4o - mini\u4e09\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u4e2a\u533b\u5b66\u9886\u57df\u7684\u7edf\u8ba1\u7ed3\u679c\u3001\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u548c\u7814\u7a76\u7279\u5f81\u63d0\u53d6\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u6d4b\u8bd5\u56db\u79cd\u63d0\u793a\u7b56\u7565\u3002", "result": "\u6240\u6709\u6a21\u578b\u7cbe\u5ea6\u9ad8\u4f46\u53ec\u56de\u7387\u4f4e\uff0c\u5b9a\u5236\u63d0\u793a\u6700\u6709\u6548\uff0c\u53ef\u5c06\u53ec\u56de\u7387\u63d0\u9ad8\u8fbe15%\u3002", "conclusion": "\u63d0\u51fa\u4e09\u5c42\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6570\u636e\u63d0\u53d6\u7684\u6307\u5357\uff0c\u4e3a\u5b9e\u9645\u5143\u5206\u6790\u4e2d\u7684\u6570\u636e\u63d0\u53d6\u63d0\u4f9b\u5b9e\u7528\u5efa\u8bae\uff0c\u5e73\u8861\u6548\u7387\u4e0e\u4e13\u5bb6\u76d1\u7763\u3002"}}
{"id": "2507.15109", "pdf": "https://arxiv.org/pdf/2507.15109", "abs": "https://arxiv.org/abs/2507.15109", "authors": ["Mohammad-Maher Nakshbandi", "Ziad Sharawy", "Sorin Grigorescu"], "title": "LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "One of the main challenges in the Simultaneous Localization and Mapping\n(SLAM) loop closure problem is the recognition of previously visited places. In\nthis work, we tackle the two main problems of real-time SLAM systems: 1) loop\nclosure detection accuracy and 2) real-time computation constraints on the\nembedded hardware. Our LoopNet method is based on a multitasking variant of the\nclassical ResNet architecture, adapted for online retraining on a dynamic\nvisual dataset and optimized for embedded devices. The online retraining is\ndesigned using a few-shot learning approach. The architecture provides both an\nindex into the queried visual dataset, and a measurement of the prediction\nquality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors,\nLoopNet surpasses the limitations of handcrafted features and traditional deep\nlearning methods, offering better performance under varying conditions. Code is\navailable at https://github.com/RovisLab/LoopNet. Additinally, we introduce a\nnew loop closure benchmarking dataset, coined LoopDB, which is available at\nhttps://github.com/RovisLab/LoopDB.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLoopNet\u65b9\u6cd5\u89e3\u51b3\u5b9e\u65f6SLAM\u7cfb\u7edf\u7684\u95ed\u73af\u68c0\u6d4b\u7cbe\u5ea6\u548c\u5d4c\u5165\u5f0f\u786c\u4ef6\u5b9e\u65f6\u8ba1\u7b97\u7ea6\u675f\u95ee\u9898\uff0c\u8fd8\u5f15\u5165\u65b0\u57fa\u51c6\u6570\u636e\u96c6LoopDB\u3002", "motivation": "\u89e3\u51b3\u5b9e\u65f6SLAM\u7cfb\u7edf\u4e2d\u95ed\u73af\u68c0\u6d4b\u7cbe\u5ea6\u548c\u5d4c\u5165\u5f0f\u786c\u4ef6\u5b9e\u65f6\u8ba1\u7b97\u7ea6\u675f\u8fd9\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178ResNet\u67b6\u6784\u7684\u591a\u4efb\u52a1\u53d8\u4f53LoopNet\u65b9\u6cd5\uff0c\u91c7\u7528\u5c11\u6837\u672c\u5b66\u4e60\u8fdb\u884c\u5728\u7ebf\u518d\u8bad\u7ec3\uff0c\u5229\u7528DISK\u63cf\u8ff0\u7b26\u3002", "result": "LoopNet\u8d85\u8d8a\u624b\u5de5\u7279\u5f81\u548c\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u6709\u66f4\u597d\u6027\u80fd\uff0c\u4ee3\u7801\u548c\u65b0\u57fa\u51c6\u6570\u636e\u96c6LoopDB\u5747\u5f00\u6e90\u3002", "conclusion": "LoopNet\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u5b9e\u65f6SLAM\u7cfb\u7edf\u76f8\u5173\u95ee\u9898\uff0c\u65b0\u6570\u636e\u96c6LoopDB\u53ef\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2507.15193", "pdf": "https://arxiv.org/pdf/2507.15193", "abs": "https://arxiv.org/abs/2507.15193", "authors": ["Tanjin Taher Toma", "Tejas Sudharshan Mathai", "Bikash Santra", "Pritam Mukherjee", "Jianfei Liu", "Wesley Jong", "Darwish Alabyad", "Vivek Batheja", "Abhishek Jha", "Mayank Patel", "Darko Pucar", "Jayadira del Rivero", "Karel Pacak", "Ronald M. Summers"], "title": "A Study of Anatomical Priors for Deep Learning-Based Segmentation of Pheochromocytoma in Abdominal CT", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Accurate segmentation of pheochromocytoma (PCC) in abdominal CT scans is\nessential for tumor burden estimation, prognosis, and treatment planning. It\nmay also help infer genetic clusters, reducing reliance on expensive testing.\nThis study systematically evaluates anatomical priors to identify\nconfigurations that improve deep learning-based PCC segmentation. We employed\nthe nnU-Net framework to evaluate eleven annotation strategies for accurate 3D\nsegmentation of pheochromocytoma, introducing a set of novel multi-class\nschemes based on organ-specific anatomical priors. These priors were derived\nfrom adjacent organs commonly surrounding adrenal tumors (e.g., liver, spleen,\nkidney, aorta, adrenal gland, and pancreas), and were compared against a broad\nbody-region prior used in previous work. The framework was trained and tested\non 105 contrast-enhanced CT scans from 91 patients at the NIH Clinical Center.\nPerformance was measured using Dice Similarity Coefficient (DSC), Normalized\nSurface Distance (NSD), and instance-wise F1 score. Among all strategies, the\nTumor + Kidney + Aorta (TKA) annotation achieved the highest segmentation\naccuracy, significantly outperforming the previously used Tumor + Body (TB)\nannotation across DSC (p = 0.0097), NSD (p = 0.0110), and F1 score (25.84%\nimprovement at an IoU threshold of 0.5), measured on a 70-30 train-test split.\nThe TKA model also showed superior tumor burden quantification (R^2 = 0.968)\nand strong segmentation across all genetic subtypes. In five-fold\ncross-validation, TKA consistently outperformed TB across IoU thresholds (0.1\nto 0.5), reinforcing its robustness and generalizability. These findings\nhighlight the value of incorporating relevant anatomical context in deep\nlearning models to achieve precise PCC segmentation, supporting clinical\nassessment and longitudinal monitoring.", "AI": {"tldr": "\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u89e3\u5256\u5148\u9a8c\u4ee5\u63d0\u5347\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u55dc\u94ec\u7ec6\u80de\u7624\uff08PCC\uff09\u5206\u5272\uff0cTumor + Kidney + Aorta\uff08TKA\uff09\u6ce8\u91ca\u7b56\u7565\u6548\u679c\u6700\u4f73\uff0c\u51f8\u663e\u89e3\u5256\u80cc\u666f\u4ef7\u503c\u3002", "motivation": "\u51c6\u786e\u5206\u5272\u8179\u90e8CT\u626b\u63cf\u4e2d\u7684PCC\u5bf9\u80bf\u7624\u8d1f\u8377\u4f30\u8ba1\u3001\u9884\u540e\u548c\u6cbb\u7597\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u89e3\u5256\u5148\u9a8c\u4ee5\u6539\u8fdb\u5206\u5272\u3002", "method": "\u91c7\u7528nnU - Net\u6846\u67b6\u8bc4\u4f3011\u79cd\u6ce8\u91ca\u7b56\u7565\uff0c\u57fa\u4e8e\u5668\u5b98\u7279\u5b9a\u89e3\u5256\u5148\u9a8c\u5f15\u5165\u591a\u7c7b\u65b9\u6848\uff0c\u5728105\u4f8bCT\u626b\u63cf\u4e0a\u8bad\u7ec3\u6d4b\u8bd5\uff0c\u7528DSC\u3001NSD\u548cF1\u5206\u6570\u8861\u91cf\u6027\u80fd\u3002", "result": "TKA\u6ce8\u91ca\u7b56\u7565\u5206\u5272\u51c6\u786e\u6027\u6700\u9ad8\uff0c\u5728DSC\u3001NSD\u548cF1\u5206\u6570\u4e0a\u663e\u8457\u4f18\u4e8eTumor + Body\uff08TB\uff09\u6ce8\u91ca\uff0c\u80bf\u7624\u8d1f\u8377\u91cf\u5316\u6548\u679c\u597d\uff0c\u8de8\u57fa\u56e0\u4e9a\u578b\u5206\u5272\u5f3a\uff0c\u4e94\u6298\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u7eb3\u5165\u76f8\u5173\u89e3\u5256\u80cc\u666f\u5bf9\u5b9e\u73b0\u7cbe\u786ePCC\u5206\u5272\u6709\u4ef7\u503c\uff0c\u652f\u6301\u4e34\u5e8a\u8bc4\u4f30\u548c\u7eb5\u5411\u76d1\u6d4b\u3002"}}
{"id": "2507.15145", "pdf": "https://arxiv.org/pdf/2507.15145", "abs": "https://arxiv.org/abs/2507.15145", "authors": ["Thai T. Vu", "John Le"], "title": "Quantum Machine Learning for Secure Cooperative Multi-Layer Edge AI with Proportional Fairness", "categories": ["cs.NI", "cs.LG"], "comment": "8 pages", "summary": "This paper proposes a communication-efficient, event-triggered inference\nframework for cooperative edge AI systems comprising multiple user devices and\nedge servers. Building upon dual-threshold early-exit strategies for rare-event\ndetection, the proposed approach extends classical single-device inference to a\ndistributed, multi-device setting while incorporating proportional fairness\nconstraints across users. A joint optimization framework is formulated to\nmaximize classification utility under communication, energy, and fairness\nconstraints. To solve the resulting problem efficiently, we exploit the\nmonotonicity of the utility function with respect to the confidence thresholds\nand apply alternating optimization with Benders decomposition. Experimental\nresults show that the proposed framework significantly enhances system-wide\nperformance and fairness in resource allocation compared to single-device\nbaselines.", "AI": {"tldr": "\u63d0\u51fa\u901a\u4fe1\u9ad8\u6548\u3001\u4e8b\u4ef6\u89e6\u53d1\u7684\u5408\u4f5c\u8fb9\u7f18AI\u7cfb\u7edf\u63a8\u7406\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u548c\u516c\u5e73\u6027\u63d0\u5347\u3002", "motivation": "\u4e3a\u542b\u591a\u7528\u6237\u8bbe\u5907\u548c\u8fb9\u7f18\u670d\u52a1\u5668\u7684\u5408\u4f5c\u8fb9\u7f18AI\u7cfb\u7edf\u8bbe\u8ba1\u901a\u4fe1\u9ad8\u6548\u7684\u63a8\u7406\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u53cc\u9608\u503c\u63d0\u524d\u9000\u51fa\u7b56\u7565\uff0c\u5c06\u5355\u8bbe\u5907\u63a8\u7406\u6269\u5c55\u5230\u5206\u5e03\u5f0f\u591a\u8bbe\u5907\u573a\u666f\uff0c\u7ed3\u5408\u6bd4\u4f8b\u516c\u5e73\u7ea6\u675f\uff0c\u5efa\u7acb\u8054\u5408\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528\u6548\u7528\u51fd\u6570\u5355\u8c03\u6027\u548cBenders\u5206\u89e3\u4ea4\u66ff\u4f18\u5316\u3002", "result": "\u8be5\u6846\u67b6\u76f8\u6bd4\u5355\u8bbe\u5907\u57fa\u7ebf\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u548c\u8d44\u6e90\u5206\u914d\u516c\u5e73\u6027\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u5408\u4f5c\u8fb9\u7f18AI\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2507.15219", "pdf": "https://arxiv.org/pdf/2507.15219", "abs": "https://arxiv.org/abs/2507.15219", "authors": ["Tianneng Shi", "Kaijie Zhu", "Zhun Wang", "Yuqi Jia", "Will Cai", "Weida Liang", "Haonan Wang", "Hend Alzahrani", "Joshua Lu", "Kenji Kawaguchi", "Basel Alomair", "Xuandong Zhao", "William Yang Wang", "Neil Gong", "Wenbo Guo", "Dawn Song"], "title": "PromptArmor: Simple yet Effective Prompt Injection Defenses", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Despite their potential, recent research has demonstrated that LLM agents are\nvulnerable to prompt injection attacks, where malicious prompts are injected\ninto the agent's input, causing it to perform an attacker-specified task rather\nthan the intended task provided by the user. In this paper, we present\nPromptArmor, a simple yet effective defense against prompt injection attacks.\nSpecifically, PromptArmor prompts an off-the-shelf LLM to detect and remove\npotential injected prompts from the input before the agent processes it. Our\nresults show that PromptArmor can accurately identify and remove injected\nprompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves\nboth a false positive rate and a false negative rate below 1% on the AgentDojo\nbenchmark. Moreover, after removing injected prompts with PromptArmor, the\nattack success rate drops to below 1%. We also demonstrate PromptArmor's\neffectiveness against adaptive attacks and explore different strategies for\nprompting an LLM. We recommend that PromptArmor be adopted as a standard\nbaseline for evaluating new defenses against prompt injection attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9632\u5fa1\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u65b9\u6cd5PromptArmor\uff0c\u6548\u679c\u597d\uff0c\u5efa\u8bae\u7528\u4f5c\u8bc4\u4f30\u65b0\u9632\u5fa1\u65b9\u6cd5\u7684\u57fa\u51c6\u3002", "motivation": "\u8fd1\u671f\u7814\u7a76\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u9700\u6709\u6548\u9632\u5fa1\u624b\u6bb5\u3002", "method": "PromptArmor\u5229\u7528\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7406\u5904\u7406\u8f93\u5165\u524d\u68c0\u6d4b\u5e76\u79fb\u9664\u6f5c\u5728\u6ce8\u5165\u63d0\u793a\u3002", "result": "\u5728AgentDojo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPromptArmor\u8bef\u62a5\u7387\u548c\u6f0f\u62a5\u7387\u4f4e\u4e8e1%\uff0c\u79fb\u9664\u6ce8\u5165\u63d0\u793a\u540e\u653b\u51fb\u6210\u529f\u7387\u964d\u81f31%\u4ee5\u4e0b\uff0c\u5bf9\u81ea\u9002\u5e94\u653b\u51fb\u4e5f\u6709\u6548\u3002", "conclusion": "\u5efa\u8bae\u5c06PromptArmor\u4f5c\u4e3a\u8bc4\u4f30\u65b0\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u9632\u5fa1\u65b9\u6cd5\u7684\u6807\u51c6\u57fa\u7ebf\u3002"}}
{"id": "2507.15243", "pdf": "https://arxiv.org/pdf/2507.15243", "abs": "https://arxiv.org/abs/2507.15243", "authors": ["Naeem Paeedeh", "Mahardhika Pratama", "Wolfgang Mayer", "Jimmy Cao", "Ryszard Kowlczyk"], "title": "Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model\npre-trained with DINO combined with a prototypical classifier outperforms the\nlatest SOTA methods. A crucial limitation that needs to be overcome is that\nupdating too many parameters of the transformers leads to overfitting due to\nthe scarcity of labeled samples. To address this challenge, we propose a new\nconcept, Coalescent Projection (CP), as an effective successor to soft prompts.\nAdditionally, we propose a novel pseudo-class generation method combined with\nSelf-Supervised Transformations (SSTs) that relies solely on the base domain to\nprepare the network for encountering unseen samples from different domains. The\nproposed method exhibits its effectiveness in comprehensive experiments on the\nextreme domain shift scenario of the BSCD-FSL benchmark. Our code is published\nat https://github.com/Naeem-Paeedeh/CPLSR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCoalescent Projection (CP)\u6982\u5ff5\u53ca\u7ed3\u5408\u81ea\u76d1\u7763\u53d8\u6362\u7684\u4f2a\u7c7b\u751f\u6210\u65b9\u6cd5\uff0c\u5728BSCD - FSL\u57fa\u51c6\u6d4b\u8bd5\u6781\u7aef\u57df\u504f\u79fb\u573a\u666f\u5b9e\u9a8c\u4e2d\u6709\u6548\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u5f53\u524d\u8de8\u57df\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\uff0c\u66f4\u65b0\u8fc7\u591aTransformer\u53c2\u6570\u56e0\u6807\u8bb0\u6837\u672c\u7a00\u7f3a\u4f1a\u5bfc\u81f4\u8fc7\u62df\u5408\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faCoalescent Projection (CP)\u6982\u5ff5\u66ff\u4ee3\u8f6f\u63d0\u793a\uff0c\u63d0\u51fa\u7ed3\u5408\u81ea\u76d1\u7763\u53d8\u6362\uff08SSTs\uff09\u7684\u4f2a\u7c7b\u751f\u6210\u65b9\u6cd5\u3002", "result": "\u5728BSCD - FSL\u57fa\u51c6\u6d4b\u8bd5\u7684\u6781\u7aef\u57df\u504f\u79fb\u573a\u666f\u7efc\u5408\u5b9e\u9a8c\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u5c55\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9\u8de8\u57df\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\u56e0\u6807\u8bb0\u6837\u672c\u7a00\u7f3a\u66f4\u65b0\u53c2\u6570\u5bfc\u81f4\u7684\u8fc7\u62df\u5408\u95ee\u9898\u3002"}}
{"id": "2507.15232", "pdf": "https://arxiv.org/pdf/2507.15232", "abs": "https://arxiv.org/abs/2507.15232", "authors": ["Minwoo Kim", "Sungkyu Jung"], "title": "Robust and Differentially Private PCA for non-Gaussian data", "categories": ["stat.ME", "cs.LG"], "comment": "38 pages, 6 figures", "summary": "Recent advances have sparked significant interest in the development of\nprivacy-preserving Principal Component Analysis (PCA). However, many existing\napproaches rely on restrictive assumptions, such as assuming sub-Gaussian data\nor being vulnerable to data contamination. Additionally, some methods are\ncomputationally expensive or depend on unknown model parameters that must be\nestimated, limiting their accessibility for data analysts seeking\nprivacy-preserving PCA. In this paper, we propose a differentially private PCA\nmethod applicable to heavy-tailed and potentially contaminated data. Our\napproach leverages the property that the covariance matrix of properly rescaled\ndata preserves eigenvectors and their order under elliptical distributions,\nwhich include Gaussian and heavy-tailed distributions. By applying a bounded\ntransformation, we enable straightforward computation of principal components\nin a differentially private manner. Additionally, boundedness guarantees\nrobustness against data contamination. We conduct both theoretical analysis and\nempirical evaluations of the proposed method, focusing on its ability to\nrecover the subspace spanned by the leading principal components. Extensive\nnumerical experiments demonstrate that our method consistently outperforms\nexisting approaches in terms of statistical utility, particularly in\nnon-Gaussian or contaminated data settings.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8e\u91cd\u5c3e\u548c\u53ef\u80fd\u53d7\u6c61\u67d3\u6570\u636e\u7684\u5dee\u5206\u9690\u79c1PCA\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u7edf\u8ba1\u6548\u7528\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u9690\u79c1\u4fdd\u62a4PCA\u65b9\u6cd5\u6709\u4f9d\u8d56\u9650\u5236\u6027\u5047\u8bbe\u3001\u8ba1\u7b97\u6602\u8d35\u7b49\u95ee\u9898\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u692d\u5706\u5206\u5e03\u4e0b\u534f\u65b9\u5dee\u77e9\u9635\u6027\u8d28\uff0c\u901a\u8fc7\u6709\u754c\u53d8\u6362\u4ee5\u5dee\u5206\u9690\u79c1\u65b9\u5f0f\u8ba1\u7b97\u4e3b\u6210\u5206\u3002", "result": "\u5e7f\u6cdb\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u975e\u9ad8\u65af\u6216\u53d7\u6c61\u67d3\u6570\u636e\u8bbe\u7f6e\u4e2d\u7edf\u8ba1\u6548\u7528\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u9002\u7528\u4e8e\u91cd\u5c3e\u548c\u53d7\u6c61\u67d3\u6570\u636e\uff0c\u80fd\u6709\u6548\u6062\u590d\u4e3b\u6210\u5206\u5f20\u6210\u7684\u5b50\u7a7a\u95f4\uff0c\u5177\u6709\u66f4\u597d\u7edf\u8ba1\u6548\u7528\u3002"}}
{"id": "2507.15254", "pdf": "https://arxiv.org/pdf/2507.15254", "abs": "https://arxiv.org/abs/2507.15254", "authors": ["Sourav Mondal", "Elaine Wong"], "title": "User Head Movement-Predictive XR in Immersive H2M Collaborations over Future Enterprise Networks", "categories": ["cs.NI", "cs.AI"], "comment": "This article is accepted for publication in IEEE Internet of Things\n  Journal. Copyright @ IEEE 2025", "summary": "The evolution towards future generation of mobile systems and fixed wireless\nnetworks is primarily driven by the urgency to support high-bandwidth and\nlow-latency services across various vertical sectors. This endeavor is fueled\nby smartphones as well as technologies like industrial internet of things,\nextended reality (XR), and human-to-machine (H2M) collaborations for fostering\nindustrial and social revolutions like Industry 4.0/5.0 and Society 5.0. To\nensure an ideal immersive experience and avoid cyber-sickness for users in all\nthe aforementioned usage scenarios, it is typically challenging to synchronize\nXR content from a remote machine to a human collaborator according to their\nhead movements across a large geographic span in real-time over communication\nnetworks. Thus, we propose a novel H2M collaboration scheme where the human's\nhead movements are predicted ahead with highly accurate models like\nbidirectional long short-term memory networks to orient the machine's camera in\nadvance. We validate that XR frame size varies in accordance with the human's\nhead movements and predict the corresponding bandwidth requirements from the\nmachine's camera to propose a human-machine coordinated dynamic bandwidth\nallocation (HMC-DBA) scheme. Through extensive simulations, we show that\nend-to-end latency and jitter requirements of XR frames are satisfied with much\nlower bandwidth consumption over enterprise networks like\nFiber-To-The-Room-Business. Furthermore, we show that better efficiency in\nnetwork resource utilization is achieved by employing our proposed HMC-DBA over\nstate-of-the-art schemes.", "AI": {"tldr": "\u4e3a\u652f\u6301\u9ad8\u5e26\u5bbd\u4f4e\u5ef6\u8fdf\u670d\u52a1\uff0c\u5e94\u5bf9XR\u5185\u5bb9\u5b9e\u65f6\u540c\u6b65\u6311\u6218\uff0c\u63d0\u51faH2M\u534f\u4f5c\u548cHMC - DBA\u65b9\u6848\uff0c\u7ecf\u6a21\u62df\u9a8c\u8bc1\u53ef\u4f4e\u5e26\u5bbd\u6ee1\u8db3\u8981\u6c42\u4e14\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u672a\u6765\u79fb\u52a8\u548c\u56fa\u5b9a\u65e0\u7ebf\u7f51\u7edc\u9700\u652f\u6301\u9ad8\u5e26\u5bbd\u4f4e\u5ef6\u8fdf\u670d\u52a1\uff0cXR\u5185\u5bb9\u5b9e\u65f6\u540c\u6b65\u56f0\u96be\uff0c\u9700\u4fdd\u969c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u7528\u53cc\u5411\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u9884\u6d4b\u4eba\u7c7b\u5934\u90e8\u52a8\u4f5c\uff0c\u6839\u636e\u5934\u90e8\u52a8\u4f5c\u9884\u6d4bXR\u5e27\u5927\u5c0f\u548c\u5e26\u5bbd\u9700\u6c42\uff0c\u63d0\u51faHMC - DBA\u65b9\u6848\u3002", "result": "\u6a21\u62df\u663e\u793a\u53ef\u5728\u4f01\u4e1a\u7f51\u7edc\u4e2d\u4ee5\u4f4e\u5e26\u5bbd\u6ee1\u8db3XR\u5e27\u7aef\u5230\u7aef\u5ef6\u8fdf\u548c\u6296\u52a8\u8981\u6c42\uff0c\u6bd4\u73b0\u6709\u65b9\u6848\u63d0\u9ad8\u7f51\u7edc\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684HMC - DBA\u65b9\u6848\u6709\u6548\uff0c\u80fd\u6ee1\u8db3\u9700\u6c42\u5e76\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2507.15236", "pdf": "https://arxiv.org/pdf/2507.15236", "abs": "https://arxiv.org/abs/2507.15236", "authors": ["Shayan Vassef", "Amirhossein Dabiriaghdam", "Mohammadreza Bakhtiari", "Yadollah Yaghoobzadeh"], "title": "SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This work investigates the impact of multi-task, multi-lingual, and\nmulti-source learning approaches on the robustness and performance of\npretrained language models. To enhance this analysis, we introduce Subsets of\nInterest (SOI), a novel categorization framework that identifies six distinct\nlearning behavior patterns during training, including forgettable examples,\nunlearned examples, and always correct examples. Through SOI transition\nheatmaps and dataset cartography visualization, we analyze how examples shift\nbetween these categories when transitioning from single-setting to\nmulti-setting configurations. We perform comprehensive experiments across three\nparallel comparisons: multi-task vs. single-task learning using English tasks\n(entailment, paraphrase, sentiment), multi-source vs. single-source learning\nusing sentiment analysis datasets, and multi-lingual vs. single-lingual\nlearning using intent classification in French, English, and Persian. Our\nresults demonstrate that multi-source learning consistently improves\nout-of-distribution performance by up to 7%, while multi-task learning shows\nmixed results with notable gains in similar task combinations. We further\nintroduce a two-stage fine-tuning approach where the second stage leverages\nSOI-based subset selection to achieve additional performance improvements.\nThese findings provide new insights into training dynamics and offer practical\napproaches for optimizing multi-setting language model performance.", "AI": {"tldr": "\u7814\u7a76\u591a\u4efb\u52a1\u3001\u591a\u8bed\u8a00\u548c\u591a\u6e90\u5b66\u4e60\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u5f15\u5165SOI\u6846\u67b6\u5206\u6790\u8bad\u7ec3\u6a21\u5f0f\uff0c\u5b9e\u9a8c\u8868\u660e\u591a\u6e90\u5b66\u4e60\u63d0\u5347OOD\u6027\u80fd\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u5fae\u8c03\u6cd5\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u63a2\u7a76\u591a\u4efb\u52a1\u3001\u591a\u8bed\u8a00\u548c\u591a\u6e90\u5b66\u4e60\u65b9\u6cd5\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9c81\u68d2\u6027\u548c\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5f15\u5165SOI\u6846\u67b6\u8bc6\u522b\u8bad\u7ec3\u4e2d\u7684\u5b66\u4e60\u884c\u4e3a\u6a21\u5f0f\uff0c\u901a\u8fc7SOI\u8f6c\u6362\u70ed\u56fe\u548c\u6570\u636e\u96c6\u5236\u56fe\u53ef\u89c6\u5316\u5206\u6790\u793a\u4f8b\u8f6c\u53d8\uff0c\u8fdb\u884c\u4e09\u7ec4\u5e73\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u5fae\u8c03\u6cd5\u3002", "result": "\u591a\u6e90\u5b66\u4e60\u4f7fOOD\u6027\u80fd\u63d0\u5347\u8fbe7%\uff0c\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u76f8\u4f3c\u4efb\u52a1\u7ec4\u5408\u4e2d\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e24\u9636\u6bb5\u5fae\u8c03\u6cd5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u65b0\u89c1\u89e3\uff0c\u4e3a\u4f18\u5316\u591a\u8bbe\u7f6e\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u63d0\u4f9b\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2507.15255", "pdf": "https://arxiv.org/pdf/2507.15255", "abs": "https://arxiv.org/abs/2507.15255", "authors": ["Deyun Zhang", "Xiang Lan", "Shijia Geng", "Qinghao Zhao", "Sumei Fan", "Mengling Feng", "Shenda Hong"], "title": "MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Electrocardiogram (ECG) plays a foundational role in modern cardiovascular\ncare, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and\nconduction disorders. While machine learning has achieved expert-level\nperformance in ECG interpretation, the development of clinically deployable\nmultimodal AI systems remains constrained, primarily due to the lack of\npublicly available datasets that simultaneously incorporate raw signals,\ndiagnostic images, and interpretation text. Most existing ECG datasets provide\nonly single-modality data or, at most, dual modalities, making it difficult to\nbuild models that can understand and integrate diverse ECG information in\nreal-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext\nECG-Text-Image), the first large-scale ECG dataset that synchronizes raw\nwaveform data, high-resolution plotted images, and detailed textual\ninterpretations generated by large language models. In addition, MEETI includes\nbeat-level quantitative ECG parameters extracted from each lead, offering\nstructured parameters that support fine-grained analysis and model\ninterpretability. Each MEETI record is aligned across four components: (1) the\nraw ECG waveform, (2) the corresponding plotted image, (3) extracted feature\nparameters, and (4) detailed interpretation text. This alignment is achieved\nusing consistent, unique identifiers. This unified structure supports\ntransformer-based multimodal learning and supports fine-grained, interpretable\nreasoning about cardiac health. By bridging the gap between traditional signal\nanalysis, image-based interpretation, and language-driven understanding, MEETI\nestablished a robust foundation for the next generation of explainable,\nmultimodal cardiovascular AI. It offers the research community a comprehensive\nbenchmark for developing and evaluating ECG-based AI systems.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u9996\u4e2a\u5927\u89c4\u6a21\u540c\u6b65\u539f\u59cb\u6ce2\u5f62\u3001\u56fe\u50cf\u548c\u6587\u672c\u7684\u5fc3\u7535\u56fe\u6570\u636e\u96c6MEETI\uff0c\u652f\u6301\u591a\u6a21\u6001\u5b66\u4e60\u548c\u7ec6\u7c92\u5ea6\u63a8\u7406\uff0c\u4e3a\u5fc3\u8840\u7ba1AI\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u5fc3\u7535\u56fe\u6570\u636e\u96c6\u591a\u4e3a\u5355\u6a21\u6001\u6216\u53cc\u6a21\u6001\uff0c\u96be\u4ee5\u6784\u5efa\u80fd\u7406\u89e3\u548c\u6574\u5408\u591a\u6837\u4fe1\u606f\u7684\u6a21\u578b\uff0c\u7f3a\u4e4f\u53ef\u4e34\u5e8a\u90e8\u7f72\u7684\u591a\u6a21\u6001AI\u7cfb\u7edf\u3002", "method": "\u5f15\u5165MEETI\u6570\u636e\u96c6\uff0c\u5305\u542b\u539f\u59cb\u6ce2\u5f62\u3001\u56fe\u50cf\u3001\u7279\u5f81\u53c2\u6570\u548c\u6587\u672c\u89e3\u8bfb\uff0c\u901a\u8fc7\u552f\u4e00\u6807\u8bc6\u7b26\u5b9e\u73b0\u56db\u7ec4\u4ef6\u5bf9\u9f50\u3002", "result": "MEETI\u6570\u636e\u96c6\u652f\u6301\u57fa\u4e8etransformer\u7684\u591a\u6a21\u6001\u5b66\u4e60\u548c\u7ec6\u7c92\u5ea6\u3001\u53ef\u89e3\u91ca\u7684\u5fc3\u810f\u5065\u5eb7\u63a8\u7406\u3002", "conclusion": "MEETI\u4e3a\u4e0b\u4e00\u4ee3\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u5fc3\u8840\u7ba1AI\u5efa\u7acb\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u4e3a\u7814\u7a76\u754c\u63d0\u4f9b\u4e86\u8bc4\u4f30\u5fc3\u7535\u56feAI\u7cfb\u7edf\u7684\u7efc\u5408\u57fa\u51c6\u3002"}}
{"id": "2507.15256", "pdf": "https://arxiv.org/pdf/2507.15256", "abs": "https://arxiv.org/abs/2507.15256", "authors": ["Zihao Hu", "Jia Yan", "Ying-Jun Angela Zhang", "Jun Zhang", "Khaled B. Letaief"], "title": "Optimal Transceiver Design in Over-the-Air Federated Distillation", "categories": ["eess.SP", "cs.AI"], "comment": "13 pages, 7 figures, submitted to IEEE Transactions on Wireless\n  Communications", "summary": "The rapid proliferation and growth of artificial intelligence (AI) has led to\nthe development of federated learning (FL). FL allows wireless devices (WDs) to\ncooperatively learn by sharing only local model parameters, without needing to\nshare the entire dataset. However, the emergence of large AI models has made\nexisting FL approaches inefficient, due to the significant communication\noverhead required. In this paper, we propose a novel over-the-air federated\ndistillation (FD) framework by synergizing the strength of FL and knowledge\ndistillation to avoid the heavy local model transmission. Instead of sharing\nthe model parameters, only the WDs' model outputs, referred to as knowledge,\nare shared and aggregated over-the-air by exploiting the superposition property\nof the multiple-access channel. We shall study the transceiver design in\nover-the-air FD, aiming to maximize the learning convergence rate while meeting\nthe power constraints of the transceivers. The main challenge lies in the\nintractability of the learning performance analysis, as well as the non-convex\nnature and the optimization spanning the whole FD training period. To tackle\nthis problem, we first derive an analytical expression of the convergence rate\nin over-the-air FD. Then, the closed-form optimal solutions of the WDs'\ntransmit power and the estimator for over-the-air aggregation are obtained\ngiven the receiver combining strategy. Accordingly, we put forth an efficient\napproach to find the optimal receiver beamforming vector via semidefinite\nrelaxation. We further prove that there is no optimality gap between the\noriginal and relaxed problem for the receiver beamforming design. Numerical\nresults will show that the proposed over-the-air FD approach achieves a\nsignificant reduction in communication overhead, with only a minor compromise\nin testing accuracy compared to conventional FL benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u65e0\u7ebf\u8054\u90a6\u84b8\u998f\u6846\u67b6\u4ee5\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u7ed9\u51fa\u76f8\u5173\u4f18\u5316\u8bbe\u8ba1\uff0c\u6570\u503c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u5f00\u9500\u4e14\u6d4b\u8bd5\u7cbe\u5ea6\u635f\u5931\u5c0f\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u5927AI\u6a21\u578b\u4e0b\u56e0\u901a\u4fe1\u5f00\u9500\u5927\u800c\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u65b0\u65b9\u6cd5\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "method": "\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u548c\u77e5\u8bc6\u84b8\u998f\u63d0\u51fa\u65e0\u7ebf\u8054\u90a6\u84b8\u998f\u6846\u67b6\uff0c\u63a8\u5bfc\u6536\u655b\u7387\u8868\u8fbe\u5f0f\uff0c\u83b7\u53d6\u53d1\u5c04\u529f\u7387\u548c\u805a\u5408\u4f30\u8ba1\u5668\u7684\u95ed\u5f0f\u89e3\uff0c\u901a\u8fc7\u534a\u5b9a\u677e\u5f1b\u6c42\u6700\u4f18\u63a5\u6536\u6ce2\u675f\u6210\u5f62\u5411\u91cf\u3002", "result": "\u6240\u63d0\u65e0\u7ebf\u8054\u90a6\u84b8\u998f\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\uff0c\u4e0e\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u57fa\u51c6\u76f8\u6bd4\uff0c\u6d4b\u8bd5\u7cbe\u5ea6\u4ec5\u6709\u8f7b\u5fae\u635f\u5931\u3002", "conclusion": "\u6240\u63d0\u65e0\u7ebf\u8054\u90a6\u84b8\u998f\u6846\u67b6\u6709\u6548\uff0c\u80fd\u5728\u6ee1\u8db3\u529f\u7387\u7ea6\u675f\u4e0b\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\uff0c\u4e14\u5bf9\u6d4b\u8bd5\u7cbe\u5ea6\u5f71\u54cd\u5c0f\u3002"}}
{"id": "2507.15269", "pdf": "https://arxiv.org/pdf/2507.15269", "abs": "https://arxiv.org/abs/2507.15269", "authors": ["Fangqiu Yi", "Jingyu Xu", "Jiawei Shao", "Chi Zhang", "Xuelong Li"], "title": "Conditional Video Generation for High-Efficiency Video Compression", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Perceptual studies demonstrate that conditional diffusion models excel at\nreconstructing video content aligned with human visual perception. Building on\nthis insight, we propose a video compression framework that leverages\nconditional diffusion models for perceptually optimized reconstruction.\nSpecifically, we reframe video compression as a conditional generation task,\nwhere a generative model synthesizes video from sparse, yet informative\nsignals. Our approach introduces three key modules: (1) Multi-granular\nconditioning that captures both static scene structure and dynamic\nspatio-temporal cues; (2) Compact representations designed for efficient\ntransmission without sacrificing semantic richness; (3) Multi-condition\ntraining with modality dropout and role-aware embeddings, which prevent\nover-reliance on any single modality and enhance robustness. Extensive\nexperiments show that our method significantly outperforms both traditional and\nneural codecs on perceptual quality metrics such as Fr\\'echet Video Distance\n(FVD) and LPIPS, especially under high compression ratios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u89c6\u9891\u538b\u7f29\u6846\u67b6\uff0c\u5f15\u5165\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u611f\u77e5\u8d28\u91cf\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u548c\u795e\u7ecf\u7f16\u89e3\u7801\u5668\u3002", "motivation": "\u5229\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5728\u91cd\u5efa\u4e0e\u4eba\u7c7b\u89c6\u89c9\u611f\u77e5\u4e00\u81f4\u7684\u89c6\u9891\u5185\u5bb9\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u6784\u5efa\u611f\u77e5\u4f18\u5316\u7684\u89c6\u9891\u538b\u7f29\u6846\u67b6\u3002", "method": "\u5c06\u89c6\u9891\u538b\u7f29\u91cd\u6784\u4e3a\u6761\u4ef6\u751f\u6210\u4efb\u52a1\uff0c\u5f15\u5165\u591a\u7c92\u5ea6\u6761\u4ef6\u3001\u7d27\u51d1\u8868\u793a\u3001\u591a\u6761\u4ef6\u8bad\u7ec3\u4e09\u4e2a\u5173\u952e\u6a21\u5757\u3002", "result": "\u5728Fr\u00e9chet\u89c6\u9891\u8ddd\u79bb\uff08FVD\uff09\u548cLPIPS\u7b49\u611f\u77e5\u8d28\u91cf\u6307\u6807\u4e0a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u548c\u795e\u7ecf\u7f16\u89e3\u7801\u5668\uff0c\u5728\u9ad8\u538b\u7f29\u6bd4\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u89c6\u9891\u538b\u7f29\u6846\u67b6\u5728\u89c6\u9891\u611f\u77e5\u8d28\u91cf\u91cd\u5efa\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.15272", "pdf": "https://arxiv.org/pdf/2507.15272", "abs": "https://arxiv.org/abs/2507.15272", "authors": ["Ayush Singh Bhadoriya", "Abhishek Nikunj Shinde", "Isha Pandey", "Ganesh Ramakrishnan"], "title": "A2TTS: TTS for Low Resource Indian Languages", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": null, "summary": "We present a speaker conditioned text-to-speech (TTS) system aimed at\naddressing challenges in generating speech for unseen speakers and supporting\ndiverse Indian languages. Our method leverages a diffusion-based TTS\narchitecture, where a speaker encoder extracts embeddings from short reference\naudio samples to condition the DDPM decoder for multispeaker generation. To\nfurther enhance prosody and naturalness, we employ a cross-attention based\nduration prediction mechanism that utilizes reference audio, enabling more\naccurate and speaker consistent timing. This results in speech that closely\nresembles the target speaker while improving duration modeling and overall\nexpressiveness. Additionally, to improve zero-shot generation, we employed\nclassifier free guidance, allowing the system to generate speech more near\nspeech for unknown speakers. Using this approach, we trained language-specific\nspeaker-conditioned models. Using the IndicSUPERB dataset for multiple Indian\nlanguages such as Bengali, Gujarati, Hindi, Marathi, Malayalam, Punjabi and\nTamil.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6269\u6563\u7684\u8bf4\u8bdd\u4eba\u6761\u4ef6TTS\u7cfb\u7edf\uff0c\u89e3\u51b3\u672a\u89c1\u8bf4\u8bdd\u4eba\u8bed\u97f3\u751f\u6210\u548c\u591a\u5370\u5ea6\u8bed\u8a00\u652f\u6301\u95ee\u9898\uff0c\u5229\u7528\u591a\u79cd\u673a\u5236\u63d0\u5347\u6548\u679c\u5e76\u8fdb\u884c\u591a\u8bed\u8a00\u8bad\u7ec3\u3002", "motivation": "\u89e3\u51b3\u672a\u89c1\u8bf4\u8bdd\u4eba\u8bed\u97f3\u751f\u6210\u6311\u6218\u548c\u652f\u6301\u591a\u79cd\u5370\u5ea6\u8bed\u8a00\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6269\u6563\u7684TTS\u67b6\u6784\uff0c\u7528\u8bf4\u8bdd\u4eba\u7f16\u7801\u5668\u63d0\u53d6\u5d4c\u5165\uff0c\u4f7f\u7528\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u65f6\u957f\u9884\u6d4b\u673a\u5236\uff0c\u91c7\u7528\u5206\u7c7b\u5668\u65e0\u6307\u5bfc\u65b9\u6cd5\uff0c\u8bad\u7ec3\u7279\u5b9a\u8bed\u8a00\u7684\u8bf4\u8bdd\u4eba\u6761\u4ef6\u6a21\u578b\u3002", "result": "\u751f\u6210\u7684\u8bed\u97f3\u63a5\u8fd1\u76ee\u6807\u8bf4\u8bdd\u4eba\uff0c\u6539\u5584\u65f6\u957f\u5efa\u6a21\u548c\u6574\u4f53\u8868\u73b0\u529b\uff0c\u80fd\u66f4\u597d\u5730\u8fdb\u884c\u96f6\u6837\u672c\u751f\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u6709\u6548\u89e3\u51b3\u672a\u89c1\u8bf4\u8bdd\u4eba\u8bed\u97f3\u751f\u6210\u548c\u591a\u5370\u5ea6\u8bed\u8a00\u652f\u6301\u95ee\u9898\u3002"}}
{"id": "2507.15259", "pdf": "https://arxiv.org/pdf/2507.15259", "abs": "https://arxiv.org/abs/2507.15259", "authors": ["Kyung-Bin Kwon", "Sayak Mukherjee", "Ramij R. Hossain", "Marcelo Elizondo"], "title": "Physics-Informed Learning of Proprietary Inverter Models for Grid Dynamic Studies", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "7 pages, 5 figures", "summary": "This letter develops a novel physics-informed neural ordinary differential\nequations-based framework to emulate the proprietary dynamics of the inverters\n-- essential for improved accuracy in grid dynamic simulations. In current\nindustry practice, the original equipment manufacturers (OEMs) often do not\ndisclose the exact internal controls and parameters of the inverters, posing\nsignificant challenges in performing accurate dynamic simulations and other\nrelevant studies, such as gain tunings for stability analysis and controls. To\naddress this, we propose a Physics-Informed Latent Neural ODE Model (PI-LNM)\nthat integrates system physics with neural learning layers to capture the\nunmodeled behaviors of proprietary units. The proposed method is validated\nusing a grid-forming inverter (GFM) case study, demonstrating improved dynamic\nsimulation accuracy over approaches that rely solely on data-driven learning\nwithout physics-based guidance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u6846\u67b6\u6765\u6a21\u62df\u9006\u53d8\u5668\u4e13\u6709\u52a8\u6001\uff0c\u63d0\u5347\u7535\u7f51\u52a8\u6001\u4eff\u771f\u7cbe\u5ea6\u3002", "motivation": "\u5f53\u524d\u9006\u53d8\u5668\u5236\u9020\u5546\u5e38\u4e0d\u516c\u5f00\u5185\u90e8\u63a7\u5236\u548c\u53c2\u6570\uff0c\u7ed9\u7cbe\u786e\u52a8\u6001\u4eff\u771f\u53ca\u76f8\u5173\u7814\u7a76\u5e26\u6765\u6311\u6218\u3002", "method": "\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u6f5c\u5728\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\uff08PI - LNM\uff09\uff0c\u7ed3\u5408\u7cfb\u7edf\u7269\u7406\u4e0e\u795e\u7ecf\u5b66\u4e60\u5c42\u6355\u6349\u4e13\u6709\u5355\u5143\u672a\u5efa\u6a21\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u5e76\u7f51\u9006\u53d8\u5668\u6848\u4f8b\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u4ec5\u4f9d\u8d56\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u52a8\u6001\u4eff\u771f\u7cbe\u5ea6\u63d0\u9ad8\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u9006\u53d8\u5668\u4e13\u6709\u52a8\u6001\u6a21\u62df\u95ee\u9898\uff0c\u63d0\u5347\u7535\u7f51\u52a8\u6001\u4eff\u771f\u51c6\u786e\u6027\u3002"}}
{"id": "2507.15281", "pdf": "https://arxiv.org/pdf/2507.15281", "abs": "https://arxiv.org/abs/2507.15281", "authors": ["Haoran Sun", "Zekun Zhang", "Shaoning Zeng"], "title": "A Novel Self-Evolution Framework for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The capabilities of Large Language Models (LLMs) are limited to some extent\nby pre-training, so some researchers optimize LLMs through post-training.\nExisting post-training strategies, such as memory-based retrieval or preference\noptimization, improve user alignment yet fail to enhance the model's domain\ncognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution\n(DPSE) framework that jointly optimizes user preference adaptation and\ndomain-specific competence. DPSE introduces a Censor module to extract\nmulti-dimensional interaction signals and estimate satisfaction scores, which\nguide structured data expansion via topic-aware and preference-driven\nstrategies. These expanded datasets support a two-stage fine-tuning pipeline:\nsupervised domain grounding followed by frequency-aware preference\noptimization. Experiments across general NLP benchmarks and long-term dialogue\ntasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning,\nPreference Optimization, and Memory-Augmented baselines. Ablation studies\nvalidate the contribution of each module. In this way, our framework provides\nan autonomous path toward continual self-evolution of LLMs.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u7b56\u7565\u4e0d\u80fd\u63d0\u5347\u9886\u57df\u8ba4\u77e5\uff0c\u63d0\u51faDPSE\u6846\u67b6\u8054\u5408\u4f18\u5316\u7528\u6237\u504f\u597d\u9002\u914d\u548c\u7279\u5b9a\u9886\u57df\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u7b56\u7565\u65e0\u6cd5\u63d0\u5347\u6a21\u578b\u7684\u9886\u57df\u8ba4\u77e5\uff0c\u9700\u63d0\u51fa\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51faDual - Phase Self - Evolution (DPSE)\u6846\u67b6\uff0c\u5f15\u5165\u5ba1\u67e5\u6a21\u5757\u63d0\u53d6\u4fe1\u53f7\u548c\u4f30\u8ba1\u6ee1\u610f\u5ea6\u5f97\u5206\uff0c\u901a\u8fc7\u7b56\u7565\u6269\u5c55\u6570\u636e\uff0c\u652f\u6301\u4e24\u9636\u6bb5\u5fae\u8c03\u6d41\u7a0b\u3002", "result": "\u5728\u901a\u7528NLP\u57fa\u51c6\u548c\u957f\u671f\u5bf9\u8bdd\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cDPSE\u59cb\u7ec8\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u3001\u504f\u597d\u4f18\u5316\u548c\u8bb0\u5fc6\u589e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u5404\u6a21\u5757\u8d21\u732e\u3002", "conclusion": "DPSE\u6846\u67b6\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u81ea\u6211\u8fdb\u5316\u63d0\u4f9b\u4e86\u81ea\u4e3b\u9014\u5f84\u3002"}}
{"id": "2507.15264", "pdf": "https://arxiv.org/pdf/2507.15264", "abs": "https://arxiv.org/abs/2507.15264", "authors": ["Kuangyu Ding", "Kim-Chuan Toh"], "title": "On exploration of an interior mirror descent flow for stochastic nonconvex constrained problem", "categories": ["math.OC", "cs.LG"], "comment": "34 Pages", "summary": "We study a nonsmooth nonconvex optimization problem defined over nonconvex\nconstraints, where the feasible set is given by the intersection of the closure\nof an open set and a smooth manifold. By endowing the open set with a\nRiemannian metric induced by a barrier function, we obtain a Riemannian\nsubgradient flow formulated as a differential inclusion, which remains strictly\nwithin the interior of the feasible set. This continuous dynamical system\nunifies two classes of iterative optimization methods, namely the Hessian\nbarrier method and mirror descent scheme, by revealing that these methods can\nbe interpreted as discrete approximations of the continuous flow. We explore\nthe long-term behavior of the trajectories generated by this dynamical system\nand show that the existing deficient convergence properties of the Hessian\nbarrier and mirror descent scheme can be unifily and more insightfully\ninterpreted through these of the continuous trajectory. For instance, the\nnotorious spurious stationary points \\cite{chen2024spurious} observed in\nHessian barrier method and mirror descent scheme are interpreted as stable\nequilibria of the dynamical system that do not correspond to real stationary\npoints of the original optimization problem. We provide two sufficient\ncondition such that these spurious stationary points can be avoided if the\nstrict complementarity conditions holds. In the absence of these regularity\ncondition, we propose a random perturbation strategy that ensures the\ntrajectory converges (subsequentially) to an approximate stationary point.\nBuilding on these insights, we introduce two iterative Riemannian subgradient\nmethods, form of interior point methods, that generalizes the existing Hessian\nbarrier method and mirror descent scheme for solving nonsmooth nonconvex\noptimization problems.", "AI": {"tldr": "\u7814\u7a76\u975e\u51f8\u7ea6\u675f\u4e0b\u975e\u5149\u6ed1\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u9ece\u66fc\u6b21\u68af\u5ea6\u6d41\u7edf\u4e00\u4e24\u79cd\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\uff0c\u89e3\u91ca\u6536\u655b\u95ee\u9898\uff0c\u7ed9\u51fa\u907f\u514d\u4f2a\u9a7b\u70b9\u6761\u4ef6\u548c\u968f\u673a\u6270\u52a8\u7b56\u7565\uff0c\u5f15\u5165\u65b0\u8fed\u4ee3\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u975e\u51f8\u7ea6\u675f\u4e0b\u975e\u5149\u6ed1\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u7edf\u4e00\u73b0\u6709\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\u5e76\u89e3\u91ca\u5176\u6536\u655b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u969c\u788d\u51fd\u6570\u8bf1\u5bfc\u7684\u9ece\u66fc\u5ea6\u91cf\u5f97\u5230\u9ece\u66fc\u6b21\u68af\u5ea6\u6d41\uff0c\u63a2\u7d22\u5176\u8f68\u8ff9\u957f\u671f\u884c\u4e3a\uff0c\u7ed9\u51fa\u907f\u514d\u4f2a\u9a7b\u70b9\u6761\u4ef6\u548c\u968f\u673a\u6270\u52a8\u7b56\u7565\u3002", "result": "\u7edf\u4e00Hessian barrier\u65b9\u6cd5\u548cmirror descent\u65b9\u6848\uff0c\u89e3\u91ca\u5176\u6536\u655b\u95ee\u9898\uff0c\u7ed9\u51fa\u907f\u514d\u4f2a\u9a7b\u70b9\u6761\u4ef6\u548c\u968f\u673a\u6270\u52a8\u7b56\u7565\u3002", "conclusion": "\u5f15\u5165\u4e24\u79cd\u8fed\u4ee3\u9ece\u66fc\u6b21\u68af\u5ea6\u65b9\u6cd5\uff0c\u63a8\u5e7f\u73b0\u6709\u65b9\u6cd5\u7528\u4e8e\u89e3\u51b3\u975e\u5149\u6ed1\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2507.15339", "pdf": "https://arxiv.org/pdf/2507.15339", "abs": "https://arxiv.org/abs/2507.15339", "authors": ["Leanne Tan", "Gabriel Chua", "Ziyu Ge", "Roy Ka-Wei Lee"], "title": "LionGuard 2: Building Lightweight, Data-Efficient & Localised Multilingual Content Moderators", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Modern moderation systems increasingly support multiple languages, but often\nfail to address localisation and low-resource variants - creating safety gaps\nin real-world deployments. Small models offer a potential alternative to large\nLLMs, yet still demand considerable data and compute. We present LionGuard 2, a\nlightweight, multilingual moderation classifier tailored to the Singapore\ncontext, supporting English, Chinese, Malay, and partial Tamil. Built on\npre-trained OpenAI embeddings and a multi-head ordinal classifier, LionGuard 2\noutperforms several commercial and open-source systems across 17 benchmarks,\nincluding both Singapore-specific and public English datasets. The system is\nactively deployed within the Singapore Government, demonstrating practical\nefficacy at scale. Our findings show that high-quality local data and robust\nmultilingual embeddings can achieve strong moderation performance, without\nfine-tuning large models. We release our model weights and part of our training\ndata to support future work on LLM safety.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u591a\u8bed\u8a00\u5ba1\u6838\u5206\u7c7b\u5668LionGuard 2\uff0c\u9002\u7528\u4e8e\u65b0\u52a0\u5761\u573a\u666f\uff0c\u6027\u80fd\u4f18\u4e14\u5df2\u90e8\u7f72\uff0c\u8fd8\u53d1\u5e03\u90e8\u5206\u6570\u636e\u3002", "motivation": "\u73b0\u4ee3\u5ba1\u6838\u7cfb\u7edf\u672a\u89e3\u51b3\u672c\u5730\u5316\u548c\u4f4e\u8d44\u6e90\u53d8\u4f53\u95ee\u9898\uff0c\u5c0f\u6a21\u578b\u4e5f\u9700\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684OpenAI\u5d4c\u5165\u548c\u591a\u5934\u5e8f\u6570\u5206\u7c7b\u5668\u6784\u5efaLionGuard 2\u3002", "result": "LionGuard 2\u572817\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u591a\u4e2a\u5546\u4e1a\u548c\u5f00\u6e90\u7cfb\u7edf\uff0c\u5df2\u5728\u65b0\u52a0\u5761\u653f\u5e9c\u4e2d\u90e8\u7f72\u3002", "conclusion": "\u9ad8\u8d28\u91cf\u672c\u5730\u6570\u636e\u548c\u5f3a\u5927\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u65e0\u9700\u5fae\u8c03\u5927\u6a21\u578b\u5c31\u80fd\u5b9e\u73b0\u826f\u597d\u5ba1\u6838\u6027\u80fd\u3002"}}
{"id": "2507.15292", "pdf": "https://arxiv.org/pdf/2507.15292", "abs": "https://arxiv.org/abs/2507.15292", "authors": ["An Wanga", "Rulin Zhou", "Mengya Xu", "Yiru Ye", "Longfei Gou", "Yiting Chang", "Hao Chen", "Chwee Ming Lim", "Jiankun Wang", "Hongliang Ren"], "title": "EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Visualizing subtle vascular motions in endoscopic surgery is crucial for\nsurgical precision and decision-making, yet remains challenging due to the\ncomplex and dynamic nature of surgical scenes. To address this, we introduce\nEndoControlMag, a training-free, Lagrangian-based framework with\nmask-conditioned vascular motion magnification tailored to endoscopic\nenvironments. Our approach features two key modules: a Periodic Reference\nResetting (PRR) scheme that divides videos into short overlapping clips with\ndynamically updated reference frames to prevent error accumulation while\nmaintaining temporal coherence, and a Hierarchical Tissue-aware Magnification\n(HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores\nusing a pretrained visual tracking model to maintain accurate localization\ndespite occlusions and view changes. It then applies one of two adaptive\nsoftening strategies to surrounding tissues: motion-based softening that\nmodulates magnification strength proportional to observed tissue displacement,\nor distance-based exponential decay that simulates biomechanical force\nattenuation. This dual-mode approach accommodates diverse surgical\nscenarios-motion-based softening excels with complex tissue deformations while\ndistance-based softening provides stability during unreliable optical flow\nconditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four\ndifferent surgery types and various challenging scenarios, including\nocclusions, instrument disturbance, view changes, and vessel deformations.\nQuantitative metrics, visual assessments, and expert surgeon evaluations\ndemonstrate that EndoControlMag significantly outperforms existing methods in\nboth magnification accuracy and visual quality while maintaining robustness\nacross challenging surgical conditions. The code, dataset, and video results\nare available at https://szupc.github.io/EndoControlMag/.", "AI": {"tldr": "\u63d0\u51faEndoControlMag\u6846\u67b6\u7528\u4e8e\u53ef\u89c6\u5316\u5185\u955c\u624b\u672f\u4e2d\u7ec6\u5fae\u8840\u7ba1\u8fd0\u52a8\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u53ef\u89c6\u5316\u5185\u955c\u624b\u672f\u4e2d\u7ec6\u5fae\u8840\u7ba1\u8fd0\u52a8\u5bf9\u624b\u672f\u7cbe\u5ea6\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56e0\u624b\u672f\u573a\u666f\u590d\u6742\u52a8\u6001\u800c\u5177\u6311\u6218\u3002", "method": "\u5f15\u5165EndoControlMag\u6846\u67b6\uff0c\u542bPRR\u65b9\u6848\u548cHTM\u6846\u67b6\uff0cPRR\u9632\u6b62\u8bef\u5dee\u79ef\u7d2f\uff0cHTM\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8ddf\u8e2a\u8840\u7ba1\u6838\u5fc3\uff0c\u6709\u4e24\u79cd\u81ea\u9002\u5e94\u8f6f\u5316\u7b56\u7565\u3002", "result": "\u5728EndoVMM24\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cEndoControlMag\u5728\u653e\u5927\u7cbe\u5ea6\u3001\u89c6\u89c9\u8d28\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u590d\u6742\u624b\u672f\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "EndoControlMag\u662f\u4e00\u79cd\u6709\u6548\u4e14\u9c81\u68d2\u7684\u5185\u955c\u624b\u672f\u8840\u7ba1\u8fd0\u52a8\u53ef\u89c6\u5316\u65b9\u6cd5\u3002"}}
{"id": "2507.15347", "pdf": "https://arxiv.org/pdf/2507.15347", "abs": "https://arxiv.org/abs/2507.15347", "authors": ["Amedeo Buonanno", "Alessandro Rivetti", "Francesco A. N. Palmieri", "Giovanni Di Gennaro", "Gianmarco Romano"], "title": "Probing Information Distribution in Transformer Architectures through Entropy Analysis", "categories": ["cs.CL", "cs.LG"], "comment": "Presented to the Italian Workshop on Neural Networks (WIRN2025) and\n  it will appear in a Springer Chapter", "summary": "This work explores entropy analysis as a tool for probing information\ndistribution within Transformer-based architectures. By quantifying token-level\nuncertainty and examining entropy patterns across different stages of\nprocessing, we aim to investigate how information is managed and transformed\nwithin these models. As a case study, we apply the methodology to a GPT-based\nlarge language model, illustrating its potential to reveal insights into model\nbehavior and internal representations. This approach may offer insights into\nmodel behavior and contribute to the development of interpretability and\nevaluation frameworks for transformer-based models", "AI": {"tldr": "\u63a2\u7d22\u71b5\u5206\u6790\u4f5c\u4e3a\u63a2\u6d4bTransformer\u67b6\u6784\u4fe1\u606f\u5206\u5e03\u7684\u5de5\u5177\uff0c\u4ee5GPT\u6a21\u578b\u4e3a\u4f8b\u5c55\u793a\u5176\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76Transformer\u67b6\u6784\u5185\u4fe1\u606f\u5982\u4f55\u7ba1\u7406\u548c\u8f6c\u6362\uff0c\u4e3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u8bc4\u4f30\u6846\u67b6\u53d1\u5c55\u63d0\u4f9b\u5e2e\u52a9\u3002", "method": "\u91cf\u5316token\u7ea7\u522b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u68c0\u67e5\u4e0d\u540c\u5904\u7406\u9636\u6bb5\u7684\u71b5\u6a21\u5f0f\uff0c\u5e76\u5e94\u7528\u5230GPT\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u3002", "result": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u63ed\u793a\u6a21\u578b\u884c\u4e3a\u548c\u5185\u90e8\u8868\u793a\u7684\u6f5c\u529b\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u884c\u4e3a\uff0c\u5bf9Transformer\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u8bc4\u4f30\u6846\u67b6\u53d1\u5c55\u6709\u8d21\u732e\u3002"}}
{"id": "2507.15355", "pdf": "https://arxiv.org/pdf/2507.15355", "abs": "https://arxiv.org/abs/2507.15355", "authors": ["Zhipeng Li", "Yi-Chi Liao", "Christian Holz"], "title": "Efficient Visual Appearance Optimization by Learning from Prior Preferences", "categories": ["cs.HC", "cs.LG"], "comment": "24 pages, UIST'25", "summary": "Adjusting visual parameters such as brightness and contrast is common in our\neveryday experiences. Finding the optimal parameter setting is challenging due\nto the large search space and the lack of an explicit objective function,\nleaving users to rely solely on their implicit preferences. Prior work has\nexplored Preferential Bayesian Optimization (PBO) to address this challenge,\ninvolving users to iteratively select preferred designs from candidate sets.\nHowever, PBO often requires many rounds of preference comparisons, making it\nmore suitable for designers than everyday end-users. We propose Meta-PO, a\nnovel method that integrates PBO with meta-learning to improve sample\nefficiency. Specifically, Meta-PO infers prior users' preferences and stores\nthem as models, which are leveraged to intelligently suggest design candidates\nfor the new users, enabling faster convergence and more personalized results.\nAn experimental evaluation of our method for appearance design tasks on 2D and\n3D content showed that participants achieved satisfactory appearance in 5.86\niterations using Meta-PO when participants shared similar goals with a\npopulation (e.g., tuning for a ``warm'' look) and in 8 iterations even\ngeneralizes across divergent goals (e.g., from ``vintage'', ``warm'', to\n``holiday''). Meta-PO makes personalized visual optimization more applicable to\nend-users through a generalizable, more efficient optimization conditioned on\npreferences, with the potential to scale interface personalization more\nbroadly.", "AI": {"tldr": "\u63d0\u51faMeta - PO\u65b9\u6cd5\u7ed3\u5408PBO\u4e0e\u5143\u5b66\u4e60\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u8ba9\u7528\u6237\u66f4\u5feb\u83b7\u5f97\u6ee1\u610f\u5916\u89c2\uff0c\u4f7f\u4e2a\u6027\u5316\u89c6\u89c9\u4f18\u5316\u66f4\u9002\u7528\u4e8e\u7ec8\u7aef\u7528\u6237\u3002", "motivation": "\u8c03\u6574\u89c6\u89c9\u53c2\u6570\u627e\u6700\u4f18\u8bbe\u7f6e\u5177\u6311\u6218\u6027\uff0c\u73b0\u6709PBO\u65b9\u6cd5\u9700\u591a\u8f6e\u6bd4\u8f83\uff0c\u66f4\u9002\u5408\u8bbe\u8ba1\u5e08\uff0c\u8981\u8ba9\u65b9\u6cd5\u9002\u7528\u4e8e\u666e\u901a\u7ec8\u7aef\u7528\u6237\u3002", "method": "\u63d0\u51faMeta - PO\u65b9\u6cd5\uff0c\u63a8\u65ad\u5e76\u5b58\u50a8\u5148\u524d\u7528\u6237\u504f\u597d\u4e3a\u6a21\u578b\uff0c\u7528\u5176\u4e3a\u65b0\u7528\u6237\u667a\u80fd\u63a8\u8350\u8bbe\u8ba1\u5019\u9009\u3002", "result": "\u57282D\u548c3D\u5185\u5bb9\u5916\u89c2\u8bbe\u8ba1\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c\u76ee\u6807\u76f8\u4f3c\u65f65.86\u6b21\u8fed\u4ee3\u3001\u76ee\u6807\u4e0d\u540c\u65f68\u6b21\u8fed\u4ee3\u7528\u6237\u53ef\u83b7\u6ee1\u610f\u5916\u89c2\u3002", "conclusion": "Meta - PO\u901a\u8fc7\u57fa\u4e8e\u504f\u597d\u7684\u9ad8\u6548\u4f18\u5316\u4f7f\u4e2a\u6027\u5316\u89c6\u89c9\u4f18\u5316\u66f4\u9002\u7528\u4e8e\u7ec8\u7aef\u7528\u6237\uff0c\u6709\u6269\u5c55\u754c\u9762\u4e2a\u6027\u5316\u6f5c\u529b\u3002"}}
{"id": "2507.15335", "pdf": "https://arxiv.org/pdf/2507.15335", "abs": "https://arxiv.org/abs/2507.15335", "authors": ["Muhammad Aqeel", "Federico Leonardi", "Francesco Setti"], "title": "ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICIAP 2025", "summary": "Industrial defect detection systems face critical limitations when confined\nto one-class anomaly detection paradigms, which assume uniform outlier\ndistributions and struggle with data scarcity in realworld manufacturing\nenvironments. We present ExDD (Explicit Dual Distribution), a novel framework\nthat transcends these limitations by explicitly modeling dual feature\ndistributions. Our approach leverages parallel memory banks that capture the\ndistinct statistical properties of both normality and anomalous patterns,\naddressing the fundamental flaw of uniform outlier assumptions. To overcome\ndata scarcity, we employ latent diffusion models with domain-specific textual\nconditioning, generating in-distribution synthetic defects that preserve\nindustrial context. Our neighborhood-aware ratio scoring mechanism elegantly\nfuses complementary distance metrics, amplifying signals in regions exhibiting\nboth deviation from normality and similarity to known defect patterns.\nExperimental validation on KSDD2 demonstrates superior performance (94.2%\nI-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.", "AI": {"tldr": "\u63d0\u51faExDD\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u53cc\u7279\u5f81\u5206\u5e03\u514b\u670d\u5de5\u4e1a\u7f3a\u9677\u68c0\u6d4b\u4e2d\u4e00\u7c7b\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\u7684\u5c40\u9650\uff0c\u5229\u7528\u591a\u79cd\u65b9\u6cd5\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u7b49\u95ee\u9898\uff0c\u5728KSDD2\u4e0a\u5b9e\u9a8c\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u5de5\u4e1a\u7f3a\u9677\u68c0\u6d4b\u7cfb\u7edf\u91c7\u7528\u4e00\u7c7b\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\u5b58\u5728\u5c40\u9650\uff0c\u5982\u5047\u8bbe\u5f02\u5e38\u5206\u5e03\u5747\u5300\u3001\u5728\u73b0\u5b9e\u5236\u9020\u73af\u5883\u4e2d\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u63d0\u51faExDD\u6846\u67b6\uff0c\u5229\u7528\u5e76\u884c\u5185\u5b58\u5e93\u6355\u6349\u6b63\u5e38\u548c\u5f02\u5e38\u6a21\u5f0f\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u91c7\u7528\u5e26\u7279\u5b9a\u9886\u57df\u6587\u672c\u6761\u4ef6\u7684\u6f5c\u5728\u6269\u6563\u6a21\u578b\u751f\u6210\u5408\u6210\u7f3a\u9677\uff0c\u4f7f\u7528\u90bb\u57df\u611f\u77e5\u6bd4\u7387\u8bc4\u5206\u673a\u5236\u878d\u5408\u8ddd\u79bb\u5ea6\u91cf\u3002", "result": "\u5728KSDD2\u4e0a\u5b9e\u9a8c\uff0cI - AUROC\u8fbe94.2%\uff0cP - AUROC\u8fbe97.7%\uff0c100\u4e2a\u5408\u6210\u6837\u672c\u65f6\u589e\u5f3a\u6548\u679c\u6700\u4f73\u3002", "conclusion": "ExDD\u6846\u67b6\u80fd\u6709\u6548\u514b\u670d\u73b0\u6709\u5de5\u4e1a\u7f3a\u9677\u68c0\u6d4b\u7cfb\u7edf\u7684\u5c40\u9650\uff0c\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.15364", "pdf": "https://arxiv.org/pdf/2507.15364", "abs": "https://arxiv.org/abs/2507.15364", "authors": ["Ruifeng Zheng", "Cong Chen", "Shuang Wang", "Yiming Liu", "Lin You", "Jindong Lu", "Ruizhe Zhu", "Guodao Zhang", "Kejie Huang"], "title": "EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure\nonsets can significantly impact patients' quality of life and health. However,\nwearable seizure-predicting devices are still limited, partly due to the bulky\nsize of EEG-collecting devices. To relieve the problem, we proposed a novel\ntwo-stage channel-aware Set Transformer Network that could perform seizure\nprediction with fewer EEG channel sensors. We also tested a seizure-independent\ndivision method which could prevent the adjacency of training and test data.\nExperiments were performed on the CHB-MIT dataset which includes 22 patients\nwith 88 merged seizures. The mean sensitivity before channel selection was\n76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection,\ndominant channels emerged in 20 out of 22 patients; the average number of\nchannels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1%\nwith an FPR of 0.11/hour. Furthermore, experimental results on the\nseizure-independent division supported our assertion that a more rigorous\nseizure-independent division should be used for patients with abundant EEG\nrecordings.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u901a\u9053\u611f\u77e5\u96c6\u53d8\u6362\u5668\u7f51\u7edc\u7528\u66f4\u5c11EEG\u901a\u9053\u4f20\u611f\u5668\u8fdb\u884c\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\uff0c\u6d4b\u8bd5\u72ec\u7acb\u53d1\u4f5c\u5212\u5206\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u53ef\u7a7f\u6234\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u8bbe\u5907\u56e0EEG\u91c7\u96c6\u8bbe\u5907\u4f53\u79ef\u5927\u53d7\u9650\uff0c\u9700\u51cf\u5c11EEG\u901a\u9053\u4f20\u611f\u5668\u8fdb\u884c\u53d1\u4f5c\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u901a\u9053\u611f\u77e5\u96c6\u53d8\u6362\u5668\u7f51\u7edc\uff0c\u6d4b\u8bd5\u72ec\u7acb\u53d1\u4f5c\u5212\u5206\u65b9\u6cd5\uff0c\u5728CHB - MIT\u6570\u636e\u96c6\u5b9e\u9a8c\u3002", "result": "\u901a\u9053\u9009\u62e9\u524d\u5e73\u5747\u654f\u611f\u5ea676.4%\uff0cFPR 0.09/\u5c0f\u65f6\uff1b\u9009\u62e9\u540e22\u4e2a\u60a3\u8005\u4e2d20\u4e2a\u51fa\u73b0\u4e3b\u5bfc\u901a\u9053\uff0c\u5e73\u5747\u901a\u9053\u6570\u4ece18\u51cf\u81f32.8\uff0c\u5e73\u5747\u654f\u611f\u5ea6\u5347\u81f380.1%\uff0cFPR 0.11/\u5c0f\u65f6\uff1b\u72ec\u7acb\u53d1\u4f5c\u5212\u5206\u5b9e\u9a8c\u652f\u6301\u4f7f\u7528\u66f4\u4e25\u683c\u5212\u5206\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u7f51\u7edc\u80fd\u4ee5\u66f4\u5c11EEG\u901a\u9053\u4f20\u611f\u5668\u8fdb\u884c\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\uff0c\u6709\u5927\u91cfEEG\u8bb0\u5f55\u60a3\u8005\u5e94\u91c7\u7528\u66f4\u4e25\u683c\u72ec\u7acb\u53d1\u4f5c\u5212\u5206\u65b9\u6cd5\u3002"}}
{"id": "2507.15340", "pdf": "https://arxiv.org/pdf/2507.15340", "abs": "https://arxiv.org/abs/2507.15340", "authors": ["Marc Boubnovski Martell", "Kristofer Linton-Reid", "Mitchell Chen", "Sumeet Hindocha", "Benjamin Hunter", "Marco A. Calzado", "Richard Lee", "Joram M. Posma", "Eric O. Aboagye"], "title": "MedSR-Impact: Transformer-Based Super-Resolution for Lung CT Segmentation, Radiomics, Classification, and Prognosis", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "High-resolution volumetric computed tomography (CT) is essential for accurate\ndiagnosis and treatment planning in thoracic diseases; however, it is limited\nby radiation dose and hardware costs. We present the Transformer Volumetric\nSuper-Resolution Network (\\textbf{TVSRN-V2}), a transformer-based\nsuper-resolution (SR) framework designed for practical deployment in clinical\nlung CT analysis. Built from scalable components, including Through-Plane\nAttention Blocks (TAB) and Swin Transformer V2 -- our model effectively\nreconstructs fine anatomical details in low-dose CT volumes and integrates\nseamlessly with downstream analysis pipelines. We evaluate its effectiveness on\nthree critical lung cancer tasks -- lobe segmentation, radiomics, and prognosis\n-- across multiple clinical cohorts. To enhance robustness across variable\nacquisition protocols, we introduce pseudo-low-resolution augmentation,\nsimulating scanner diversity without requiring private data. TVSRN-V2\ndemonstrates a significant improvement in segmentation accuracy (+4\\% Dice),\nhigher radiomic feature reproducibility, and enhanced predictive performance\n(+0.06 C-index and AUC). These results indicate that SR-driven recovery of\nstructural detail significantly enhances clinical decision support, positioning\nTVSRN-V2 as a well-engineered, clinically viable system for dose-efficient\nimaging and quantitative analysis in real-world CT workflows.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u8d85\u5206\u8fa8\u7387\u6846\u67b6TVSRN - V2\u7528\u4e8e\u4e34\u5e8a\u80ba\u90e8CT\u5206\u6790\uff0c\u5728\u591a\u4efb\u52a1\u8bc4\u4f30\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u53ef\u63d0\u5347\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387\u80ba\u90e8CT\u53d7\u8f90\u5c04\u5242\u91cf\u548c\u786c\u4ef6\u6210\u672c\u9650\u5236\uff0c\u9700\u8981\u66f4\u597d\u7684\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u7528\u4e8e\u4e34\u5e8a\u5206\u6790\u3002", "method": "\u6784\u5efa\u5305\u542bThrough - Plane Attention Blocks\u548cSwin Transformer V2\u7684TVSRN - V2\u6a21\u578b\uff0c\u5728\u591a\u4e34\u5e8a\u961f\u5217\u7684\u4e09\u9879\u80ba\u764c\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0c\u5f15\u5165\u4f2a\u4f4e\u5206\u8fa8\u7387\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "\u5728\u5206\u5272\u51c6\u786e\u6027\u3001\u653e\u5c04\u7ec4\u5b66\u7279\u5f81\u53ef\u91cd\u590d\u6027\u548c\u9884\u6d4b\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "TVSRN - V2\u662f\u9002\u7528\u4e8e\u73b0\u5b9eCT\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u5242\u91cf\u9ad8\u6548\u6210\u50cf\u548c\u5b9a\u91cf\u5206\u6790\u7684\u4e34\u5e8a\u53ef\u884c\u7cfb\u7edf\u3002"}}
{"id": "2507.15460", "pdf": "https://arxiv.org/pdf/2507.15460", "abs": "https://arxiv.org/abs/2507.15460", "authors": ["Mehdi Khalaj", "Shahrzad Golestani Najafabadi", "Julita Vassileva"], "title": "Privacy-Preserving Multimodal News Recommendation through Federated Learning", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "Personalized News Recommendation systems (PNR) have emerged as a solution to\ninformation overload by predicting and suggesting news items tailored to\nindividual user interests. However, traditional PNR systems face several\nchallenges, including an overreliance on textual content, common neglect of\nshort-term user interests, and significant privacy concerns due to centralized\ndata storage. This paper addresses these issues by introducing a novel\nmultimodal federated learning-based approach for news recommendation. First, it\nintegrates both textual and visual features of news items using a multimodal\nmodel, enabling a more comprehensive representation of content. Second, it\nemploys a time-aware model that balances users' long-term and short-term\ninterests through multi-head self-attention networks, improving recommendation\naccuracy. Finally, to enhance privacy, a federated learning framework is\nimplemented, enabling collaborative model training without sharing user data.\nThe framework divides the recommendation model into a large server-maintained\nnews model and a lightweight user model shared between the server and clients.\nThe client requests news representations (vectors) and a user model from the\ncentral server, then computes gradients with user local data, and finally sends\ntheir locally computed gradients to the server for aggregation. The central\nserver aggregates gradients to update the global user model and news model. The\nupdated news model is further used to infer news representation by the server.\nTo further safeguard user privacy, a secure aggregation algorithm based on\nShamir's secret sharing is employed. Experiments on a real-world news dataset\ndemonstrate strong performance compared to existing systems, representing a\nsignificant advancement in privacy-preserving personalized news recommendation.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u57fa\u4e8e\u591a\u6a21\u6001\u8054\u90a6\u5b66\u4e60\u7684\u65b0\u95fb\u63a8\u8350\u65b9\u6cd5\uff0c\u6574\u5408\u6587\u672c\u4e0e\u89c6\u89c9\u7279\u5f81\u3001\u5e73\u8861\u7528\u6237\u957f\u77ed\u5174\u8da3\u3001\u4fdd\u969c\u9690\u79c1\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u4e2a\u6027\u5316\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u4f9d\u8d56\u6587\u672c\u3001\u5ffd\u89c6\u77ed\u671f\u5174\u8da3\u548c\u9690\u79c1\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001\u6a21\u578b\u6574\u5408\u65b0\u95fb\u6587\u672c\u4e0e\u89c6\u89c9\u7279\u5f81\uff1b\u7528\u65f6\u95f4\u611f\u77e5\u6a21\u578b\u901a\u8fc7\u591a\u5934\u81ea\u6ce8\u610f\u529b\u7f51\u7edc\u5e73\u8861\u7528\u6237\u957f\u77ed\u5174\u8da3\uff1b\u5b9e\u65bd\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u5b89\u5168\u805a\u5408\u7b97\u6cd5\u4fdd\u969c\u9690\u79c1\u3002", "result": "\u5728\u771f\u5b9e\u65b0\u95fb\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u9690\u79c1\u4fdd\u62a4\u4e2a\u6027\u5316\u65b0\u95fb\u63a8\u8350\u7684\u91cd\u5927\u8fdb\u6b65\u3002"}}
{"id": "2507.15478", "pdf": "https://arxiv.org/pdf/2507.15478", "abs": "https://arxiv.org/abs/2507.15478", "authors": ["Simon Kohaut", "Felix Divo", "Navid Hamid", "Benedict Flade", "Julian Eggert", "Devendra Singh Dhami", "Kristian Kersting"], "title": "The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring reliable and rule-compliant behavior of autonomous agents in\nuncertain environments remains a fundamental challenge in modern robotics. Our\nwork shows how neuro-symbolic systems, which integrate probabilistic, symbolic\nwhite-box reasoning models with deep learning methods, offer a powerful\nsolution to this challenge. This enables the simultaneous consideration of\nexplicit rules and neural models trained on noisy data, combining the strength\nof structured reasoning with flexible representations. To this end, we\nintroduce the Constitutional Controller (CoCo), a novel framework designed to\nenhance the safety and reliability of agents by reasoning over deep\nprobabilistic logic programs representing constraints such as those found in\nshared traffic spaces. Furthermore, we propose the concept of self-doubt,\nimplemented as a probability density conditioned on doubt features such as\ntravel velocity, employed sensors, or health factors. In a real-world aerial\nmobility study, we demonstrate CoCo's advantages for intelligent autonomous\nsystems to learn appropriate doubts and navigate complex and uncertain\nenvironments safely and compliantly.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u53ef\u89e3\u51b3\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u53ef\u9760\u548c\u5408\u89c4\u884c\u4e3a\u7684\u6311\u6218\uff0c\u63d0\u51faConstitutional Controller (CoCo)\u6846\u67b6\u548c\u81ea\u6211\u6000\u7591\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u52bf\u3002", "motivation": "\u89e3\u51b3\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u786e\u4fdd\u53ef\u9760\u548c\u5408\u89c4\u884c\u4e3a\u7684\u6311\u6218\u3002", "method": "\u5f15\u5165CoCo\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u8868\u793a\u7ea6\u675f\u7684\u6df1\u5ea6\u6982\u7387\u903b\u8f91\u7a0b\u5e8f\u8fdb\u884c\u63a8\u7406\uff1b\u63d0\u51fa\u81ea\u6211\u6000\u7591\u6982\u5ff5\uff0c\u4ee5\u57fa\u4e8e\u6000\u7591\u7279\u5f81\u7684\u6982\u7387\u5bc6\u5ea6\u5b9e\u73b0\u3002", "result": "\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u7a7a\u4e2d\u79fb\u52a8\u6027\u7814\u7a76\u4e2d\uff0c\u8bc1\u660eCoCo\u80fd\u8ba9\u667a\u80fd\u81ea\u4e3b\u7cfb\u7edf\u5b66\u4e60\u9002\u5f53\u7684\u6000\u7591\uff0c\u5b89\u5168\u5408\u89c4\u5730\u5bfc\u822a\u590d\u6742\u4e0d\u786e\u5b9a\u73af\u5883\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u7ed3\u5408CoCo\u6846\u67b6\u548c\u81ea\u6211\u6000\u7591\u6982\u5ff5\uff0c\u662f\u89e3\u51b3\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u53ef\u9760\u548c\u5408\u89c4\u884c\u4e3a\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2507.15485", "pdf": "https://arxiv.org/pdf/2507.15485", "abs": "https://arxiv.org/abs/2507.15485", "authors": ["Robin Labryga", "Tomislav Prusina", "S\u00f6ren Laue"], "title": "Information Preserving Line Search via Bayesian Optimization", "categories": ["math.OC", "cs.LG"], "comment": "Accepted for publication at: LION 19: Learning and Intelligent\n  Optimization, 19th International Conference, Prague, 2025 (Springer LNCS).\n  This is the preprint version (DOI to be added when available)", "summary": "Line search is a fundamental part of iterative optimization methods for\nunconstrained and bound-constrained optimization problems to determine suitable\nstep lengths that provide sufficient improvement in each iteration. Traditional\nline search methods are based on iterative interval refinement, where valuable\ninformation about function value and gradient is discarded in each iteration.\nWe propose a line search method via Bayesian optimization, preserving and\nutilizing otherwise discarded information to improve step-length choices. Our\napproach is guaranteed to converge and shows superior performance compared to\nstate-of-the-art methods based on empirical tests on the challenging\nunconstrained and bound-constrained optimization problems from the CUTEst test\nset.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u7ebf\u641c\u7d22\u65b9\u6cd5\uff0c\u5728CUTEst\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u4fdd\u8bc1\u6536\u655b\u3002", "motivation": "\u4f20\u7edf\u7ebf\u641c\u7d22\u65b9\u6cd5\u5728\u8fed\u4ee3\u533a\u95f4\u7ec6\u5316\u8fc7\u7a0b\u4e2d\u4f1a\u4e22\u5f03\u51fd\u6570\u503c\u548c\u68af\u5ea6\u7684\u6709\u4ef7\u503c\u4fe1\u606f\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u7ebf\u641c\u7d22\u65b9\u6cd5\uff0c\u4fdd\u7559\u5e76\u5229\u7528\u4f20\u7edf\u65b9\u6cd5\u4e2d\u4e22\u5f03\u7684\u4fe1\u606f\u6765\u9009\u62e9\u6b65\u957f\u3002", "result": "\u5728CUTEst\u6d4b\u8bd5\u96c6\u4e0a\u7684\u5177\u6709\u6311\u6218\u6027\u7684\u65e0\u7ea6\u675f\u548c\u8fb9\u754c\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u7684\u5b9e\u8bc1\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ebf\u641c\u7d22\u65b9\u6cd5\u4fdd\u8bc1\u6536\u655b\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.15357", "pdf": "https://arxiv.org/pdf/2507.15357", "abs": "https://arxiv.org/abs/2507.15357", "authors": ["Elisa Sanchez-Bayona", "Rodrigo Agerri"], "title": "Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper presents a comprehensive evaluation of the capabilities of Large\nLanguage Models (LLMs) in metaphor interpretation across multiple datasets,\ntasks, and prompt configurations. Although metaphor processing has gained\nsignificant attention in Natural Language Processing (NLP), previous research\nhas been limited to single-dataset evaluations and specific task settings,\noften using artificially constructed data through lexical replacement. We\naddress these limitations by conducting extensive experiments using diverse\npublicly available datasets with inference and metaphor annotations, focusing\non Natural Language Inference (NLI) and Question Answering (QA) tasks. The\nresults indicate that LLMs' performance is more influenced by features like\nlexical overlap and sentence length than by metaphorical content, demonstrating\nthat any alleged emergent abilities of LLMs to understand metaphorical language\nare the result of a combination of surface-level features, in-context learning,\nand linguistic knowledge. This work provides critical insights into the current\ncapabilities and limitations of LLMs in processing figurative language,\nhighlighting the need for more realistic evaluation frameworks in metaphor\ninterpretation tasks. Data and code are publicly available.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9690\u55bb\u89e3\u91ca\u65b9\u9762\u7684\u80fd\u529b\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u53d1\u73b0\u5176\u8868\u73b0\u53d7\u8868\u5c42\u7279\u5f81\u5f71\u54cd\uff0c\u5f3a\u8c03\u9700\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u4ee5\u5f80\u9690\u55bb\u5904\u7406\u7814\u7a76\u5c40\u9650\u4e8e\u5355\u6570\u636e\u96c6\u8bc4\u4f30\u548c\u7279\u5b9a\u4efb\u52a1\u8bbe\u7f6e\uff0c\u4f7f\u7528\u4eba\u5de5\u6784\u9020\u6570\u636e\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u3002", "method": "\u5229\u7528\u591a\u4e2a\u542b\u63a8\u7406\u548c\u9690\u55bb\u6ce8\u91ca\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u548c\u95ee\u7b54\u4efb\u52a1\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u66f4\u591a\u53d7\u8bcd\u6c47\u91cd\u53e0\u548c\u53e5\u5b50\u957f\u5ea6\u7b49\u7279\u5f81\u5f71\u54cd\uff0c\u6240\u8c13\u7406\u89e3\u9690\u55bb\u8bed\u8a00\u7684\u80fd\u529b\u662f\u8868\u5c42\u7279\u5f81\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u8bed\u8a00\u77e5\u8bc6\u7684\u7efc\u5408\u7ed3\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u6bd4\u55bb\u6027\u8bed\u8a00\u7684\u80fd\u529b\u548c\u5c40\u9650\uff0c\u5f3a\u8c03\u9690\u55bb\u89e3\u91ca\u4efb\u52a1\u9700\u8981\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2507.15496", "pdf": "https://arxiv.org/pdf/2507.15496", "abs": "https://arxiv.org/abs/2507.15496", "authors": ["JunYing Huang", "Ao Xu", "DongSun Yong", "KeRen Li", "YuanFeng Wang", "Qi Qin"], "title": "Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Odometry is a critical task for autonomous systems for self-localization and\nnavigation. We propose a novel LiDAR-Visual odometry framework that integrates\nLiDAR point clouds and images for accurate and robust pose estimation. Our\nmethod utilizes a dense-depth map estimated from point clouds and images\nthrough depth completion, and incorporates a multi-scale feature extraction\nnetwork with attention mechanisms, enabling adaptive depth-aware\nrepresentations. Furthermore, we leverage dense depth information to refine\nflow estimation and mitigate errors in occlusion-prone regions. Our\nhierarchical pose refinement module optimizes motion estimation progressively,\nensuring robust predictions against dynamic environments and scale ambiguities.\nComprehensive experiments on the KITTI odometry benchmark demonstrate that our\napproach achieves similar or superior accuracy and robustness compared to\nstate-of-the-art visual and LiDAR odometry methods.", "AI": {"tldr": "\u63d0\u51fa\u878d\u5408LiDAR\u70b9\u4e91\u548c\u56fe\u50cf\u7684\u91cc\u7a0b\u8ba1\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u51c6\u786e\u9c81\u68d2\u3002", "motivation": "\u91cc\u7a0b\u8ba1\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u7684\u81ea\u5b9a\u4f4d\u548c\u5bfc\u822a\u81f3\u5173\u91cd\u8981\uff0c\u9700\u51c6\u786e\u9c81\u68d2\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6df1\u5ea6\u8865\u5168\u4f30\u8ba1\u7684\u5bc6\u96c6\u6df1\u5ea6\u56fe\uff0c\u7ed3\u5408\u5e26\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff1b\u5229\u7528\u5bc6\u96c6\u6df1\u5ea6\u4fe1\u606f\u4f18\u5316\u5149\u6d41\u4f30\u8ba1\uff1b\u4f7f\u7528\u5206\u5c42\u4f4d\u59ff\u7ec6\u5316\u6a21\u5757\u9010\u6b65\u4f18\u5316\u8fd0\u52a8\u4f30\u8ba1\u3002", "result": "\u5728KITTI\u91cc\u7a0b\u8ba1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e0e\u73b0\u6709\u89c6\u89c9\u548cLiDAR\u91cc\u7a0b\u8ba1\u65b9\u6cd5\u76f8\u4f3c\u6216\u66f4\u4f18\u7684\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LiDAR - \u89c6\u89c9\u91cc\u7a0b\u8ba1\u6846\u67b6\u51c6\u786e\u4e14\u9c81\u68d2\u3002"}}
{"id": "2507.15361", "pdf": "https://arxiv.org/pdf/2507.15361", "abs": "https://arxiv.org/abs/2507.15361", "authors": ["Muhammad Aqeel", "Maham Nazir", "Zanxi Ruan", "Francesco Setti"], "title": "Latent Space Synergy: Text-Guided Data Augmentation for Direct Diffusion Biomedical Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted to CVGMMI Workshop at ICIAP 2025", "summary": "Medical image segmentation suffers from data scarcity, particularly in polyp\ndetection where annotation requires specialized expertise. We present SynDiff,\na framework combining text-guided synthetic data generation with efficient\ndiffusion-based segmentation. Our approach employs latent diffusion models to\ngenerate clinically realistic synthetic polyps through text-conditioned\ninpainting, augmenting limited training data with semantically diverse samples.\nUnlike traditional diffusion methods requiring iterative denoising, we\nintroduce direct latent estimation enabling single-step inference with T x\ncomputational speedup. On CVC-ClinicDB, SynDiff achieves 96.0% Dice and 92.9%\nIoU while maintaining real-time capability suitable for clinical deployment.\nThe framework demonstrates that controlled synthetic augmentation improves\nsegmentation robustness without distribution shift. SynDiff bridges the gap\nbetween data-hungry deep learning models and clinical constraints, offering an\nefficient solution for deployment in resourcelimited medical settings.", "AI": {"tldr": "\u63d0\u51faSynDiff\u6846\u67b6\u7ed3\u5408\u6587\u672c\u5f15\u5bfc\u5408\u6210\u6570\u636e\u751f\u6210\u4e0e\u9ad8\u6548\u6269\u6563\u5206\u5272\uff0c\u89e3\u51b3\u533b\u5b66\u56fe\u50cf\u5206\u5272\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5728CVC - ClinicDB\u4e0a\u6548\u679c\u597d\u4e14\u9002\u5408\u4e34\u5e8a\u90e8\u7f72\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u5206\u5272\u5b58\u5728\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5c24\u5176\u662f\u606f\u8089\u68c0\u6d4b\u4e2d\u6ce8\u91ca\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u3002", "method": "\u91c7\u7528\u6f5c\u5728\u6269\u6563\u6a21\u578b\u901a\u8fc7\u6587\u672c\u6761\u4ef6\u4fee\u590d\u751f\u6210\u4e34\u5e8a\u903c\u771f\u7684\u5408\u6210\u606f\u8089\uff0c\u5f15\u5165\u76f4\u63a5\u6f5c\u5728\u4f30\u8ba1\u5b9e\u73b0\u5355\u6b65\u63a8\u7406\u3002", "result": "\u5728CVC - ClinicDB\u4e0a\u8fbe\u523096.0%\u7684Dice\u548c92.9%\u7684IoU\uff0c\u4fdd\u6301\u5b9e\u65f6\u6027\u9002\u5408\u4e34\u5e8a\u90e8\u7f72\u3002", "conclusion": "\u53ef\u63a7\u7684\u5408\u6210\u589e\u5f3a\u53ef\u63d0\u9ad8\u5206\u5272\u9c81\u68d2\u6027\u4e14\u65e0\u5206\u5e03\u504f\u79fb\uff0cSynDiff\u4e3a\u8d44\u6e90\u6709\u9650\u7684\u533b\u7597\u73af\u5883\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15501", "pdf": "https://arxiv.org/pdf/2507.15501", "abs": "https://arxiv.org/abs/2507.15501", "authors": ["Alexandru Coca", "Mark Gaynor", "Zhenxing Zhang", "Jianpeng Cheng", "Bo-Hsiang Tseng", "Pete Boothroyd", "H\u00e9ctor Martinez Alonso", "Diarmuid \u00d3 S\u00e9aghdha", "Anders Johannsen"], "title": "ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "37 pages, 22 figures. To appear at ACL 2025", "summary": "This work evaluates the potential of large language models (LLMs) to power\ndigital assistants capable of complex action execution. These assistants rely\non pre-trained programming knowledge to execute multi-step goals by composing\nobjects and functions defined in assistant libraries into action execution\nprograms. To achieve this, we develop ASPERA, a framework comprising an\nassistant library simulation and a human-assisted LLM data generation engine.\nOur engine allows developers to guide LLM generation of high-quality tasks\nconsisting of complex user queries, simulation state and corresponding\nvalidation programs, tackling data availability and evaluation robustness\nchallenges. Alongside the framework we release Asper-Bench, an evaluation\ndataset of 250 challenging tasks generated using ASPERA, which we use to show\nthat program generation grounded in custom assistant libraries is a significant\nchallenge to LLMs compared to dependency-free code generation.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u80fd\u6267\u884c\u590d\u6742\u64cd\u4f5c\u7684\u6570\u5b57\u52a9\u624b\u7684\u6f5c\u529b\uff0c\u5f00\u53d1ASPERA\u6846\u67b6\u5e76\u53d1\u5e03Asper - Bench\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u53ef\u6267\u884c\u590d\u6742\u64cd\u4f5c\u7684\u6570\u5b57\u52a9\u624b\u7684\u6f5c\u529b\uff0c\u89e3\u51b3\u6570\u636e\u53ef\u7528\u6027\u548c\u8bc4\u4f30\u9c81\u68d2\u6027\u6311\u6218\u3002", "method": "\u5f00\u53d1\u5305\u542b\u52a9\u624b\u5e93\u6a21\u62df\u548c\u4eba\u5de5\u8f85\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u6570\u636e\u751f\u6210\u5f15\u64ce\u7684ASPERA\u6846\u67b6\u3002", "result": "\u53d1\u5e03\u7531250\u4e2a\u5177\u6709\u6311\u6218\u6027\u4efb\u52a1\u7ec4\u6210\u7684Asper - Bench\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u57fa\u4e8e\u81ea\u5b9a\u4e49\u52a9\u624b\u5e93\u7684\u7a0b\u5e8f\u751f\u6210\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u662f\u91cd\u5927\u6311\u6218\u3002", "conclusion": "\u57fa\u4e8e\u81ea\u5b9a\u4e49\u52a9\u624b\u5e93\u7684\u7a0b\u5e8f\u751f\u6210\u6bd4\u65e0\u4f9d\u8d56\u4ee3\u7801\u751f\u6210\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u5177\u6311\u6218\u6027\u3002"}}
{"id": "2507.15577", "pdf": "https://arxiv.org/pdf/2507.15577", "abs": "https://arxiv.org/abs/2507.15577", "authors": ["Hugo Carlesso", "Maria Eliza Patulea", "Moncef Garouani", "Radu Tudor Ionescu", "Josiane Mothe"], "title": "GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Mixup has become a popular augmentation strategy for image classification,\nyet its naive pixel-wise interpolation often produces unrealistic images that\ncan hinder learning, particularly in high-stakes medical applications. We\npropose GeMix, a two-stage framework that replaces heuristic blending with a\nlearned, label-aware interpolation powered by class-conditional GANs. First, a\nStyleGAN2-ADA generator is trained on the target dataset. During augmentation,\nwe sample two label vectors from Dirichlet priors biased toward different\nclasses and blend them via a Beta-distributed coefficient. Then, we condition\nthe generator on this soft label to synthesize visually coherent images that\nlie along a continuous class manifold. We benchmark GeMix on the large-scale\nCOVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101,\nEfficientNet-B0). When combined with real data, our method increases macro-F1\nover traditional mixup for all backbones, reducing the false negative rate for\nCOVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup,\ndelivering stronger regularization and greater semantic fidelity, without\ndisrupting existing training pipelines. We publicly release our code at\nhttps://github.com/hugocarlesso/GeMix to foster reproducibility and further\nresearch.", "AI": {"tldr": "\u63d0\u51faGeMix\u6846\u67b6\u66ff\u4ee3\u4f20\u7edfMixup\uff0c\u5728COVIDx - CT - 3\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u6027\u80fd\uff0c\u4ee3\u7801\u516c\u5f00\u3002", "motivation": "\u4f20\u7edfMixup\u7684\u50cf\u7d20\u63d2\u503c\u751f\u6210\u4e0d\u771f\u5b9e\u56fe\u50cf\uff0c\u5f71\u54cd\u5b66\u4e60\uff0c\u5c24\u5176\u5728\u533b\u7597\u5e94\u7528\u4e2d\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5GeMix\u6846\u67b6\uff0c\u7528StyleGAN2 - ADA\u751f\u6210\u5668\uff0c\u4ece\u72c4\u5229\u514b\u96f7\u5148\u9a8c\u91c7\u6837\u6807\u7b7e\u5411\u91cf\u5e76\u6df7\u5408\uff0c\u4ee5\u8f6f\u6807\u7b7e\u751f\u6210\u56fe\u50cf\u3002", "result": "\u5728COVIDx - CT - 3\u6570\u636e\u96c6\u4e0a\uff0c\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u65f6\uff0c\u76f8\u6bd4\u4f20\u7edfMixup\u63d0\u9ad8\u4e86macro - F1\uff0c\u964d\u4f4e\u4e86COVID - 19\u68c0\u6d4b\u7684\u5047\u9634\u6027\u7387\u3002", "conclusion": "GeMix\u53ef\u66ff\u4ee3\u50cf\u7d20\u7a7a\u95f4Mixup\uff0c\u63d0\u4f9b\u66f4\u5f3a\u6b63\u5219\u5316\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u4e0d\u5f71\u54cd\u73b0\u6709\u8bad\u7ec3\u6d41\u7a0b\u3002"}}
{"id": "2507.15367", "pdf": "https://arxiv.org/pdf/2507.15367", "abs": "https://arxiv.org/abs/2507.15367", "authors": ["Shumin Wang", "Hajar El Hassani", "Marco Di Renzo", "Marios Poulakis"], "title": "Multi-beam Beamforming in RIS-aided MIMO Subject to Reradiation Mask Constraints -- Optimization and Machine Learning Design", "categories": ["math.OC", "cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "Reconfigurable intelligent surfaces (RISs) are an emerging technology for\nimproving spectral efficiency and reducing power consumption in future wireless\nsystems. This paper investigates the joint design of the transmit precoding\nmatrices and the RIS phase shift vector in a multi-user RIS-aided\nmultiple-input multiple-output (MIMO) communication system. We formulate a\nmax-min optimization problem to maximize the minimum achievable rate while\nconsidering transmit power and reradiation mask constraints. The achievable\nrate is simplified using the Arimoto-Blahut algorithm, and the problem is\nbroken into quadratic programs with quadratic constraints (QPQC) sub-problems\nusing an alternating optimization approach. To improve efficiency, we develop a\nmodel-based neural network optimization that utilizes the one-hot encoding for\nthe angles of incidence and reflection. We address practical RIS limitations by\nusing a greedy search algorithm to solve the optimization problem for discrete\nphase shifts. Simulation results demonstrate that the proposed methods\neffectively shape the multi-beam radiation pattern towards desired directions\nwhile satisfying reradiation mask constraints. The neural network design\nreduces the execution time, and the discrete phase shift scheme performs well\nwith a small reduction of the beamforming gain by using only four phase shift\nlevels.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u591a\u7528\u6237RIS\u8f85\u52a9MIMO\u901a\u4fe1\u7cfb\u7edf\u4e2d\u53d1\u5c04\u9884\u7f16\u7801\u77e9\u9635\u548cRIS\u76f8\u79fb\u5411\u91cf\u7684\u8054\u5408\u8bbe\u8ba1\uff0c\u63d0\u51fa\u591a\u79cd\u4f18\u5316\u65b9\u6cd5\uff0c\u4eff\u771f\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u63d0\u9ad8\u672a\u6765\u65e0\u7ebf\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\u548c\u964d\u4f4e\u529f\u8017\uff0c\u7814\u7a76\u591a\u7528\u6237RIS\u8f85\u52a9MIMO\u901a\u4fe1\u7cfb\u7edf\u4e2d\u53d1\u5c04\u9884\u7f16\u7801\u77e9\u9635\u548cRIS\u76f8\u79fb\u5411\u91cf\u7684\u8054\u5408\u8bbe\u8ba1\u3002", "method": "\u6784\u5efa\u6700\u5927\u6700\u5c0f\u4f18\u5316\u95ee\u9898\uff0c\u7528Arimoto - Blahut\u7b97\u6cd5\u7b80\u5316\u53ef\u8fbe\u901f\u7387\uff0c\u7528\u4ea4\u66ff\u4f18\u5316\u65b9\u6cd5\u5c06\u95ee\u9898\u5206\u89e3\u4e3aQPQC\u5b50\u95ee\u9898\uff0c\u5f00\u53d1\u57fa\u4e8e\u6a21\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\uff0c\u7528\u8d2a\u5a6a\u641c\u7d22\u7b97\u6cd5\u89e3\u51b3\u79bb\u6563\u76f8\u79fb\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u5c06\u591a\u6ce2\u675f\u8f90\u5c04\u65b9\u5411\u56fe\u5851\u9020\u6210\u671f\u671b\u65b9\u5411\uff0c\u6ee1\u8db3\u518d\u8f90\u5c04\u63a9\u6a21\u7ea6\u675f\uff0c\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u51cf\u5c11\u6267\u884c\u65f6\u95f4\uff0c\u79bb\u6563\u76f8\u79fb\u65b9\u6848\u7528\u56db\u4e2a\u76f8\u79fb\u7ea7\u522b\u65f6\u6ce2\u675f\u5f62\u6210\u589e\u76ca\u7565\u6709\u964d\u4f4e\u4f46\u6027\u80fd\u826f\u597d\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u7528\u6237RIS\u8f85\u52a9MIMO\u901a\u4fe1\u7cfb\u7edf\u4e2d\u80fd\u6709\u6548\u5b9e\u73b0\u8bbe\u8ba1\u76ee\u6807\uff0c\u6709\u8f83\u597d\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2507.15597", "pdf": "https://arxiv.org/pdf/2507.15597", "abs": "https://arxiv.org/abs/2507.15597", "authors": ["Hao Luo", "Yicheng Feng", "Wanpeng Zhang", "Sipeng Zheng", "Ye Wang", "Haoqi Yuan", "Jiazheng Liu", "Chaoyi Xu", "Qin Jin", "Zongqing Lu"], "title": "Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "37 pages", "summary": "We introduce Being-H0, a dexterous Vision-Language-Action model (VLA) trained\non large-scale human videos. Existing VLAs struggle with complex manipulation\ntasks requiring high dexterity and generalize poorly to novel scenarios and\ntasks, primarily due to their reliance on synthetic data with significant\nsim-to-real gaps or teleoperated demonstrations lacking scale and diversity. To\naddress this data bottleneck, we propose leveraging human hands as a foundation\nmanipulator, capitalizing on the rich dexterity and scalability present in web\ndata. Our approach centers on physical instruction tuning, a novel training\nparadigm that combines large-scale VLA pretraining from human videos, physical\nspace alignment for 3D reasoning, and post-training adaptation for robotic\ntasks. Additionally, we introduce a part-level motion tokenization method which\nachieves millimeter-level reconstruction accuracy to model precise hand\ntrajectories for action learning. To support our proposed paradigm, we further\ndevelop a comprehensive data curation pipeline that integrates heterogeneous\nsources -- including motion capture, VR, and RGB-only videos -- into a\nlarge-scale dataset with millions of motion-based instructional instances. We\nempirically show the excellence of Being-H0 in hand motion generation and\ninstruction following, and it also scales well with model and data sizes.\nImportantly, we observe the expected gains of Being-H0 in real-world robotic\nmanipulation as physical instruction tuning is applied. More details are\navailable at https://beingbeyond.github.io/Being-H0.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u5927\u89c4\u6a21\u4eba\u7c7b\u89c6\u9891\u8bad\u7ec3\u7684\u7075\u5de7\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578bBeing - H0\uff0c\u63d0\u51fa\u7269\u7406\u6307\u4ee4\u5fae\u8c03\u65b9\u6cd5\u548c\u90e8\u5206\u7ea7\u8fd0\u52a8\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u6784\u5efa\u7efc\u5408\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u624b\u90e8\u52a8\u4f5c\u751f\u6210\u3001\u6307\u4ee4\u9075\u5faa\u548c\u73b0\u5b9e\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u6709\u51fa\u8272\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u5728\u590d\u6742\u7075\u5de7\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5728\u65b0\u573a\u666f\u548c\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u4f9d\u8d56\u5408\u6210\u6570\u636e\u6216\u7f3a\u4e4f\u89c4\u6a21\u548c\u591a\u6837\u6027\u7684\u8fdc\u7a0b\u64cd\u4f5c\u6f14\u793a\u3002", "method": "\u63d0\u51fa\u4ee5\u4eba\u7c7b\u624b\u90e8\u4e3a\u57fa\u7840\u64cd\u7eb5\u5668\uff0c\u91c7\u7528\u7269\u7406\u6307\u4ee4\u5fae\u8c03\u8303\u5f0f\uff0c\u7ed3\u5408\u5927\u89c4\u6a21\u4eba\u7c7b\u89c6\u9891\u9884\u8bad\u7ec3\u3001\u7269\u7406\u7a7a\u95f4\u5bf9\u9f50\u548c\u540e\u8bad\u7ec3\u9002\u5e94\uff1b\u5f15\u5165\u90e8\u5206\u7ea7\u8fd0\u52a8\u6807\u8bb0\u5316\u65b9\u6cd5\uff1b\u5f00\u53d1\u7efc\u5408\u6570\u636e\u5904\u7406\u6d41\u7a0b\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "result": "Being - H0\u5728\u624b\u90e8\u52a8\u4f5c\u751f\u6210\u548c\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u968f\u6a21\u578b\u548c\u6570\u636e\u89c4\u6a21\u6269\u5927\u8868\u73b0\u826f\u597d\uff0c\u5e94\u7528\u7269\u7406\u6307\u4ee4\u5fae\u8c03\u540e\u5728\u73b0\u5b9e\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u6709\u9884\u671f\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u6a21\u578bBeing - H0\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u7684\u6570\u636e\u74f6\u9888\u95ee\u9898\uff0c\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5177\u6709\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2507.15393", "pdf": "https://arxiv.org/pdf/2507.15393", "abs": "https://arxiv.org/abs/2507.15393", "authors": ["Ruofan Liu", "Yun Lin", "Silas Yeo Shuen Yu", "Xiwen Teoh", "Zhenkai Liang", "Jin Song Dong"], "title": "PiMRef: Detecting and Explaining Ever-evolving Spear Phishing Emails with Knowledge Base Invariants", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Phishing emails are a critical component of the cybercrime kill chain due to\ntheir wide reach and low cost. Their ever-evolving nature renders traditional\nrule-based and feature-engineered detectors ineffective in the ongoing arms\nrace between attackers and defenders. The rise of large language models (LLMs)\nfurther exacerbates the threat, enabling attackers to craft highly convincing\nphishing emails at minimal cost.\n  This work demonstrates that LLMs can generate psychologically persuasive\nphishing emails tailored to victim profiles, successfully bypassing nearly all\ncommercial and academic detectors. To defend against such threats, we propose\nPiMRef, the first reference-based phishing email detector that leverages\nknowledge-based invariants. Our core insight is that persuasive phishing emails\noften contain disprovable identity claims, which contradict real-world facts.\nPiMRef reframes phishing detection as an identity fact-checking task. Given an\nemail, PiMRef (i) extracts the sender's claimed identity, (ii) verifies the\nlegitimacy of the sender's domain against a predefined knowledge base, and\n(iii) detects call-to-action prompts that push user engagement. Contradictory\nclaims are flagged as phishing indicators and serve as human-understandable\nexplanations.\n  Compared to existing methods such as D-Fence, HelpHed, and ChatSpamDetector,\nPiMRef boosts precision by 8.8% with no loss in recall on standard benchmarks\nlike Nazario and PhishPot. In a real-world evaluation of 10,183 emails across\nfive university accounts over three years, PiMRef achieved 92.1% precision,\n87.9% recall, and a median runtime of 0.05s, outperforming the state-of-the-art\nin both effectiveness and efficiency.", "AI": {"tldr": "\u9493\u9c7c\u90ae\u4ef6\u5a01\u80c1\u5927\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u5931\u6548\uff0c\u7814\u7a76\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9493\u9c7c\u90ae\u4ef6\u80fd\u7ed5\u8fc7\u591a\u6570\u68c0\u6d4b\u5668\uff0c\u63d0\u51faPiMRef\u68c0\u6d4b\u5668\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u89c4\u5219\u548c\u7279\u5f81\u5de5\u7a0b\u68c0\u6d4b\u5668\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u9493\u9c7c\u90ae\u4ef6\u5931\u6548\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u52a0\u5267\u5a01\u80c1\uff0c\u9700\u65b0\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPiMRef\uff0c\u5c06\u9493\u9c7c\u68c0\u6d4b\u91cd\u6784\u4e3a\u8eab\u4efd\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\uff0c\u63d0\u53d6\u53d1\u4ef6\u4eba\u8eab\u4efd\u3001\u9a8c\u8bc1\u57df\u540d\u5408\u6cd5\u6027\u3001\u68c0\u6d4b\u884c\u52a8\u547c\u5401\u63d0\u793a\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad88.8%\u7cbe\u5ea6\u4e14\u4e0d\u635f\u5931\u53ec\u56de\u7387\uff0c\u5728\u771f\u5b9e\u8bc4\u4f30\u4e2d\u7cbe\u5ea692.1%\u3001\u53ec\u56de\u738787.9%\u3001\u4e2d\u4f4d\u8fd0\u884c\u65f6\u95f40.05s\u3002", "conclusion": "PiMRef\u5728\u68c0\u6d4b\u9493\u9c7c\u90ae\u4ef6\u4e0a\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u6709\u6548\u548c\u9ad8\u6548\u3002"}}
{"id": "2507.15396", "pdf": "https://arxiv.org/pdf/2507.15396", "abs": "https://arxiv.org/abs/2507.15396", "authors": ["Hui-Guan Yuan", "Ryandhimas E. Zezario", "Shafique Ahmed", "Hsin-Min Wang", "Kai-Lung Hua", "Yu Tsao"], "title": "Neuro-MSBG: An End-to-End Neural Model for Hearing Loss Simulation", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Hearing loss simulation models are essential for hearing aid deployment.\nHowever, existing models have high computational complexity and latency, which\nlimits real-time applications and lack direct integration with speech\nprocessing systems. To address these issues, we propose Neuro-MSBG, a\nlightweight end-to-end model with a personalized audiogram encoder for\neffective time-frequency modeling. Experiments show that Neuro-MSBG supports\nparallel inference and retains the intelligibility and perceptual quality of\nthe original MSBG, with a Spearman's rank correlation coefficient (SRCC) of\n0.9247 for Short-Time Objective Intelligibility (STOI) and 0.8671 for\nPerceptual Evaluation of Speech Quality (PESQ). Neuro-MSBG reduces simulation\nruntime by a factor of 46 (from 0.970 seconds to 0.021 seconds for a 1 second\ninput), further demonstrating its efficiency and practicality.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u7aef\u5230\u7aef\u6a21\u578bNeuro - MSBG\u89e3\u51b3\u73b0\u6709\u542c\u529b\u635f\u5931\u6a21\u62df\u6a21\u578b\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u9ad8\u6548\u5b9e\u7528\u3002", "motivation": "\u73b0\u6709\u542c\u529b\u635f\u5931\u6a21\u62df\u6a21\u578b\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u5ef6\u8fdf\u5927\uff0c\u9650\u5236\u5b9e\u65f6\u5e94\u7528\u4e14\u7f3a\u4e4f\u4e0e\u8bed\u97f3\u5904\u7406\u7cfb\u7edf\u7684\u76f4\u63a5\u96c6\u6210\u3002", "method": "\u63d0\u51fa\u5177\u6709\u4e2a\u6027\u5316\u542c\u529b\u56fe\u7f16\u7801\u5668\u7684\u8f7b\u91cf\u7ea7\u7aef\u5230\u7aef\u6a21\u578bNeuro - MSBG\u8fdb\u884c\u6709\u6548\u7684\u65f6\u9891\u5efa\u6a21\u3002", "result": "Neuro - MSBG\u652f\u6301\u5e76\u884c\u63a8\u7406\uff0c\u4fdd\u7559\u539fMSBG\u7684\u53ef\u61c2\u5ea6\u548c\u611f\u77e5\u8d28\u91cf\uff0cSTOI\u7684SRCC\u4e3a0.9247\uff0cPESQ\u4e3a0.8671\uff0c\u5c06\u6a21\u62df\u8fd0\u884c\u65f6\u95f4\u7f29\u77ed46\u500d\u3002", "conclusion": "Neuro - MSBG\u5177\u6709\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.15698", "pdf": "https://arxiv.org/pdf/2507.15698", "abs": "https://arxiv.org/abs/2507.15698", "authors": ["Congmin Zheng", "Jiachen Zhu", "Jianghao Lin", "Xinyi Dai", "Yong Yu", "Weinan Zhang", "Mengyue Yang"], "title": "CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Process Reward Models (PRMs) play a central role in evaluating and guiding\nmulti-step reasoning in large language models (LLMs), especially for\nmathematical problem solving. However, we identify a pervasive length bias in\nexisting PRMs: they tend to assign higher scores to longer reasoning steps,\neven when the semantic content and logical validity are unchanged. This bias\nundermines the reliability of reward predictions and leads to overly verbose\noutputs during inference. To address this issue, we propose\nCoLD(Counterfactually-Guided Length Debiasing), a unified framework that\nmitigates length bias through three components: an explicit length-penalty\nadjustment, a learned bias estimator trained to capture spurious length-related\nsignals, and a joint training strategy that enforces length-invariance in\nreward predictions. Our approach is grounded in counterfactual reasoning and\ninformed by causal graph analysis. Extensive experiments on MATH500 and\nGSM-Plus show that CoLD consistently reduces reward-length correlation,\nimproves accuracy in step selection, and encourages more concise, logically\nvalid reasoning. These results demonstrate the effectiveness and practicality\nof CoLD in improving the fidelity and robustness of PRMs.", "AI": {"tldr": "\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u5b58\u5728\u957f\u5ea6\u504f\u5dee\uff0c\u63d0\u51faCoLD\u6846\u67b6\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548", "motivation": "\u73b0\u6709PRMs\u5b58\u5728\u957f\u5ea6\u504f\u5dee\uff0c\u5f71\u54cd\u5956\u52b1\u9884\u6d4b\u53ef\u9760\u6027\u548c\u63a8\u7406\u8f93\u51fa\u8d28\u91cf", "method": "\u63d0\u51faCoLD\u6846\u67b6\uff0c\u5305\u542b\u663e\u5f0f\u957f\u5ea6\u60e9\u7f5a\u8c03\u6574\u3001\u5b66\u4e60\u504f\u5dee\u4f30\u8ba1\u5668\u548c\u8054\u5408\u8bad\u7ec3\u7b56\u7565\uff0c\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u63a8\u7406\u548c\u56e0\u679c\u56fe\u5206\u6790", "result": "\u5728MATH500\u548cGSM - Plus\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cCoLD\u964d\u4f4e\u5956\u52b1 - \u957f\u5ea6\u76f8\u5173\u6027\uff0c\u63d0\u9ad8\u6b65\u9aa4\u9009\u62e9\u51c6\u786e\u6027\uff0c\u9f13\u52b1\u66f4\u7b80\u6d01\u6709\u6548\u7684\u63a8\u7406", "conclusion": "CoLD\u80fd\u6709\u6548\u63d0\u9ad8PRMs\u7684\u4fdd\u771f\u5ea6\u548c\u9c81\u68d2\u6027"}}
{"id": "2507.15428", "pdf": "https://arxiv.org/pdf/2507.15428", "abs": "https://arxiv.org/abs/2507.15428", "authors": ["Jiaao Li", "Kaiyuan Li", "Chen Gao", "Yong Li", "Xinlei Chen"], "title": "EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Egomotion videos are first-person recordings where the view changes\ncontinuously due to the agent's movement. As they serve as the primary visual\ninput for embodied AI agents, making egomotion video reasoning more efficient\nis therefore essential for real-world deployment. Recent advances in\nvision-language models have enabled strong multimodal reasoning capabilities,\nbut their computational cost remains prohibitive for long, redundant video\ninputs. Existing token pruning methods, typically designed for third-person\nvideos, fail to leverage the spatiotemporal continuity and motion constraints\ninherent in egomotion settings. To address this, we propose EgoPrune, a\ntraining-free token pruning method tailored for egomotion video reasoning.\nEgoPrune comprises three components: a keyframe selector adapted from EmbodiedR\nfor temporally efficient sampling; Perspective-Aware Redundancy Filtering\n(PARF), which aligns visual tokens using perspective transformations and\nremoves redundant tokens; and a Maximal Marginal Relevance (MMR)-based token\nselector that jointly considers visual-text relevance and intra-frame\ndiversity. Experiments on two egomotion video benchmarks show that EgoPrune\nconsistently outperforms prior training-free methods across various pruning\nratios while significantly reducing FLOPs, memory usage, and latency. Moreover,\nwe deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB\nedge device, demonstrating its real-world efficiency and suitability for\non-device egomotion video reasoning.", "AI": {"tldr": "\u63d0\u51fa\u8bad\u7ec3\u65e0\u5173\u7684EgoPrune\u7528\u4e8e\u81ea\u6211\u8fd0\u52a8\u89c6\u9891\u63a8\u7406\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u8fd8\u5c55\u793a\u4e86\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u4e14\u5197\u4f59\u7684\u81ea\u6211\u8fd0\u52a8\u89c6\u9891\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u4ee4\u724c\u4fee\u526a\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u81ea\u6211\u8fd0\u52a8\u89c6\u9891\u3002", "method": "\u63d0\u51faEgoPrune\uff0c\u5305\u542b\u9002\u5e94EmbodiedR\u7684\u5173\u952e\u5e27\u9009\u62e9\u5668\u3001\u900f\u89c6\u611f\u77e5\u5197\u4f59\u8fc7\u6ee4\u548c\u57fa\u4e8e\u6700\u5927\u8fb9\u9645\u76f8\u5173\u6027\u7684\u4ee4\u724c\u9009\u62e9\u5668\u3002", "result": "\u5728\u4e24\u4e2a\u81ea\u6211\u8fd0\u52a8\u89c6\u9891\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEgoPrune\u5728\u4e0d\u540c\u4fee\u526a\u7387\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u5148\u524d\u8bad\u7ec3\u65e0\u5173\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4eFLOPs\u3001\u5185\u5b58\u4f7f\u7528\u548c\u5ef6\u8fdf\u3002", "conclusion": "EgoPrune\u5728\u81ea\u6211\u8fd0\u52a8\u89c6\u9891\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9002\u5408\u5728\u8bbe\u5907\u4e0a\u8fdb\u884c\u81ea\u6211\u8fd0\u52a8\u89c6\u9891\u63a8\u7406\u3002"}}
{"id": "2507.15454", "pdf": "https://arxiv.org/pdf/2507.15454", "abs": "https://arxiv.org/abs/2507.15454", "authors": ["Ruijie Zhu", "Mulin Yu", "Linning Xu", "Lihan Jiang", "Yixuan Li", "Tianzhu Zhang", "Jiangmiao Pang", "Bo Dai"], "title": "ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.HC"], "comment": "Accepted by ICCV 2025", "summary": "3D Gaussian Splatting is renowned for its high-fidelity reconstructions and\nreal-time novel view synthesis, yet its lack of semantic understanding limits\nobject-level perception. In this work, we propose ObjectGS, an object-aware\nframework that unifies 3D scene reconstruction with semantic understanding.\nInstead of treating the scene as a unified whole, ObjectGS models individual\nobjects as local anchors that generate neural Gaussians and share object IDs,\nenabling precise object-level reconstruction. During training, we dynamically\ngrow or prune these anchors and optimize their features, while a one-hot ID\nencoding with a classification loss enforces clear semantic constraints. We\nshow through extensive experiments that ObjectGS not only outperforms\nstate-of-the-art methods on open-vocabulary and panoptic segmentation tasks,\nbut also integrates seamlessly with applications like mesh extraction and scene\nediting. Project page: https://ruijiezhu94.github.io/ObjectGS_page", "AI": {"tldr": "\u63d0\u51faObjectGS\u6846\u67b6\u7edf\u4e003D\u573a\u666f\u91cd\u5efa\u4e0e\u8bed\u4e49\u7406\u89e3\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u80fd\u65e0\u7f1d\u96c6\u6210\u5e94\u7528\u3002", "motivation": "3D Gaussian Splatting\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\uff0c\u9650\u5236\u5bf9\u8c61\u7ea7\u611f\u77e5\uff0c\u9700\u8981\u7edf\u4e003D\u573a\u666f\u91cd\u5efa\u4e0e\u8bed\u4e49\u7406\u89e3\u3002", "method": "\u5c06\u5355\u4e2a\u5bf9\u8c61\u5efa\u6a21\u4e3a\u5c40\u90e8\u951a\u70b9\u751f\u6210\u795e\u7ecf\u9ad8\u65af\u5e76\u5171\u4eab\u5bf9\u8c61ID\uff0c\u8bad\u7ec3\u65f6\u52a8\u6001\u8c03\u6574\u951a\u70b9\u5e76\u4f18\u5316\u7279\u5f81\uff0c\u7528one - hot ID\u7f16\u7801\u548c\u5206\u7c7b\u635f\u5931\u65bd\u52a0\u8bed\u4e49\u7ea6\u675f\u3002", "result": "\u5728\u5f00\u653e\u8bcd\u6c47\u548c\u5168\u666f\u5206\u5272\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u65e0\u7f1d\u96c6\u6210\u5230\u7f51\u683c\u63d0\u53d6\u548c\u573a\u666f\u7f16\u8f91\u7b49\u5e94\u7528\u4e2d\u3002", "conclusion": "ObjectGS\u6709\u6548\u7edf\u4e00\u4e863D\u573a\u666f\u91cd\u5efa\u4e0e\u8bed\u4e49\u7406\u89e3\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.15455", "pdf": "https://arxiv.org/pdf/2507.15455", "abs": "https://arxiv.org/abs/2507.15455", "authors": ["Hee Jun Yang", "Min Jung Kim", "Yeoneung Kim"], "title": "Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration", "categories": ["math.NA", "cs.AI", "cs.NA", "math.AP", "49N70, 35Q93, 49L25, 68T07"], "comment": null, "summary": "We propose a mesh-free policy iteration framework that combines classical\ndynamic programming with physics-informed neural networks (PINNs) to solve\nhigh-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in\nstochastic differential games and robust control. The method alternates between\nsolving linear second-order PDEs under fixed feedback policies and updating the\ncontrols via pointwise minimax optimization using automatic differentiation.\nUnder standard Lipschitz and uniform ellipticity assumptions, we prove that the\nvalue function iterates converge locally uniformly to the unique viscosity\nsolution of the HJI equation. The analysis establishes equi-Lipschitz\nregularity of the iterates, enabling provable stability and convergence without\nrequiring convexity of the Hamiltonian. Numerical experiments demonstrate the\naccuracy and scalability of the method. In a two-dimensional stochastic\npath-planning game with a moving obstacle, our method matches finite-difference\nbenchmarks with relative $L^2$-errors below %10^{-2}%. In five- and\nten-dimensional publisher-subscriber differential games with anisotropic noise,\nthe proposed approach consistently outperforms direct PINN solvers, yielding\nsmoother value functions and lower residuals. Our results suggest that\nintegrating PINNs with policy iteration is a practical and theoretically\ngrounded method for solving high-dimensional, nonconvex HJI equations, with\npotential applications in robotics, finance, and multi-agent reinforcement\nlearning.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u7ecf\u5178\u52a8\u6001\u89c4\u5212\u4e0e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u7684\u65e0\u7f51\u683c\u7b56\u7565\u8fed\u4ee3\u6846\u67b6\uff0c\u7528\u4e8e\u6c42\u89e3\u9ad8\u7ef4\u3001\u975e\u51f8HJI\u65b9\u7a0b\uff0c\u8bc1\u660e\u6536\u655b\u6027\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u968f\u673a\u5fae\u5206\u535a\u5f08\u548c\u9c81\u68d2\u63a7\u5236\u4e2d\u51fa\u73b0\u7684\u9ad8\u7ef4\u3001\u975e\u51f8HJI\u65b9\u7a0b\u3002", "method": "\u5728\u56fa\u5b9a\u53cd\u9988\u7b56\u7565\u4e0b\u6c42\u89e3\u7ebf\u6027\u4e8c\u9636PDE\u548c\u5229\u7528\u81ea\u52a8\u5fae\u5206\u901a\u8fc7\u9010\u70b9\u6781\u5c0f\u6781\u5927\u4f18\u5316\u66f4\u65b0\u63a7\u5236\u4ea4\u66ff\u8fdb\u884c\u3002", "result": "\u8bc1\u660e\u503c\u51fd\u6570\u8fed\u4ee3\u5c40\u90e8\u4e00\u81f4\u6536\u655b\u5230HJI\u65b9\u7a0b\u552f\u4e00\u7c98\u6027\u89e3\uff1b\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u51c6\u786e\u4e14\u53ef\u6269\u5c55\uff0c\u5728\u4e0d\u540c\u6848\u4f8b\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u5c06PINNs\u4e0e\u7b56\u7565\u8fed\u4ee3\u7ed3\u5408\u662f\u6c42\u89e3\u9ad8\u7ef4\u3001\u975e\u51f8HJI\u65b9\u7a0b\u5b9e\u7528\u4e14\u6709\u7406\u8bba\u4f9d\u636e\u7684\u65b9\u6cd5\uff0c\u6709\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2507.15773", "pdf": "https://arxiv.org/pdf/2507.15773", "abs": "https://arxiv.org/abs/2507.15773", "authors": ["Andrei-Valentin Tanase", "Elena Pelican"], "title": "Supernova: Achieving More with Less in Transformer Architectures", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present Supernova, a 650M-parameter decoder-only transformer that\ndemonstrates how careful architectural design and tokenization innovation can\nachieve the performance of larger models while maintaining computational\nefficiency. Our architecture combines Rotary Positional Embeddings (RoPE),\nGrouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for\ncomputational efficiency, and SwiGLU activation functions. A critical\ninnovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which\nachieves state-of-the-art compression performance. Through detailed analysis,\nwe show that Supernova achieves 90% of the performance of 1B-parameter models\nwhile using 53% fewer parameters and requiring only 100B training tokens--an\norder of magnitude less than competing models. Our findings challenge the\nprevailing scaling paradigm, demonstrating that architectural efficiency and\ntokenization quality can compensate for reduced parameter counts.", "AI": {"tldr": "\u4ecb\u7ecd650M\u53c2\u6570\u7684Supernova\u6a21\u578b\uff0c\u901a\u8fc7\u67b6\u6784\u8bbe\u8ba1\u548c\u5206\u8bcd\u521b\u65b0\uff0c\u5728\u51cf\u5c11\u53c2\u6570\u548c\u8bad\u7ec3\u6570\u636e\u4e0b\u8fbe\u8f83\u5927\u6a21\u578b90%\u6027\u80fd\uff0c\u6311\u6218\u73b0\u6709\u7f29\u653e\u8303\u5f0f\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u67b6\u6784\u8bbe\u8ba1\u548c\u5206\u8bcd\u521b\u65b0\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u8fbe\u5230\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528RoPE\u3001GQA\u3001RMSNorm\u548cSwiGLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f7f\u7528\u81ea\u5b9a\u4e49128,000\u8bcd\u6c47\u5b57\u8282\u7ea7BPE\u5206\u8bcd\u5668\u3002", "result": "Supernova\u8fbe\u52301B\u53c2\u6570\u6a21\u578b90%\u7684\u6027\u80fd\uff0c\u53c2\u6570\u51cf\u5c1153%\uff0c\u4ec5\u9700100B\u8bad\u7ec3\u4ee4\u724c\u3002", "conclusion": "\u67b6\u6784\u6548\u7387\u548c\u5206\u8bcd\u8d28\u91cf\u53ef\u5f25\u8865\u53c2\u6570\u6570\u91cf\u7684\u51cf\u5c11\uff0c\u6311\u6218\u4e86\u73b0\u6709\u7684\u7f29\u653e\u8303\u5f0f\u3002"}}
{"id": "2507.15465", "pdf": "https://arxiv.org/pdf/2507.15465", "abs": "https://arxiv.org/abs/2507.15465", "authors": ["Sungmin Yun", "Seonyong Park", "Hwayong Nam", "Younjoo Lee", "Gunjun Lee", "Kwanhee Kyung", "Sangpyo Kim", "Nam Sung Kim", "Jongmin Kim", "Hyungyo Kim", "Juhwan Cho", "Seungmin Baek", "Jung Ho Ahn"], "title": "The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts", "categories": ["cs.AR", "cs.AI"], "comment": "15 pages, 11 figures", "summary": "Computational workloads composing traditional Transformer models are starkly\nbifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic\nintensity, while feedforward layers are compute-bound. This dichotomy has long\nmotivated research into specialized hardware to mitigate the MHA bottleneck.\n  This paper argues that recent architectural shifts, namely Multi-head Latent\nAttention (MLA) and Mixture-of-Experts (MoE), challenge the premise of\nspecialized attention hardware. We make two key observations. First, the\narithmetic intensity of MLA is over two orders of magnitude greater than that\nof MHA, shifting it close to a compute-bound regime well-suited for modern\naccelerators like GPUs. Second, by distributing MoE experts across a pool of\naccelerators, their arithmetic intensity can be tuned through batching to match\nthat of the dense layers, creating a more balanced computational profile.\n  These findings reveal a diminishing need for specialized attention hardware.\nThe central challenge for next-generation Transformers is no longer\naccelerating a single memory-bound layer. Instead, the focus must shift to\ndesigning balanced systems with sufficient compute, memory capacity, memory\nbandwidth, and high-bandwidth interconnects to manage the diverse demands of\nlarge-scale models.", "AI": {"tldr": "\u8bba\u6587\u6307\u51faMLA\u548cMoE\u67b6\u6784\u53d8\u5316\u6311\u6218\u4e13\u7528\u6ce8\u610f\u529b\u786c\u4ef6\u524d\u63d0\uff0c\u51cf\u5c11\u5176\u9700\u6c42\uff0c\u4e0b\u4e00\u4ee3Transformer\u5e94\u8bbe\u8ba1\u5e73\u8861\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edfTransformer\u6a21\u578b\u4e2dMHA\u5185\u5b58\u53d7\u9650\uff0c\u957f\u671f\u4ee5\u6765\u4fc3\u4f7f\u7814\u7a76\u4e13\u7528\u786c\u4ef6\u7f13\u89e3\u74f6\u9888\uff0c\u800c\u8fd1\u671f\u67b6\u6784\u53d8\u5316\u4fc3\u4f7f\u91cd\u65b0\u5ba1\u89c6\u4e13\u7528\u786c\u4ef6\u9700\u6c42\u3002", "method": "\u5bf9MLA\u548cMoE\u67b6\u6784\u8fdb\u884c\u5206\u6790\uff0c\u89c2\u5bdf\u5176\u7b97\u672f\u5f3a\u5ea6\u53d8\u5316\u3002", "result": "MLA\u7b97\u672f\u5f3a\u5ea6\u5927\u5e45\u63d0\u5347\u63a5\u8fd1\u8ba1\u7b97\u5bc6\u96c6\u578b\uff0cMoE\u53ef\u901a\u8fc7\u6279\u5904\u7406\u8c03\u6574\u7b97\u672f\u5f3a\u5ea6\u4f7f\u8ba1\u7b97\u66f4\u5e73\u8861\u3002", "conclusion": "\u4e13\u7528\u6ce8\u610f\u529b\u786c\u4ef6\u9700\u6c42\u51cf\u5c11\uff0c\u4e0b\u4e00\u4ee3Transformer\u5e94\u805a\u7126\u8bbe\u8ba1\u5e73\u8861\u7cfb\u7edf\u4ee5\u5e94\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u9700\u6c42\u3002"}}
{"id": "2507.15776", "pdf": "https://arxiv.org/pdf/2507.15776", "abs": "https://arxiv.org/abs/2507.15776", "authors": ["Noor Sajid", "Johan Medrano"], "title": "Dissociating model architectures from inference computations", "categories": ["q-bio.NC", "cs.CL", "cs.LG"], "comment": "3 pages, 1 figure", "summary": "Parr et al., 2025 examines how auto-regressive and deep temporal models\ndiffer in their treatment of non-Markovian sequence modelling. Building on\nthis, we highlight the need for dissociating model architectures, i.e., how the\npredictive distribution factorises, from the computations invoked at inference.\nWe demonstrate that deep temporal computations are mimicked by autoregressive\nmodels by structuring context access during iterative inference. Using a\ntransformer trained on next-token prediction, we show that inducing\nhierarchical temporal factorisation during iterative inference maintains\npredictive capacity while instantiating fewer computations. This emphasises\nthat processes for constructing and refining predictions are not necessarily\nbound to their underlying model architectures.", "AI": {"tldr": "\u7814\u7a76\u81ea\u56de\u5f52\u548c\u6df1\u5ea6\u65f6\u95f4\u6a21\u578b\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u5dee\u5f02\uff0c\u6307\u51fa\u6784\u5efa\u548c\u5b8c\u5584\u9884\u6d4b\u7684\u8fc7\u7a0b\u4e0d\u4e00\u5b9a\u4e0e\u6a21\u578b\u67b6\u6784\u7ed1\u5b9a\u3002", "motivation": "\u63a2\u7a76\u81ea\u56de\u5f52\u548c\u6df1\u5ea6\u65f6\u95f4\u6a21\u578b\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u5e8f\u5217\u5efa\u6a21\u5904\u7406\u4e0a\u7684\u5dee\u5f02\uff0c\u5f3a\u8c03\u5206\u79bb\u6a21\u578b\u67b6\u6784\u548c\u63a8\u7406\u8ba1\u7b97\u7684\u5fc5\u8981\u6027\u3002", "method": "\u901a\u8fc7\u5728\u8fed\u4ee3\u63a8\u7406\u4e2d\u6784\u5efa\u4e0a\u4e0b\u6587\u8bbf\u95ee\uff0c\u8ba9\u81ea\u56de\u5f52\u6a21\u578b\u6a21\u4eff\u6df1\u5ea6\u65f6\u95f4\u8ba1\u7b97\uff1b\u7528\u57fa\u4e8e\u4e0b\u4e00\u4e2a\u4ee4\u724c\u9884\u6d4b\u8bad\u7ec3\u7684\u53d8\u538b\u5668\uff0c\u5728\u8fed\u4ee3\u63a8\u7406\u4e2d\u5f15\u5165\u5206\u5c42\u65f6\u95f4\u5206\u89e3\u3002", "result": "\u5728\u8fed\u4ee3\u63a8\u7406\u4e2d\u5f15\u5165\u5206\u5c42\u65f6\u95f4\u5206\u89e3\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u80fd\u529b\u7684\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "conclusion": "\u6784\u5efa\u548c\u5b8c\u5584\u9884\u6d4b\u7684\u8fc7\u7a0b\u4e0d\u4e00\u5b9a\u4e0e\u5e95\u5c42\u6a21\u578b\u67b6\u6784\u76f8\u5173\u3002"}}
{"id": "2507.15469", "pdf": "https://arxiv.org/pdf/2507.15469", "abs": "https://arxiv.org/abs/2507.15469", "authors": ["Thanh Thi Nguyen", "Saeid Nahavandi", "Imran Razzak", "Dung Nguyen", "Nhat Truong Pham", "Quoc Viet Hung Nguyen"], "title": "The Emergence of Deep Reinforcement Learning for Path Planning", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted for publication in the Proceedings of the 2025 IEEE\n  International Conference on Systems, Man, and Cybernetics (SMC)", "summary": "The increasing demand for autonomous systems in complex and dynamic\nenvironments has driven significant research into intelligent path planning\nmethodologies. For decades, graph-based search algorithms, linear programming\ntechniques, and evolutionary computation methods have served as foundational\napproaches in this domain. Recently, deep reinforcement learning (DRL) has\nemerged as a powerful method for enabling autonomous agents to learn optimal\nnavigation strategies through interaction with their environments. This survey\nprovides a comprehensive overview of traditional approaches as well as the\nrecent advancements in DRL applied to path planning tasks, focusing on\nautonomous vehicles, drones, and robotic platforms. Key algorithms across both\nconventional and learning-based paradigms are categorized, with their\ninnovations and practical implementations highlighted. This is followed by a\nthorough discussion of their respective strengths and limitations in terms of\ncomputational efficiency, scalability, adaptability, and robustness. The survey\nconcludes by identifying key open challenges and outlining promising avenues\nfor future research. Special attention is given to hybrid approaches that\nintegrate DRL with classical planning techniques to leverage the benefits of\nboth learning-based adaptability and deterministic reliability, offering\npromising directions for robust and resilient autonomous navigation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u6db5\u76d6\u4f20\u7edf\u65b9\u6cd5\u4e0eDRL\uff0c\u5206\u6790\u4f18\u7f3a\u70b9\uff0c\u6307\u51fa\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5c24\u5176\u5173\u6ce8\u6df7\u5408\u65b9\u6cd5\u3002", "motivation": "\u590d\u6742\u52a8\u6001\u73af\u5883\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u9700\u6c42\u589e\u52a0\uff0c\u63a8\u52a8\u667a\u80fd\u8def\u5f84\u89c4\u5212\u7814\u7a76\u3002", "method": "\u5bf9\u4f20\u7edf\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u548cDRL\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u5206\u7c7b\u5173\u952e\u7b97\u6cd5\uff0c\u8ba8\u8bba\u4f18\u7f3a\u70b9\u3002", "result": "\u660e\u786e\u4f20\u7edf\u65b9\u6cd5\u548cDRL\u5728\u8ba1\u7b97\u6548\u7387\u3001\u53ef\u6269\u5c55\u6027\u7b49\u65b9\u9762\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "\u6307\u51fa\u5173\u952e\u5f00\u653e\u6311\u6218\uff0c\u5f3a\u8c03\u6df7\u5408\u65b9\u6cd5\u662f\u672a\u6765\u81ea\u4e3b\u5bfc\u822a\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2507.15803", "pdf": "https://arxiv.org/pdf/2507.15803", "abs": "https://arxiv.org/abs/2507.15803", "authors": ["Danhui Chen", "Ziquan Liu", "Chuxi Yang", "Dan Wang", "Yan Yan", "Yi Xu", "Xiangyang Ji"], "title": "ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV 2025", "summary": "Pixel-level vision tasks, such as semantic segmentation, require extensive\nand high-quality annotated data, which is costly to obtain. Semi-supervised\nsemantic segmentation (SSSS) has emerged as a solution to alleviate the\nlabeling burden by leveraging both labeled and unlabeled data through\nself-training techniques. Meanwhile, the advent of foundational segmentation\nmodels pre-trained on massive data, has shown the potential to generalize\nacross domains effectively. This work explores whether a foundational\nsegmentation model can address label scarcity in the pixel-level vision task as\nan annotator for unlabeled images. Specifically, we investigate the efficacy of\nusing SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual\ninput, to generate predictive masks for unlabeled data. To address the\nshortcomings of using SEEM-generated masks as supervision, we propose\nConformalSAM, a novel SSSS framework which first calibrates the foundation\nmodel using the target domain's labeled data and then filters out unreliable\npixel labels of unlabeled data so that only high-confidence labels are used as\nsupervision. By leveraging conformal prediction (CP) to adapt foundation models\nto target data through uncertainty calibration, ConformalSAM exploits the\nstrong capability of the foundational segmentation model reliably which\nbenefits the early-stage learning, while a subsequent self-reliance training\nstrategy mitigates overfitting to SEEM-generated masks in the later training\nstage. Our experiment demonstrates that, on three standard benchmarks of SSSS,\nConformalSAM achieves superior performance compared to recent SSSS methods and\nhelps boost the performance of those methods as a plug-in.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528\u57fa\u7840\u5206\u5272\u6a21\u578b\u89e3\u51b3\u50cf\u7d20\u7ea7\u89c6\u89c9\u4efb\u52a1\u6807\u7b7e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u51faConformalSAM\u6846\u67b6\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u50cf\u7d20\u7ea7\u89c6\u89c9\u4efb\u52a1\u6807\u6ce8\u6570\u636e\u83b7\u53d6\u6210\u672c\u9ad8\uff0c\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\u53ef\u7f13\u89e3\u6807\u6ce8\u8d1f\u62c5\uff0c\u63a2\u7d22\u57fa\u7840\u5206\u5272\u6a21\u578b\u4f5c\u4e3a\u672a\u6807\u6ce8\u56fe\u50cf\u6807\u6ce8\u5668\u7684\u6709\u6548\u6027\u3002", "method": "\u4f7f\u7528SEEM\u4e3a\u672a\u6807\u6ce8\u6570\u636e\u751f\u6210\u9884\u6d4b\u63a9\u7801\uff0c\u63d0\u51faConformalSAM\u6846\u67b6\uff0c\u5229\u7528\u4fdd\u5f62\u9884\u6d4b\u6821\u51c6\u57fa\u7840\u6a21\u578b\uff0c\u8fc7\u6ee4\u4e0d\u53ef\u9760\u50cf\u7d20\u6807\u7b7e\uff0c\u91c7\u7528\u81ea\u4f9d\u8d56\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u6807\u51c6\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cConformalSAM\u6027\u80fd\u4f18\u4e8e\u8fd1\u671f\u65b9\u6cd5\uff0c\u4e14\u53ef\u4f5c\u4e3a\u63d2\u4ef6\u63d0\u5347\u5176\u4ed6\u65b9\u6cd5\u6027\u80fd\u3002", "conclusion": "ConformalSAM\u80fd\u6709\u6548\u5229\u7528\u57fa\u7840\u5206\u5272\u6a21\u578b\u80fd\u529b\uff0c\u89e3\u51b3\u50cf\u7d20\u7ea7\u89c6\u89c9\u4efb\u52a1\u6807\u7b7e\u7a00\u7f3a\u95ee\u9898\u3002"}}
{"id": "2507.15493", "pdf": "https://arxiv.org/pdf/2507.15493", "abs": "https://arxiv.org/abs/2507.15493", "authors": ["Chilam Cheang", "Sijin Chen", "Zhongren Cui", "Yingdong Hu", "Liqun Huang", "Tao Kong", "Hang Li", "Yifeng Li", "Yuxiao Liu", "Xiao Ma", "Hao Niu", "Wenxuan Ou", "Wanli Peng", "Zeyu Ren", "Haixin Shi", "Jiawen Tian", "Hongtao Wu", "Xin Xiao", "Yuyang Xiao", "Jiafeng Xu", "Yichu Yang"], "title": "GR-3 Technical Report", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Tech report. Authors are listed in alphabetical order. Project page:\n  https://seed.bytedance.com/GR3/", "summary": "We report our recent progress towards building generalist robot policies, the\ndevelopment of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.\nIt showcases exceptional capabilities in generalizing to novel objects,\nenvironments, and instructions involving abstract concepts. Furthermore, it can\nbe efficiently fine-tuned with minimal human trajectory data, enabling rapid\nand cost-effective adaptation to new settings. GR-3 also excels in handling\nlong-horizon and dexterous tasks, including those requiring bi-manual\nmanipulation and mobile movement, showcasing robust and reliable performance.\nThese capabilities are achieved through a multi-faceted training recipe that\nincludes co-training with web-scale vision-language data, efficient fine-tuning\nfrom human trajectory data collected via VR devices, and effective imitation\nlearning with robot trajectory data. In addition, we introduce ByteMini, a\nversatile bi-manual mobile robot designed with exceptional flexibility and\nreliability, capable of accomplishing a wide range of tasks when integrated\nwith GR-3. Through extensive real-world experiments, we show GR-3 surpasses the\nstate-of-the-art baseline method, $\\pi_0$, on a wide variety of challenging\ntasks. We hope GR-3 can serve as a step towards building generalist robots\ncapable of assisting humans in daily life.", "AI": {"tldr": "\u4ecb\u7ecd\u6784\u5efa\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u7684\u8fdb\u5c55\uff0c\u5f00\u53d1GR - 3\u6a21\u578b\u548cByteMini\u673a\u5668\u4eba\uff0c\u5b9e\u9a8c\u663e\u793aGR - 3\u8868\u73b0\u8d85\u57fa\u7ebf\uff0c\u671b\u52a9\u529b\u901a\u7528\u673a\u5668\u4eba\u53d1\u5c55\u3002", "motivation": "\u6784\u5efa\u80fd\u5728\u65e5\u5e38\u751f\u6d3b\u4e2d\u534f\u52a9\u4eba\u7c7b\u7684\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u3002", "method": "\u91c7\u7528\u591a\u65b9\u9762\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\u4e0e\u7f51\u7edc\u89c4\u6a21\u89c6\u89c9\u8bed\u8a00\u6570\u636e\u5171\u540c\u8bad\u7ec3\u3001\u5229\u7528VR\u8bbe\u5907\u6536\u96c6\u7684\u4eba\u7c7b\u8f68\u8ff9\u6570\u636e\u9ad8\u6548\u5fae\u8c03\u3001\u7528\u673a\u5668\u4eba\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u6709\u6548\u6a21\u4eff\u5b66\u4e60\u3002", "result": "GR - 3\u5728\u591a\u79cd\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u03c0\u2080\u3002", "conclusion": "GR - 3\u662f\u8fc8\u5411\u6784\u5efa\u901a\u7528\u673a\u5668\u4eba\u7684\u4e00\u6b65\uff0c\u6709\u671b\u534f\u52a9\u4eba\u7c7b\u65e5\u5e38\u751f\u6d3b\u3002"}}
{"id": "2507.15809", "pdf": "https://arxiv.org/pdf/2507.15809", "abs": "https://arxiv.org/abs/2507.15809", "authors": ["Roberto Miele", "Niklas Linde"], "title": "Diffusion models for multivariate subsurface generation and efficient probabilistic inversion", "categories": ["cs.CV", "cs.LG", "physics.geo-ph", "stat.AP"], "comment": null, "summary": "Diffusion models offer stable training and state-of-the-art performance for\ndeep generative modeling tasks. Here, we consider their use in the context of\nmultivariate subsurface modeling and probabilistic inversion. We first\ndemonstrate that diffusion models enhance multivariate modeling capabilities\ncompared to variational autoencoders and generative adversarial networks. In\ndiffusion modeling, the generative process involves a comparatively large\nnumber of time steps with update rules that can be modified to account for\nconditioning data. We propose different corrections to the popular Diffusion\nPosterior Sampling approach by Chung et al. (2023). In particular, we introduce\na likelihood approximation accounting for the noise-contamination that is\ninherent in diffusion modeling. We assess performance in a multivariate\ngeological scenario involving facies and correlated acoustic impedance.\nConditional modeling is demonstrated using both local hard data (well logs) and\nnonlinear geophysics (fullstack seismic data). Our tests show significantly\nimproved statistical robustness, enhanced sampling of the posterior probability\ndensity function and reduced computational costs, compared to the original\napproach. The method can be used with both hard and indirect conditioning data,\nindividually or simultaneously. As the inversion is included within the\ndiffusion process, it is faster than other methods requiring an outer-loop\naround the generative model, such as Markov chain Monte Carlo.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u6269\u6563\u6a21\u578b\u5728\u591a\u53d8\u91cf\u5730\u4e0b\u5efa\u6a21\u548c\u6982\u7387\u53cd\u6f14\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u5bf9\u6269\u6563\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u7684\u6539\u8fdb\uff0c\u6d4b\u8bd5\u663e\u793a\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u8003\u8651\u6269\u6563\u6a21\u578b\u5728\u591a\u53d8\u91cf\u5730\u4e0b\u5efa\u6a21\u548c\u6982\u7387\u53cd\u6f14\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u5347\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5bf9\u6d41\u884c\u7684\u6269\u6563\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u7684\u4e0d\u540c\u4fee\u6b63\uff0c\u5f15\u5165\u8003\u8651\u566a\u58f0\u6c61\u67d3\u7684\u4f3c\u7136\u8fd1\u4f3c\u3002", "result": "\u4e0e\u539f\u65b9\u6cd5\u76f8\u6bd4\uff0c\u7edf\u8ba1\u9c81\u68d2\u6027\u663e\u8457\u63d0\u9ad8\uff0c\u540e\u9a8c\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u91c7\u6837\u589e\u5f3a\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5904\u7406\u591a\u79cd\u6761\u4ef6\u6570\u636e\uff0c\u53cd\u6f14\u901f\u5ea6\u6bd4\u5176\u4ed6\u65b9\u6cd5\u5feb\u3002"}}
{"id": "2507.15815", "pdf": "https://arxiv.org/pdf/2507.15815", "abs": "https://arxiv.org/abs/2507.15815", "authors": ["Seth Karten", "Wenzhe Li", "Zihan Ding", "Samuel Kleiner", "Yu Bai", "Chi Jin"], "title": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra", "categories": ["cs.MA", "cs.LG"], "comment": "27 pages, 6 figures, Code:\n  https://github.com/sethkarten/LLM-Economist", "summary": "We present the LLM Economist, a novel framework that uses agent-based\nmodeling to design and assess economic policies in strategic environments with\nhierarchical decision-making. At the lower level, bounded rational worker\nagents -- instantiated as persona-conditioned prompts sampled from U.S.\nCensus-calibrated income and demographic statistics -- choose labor supply to\nmaximize text-based utility functions learned in-context. At the upper level, a\nplanner agent employs in-context reinforcement learning to propose\npiecewise-linear marginal tax schedules anchored to the current U.S. federal\nbrackets. This construction endows economic simulacra with three capabilities\nrequisite for credible fiscal experimentation: (i) optimization of\nheterogeneous utilities, (ii) principled generation of large, demographically\nrealistic agent populations, and (iii) mechanism design -- the ultimate nudging\nproblem -- expressed entirely in natural language. Experiments with populations\nof up to one hundred interacting agents show that the planner converges near\nStackelberg equilibria that improve aggregate social welfare relative to Saez\nsolutions, while a periodic, persona-level voting procedure furthers these\ngains under decentralized governance. These results demonstrate that large\nlanguage model-based agents can jointly model, simulate, and govern complex\neconomic systems, providing a tractable test bed for policy evaluation at the\nsocietal scale to help build better civilizations.", "AI": {"tldr": "\u63d0\u51faLLM Economist\u6846\u67b6\uff0c\u7528\u57fa\u4e8e\u4ee3\u7406\u7684\u5efa\u6a21\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7ecf\u6d4e\u653f\u7b56\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u6539\u5584\u793e\u4f1a\u798f\u5229\uff0c\u4e3a\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u6d4b\u8bd5\u5e8a\u3002", "motivation": "\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u5728\u5206\u5c42\u51b3\u7b56\u7684\u6218\u7565\u73af\u5883\u4e2d\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7ecf\u6d4e\u653f\u7b56\u7684\u6846\u67b6\u3002", "method": "\u5728\u4e0b\u5c42\uff0c\u7528\u57fa\u4e8e\u7f8e\u56fd\u4eba\u53e3\u666e\u67e5\u6570\u636e\u7684\u53d7\u9650\u7406\u6027\u5de5\u4eba\u4ee3\u7406\u9009\u62e9\u52b3\u52a8\u529b\u4f9b\u5e94\uff1b\u4e0a\u5c42\uff0c\u89c4\u5212\u4ee3\u7406\u7528\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u63d0\u51fa\u5206\u6bb5\u7ebf\u6027\u8fb9\u9645\u7a0e\u7387\u8868\u3002", "result": "\u89c4\u5212\u8005\u6536\u655b\u4e8e\u63a5\u8fd1Stackelberg\u5747\u8861\uff0c\u63d0\u9ad8\u4e86\u793e\u4f1a\u798f\u5229\uff0c\u5468\u671f\u6027\u6295\u7968\u7a0b\u5e8f\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6536\u76ca\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u53ef\u4ee5\u8054\u5408\u5efa\u6a21\u3001\u6a21\u62df\u548c\u6cbb\u7406\u590d\u6742\u7ecf\u6d4e\u7cfb\u7edf\uff0c\u4e3a\u793e\u4f1a\u5c42\u9762\u7684\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u6d4b\u8bd5\u5e8a\u3002"}}
{"id": "2507.15524", "pdf": "https://arxiv.org/pdf/2507.15524", "abs": "https://arxiv.org/abs/2507.15524", "authors": ["Simon Winther Albertsen", "Hjalte Svaneborg Bj\u00f8rnstrup", "Mostafa Mehdipour Ghazi"], "title": "RARE-UNet: Resolution-Aligned Routing Entry for Adaptive Medical Image Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "EMA4MICCAI 2025", "summary": "Accurate segmentation is crucial for clinical applications, but existing\nmodels often assume fixed, high-resolution inputs and degrade significantly\nwhen faced with lower-resolution data in real-world scenarios. To address this\nlimitation, we propose RARE-UNet, a resolution-aware multi-scale segmentation\narchitecture that dynamically adapts its inference path to the spatial\nresolution of the input. Central to our design are multi-scale blocks\nintegrated at multiple encoder depths, a resolution-aware routing mechanism,\nand consistency-driven training that aligns multi-resolution features with\nfull-resolution representations. We evaluate RARE-UNet on two benchmark brain\nimaging tasks for hippocampus and tumor segmentation. Compared to standard\nUNet, its multi-resolution augmented variant, and nnUNet, our model achieves\nthe highest average Dice scores of 0.84 and 0.65 across resolution, while\nmaintaining consistent performance and significantly reduced inference time at\nlower resolutions. These results highlight the effectiveness and scalability of\nour architecture in achieving resolution-robust segmentation. The codes are\navailable at: https://github.com/simonsejse/RARE-UNet.", "AI": {"tldr": "\u63d0\u51faRARE - UNet\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u5904\u7406\u4f4e\u5206\u8fa8\u7387\u6570\u636e\u65f6\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5728\u8111\u6210\u50cf\u5206\u5272\u4efb\u52a1\u8868\u73b0\u4f18\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5047\u8bbe\u56fa\u5b9a\u9ad8\u5206\u8fa8\u7387\u8f93\u5165\uff0c\u5728\u73b0\u5b9e\u4f4e\u5206\u8fa8\u7387\u6570\u636e\u573a\u666f\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u9700\u89e3\u51b3\u6b64\u9650\u5236\u3002", "method": "\u63d0\u51faRARE - UNet\uff0c\u5305\u542b\u591a\u5c3a\u5ea6\u5757\u3001\u5206\u8fa8\u7387\u611f\u77e5\u8def\u7531\u673a\u5236\u548c\u4e00\u81f4\u6027\u9a71\u52a8\u8bad\u7ec3\u3002", "result": "\u5728\u4e24\u4e2a\u8111\u6210\u50cf\u5206\u5272\u4efb\u52a1\u4e0a\uff0c\u76f8\u6bd4\u6807\u51c6UNet\u7b49\u6a21\u578b\uff0c\u5e73\u5747Dice\u5206\u6570\u6700\u9ad8\uff0c\u4f4e\u5206\u8fa8\u7387\u4e0b\u6027\u80fd\u7a33\u5b9a\u4e14\u63a8\u7406\u65f6\u95f4\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "RARE - UNet\u5728\u5b9e\u73b0\u5206\u8fa8\u7387\u9c81\u68d2\u5206\u5272\u65b9\u9762\u6709\u6548\u4e14\u53ef\u6269\u5c55\u3002"}}
{"id": "2507.15849", "pdf": "https://arxiv.org/pdf/2507.15849", "abs": "https://arxiv.org/abs/2507.15849", "authors": ["Yihao Li", "Jiayi Xin", "Miranda Muqing Miao", "Qi Long", "Lyle Ungar"], "title": "The Impact of Language Mixing on Bilingual LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Proficient multilingual speakers often intentionally switch languages in the\nmiddle of a conversation. Similarly, recent reasoning-focused bilingual large\nlanguage models (LLMs) with strong capabilities in both languages exhibit\nlanguage mixing--alternating languages within their chain of thought.\nDiscouraging this behavior in DeepSeek-R1 was found to degrade accuracy,\nsuggesting that language mixing may benefit reasoning. In this work, we study\nlanguage switching in Chinese-English bilingual reasoning models. We identify\nreinforcement learning with verifiable rewards (RLVR) as the critical training\nstage that leads to language mixing. We demonstrate that language mixing can\nenhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6\npercentage points on math reasoning tasks. Additionally, a lightweight probe\ncan be trained to predict whether a potential language switch would benefit or\nharm reasoning, and when used to guide decoding, increases accuracy by up to\n6.25 percentage points. Our findings suggest that language mixing is not merely\na byproduct of multilingual training, but is a strategic reasoning behavior.", "AI": {"tldr": "\u7814\u7a76\u4e2d\u82f1\u53cc\u8bed\u63a8\u7406\u6a21\u578b\u8bed\u8a00\u5207\u6362\uff0c\u53d1\u73b0\u8bed\u8a00\u6df7\u5408\u6709\u76ca\u63a8\u7406\uff0cRLVR\u8bad\u7ec3\u9636\u6bb5\u81f4\u8bed\u8a00\u6df7\u5408\uff0c\u7528\u8f7b\u91cf\u7ea7\u63a2\u9488\u5f15\u5bfc\u89e3\u7801\u53ef\u63d0\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u8ba8\u53cc\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u8bed\u8a00\u6df7\u5408\u73b0\u8c61\u53ca\u5bf9\u63a8\u7406\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u53cc\u8bed\u63a8\u7406\u6a21\u578b\u4e2d\u8bed\u8a00\u5207\u6362\u3002", "method": "\u786e\u5b9aRLVR\u4e3a\u5bfc\u81f4\u8bed\u8a00\u6df7\u5408\u7684\u5173\u952e\u8bad\u7ec3\u9636\u6bb5\uff0c\u7528\u5f3a\u5236\u5355\u8bed\u89e3\u7801\u5bf9\u6bd4\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u63a2\u9488\u9884\u6d4b\u8bed\u8a00\u5207\u6362\u5f71\u54cd\u5e76\u5f15\u5bfc\u89e3\u7801\u3002", "result": "\u5f3a\u5236\u5355\u8bed\u89e3\u7801\u4f7f\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u51c6\u786e\u7387\u964d5.6\u4e2a\u767e\u5206\u70b9\uff0c\u8f7b\u91cf\u7ea7\u63a2\u9488\u5f15\u5bfc\u89e3\u7801\u4f7f\u51c6\u786e\u7387\u6700\u591a\u63d0\u53476.25\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8bed\u8a00\u6df7\u5408\u4e0d\u662f\u591a\u8bed\u8a00\u8bad\u7ec3\u526f\u4ea7\u54c1\uff0c\u800c\u662f\u7b56\u7565\u6027\u63a8\u7406\u884c\u4e3a\u3002"}}
{"id": "2507.15585", "pdf": "https://arxiv.org/pdf/2507.15585", "abs": "https://arxiv.org/abs/2507.15585", "authors": ["Atreya Ghosal", "Ashim Gupta", "Vivek Srikumar"], "title": "Unequal Voices: How LLMs Construct Constrained Queer Narratives", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "One way social groups are marginalized in discourse is that the narratives\ntold about them often default to a narrow, stereotyped range of topics. In\ncontrast, default groups are allowed the full complexity of human existence. We\ndescribe the constrained representations of queer people in LLM generations in\nterms of harmful representations, narrow representations, and discursive\nothering and formulate hypotheses to test for these phenomena. Our results show\nthat LLMs are significantly limited in their portrayals of queer personas.", "AI": {"tldr": "\u7814\u7a76\u6307\u51fa\u793e\u4f1a\u7fa4\u4f53\u5728\u8bdd\u8bed\u4e2d\u88ab\u8fb9\u7f18\u5316\u8868\u73b0\u4e3a\u53d9\u4e8b\u8bdd\u9898\u72ed\u9698\uff0c\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bf9\u9177\u513f\u7fa4\u4f53\u7684\u8868\u8ff0\u5b58\u5728\u5c40\u9650\u3002", "motivation": "\u63a2\u7a76\u793e\u4f1a\u7fa4\u4f53\u5728\u8bdd\u8bed\u4e2d\u88ab\u8fb9\u7f18\u5316\u7684\u73b0\u8c61\uff0c\u805a\u7126\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9177\u513f\u7fa4\u4f53\u7684\u8868\u8ff0\u60c5\u51b5\u3002", "method": "\u4ece\u6709\u5bb3\u8868\u8ff0\u3001\u72ed\u9698\u8868\u8ff0\u548c\u8bdd\u8bed\u4ed6\u8005\u5316\u65b9\u9762\u63cf\u8ff0\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9177\u513f\u7fa4\u4f53\u7684\u53d7\u9650\u8868\u8ff0\uff0c\u5e76\u63d0\u51fa\u5047\u8bbe\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9177\u513f\u89d2\u8272\u7684\u63cf\u7ed8\u5b58\u5728\u663e\u8457\u5c40\u9650\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5448\u73b0\u9177\u513f\u7fa4\u4f53\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002"}}
{"id": "2507.15613", "pdf": "https://arxiv.org/pdf/2507.15613", "abs": "https://arxiv.org/abs/2507.15613", "authors": ["Andrii Balashov", "Olena Ponomarova", "Xiaohua Zhai"], "title": "Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems", "categories": ["cs.CR", "cs.AI"], "comment": "26 pages", "summary": "Large Language Models (LLMs) deployed in enterprise settings (e.g., as\nMicrosoft 365 Copilot) face novel security challenges. One critical threat is\nprompt inference attacks: adversaries chain together seemingly benign prompts\nto gradually extract confidential data. In this paper, we present a\ncomprehensive study of multi-stage prompt inference attacks in an enterprise\nLLM context. We simulate realistic attack scenarios where an attacker uses\nmild-mannered queries and indirect prompt injections to exploit an LLM\nintegrated with private corporate data. We develop a formal threat model for\nthese multi-turn inference attacks and analyze them using probability theory,\noptimization frameworks, and information-theoretic leakage bounds. The attacks\nare shown to reliably exfiltrate sensitive information from the LLM's context\n(e.g., internal SharePoint documents or emails), even when standard safety\nmeasures are in place.\n  We propose and evaluate defenses to counter such attacks, including\nstatistical anomaly detection, fine-grained access control, prompt sanitization\ntechniques, and architectural modifications to LLM deployment. Each defense is\nsupported by mathematical analysis or experimental simulation. For example, we\nderive bounds on information leakage under differential privacy-based training\nand demonstrate an anomaly detection method that flags multi-turn attacks with\nhigh AUC. We also introduce an approach called \"spotlighting\" that uses input\ntransformations to isolate untrusted prompt content, reducing attack success by\nan order of magnitude. Finally, we provide a formal proof of concept and\nempirical validation for a combined defense-in-depth strategy. Our work\nhighlights that securing LLMs in enterprise settings requires moving beyond\nsingle-turn prompt filtering toward a holistic, multi-stage perspective on both\nattacks and defenses.", "AI": {"tldr": "\u7814\u7a76\u4f01\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u591a\u9636\u6bb5\u63d0\u793a\u63a8\u7406\u653b\u51fb\uff0c\u63d0\u51fa\u591a\u79cd\u9632\u5fa1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5168\u9762\u5b89\u5168\u89c6\u89d2\u3002", "motivation": "\u4f01\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u63d0\u793a\u63a8\u7406\u653b\u51fb\u7b49\u65b0\u5b89\u5168\u6311\u6218\uff0c\u9700\u7814\u7a76\u5e94\u5bf9\u65b9\u6cd5\u3002", "method": "\u6a21\u62df\u653b\u51fb\u573a\u666f\uff0c\u5efa\u7acb\u5f62\u5f0f\u5316\u5a01\u80c1\u6a21\u578b\uff0c\u7528\u6982\u7387\u7406\u8bba\u7b49\u5206\u6790\uff1b\u63d0\u51fa\u7edf\u8ba1\u5f02\u5e38\u68c0\u6d4b\u7b49\u9632\u5fa1\u65b9\u6cd5\uff0c\u8fdb\u884c\u6570\u5b66\u5206\u6790\u548c\u5b9e\u9a8c\u6a21\u62df\u3002", "result": "\u653b\u51fb\u80fd\u53ef\u9760\u7a83\u53d6\u654f\u611f\u4fe1\u606f\uff1b\u5404\u9632\u5fa1\u65b9\u6cd5\u6709\u6570\u5b66\u5206\u6790\u6216\u5b9e\u9a8c\u652f\u6301\uff0c\u5982\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u4fe1\u606f\u6cc4\u6f0f\u8fb9\u754c\u3001\u9ad8AUC\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7b49\u3002", "conclusion": "\u4f01\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u9700\u8d85\u8d8a\u5355\u8f6e\u63d0\u793a\u8fc7\u6ee4\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u6574\u4f53\u89c6\u89d2\u3002"}}
{"id": "2507.15617", "pdf": "https://arxiv.org/pdf/2507.15617", "abs": "https://arxiv.org/abs/2507.15617", "authors": ["David Bann", "Ed Lowther", "Liam Wright", "Yevgeniya Kovalchuk"], "title": "Why can't Epidemiology be automated (yet)?", "categories": ["cs.CY", "cs.AI"], "comment": "9 pages, 2 figures, 1 table", "summary": "Recent advances in artificial intelligence (AI) - particularly generative AI\n- present new opportunities to accelerate, or even automate, epidemiological\nresearch. Unlike disciplines based on physical experimentation, a sizable\nfraction of Epidemiology relies on secondary data analysis and thus is\nwell-suited for such augmentation. Yet, it remains unclear which specific tasks\ncan benefit from AI interventions or where roadblocks exist. Awareness of\ncurrent AI capabilities is also mixed. Here, we map the landscape of\nepidemiological tasks using existing datasets - from literature review to data\naccess, analysis, writing up, and dissemination - and identify where existing\nAI tools offer efficiency gains. While AI can increase productivity in some\nareas such as coding and administrative tasks, its utility is constrained by\nlimitations of existing AI models (e.g. hallucinations in literature reviews)\nand human systems (e.g. barriers to accessing datasets). Through examples of\nAI-generated epidemiological outputs, including fully AI-generated papers, we\ndemonstrate that recently developed agentic systems can now design and execute\nepidemiological analysis, albeit to varied quality (see\nhttps://github.com/edlowther/automated-epidemiology). Epidemiologists have new\nopportunities to empirically test and benchmark AI systems; realising the\npotential of AI will require two-way engagement between epidemiologists and\nengineers.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5728\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u6307\u51fa\u5176\u6709\u63d0\u5347\u6548\u7387\u7684\u53ef\u80fd\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\uff0c\u9700\u6d41\u884c\u75c5\u5b66\u5bb6\u548c\u5de5\u7a0b\u5e08\u53cc\u5411\u5408\u4f5c\u3002", "motivation": "\u660e\u786e\u4eba\u5de5\u667a\u80fd\u53ef\u52a0\u901f\u751a\u81f3\u81ea\u52a8\u5316\u6d41\u884c\u75c5\u5b66\u7814\u7a76\uff0c\u4f46\u4e0d\u6e05\u695a\u5177\u4f53\u54ea\u4e9b\u4efb\u52a1\u80fd\u53d7\u76ca\u53ca\u5b58\u5728\u7684\u969c\u788d\uff0c\u4e14\u5bf9\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u80fd\u529b\u8ba4\u77e5\u4e0d\u4e00\u3002", "method": "\u68b3\u7406\u5229\u7528\u73b0\u6709\u6570\u636e\u96c6\u7684\u6d41\u884c\u75c5\u5b66\u4efb\u52a1\uff0c\u5206\u6790\u73b0\u6709AI\u5de5\u5177\u5728\u5404\u73af\u8282\u7684\u6548\u7387\u63d0\u5347\u60c5\u51b5\uff0c\u5e76\u901a\u8fc7AI\u751f\u6210\u7684\u6d41\u884c\u75c5\u5b66\u6210\u679c\u4e3e\u4f8b\u3002", "result": "AI\u5728\u7f16\u7801\u548c\u884c\u653f\u4efb\u52a1\u7b49\u65b9\u9762\u53ef\u63d0\u9ad8\u751f\u4ea7\u529b\uff0c\u4f46\u53d7\u73b0\u6709AI\u6a21\u578b\u548c\u4eba\u7c7b\u7cfb\u7edf\u9650\u5236\uff1b\u8fd1\u671f\u5f00\u53d1\u7684\u667a\u80fd\u7cfb\u7edf\u80fd\u8fdb\u884c\u6d41\u884c\u75c5\u5b66\u5206\u6790\uff0c\u4f46\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\u3002", "conclusion": "\u6d41\u884c\u75c5\u5b66\u5bb6\u6709\u673a\u4f1a\u5bf9AI\u7cfb\u7edf\u8fdb\u884c\u5b9e\u8bc1\u6d4b\u8bd5\u548c\u57fa\u51c6\u8bc4\u4f30\uff0c\u5b9e\u73b0AI\u6f5c\u529b\u9700\u8981\u6d41\u884c\u75c5\u5b66\u5bb6\u548c\u5de5\u7a0b\u5e08\u53cc\u5411\u5408\u4f5c\u3002"}}
{"id": "2507.15636", "pdf": "https://arxiv.org/pdf/2507.15636", "abs": "https://arxiv.org/abs/2507.15636", "authors": ["Lisan Al Amin", "Md. Ismail Hossain", "Thanh Thi Nguyen", "Tasnim Jahan", "Mahbubul Islam", "Faisal Quader"], "title": "Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted for publication at the 2025 IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC)", "summary": "Recent advances in deepfake technology have created increasingly convincing\nsynthetic media that poses significant challenges to information integrity and\nsocial trust. While current detection methods show promise, their underlying\nmechanisms remain poorly understood, and the large sizes of their models make\nthem challenging to deploy in resource-limited environments. This study\ninvestigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake\ndetection, aiming to identify the key features crucial for recognizing\ndeepfakes. We examine how neural networks can be efficiently pruned while\nmaintaining high detection accuracy. Through extensive experiments with\nMesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and\nFaceForensics++ datasets, we find that deepfake detection networks contain\nwinning tickets, i.e., subnetworks, that preserve performance even at\nsubstantial sparsity levels. Our results indicate that MesoNet retains 56.2%\naccuracy at 80% sparsity on the OpenForensic dataset, with only 3,000\nparameters, which is about 90% of its baseline accuracy (62.6%). The results\nalso show that our proposed LTH-based iterative magnitude pruning approach\nconsistently outperforms one-shot pruning methods. Using Grad-CAM\nvisualization, we analyze how pruned networks maintain their focus on critical\nfacial regions for deepfake detection. Additionally, we demonstrate the\ntransferability of winning tickets across datasets, suggesting potential for\nefficient, deployable deepfake detection systems.", "AI": {"tldr": "\u7814\u7a76\u5c06\u5f69\u7968\u5047\u8bf4\u5e94\u7528\u4e8e\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u68c0\u6d4b\u7f51\u7edc\u5b58\u5728\u4fdd\u7559\u6027\u80fd\u7684\u5b50\u7f51\u7edc\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u4e00\u6b21\u6027\u526a\u679d\u6cd5\uff0c\u8fd8\u8bc1\u660e\u4e86\u4e2d\u5956\u5f69\u7968\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u65b9\u6cd5\u673a\u5236\u4e0d\u660e\u4e14\u6a21\u578b\u5927\uff0c\u96be\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u90e8\u7f72\uff0c\u9700\u627e\u51fa\u8bc6\u522b\u6df1\u5ea6\u4f2a\u9020\u7684\u5173\u952e\u7279\u5f81\u3002", "method": "\u7814\u7a76\u5f69\u7968\u5047\u8bf4\u5728\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u5bf9MesoNet\u3001CNN - 5\u548cResNet - 18\u67b6\u6784\u8fdb\u884c\u526a\u679d\uff0c\u91c7\u7528\u57fa\u4e8e\u5f69\u7968\u5047\u8bf4\u7684\u8fed\u4ee3\u5e45\u5ea6\u526a\u679d\u65b9\u6cd5\uff0c\u7528Grad - CAM\u53ef\u89c6\u5316\u5206\u6790\u3002", "result": "\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7f51\u7edc\u5b58\u5728\u4e2d\u5956\u5f69\u7968\uff08\u5b50\u7f51\u7edc\uff09\uff0cMesoNet\u5728OpenForensic\u6570\u636e\u96c680%\u7a00\u758f\u5ea6\u4e0b\u4fdd\u755956.2%\u51c6\u786e\u7387\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u4e00\u6b21\u6027\u526a\u679d\u6cd5\uff0c\u4e2d\u5956\u5f69\u7968\u53ef\u8de8\u6570\u636e\u96c6\u8fc1\u79fb\u3002", "conclusion": "\u5f69\u7968\u5047\u8bf4\u53ef\u7528\u4e8e\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c\u80fd\u9ad8\u6548\u526a\u679d\u7f51\u7edc\uff0c\u6709\u671b\u6784\u5efa\u9ad8\u6548\u53ef\u90e8\u7f72\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002"}}
{"id": "2507.15641", "pdf": "https://arxiv.org/pdf/2507.15641", "abs": "https://arxiv.org/abs/2507.15641", "authors": ["Alessio Pittiglio"], "title": "Leveraging Context for Multimodal Fallacy Classification in Political Debates", "categories": ["cs.CL", "cs.AI"], "comment": "12th Workshop on Argument Mining (ArgMining 2025) @ ACL 2025", "summary": "In this paper, we present our submission to the MM-ArgFallacy2025 shared\ntask, which aims to advance research in multimodal argument mining, focusing on\nlogical fallacies in political debates. Our approach uses pretrained\nTransformer-based models and proposes several ways to leverage context. In the\nfallacy classification subtask, our models achieved macro F1-scores of 0.4444\n(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed\nperformance comparable to the text-only model, suggesting potential for\nimprovements.", "AI": {"tldr": "\u4ecb\u7ecdMM - ArgFallacy2025\u5171\u4eab\u4efb\u52a1\u63d0\u4ea4\u60c5\u51b5\uff0c\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u53ca\u4e0a\u4e0b\u6587\u5229\u7528\u65b9\u6cd5\uff0c\u7ed9\u51fa\u5404\u6a21\u6001\u8c2c\u8bef\u5206\u7c7bF1\u5206\u6570\uff0c\u663e\u793a\u591a\u6a21\u6001\u6a21\u578b\u6f5c\u529b\u3002", "motivation": "\u63a8\u8fdb\u591a\u6a21\u6001\u8bba\u8bc1\u6316\u6398\u7814\u7a76\uff0c\u805a\u7126\u653f\u6cbb\u8fa9\u8bba\u4e2d\u7684\u903b\u8f91\u8c2c\u8bef\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\u3002", "result": "\u5728\u8c2c\u8bef\u5206\u7c7b\u5b50\u4efb\u52a1\u4e2d\uff0c\u6587\u672c\u3001\u97f3\u9891\u548c\u591a\u6a21\u6001\u7684\u5b8f\u89c2F1\u5206\u6570\u5206\u522b\u4e3a0.4444\u30010.3559\u548c0.4403\uff0c\u591a\u6a21\u6001\u6a21\u578b\u6027\u80fd\u4e0e\u7eaf\u6587\u672c\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u591a\u6a21\u6001\u6a21\u578b\u6709\u6539\u8fdb\u6f5c\u529b\u3002"}}
{"id": "2507.15686", "pdf": "https://arxiv.org/pdf/2507.15686", "abs": "https://arxiv.org/abs/2507.15686", "authors": ["Wenjie Huang", "Qi Yang", "Shuting Xia", "He Huang", "Zhu Li", "Yiling Xu"], "title": "LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICCV 2025", "summary": "Existing AI-based point cloud compression methods struggle with dependence on\nspecific training data distributions, which limits their real-world deployment.\nImplicit Neural Representation (INR) methods solve the above problem by\nencoding overfitted network parameters to the bitstream, resulting in more\ndistribution-agnostic results. However, due to the limitation of encoding time\nand decoder size, current INR based methods only consider lossy geometry\ncompression. In this paper, we propose the first INR based lossless point cloud\ngeometry compression method called Lossless Implicit Neural Representations for\nPoint Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we\ndesign a group of point clouds level coding framework with an effective network\ninitialization strategy, which can reduce around 60% encoding time. A\nlightweight coding network based on multiscale SparseConv, consisting of scale\ncontext extraction, child node prediction, and model compression modules, is\nproposed to realize fast inference and compact decoder size. Experimental\nresults show that our method consistently outperforms traditional and AI-based\nmethods: for example, with the convergence time in the MVUB dataset, our method\nreduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and\n21.95% compared to SparsePCGC. Our project can be seen on\nhttps://huangwenjie2023.github.io/LINR-PCGC/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8eINR\u7684\u65e0\u635f\u70b9\u4e91\u51e0\u4f55\u538b\u7f29\u65b9\u6cd5LINR - PCGC\uff0c\u8bbe\u8ba1\u7f16\u7801\u6846\u67b6\u548c\u8f7b\u91cf\u7ea7\u7f16\u7801\u7f51\u7edc\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u548cAI\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eAI\u7684\u70b9\u4e91\u538b\u7f29\u65b9\u6cd5\u4f9d\u8d56\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\u5206\u5e03\uff0c\u5f53\u524d\u57fa\u4e8eINR\u7684\u65b9\u6cd5\u4ec5\u8003\u8651\u6709\u635f\u51e0\u4f55\u538b\u7f29\uff0c\u9700\u65e0\u635f\u70b9\u4e91\u51e0\u4f55\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLINR - PCGC\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u70b9\u4e91\u7ea7\u7f16\u7801\u6846\u67b6\u548c\u6709\u6548\u7f51\u7edc\u521d\u59cb\u5316\u7b56\u7565\u52a0\u901f\u7f16\u7801\uff0c\u63d0\u51fa\u57fa\u4e8e\u591a\u5c3a\u5ea6SparseConv\u7684\u8f7b\u91cf\u7ea7\u7f16\u7801\u7f51\u7edc\u5b9e\u73b0\u5feb\u901f\u63a8\u7406\u548c\u7d27\u51d1\u89e3\u7801\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728MVUB\u6570\u636e\u96c6\u6536\u655b\u65f6\u95f4\u4e0b\uff0c\u6bd4\u7279\u6d41\u6bd4G - PCC TMC13v23\u51cf\u5c11\u7ea621.21%\uff0c\u6bd4SparsePCGC\u51cf\u5c1121.95%\u3002", "conclusion": "LINR - PCGC\u65b9\u6cd5\u6709\u6548\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u548cAI\u65b9\u6cd5\u3002"}}
{"id": "2507.15706", "pdf": "https://arxiv.org/pdf/2507.15706", "abs": "https://arxiv.org/abs/2507.15706", "authors": ["David Peter Wallis Freeborn"], "title": "Compositional Understanding in Signaling Games", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Receivers in standard signaling game models struggle with learning\ncompositional information. Even when the signalers send compositional messages,\nthe receivers do not interpret them compositionally. When information from one\nmessage component is lost or forgotten, the information from other components\nis also erased. In this paper I construct signaling game models in which\ngenuine compositional understanding evolves. I present two new models: a\nminimalist receiver who only learns from the atomic messages of a signal, and a\ngeneralist receiver who learns from all of the available information. These\nmodels are in many ways simpler than previous alternatives, and allow the\nreceivers to learn from the atomic components of messages.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4fe1\u53f7\u535a\u5f08\u6a21\u578b\u4f7f\u63a5\u6536\u8005\u5b9e\u73b0\u771f\u6b63\u7684\u7ec4\u5408\u7406\u89e3\uff0c\u63d0\u51fa\u6781\u7b80\u63a5\u6536\u8005\u548c\u901a\u624d\u63a5\u6536\u8005\u4e24\u79cd\u65b0\u6a21\u578b\u3002", "motivation": "\u6807\u51c6\u4fe1\u53f7\u535a\u5f08\u6a21\u578b\u4e2d\u63a5\u6536\u8005\u96be\u4ee5\u5b66\u4e60\u7ec4\u5408\u4fe1\u606f\uff0c\u5373\u4fbf\u4fe1\u53f7\u53d1\u9001\u8005\u53d1\u9001\u7ec4\u5408\u6d88\u606f\uff0c\u63a5\u6536\u8005\u4e5f\u65e0\u6cd5\u8fdb\u884c\u7ec4\u5408\u89e3\u8bfb\uff0c\u4e14\u4e00\u4e2a\u6d88\u606f\u7ec4\u4ef6\u4fe1\u606f\u4e22\u5931\u65f6\u5176\u4ed6\u7ec4\u4ef6\u4fe1\u606f\u4e5f\u4f1a\u88ab\u62b9\u53bb\u3002", "method": "\u6784\u5efa\u4e24\u79cd\u65b0\u7684\u4fe1\u53f7\u535a\u5f08\u6a21\u578b\uff0c\u5373\u53ea\u4ece\u4fe1\u53f7\u539f\u5b50\u6d88\u606f\u5b66\u4e60\u7684\u6781\u7b80\u63a5\u6536\u8005\u6a21\u578b\u548c\u4ece\u6240\u6709\u53ef\u7528\u4fe1\u606f\u5b66\u4e60\u7684\u901a\u624d\u63a5\u6536\u8005\u6a21\u578b\u3002", "result": "\u65b0\u6a21\u578b\u5728\u5f88\u591a\u65b9\u9762\u6bd4\u4ee5\u5f80\u6a21\u578b\u66f4\u7b80\u5355\uff0c\u80fd\u8ba9\u63a5\u6536\u8005\u4ece\u6d88\u606f\u7684\u539f\u5b50\u7ec4\u4ef6\u4e2d\u5b66\u4e60\u3002", "conclusion": "\u65b0\u6784\u5efa\u7684\u6a21\u578b\u53ef\u4f7f\u63a5\u6536\u8005\u5b9e\u73b0\u771f\u6b63\u7684\u7ec4\u5408\u7406\u89e3\u3002"}}
{"id": "2507.15707", "pdf": "https://arxiv.org/pdf/2507.15707", "abs": "https://arxiv.org/abs/2507.15707", "authors": ["Seok Hwan Song", "Mohna Chakraborty", "Qi Li", "Wallapak Tavanapong"], "title": "Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been evaluated using diverse question\ntypes, e.g., multiple-choice, true/false, and short/long answers. This study\nanswers an unexplored question about the impact of different question types on\nLLM accuracy on reasoning tasks. We investigate the performance of five LLMs on\nthree different types of questions using quantitative and deductive reasoning\ntasks. The performance metrics include accuracy in the reasoning steps and\nchoosing the final answer. Key Findings: (1) Significant differences exist in\nLLM performance across different question types. (2) Reasoning accuracy does\nnot necessarily correlate with the final selection accuracy. (3) The number of\noptions and the choice of words, influence LLM performance.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4efb\u52a1\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u4e0b\u6a21\u578b\u8868\u73b0\u6709\u5dee\u5f02\u7b49\u3002", "motivation": "\u56de\u7b54\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4efb\u52a1\u51c6\u786e\u6027\u5f71\u54cd\u8fd9\u4e00\u672a\u63a2\u7d22\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5b9a\u91cf\u548c\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\uff0c\u7814\u7a76\u4e94\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u79cd\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u91c7\u7528\u63a8\u7406\u6b65\u9aa4\u51c6\u786e\u6027\u548c\u6700\u7ec8\u7b54\u6848\u9009\u62e9\u51c6\u786e\u6027\u7b49\u6307\u6807\u3002", "result": "\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b\u63a8\u7406\u51c6\u786e\u6027\u4e0d\u4e00\u5b9a\u4e0e\u6700\u7ec8\u9009\u62e9\u51c6\u786e\u6027\u76f8\u5173\uff1b\u9009\u9879\u6570\u91cf\u548c\u7528\u8bcd\u4f1a\u5f71\u54cd\u6a21\u578b\u8868\u73b0\u3002", "conclusion": "\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u4f1a\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4efb\u52a1\u51c6\u786e\u6027\u4ea7\u751f\u5f71\u54cd\u3002"}}
{"id": "2507.15717", "pdf": "https://arxiv.org/pdf/2507.15717", "abs": "https://arxiv.org/abs/2507.15717", "authors": ["Sahana Srinivasan", "Xuguang Ai", "Thaddaeus Wai Soon Lo", "Aidan Gilson", "Minjie Zou", "Ke Zou", "Hyunjae Kim", "Mingjia Yang", "Krithi Pushpanathan", "Samantha Yew", "Wan Ting Loke", "Jocelyn Goh", "Yibing Chen", "Yiming Kong", "Emily Yuelei Fu", "Michelle Ongyong Hui", "Kristen Nwanyanwu", "Amisha Dave", "Kelvin Zhenghao Li", "Chen-Hsin Sun", "Mark Chia", "Gabriel Dawei Yang", "Wendy Meihua Wong", "David Ziyou Chen", "Dianbo Liu", "Maxwell Singer", "Fares Antaki", "Lucian V Del Priore", "Jost Jonas", "Ron Adelman", "Qingyu Chen", "Yih-Chung Tham"], "title": "BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Current benchmarks evaluating large language models (LLMs) in ophthalmology\nare limited in scope and disproportionately prioritise accuracy. We introduce\nBELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive\nevaluation benchmark developed through multiple rounds of expert checking by 13\nophthalmologists. BELO assesses ophthalmology-related clinical accuracy and\nreasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we\ncurated ophthalmology-specific multiple-choice-questions (MCQs) from diverse\nmedical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset\nunderwent multiple rounds of expert checking. Duplicate and substandard\nquestions were systematically removed. Ten ophthalmologists refined the\nexplanations of each MCQ's correct answer. This was further adjudicated by\nthree senior ophthalmologists. To illustrate BELO's utility, we evaluated six\nLLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro)\nusing accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore,\nBARTScore, METEOR, and AlignScore). In a further evaluation involving human\nexperts, two ophthalmologists qualitatively reviewed 50 randomly selected\noutputs for accuracy, comprehensiveness, and completeness. BELO consists of 900\nhigh-quality, expert-reviewed questions aggregated from five sources: BCSC\n(260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public\nleaderboard has been established to promote transparent evaluation and\nreporting. Importantly, the BELO dataset will remain a hold-out,\nevaluation-only benchmark to ensure fair and reproducible comparisons of future\nmodels.", "AI": {"tldr": "\u63d0\u51fa\u773c\u79d1\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6BELO\uff0c\u542b900\u4e2a\u9ad8\u8d28\u91cf\u95ee\u9898\uff0c\u8bc4\u4f30\u591a\u4e2a\u6a21\u578b\u5e76\u8bbe\u516c\u5f00\u6392\u884c\u699c\u3002", "motivation": "\u73b0\u6709\u773c\u79d1\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\u8303\u56f4\u6709\u9650\u4e14\u8fc7\u5ea6\u5173\u6ce8\u51c6\u786e\u6027\uff0c\u9700\u5168\u9762\u8bc4\u4f30\u3002", "method": "\u901a\u8fc713\u4f4d\u773c\u79d1\u4e13\u5bb6\u591a\u8f6e\u68c0\u67e5\u5f00\u53d1BELO\uff0c\u7528\u5173\u952e\u8bcd\u5339\u914d\u548c\u5fae\u8c03\u6a21\u578b\u7b5b\u9009\u9898\u76ee\uff0c\u53bb\u9664\u91cd\u590d\u548c\u4f4e\u8d28\u91cf\u95ee\u9898\uff0c\u7531\u4e13\u5bb6\u5b8c\u5584\u7b54\u6848\u89e3\u91ca\uff1b\u7528\u591a\u79cd\u6307\u6807\u8bc4\u4f306\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e13\u5bb6\u5b9a\u6027\u8bc4\u4f30\u90e8\u5206\u8f93\u51fa\u3002", "result": "BELO\u5305\u542b900\u4e2a\u4e13\u5bb6\u5ba1\u6838\u7684\u9ad8\u8d28\u91cf\u95ee\u9898\uff0c\u6765\u81ea\u4e94\u4e2a\u6570\u636e\u6e90\uff1b\u5efa\u7acb\u516c\u5f00\u6392\u884c\u699c\u3002", "conclusion": "BELO\u4f5c\u4e3a\u8bc4\u4f30\u57fa\u51c6\u53ef\u786e\u4fdd\u672a\u6765\u6a21\u578b\u516c\u5e73\u53ef\u91cd\u590d\u6bd4\u8f83\u3002"}}
{"id": "2507.15752", "pdf": "https://arxiv.org/pdf/2507.15752", "abs": "https://arxiv.org/abs/2507.15752", "authors": ["Ruizhe Zhu", "Hao Zhu", "Yaxuan Li", "Syang Zhou", "Shijing Cai", "Malgorzata Lazuka", "Elliott Ash"], "title": "DialogueForge: LLM Simulation of Human-Chatbot Dialogue", "categories": ["cs.CL", "cs.AI"], "comment": "For our code and data, see\n  https://github.com/nerchio/Human_Chatbot-Generation", "summary": "Collecting human-chatbot dialogues typically demands substantial manual\neffort and is time-consuming, which limits and poses challenges for research on\nconversational AI. In this work, we propose DialogueForge - a framework for\ngenerating AI-simulated conversations in human-chatbot style. To initialize\neach generated conversation, DialogueForge uses seed prompts extracted from\nreal human-chatbot interactions. We test a variety of LLMs to simulate the\nhuman chatbot user, ranging from state-of-the-art proprietary models to\nsmall-scale open-source LLMs, and generate multi-turn dialogues tailored to\nspecific tasks. In addition, we explore fine-tuning techniques to enhance the\nability of smaller models to produce indistinguishable human-like dialogues. We\nevaluate the quality of the simulated conversations and compare different\nmodels using the UniEval and GTEval evaluation protocols. Our experiments show\nthat large proprietary models (e.g., GPT-4o) generally outperform others in\ngenerating more realistic dialogues, while smaller open-source models (e.g.,\nLlama, Mistral) offer promising performance with greater customization. We\ndemonstrate that the performance of smaller models can be significantly\nimproved by employing supervised fine-tuning techniques. Nevertheless,\nmaintaining coherent and natural long-form human-like dialogues remains a\ncommon challenge across all models.", "AI": {"tldr": "\u63d0\u51faDialogueForge\u6846\u67b6\u751f\u6210AI\u6a21\u62df\u7684\u4eba\u673a\u5bf9\u8bdd\uff0c\u6d4b\u8bd5\u591a\u79cd\u5927\u6a21\u578b\uff0c\u8bc4\u4f30\u5bf9\u8bdd\u8d28\u91cf\uff0c\u5927\u6a21\u578b\u8868\u73b0\u4f18\uff0c\u5c0f\u6a21\u578b\u53ef\u901a\u8fc7\u5fae\u8c03\u63d0\u5347\u4f46\u957f\u5bf9\u8bdd\u4ecd\u6709\u6311\u6218\u3002", "motivation": "\u6536\u96c6\u4eba\u673a\u5bf9\u8bdd\u9700\u5927\u91cf\u4eba\u529b\u548c\u65f6\u95f4\uff0c\u9650\u5236\u5bf9\u8bdd\u5f0fAI\u7814\u7a76\uff0c\u56e0\u6b64\u63d0\u51fa\u6846\u67b6\u751f\u6210\u6a21\u62df\u5bf9\u8bdd\u3002", "method": "\u4f7f\u7528\u4ece\u771f\u5b9e\u4eba\u673a\u4ea4\u4e92\u4e2d\u63d0\u53d6\u7684\u79cd\u5b50\u63d0\u793a\u521d\u59cb\u5316\u5bf9\u8bdd\uff0c\u6d4b\u8bd5\u591a\u79cd\u5927\u6a21\u578b\u6a21\u62df\u4eba\u7c7b\u7528\u6237\u751f\u6210\u591a\u8f6e\u5bf9\u8bdd\uff0c\u63a2\u7d22\u5fae\u8c03\u6280\u672f\uff0c\u7528UniEval\u548cGTEval\u8bc4\u4f30\u5bf9\u8bdd\u8d28\u91cf\u3002", "result": "\u5927\u578b\u4e13\u6709\u6a21\u578b\u751f\u6210\u66f4\u771f\u5b9e\u5bf9\u8bdd\uff0c\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u6709\u5b9a\u5236\u4f18\u52bf\uff0c\u5fae\u8c03\u53ef\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u5fae\u8c03\u53ef\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u6240\u6709\u6a21\u578b\u7ef4\u6301\u8fde\u8d2f\u81ea\u7136\u7684\u957f\u5bf9\u8bdd\u4ecd\u662f\u6311\u6218\u3002"}}
{"id": "2507.15775", "pdf": "https://arxiv.org/pdf/2507.15775", "abs": "https://arxiv.org/abs/2507.15775", "authors": ["Mingyuan Sun", "Zheng Fang", "Jiaxu Wang", "Kunyi Zhang", "Qiang Zhang", "Renjing Xu"], "title": "Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity", "categories": ["gr-qc", "astro-ph.IM", "cs.AI"], "comment": "ICCV 2025", "summary": "We present GravLensX, an innovative method for rendering black holes with\ngravitational lensing effects using neural networks. The methodology involves\ntraining neural networks to fit the spacetime around black holes and then\nemploying these trained models to generate the path of light rays affected by\ngravitational lensing. This enables efficient and scalable simulations of black\nholes with optically thin accretion disks, significantly decreasing the time\nrequired for rendering compared to traditional methods. We validate our\napproach through extensive rendering of multiple black hole systems with\nsuperposed Kerr metric, demonstrating its capability to produce accurate\nvisualizations with significantly $15\\times$ reduced computational time. Our\nfindings suggest that neural networks offer a promising alternative for\nrendering complex astrophysical phenomena, potentially paving a new path to\nastronomical visualization.", "AI": {"tldr": "\u63d0\u51faGravLensX\u65b9\u6cd5\uff0c\u7528\u795e\u7ecf\u7f51\u7edc\u6e32\u67d3\u6709\u5f15\u529b\u900f\u955c\u6548\u5e94\u7684\u9ed1\u6d1e\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5feb\u4e14\u6709\u6548\u3002", "motivation": "\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u6e32\u67d3\u6709\u5f15\u529b\u900f\u955c\u6548\u5e94\u7684\u9ed1\u6d1e\u7684\u65b9\u6cd5\u3002", "method": "\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u62df\u5408\u9ed1\u6d1e\u5468\u56f4\u65f6\u7a7a\uff0c\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u751f\u6210\u53d7\u5f15\u529b\u900f\u955c\u5f71\u54cd\u7684\u5149\u7ebf\u8def\u5f84\u3002", "result": "\u80fd\u5bf9\u6709\u5149\u5b66\u8584\u5438\u79ef\u76d8\u7684\u9ed1\u6d1e\u8fdb\u884c\u9ad8\u6548\u53ef\u6269\u5c55\u6a21\u62df\uff0c\u6e32\u67d3\u591a\u4e2a\u53e0\u52a0Kerr\u5ea6\u91cf\u7684\u9ed1\u6d1e\u7cfb\u7edf\u65f6\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1115\u500d\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u4e3a\u6e32\u67d3\u590d\u6742\u5929\u4f53\u7269\u7406\u73b0\u8c61\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u53ef\u80fd\u4e3a\u5929\u6587\u53ef\u89c6\u5316\u5f00\u8f9f\u65b0\u9053\u8def\u3002"}}
{"id": "2507.15783", "pdf": "https://arxiv.org/pdf/2507.15783", "abs": "https://arxiv.org/abs/2507.15783", "authors": ["Mohammad 'Matt' Namvarpour", "Brandon Brofsky", "Jessica Medina", "Mamtaj Akter", "Afsaneh Razi"], "title": "Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "As Generative Artificial Intelligence (GenAI) driven chatbots like\nCharacter.AI become embedded in adolescent life, they raise concerns about\nemotional dependence and digital overreliance. While studies have investigated\nthe overreliance of adults on these chatbots, they have not investigated teens'\ninteractions with chatbots with customizable personas. We analyzed 318 Reddit\nposts made by users self-reported as 13-17 years old on the Character.AI\nsubreddit to understand patterns of overreliance. We found teens commonly begin\nusing chatbots for emotional support or creative expression, but many develop\nstrong attachments that interfere with offline relationships and daily\nroutines. Their posts revealed recurring signs of psychological distress,\ncycles of relapse, and difficulty disengaging. Teens reported that their\noverreliance often ended when they reflect on the harm, return to in-person\nsocial settings, or become frustrated by platform restrictions. Based on the\nimplications of our findings, we provide recommendations for future chatbot\ndesign so they can promote self-awareness, support real-world engagement, and\ninvolve teens in developing safer digital tools.", "AI": {"tldr": "\u5206\u6790\u9752\u5c11\u5e74\u5bf9Character.AI\u804a\u5929\u673a\u5668\u4eba\u7684\u8fc7\u5ea6\u4f9d\u8d56\u60c5\u51b5\uff0c\u7ed9\u51fa\u672a\u6765\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u5efa\u8bae", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u6d89\u53ca\u9752\u5c11\u5e74\u4e0e\u53ef\u5b9a\u5236\u89d2\u8272\u804a\u5929\u673a\u5668\u4eba\u7684\u4e92\u52a8\uff0c\u9700\u4e86\u89e3\u9752\u5c11\u5e74\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u5f0f", "method": "\u5206\u6790318\u7bc713 - 17\u5c81\u7528\u6237\u5728Character.AI\u5b50\u7248\u5757\u7684Reddit\u5e16\u5b50", "result": "\u9752\u5c11\u5e74\u5e38\u56e0\u60c5\u611f\u652f\u6301\u6216\u521b\u610f\u8868\u8fbe\u4f7f\u7528\u804a\u5929\u673a\u5668\u4eba\uff0c\u540e\u4ea7\u751f\u5f3a\u4f9d\u8d56\uff0c\u5e72\u6270\u7ebf\u4e0b\u5173\u7cfb\u548c\u65e5\u5e38\uff0c\u6709\u5fc3\u7406\u56f0\u6270\u7b49\u95ee\u9898\uff0c\u4f9d\u8d56\u5e38\u56e0\u53cd\u601d\u5371\u5bb3\u3001\u56de\u5f52\u7ebf\u4e0b\u793e\u4ea4\u6216\u5e73\u53f0\u9650\u5236\u7ed3\u675f", "conclusion": "\u4e3a\u672a\u6765\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u63d0\u4f9b\u5efa\u8bae\uff0c\u4fc3\u8fdb\u81ea\u6211\u8ba4\u77e5\u3001\u652f\u6301\u73b0\u5b9e\u53c2\u4e0e\u3001\u8ba9\u9752\u5c11\u5e74\u53c2\u4e0e\u5f00\u53d1\u5b89\u5168\u6570\u5b57\u5de5\u5177"}}
{"id": "2507.15807", "pdf": "https://arxiv.org/pdf/2507.15807", "abs": "https://arxiv.org/abs/2507.15807", "authors": ["Shuo Chen", "Jianzhe Liu", "Zhen Han", "Yan Xia", "Daniel Cremers", "Philip Torr", "Volker Tresp", "Jindong Gu"], "title": "True Multimodal In-Context Learning Needs Attention to the Visual Context", "categories": ["cs.CV", "cs.AI"], "comment": "accepted to COLM 2025", "summary": "Multimodal Large Language Models (MLLMs), built on powerful language\nbackbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new\ntasks from a few multimodal demonstrations consisting of images, questions, and\nanswers. Despite showing noticeable improvement on standard vision-language\ndatasets, current MLLMs struggle to leverage visual information in the\ndemonstrations. Specifically, they tend to neglect visual cues and over-rely on\ntextual patterns, leading to mere text imitation rather than genuine multimodal\nadaptation. This behavior makes MICL still unimodal and largely restricts its\npractical utility. More importantly, this limitation is often concealed by the\nimproved performance on tasks that do not require understanding the visual\ncontext. As a result, how to effectively enhance MICL ability and reliably\nevaluate the MICL performance remains underexplored. To address these issues,\nwe first introduce Dynamic Attention Reallocation (DARA), an efficient\nfine-tuning strategy that encourages models to attend to the visual context by\nrebalancing attention across visual and textual tokens. In addition, we present\nTrueMICL, an MICL-dedicated dataset with both support and test sets that\nexplicitly requires the integration of multimodal information-particularly\nvisual content-for correct task completion. Extensive experiments demonstrate\nthe effectiveness of our holistic solution, showcasing substantial improvements\nin the true multimodal in-context learning capabilities. Code and datasets are\navailable at https://chenxshuo.github.io/true-micl-colm .", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u96be\u4ee5\u5229\u7528\u89c6\u89c9\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u52a8\u6001\u6ce8\u610f\u529b\u91cd\u65b0\u5206\u914d\u7b56\u7565\u548c\u4e13\u7528\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u63d0\u5347\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u96be\u4ee5\u6709\u6548\u5229\u7528\u89c6\u89c9\u4fe1\u606f\uff0c\u5bfc\u81f4\u5b66\u4e60\u4ecd\u4e3a\u5355\u6a21\u6001\uff0c\u4e14\u5bf9\u5176\u80fd\u529b\u589e\u5f3a\u548c\u6027\u80fd\u8bc4\u4f30\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u6ce8\u610f\u529b\u91cd\u65b0\u5206\u914d\uff08DARA\uff09\u5fae\u8c03\u7b56\u7565\uff0c\u901a\u8fc7\u5e73\u8861\u89c6\u89c9\u548c\u6587\u672c\u6807\u8bb0\u7684\u6ce8\u610f\u529b\u8ba9\u6a21\u578b\u5173\u6ce8\u89c6\u89c9\u4e0a\u4e0b\u6587\uff1b\u521b\u5efa\u4e13\u95e8\u7684TrueMICL\u6570\u636e\u96c6\uff0c\u8981\u6c42\u96c6\u6210\u591a\u6a21\u6001\u4fe1\u606f\u5b8c\u6210\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u7684\u6574\u4f53\u89e3\u51b3\u65b9\u6848\u6709\u6548\uff0c\u663e\u8457\u63d0\u5347\u4e86\u771f\u6b63\u7684\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u80fd\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5176\u80fd\u529b\u3002"}}
{"id": "2507.15823", "pdf": "https://arxiv.org/pdf/2507.15823", "abs": "https://arxiv.org/abs/2507.15823", "authors": ["Anton Abilov", "Ke Zhang", "Hemank Lamba", "Elizabeth M. Olson", "Joel R. Tetreault", "Alejandro Jaimes"], "title": "Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work", "categories": ["cs.CL", "cs.AI", "cs.SI"], "comment": null, "summary": "Publications in the AI for Good space have tended to focus on the research\nand model development that can support high-impact applications. However, very\nfew AI for Good papers discuss the process of deploying and collaborating with\nthe partner organization, and the resulting real-world impact. In this work, we\nshare details about the close collaboration with a humanitarian-to-humanitarian\n(H2H) organization and how to not only deploy the AI model in a\nresource-constrained environment, but also how to maintain it for continuous\nperformance updates, and share key takeaways for practitioners.", "AI": {"tldr": "\u6587\u7ae0\u5206\u4eab\u4e0eH2H\u7ec4\u7ec7\u5408\u4f5c\u90e8\u7f72\u548c\u7ef4\u62a4AI\u6a21\u578b\u7ec6\u8282\u53ca\u5173\u952e\u7ecf\u9a8c\u3002", "motivation": "\u73b0\u6709AI for Good\u9886\u57df\u8bba\u6587\u5f88\u5c11\u8ba8\u8bba\u6a21\u578b\u90e8\u7f72\u3001\u5408\u4f5c\u8fc7\u7a0b\u53ca\u5b9e\u9645\u5f71\u54cd\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4e0eH2H\u7ec4\u7ec7\u5bc6\u5207\u5408\u4f5c\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u90e8\u7f72\u5e76\u7ef4\u62a4AI\u6a21\u578b\u3002", "result": "\u5b8c\u6210AI\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7684\u90e8\u7f72\u548c\u6301\u7eed\u6027\u80fd\u66f4\u65b0\u3002", "conclusion": "\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e0e\u5408\u4f5c\u7ec4\u7ec7\u90e8\u7f72\u548c\u7ef4\u62a4AI\u6a21\u578b\u7684\u5173\u952e\u7ecf\u9a8c\u3002"}}
{"id": "2507.15833", "pdf": "https://arxiv.org/pdf/2507.15833", "abs": "https://arxiv.org/abs/2507.15833", "authors": ["Ian Chuang", "Andrew Lee", "Dechen Gao", "Jinyu Zou", "Iman Soltani"], "title": "Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "13 pages, 10 figures", "summary": "Human vision is a highly active process driven by gaze, which directs\nattention and fixation to task-relevant regions and dramatically reduces visual\nprocessing. In contrast, robot learning systems typically rely on passive,\nuniform processing of raw camera images. In this work, we explore how\nincorporating human-like active gaze into robotic policies can enhance both\nefficiency and performance. We build on recent advances in foveated image\nprocessing and apply them to an Active Vision robot system that emulates both\nhuman head movement and eye tracking. Extending prior work on the AV-ALOHA\nrobot simulation platform, we introduce a framework for simultaneously\ncollecting eye-tracking data and robot demonstrations from a human operator as\nwell as a simulation benchmark and dataset for training robot policies that\nincorporate human gaze. Given the widespread use of Vision Transformers (ViTs)\nin robot learning, we integrate gaze information into ViTs using a foveated\npatch tokenization scheme inspired by recent work in image segmentation.\nCompared to uniform patch tokenization, this significantly reduces the number\nof tokens-and thus computation-without sacrificing visual fidelity near regions\nof interest. We also explore two approaches to gaze imitation and prediction\nfrom human data. The first is a two-stage model that predicts gaze to guide\nfoveation and action; the second integrates gaze into the action space,\nallowing the policy to jointly predict gaze and actions end-to-end. Our results\nshow that our method for foveated robot vision not only drastically reduces\ncomputational overhead, but also improves performance for high precision tasks\nand robustness to unseen distractors. Together, these findings suggest that\nhuman-inspired visual processing offers a useful inductive bias for robotic\nvision systems. https://ian-chuang.github.io/gaze-av-aloha/", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u5c06\u7c7b\u4eba\u4e3b\u52a8\u6ce8\u89c6\u878d\u5165\u673a\u5668\u4eba\u7b56\u7565\uff0c\u6784\u5efa\u4e3b\u52a8\u89c6\u89c9\u7cfb\u7edf\uff0c\u91c7\u7528\u65b0\u7684\u6807\u8bb0\u5316\u65b9\u6848\u548c\u4e24\u79cd\u6ce8\u89c6\u6a21\u4eff\u4e0e\u9884\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3001\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4eba\u7c7b\u89c6\u89c9\u662f\u7531\u6ce8\u89c6\u9a71\u52a8\u7684\u4e3b\u52a8\u8fc7\u7a0b\uff0c\u800c\u673a\u5668\u4eba\u5b66\u4e60\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u88ab\u52a8\u3001\u5747\u5300\u7684\u539f\u59cb\u56fe\u50cf\uff0c\u56e0\u6b64\u63a2\u7d22\u5c06\u7c7b\u4eba\u4e3b\u52a8\u6ce8\u89c6\u878d\u5165\u673a\u5668\u4eba\u7b56\u7565\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u57fa\u4e8e\u51f9\u89c6\u56fe\u50cf\u6280\u672f\u6784\u5efa\u4e3b\u52a8\u89c6\u89c9\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u5f15\u5165\u6536\u96c6\u6570\u636e\u548c\u8bad\u7ec3\u7b56\u7565\u7684\u6846\u67b6\uff0c\u5c06\u6ce8\u89c6\u4fe1\u606f\u878d\u5165\u89c6\u89c9\u53d8\u6362\u5668\uff0c\u91c7\u7528\u51f9\u89c6\u6807\u8bb0\u5316\u65b9\u6848\uff0c\u63a2\u7d22\u4e24\u79cd\u6ce8\u89c6\u6a21\u4eff\u548c\u9884\u6d4b\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u51f9\u89c6\u673a\u5668\u4eba\u89c6\u89c9\u65b9\u6cd5\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u63d0\u9ad8\u9ad8\u7cbe\u5ea6\u4efb\u52a1\u6027\u80fd\u548c\u5bf9\u5e72\u6270\u7269\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u53d7\u4eba\u7c7b\u542f\u53d1\u7684\u89c6\u89c9\u5904\u7406\u4e3a\u673a\u5668\u4eba\u89c6\u89c9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u5f52\u7eb3\u504f\u7f6e\u3002"}}
{"id": "2507.15852", "pdf": "https://arxiv.org/pdf/2507.15852", "abs": "https://arxiv.org/abs/2507.15852", "authors": ["Zhixiong Zhang", "Shuangrui Ding", "Xiaoyi Dong", "Songxin He", "Jianfan Lin", "Junsong Tang", "Yuhang Zang", "Yuhang Cao", "Dahua Lin", "Jiaqi Wang"], "title": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction", "categories": ["cs.CV", "cs.AI"], "comment": "project page: https://rookiexiong7.github.io/projects/SeC/; code:\n  https://github.com/OpenIXCLab/SeC; dataset:\n  https://huggingface.co/datasets/OpenIXCLab/SeCVOS", "summary": "Video Object Segmentation (VOS) is a core task in computer vision, requiring\nmodels to track and segment target objects across video frames. Despite notable\nadvances with recent efforts, current techniques still lag behind human\ncapabilities in handling drastic visual variations, occlusions, and complex\nscene changes. This limitation arises from their reliance on appearance\nmatching, neglecting the human-like conceptual understanding of objects that\nenables robust identification across temporal dynamics. Motivated by this gap,\nwe propose Segment Concept (SeC), a concept-driven segmentation framework that\nshifts from conventional feature matching to the progressive construction and\nutilization of high-level, object-centric representations. SeC employs Large\nVision-Language Models (LVLMs) to integrate visual cues across diverse frames,\nconstructing robust conceptual priors. During inference, SeC forms a\ncomprehensive semantic representation of the target based on processed frames,\nrealizing robust segmentation of follow-up frames. Furthermore, SeC adaptively\nbalances LVLM-based semantic reasoning with enhanced feature matching,\ndynamically adjusting computational efforts based on scene complexity. To\nrigorously assess VOS methods in scenarios demanding high-level conceptual\nreasoning and robust semantic understanding, we introduce the Semantic Complex\nScenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160\nmanually annotated multi-scenario videos designed to challenge models with\nsubstantial appearance variations and dynamic scene transformations. In\nparticular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,\nestablishing a new state-of-the-art in concept-aware video object segmentation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6982\u5ff5\u9a71\u52a8\u7684\u5206\u5272\u6846\u67b6SeC\u548cSeCVOS\u57fa\u51c6\uff0cSeC\u5728SeCVOS\u4e0a\u663e\u8457\u4f18\u4e8eSAM 2.1\uff0c\u5b9e\u73b0\u6982\u5ff5\u611f\u77e5\u89c6\u9891\u5bf9\u8c61\u5206\u5272\u65b0SOTA\u3002", "motivation": "\u5f53\u524d\u89c6\u9891\u5bf9\u8c61\u5206\u5272\u6280\u672f\u4f9d\u8d56\u5916\u89c2\u5339\u914d\uff0c\u5728\u5904\u7406\u89c6\u89c9\u53d8\u5316\u3001\u906e\u6321\u548c\u573a\u666f\u53d8\u5316\u65b9\u9762\u4e0d\u5982\u4eba\u7c7b\uff0c\u7f3a\u4e4f\u7c7b\u4eba\u6982\u5ff5\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51faSeC\u6846\u67b6\uff0c\u7528\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u6982\u5ff5\u5148\u9a8c\uff0c\u63a8\u7406\u65f6\u5f62\u6210\u76ee\u6807\u8bed\u4e49\u8868\u793a\uff0c\u81ea\u9002\u5e94\u5e73\u8861\u8bed\u4e49\u63a8\u7406\u548c\u7279\u5f81\u5339\u914d\uff1b\u5f15\u5165SeCVOS\u57fa\u51c6\u8bc4\u4f30\u6a21\u578b\u3002", "result": "SeC\u5728SeCVOS\u4e0a\u6bd4SAM 2.1\u63d0\u534711.8\u4e2a\u70b9\u3002", "conclusion": "SeC\u5efa\u7acb\u4e86\u6982\u5ff5\u611f\u77e5\u89c6\u9891\u5bf9\u8c61\u5206\u5272\u7684\u65b0SOTA\u3002"}}
