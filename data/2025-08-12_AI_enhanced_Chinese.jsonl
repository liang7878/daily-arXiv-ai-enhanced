{"id": "2508.06526", "pdf": "https://arxiv.org/pdf/2508.06526", "abs": "https://arxiv.org/abs/2508.06526", "authors": ["Dong Liu", "Yanxuan Yu", "Ben Lengerich", "Ying Nian Wu", "Xuhong Wang"], "title": "PiKV: KV Cache Management System for Mixture of Experts", "categories": ["cs.DC", "cs.AI", "cs.AR"], "comment": "Accepted to ICML ES-MoFo III WorkShop Paper Link:\n  https://openreview.net/pdf?id=hHoK1kBPd9 Github Link:\n  https://github.com/NoakLiu/PiKV", "summary": "As large language models continue to scale up in both size and context\nlength, the memory and communication cost of key-value (KV) cache storage has\nbecome a major bottleneck in multi-GPU and multi-node inference. While\nMoE-based architectures sparsify computation across experts, the corresponding\nKV caches remain dense and globally synchronized, resulting in significant\noverhead.\n  We introduce \\textbf{PiKV}, a parallel and distributed KV cache serving\nframework tailored for MoE architecture. PiKV leverages \\textit{expert-sharded\nKV storage} to partition caches across GPUs, \\textit{PiKV routing} to reduce\ntoken-to-KV access, and a \\textit{PiKV Scheduling} to adaptively retain\nquery-relevant entries. To further reduce memory usage, PiKV integrates\n\\textit{PiKV Compression} modules the caching pipeline for acceleration.\n  PiKV is recently publicly available as an open-source software library:\n\\href{https://github.com/NoakLiu/PiKV}{https://github.com/NoakLiu/PiKV}.\nExperiments details is recorded at:\n\\href{https://github.com/NoakLiu/PiKV/blob/main/downstream_tasks/README.md}{https://github.com/NoakLiu/PiKV/Experimental\\_Results}.\nWe also have PiKV integrated with Nvidia kvpress for acceleration, details see\n\\href{https://github.com/NoakLiu/PiKVpress}{https://github.com/NoakLiu/PiKVpress}.\nPiKV is still a living project, aiming to become a comprehesive KV Cache\nmanagement system for MoE Architectures.", "AI": {"tldr": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\uff0cKV\u7f13\u5b58\u5b58\u50a8\u6210\u672c\u6210\u74f6\u9888\uff0c\u8bba\u6587\u63d0\u51faPiKV\u6846\u67b6\u89e3\u51b3\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e2dKV\u7f13\u5b58\u5b58\u50a8\u7684\u5185\u5b58\u548c\u901a\u4fe1\u6210\u672c\u6210\u4e3a\u591aGPU\u548c\u591a\u8282\u70b9\u63a8\u7406\u7684\u4e3b\u8981\u74f6\u9888\uff0cMoE\u67b6\u6784\u4e0bKV\u7f13\u5b58\u4ecd\u5b58\u5728\u663e\u8457\u5f00\u9500\u3002", "method": "\u5f15\u5165PiKV\u6846\u67b6\uff0c\u5229\u7528\u4e13\u5bb6\u5206\u7247KV\u5b58\u50a8\u3001PiKV\u8def\u7531\u3001PiKV\u8c03\u5ea6\u548cPiKV\u538b\u7f29\u6a21\u5757\u3002", "result": "PiKV\u4f5c\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u5e93\u53d1\u5e03\uff0c\u53ef\u4e0eNvidia kvpress\u96c6\u6210\u52a0\u901f\u3002", "conclusion": "PiKV\u65e8\u5728\u6210\u4e3aMoE\u67b6\u6784\u5168\u9762\u7684KV\u7f13\u5b58\u7ba1\u7406\u7cfb\u7edf\u3002"}}
{"id": "2508.06948", "pdf": "https://arxiv.org/pdf/2508.06948", "abs": "https://arxiv.org/abs/2508.06948", "authors": ["Jinyuan Chen", "Jiuchen Shi", "Quan Chen", "Minyi Guo"], "title": "Kairos: Low-latency Multi-Agent Serving with Shared LLMs and Excessive Loads in the Public Cloud", "categories": ["cs.DC"], "comment": null, "summary": "Multi-agent applications utilize the advanced capabilities of large language\nmodels (LLMs) for intricate task completion through agent collaboration in a\nworkflow. Under this situation, requests from different agents usually access\nthe same shared LLM to perform different kinds of tasks, forcing the shared LLM\nto suffer excessive loads. However, existing works have low serving performance\nfor these multi-agent applications, mainly due to the ignorance of inter-agent\nlatency and resource differences for request scheduling. We therefore propose\nKairos, a multi-agent orchestration system that optimizes end-to-end latency\nfor multi-agent applications. Kairos consists of a workflow orchestrator, a\nworkflow-aware priority scheduler, and a memory-aware dispatcher. The\norchestrator collects agent-specific information for online workflow analysis.\nThe scheduler decides the serving priority of the requests based on their\nlatency characteristics to reduce the overall queuing. The dispatcher\ndispatches the requests to different LLM instances based on their memory\ndemands to avoid GPU overloading. Experimental results show that Kairos reduces\nend-to-end latency by 17.8% to 28.4% compared to state-of-the-art works.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7f16\u6392\u7cfb\u7edfKairos\uff0c\u4f18\u5316\u591a\u667a\u80fd\u4f53\u5e94\u7528\u7aef\u5230\u7aef\u5ef6\u8fdf\uff0c\u5b9e\u9a8c\u8868\u660e\u6bd4\u73b0\u6709\u6280\u672f\u51cf\u5c1117.8% - 28.4%\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5728\u591a\u667a\u80fd\u4f53\u5e94\u7528\u4e2d\u670d\u52a1\u6027\u80fd\u4f4e\uff0c\u672a\u8003\u8651\u667a\u80fd\u4f53\u95f4\u5ef6\u8fdf\u548c\u8d44\u6e90\u5dee\u5f02\u8fdb\u884c\u8bf7\u6c42\u8c03\u5ea6\uff0c\u5171\u4eab\u5927\u8bed\u8a00\u6a21\u578b\u8d1f\u8f7d\u8fc7\u9ad8\u3002", "method": "\u63d0\u51faKairos\u7cfb\u7edf\uff0c\u5305\u542b\u5de5\u4f5c\u6d41\u7f16\u6392\u5668\u3001\u5de5\u4f5c\u6d41\u611f\u77e5\u4f18\u5148\u7ea7\u8c03\u5ea6\u5668\u548c\u5185\u5b58\u611f\u77e5\u8c03\u5ea6\u5668\u3002\u7f16\u6392\u5668\u6536\u96c6\u4fe1\u606f\u5206\u6790\u5de5\u4f5c\u6d41\uff0c\u8c03\u5ea6\u5668\u6839\u636e\u5ef6\u8fdf\u7279\u6027\u51b3\u5b9a\u8bf7\u6c42\u4f18\u5148\u7ea7\uff0c\u8c03\u5ea6\u5668\u6839\u636e\u5185\u5b58\u9700\u6c42\u5206\u53d1\u8bf7\u6c42\u3002", "result": "Kairos\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u5c06\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e\u4e8617.8%\u523028.4%\u3002", "conclusion": "Kairos\u7cfb\u7edf\u80fd\u6709\u6548\u4f18\u5316\u591a\u667a\u80fd\u4f53\u5e94\u7528\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002"}}
{"id": "2508.06949", "pdf": "https://arxiv.org/pdf/2508.06949", "abs": "https://arxiv.org/abs/2508.06949", "authors": ["Arya Tanmay Gupta"], "title": "Convergence Sans Synchronization", "categories": ["cs.DC", "cs.DM"], "comment": "PhD thesis", "summary": "We currently see a steady rise in the usage and size of multiprocessor\nsystems, and so the community is evermore interested in developing fast\nparallel processing algorithms. However, most algorithms require a\nsynchronization mechanism, which is costly in terms of computational resources\nand time. If an algorithm can be executed in asynchrony, then it can use all\nthe available computation power, and the nodes can execute without being\nscheduled or locked. However, to show that an algorithm guarantees convergence\nin asynchrony, we need to generate the entire global state transition graph and\ncheck for the absence of cycles. This takes time exponential in the size of the\nglobal state space. In this dissertation, we present a theory that explains the\nnecessary and sufficient properties of a multiprocessor algorithm that\nguarantees convergence even without synchronization. We develop algorithms for\nvarious problems that do not require synchronization. Additionally, we show for\nseveral existing algorithms that they can be executed without any\nsynchronization mechanism. A significant theoretical benefit of our work is in\nproving that an algorithm can converge even in asynchrony. Our theory implies\nthat we can make such conclusions about an algorithm, by only showing that the\nlocal state transition graph of a computing node forms a partial order, rather\nthan generating the entire global state space and determining the absence of\ncycles in it. Thus, the complexity of rendering such proofs, formal or social,\nis phenomenally reduced. Experiments show a significant reduction in time taken\nto converge, when we compare the execution time of algorithms in the literature\nversus the algorithms that we design. We get similar results when we run an\nalgorithm, that guarantees convergence in asynchrony, under a scheduler versus\nin asynchrony.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4fdd\u8bc1\u591a\u5904\u7406\u5668\u7b97\u6cd5\u5f02\u6b65\u6536\u655b\u7684\u7406\u8bba\uff0c\u5f00\u53d1\u65e0\u9700\u540c\u6b65\u7684\u7b97\u6cd5\uff0c\u8bc1\u660e\u5f02\u6b65\u6536\u655b\u53ef\u901a\u8fc7\u5c40\u90e8\u72b6\u6001\u56fe\u5224\u65ad\uff0c\u5b9e\u9a8c\u663e\u793a\u7b97\u6cd5\u6536\u655b\u65f6\u95f4\u663e\u8457\u51cf\u5c11\u3002", "motivation": "\u591a\u5904\u7406\u5668\u7cfb\u7edf\u4f7f\u7528\u548c\u89c4\u6a21\u589e\u52a0\uff0c\u793e\u533a\u5bf9\u5feb\u901f\u5e76\u884c\u5904\u7406\u7b97\u6cd5\u9700\u6c42\u5927\uff0c\u4f46\u591a\u6570\u7b97\u6cd5\u540c\u6b65\u673a\u5236\u6210\u672c\u9ad8\uff0c\u9700\u5bfb\u627e\u5f02\u6b65\u6536\u655b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u89e3\u91ca\u591a\u5904\u7406\u5668\u7b97\u6cd5\u5f02\u6b65\u6536\u655b\u5fc5\u8981\u5145\u5206\u5c5e\u6027\u7684\u7406\u8bba\uff0c\u5f00\u53d1\u65e0\u9700\u540c\u6b65\u7684\u7b97\u6cd5\uff0c\u8bc1\u660e\u73b0\u6709\u7b97\u6cd5\u53ef\u5f02\u6b65\u6267\u884c\u3002", "result": "\u901a\u8fc7\u8bc1\u660e\u5c40\u90e8\u72b6\u6001\u56fe\u5f62\u6210\u504f\u5e8f\u5373\u53ef\u5224\u65ad\u7b97\u6cd5\u5f02\u6b65\u6536\u655b\uff0c\u964d\u4f4e\u8bc1\u660e\u590d\u6742\u5ea6\uff1b\u5b9e\u9a8c\u8868\u660e\u8bbe\u8ba1\u7684\u7b97\u6cd5\u6536\u655b\u65f6\u95f4\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "\u63d0\u51fa\u7684\u7406\u8bba\u53ef\u6709\u6548\u964d\u4f4e\u5224\u65ad\u7b97\u6cd5\u5f02\u6b65\u6536\u655b\u7684\u590d\u6742\u5ea6\uff0c\u8bbe\u8ba1\u7684\u7b97\u6cd5\u5728\u6536\u655b\u65f6\u95f4\u4e0a\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2508.07071", "pdf": "https://arxiv.org/pdf/2508.07071", "abs": "https://arxiv.org/abs/2508.07071", "authors": ["Oscar Amoros", "Albert Andaluz", "Johnny Nunez", "Antonio J. Pena"], "title": "The Fused Kernel Library: A C++ API to Develop Highly-Efficient GPU Libraries", "categories": ["cs.DC"], "comment": "16 pages", "summary": "Existing GPU libraries often struggle to fully exploit the parallel resources\nand on-chip memory (SRAM) of GPUs when chaining multiple GPU functions as\nindividual kernels. While Kernel Fusion (KF) techniques like Horizontal Fusion\n(HF) and Vertical Fusion (VF) can mitigate this, current library\nimplementations often require library developers to manually create fused\nkernels. Hence, library users rely on limited sets of pre-compiled or\ntemplate-based fused kernels. This limits the use cases that can benefit from\nHF and VF and increases development costs. In order to solve these issues, we\npresent a novel methodology for building GPU libraries that enables automatic\non-demand HF and VF for arbitrary combinations of GPU library functions. Our\nmethodology defines reusable, fusionable components that users combine via\nhigh-level programming interfaces. Leveraging C++17 metaprogramming features\navailable in compilers like nvcc, our methodology generates a single and\noptimized fused kernel tailored to the user's specific sequence of operations\nat compile time, without needing a custom compiler or manual development and\npre-compilation of kernel combinations. This approach abstracts low-level GPU\ncomplexities while maximizing GPU resource utilization and keeping intermediate\ndata in SRAM. We provide an open-source implementation demonstrating\nsignificant speedups compared to traditional libraries in various benchmarks,\nvalidating the effectiveness of this methodology for improving GPU performance\nin the range of 2x to more than 1000x, while preserving high-level\nprogrammability.", "AI": {"tldr": "\u73b0\u6709GPU\u5e93\u94fe\u5f0f\u8c03\u7528\u51fd\u6570\u65f6\u96be\u4ee5\u5145\u5206\u5229\u7528\u8d44\u6e90\uff0c\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\u5b9e\u73b0\u6309\u9700\u81ea\u52a8\u6c34\u5e73\u548c\u5782\u76f4\u878d\u5408\uff0c\u5f00\u6e90\u5b9e\u73b0\u5c55\u793a\u663e\u8457\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u73b0\u6709GPU\u5e93\u94fe\u5f0f\u8c03\u7528\u51fd\u6570\u96be\u4ee5\u5229\u7528\u8d44\u6e90\uff0c\u73b0\u6709\u5185\u6838\u878d\u5408\u6280\u672f\u9700\u624b\u52a8\u521b\u5efa\u878d\u5408\u5185\u6838\uff0c\u9650\u5236\u5e94\u7528\u573a\u666f\u4e14\u589e\u52a0\u5f00\u53d1\u6210\u672c\u3002", "method": "\u5b9a\u4e49\u53ef\u590d\u7528\u3001\u53ef\u878d\u5408\u7ec4\u4ef6\uff0c\u7528\u6237\u901a\u8fc7\u9ad8\u7ea7\u7f16\u7a0b\u63a5\u53e3\u7ec4\u5408\uff0c\u5229\u7528C++17\u5143\u7f16\u7a0b\u7279\u6027\u5728\u7f16\u8bd1\u65f6\u751f\u6210\u4f18\u5316\u878d\u5408\u5185\u6838\u3002", "result": "\u5f00\u6e90\u5b9e\u73b0\u5bf9\u6bd4\u4f20\u7edf\u5e93\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u663e\u8457\u52a0\u901f\uff0c\u6027\u80fd\u63d0\u53472\u500d\u5230\u8d851000\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347GPU\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u7559\u9ad8\u7ea7\u53ef\u7f16\u7a0b\u6027\u3002"}}
{"id": "2508.06730", "pdf": "https://arxiv.org/pdf/2508.06730", "abs": "https://arxiv.org/abs/2508.06730", "authors": ["Lauren A Hurley", "Sean E Shaheen"], "title": "Reservoir computing with large valid prediction time for the Lorenz system", "categories": ["cs.NE"], "comment": null, "summary": "We study the dependence of the Valid Prediction Time (VPT) of Reservoir\nComputers (RCs) on hyperparameters including the regularization coefficient,\nreservoir size, and spectral radius. Under carefully chosen conditions, the RC\ncan achieve approximately 70% of a benchmark performance, based on the output\nof a single prediction step used as initial conditions for the Lorenz\nequations. We report high VPT values (>30 Lyapunov times), as we are predicting\na noiseless system where overfitting can be beneficial. While these conditions\nmay not hold for noisy systems, they could still be useful for real-world\napplications with limited noise. Furthermore, utilizing knowledge of the\nLyapunov exponent, we find that the VPT can be predicted by the error in the\nfirst few prediction steps, offering a computationally efficient evaluation\nmethod. We emphasize the importance of the numerical solver used to generate\nthe Lorenz dataset and define a Valid Ground Truth Time (VGTT), during which\nthe outputs of several common solvers agree. A VPT exceeding the VGTT is not\nmeaningful, as a different solver could produce a different result. Lastly, we\nidentify two spectral radius regimes that achieve large VPT: a small radius\nnear zero, resulting in simple but stable operation, and a larger radius\noperating at the \"edge of chaos.\"", "AI": {"tldr": "\u7814\u7a76\u50a8\u5c42\u8ba1\u7b97\u673a\uff08RC\uff09\u6709\u6548\u9884\u6d4b\u65f6\u95f4\uff08VPT\uff09\u4e0e\u8d85\u53c2\u6570\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u53d1\u73b0\u7279\u5b9a\u6761\u4ef6\u4e0b RC \u53ef\u63a5\u8fd1\u57fa\u51c6\u6027\u80fd 70%\uff0c\u6709\u9ad8 VPT \u503c\uff0c\u53ef\u901a\u8fc7\u521d\u59cb\u8bef\u5dee\u9884\u6d4b VPT\uff0c\u5f3a\u8c03\u6570\u503c\u6c42\u89e3\u5668\u91cd\u8981\u6027\u5e76\u5b9a\u4e49 VGTT\uff0c\u786e\u5b9a\u4e24\u79cd\u5927 VPT \u7684\u8c31\u534a\u5f84\u533a\u57df\u3002", "motivation": "\u7814\u7a76\u50a8\u5c42\u8ba1\u7b97\u673a\u6709\u6548\u9884\u6d4b\u65f6\u95f4\u4e0e\u8d85\u53c2\u6570\u7684\u5173\u7cfb\uff0c\u63a2\u7d22\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u901a\u8fc7\u5bf9 Lorenz \u65b9\u7a0b\u8fdb\u884c\u5355\u6b65\u9884\u6d4b\u8f93\u51fa\u4f5c\u4e3a\u521d\u59cb\u6761\u4ef6\uff0c\u7814\u7a76\u4e0d\u540c\u8d85\u53c2\u6570\u4e0b\u7684 VPT\uff1b\u5229\u7528 Lyapunov \u6307\u6570\uff0c\u901a\u8fc7\u521d\u59cb\u51e0\u6b65\u9884\u6d4b\u8bef\u5dee\u9884\u6d4b VPT\uff1b\u5bf9\u6bd4\u4e0d\u540c\u6570\u503c\u6c42\u89e3\u5668\u7684\u8f93\u51fa\u3002", "result": "\u7279\u5b9a\u6761\u4ef6\u4e0b RC \u53ef\u8fbe\u57fa\u51c6\u6027\u80fd\u7ea6 70%\uff0c\u6709\u9ad8 VPT \u503c\uff08>30 Lyapunov \u65f6\u95f4\uff09\uff1b\u53ef\u901a\u8fc7\u521d\u59cb\u8bef\u5dee\u9884\u6d4b VPT\uff1b\u786e\u5b9a VGTT\uff1b\u53d1\u73b0\u4e24\u79cd\u5927 VPT \u7684\u8c31\u534a\u5f84\u533a\u57df\u3002", "conclusion": "\u50a8\u5c42\u8ba1\u7b97\u673a\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6709\u8f83\u597d\u9884\u6d4b\u6027\u80fd\uff0c\u53ef\u901a\u8fc7\u521d\u59cb\u8bef\u5dee\u9ad8\u6548\u8bc4\u4f30 VPT\uff0c\u6570\u503c\u6c42\u89e3\u5668\u5bf9\u7ed3\u679c\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4e0d\u540c\u8c31\u534a\u5f84\u533a\u57df\u53ef\u5b9e\u73b0\u5927 VPT\u3002"}}
{"id": "2508.06559", "pdf": "https://arxiv.org/pdf/2508.06559", "abs": "https://arxiv.org/abs/2508.06559", "authors": ["Sina Baghal"], "title": "Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization", "categories": ["cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "Pasur is a fishing card game played over six rounds and is played similarly\nto games such as Cassino and Scopa, and Bastra. This paper introduces a\nCUDA-accelerated computational framework for simulating Pasur, emphasizing\nefficient memory management. We use our framework to compute near-Nash\nequilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm\nfor solving large imperfect-information games.\n  Solving Pasur presents unique challenges due to its intricate rules and the\nlarge size of its game tree. We handle rule complexity using PyTorch CUDA\ntensors and to address the memory-intensive nature of the game, we decompose\nthe game tree into two key components: (1) actual game states, and (2)\ninherited scores from previous rounds. We construct the Full Game Tree by\npairing card states with accumulated scores in the Unfolding Process. This\ndesign reduces memory overhead by storing only essential strategy values and\nnode connections. To further manage computational complexity, we apply a\nround-by-round backward training strategy, starting from the final round and\nrecursively propagating average utilities to earlier stages. Our approach\nconstructs the complete game tree, which on average consists of over $10^9$\nnodes. We provide detailed implementation snippets.\n  After computing a near-Nash equilibrium strategy, we train a tree-based model\nto predict these strategies for use during gameplay. We then estimate the fair\nvalue of each deck through large-scale self-play between equilibrium strategies\nby simulating, for instance, 10,000 games per matchup, executed in parallel\nusing GPU acceleration.\n  Similar frameworks can be extended to other reinforcement learning algorithms\nwhere the action tree naturally decomposes into multiple rounds such as\nturn-based strategy games or sequential trading decisions in financial markets.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8e\u6a21\u62dfPasur\u724c\u7c7b\u6e38\u620f\u7684CUDA\u52a0\u901f\u8ba1\u7b97\u6846\u67b6\uff0c\u7528CFR\u7b97\u6cd5\u8ba1\u7b97\u8fd1\u7eb3\u4ec0\u5747\u8861\uff0c\u8fd8\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u7b56\u7565\u5e76\u8bc4\u4f30\u724c\u7ec4\u4ef7\u503c\uff0c\u6846\u67b6\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u3002", "motivation": "Pasur\u6e38\u620f\u89c4\u5219\u590d\u6742\u3001\u6e38\u620f\u6811\u89c4\u6a21\u5927\uff0c\u6c42\u89e3\u8fd1\u7eb3\u4ec0\u5747\u8861\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u8ba1\u7b97\u6846\u67b6\u3002", "method": "\u4f7f\u7528PyTorch CUDA\u5f20\u91cf\u5904\u7406\u89c4\u5219\u590d\u6742\u6027\uff0c\u5c06\u6e38\u620f\u6811\u5206\u89e3\u4e3a\u6e38\u620f\u72b6\u6001\u548c\u4e0a\u8f6e\u5f97\u5206\uff0c\u6784\u5efa\u5b8c\u6574\u6e38\u620f\u6811\uff1b\u91c7\u7528\u9010\u8f6e\u53cd\u5411\u8bad\u7ec3\u7b56\u7565\uff1b\u8bad\u7ec3\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u9884\u6d4b\u7b56\u7565\uff0c\u7528GPU\u52a0\u901f\u5927\u89c4\u6a21\u81ea\u6211\u5bf9\u5f08\u3002", "result": "\u6784\u5efa\u5e73\u5747\u542b\u8d85$10^9$\u8282\u70b9\u7684\u5b8c\u6574\u6e38\u620f\u6811\uff0c\u8ba1\u7b97\u51fa\u8fd1\u7eb3\u4ec0\u5747\u8861\u7b56\u7565\uff0c\u53ef\u9884\u6d4b\u7b56\u7565\u5e76\u8bc4\u4f30\u724c\u7ec4\u516c\u5e73\u4ef7\u503c\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u884c\u52a8\u6811\u80fd\u81ea\u7136\u5206\u89e3\u4e3a\u591a\u8f6e\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u573a\u666f\u3002"}}
{"id": "2508.06617", "pdf": "https://arxiv.org/pdf/2508.06617", "abs": "https://arxiv.org/abs/2508.06617", "authors": ["Md Arafat Hossain", "Xingfu Wu", "Valerie Taylor", "Ali Jannesari"], "title": "Generalizing Scaling Laws for Dense and Sparse Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "8 pages, 8 figures", "summary": "Over the past few years, the size of language models has grown exponentially,\nas has the computational cost to train these large models. This rapid growth\nhas motivated researchers to develop new techniques aimed at enhancing the\nefficiency of the training process. Despite these advancements, optimally\npredicting the model size or allocating optimal resources remains a challenge.\nSeveral efforts have addressed the challenge by proposing different scaling\nlaws, but almost all of them are architecture-specific (dense or sparse). In\nthis work we revisit existing scaling laws and propose a generalized scaling\nlaw to provide a unified framework that is applicable to both dense and sparse\nlarge language models. We evaluate and compare our proposed scaling law with\nexisting scaling laws to demonstrate its effectiveness.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u548c\u8bad\u7ec3\u6210\u672c\u589e\u957f\u4fc3\u4f7f\u7814\u7a76\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u672c\u6587\u63d0\u51fa\u901a\u7528\u7f29\u653e\u5b9a\u5f8b\u5e76\u8bc4\u4f30\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u548c\u8bad\u7ec3\u6210\u672c\u6307\u6570\u589e\u957f\uff0c\u73b0\u6709\u7f29\u653e\u5b9a\u5f8b\u591a\u9488\u5bf9\u7279\u5b9a\u67b6\u6784\uff0c\u96be\u4ee5\u6700\u4f18\u9884\u6d4b\u6a21\u578b\u5927\u5c0f\u548c\u5206\u914d\u8d44\u6e90\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6\u73b0\u6709\u7f29\u653e\u5b9a\u5f8b\uff0c\u63d0\u51fa\u9002\u7528\u4e8e\u7a20\u5bc6\u548c\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u7f29\u653e\u5b9a\u5f8b\u3002", "result": "\u8bc4\u4f30\u5e76\u6bd4\u8f83\u4e86\u63d0\u51fa\u7684\u7f29\u653e\u5b9a\u5f8b\u4e0e\u73b0\u6709\u7f29\u653e\u5b9a\u5f8b\u3002", "conclusion": "\u63d0\u51fa\u7684\u901a\u7528\u7f29\u653e\u5b9a\u5f8b\u6709\u6548\uff0c\u4e3a\u7a20\u5bc6\u548c\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2508.06550", "pdf": "https://arxiv.org/pdf/2508.06550", "abs": "https://arxiv.org/abs/2508.06550", "authors": ["Yinqiu Huang", "Hao Ma", "Wenshuai Chen", "Shuli Wang", "Yongqiang Zhang", "Xue Wei", "Yinhua Zhu", "Haitao Wang", "Xingxing Wang"], "title": "Generative Bid Shading in Real-Time Bidding Advertising", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "Bid shading plays a crucial role in Real-Time Bidding~(RTB) by adaptively\nadjusting the bid to avoid advertisers overspending. Existing mainstream\ntwo-stage methods, which first model bid landscapes and then optimize surplus\nusing operations research techniques, are constrained by unimodal assumptions\nthat fail to adapt for non-convex surplus curves and are vulnerable to\ncascading errors in sequential workflows. Additionally, existing discretization\nmodels of continuous values ignore the dependence between discrete intervals,\nreducing the model's error correction ability, while sample selection bias in\nbidding scenarios presents further challenges for prediction. To address these\nissues, this paper introduces Generative Bid Shading~(GBS), which comprises two\nprimary components: (1) an end-to-end generative model that utilizes an\nautoregressive approach to generate shading ratios by stepwise residuals,\ncapturing complex value dependencies without relying on predefined priors; and\n(2) a reward preference alignment system, which incorporates a channel-aware\nhierarchical dynamic network~(CHNet) as the reward model to extract\nfine-grained features, along with modules for surplus optimization and\nexploration utility reward alignment, ultimately optimizing both short-term and\nlong-term surplus using group relative policy optimization~(GRPO). Extensive\nexperiments on both offline and online A/B tests validate GBS's effectiveness.\nMoreover, GBS has been deployed on the Meituan DSP platform, serving billions\nof bid requests daily.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5b9e\u65f6\u7ade\u4ef7\u4e2d\u73b0\u6709\u51fa\u4ef7\u9634\u5f71\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u751f\u6210\u5f0f\u51fa\u4ef7\u9634\u5f71\uff08GBS\uff09\u65b9\u6cd5\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u5e76\u5df2\u90e8\u7f72\u5230\u7f8e\u56e2DSP\u5e73\u53f0\u3002", "motivation": "\u73b0\u6709\u4e3b\u6d41\u4e24\u9636\u6bb5\u65b9\u6cd5\u53d7\u5355\u5cf0\u5047\u8bbe\u9650\u5236\uff0c\u79bb\u6563\u5316\u6a21\u578b\u5ffd\u7565\u533a\u95f4\u4f9d\u8d56\uff0c\u51fa\u4ef7\u573a\u666f\u5b58\u5728\u6837\u672c\u9009\u62e9\u504f\u5dee\uff0c\u65e0\u6cd5\u9002\u5e94\u975e\u51f8\u76c8\u4f59\u66f2\u7ebf\u3001\u6613\u7ea7\u8054\u9519\u8bef\u3001\u964d\u4f4e\u7ea0\u9519\u80fd\u529b\u548c\u5e26\u6765\u9884\u6d4b\u6311\u6218\u3002", "method": "\u63d0\u51faGBS\u65b9\u6cd5\uff0c\u5305\u542b\u7aef\u5230\u7aef\u751f\u6210\u6a21\u578b\uff08\u5229\u7528\u81ea\u56de\u5f52\u65b9\u6cd5\u6309\u9010\u6b65\u6b8b\u5dee\u751f\u6210\u9634\u5f71\u6bd4\u7387\uff09\u548c\u5956\u52b1\u504f\u597d\u5bf9\u9f50\u7cfb\u7edf\uff08\u91c7\u7528CHNet\u63d0\u53d6\u7279\u5f81\uff0c\u7ed3\u5408\u76c8\u4f59\u4f18\u5316\u548c\u63a2\u7d22\u6548\u7528\u5956\u52b1\u5bf9\u9f50\u6a21\u5757\uff0c\u7528GRPO\u4f18\u5316\u957f\u77ed\u76c8\u4f59\uff09\u3002", "result": "\u79bb\u7ebf\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86GBS\u7684\u6709\u6548\u6027\uff0c\u4e14\u5df2\u90e8\u7f72\u5230\u7f8e\u56e2DSP\u5e73\u53f0\uff0c\u6bcf\u5929\u5904\u7406\u6570\u5341\u4ebf\u51fa\u4ef7\u8bf7\u6c42\u3002", "conclusion": "GBS\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u51fa\u4ef7\u9634\u5f71\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5728\u5b9e\u65f6\u7ade\u4ef7\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2508.06781", "pdf": "https://arxiv.org/pdf/2508.06781", "abs": "https://arxiv.org/abs/2508.06781", "authors": ["Christos Tsirigotis", "Vaibhav Adlakha", "Joao Monteiro", "Aaron Courville", "Perouz Taslakian"], "title": "BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "22 pages, 5 figures, accepted at COLM 2025", "summary": "Neural sentence embedding models for dense retrieval typically rely on binary\nrelevance labels, treating query-document pairs as either relevant or\nirrelevant. However, real-world relevance often exists on a continuum, and\nrecent advances in large language models (LLMs) have made it feasible to scale\nthe generation of fine-grained graded relevance labels. In this work, we\npropose BiXSE, a simple and effective pointwise training method that optimizes\nbinary cross-entropy (BCE) over LLM-generated graded relevance scores. BiXSE\ninterprets these scores as probabilistic targets, enabling granular supervision\nfrom a single labeled query-document pair per query. Unlike pairwise or\nlistwise losses that require multiple annotated comparisons per query, BiXSE\nachieves strong performance with reduced annotation and compute costs by\nleveraging in-batch negatives. Extensive experiments across sentence embedding\n(MMTEB) and retrieval benchmarks (BEIR, TREC-DL) show that BiXSE consistently\noutperforms softmax-based contrastive learning (InfoNCE), and matches or\nexceeds strong pairwise ranking baselines when trained on LLM-supervised data.\nBiXSE offers a robust, scalable alternative for training dense retrieval models\nas graded relevance supervision becomes increasingly accessible.", "AI": {"tldr": "\u63d0\u51faBiXSE\u65b9\u6cd5\uff0c\u5229\u7528LLM\u751f\u6210\u7684\u5206\u7ea7\u76f8\u5173\u6027\u5206\u6570\u4f18\u5316\u4e8c\u5143\u4ea4\u53c9\u71b5\uff0c\u51cf\u5c11\u6807\u6ce8\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u5b9e\u9a8c\u8868\u73b0\u597d\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u4f9d\u8d56\u4e8c\u5143\u76f8\u5173\u6027\u6807\u7b7e\uff0c\u800c\u73b0\u5b9e\u76f8\u5173\u6027\u662f\u8fde\u7eed\u7684\uff0c\u4e14LLM\u4f7f\u751f\u6210\u7ec6\u7c92\u5ea6\u5206\u7ea7\u76f8\u5173\u6027\u6807\u7b7e\u53ef\u884c\u3002", "method": "\u63d0\u51faBiXSE\u70b9\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5bf9LLM\u751f\u6210\u7684\u5206\u7ea7\u76f8\u5173\u6027\u5206\u6570\u4f18\u5316\u4e8c\u5143\u4ea4\u53c9\u71b5\uff0c\u5c06\u5206\u6570\u89c6\u4e3a\u6982\u7387\u76ee\u6807\uff0c\u5229\u7528\u6279\u6b21\u5185\u8d1f\u6837\u672c\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBiXSE\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8esoftmax\u7684\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5728LLM\u76d1\u7763\u6570\u636e\u4e0a\u8bad\u7ec3\u65f6\u4e0e\u6216\u8d85\u8fc7\u5f3a\u6210\u5bf9\u6392\u5e8f\u57fa\u7ebf\u3002", "conclusion": "\u968f\u7740\u5206\u7ea7\u76f8\u5173\u6027\u76d1\u7763\u66f4\u6613\u83b7\u53d6\uff0cBiXSE\u4e3a\u8bad\u7ec3\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\u63d0\u4f9b\u4e86\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2508.06693", "pdf": "https://arxiv.org/pdf/2508.06693", "abs": "https://arxiv.org/abs/2508.06693", "authors": ["Matthew Fahrbach", "Mehrdad Ghadiri"], "title": "A Tight Lower Bound for the Approximation Guarantee of Higher-Order Singular Value Decomposition", "categories": ["cs.DS", "cs.LG"], "comment": "15 pages", "summary": "We prove that the classic approximation guarantee for the higher-order\nsingular value decomposition (HOSVD) is tight by constructing a tensor for\nwhich HOSVD achieves an approximation ratio of $N/(1+\\varepsilon)$, for any\n$\\varepsilon > 0$. This matches the upper bound of De Lathauwer et al. (2000a)\nand shows that the approximation ratio of HOSVD cannot be improved. Using a\nmore advanced construction, we also prove that the approximation guarantees for\nthe ST-HOSVD algorithm of Vannieuwenhoven et al. (2012) and higher-order\northogonal iteration (HOOI) of De Lathauwer et al. (2000b) are tight by showing\nthat they can achieve their worst-case approximation ratio of $N / (1 +\n\\varepsilon)$, for any $\\varepsilon > 0$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.06718", "pdf": "https://arxiv.org/pdf/2508.06718", "abs": "https://arxiv.org/abs/2508.06718", "authors": ["Daniel Ogenrwot", "John Businge"], "title": "Refactoring-Aware Patch Integration Across Structurally Divergent Java Forks", "categories": ["cs.SE", "K.6.3; D.2.7"], "comment": "12 pages, 3 figures", "summary": "While most forks on platforms like GitHub are short-lived and used for social\ncollaboration, a smaller but impactful subset evolve into long-lived forks,\nreferred to here as variants, that maintain independent development\ntrajectories. Integrating bug-fix patches across such divergent variants poses\nchallenges due to structural drift, including refactorings that rename,\nrelocate, or reorganize code elements and obscure semantic correspondence. This\npaper presents an empirical study of patch integration failures in 14 divergent\npair of variants and introduces RePatch, a refactoring-aware integration system\nfor Java repositories. RePatch extends the RefMerge framework, originally\ndesigned for symmetric merges, by supporting asymmetric patch transfer. RePatch\ninverts refactorings in both the source and target to realign the patch\ncontext, applies the patch, and replays the transformations to preserve the\nintent of the variant. In our evaluation of 478 bug-fix pull requests, Git\ncherry-pick fails in 64.4% of cases due to structural misalignments, while\nRePatch successfully integrates 52.8% of the previously failing patches. These\nresults highlight the limitations of syntax-based tools and the need for\nsemantic reasoning in variant-aware patch propagation.", "AI": {"tldr": "\u7814\u7a76GitHub\u4e0a\u53d8\u4f53\u95f4\u8865\u4e01\u96c6\u6210\u95ee\u9898\uff0c\u63d0\u51faRePatch\u7cfb\u7edf\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8eGit cherry - pick\u3002", "motivation": "GitHub\u4e0a\u53d8\u4f53\u72ec\u7acb\u5f00\u53d1\uff0c\u7ed3\u6784\u6f02\u79fb\u4f7f\u8de8\u53d8\u4f53\u96c6\u6210\u8865\u4e01\u6709\u6311\u6218\uff0c\u9700\u89e3\u51b3\u8865\u4e01\u96c6\u6210\u5931\u8d25\u95ee\u9898\u3002", "method": "\u5bf914\u5bf9\u53d8\u4f53\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u6269\u5c55RefMerge\u6846\u67b6\uff0c\u652f\u6301\u975e\u5bf9\u79f0\u8865\u4e01\u8f6c\u79fb\uff0c\u53cd\u8f6c\u91cd\u6784\u3001\u5e94\u7528\u8865\u4e01\u5e76\u56de\u653e\u8f6c\u6362\u3002", "result": "\u8bc4\u4f30478\u4e2a\u8865\u4e01\u8bf7\u6c42\uff0cGit cherry - pick\u56e0\u7ed3\u6784\u4e0d\u5bf9\u9f50\u5931\u8d25\u738764.4%\uff0cRePatch\u6210\u529f\u96c6\u621052.8%\u6b64\u524d\u5931\u8d25\u7684\u8865\u4e01\u3002", "conclusion": "\u57fa\u4e8e\u8bed\u6cd5\u7684\u5de5\u5177\u5b58\u5728\u5c40\u9650\uff0c\u53d8\u4f53\u611f\u77e5\u7684\u8865\u4e01\u4f20\u64ad\u9700\u8981\u8bed\u4e49\u63a8\u7406\u3002"}}
{"id": "2508.06539", "pdf": "https://arxiv.org/pdf/2508.06539", "abs": "https://arxiv.org/abs/2508.06539", "authors": ["Atahan Karagoz"], "title": "Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Survival is traditionally modeled as a supervised learning task, reliant on\ncurated outcome labels and fixed covariates. This work rejects that premise. It\nproposes that survival is not an externally annotated target but a geometric\nconsequence: an emergent property of the curvature and flow inherent in\nbiological state space. We develop a theory of Self-Organizing Survival\nManifolds (SOSM), in which survival-relevant dynamics arise from low-curvature\ngeodesic flows on latent manifolds shaped by internal biological constraints. A\nsurvival energy functional based on geodesic curvature minimization is\nintroduced and shown to induce structures where prognosis aligns with geometric\nflow stability. We derive discrete and continuous formulations of the objective\nand prove theoretical results demonstrating the emergence and convergence of\nsurvival-aligned trajectories under biologically plausible conditions. The\nframework draws connections to thermodynamic efficiency, entropy flow, Ricci\ncurvature, and optimal transport, grounding survival modeling in physical law.\nHealth, disease, aging, and death are reframed as geometric phase transitions\nin the manifold's structure. This theory offers a universal, label-free\nfoundation for modeling survival as a property of form, not annotation-bridging\nmachine learning, biophysics, and the geometry of life itself.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u7ec4\u7ec7\u751f\u5b58\u6d41\u5f62\uff08SOSM\uff09\u7406\u8bba\uff0c\u5c06\u751f\u5b58\u5efa\u6a21\u4e3a\u51e0\u4f55\u5c5e\u6027\u800c\u975e\u4f9d\u8d56\u6807\u6ce8\uff0c\u63a8\u5bfc\u76ee\u6807\u516c\u5f0f\u5e76\u8bc1\u660e\u76f8\u5173\u7ed3\u679c\uff0c\u8fde\u63a5\u591a\u9886\u57df\u77e5\u8bc6\uff0c\u63d0\u4f9b\u65e0\u6807\u7b7e\u751f\u5b58\u5efa\u6a21\u57fa\u7840\u3002", "motivation": "\u4f20\u7edf\u751f\u5b58\u5efa\u6a21\u4f9d\u8d56\u6807\u6ce8\u548c\u56fa\u5b9a\u534f\u53d8\u91cf\uff0c\u672c\u6587\u6b32\u6253\u7834\u6b64\u524d\u63d0\uff0c\u4ece\u51e0\u4f55\u89d2\u5ea6\u5efa\u6a21\u751f\u5b58\u3002", "method": "\u63d0\u51faSOSM\u7406\u8bba\uff0c\u5f15\u5165\u57fa\u4e8e\u6d4b\u5730\u66f2\u7387\u6700\u5c0f\u5316\u7684\u751f\u5b58\u80fd\u91cf\u6cdb\u51fd\uff0c\u63a8\u5bfc\u79bb\u6563\u548c\u8fde\u7eed\u76ee\u6807\u516c\u5f0f\u5e76\u8bc1\u660e\u7406\u8bba\u7ed3\u679c\u3002", "result": "\u8bc1\u660e\u5728\u751f\u7269\u5b66\u5408\u7406\u6761\u4ef6\u4e0b\u751f\u5b58\u5bf9\u9f50\u8f68\u8ff9\u7684\u51fa\u73b0\u548c\u6536\u655b\uff0c\u5c06\u5065\u5eb7\u3001\u75be\u75c5\u7b49\u73b0\u8c61\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6d41\u5f62\u7ed3\u6784\u7684\u51e0\u4f55\u76f8\u53d8\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e3a\u751f\u5b58\u5efa\u6a21\u63d0\u4f9b\u4e86\u901a\u7528\u3001\u65e0\u6807\u7b7e\u7684\u57fa\u7840\uff0c\u8fde\u63a5\u4e86\u673a\u5668\u5b66\u4e60\u3001\u751f\u7269\u7269\u7406\u5b66\u548c\u751f\u547d\u51e0\u4f55\u5b66\u3002"}}
{"id": "2508.06497", "pdf": "https://arxiv.org/pdf/2508.06497", "abs": "https://arxiv.org/abs/2508.06497", "authors": ["Mohammed-Khalil Ghali", "Cecil Pang", "Oscar Molina", "Carlos Gershenson-Garcia", "Daehan Won"], "title": "Forecasting Commodity Price Shocks Using Temporal and Semantic Fusion of Prices Signals and Agentic Generative AI Extracted Economic News", "categories": ["q-fin.CP", "cs.AI", "cs.LG"], "comment": null, "summary": "Accurate forecasting of commodity price spikes is vital for countries with\nlimited economic buffers, where sudden increases can strain national budgets,\ndisrupt import-reliant sectors, and undermine food and energy security. This\npaper introduces a hybrid forecasting framework that combines historical\ncommodity price data with semantic signals derived from global economic news,\nusing an agentic generative AI pipeline. The architecture integrates\ndual-stream Long Short-Term Memory (LSTM) networks with attention mechanisms to\nfuse structured time-series inputs with semantically embedded, fact-checked\nnews summaries collected from 1960 to 2023. The model is evaluated on a 64-year\ndataset comprising normalized commodity price series and temporally aligned\nnews embeddings. Results show that the proposed approach achieves a mean AUC of\n0.94 and an overall accuracy of 0.91 substantially outperforming traditional\nbaselines such as logistic regression (AUC = 0.34), random forest (AUC = 0.57),\nand support vector machines (AUC = 0.47). Additional ablation studies reveal\nthat the removal of attention or dimensionality reduction leads to moderate\ndeclines in performance, while eliminating the news component causes a steep\ndrop in AUC to 0.46, underscoring the critical value of incorporating\nreal-world context through unstructured text. These findings demonstrate that\nintegrating agentic generative AI with deep learning can meaningfully improve\nearly detection of commodity price shocks, offering a practical tool for\neconomic planning and risk mitigation in volatile market environments while\nsaving the very high costs of operating a full generative AI agents pipeline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u5386\u53f2\u5546\u54c1\u4ef7\u683c\u6570\u636e\u4e0e\u7ecf\u6d4e\u65b0\u95fb\u8bed\u4e49\u4fe1\u53f7\u7684\u6df7\u5408\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u751f\u6210\u5f0fAI\u7ba1\u9053\uff0c\u6a21\u578b\u8868\u73b0\u8fdc\u8d85\u4f20\u7edf\u57fa\u7ebf\uff0c\u8bc1\u660e\u6574\u5408\u751f\u6210\u5f0fAI\u4e0e\u6df1\u5ea6\u5b66\u4e60\u53ef\u63d0\u5347\u5546\u54c1\u4ef7\u683c\u51b2\u51fb\u9884\u8b66\u80fd\u529b\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u5546\u54c1\u4ef7\u683c\u98d9\u5347\u5bf9\u7ecf\u6d4e\u7f13\u51b2\u80fd\u529b\u6709\u9650\u7684\u56fd\u5bb6\u81f3\u5173\u91cd\u8981\uff0c\u53ef\u907f\u514d\u56fd\u5bb6\u9884\u7b97\u7d27\u5f20\u3001\u884c\u4e1a\u53d7\u6270\u53ca\u7cae\u98df\u548c\u80fd\u6e90\u5b89\u5168\u53d7\u635f\u3002", "method": "\u5f15\u5165\u6df7\u5408\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u5386\u53f2\u5546\u54c1\u4ef7\u683c\u6570\u636e\u4e0e\u5168\u7403\u7ecf\u6d4e\u65b0\u95fb\u8bed\u4e49\u4fe1\u53f7\uff0c\u91c7\u7528\u751f\u6210\u5f0fAI\u7ba1\u9053\uff0c\u7528\u53cc\u6d41LSTM\u7f51\u7edc\u4e0e\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u7ed3\u6784\u5316\u65f6\u95f4\u5e8f\u5217\u8f93\u5165\u548c\u65b0\u95fb\u6458\u8981\u3002", "result": "\u6a21\u578b\u5e73\u5747AUC\u4e3a0.94\uff0c\u6574\u4f53\u51c6\u786e\u73870.91\uff0c\u8fdc\u8d85\u4f20\u7edf\u57fa\u7ebf\uff1b\u6d88\u878d\u7814\u7a76\u8868\u660e\u53bb\u9664\u6ce8\u610f\u529b\u6216\u964d\u7ef4\u6027\u80fd\u9002\u5ea6\u4e0b\u964d\uff0c\u53bb\u9664\u65b0\u95fb\u7ec4\u4ef6AUC\u964d\u81f30.46\u3002", "conclusion": "\u6574\u5408\u751f\u6210\u5f0fAI\u4e0e\u6df1\u5ea6\u5b66\u4e60\u80fd\u6709\u6548\u6539\u5584\u5546\u54c1\u4ef7\u683c\u51b2\u51fb\u7684\u65e9\u671f\u68c0\u6d4b\uff0c\u4e3a\u7ecf\u6d4e\u89c4\u5212\u548c\u98ce\u9669\u7f13\u89e3\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\uff0c\u8fd8\u80fd\u8282\u7701\u6210\u672c\u3002"}}
{"id": "2508.07774", "pdf": "https://arxiv.org/pdf/2508.07774", "abs": "https://arxiv.org/abs/2508.07774", "authors": ["Quirini Lorenzo", "Vannucci Luigi", "Quirini Giovanni"], "title": "Modelling Prepayment and Default under Changing Credit Market Conditions for a Net Present Value Analysis", "categories": ["q-fin.RM"], "comment": null, "summary": "A model is developed to assess the profitability of loans or mortgages with a\nspecified repayment schedule. Financial institutions face two competing risks:\ndefault and prepayment, both influenced by the stochastic evolution of credit\nmarket conditions. This study focuses on the Random Net Present Value (RNPV) as\na key performance metric. The analysis evaluates the mean and variance of the\nRNPV at both the individual loan level and the portfolio level, within a\nunified framework that accounts for borrower behavior and prevailing credit\nmarket dynamics.", "AI": {"tldr": "\u5f00\u53d1\u6a21\u578b\u8bc4\u4f30\u7279\u5b9a\u8fd8\u6b3e\u8ba1\u5212\u4e0b\u8d37\u6b3e\u6216\u62b5\u62bc\u8d37\u6b3e\u7684\u76c8\u5229\u80fd\u529b\uff0c\u805a\u7126RNPV\u6307\u6807\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u8bc4\u4f30\u5176\u5747\u503c\u548c\u65b9\u5dee\u3002", "motivation": "\u91d1\u878d\u673a\u6784\u9762\u4e34\u8fdd\u7ea6\u548c\u63d0\u524d\u8fd8\u6b3e\u98ce\u9669\uff0c\u53d7\u4fe1\u8d37\u5e02\u573a\u6761\u4ef6\u5f71\u54cd\uff0c\u9700\u8bc4\u4f30\u8d37\u6b3e\u76c8\u5229\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u6a21\u578b\uff0c\u4ee5\u968f\u673a\u51c0\u73b0\u503c\uff08RNPV\uff09\u4e3a\u5173\u952e\u6307\u6807\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5bf9\u4e2a\u4f53\u8d37\u6b3e\u548c\u6295\u8d44\u7ec4\u5408\u5c42\u9762\u7684RNPV\u5747\u503c\u548c\u65b9\u5dee\u8fdb\u884c\u8bc4\u4f30\u3002", "conclusion": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u63d0\u53ca\u7ed3\u8bba\u3002"}}
{"id": "2508.08148", "pdf": "https://arxiv.org/pdf/2508.08148", "abs": "https://arxiv.org/abs/2508.08148", "authors": ["Victor Olkhov"], "title": "Unwitting Markowitz' Simplification of Portfolio Random Returns", "categories": ["econ.GN", "q-fin.EC", "q-fin.GN", "q-fin.PM", "q-fin.ST"], "comment": "10 pages. arXiv admin note: text overlap with arXiv:2507.21824", "summary": "In his famous paper, Markowitz (1952) derived the dependence of portfolio\nrandom returns on the random returns of its securities. This result allowed\nMarkowitz to obtain his famous expression for portfolio variance. We show that\nMarkowitz's equation for portfolio random returns and the expression for\nportfolio variance, which results from it, describe a simplified approximation\nof the real markets when the volumes of all consecutive trades with the\nsecurities are assumed to be constant during the averaging interval. To show\nthis, we consider the investor who doesn't trade shares of securities of his\nportfolio. The investor only observes the trades made in the market with his\nsecurities and derives the time series that model the trades with his portfolio\nas with a single security. These time series describe the portfolio return and\nvariance in exactly the same way as the time series of trades with securities\ndescribe their returns and variances. The portfolio time series reveal the\ndependence of portfolio random returns on the random returns of securities and\non the ratio of the random volumes of trades with the securities to the random\nvolumes of trades with the portfolio. If we assume that all volumes of the\nconsecutive trades with securities are constant, obtain Markowitz's equation\nfor the portfolio's random returns. The market-based variance of the portfolio\naccounts for the effects of random fluctuations of the volumes of the\nconsecutive trades. The use of Markowitz variance may give significantly higher\nor lower estimates than market-based portfolio variance.", "AI": {"tldr": "\u6307\u51faMarkowitz\u6a21\u578b\u662f\u5bf9\u771f\u5b9e\u5e02\u573a\u7684\u7b80\u5316\u8fd1\u4f3c\uff0c\u8003\u8651\u4ea4\u6613\u6570\u91cf\u968f\u673a\u6027\u53ef\u5f97\u5230\u57fa\u4e8e\u5e02\u573a\u7684\u6295\u8d44\u7ec4\u5408\u65b9\u5dee\uff0c\u5176\u4e0eMarkowitz\u65b9\u5dee\u4f30\u8ba1\u6709\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76Markowitz\u6a21\u578b\u5bf9\u771f\u5b9e\u5e02\u573a\u7684\u9002\u7528\u6027\u3002", "method": "\u8003\u8651\u4e0d\u4ea4\u6613\u8bc1\u5238\u7684\u6295\u8d44\u8005\uff0c\u89c2\u5bdf\u5e02\u573a\u4ea4\u6613\u5e76\u63a8\u5bfc\u6a21\u62df\u6295\u8d44\u7ec4\u5408\u4ea4\u6613\u7684\u65f6\u95f4\u5e8f\u5217\u3002", "result": "\u6295\u8d44\u7ec4\u5408\u65f6\u95f4\u5e8f\u5217\u63ed\u793a\u968f\u673a\u56de\u62a5\u4f9d\u8d56\u8bc1\u5238\u56de\u62a5\u53ca\u4ea4\u6613\u6570\u91cf\u6bd4\uff0c\u5047\u8bbe\u4ea4\u6613\u6570\u91cf\u6052\u5b9a\u53ef\u5f97Markowitz\u65b9\u7a0b\uff0c\u5e02\u573a\u65b9\u5dee\u8003\u8651\u4ea4\u6613\u6570\u91cf\u968f\u673a\u6ce2\u52a8\u3002", "conclusion": "Markowitz\u65b9\u5dee\u4e0e\u57fa\u4e8e\u5e02\u573a\u7684\u6295\u8d44\u7ec4\u5408\u65b9\u5dee\u4f30\u8ba1\u6709\u663e\u8457\u5dee\u5f02\u3002"}}
{"id": "2508.06834", "pdf": "https://arxiv.org/pdf/2508.06834", "abs": "https://arxiv.org/abs/2508.06834", "authors": ["Toan Huynh", "Ruth Lopez Fajardo", "Guannan Zhang", "Lili Ju", "Feng Bao"], "title": "A Score-based Diffusion Model Approach for Adaptive Learning of Stochastic Partial Differential Equation Solutions", "categories": ["stat.CO", "cs.LG", "math.DS", "math.PR", "stat.ML", "Stochastic partial differential equation, score-based diffusion\n  model, adaptive learning, Ensemble Score Filter, data assimilation, Bayesian\n  inference"], "comment": null, "summary": "We propose a novel framework for adaptively learning the time-evolving\nsolutions of stochastic partial differential equations (SPDEs) using\nscore-based diffusion models within a recursive Bayesian inference setting.\nSPDEs play a central role in modeling complex physical systems under\nuncertainty, but their numerical solutions often suffer from model errors and\nreduced accuracy due to incomplete physical knowledge and environmental\nvariability. To address these challenges, we encode the governing physics into\nthe score function of a diffusion model using simulation data and incorporate\nobservational information via a likelihood-based correction in a reverse-time\nstochastic differential equation. This enables adaptive learning through\niterative refinement of the solution as new data becomes available. To improve\ncomputational efficiency in high-dimensional settings, we introduce the\nensemble score filter, a training-free approximation of the score function\ndesigned for real-time inference. Numerical experiments on benchmark SPDEs\ndemonstrate the accuracy and robustness of the proposed method under sparse and\nnoisy observations.", "AI": {"tldr": "\u63d0\u51fa\u7528\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\u5728\u9012\u5f52\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6\u4e0b\u81ea\u9002\u5e94\u5b66\u4e60\u968f\u673a\u504f\u5fae\u5206\u65b9\u7a0b\uff08SPDEs\uff09\u65f6\u53d8\u89e3\u7684\u65b0\u6846\u67b6\uff0c\u5f15\u5165\u96c6\u6210\u5206\u6570\u6ee4\u6ce2\u5668\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "SPDEs\u5728\u6a21\u62df\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u590d\u6742\u7269\u7406\u7cfb\u7edf\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u6570\u503c\u89e3\u5e38\u56e0\u7269\u7406\u77e5\u8bc6\u4e0d\u5b8c\u6574\u548c\u73af\u5883\u591a\u53d8\u5b58\u5728\u6a21\u578b\u8bef\u5dee\u548c\u7cbe\u5ea6\u964d\u4f4e\u95ee\u9898\u3002", "method": "\u5c06\u63a7\u5236\u7269\u7406\u539f\u7406\u7f16\u7801\u5230\u6269\u6563\u6a21\u578b\u7684\u5206\u6570\u51fd\u6570\u4e2d\uff0c\u901a\u8fc7\u53cd\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u4e2d\u57fa\u4e8e\u4f3c\u7136\u7684\u6821\u6b63\u7eb3\u5165\u89c2\u6d4b\u4fe1\u606f\uff0c\u5f15\u5165\u96c6\u6210\u5206\u6570\u6ee4\u6ce2\u5668\u63d0\u5347\u9ad8\u7ef4\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u57fa\u51c6SPDEs\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u7a00\u758f\u548c\u566a\u58f0\u89c2\u6d4b\u4e0b\u5c55\u73b0\u51fa\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3SPDEs\u6570\u503c\u89e3\u7684\u95ee\u9898\uff0c\u4e14\u5177\u6709\u8f83\u597d\u6027\u80fd\u3002"}}
{"id": "2508.07408", "pdf": "https://arxiv.org/pdf/2508.07408", "abs": "https://arxiv.org/abs/2508.07408", "authors": ["Yueyi Wang", "Qiyao Wei"], "title": "Event-Aware Sentiment Factors from LLM-Augmented Financial Tweets: A Transparent Framework for Interpretable Quant Trading", "categories": ["q-fin.ST", "cs.CL", "cs.LG"], "comment": "16 pages, 12 figures, accepted at ICML 2025 New in ML Workshop", "summary": "In this study, we wish to showcase the unique utility of large language\nmodels (LLMs) in financial semantic annotation and alpha signal discovery.\nLeveraging a corpus of company-related tweets, we use an LLM to automatically\nassign multi-label event categories to high-sentiment-intensity tweets. We\nalign these labeled sentiment signals with forward returns over 1-to-7-day\nhorizons to evaluate their statistical efficacy and market tradability. Our\nexperiments reveal that certain event labels consistently yield negative alpha,\nwith Sharpe ratios as low as -0.38 and information coefficients exceeding 0.05,\nall statistically significant at the 95\\% confidence level. This study\nestablishes the feasibility of transforming unstructured social media text into\nstructured, multi-label event variables. A key contribution of this work is its\ncommitment to transparency and reproducibility; all code and methodologies are\nmade publicly available. Our results provide compelling evidence that social\nmedia sentiment is a valuable, albeit noisy, signal in financial forecasting\nand underscore the potential of open-source frameworks to democratize\nalgorithmic trading research.", "AI": {"tldr": "\u7814\u7a76\u5c55\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u8bed\u4e49\u6807\u6ce8\u548c\u963f\u5c14\u6cd5\u4fe1\u53f7\u53d1\u73b0\u4e2d\u7684\u4f5c\u7528\uff0c\u5229\u7528\u63a8\u6587\u5b9e\u9a8c\uff0c\u8bc1\u660e\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\u5bf9\u91d1\u878d\u9884\u6d4b\u6709\u4ef7\u503c\u3002", "motivation": "\u5c55\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u8bed\u4e49\u6807\u6ce8\u548c\u963f\u5c14\u6cd5\u4fe1\u53f7\u53d1\u73b0\u7684\u72ec\u7279\u6548\u7528\u3002", "method": "\u5229\u7528\u516c\u53f8\u76f8\u5173\u63a8\u6587\u8bed\u6599\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u9ad8\u60c5\u7eea\u5f3a\u5ea6\u63a8\u6587\u5206\u914d\u591a\u6807\u7b7e\u4e8b\u4ef6\u7c7b\u522b\uff0c\u5c06\u6807\u7b7e\u5316\u60c5\u7eea\u4fe1\u53f7\u4e0e1 - 7\u5929\u7684\u8fdc\u671f\u56de\u62a5\u5bf9\u9f50\u8bc4\u4f30\u3002", "result": "\u67d0\u4e9b\u4e8b\u4ef6\u6807\u7b7e\u6301\u7eed\u4ea7\u751f\u8d1f\u963f\u5c14\u6cd5\uff0c\u590f\u666e\u6bd4\u7387\u4f4e\u81f3 -0.38\uff0c\u4fe1\u606f\u7cfb\u6570\u8d850.05\uff0c\u4e14\u572895%\u7f6e\u4fe1\u6c34\u5e73\u663e\u8457\u3002", "conclusion": "\u5c06\u975e\u7ed3\u6784\u5316\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u591a\u6807\u7b7e\u4e8b\u4ef6\u53d8\u91cf\u53ef\u884c\uff0c\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\u662f\u6709\u4ef7\u503c\u4f46\u6709\u566a\u58f0\u7684\u91d1\u878d\u9884\u6d4b\u4fe1\u53f7\uff0c\u5f00\u6e90\u6846\u67b6\u53ef\u63a8\u52a8\u7b97\u6cd5\u4ea4\u6613\u7814\u7a76\u6c11\u4e3b\u5316\u3002"}}
{"id": "2508.06652", "pdf": "https://arxiv.org/pdf/2508.06652", "abs": "https://arxiv.org/abs/2508.06652", "authors": ["Jingmao Li", "Yuanxing Chen", "Shuangge Ma", "Kuangnan Fang"], "title": "Federated Online Learning for Heterogeneous Multisource Streaming Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Federated learning has emerged as an essential paradigm for distributed\nmulti-source data analysis under privacy concerns. Most existing federated\nlearning methods focus on the ``static\" datasets. However, in many real-world\napplications, data arrive continuously over time, forming streaming datasets.\nThis introduces additional challenges for data storage and algorithm design,\nparticularly under high-dimensional settings. In this paper, we propose a\nfederated online learning (FOL) method for distributed multi-source streaming\ndata analysis. To account for heterogeneity, a personalized model is\nconstructed for each data source, and a novel ``subgroup\" assumption is\nemployed to capture potential similarities, thereby enhancing model\nperformance. We adopt the penalized renewable estimation method and the\nefficient proximal gradient descent for model training. The proposed method\naligns with both federated and online learning frameworks: raw data are not\nexchanged among sources, ensuring data privacy, and only summary statistics of\nprevious data batches are required for model updates, significantly reducing\nstorage demands. Theoretically, we establish the consistency properties for\nmodel estimation, variable selection, and subgroup structure recovery,\ndemonstrating optimal statistical efficiency. Simulations illustrate the\neffectiveness of the proposed method. Furthermore, when applied to the\nfinancial lending data and the web log data, the proposed method also exhibits\nadvantageous prediction performance. Results of the analysis also provide some\npractical insights.", "AI": {"tldr": "\u63d0\u51fa\u8054\u90a6\u5728\u7ebf\u5b66\u4e60\uff08FOL\uff09\u65b9\u6cd5\u7528\u4e8e\u5206\u5e03\u5f0f\u591a\u6e90\u6d41\u6570\u636e\u5206\u6790\uff0c\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u6a21\u62df\u9a8c\u8bc1\uff0c\u5e94\u7528\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u591a\u5173\u6ce8\u9759\u6001\u6570\u636e\u96c6\uff0c\u800c\u73b0\u5b9e\u4e2d\u6570\u636e\u591a\u4e3a\u6d41\u5f0f\uff0c\u5728\u9ad8\u7ef4\u573a\u666f\u4e0b\u7ed9\u6570\u636e\u5b58\u50a8\u548c\u7b97\u6cd5\u8bbe\u8ba1\u5e26\u6765\u6311\u6218\u3002", "method": "\u4e3a\u6bcf\u4e2a\u6570\u636e\u6e90\u6784\u5efa\u4e2a\u6027\u5316\u6a21\u578b\uff0c\u91c7\u7528\u201c\u5b50\u7ec4\u201d\u5047\u8bbe\uff1b\u4f7f\u7528 penalized renewable estimation \u65b9\u6cd5\u548c\u9ad8\u6548\u8fd1\u7aef\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u6a21\u578b\u4f30\u8ba1\u3001\u53d8\u91cf\u9009\u62e9\u548c\u5b50\u7ec4\u7ed3\u6784\u6062\u590d\u7684\u4e00\u81f4\u6027\uff0c\u6a21\u62df\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5728\u91d1\u878d\u8d37\u6b3e\u548c\u7f51\u7edc\u65e5\u5fd7\u6570\u636e\u4e0a\u9884\u6d4b\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "\u6240\u63d0 FOL \u65b9\u6cd5\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u591a\u6e90\u6d41\u6570\u636e\u5206\u6790\uff0c\u80fd\u4fdd\u8bc1\u9690\u79c1\u548c\u51cf\u5c11\u5b58\u50a8\u9700\u6c42\uff0c\u6709\u826f\u597d\u7edf\u8ba1\u6548\u7387\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.06584", "pdf": "https://arxiv.org/pdf/2508.06584", "abs": "https://arxiv.org/abs/2508.06584", "authors": ["Kalana Wijegunarathna", "Kristin Stock", "Christopher B. Jones"], "title": "Omni Geometry Representation Learning vs Large Language Models for Geospatial Entity Resolution", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "The development, integration, and maintenance of geospatial databases rely\nheavily on efficient and accurate matching procedures of Geospatial Entity\nResolution (ER). While resolution of points-of-interest (POIs) has been widely\naddressed, resolution of entities with diverse geometries has been largely\noverlooked. This is partly due to the lack of a uniform technique for embedding\nheterogeneous geometries seamlessly into a neural network framework. Existing\nneural approaches simplify complex geometries to a single point, resulting in\nsignificant loss of spatial information. To address this limitation, we propose\nOmni, a geospatial ER model featuring an omni-geometry encoder. This encoder is\ncapable of embedding point, line, polyline, polygon, and multi-polygon\ngeometries, enabling the model to capture the complex geospatial intricacies of\nthe places being compared. Furthermore, Omni leverages transformer-based\npre-trained language models over individual textual attributes of place records\nin an Attribute Affinity mechanism. The model is rigorously tested on existing\npoint-only datasets and a new diverse-geometry geospatial ER dataset. Omni\nproduces up to 12% (F1) improvement over existing methods.\n  Furthermore, we test the potential of Large Language Models (LLMs) to conduct\ngeospatial ER, experimenting with prompting strategies and learning scenarios,\ncomparing the results of pre-trained language model-based methods with LLMs.\nResults indicate that LLMs show competitive results.", "AI": {"tldr": "\u63d0\u51fa\u5730\u7406\u7a7a\u95f4\u5b9e\u4f53\u89e3\u6790\u6a21\u578bOmni\u89e3\u51b3\u4e0d\u540c\u51e0\u4f55\u5f62\u72b6\u5b9e\u4f53\u89e3\u6790\u95ee\u9898\uff0c\u6d4b\u8bd5\u663e\u793a\u5176\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u63d0\u5347\uff0c\u8fd8\u6d4b\u8bd5\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5730\u7406\u7a7a\u95f4\u5b9e\u4f53\u89e3\u6790\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u5730\u7406\u7a7a\u95f4\u5b9e\u4f53\u89e3\u6790\u65b9\u6cd5\u591a\u5173\u6ce8\u5174\u8da3\u70b9\uff0c\u5bf9\u4e0d\u540c\u51e0\u4f55\u5f62\u72b6\u5b9e\u4f53\u89e3\u6790\u7f3a\u4e4f\u7edf\u4e00\u6280\u672f\uff0c\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u4f1a\u9020\u6210\u7a7a\u95f4\u4fe1\u606f\u635f\u5931\u3002", "method": "\u63d0\u51fa\u5177\u6709\u5168\u51e0\u4f55\u7f16\u7801\u5668\u7684Omni\u6a21\u578b\uff0c\u80fd\u5d4c\u5165\u591a\u79cd\u51e0\u4f55\u5f62\u72b6\uff0c\u5229\u7528\u57fa\u4e8eTransformer\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5904\u7406\u6587\u672c\u5c5e\u6027\uff1b\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5730\u7406\u7a7a\u95f4\u5b9e\u4f53\u89e3\u6790\u7684\u6f5c\u529b\u3002", "result": "Omni\u6a21\u578b\u5728F1\u503c\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u6700\u591a\u63d0\u534712%\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5730\u7406\u7a7a\u95f4\u5b9e\u4f53\u89e3\u6790\u4e2d\u8868\u73b0\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "Omni\u6a21\u578b\u80fd\u6709\u6548\u89e3\u51b3\u4e0d\u540c\u51e0\u4f55\u5f62\u72b6\u5b9e\u4f53\u7684\u5730\u7406\u7a7a\u95f4\u5b9e\u4f53\u89e3\u6790\u95ee\u9898\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u9886\u57df\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.06771", "pdf": "https://arxiv.org/pdf/2508.06771", "abs": "https://arxiv.org/abs/2508.06771", "authors": ["James Almgren-Bell", "Nader Al Awar", "Dilip S Geethakrishnan", "Milos Gligoric", "George Biros"], "title": "A Portable Multi-GPU Solver for Collisional Plasmas with Coulombic Interactions", "categories": ["cs.CE", "cs.DC"], "comment": null, "summary": "We study parallel particle-in-cell (PIC) methods for low-temperature plasmas\n(LTPs), which discretize kinetic formulations that capture the time evolution\nof the probability density function of particles as a function of position and\nvelocity. We use a kinetic description for electrons and a fluid approximation\nfor heavy species. In this paper, we focus on GPU acceleration of algorithms\nfor velocity-space interactions and in particular, collisions of electrons with\nneutrals, ions, and electrons. Our work has two thrusts. The first is\nalgorithmic exploration and analysis. The second is examining the viability of\nrapid-prototyping implementations using Python-based HPC tools, in particular\nPyKokkos. We discuss several common PIC kernels and present performance results\non NVIDIA Volta V100 and AMD MI250X GPUs. Overall, the MI250X is slightly\nfaster for most kernels but shows more sensitivity to register pressure. We\nalso report scaling results for a distributed memory implementation on up to 16\nMPI ranks.", "AI": {"tldr": "\u7814\u7a76\u4f4e\u6e29\u7b49\u79bb\u5b50\u4f53\u7684\u5e76\u884c\u7c92\u5b50\u6a21\u62df\u65b9\u6cd5\uff0c\u805a\u7126GPU\u52a0\u901f\u53caPython\u5feb\u901f\u539f\u578b\u5b9e\u73b0\uff0c\u7ed9\u51fa\u4e0d\u540cGPU\u6027\u80fd\u548c\u5206\u5e03\u5f0f\u5185\u5b58\u6269\u5c55\u7ed3\u679c\u3002", "motivation": "\u5bf9\u4f4e\u6e29\u7b49\u79bb\u5b50\u4f53\u5e76\u884c\u7c92\u5b50\u6a21\u62df\u65b9\u6cd5\u7684GPU\u52a0\u901f\u53ca\u5feb\u901f\u539f\u578b\u5b9e\u73b0\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u91c7\u7528\u7535\u5b50\u52a8\u529b\u5b66\u63cf\u8ff0\u548c\u91cd\u7c92\u5b50\u6d41\u4f53\u8fd1\u4f3c\uff0c\u8fdb\u884c\u7b97\u6cd5\u63a2\u7d22\u5206\u6790\uff0c\u7528Python\u7684PyKokkos\u5de5\u5177\u5feb\u901f\u539f\u578b\u5b9e\u73b0\u3002", "result": "MI250X\u5bf9\u591a\u6570\u5185\u6838\u7a0d\u5feb\uff0c\u4f46\u5bf9\u5bc4\u5b58\u5668\u538b\u529b\u66f4\u654f\u611f\uff0c\u7ed9\u51fa\u5206\u5e03\u5f0f\u5185\u5b58\u5b9e\u73b0\u7684\u6269\u5c55\u7ed3\u679c\u3002", "conclusion": "\u5b8c\u6210\u5bf9\u4f4e\u6e29\u7b49\u79bb\u5b50\u4f53\u5e76\u884c\u7c92\u5b50\u6a21\u62df\u65b9\u6cd5\u7684GPU\u52a0\u901f\u7814\u7a76\u53ca\u6027\u80fd\u6d4b\u8bd5\u3002"}}
{"id": "2508.06594", "pdf": "https://arxiv.org/pdf/2508.06594", "abs": "https://arxiv.org/abs/2508.06594", "authors": ["Tatsuru Kikuchi"], "title": "Stochastic Boundaries in Spatial General Equilibrium: A Diffusion-Based Approach to Causal Inference with Spillover Effects", "categories": ["econ.GN", "q-fin.EC"], "comment": "62 pages", "summary": "This paper introduces a novel framework for causal inference in spatial\neconomics that explicitly models the stochastic transition from partial to\ngeneral equilibrium effects. We develop a Denoising Diffusion Probabilistic\nModel (DDPM) integrated with boundary detection methods from stochastic process\ntheory to identify when and how treatment effects propagate beyond local\nmarkets. Our approach treats the evolution of spatial spillovers as a L\\'evy\nprocess with jump-diffusion dynamics, where the first passage time to critical\nthresholds indicates regime shifts from partial to general equilibrium. Using\nCUSUM-based sequential detection, we identify the spatial and temporal\nboundaries at which local interventions become systemic. Applied to AI adoption\nacross Japanese prefectures, we find that treatment effects exhibit L\\'evy\njumps at approximately 35km spatial scales, with general equilibrium effects\namplifying partial equilibrium estimates by 42\\%. Monte Carlo simulations show\nthat ignoring these stochastic boundaries leads to underestimation of treatment\neffects by 28-67\\%, with particular severity in densely connected economic\nregions. Our framework provides the first rigorous method for determining when\nspatial spillovers necessitate general equilibrium analysis, offering crucial\nguidance for policy evaluation in interconnected economies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7a7a\u95f4\u7ecf\u6d4e\u5b66\u56e0\u679c\u63a8\u65ad\u65b0\u6846\u67b6\uff0c\u7ed3\u5408DDPM\u4e0e\u8fb9\u754c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u65e5\u672cAI\u91c7\u7eb3\u5206\u6790\uff0c\u53d1\u73b0\u5904\u7406\u6548\u5e94\u5728\u7ea635km\u5c3a\u5ea6\u6709\u8df3\u8dc3\uff0c\u5ffd\u89c6\u8fb9\u754c\u4f1a\u4f4e\u4f30\u6548\u5e94\uff0c\u6846\u67b6\u4e3a\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5728\u7a7a\u95f4\u7ecf\u6d4e\u5b66\u4e2d\u5efa\u7acb\u80fd\u660e\u786e\u5efa\u6a21\u4ece\u5c40\u90e8\u5230\u4e00\u822c\u5747\u8861\u6548\u5e94\u968f\u673a\u8f6c\u53d8\u7684\u56e0\u679c\u63a8\u65ad\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u96c6\u6210\u8fb9\u754c\u68c0\u6d4b\u65b9\u6cd5\u7684Denoising Diffusion Probabilistic Model (DDPM)\uff0c\u5c06\u7a7a\u95f4\u6ea2\u51fa\u6f14\u53d8\u89c6\u4e3a\u5e26\u8df3\u8dc3\u6269\u6563\u52a8\u6001\u7684L\u00e9vy\u8fc7\u7a0b\uff0c\u7528CUSUM-based sequential detection\u786e\u5b9a\u8fb9\u754c\u3002", "result": "\u5904\u7406\u6548\u5e94\u5728\u7ea635km\u7a7a\u95f4\u5c3a\u5ea6\u6709L\u00e9vy\u8df3\u8dc3\uff0c\u4e00\u822c\u5747\u8861\u6548\u5e94\u4f7f\u5c40\u90e8\u5747\u8861\u4f30\u8ba1\u653e\u592742%\uff0c\u5ffd\u89c6\u8fb9\u754c\u4f1a\u4f4e\u4f30\u5904\u7406\u6548\u5e9428 - 67%\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u786e\u5b9a\u7a7a\u95f4\u6ea2\u51fa\u4f55\u65f6\u9700\u8981\u4e00\u822c\u5747\u8861\u5206\u6790\u7684\u9996\u4e2a\u4e25\u683c\u65b9\u6cd5\uff0c\u4e3a\u4e92\u8054\u7ecf\u6d4e\u4f53\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u5173\u952e\u6307\u5bfc\u3002"}}
{"id": "2508.06788", "pdf": "https://arxiv.org/pdf/2508.06788", "abs": "https://arxiv.org/abs/2508.06788", "authors": ["Makoto Takahashi"], "title": "Interaction between Returns and Order Flow Imbalances: Endogeneity, Intraday Variations, and Macroeconomic News Announcements", "categories": ["q-fin.TR", "econ.EM"], "comment": null, "summary": "The study examines the interaction between returns and order flow imbalances\n(differences between buy and sell orders), constructed from the best bid and\noffer files of S&P 500 E-mini futures contract, using a structural vector\nautoregressive model. The intraday variation in market activity is considered\nby applying the model for each short interval each day, whereas the endogeneity\ndue to time aggregation is handled by estimating the structural parameters via\nthe identification through heteroskedasticity. The estimation results show that\nsignificant endogeneity exists and that the estimated parameters and impulse\nresponses exhibit significant intraday variations, reflecting intense or mild\norder submission activities. Further, the estimated parameters change around\nmacroeconomic news announcements, suggesting inactive order submission periods\nexist when they occur. Overall, such announcement effects are mostly explained\nby the order submission activities reflecting the public information.", "AI": {"tldr": "\u7814\u7a76\u7528\u7ed3\u6784\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\u5206\u6790\u6807\u666e500\u7535\u5b50\u8ff7\u4f60\u671f\u8d27\u5408\u7ea6\u6536\u76ca\u4e0e\u8ba2\u5355\u6d41\u5931\u8861\u7684\u4e92\u52a8\uff0c\u8003\u8651\u65e5\u5185\u5e02\u573a\u6d3b\u52a8\u53d8\u5316\u53ca\u65f6\u95f4\u805a\u5408\u7684\u5185\u751f\u6027\uff0c\u53d1\u73b0\u5b58\u5728\u663e\u8457\u5185\u751f\u6027\u3001\u53c2\u6570\u6709\u65e5\u5185\u53d8\u5316\u53ca\u5b8f\u89c2\u6d88\u606f\u5f71\u54cd\u8ba2\u5355\u63d0\u4ea4\u6d3b\u52a8\u3002", "motivation": "\u7814\u7a76\u6807\u666e500\u7535\u5b50\u8ff7\u4f60\u671f\u8d27\u5408\u7ea6\u6536\u76ca\u4e0e\u8ba2\u5355\u6d41\u5931\u8861\u7684\u4e92\u52a8\uff0c\u8003\u8651\u65e5\u5185\u5e02\u573a\u6d3b\u52a8\u53d8\u5316\u548c\u65f6\u95f4\u805a\u5408\u7684\u5185\u751f\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u7ed3\u6784\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u6309\u77ed\u65f6\u95f4\u95f4\u9694\u5e94\u7528\u6a21\u578b\u8003\u8651\u65e5\u5185\u53d8\u5316\uff0c\u901a\u8fc7\u5f02\u65b9\u5dee\u8bc6\u522b\u4f30\u8ba1\u7ed3\u6784\u53c2\u6570\u5904\u7406\u5185\u751f\u6027\u3002", "result": "\u5b58\u5728\u663e\u8457\u5185\u751f\u6027\uff0c\u4f30\u8ba1\u53c2\u6570\u548c\u8109\u51b2\u54cd\u5e94\u6709\u663e\u8457\u65e5\u5185\u53d8\u5316\uff0c\u5b8f\u89c2\u7ecf\u6d4e\u65b0\u95fb\u516c\u544a\u524d\u540e\u4f30\u8ba1\u53c2\u6570\u6539\u53d8\u3002", "conclusion": "\u5b8f\u89c2\u7ecf\u6d4e\u65b0\u95fb\u516c\u544a\u7684\u5f71\u54cd\u4e3b\u8981\u7531\u53cd\u6620\u516c\u5171\u4fe1\u606f\u7684\u8ba2\u5355\u63d0\u4ea4\u6d3b\u52a8\u89e3\u91ca\u3002"}}
{"id": "2508.07124", "pdf": "https://arxiv.org/pdf/2508.07124", "abs": "https://arxiv.org/abs/2508.07124", "authors": ["Shashwat Jaiswal", "Suman Raj", "Subhajit Sidhanta", "Yogesh Simmhan"], "title": "AerialDB: A Federated Peer-to-Peer Spatio-temporal Edge Datastore for Drone Fleets", "categories": ["cs.DC", "cs.DB"], "comment": null, "summary": "Recent years have seen an unprecedented growth in research that leverages the\nnewest computing paradigm of Internet of Drones, comprising a fleet of\nconnected Unmanned Aerial Vehicles (UAVs) used for a wide range of tasks such\nas monitoring and analytics in highly mobile and changing environments\ncharacteristic of disaster regions. Given that the typical data (i.e., videos\nand images) collected by the fleet of UAVs deployed in such scenarios can be\nconsiderably larger than what the onboard computers can process, the UAVs need\nto offload their data in real-time to the edge and the cloud for further\nprocessing. To that end, we present the design of AerialDB - a lightweight\ndecentralized data storage and query system that can store and process time\nseries data on a multi-UAV system comprising: A) a fleet of hundreds of UAVs\nfitted with onboard computers, and B) ground-based edge servers connected\nthrough a cellular link. Leveraging lightweight techniques for content-based\nreplica placement and indexing of shards, AerialDB has been optimized for\nefficient processing of different possible combinations of typical spatial and\ntemporal queries performed by real-world disaster management applications.\nUsing containerized deployment spanning up to 400 drones and 80 edges, we\ndemonstrate that AerialDB is able to scale efficiently while providing near\nreal-time performance with different realistic workloads. Further, AerialDB\ncomprises a decentralized and locality-aware distributed execution engine which\nprovides graceful degradation of performance upon edge failures with relatively\nlow latency while processing large spatio-temporal data. AerialDB exhibits\ncomparable insertion performance and 100 times improvement in query performance\nagainst state-of-the-art baseline. Moreover, it exhibits a 10 times and 100\ntimes improvement with insertion and query workloads respectively over the\ncloud baseline.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u5b58\u50a8\u67e5\u8be2\u7cfb\u7edfAerialDB\uff0c\u53ef\u5728\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u5b58\u50a8\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u80fd\u9ad8\u6548\u6269\u5c55\uff0c\u6027\u80fd\u8868\u73b0\u4f18\u3002", "motivation": "\u65e0\u4eba\u673a\u6536\u96c6\u7684\u6570\u636e\u8fdc\u8d85\u673a\u8f7d\u8ba1\u7b97\u673a\u5904\u7406\u80fd\u529b\uff0c\u9700\u5b9e\u65f6\u5378\u8f7d\u5230\u8fb9\u7f18\u548c\u4e91\u7aef\u5904\u7406\uff0c\u73b0\u6709\u7cfb\u7edf\u96be\u4ee5\u6ee1\u8db3\u707e\u5bb3\u7ba1\u7406\u5e94\u7528\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1AerialDB\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u5185\u5bb9\u526f\u672c\u653e\u7f6e\u548c\u5206\u7247\u7d22\u5f15\u6280\u672f\uff0c\u6709\u53bb\u4e2d\u5fc3\u5316\u3001\u4f4d\u7f6e\u611f\u77e5\u7684\u5206\u5e03\u5f0f\u6267\u884c\u5f15\u64ce\u3002", "result": "\u901a\u8fc7\u6700\u591a400\u67b6\u65e0\u4eba\u673a\u548c80\u4e2a\u8fb9\u7f18\u8282\u70b9\u7684\u5bb9\u5668\u5316\u90e8\u7f72\u9a8c\u8bc1\uff0cAerialDB\u80fd\u9ad8\u6548\u6269\u5c55\uff0c\u8fd1\u5b9e\u65f6\u5904\u7406\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "AerialDB\u5728\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u4e2d\u80fd\u9ad8\u6548\u5904\u7406\u65f6\u7a7a\u6570\u636e\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u6027\u80fd\u7b49\u4f18\u52bf\u3002"}}
{"id": "2508.06793", "pdf": "https://arxiv.org/pdf/2508.06793", "abs": "https://arxiv.org/abs/2508.06793", "authors": ["Bowen Zhang", "Genan Dai", "Hu Huang", "Long Lan"], "title": "Geometry-Aware Spiking Graph Neural Network", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated impressive capabilities in\nmodeling graph-structured data, while Spiking Neural Networks (SNNs) offer high\nenergy efficiency through sparse, event-driven computation. However, existing\nspiking GNNs predominantly operate in Euclidean space and rely on fixed\ngeometric assumptions, limiting their capacity to model complex graph\nstructures such as hierarchies and cycles. To overcome these limitations, we\npropose \\method{}, a novel Geometry-Aware Spiking Graph Neural Network that\nunifies spike-based neural dynamics with adaptive representation learning on\nRiemannian manifolds. \\method{} features three key components: a Riemannian\nEmbedding Layer that projects node features into a pool of constant-curvature\nmanifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that\nmodels membrane potential evolution and spiking behavior in curved spaces via\ngeometry-consistent neighbor aggregation and curvature-based attention; and a\nManifold Learning Objective that enables instance-wise geometry adaptation\nthrough jointly optimized classification and link prediction losses defined\nover geodesic distances. All modules are trained using Riemannian SGD,\neliminating the need for backpropagation through time. Extensive experiments on\nmultiple benchmarks show that GSG achieves superior accuracy, robustness, and\nenergy efficiency compared to both Euclidean SNNs and manifold-based GNNs,\nestablishing a new paradigm for curvature-aware, energy-efficient graph\nlearning.", "AI": {"tldr": "\u63d0\u51faGeometry - Aware Spiking Graph Neural Network\uff08GSG\uff09\uff0c\u7edf\u4e00\u57fa\u4e8e\u8109\u51b2\u7684\u795e\u7ecf\u52a8\u529b\u5b66\u4e0e\u9ece\u66fc\u6d41\u5f62\u4e0a\u7684\u81ea\u9002\u5e94\u8868\u793a\u5b66\u4e60\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u80fd\u6548\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u8109\u51b2\u56fe\u795e\u7ecf\u7f51\u7edc\u4e3b\u8981\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u8fd0\u884c\uff0c\u4f9d\u8d56\u56fa\u5b9a\u51e0\u4f55\u5047\u8bbe\uff0c\u96be\u4ee5\u5bf9\u590d\u6742\u56fe\u7ed3\u6784\u5efa\u6a21\uff0c\u56e0\u6b64\u8981\u63d0\u51fa\u65b0\u65b9\u6cd5\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u3002", "method": "\u63d0\u51faGSG\uff0c\u5305\u542b\u5c06\u8282\u70b9\u7279\u5f81\u6295\u5f71\u5230\u5e38\u66f2\u7387\u6d41\u5f62\u6c60\u7684\u9ece\u66fc\u5d4c\u5165\u5c42\u3001\u5728\u5f2f\u66f2\u7a7a\u95f4\u4e2d\u5efa\u6a21\u819c\u7535\u4f4d\u6f14\u5316\u548c\u8109\u51b2\u884c\u4e3a\u7684\u6d41\u5f62\u8109\u51b2\u5c42\u3001\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5206\u7c7b\u548c\u94fe\u63a5\u9884\u6d4b\u635f\u5931\u5b9e\u73b0\u5b9e\u4f8b\u7ea7\u51e0\u4f55\u81ea\u9002\u5e94\u7684\u6d41\u5f62\u5b66\u4e60\u76ee\u6807\uff0c\u4f7f\u7528\u9ece\u66fcSGD\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGSG\u6bd4\u6b27\u51e0\u91cc\u5f97SNN\u548c\u57fa\u4e8e\u6d41\u5f62\u7684GNN\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u80fd\u6548\u3002", "conclusion": "GSG\u4e3a\u66f2\u7387\u611f\u77e5\u3001\u8282\u80fd\u7684\u56fe\u5b66\u4e60\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2508.06569", "pdf": "https://arxiv.org/pdf/2508.06569", "abs": "https://arxiv.org/abs/2508.06569", "authors": ["Lance Yao", "Suman Samantray", "Ayana Ghosh", "Kevin Roccapriore", "Libor Kovarik", "Sarah Allec", "Maxim Ziatdinov"], "title": "Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "comment": null, "summary": "The history of science is punctuated by serendipitous discoveries, where\nunexpected observations, rather than targeted hypotheses, opened new fields of\ninquiry. While modern autonomous laboratories excel at accelerating hypothesis\ntesting, their optimization for efficiency risks overlooking these crucial,\nunplanned findings. To address this gap, we introduce SciLink, an open-source,\nmulti-agent artificial intelligence framework designed to operationalize\nserendipity in materials research by creating a direct, automated link between\nexperimental observation, novelty assessment, and theoretical simulations. The\nframework employs a hybrid AI strategy where specialized machine learning\nmodels perform quantitative analysis of experimental data, while large language\nmodels handle higher-level reasoning. These agents autonomously convert raw\ndata from materials characterization techniques into falsifiable scientific\nclaims, which are then quantitatively scored for novelty against the published\nliterature. We demonstrate the framework's versatility across diverse research\nscenarios, showcasing its application to atomic-resolution and hyperspectral\ndata, its capacity to integrate real-time human expert guidance, and its\nability to close the research loop by proposing targeted follow-up experiments.\nBy systematically analyzing all observations and contextualizing them, SciLink\nprovides a practical framework for AI-driven materials research that not only\nenhances efficiency but also actively cultivates an environment ripe for\nserendipitous discoveries, thereby bridging the gap between automated\nexperimentation and open-ended scientific exploration.", "AI": {"tldr": "\u5f15\u5165\u5f00\u6e90\u591a\u667a\u80fd\u4f53AI\u6846\u67b6SciLink\uff0c\u5c06\u5b9e\u9a8c\u89c2\u5bdf\u3001\u65b0\u9896\u6027\u8bc4\u4f30\u548c\u7406\u8bba\u6a21\u62df\u81ea\u52a8\u5173\u8054\uff0c\u5728\u6750\u6599\u7814\u7a76\u4e2d\u5b9e\u73b0\u610f\u5916\u53d1\u73b0\uff0c\u5c55\u793a\u5176\u591a\u529f\u80fd\u6027\uff0c\u5f25\u8865\u81ea\u52a8\u5316\u5b9e\u9a8c\u4e0e\u5f00\u653e\u6027\u79d1\u5b66\u63a2\u7d22\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u4ee3\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u5728\u52a0\u901f\u5047\u8bbe\u68c0\u9a8c\u65f6\u53ef\u80fd\u5ffd\u7565\u610f\u5916\u53d1\u73b0\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df7\u5408AI\u7b56\u7565\uff0c\u4e13\u4e1a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5206\u6790\u5b9e\u9a8c\u6570\u636e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9ad8\u5c42\u63a8\u7406\uff0c\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u8bc1\u4f2a\u79d1\u5b66\u4e3b\u5f20\u5e76\u8bc4\u4f30\u65b0\u9896\u6027\u3002", "result": "\u5c55\u793a\u4e86\u6846\u67b6\u5728\u4e0d\u540c\u7814\u7a76\u573a\u666f\u7684\u591a\u529f\u80fd\u6027\uff0c\u5982\u5904\u7406\u539f\u5b50\u5206\u8fa8\u7387\u548c\u9ad8\u5149\u8c31\u6570\u636e\u3001\u6574\u5408\u4e13\u5bb6\u6307\u5bfc\u3001\u63d0\u51fa\u540e\u7eed\u5b9e\u9a8c\u3002", "conclusion": "SciLink\u4e3aAI\u9a71\u52a8\u7684\u6750\u6599\u7814\u7a76\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\uff0c\u65e2\u63d0\u9ad8\u6548\u7387\u53c8\u4fc3\u8fdb\u610f\u5916\u53d1\u73b0\u3002"}}
{"id": "2508.06753", "pdf": "https://arxiv.org/pdf/2508.06753", "abs": "https://arxiv.org/abs/2508.06753", "authors": ["Evangelos Georganas", "Dhiraj Kalamkar", "Alexander Heinecke"], "title": "Pushing the Envelope of LLM Inference on AI-PC", "categories": ["cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the\nperplexity and end-task performance of their full-precision counterparts using\nthe same model size, is ushering in a new era of LLM inference for\nresource-constrained environments such as edge devices and AI PCs. While these\nquantization advances promise models that are more cost-effective in terms of\nlatency, memory, throughput, and energy consumption, the computational\nefficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp)\nused to deploy them remains underexplored. In this work, we take a bottom-up\napproach: we first design and implement 1-bit and 2-bit microkernels optimized\nfor modern CPUs, achieving peak computational efficiency across a variety of\nCPU platforms. We integrate these microkernels into a state-of-the-art LLM\ninference framework, namely PyTorch-TPP, and present end-to-end inference\nresults with 2-bit models that outperform the current SOTA runtime bitnet.cpp\nby up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model\ninference. Our optimized runtime advances the state of LLM inference on AI PCs\nand edge devices, paving the way for efficient deployment of ultra-low-bit LLM\nmodels.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u8d85\u4f4e\u6bd4\u7279LLM\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63a8\u7406\uff0c\u8bbe\u8ba1\u4f18\u5316\u5fae\u5185\u6838\u5e76\u96c6\u6210\u5230\u6846\u67b6\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u63a8\u7406\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u8d85\u4f4e\u6bd4\u7279LLM\u6a21\u578b\u867d\u6709\u4f18\u52bf\uff0c\u4f46\u73b0\u6709\u63a8\u7406\u8fd0\u884c\u65f6\u8ba1\u7b97\u6548\u7387\u5f85\u7814\u7a76\uff0c\u9700\u63d0\u5347\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63a8\u7406\u6548\u7387\u3002", "method": "\u91c7\u7528\u81ea\u5e95\u5411\u4e0a\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u9488\u5bf9\u73b0\u4ee3CPU\u4f18\u5316\u76841\u4f4d\u548c2\u4f4d\u5fae\u5185\u6838\uff0c\u96c6\u6210\u5230PyTorch - TPP\u6846\u67b6\u3002", "result": "2\u4f4d\u6a21\u578b\u7aef\u5230\u7aef\u63a8\u7406\u7ed3\u679c\u6bd4\u5f53\u524dSOTA\u8fd0\u884c\u65f6bitnet.cpp\u5feb\u8fbe2.2\u500d\uff0c\u6bd416\u4f4d\u6a21\u578b\u63a8\u7406\u5feb\u8fbe7\u500d\u3002", "conclusion": "\u4f18\u5316\u540e\u7684\u8fd0\u884c\u65f6\u63a8\u52a8\u4e86AI PC\u548c\u8fb9\u7f18\u8bbe\u5907\u4e0aLLM\u63a8\u7406\u53d1\u5c55\uff0c\u4e3a\u8d85\u4f4e\u6bd4\u7279LLM\u6a21\u578b\u9ad8\u6548\u90e8\u7f72\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.06562", "pdf": "https://arxiv.org/pdf/2508.06562", "abs": "https://arxiv.org/abs/2508.06562", "authors": ["Mohammad T. Hajiaghayi", "Suho Shin"], "title": "Algorithmic Delegated Choice: An Annotated Reading List", "categories": ["cs.GT", "cs.DS", "econ.TH"], "comment": "SIGecom Exchanges, Vol 23, No. 1, July 2025, Pages 80-85", "summary": "The problem of delegated choice has been of long interest in economics and\nrecently on computer science. We overview a list of papers on delegated choice\nproblem, from classic works to recent papers with algorithmic perspectives.", "AI": {"tldr": "\u6982\u8ff0\u59d4\u6258\u9009\u62e9\u95ee\u9898\u76f8\u5173\u8bba\u6587\uff0c\u6db5\u76d6\u7ecf\u5178\u4e0e\u7b97\u6cd5\u89c6\u89d2\u65b0\u8bba\u6587\u3002", "motivation": "\u59d4\u6258\u9009\u62e9\u95ee\u9898\u5728\u7ecf\u6d4e\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u957f\u671f\u53d7\u5173\u6ce8\u3002", "method": "\u5bf9\u59d4\u6258\u9009\u62e9\u95ee\u9898\u76f8\u5173\u8bba\u6587\u8fdb\u884c\u6982\u8ff0\u3002", "result": "\u5b8c\u6210\u5bf9\u76f8\u5173\u8bba\u6587\u7684\u6982\u8ff0\u3002", "conclusion": "\u65e0\u660e\u786e\u7ed3\u8bba"}}
{"id": "2508.06941", "pdf": "https://arxiv.org/pdf/2508.06941", "abs": "https://arxiv.org/abs/2508.06941", "authors": ["Huanwei Xu", "Lin Xu", "Liang Yuan"], "title": "CLAP: Coreference-Linked Augmentation for Passage Retrieval", "categories": ["cs.IR", "cs.AI", "68T50", "I.2.7; H.3.3"], "comment": "This paper has been accepted by CIKM 2025", "summary": "Large Language Model (LLM)-based passage expansion has shown promise for\nenhancing first-stage retrieval, but often underperforms with dense retrievers\ndue to semantic drift and misalignment with their pretrained semantic space.\nBeyond this, only a portion of a passage is typically relevant to a query,\nwhile the rest introduces noise--an issue compounded by chunking techniques\nthat break coreference continuity. We propose Coreference-Linked Augmentation\nfor Passage Retrieval (CLAP), a lightweight LLM-based expansion framework that\nsegments passages into coherent chunks, resolves coreference chains, and\ngenerates localized pseudo-queries aligned with dense retriever\nrepresentations. A simple fusion of global topical signals and fine-grained\nsubtopic signals achieves robust performance across domains. CLAP yields\nconsistent gains even as retriever strength increases, enabling dense\nretrievers to match or surpass second-stage rankers such as BM25 + MonoT5-3B,\nwith up to 20.68% absolute nDCG@10 improvement. These improvements are\nespecially notable in out-of-domain settings, where conventional LLM-based\nexpansion methods relying on domain knowledge often falter. CLAP instead adopts\na logic-centric pipeline that enables robust, domain-agnostic generalization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u6269\u5c55\u6846\u67b6CLAP\u7528\u4e8e\u6bb5\u843d\u68c0\u7d22\uff0c\u80fd\u63d0\u5347\u68c0\u7d22\u6027\u80fd\uff0c\u5c24\u5176\u5728\u8de8\u9886\u57df\u573a\u666f\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6bb5\u843d\u6269\u5c55\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u6f02\u79fb\u3001\u4e0e\u9884\u8bad\u7ec3\u8bed\u4e49\u7a7a\u95f4\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e14\u6bb5\u843d\u90e8\u5206\u5185\u5bb9\u4e3a\u566a\u58f0\uff0c\u5206\u5757\u6280\u672f\u4f1a\u7834\u574f\u5171\u6307\u8fde\u7eed\u6027\u3002", "method": "\u63d0\u51faCoreference - Linked Augmentation for Passage Retrieval (CLAP)\u6846\u67b6\uff0c\u5c06\u6bb5\u843d\u5206\u5272\u6210\u8fde\u8d2f\u5757\uff0c\u89e3\u51b3\u5171\u6307\u94fe\uff0c\u751f\u6210\u4e0e\u5bc6\u96c6\u68c0\u7d22\u5668\u8868\u793a\u4e00\u81f4\u7684\u5c40\u90e8\u4f2a\u67e5\u8be2\uff0c\u878d\u5408\u5168\u5c40\u4e3b\u9898\u4fe1\u53f7\u548c\u7ec6\u7c92\u5ea6\u5b50\u4e3b\u9898\u4fe1\u53f7\u3002", "result": "CLAP\u5728\u68c0\u7d22\u5668\u6027\u80fd\u63d0\u5347\u65f6\u4ecd\u6709\u7a33\u5b9a\u589e\u76ca\uff0c\u80fd\u4f7f\u5bc6\u96c6\u68c0\u7d22\u5668\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u4e8c\u7ea7\u6392\u5e8f\u5668\uff0cnDCG@10\u7edd\u5bf9\u63d0\u5347\u8fbe20.68%\uff0c\u5728\u8de8\u9886\u57df\u573a\u666f\u4f18\u52bf\u660e\u663e\u3002", "conclusion": "CLAP\u91c7\u7528\u4ee5\u903b\u8f91\u4e3a\u4e2d\u5fc3\u7684\u7ba1\u9053\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u3001\u4e0e\u9886\u57df\u65e0\u5173\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.06774", "pdf": "https://arxiv.org/pdf/2508.06774", "abs": "https://arxiv.org/abs/2508.06774", "authors": ["Lorenzo Beretta", "Vincent Cohen-Addad", "Rajesh Jayaram", "Erik Waingarten"], "title": "Approximating High-Dimensional Earth Mover's Distance as Fast as Closest Pair", "categories": ["cs.DS"], "comment": "FOCS 2025", "summary": "We give a reduction from $(1+\\varepsilon)$-approximate Earth Mover's Distance\n(EMD) to $(1+\\varepsilon)$-approximate Closest Pair (CP). As a consequence, we\nimprove the fastest known approximation algorithm for high-dimensional EMD.\nHere, given $p\\in [1, 2]$ and two sets of $n$ points $X,Y \\subseteq (\\mathbb\nR^d,\\ell_p)$, their EMD is the minimum cost of a perfect matching between $X$\nand $Y$, where the cost of matching two vectors is their $\\ell_p$ distance.\nFurther, CP is the basic problem of finding a pair of points realizing $\\min_{x\n\\in X, y\\in Y} ||x-y||_p$. Our contribution is twofold: we show that if a\n$(1+\\varepsilon)$-approximate CP can be computed in time $n^{2-\\phi}$, then a\n$1+O(\\varepsilon)$ approximation to EMD can be computed in time\n$n^{2-\\Omega(\\phi)}$; plugging in the fastest known algorithm for CP [Alman,\nChan, Williams FOCS'16], we obtain a $(1+\\varepsilon)$-approximation algorithm\nfor EMD running in time $n^{2-\\tilde{\\Omega}(\\varepsilon^{1/3})}$ for\nhigh-dimensional point sets, which improves over the prior fastest running time\nof $n^{2-\\Omega(\\varepsilon^2)}$ [Andoni, Zhang FOCS'23]. Our main technical\ncontribution is a sublinear implementation of the Multiplicative Weights Update\nframework for EMD. Specifically, we demonstrate that the updates can be\nexecuted without ever explicitly computing or storing the weights; instead, we\nexploit the underlying geometric structure to perform the updates implicitly.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.06879", "pdf": "https://arxiv.org/pdf/2508.06879", "abs": "https://arxiv.org/abs/2508.06879", "authors": ["Michael Dorner", "Andreas Bauer", "Darja \u0160mite", "Lukas Thode", "Daniel Mendez", "Ricardo Britto", "Stephan Lukasczyk", "Ehsan Zabardast", "Michael Kormann"], "title": "Quo Vadis, Code Review? Exploring the Future of Code Review", "categories": ["cs.SE"], "comment": null, "summary": "Code review has long been a core practice in collaborative software\nengineering. In this research, we explore how practitioners reflect on code\nreview today and what changes they anticipate in the near future. We then\ndiscuss the potential long-term risks of these anticipated changes for the\nevolution of code review and its role in collaborative software engineering.", "AI": {"tldr": "\u7814\u7a76\u4ece\u4e1a\u8005\u5bf9\u4ee3\u7801\u5ba1\u67e5\u73b0\u72b6\u7684\u770b\u6cd5\u3001\u672a\u6765\u9884\u671f\u53d8\u5316\u53ca\u6f5c\u5728\u957f\u671f\u98ce\u9669\u3002", "motivation": "\u4e86\u89e3\u4ee3\u7801\u5ba1\u67e5\u5728\u5f53\u4e0b\u4ece\u4e1a\u8005\u4e2d\u7684\u60c5\u51b5\u4ee5\u53ca\u672a\u6765\u53ef\u80fd\u7684\u53d8\u5316\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2508.06574", "pdf": "https://arxiv.org/pdf/2508.06574", "abs": "https://arxiv.org/abs/2508.06574", "authors": ["Fatemeh Moradi", "Mehran Tarif", "Mohammadhossein Homaei"], "title": "Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering", "categories": ["cs.LG", "cs.CR"], "comment": "Six Pages, two Figures and six Tables", "summary": "Detecting fraud in modern supply chains is a growing challenge, driven by the\ncomplexity of global networks and the scarcity of labeled data. Traditional\ndetection methods often struggle with class imbalance and limited supervision,\nreducing their effectiveness in real-world applications. This paper proposes a\nnovel two-phase learning framework to address these challenges. In the first\nphase, the Isolation Forest algorithm performs unsupervised anomaly detection\nto identify potential fraud cases and reduce the volume of data requiring\nfurther analysis. In the second phase, a self-training Support Vector Machine\n(SVM) refines the predictions using both labeled and high-confidence\npseudo-labeled samples, enabling robust semi-supervised learning. The proposed\nmethod is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive\nreal-world supply chain dataset with fraud indicators. It achieves an F1-score\nof 0.817 while maintaining a false positive rate below 3.0%. These results\ndemonstrate the effectiveness and efficiency of combining unsupervised\npre-filtering with semi-supervised refinement for supply chain fraud detection\nunder real-world constraints, though we acknowledge limitations regarding\nconcept drift and the need for comparison with deep learning approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u9636\u6bb5\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u4f9b\u5e94\u94fe\u6b3a\u8bc8\u68c0\u6d4b\u96be\u9898\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u4ee3\u4f9b\u5e94\u94fe\u6b3a\u8bc8\u68c0\u6d4b\u56e0\u5168\u7403\u7f51\u7edc\u590d\u6742\u548c\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u76d1\u7763\u6709\u9650\u95ee\u9898\u3002", "method": "\u7b2c\u4e00\u9636\u6bb5\u7528Isolation Forest\u7b97\u6cd5\u8fdb\u884c\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7528\u81ea\u8bad\u7ec3\u652f\u6301\u5411\u91cf\u673a\u7ed3\u5408\u6807\u6ce8\u548c\u9ad8\u7f6e\u4fe1\u5ea6\u4f2a\u6807\u6ce8\u6837\u672c\u8fdb\u884c\u534a\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u5728DataCo\u667a\u80fd\u4f9b\u5e94\u94fe\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u8fbe0.817\uff0c\u5047\u9633\u6027\u7387\u4f4e\u4e8e3.0%\u3002", "conclusion": "\u7ed3\u5408\u65e0\u76d1\u7763\u9884\u8fc7\u6ee4\u548c\u534a\u76d1\u7763\u7ec6\u5316\u7684\u65b9\u6cd5\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u5bf9\u4f9b\u5e94\u94fe\u6b3a\u8bc8\u68c0\u6d4b\u6709\u6548\uff0c\u4f46\u5b58\u5728\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\u4e14\u9700\u4e0e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5bf9\u6bd4\u3002"}}
{"id": "2508.07068", "pdf": "https://arxiv.org/pdf/2508.07068", "abs": "https://arxiv.org/abs/2508.07068", "authors": ["Hardhik Mohanty", "Giovanni Zaarour", "Bhaskar Krishnamachari"], "title": "Proactive Market Making and Liquidity Analysis for Everlasting Options in DeFi Ecosystems", "categories": ["q-fin.CP", "q-fin.MF"], "comment": "6 pages, 3 figures", "summary": "Everlasting options, a relatively new class of perpetual financial\nderivatives, have emerged to tackle the challenges of rolling contracts and\nliquidity fragmentation in decentralized finance markets. This paper offers an\nin-depth analysis of markets for everlasting options, modeled using a dynamic\nproactive market maker. We examine the behavior of funding fees and transaction\ncosts across varying liquidity conditions. Using simulations and modeling, we\ndemonstrate that liquidity providers can aim to achieve a net positive PnL by\nemploying effective hedging strategies, even in challenging environments\ncharacterized by low liquidity and high transaction costs. Additionally, we\nprovide insights into the incentives that drive liquidity providers to support\nthe growth of everlasting option markets and highlight the significant benefits\nthese instruments offer to traders as a reliable and efficient financial tool.", "AI": {"tldr": "\u672c\u6587\u6df1\u5165\u5206\u6790\u6c38\u7eed\u671f\u6743\u5e02\u573a\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u5efa\u6a21\u8868\u660e\u6d41\u52a8\u6027\u63d0\u4f9b\u8005\u53ef\u91c7\u7528\u6709\u6548\u5bf9\u51b2\u7b56\u7565\u5b9e\u73b0\u6b63\u635f\u76ca\uff0c\u9610\u8ff0\u5176\u5bf9\u5e02\u573a\u589e\u957f\u7684\u6fc0\u52b1\u53ca\u5bf9\u4ea4\u6613\u8005\u7684\u76ca\u5904\u3002", "motivation": "\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u91d1\u878d\u5e02\u573a\u4e2d\u6eda\u52a8\u5408\u7ea6\u548c\u6d41\u52a8\u6027\u788e\u7247\u5316\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u52a8\u6001\u4e3b\u52a8\u505a\u5e02\u5546\u6a21\u578b\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u5efa\u6a21\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u5373\u4f7f\u5728\u4f4e\u6d41\u52a8\u6027\u548c\u9ad8\u4ea4\u6613\u6210\u672c\u73af\u5883\u4e0b\uff0c\u6d41\u52a8\u6027\u63d0\u4f9b\u8005\u91c7\u7528\u6709\u6548\u5bf9\u51b2\u7b56\u7565\u53ef\u5b9e\u73b0\u51c0\u6b63\u635f\u76ca\u3002", "conclusion": "\u9610\u8ff0\u4e86\u6fc0\u52b1\u6d41\u52a8\u6027\u63d0\u4f9b\u8005\u652f\u6301\u6c38\u7eed\u671f\u6743\u5e02\u573a\u589e\u957f\u7684\u56e0\u7d20\uff0c\u5f3a\u8c03\u8be5\u5de5\u5177\u5bf9\u4ea4\u6613\u8005\u53ef\u9760\u4e14\u9ad8\u6548\u3002"}}
{"id": "2508.08130", "pdf": "https://arxiv.org/pdf/2508.08130", "abs": "https://arxiv.org/abs/2508.08130", "authors": ["Tim J. Boonen", "Engel John C. Dela Vega", "Bin Zou"], "title": "Optimal Dividend, Reinsurance, and Capital Injection Strategies for an Insurer with Two Collaborating Business Lines", "categories": ["math.OC", "q-fin.MF", "q-fin.RM", "91G05 (Primary) 93E20 (Secondary)"], "comment": "36 pages, 11 figures", "summary": "This paper considers an insurer with two collaborating business lines, and\nthe risk exposure of each line follows a diffusion risk model. The manager of\nthe insurer makes three decisions for each line: (i) dividend payout, (ii)\n(proportional) reinsurance coverage, and (iii) capital injection (from one line\ninto the other). The manager seeks an optimal dividend, reinsurance, and\ncapital injection strategy to maximize the expected weighted sum of the total\ndividend payments until the first ruin. We completely solve this problem and\nobtain the value function and optimal strategies in closed form. We show that\nthe optimal dividend strategy is a threshold strategy, and the more important\nline always has a lower threshold to pay dividends. The optimal proportion of\nrisk ceded to the reinsurer is decreasing with respect to the aggregate reserve\nlevel for each line, and capital injection is only used to prevent the ruin of\na business line. Finally, numerical examples are presented to illustrate the\nimpact of model parameters on the optimal strategies.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6709\u4e24\u6761\u534f\u4f5c\u4e1a\u52a1\u7ebf\u7684\u4fdd\u9669\u516c\u53f8\uff0c\u7ba1\u7406\u8005\u505a\u7ea2\u5229\u652f\u4ed8\u3001\u518d\u4fdd\u9669\u548c\u8d44\u672c\u6ce8\u5165\u51b3\u7b56\uff0c\u6c42\u89e3\u6700\u4f18\u7b56\u7565\uff0c\u7ed9\u51fa\u4ef7\u503c\u51fd\u6570\uff0c\u5206\u6790\u7b56\u7565\u7279\u70b9\u5e76\u901a\u8fc7\u6570\u503c\u7b97\u4f8b\u8bf4\u660e\u53c2\u6570\u5f71\u54cd\u3002", "motivation": "\u4e3a\u6709\u4e24\u6761\u534f\u4f5c\u4e1a\u52a1\u7ebf\u7684\u4fdd\u9669\u516c\u53f8\u7ba1\u7406\u8005\u627e\u5230\u6700\u4f18\u7ea2\u5229\u3001\u518d\u4fdd\u9669\u548c\u8d44\u672c\u6ce8\u5165\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u5316\u9996\u6b21\u7834\u4ea7\u524d\u603b\u7ea2\u5229\u652f\u4ed8\u7684\u671f\u671b\u52a0\u6743\u548c\u3002", "method": "\u6c42\u89e3\u4fdd\u9669\u516c\u53f8\u51b3\u7b56\u95ee\u9898\uff0c\u4ee5\u83b7\u5f97\u4ef7\u503c\u51fd\u6570\u548c\u6700\u4f18\u7b56\u7565\u7684\u95ed\u5f0f\u89e3\u3002", "result": "\u6700\u4f18\u7ea2\u5229\u7b56\u7565\u662f\u9608\u503c\u7b56\u7565\uff0c\u66f4\u91cd\u8981\u4e1a\u52a1\u7ebf\u5206\u7ea2\u9608\u503c\u4f4e\uff1b\u6700\u4f18\u518d\u4fdd\u9669\u6bd4\u4f8b\u968f\u5404\u4e1a\u52a1\u7ebf\u603b\u51c6\u5907\u91d1\u6c34\u5e73\u4e0b\u964d\uff1b\u8d44\u672c\u6ce8\u5165\u4ec5\u7528\u4e8e\u9632\u6b62\u4e1a\u52a1\u7ebf\u7834\u4ea7\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4fdd\u9669\u516c\u53f8\u51b3\u7b56\u95ee\u9898\uff0c\u5f97\u5230\u6700\u4f18\u7b56\u7565\u5e76\u5206\u6790\u5176\u7279\u70b9\uff0c\u901a\u8fc7\u6570\u503c\u7b97\u4f8b\u5c55\u793a\u6a21\u578b\u53c2\u6570\u5bf9\u6700\u4f18\u7b56\u7565\u7684\u5f71\u54cd\u3002"}}
{"id": "2508.08152", "pdf": "https://arxiv.org/pdf/2508.08152", "abs": "https://arxiv.org/abs/2508.08152", "authors": ["Steven Campbell", "Philippe Bergault", "Jason Milionis", "Marcel Nutz"], "title": "Optimal Fees for Liquidity Provision in Automated Market Makers", "categories": ["q-fin.TR", "econ.GN", "math.OC", "q-fin.CP", "q-fin.EC", "q-fin.PM"], "comment": "43 pages, 23 figures, 8 tables", "summary": "Passive liquidity providers (LPs) in automated market makers (AMMs) face\nlosses due to adverse selection (LVR), which static trading fees often fail to\noffset in practice. We study the key determinants of LP profitability in a\ndynamic reduced-form model where an AMM operates in parallel with a centralized\nexchange (CEX), traders route their orders optimally to the venue offering the\nbetter price, and arbitrageurs exploit price discrepancies. Using large-scale\nsimulations and real market data, we analyze how LP profits vary with market\nconditions such as volatility and trading volume, and characterize the optimal\nAMM fee as a function of these conditions. We highlight the mechanisms driving\nthese relationships through extensive comparative statics, and confirm the\nmodel's relevance through market data calibration. A key trade-off emerges:\nfees must be low enough to attract volume, yet high enough to earn sufficient\nrevenues and mitigate arbitrage losses. We find that under normal market\nconditions, the optimal AMM fee is competitive with the trading cost on the CEX\nand remarkably stable, whereas in periods of very high volatility, a high fee\nprotects passive LPs from severe losses. These findings suggest that a\nthreshold-type dynamic fee schedule is both robust enough to market conditions\nand improves LP outcomes.", "AI": {"tldr": "\u7814\u7a76\u81ea\u52a8\u5316\u505a\u5e02\u5546\uff08AMM\uff09\u4e2d\u88ab\u52a8\u6d41\u52a8\u6027\u63d0\u4f9b\u8005\uff08LP\uff09\u76c8\u5229\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\uff0c\u5206\u6790LP\u5229\u6da6\u968f\u5e02\u573a\u6761\u4ef6\u7684\u53d8\u5316\uff0c\u786e\u5b9a\u6700\u4f18AMM\u8d39\u7528\uff0c\u63d0\u51fa\u9608\u503c\u578b\u52a8\u6001\u8d39\u7528\u7b56\u7565\u3002", "motivation": "AMM\u4e2d\u88ab\u52a8LP\u56e0\u9006\u5411\u9009\u62e9\u9762\u4e34\u635f\u5931\uff0c\u9759\u6001\u4ea4\u6613\u8d39\u7528\u96be\u4ee5\u5f25\u8865\uff0c\u9700\u7814\u7a76LP\u76c8\u5229\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u6784\u5efa\u52a8\u6001\u7b80\u5316\u6a21\u578b\uff0c\u7ed3\u5408\u5927\u89c4\u6a21\u6a21\u62df\u548c\u771f\u5b9e\u5e02\u573a\u6570\u636e\uff0c\u8fdb\u884c\u6bd4\u8f83\u9759\u6001\u5206\u6790\u548c\u5e02\u573a\u6570\u636e\u6821\u51c6\u3002", "result": "\u53d1\u73b0\u6b63\u5e38\u5e02\u573a\u6761\u4ef6\u4e0b\u6700\u4f18AMM\u8d39\u7528\u6709\u7ade\u4e89\u529b\u4e14\u7a33\u5b9a\uff0c\u9ad8\u6ce2\u52a8\u65f6\u671f\u9ad8\u8d39\u7528\u53ef\u4fdd\u62a4LP\uff0c\u5b58\u5728\u5438\u5f15\u4ea4\u6613\u91cf\u548c\u8d5a\u53d6\u6536\u5165\u3001\u51cf\u5c11\u5957\u5229\u635f\u5931\u7684\u6743\u8861\u3002", "conclusion": "\u9608\u503c\u578b\u52a8\u6001\u8d39\u7528\u7b56\u7565\u5bf9\u5e02\u573a\u6761\u4ef6\u6709\u5f3a\u9c81\u68d2\u6027\uff0c\u80fd\u6539\u5584LP\u6536\u76ca\u3002"}}
{"id": "2508.07527", "pdf": "https://arxiv.org/pdf/2508.07527", "abs": "https://arxiv.org/abs/2508.07527", "authors": ["Xiaochen Long", "Marek Kimmel"], "title": "An Approximate Maximum Likelihood Estimator for Discretely Observed Linear Birth-and-Death Processes", "categories": ["stat.CO", "stat.AP"], "comment": "41 pages, 1 figure", "summary": "Linear birth-and-death processes (LBDPs) are foundational stochastic models\nin population dynamics, evolutionary biology, and hematopoiesis. Estimating\nparameters from discretely observed data is computationally demanding due to\nirregular sampling, noise, and missing values. We propose a novel approximate\nmaximum likelihood estimator (MLE) for LBDPs based on a Gaussian approximation\nto transition probabilities. The approach transforms estimation into a\nunivariate optimization problem, achieving substantial computational gains\nwithout sacrificing accuracy.\n  Through simulations, we show that the approximate MLE outperforms Gaussian\nand saddlepoint-based estimators in speed and precision under realistic noise\nand sparsity. Applied to longitudinal clonal hematopoiesis data, the method\nproduces biologically meaningful growth estimates even with noisy,\ncompositional input. Unlike Gaussian and saddlepoint approximations, our\nestimator is invariant to data scaling, making it ideal for real-world\napplications such as variant allele frequency analyses.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9ad8\u65af\u8fd1\u4f3c\u7684\u7ebf\u6027\u751f\u6b7b\u8fc7\u7a0b\uff08LBDPs\uff09\u8fd1\u4f3c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\uff0c\u6709\u8ba1\u7b97\u4f18\u52bf\uff0c\u5728\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u5e94\u7528\u4e2d\u8868\u73b0\u597d\u3002", "motivation": "\u79bb\u6563\u89c2\u6d4b\u6570\u636e\u7684LBDPs\u53c2\u6570\u4f30\u8ba1\u8ba1\u7b97\u8981\u6c42\u9ad8\uff0c\u56e0\u4e0d\u89c4\u5219\u91c7\u6837\u3001\u566a\u58f0\u548c\u7f3a\u5931\u503c\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u9ad8\u65af\u8fd1\u4f3c\u8f6c\u79fb\u6982\u7387\u63d0\u51fa\u8fd1\u4f3c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\uff0c\u5c06\u4f30\u8ba1\u8f6c\u5316\u4e3a\u5355\u53d8\u91cf\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6a21\u62df\u4e2d\u8fd1\u4f3cMLE\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u9ad8\u65af\u548c\u978d\u70b9\u4f30\u8ba1\u5668\uff1b\u5e94\u7528\u4e8e\u7eb5\u5411\u514b\u9686\u9020\u8840\u6570\u636e\u80fd\u4ea7\u751f\u6709\u751f\u7269\u5b66\u610f\u4e49\u7684\u751f\u957f\u4f30\u8ba1\uff0c\u4e14\u5bf9\u6570\u636e\u7f29\u653e\u4e0d\u53d8\u3002", "conclusion": "\u63d0\u51fa\u7684\u8fd1\u4f3cMLE\u6709\u8ba1\u7b97\u4f18\u52bf\uff0c\u9002\u5408\u73b0\u5b9e\u5e94\u7528\u5982\u53d8\u5f02\u7b49\u4f4d\u57fa\u56e0\u9891\u7387\u5206\u6790\u3002"}}
{"id": "2508.06847", "pdf": "https://arxiv.org/pdf/2508.06847", "abs": "https://arxiv.org/abs/2508.06847", "authors": ["Lam Ngo", "Huong Ha", "Jeffrey Chan", "Hongyu Zhang"], "title": "MOCA-HESP: Meta High-dimensional Bayesian Optimization for Combinatorial and Mixed Spaces via Hyper-ellipsoid Partitioning", "categories": ["stat.ML", "cs.LG"], "comment": "Published at the 28th European Conference on Artificial Intelligence\n  (ECAI-2025)", "summary": "High-dimensional Bayesian Optimization (BO) has attracted significant\nattention in recent research. However, existing methods have mainly focused on\noptimizing in continuous domains, while combinatorial (ordinal and categorical)\nand mixed domains still remain challenging. In this paper, we first propose\nMOCA-HESP, a novel high-dimensional BO method for combinatorial and mixed\nvariables. The key idea is to leverage the hyper-ellipsoid space partitioning\n(HESP) technique with different categorical encoders to work with\nhigh-dimensional, combinatorial and mixed spaces, while adaptively selecting\nthe optimal encoders for HESP using a multi-armed bandit technique. Our method,\nMOCA-HESP, is designed as a \\textit{meta-algorithm} such that it can\nincorporate other combinatorial and mixed BO optimizers to further enhance the\noptimizers' performance. Finally, we develop three practical BO methods by\nintegrating MOCA-HESP with state-of-the-art BO optimizers for combinatorial and\nmixed variables: standard BO, CASMOPOLITAN, and Bounce. Our experimental\nresults on various synthetic and real-world benchmarks show that our methods\noutperform existing baselines. Our code implementation can be found at\nhttps://github.com/LamNgo1/moca-hesp", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMOCA - HESP\u7528\u4e8e\u7ec4\u5408\u548c\u6df7\u5408\u53d8\u91cf\u7684\u9ad8\u7ef4\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u96c6\u6210\u73b0\u6709\u4f18\u5316\u5668\u5f00\u53d1\u4e09\u79cd\u5b9e\u7528\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u9ad8\u7ef4\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8fde\u7eed\u57df\uff0c\u7ec4\u5408\u548c\u6df7\u5408\u57df\u4f18\u5316\u4ecd\u5177\u6311\u6218\u3002", "method": "\u63d0\u51faMOCA - HESP\u65b9\u6cd5\uff0c\u5229\u7528\u8d85\u692d\u7403\u7a7a\u95f4\u5212\u5206\u6280\u672f\u4e0e\u4e0d\u540c\u5206\u7c7b\u7f16\u7801\u5668\u7ed3\u5408\uff0c\u7528\u591a\u81c2\u8001\u864e\u673a\u6280\u672f\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f18\u7f16\u7801\u5668\uff0c\u5c06\u5176\u4f5c\u4e3a\u5143\u7b97\u6cd5\u96c6\u6210\u5176\u4ed6\u4f18\u5316\u5668\u3002", "result": "\u5728\u5404\u79cd\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "MOCA - HESP\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u7ec4\u5408\u548c\u6df7\u5408\u53d8\u91cf\u7684\u9ad8\u7ef4\u8d1d\u53f6\u65af\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u4f18\u5316\u6027\u80fd\u3002"}}
{"id": "2508.06814", "pdf": "https://arxiv.org/pdf/2508.06814", "abs": "https://arxiv.org/abs/2508.06814", "authors": ["Jinjin Zhao", "Sanjay Krishnan"], "title": "Metadata Management for AI-Augmented Data Workflows", "categories": ["cs.DB"], "comment": null, "summary": "AI-augmented data workflows introduce complex governance challenges, as both\nhuman and model-driven processes generate, transform, and consume data\nartifacts. These workflows blend heterogeneous tools, dynamic execution\npatterns, and opaque model decisions, making comprehensive metadata capture\ndifficult. In this work, we present TableVault, a metadata governance framework\ndesigned for human-AI collaborative data creation. TableVault records ingestion\nevents, traces operation status, links execution parameters to their data\norigins, and exposes a standardized metadata layer. By combining\ndatabase-inspired guarantees with AI-oriented design, such as declarative\noperation builders and lineage-aware references, TableVault supports\ntransparency and reproducibility across mixed human-model pipelines. Through a\ndocument classification case study, we demonstrate how TableVault preserves\ndetailed lineage and operational context, enabling robust metadata management,\neven in partially observable execution environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u4eba\u673a\u534f\u4f5c\u6570\u636e\u521b\u5efa\u7684\u5143\u6570\u636e\u6cbb\u7406\u6846\u67b6TableVault\uff0c\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u5176\u80fd\u5b9e\u73b0\u5f3a\u5927\u5143\u6570\u636e\u7ba1\u7406\u3002", "motivation": "AI\u589e\u5f3a\u7684\u6570\u636e\u5de5\u4f5c\u6d41\u5e26\u6765\u590d\u6742\u6cbb\u7406\u6311\u6218\uff0c\u96be\u4ee5\u8fdb\u884c\u5168\u9762\u5143\u6570\u636e\u6355\u83b7\u3002", "method": "\u63d0\u51faTableVault\u6846\u67b6\uff0c\u8bb0\u5f55\u6444\u5165\u4e8b\u4ef6\u3001\u8ffd\u8e2a\u64cd\u4f5c\u72b6\u6001\u3001\u5173\u8054\u6267\u884c\u53c2\u6570\u4e0e\u6570\u636e\u6765\u6e90\u3001\u63d0\u4f9b\u6807\u51c6\u5316\u5143\u6570\u636e\u5c42\uff0c\u7ed3\u5408\u6570\u636e\u5e93\u4fdd\u969c\u548cAI\u5bfc\u5411\u8bbe\u8ba1\u3002", "result": "\u901a\u8fc7\u6587\u6863\u5206\u7c7b\u6848\u4f8b\u7814\u7a76\uff0c\u8868\u660eTableVault\u80fd\u4fdd\u7559\u8be6\u7ec6\u6cbf\u88ad\u548c\u64cd\u4f5c\u4e0a\u4e0b\u6587\u3002", "conclusion": "TableVault\u652f\u6301\u6df7\u5408\u4eba\u673a\u7ba1\u9053\u7684\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\uff0c\u80fd\u5728\u90e8\u5206\u53ef\u89c2\u5bdf\u7684\u6267\u884c\u73af\u5883\u4e2d\u5b9e\u73b0\u5f3a\u5927\u7684\u5143\u6570\u636e\u7ba1\u7406\u3002"}}
{"id": "2508.07076", "pdf": "https://arxiv.org/pdf/2508.07076", "abs": "https://arxiv.org/abs/2508.07076", "authors": ["Valeria Aloisi", "Sergio Noce", "Italo Epicoco", "Cristina Cipriano", "Massimo Cafaro", "Giuseppe Brundu", "Lorenzo Arcidiaco", "Donatella Spano", "Giovanni Aloisio", "Simone Mereu"], "title": "Application of association rule mining to assess forest species distribution in Italy considering abiotic and biotic factors", "categories": ["cs.CE", "J.2"], "comment": "41 pages, 6 tables, 6 figures, submitted to ecological informatics\n  journal", "summary": "Biodiversity monitoring represents a pressing global priority, and assessing\nforest community composition plays a crucial role due to its influence on\necosystem functions. The spatial distribution of forest species becomes\nessential for understanding biodiversity dynamics, territorial planning, aiding\nnature conservation and enhancing ecosystem resilience amid global change.\nAssociation Rule Mining, commonly applied to other scientific contexts, is now\ninnovatively adopted in the ecological field to explore the relationships among\nco-occurring plant species and extract hidden interpretable patterns, also with\nabiotic and biotic conditions. Multiple heterogeneous data sources were\nintegrated through data preprocessing into a unique dataset, including\ngeoreferenced information about 151 plant species monitored within 6,784 plots\nacross Italy and several bioclimatic indices, soil-related factors, and\nvariables from earth observations. The Frequent Pattern Growth algorithm, used\nfor association rule mining, provided interesting and encouraging findings,\nsuggesting ecological rules among plant species and environmental conditions.\nIndeed, temperature seasonality between 650-700 and precipitation seasonality\nbetween 45-50 resulted very correlated with Picea abies (confidence = 90.9%,\nlift = 7.13). Patterns detected for Picea abies highlighted its ecological\nspecificity, indicating a strong association with cold, highly seasonal\nenvironments, and particular plant communities. Some species appeared acting as\ncommunity \"hubs\", frequently co-occurring with other species, suggesting ties\nto specific environmental or biotic conditions. These findings represent a\nvaluable resource for future research, especially in regions with similar\nenvironmental settings and when prior ecological knowledge exists, also\nunderlining the importance of publicly accessible, high-quality ecological\ndata.", "AI": {"tldr": "\u672c\u6587\u5c06\u5173\u8054\u89c4\u5219\u6316\u6398\u7528\u4e8e\u751f\u6001\u9886\u57df\uff0c\u6574\u5408\u591a\u6e90\u6570\u636e\uff0c\u7528FP-growth\u7b97\u6cd5\u6316\u6398\u690d\u7269\u7269\u79cd\u4e0e\u73af\u5883\u6761\u4ef6\u7684\u89c4\u5219\uff0c\u53d1\u73b0\u4e91\u6749\u4e0e\u7279\u5b9a\u6c14\u5019\u6761\u4ef6\u5f3a\u76f8\u5173\uff0c\u90e8\u5206\u7269\u79cd\u662f\u7fa4\u843d\u2018\u67a2\u7ebd\u2019\uff0c\u7814\u7a76\u6210\u679c\u6709\u91cd\u8981\u4ef7\u503c\u3002", "motivation": "\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u662f\u5168\u7403\u4f18\u5148\u4e8b\u9879\uff0c\u8bc4\u4f30\u68ee\u6797\u7fa4\u843d\u7ec4\u6210\u5bf9\u751f\u6001\u7cfb\u7edf\u529f\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u9700\u4e86\u89e3\u68ee\u6797\u7269\u79cd\u7a7a\u95f4\u5206\u5e03\uff0c\u4f20\u7edf\u5173\u8054\u89c4\u5219\u6316\u6398\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u751f\u6001\u9886\u57df\u6316\u6398\u7269\u79cd\u5173\u7cfb\u3002", "method": "\u5c06\u591a\u6e90\u5f02\u6784\u6570\u636e\u9884\u5904\u7406\u6210\u7edf\u4e00\u6570\u636e\u96c6\uff0c\u4f7f\u7528Frequent Pattern Growth\u7b97\u6cd5\u8fdb\u884c\u5173\u8054\u89c4\u5219\u6316\u6398\u3002", "result": "\u53d1\u73b0\u6e29\u5ea6\u5b63\u8282\u6027650 - 700\u3001\u964d\u6c34\u5b63\u8282\u602745 - 50\u4e0e\u6b27\u6d32\u4e91\u6749\u9ad8\u5ea6\u76f8\u5173\uff0c\u4e91\u6749\u751f\u6001\u7279\u5f02\u6027\u660e\u663e\uff0c\u90e8\u5206\u7269\u79cd\u5e38\u4e0e\u5176\u4ed6\u7269\u79cd\u5171\u5b58\uff0c\u662f\u7fa4\u843d\u2018\u67a2\u7ebd\u2019\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u7c7b\u4f3c\u73af\u5883\u533a\u57df\u548c\u6709\u5148\u9a8c\u751f\u6001\u77e5\u8bc6\u7684\u7814\u7a76\u6709\u4ef7\u503c\uff0c\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u751f\u6001\u6570\u636e\u516c\u5f00\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.06662", "pdf": "https://arxiv.org/pdf/2508.06662", "abs": "https://arxiv.org/abs/2508.06662", "authors": ["Austin Kennedy"], "title": "Fiscal Spillovers through Informal Financial Channels", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper examines fiscal policy spillovers through informal international\nfinancial channels, using the US stimulus checks as a positive, sudden, and\ndirect fiscal shock. I utilize granular, transaction-level cryptocurrency data\ncombined with an algorithm to probabilistically identify cross-border \"crypto\nvehicle\" transactions to construct bilateral cryptocurrency flows between\ncountries. Using a difference-in-differences strategy, I compare cryptocurrency\noutflows between the US and other high-income countries and find a sharp but\ntemporary increase in cryptocurrency outflows as a result of the direct\nstimulus. I quantify the fiscal spillover relative to expenditure and place an\nupper bound of 2.52% through this channel. This implies that fiscal spillovers\nthrough remittance channels are likely modest in size.", "AI": {"tldr": "\u672c\u6587\u4ee5\u7f8e\u56fd\u523a\u6fc0\u652f\u7968\u4e3a\u8d22\u653f\u51b2\u51fb\uff0c\u7528\u52a0\u5bc6\u8d27\u5e01\u6570\u636e\u7814\u7a76\u8d22\u653f\u653f\u7b56\u6ea2\u51fa\uff0c\u53d1\u73b0\u6c47\u6b3e\u6e20\u9053\u8d22\u653f\u6ea2\u51fa\u89c4\u6a21\u53ef\u80fd\u8f83\u5c0f\u3002", "motivation": "\u7814\u7a76\u8d22\u653f\u653f\u7b56\u901a\u8fc7\u975e\u6b63\u5f0f\u56fd\u9645\u91d1\u878d\u6e20\u9053\u7684\u6ea2\u51fa\u6548\u5e94\u3002", "method": "\u5229\u7528\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u6570\u636e\u6784\u5efa\u53cc\u8fb9\u52a0\u5bc6\u8d27\u5e01\u6d41\u52a8\uff0c\u91c7\u7528\u53cc\u91cd\u5dee\u5206\u7b56\u7565\u5bf9\u6bd4\u7f8e\u56fd\u4e0e\u5176\u4ed6\u9ad8\u6536\u5165\u56fd\u5bb6\u7684\u52a0\u5bc6\u8d27\u5e01\u6d41\u51fa\u3002", "result": "\u76f4\u63a5\u523a\u6fc0\u5bfc\u81f4\u52a0\u5bc6\u8d27\u5e01\u6d41\u51fa\u6025\u5267\u4f46\u77ed\u6682\u589e\u52a0\uff0c\u91cf\u5316\u8be5\u6e20\u9053\u8d22\u653f\u6ea2\u51fa\u76f8\u5bf9\u652f\u51fa\u4e0a\u9650\u4e3a2.52%\u3002", "conclusion": "\u6c47\u6b3e\u6e20\u9053\u7684\u8d22\u653f\u6ea2\u51fa\u89c4\u6a21\u53ef\u80fd\u8f83\u5c0f\u3002"}}
{"id": "2508.06914", "pdf": "https://arxiv.org/pdf/2508.06914", "abs": "https://arxiv.org/abs/2508.06914", "authors": ["Ying Peng", "Yifan Zhang", "Xin Wang"], "title": "Prediction of high-frequency futures return directions based on the mean uncertainty classification methods: An application in China's future market", "categories": ["q-fin.TR", "91B82, 68T10,", "I.6.3; J.4"], "comment": "19 pages, 3 figures", "summary": "In this paper, we mainly focus on the prediction of short-term average return\ndirections in China's high-frequency futures market. As minor fluctuations with\nlimited amplitude and short duration are typically regarded as random noise,\nonly price movements of sufficient magnitude qualify as statistically\nsignificant signals. Therefore data imbalance emerges as a key problem during\npredictive modeling. From the view of data distribution imbalance, we employee\nthe mean-uncertainty logistic regression (mean-uncertainty LR) classification\nmethod under the sublinear expectation (SLE) framework, and further propose the\nmean-uncertainty support vector machines (mean-uncertainty SVM) method for the\nprediction. Corresponding investment strategies are developed based on the\nprediction results. For data selection, we utilize trading data and limit order\nbook data of the top 15 liquid products among the most active contracts in\nChina's future market. Empirical results demonstrate that comparing with\nconventional LR-related and SVM-related imbalanced data classification methods,\nthe two mean-uncertainty approaches yields significant advantages in both\nclassification metrics and average returns per trade.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u4e2d\u56fd\u9ad8\u9891\u671f\u8d27\u5e02\u573a\u77ed\u671f\u5e73\u5747\u56de\u62a5\u65b9\u5411\u9884\u6d4b\uff0c\u91c7\u7528\u5747\u503c-\u4e0d\u786e\u5b9a\u6027\u5206\u7c7b\u65b9\u6cd5\uff0c\u7ed3\u5408\u6295\u8d44\u7b56\u7565\uff0c\u5b9e\u8bc1\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4e2d\u56fd\u9ad8\u9891\u671f\u8d27\u5e02\u573a\u9884\u6d4b\u5efa\u6a21\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u5728\u6b21\u7ebf\u6027\u671f\u671b\uff08SLE\uff09\u6846\u67b6\u4e0b\u91c7\u7528\u5747\u503c-\u4e0d\u786e\u5b9a\u6027\u903b\u8f91\u56de\u5f52\uff08mean-uncertainty LR\uff09\u5206\u7c7b\u65b9\u6cd5\uff0c\u8fdb\u4e00\u6b65\u63d0\u51fa\u5747\u503c-\u4e0d\u786e\u5b9a\u6027\u652f\u6301\u5411\u91cf\u673a\uff08mean-uncertainty SVM\uff09\u65b9\u6cd5\uff0c\u57fa\u4e8e\u9884\u6d4b\u7ed3\u679c\u5236\u5b9a\u6295\u8d44\u7b56\u7565\uff0c\u9009\u7528\u4e2d\u56fd\u671f\u8d27\u5e02\u573a\u6d3b\u8dc3\u5408\u7ea6\u4e2d\u524d15\u5927\u6d41\u52a8\u6027\u4ea7\u54c1\u7684\u4ea4\u6613\u6570\u636e\u548c\u9650\u4ef7\u8ba2\u5355\u7c3f\u6570\u636e\u3002", "result": "\u4e0e\u4f20\u7edfLR\u548cSVM\u4e0d\u5e73\u8861\u6570\u636e\u5206\u7c7b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u4e24\u79cd\u5747\u503c-\u4e0d\u786e\u5b9a\u6027\u65b9\u6cd5\u5728\u5206\u7c7b\u6307\u6807\u548c\u6bcf\u7b14\u4ea4\u6613\u5e73\u5747\u56de\u62a5\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u5747\u503c-\u4e0d\u786e\u5b9a\u6027LR\u548cSVM\u65b9\u6cd5\u5728\u89e3\u51b3\u4e2d\u56fd\u9ad8\u9891\u671f\u8d27\u5e02\u573a\u9884\u6d4b\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u4e0a\u6548\u679c\u826f\u597d\uff0c\u80fd\u5e26\u6765\u66f4\u597d\u7684\u5206\u7c7b\u548c\u56de\u62a5\u8868\u73b0\u3002"}}
{"id": "2508.07193", "pdf": "https://arxiv.org/pdf/2508.07193", "abs": "https://arxiv.org/abs/2508.07193", "authors": ["Haoyuan Zhang", "Yaqian Gao", "Xinxin Zhang", "Jialin Li", "Runfeng Jin", "Yidong Chen", "Feng Zhang", "Wu Yuan", "Wenpeng Ma", "Shan Liang", "Jian Zhang", "Zhonghua Lu"], "title": "FlashMP: Fast Discrete Transform-Based Solver for Preconditioning Maxwell's Equations on GPUs", "categories": ["cs.DC"], "comment": null, "summary": "Efficiently solving large-scale linear systems is a critical challenge in\nelectromagnetic simulations, particularly when using the Crank-Nicolson\nFinite-Difference Time-Domain (CN-FDTD) method. Existing iterative solvers are\ncommonly employed to handle the resulting sparse systems but suffer from slow\nconvergence due to the ill-conditioned nature of the double-curl operator.\nApproximate preconditioners, like Successive Over-Relaxation (SOR) and\nIncomplete LU decomposition (ILU), provide insufficient convergence, while\ndirect solvers are impractical due to excessive memory requirements. To address\nthis, we propose FlashMP, a novel preconditioning system that designs a\nsubdomain exact solver based on discrete transforms. FlashMP provides an\nefficient GPU implementation that achieves multi-GPU scalability through domain\ndecomposition. Evaluations on AMD MI60 GPU clusters (up to 1000 GPUs) show that\nFlashMP reduces iteration counts by up to 16x and achieves speedups of 2.5x to\n4.9x compared to baseline implementations in state-of-the-art libraries such as\nHypre. Weak scalability tests show parallel efficiencies up to 84.1%.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u9884\u6761\u4ef6\u7cfb\u7edfFlashMP\u89e3\u51b3\u7535\u78c1\u6a21\u62df\u4e2d\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u95ee\u9898\uff0c\u5728GPU\u96c6\u7fa4\u8bc4\u4f30\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u8fed\u4ee3\u6c42\u89e3\u5668\u6536\u655b\u6162\uff0c\u8fd1\u4f3c\u9884\u6761\u4ef6\u5668\u6536\u655b\u4e0d\u8db3\uff0c\u76f4\u63a5\u6c42\u89e3\u5668\u5185\u5b58\u9700\u6c42\u5927\uff0c\u9700\u9ad8\u6548\u65b9\u6cd5\u89e3\u51b3\u7535\u78c1\u6a21\u62df\u4e2d\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u95ee\u9898\u3002", "method": "\u63d0\u51faFlashMP\uff0c\u57fa\u4e8e\u79bb\u6563\u53d8\u6362\u8bbe\u8ba1\u5b50\u57df\u7cbe\u786e\u6c42\u89e3\u5668\uff0c\u5b9e\u73b0\u9ad8\u6548GPU\u7248\u672c\u5e76\u901a\u8fc7\u57df\u5206\u89e3\u5b9e\u73b0\u591aGPU\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728AMD MI60 GPU\u96c6\u7fa4\u8bc4\u4f30\uff0c\u8fed\u4ee3\u6b21\u6570\u6700\u591a\u51cf\u5c1116\u500d\uff0c\u52a0\u901f\u6bd42.5 - 4.9\u500d\uff0c\u5f31\u53ef\u6269\u5c55\u6027\u6d4b\u8bd5\u5e76\u884c\u6548\u7387\u8fbe84.1%\u3002", "conclusion": "FlashMP\u80fd\u6709\u6548\u89e3\u51b3\u7535\u78c1\u6a21\u62df\u4e2d\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u95ee\u9898\uff0c\u63d0\u5347\u6c42\u89e3\u6548\u7387\u3002"}}
{"id": "2508.06841", "pdf": "https://arxiv.org/pdf/2508.06841", "abs": "https://arxiv.org/abs/2508.06841", "authors": ["Yiwei Li", "Zhihua Allen-Zhao", "Yuncheng Xu", "Sanyang Liu"], "title": "Memory Enhanced Fractional-Order Dung Beetle Optimization for Photovoltaic Parameter Identification", "categories": ["cs.NE"], "comment": null, "summary": "Accurate parameter identification in photovoltaic (PV) models is crucial for\nperformance evaluation but remains challenging due to their nonlinear,\nmultimodal, and high-dimensional nature. Although the Dung Beetle Optimization\n(DBO) algorithm has shown potential in addressing such problems, it often\nsuffers from premature convergence. To overcome these issues, this paper\nproposes a Memory Enhanced Fractional-Order Dung Beetle Optimization (MFO-DBO)\nalgorithm that integrates three coordinated strategies. Firstly,\nfractional-order (FO) calculus introduces memory into the search process,\nenhancing convergence stability and solution quality. Secondly, a\nfractional-order logistic chaotic map improves population diversity during\ninitialization. Thirdly, a chaotic perturbation mechanism helps elite solutions\nescape local optima. Numerical results on the CEC2017 benchmark suite and the\nPV parameter identification problem demonstrate that MFO-DBO consistently\noutperforms advanced DBO variants, CEC competition winners, FO-based\noptimizers, enhanced classical algorithms, and recent metaheuristics in terms\nof accuracy, robustness, convergence speed, while also maintaining an excellent\nbalance between exploration and exploitation compared to the standard DBO\nalgorithm.", "AI": {"tldr": "\u63d0\u51faMFO - DBO\u7b97\u6cd5\u89e3\u51b3\u5149\u4f0f\u6a21\u578b\u53c2\u6570\u8bc6\u522b\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u591a\u79cd\u7b97\u6cd5\u3002", "motivation": "\u5149\u4f0f\u6a21\u578b\u53c2\u6570\u51c6\u786e\u8bc6\u522b\u5177\u6709\u6311\u6218\u6027\uff0c\u539fDBO\u7b97\u6cd5\u6613\u65e9\u719f\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faMFO - DBO\u7b97\u6cd5\uff0c\u6574\u5408\u5206\u6570\u9636\u5fae\u79ef\u5206\u3001\u5206\u6570\u9636\u903b\u8f91\u6df7\u6c8c\u6620\u5c04\u548c\u6df7\u6c8c\u6270\u52a8\u673a\u5236\u4e09\u4e2a\u7b56\u7565\u3002", "result": "\u5728CEC2017\u57fa\u51c6\u5957\u4ef6\u548c\u5149\u4f0f\u53c2\u6570\u8bc6\u522b\u95ee\u9898\u4e0a\uff0cMFO - DBO\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u3001\u6536\u655b\u901f\u5ea6\u7b49\u65b9\u9762\u4f18\u4e8e\u591a\u79cd\u7b97\u6cd5\u3002", "conclusion": "MFO - DBO\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5149\u4f0f\u6a21\u578b\u53c2\u6570\u8bc6\u522b\u95ee\u9898\uff0c\u4e14\u5728\u63a2\u7d22\u4e0e\u5f00\u53d1\u95f4\u4fdd\u6301\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2508.06571", "pdf": "https://arxiv.org/pdf/2508.06571", "abs": "https://arxiv.org/abs/2508.06571", "authors": ["Anqing Jiang", "Yu Gao", "Yiru Wang", "Zhigang Sun", "Shuo Wang", "Yuwen Heng", "Hao Sun", "Shichen Tang", "Lijuan Zhu", "Jinhao Chai", "Jijun Wang", "Zichong Gu", "Hao Jiang", "Li Sun"], "title": "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model", "categories": ["cs.AI", "cs.CV", "cs.RO"], "comment": "9 pagres, 2 figures", "summary": "Vision-Language-Action (VLA) models have demonstrated potential in autonomous\ndriving. However, two critical challenges hinder their development: (1)\nExisting VLA architectures are typically based on imitation learning in\nopen-loop setup which tends to capture the recorded behaviors in the dataset,\nleading to suboptimal and constrained performance, (2) Close-loop training\nrelies heavily on high-fidelity sensor simulation, where domain gaps and\ncomputational inefficiencies pose significant barriers. In this paper, we\nintroduce IRL-VLA, a novel close-loop Reinforcement Learning via\n\\textbf{I}nverse \\textbf{R}einforcement \\textbf{L}earning reward world model\nwith a self-built VLA approach. Our framework proceeds in a three-stage\nparadigm: In the first stage, we propose a VLA architecture and pretrain the\nVLA policy via imitation learning. In the second stage, we construct a\nlightweight reward world model via inverse reinforcement learning to enable\nefficient close-loop reward computation. To further enhance planning\nperformance, finally, we design specialized reward world model guidence\nreinforcement learning via PPO(Proximal Policy Optimization) to effectively\nbalance the safety incidents, comfortable driving, and traffic efficiency. Our\napproach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving\nbenchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that\nour framework will accelerate VLA research in close-loop autonomous driving.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u53d1\u5c55\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u51faIRL - VLA\u6846\u67b6\uff0c\u7ecf\u4e09\u9636\u6bb5\u8bad\u7ec3\uff0c\u5728\u76f8\u5173\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\uff0c\u6709\u671b\u52a0\u901f\u95ed\u73af\u81ea\u52a8\u9a7e\u9a76\u7684VLA\u7814\u7a76\u3002", "motivation": "\u73b0\u6709VLA\u67b6\u6784\u57fa\u4e8e\u5f00\u73af\u6a21\u4eff\u5b66\u4e60\u6027\u80fd\u6b20\u4f73\uff0c\u95ed\u73af\u8bad\u7ec3\u4f9d\u8d56\u9ad8\u4fdd\u771f\u4f20\u611f\u5668\u6a21\u62df\uff0c\u5b58\u5728\u9886\u57df\u5dee\u8ddd\u548c\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u963b\u788dVLA\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51faIRL - VLA\u6846\u67b6\uff0c\u5206\u4e09\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u63d0\u51faVLA\u67b6\u6784\u5e76\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\u9884\u8bad\u7ec3VLA\u7b56\u7565\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u9006\u5f3a\u5316\u5b66\u4e60\u6784\u5efa\u8f7b\u91cf\u7ea7\u5956\u52b1\u4e16\u754c\u6a21\u578b\u4ee5\u5b9e\u73b0\u9ad8\u6548\u95ed\u73af\u5956\u52b1\u8ba1\u7b97\uff1b\u7b2c\u4e09\u9636\u6bb5\u901a\u8fc7PPO\u8bbe\u8ba1\u4e13\u95e8\u7684\u5956\u52b1\u4e16\u754c\u6a21\u578b\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\uff0c\u5e73\u8861\u5b89\u5168\u3001\u8212\u9002\u9a7e\u9a76\u548c\u4ea4\u901a\u6548\u7387\u3002", "result": "\u5728NAVSIM v2\u7aef\u5230\u7aef\u9a7e\u9a76\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728CVPR2025\u81ea\u52a8\u9a7e\u9a76\u5927\u6311\u6218\u4e2d\u83b7\u5f97\u4e9a\u519b\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u671b\u52a0\u901f\u95ed\u73af\u81ea\u52a8\u9a7e\u9a76\u7684VLA\u7814\u7a76\u3002"}}
{"id": "2508.07084", "pdf": "https://arxiv.org/pdf/2508.07084", "abs": "https://arxiv.org/abs/2508.07084", "authors": ["Kaveh Shahedi", "Nana Gyambrah", "Heng Li", "Maxime Lamothe", "Foutse Khomh"], "title": "An Empirical Study on Method-Level Performance Evolution in Open-Source Java Projects", "categories": ["cs.SE", "cs.PF"], "comment": null, "summary": "Performance is a critical quality attribute in software development, yet the\nimpact of method-level code changes on performance evolution remains poorly\nunderstood. While developers often make intuitive assumptions about which types\nof modifications are likely to cause performance regressions or improvements,\nthese beliefs lack empirical validation at a fine-grained level. We conducted a\nlarge-scale empirical study analyzing performance evolution in 15 mature\nopen-source Java projects hosted on GitHub. Our analysis encompassed 739\ncommits containing 1,499 method-level code changes, using Java Microbenchmark\nHarness (JMH) for precise performance measurement and rigorous statistical\nanalysis to quantify both the significance and magnitude of performance\nvariations. We employed bytecode instrumentation to capture method-specific\nexecution metrics and systematically analyzed four key aspects: temporal\nperformance patterns, code change type correlations, developer and complexity\nfactors, and domain-size interactions. Our findings reveal that 32.7% of\nmethod-level changes result in measurable performance impacts, with regressions\noccurring 1.3 times more frequently than improvements. Contrary to conventional\nwisdom, we found no significant differences in performance impact distributions\nacross code change categories, challenging risk-stratified development\nstrategies. Algorithmic changes demonstrate the highest improvement potential\nbut carry substantial regression risk. Senior developers produce more stable\nchanges with fewer extreme variations, while code complexity correlates with\nincreased regression likelihood. Domain-size interactions reveal significant\npatterns, with web server + small projects exhibiting the highest performance\ninstability. Our study provides empirical evidence for integrating automated\nperformance testing into continuous integration pipelines.", "AI": {"tldr": "\u5bf915\u4e2aJava\u5f00\u6e90\u9879\u76ee739\u6b21\u63d0\u4ea4\u4e2d1499\u4e2a\u65b9\u6cd5\u7ea7\u4ee3\u7801\u53d8\u66f4\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b032.7%\u53d8\u66f4\u6709\u6027\u80fd\u5f71\u54cd\uff0c\u56de\u5f52\u6bd4\u6539\u8fdb\u591a1.3\u500d\u7b49\uff0c\u4e3a\u81ea\u52a8\u5316\u6027\u80fd\u6d4b\u8bd5\u878d\u5165\u6301\u7eed\u96c6\u6210\u7ba1\u9053\u63d0\u4f9b\u5b9e\u8bc1\u3002", "motivation": "\u5f53\u524d\u5bf9\u65b9\u6cd5\u7ea7\u4ee3\u7801\u53d8\u66f4\u5bf9\u6027\u80fd\u6f14\u53d8\u7684\u5f71\u54cd\u4e86\u89e3\u4e0d\u8db3\uff0c\u5f00\u53d1\u8005\u76f8\u5173\u76f4\u89c9\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "method": "\u5206\u679015\u4e2a\u6210\u719fJava\u5f00\u6e90\u9879\u76ee\uff0c\u7528JMH\u7cbe\u786e\u6d4b\u91cf\u6027\u80fd\uff0c\u7528\u7edf\u8ba1\u5206\u6790\u91cf\u5316\u6027\u80fd\u53d8\u5316\uff0c\u91c7\u7528\u5b57\u8282\u7801\u63d2\u6869\u6355\u83b7\u6267\u884c\u6307\u6807\uff0c\u5206\u6790\u56db\u4e2a\u5173\u952e\u65b9\u9762\u3002", "result": "32.7%\u65b9\u6cd5\u7ea7\u53d8\u66f4\u6709\u6027\u80fd\u5f71\u54cd\uff0c\u56de\u5f52\u6bd4\u6539\u8fdb\u591a1.3\u500d\uff1b\u5404\u4ee3\u7801\u53d8\u66f4\u7c7b\u522b\u6027\u80fd\u5f71\u54cd\u5206\u5e03\u65e0\u663e\u8457\u5dee\u5f02\uff1b\u7b97\u6cd5\u53d8\u66f4\u6539\u8fdb\u6f5c\u529b\u5927\u4f46\u56de\u5f52\u98ce\u9669\u9ad8\uff1b\u9ad8\u7ea7\u5f00\u53d1\u8005\u53d8\u66f4\u66f4\u7a33\u5b9a\uff1b\u4ee3\u7801\u590d\u6742\u5ea6\u4e0e\u56de\u5f52\u53ef\u80fd\u6027\u6b63\u76f8\u5173\uff1b\u4e0d\u540c\u9886\u57df\u89c4\u6a21\u7ec4\u5408\u6709\u4e0d\u540c\u6027\u80fd\u7a33\u5b9a\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5c06\u81ea\u52a8\u5316\u6027\u80fd\u6d4b\u8bd5\u96c6\u6210\u5230\u6301\u7eed\u96c6\u6210\u7ba1\u9053\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2508.06619", "pdf": "https://arxiv.org/pdf/2508.06619", "abs": "https://arxiv.org/abs/2508.06619", "authors": ["Kiran Rokade", "Adit Jain", "Francesca Parise", "Vikram Krishnamurthy", "Eva Tardos"], "title": "Asymmetric Network Games: $\u03b1$-Potential Function and Learning", "categories": ["cs.GT", "cs.MA", "cs.SI", "cs.SY", "eess.SY"], "comment": null, "summary": "In a network game, players interact over a network and the utility of each\nplayer depends on his own action and on an aggregate of his neighbours'\nactions. Many real world networks of interest are asymmetric and involve a\nlarge number of heterogeneous players. This paper analyzes static network games\nusing the framework of $\\alpha$-potential games. Under mild assumptions on the\naction sets (compact intervals) and the utility functions (twice continuously\ndifferentiable) of the players, we derive an expression for an inexact\npotential function of the game, called the $\\alpha$-potential function. Using\nsuch a function, we show that modified versions of the sequential best-response\nalgorithm and the simultaneous gradient play algorithm achieve convergence of\nplayers' actions to a $2\\alpha$-Nash equilibrium. For linear-quadratic network\ngames, we show that $\\alpha$ depends on the maximum asymmetry in the network\nand is well-behaved for a wide range of networks of practical interest.\nFurther, we derive bounds on the social welfare of the $\\alpha$-Nash\nequilibrium corresponding to the maximum of the $\\alpha$-potential function,\nunder suitable assumptions. We numerically illustrate the convergence of the\nproposed algorithms and properties of the learned $2\\alpha$-Nash equilibria.", "AI": {"tldr": "\u672c\u6587\u7528\u03b1 - \u52bf\u535a\u5f08\u6846\u67b6\u5206\u6790\u9759\u6001\u7f51\u7edc\u535a\u5f08\uff0c\u63a8\u5bfc\u03b1 - \u52bf\u51fd\u6570\uff0c\u8bc1\u660e\u7b97\u6cd5\u6536\u655b\u52302\u03b1 - \u7eb3\u4ec0\u5747\u8861\uff0c\u7ed9\u51fa\u03b1\u53d6\u503c\u53ca\u793e\u4f1a\u798f\u5229\u8fb9\u754c\u5e76\u8fdb\u884c\u6570\u503c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u5f88\u591a\u7f51\u7edc\u4e0d\u5bf9\u79f0\u4e14\u73a9\u5bb6\u5f02\u8d28\uff0c\u9700\u5206\u6790\u9759\u6001\u7f51\u7edc\u535a\u5f08\u3002", "method": "\u8fd0\u7528\u03b1 - \u52bf\u535a\u5f08\u6846\u67b6\uff0c\u5728\u73a9\u5bb6\u884c\u52a8\u96c6\u548c\u6548\u7528\u51fd\u6570\u7684\u6e29\u548c\u5047\u8bbe\u4e0b\u63a8\u5bfc\u03b1 - \u52bf\u51fd\u6570\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u5e8f\u8d2f\u6700\u4f18\u54cd\u5e94\u7b97\u6cd5\u548c\u540c\u6b65\u68af\u5ea6\u535a\u5f08\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u80fd\u4f7f\u73a9\u5bb6\u884c\u52a8\u6536\u655b\u52302\u03b1 - \u7eb3\u4ec0\u5747\u8861\uff0c\u03b1\u4e0e\u7f51\u7edc\u6700\u5927\u4e0d\u5bf9\u79f0\u6027\u6709\u5173\uff0c\u63a8\u5bfc\u4e86\u03b1 - \u7eb3\u4ec0\u5747\u8861\u793e\u4f1a\u798f\u5229\u8fb9\u754c\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u6536\u655b\uff0c\u5b66\u4e60\u5230\u76842\u03b1 - \u7eb3\u4ec0\u5747\u8861\u6709\u76f8\u5e94\u6027\u8d28\u3002"}}
{"id": "2508.06970", "pdf": "https://arxiv.org/pdf/2508.06970", "abs": "https://arxiv.org/abs/2508.06970", "authors": ["Sergei Makeev", "Alexandr Andreev", "Vladimir Baikalov", "Vladislav Tytskiy", "Aleksei Krasilnikov", "Kirill Khrylchenko"], "title": "Blending Sequential Embeddings, Graphs, and Engineered Features: 4th Place Solution in RecSys Challenge 2025", "categories": ["cs.IR"], "comment": null, "summary": "This paper describes the 4th-place solution by team ambitious for the RecSys\nChallenge 2025, organized by Synerise and ACM RecSys, which focused on\nuniversal behavioral modeling. The challenge objective was to generate user\nembeddings effective across six diverse downstream tasks. Our solution\nintegrates (1) a sequential encoder to capture the temporal evolution of user\ninterests, (2) a graph neural network to enhance generalization, (3) a deep\ncross network to model high-order feature interactions, and (4)\nperformance-critical feature engineering.", "AI": {"tldr": "\u4ecb\u7ecd\u56e2\u961fambitious\u5728RecSys Challenge 2025\u4e2d\u7684\u7b2c4\u540d\u89e3\u51b3\u65b9\u6848\uff0c\u805a\u7126\u901a\u7528\u884c\u4e3a\u5efa\u6a21\u3002", "motivation": "\u53c2\u52a0\u7531Synerise\u548cACM RecSys\u7ec4\u7ec7\u7684RecSys Challenge 2025\uff0c\u76ee\u6807\u662f\u751f\u6210\u5728\u516d\u4e2a\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u6709\u6548\u7684\u7528\u6237\u5d4c\u5165\u3002", "method": "\u96c6\u6210\u987a\u5e8f\u7f16\u7801\u5668\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u6df1\u5ea6\u4ea4\u53c9\u7f51\u7edc\u548c\u5173\u952e\u6027\u80fd\u7279\u5f81\u5de5\u7a0b\u3002", "result": "\u83b7\u5f97\u6bd4\u8d5b\u7b2c4\u540d\u3002", "conclusion": "\u8be5\u96c6\u6210\u65b9\u6cd5\u5728\u901a\u7528\u884c\u4e3a\u5efa\u6a21\u6bd4\u8d5b\u4e2d\u53d6\u5f97\u8f83\u597d\u6210\u7ee9\u3002"}}
{"id": "2508.06809", "pdf": "https://arxiv.org/pdf/2508.06809", "abs": "https://arxiv.org/abs/2508.06809", "authors": ["Qiming Cui", "Michael Dinitz"], "title": "Controlling tail risk in two-slope ski rental", "categories": ["cs.DS"], "comment": "This paper will appear at WAOA 2025", "summary": "We study the optimal solution to a general two-slope ski rental problem with\na tail risk, i.e., the chance of the competitive ratio exceeding a value\n$\\gamma$ is bounded by $\\delta$. This extends the recent study of tail bounds\nfor ski rental by [Dinitz et al. SODA 2024] to the two-slope version defined by\n[Lotker et al. IPL 2008]. In this version, even after \"buying,\" we must still\npay a rental cost at each time step, though it is lower after buying. This\nmodels many real-world \"rent-or-buy\" scenarios where a one-time investment\ndecreases (but does not eliminate) the per-time cost.\n  Despite this being a simple extension of the classical problem, we find that\nadding tail risk bounds creates a fundamentally different solution structure.\nFor example, in our setting there is a possibility that we never buy in an\noptimal solution (which can also occur without tail bounds), but more strangely\n(and unlike the case without tail bounds or the classical case with tail\nbounds) we also show that the optimal solution might need to have nontrivial\nprobabilities of buying even at finite points beyond the time corresponding to\nthe buying cost. Moreover, in many regimes there does not exist a unique\noptimal solution. As our first contribution, we develop a series of structure\ntheorems to characterize some features of optimal solutions.\n  The complex structure of optimal solutions makes it more difficult to develop\nan algorithm to compute such a solution. As our second contribution, we utilize\nour structure theorems to design two algorithms: one based on a greedy\nalgorithm combined with binary search that is fast but yields arbitrarily close\nto optimal solutions, and a slower algorithm based on linear programming which\ncomputes exact optimal solutions.", "AI": {"tldr": "\u7814\u7a76\u5e26\u5c3e\u98ce\u9669\u7684\u4e24\u659c\u7387\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u6700\u4f18\u89e3\uff0c\u7ed9\u51fa\u7ed3\u6784\u5b9a\u7406\u5e76\u8bbe\u8ba1\u7b97\u6cd5\u8ba1\u7b97\u89e3\u3002", "motivation": "\u5c06\u5e26\u5c3e\u754c\u7684\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u7814\u7a76\u62d3\u5c55\u5230\u4e24\u659c\u7387\u7248\u672c\uff0c\u8be5\u7248\u672c\u66f4\u8d34\u5408\u73b0\u5b9e\u573a\u666f\u3002", "method": "\u5148\u63a8\u5bfc\u4e00\u7cfb\u5217\u7ed3\u6784\u5b9a\u7406\u523b\u753b\u6700\u4f18\u89e3\u7279\u5f81\uff0c\u518d\u5229\u7528\u5b9a\u7406\u8bbe\u8ba1\u8d2a\u5a6a\u7ed3\u5408\u4e8c\u5206\u67e5\u627e\u7684\u5feb\u901f\u8fd1\u4f3c\u7b97\u6cd5\u548c\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u7cbe\u786e\u7b97\u6cd5\u3002", "result": "\u53d1\u73b0\u6dfb\u52a0\u5c3e\u98ce\u9669\u754c\u540e\u89e3\u7ed3\u6784\u4e0d\u540c\uff0c\u5f88\u591a\u60c5\u51b5\u4e0b\u65e0\u552f\u4e00\u6700\u4f18\u89e3\uff0c\u8bbe\u8ba1\u4e86\u4e24\u79cd\u7b97\u6cd5\u8ba1\u7b97\u89e3\u3002", "conclusion": "\u5bf9\u5e26\u5c3e\u98ce\u9669\u7684\u4e24\u659c\u7387\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u6709\u6df1\u5165\u7814\u7a76\uff0c\u7ed3\u6784\u5b9a\u7406\u548c\u7b97\u6cd5\u4e3a\u89e3\u51b3\u8be5\u95ee\u9898\u63d0\u4f9b\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.06888", "pdf": "https://arxiv.org/pdf/2508.06888", "abs": "https://arxiv.org/abs/2508.06888", "authors": ["Fanyu Wang", "Chetan Arora", "Yonghui Liu", "Kaicheng Huang", "Chakkrit Tantithamthavorn", "Aldeida Aleti", "Dishan Sambathkumar", "David Lo"], "title": "Multi-Modal Requirements Data-based Acceptance Criteria Generation using LLMs", "categories": ["cs.SE"], "comment": null, "summary": "Acceptance criteria (ACs) play a critical role in software development by\nclearly defining the conditions under which a software feature satisfies\nstakeholder expectations. However, manually creating accurate, comprehensive,\nand unambiguous acceptance criteria is challenging, particularly in user\ninterface-intensive applications, due to the reliance on domain-specific\nknowledge and visual context that is not always captured by textual\nrequirements alone. To address these challenges, we propose RAGcceptance M2RE,\na novel approach that leverages Retrieval-Augmented Generation (RAG) to\ngenerate acceptance criteria from multi-modal requirements data, including both\ntextual documentation and visual UI information. We systematically evaluated\nour approach in an industrial case study involving an education-focused\nsoftware system used by approximately 100,000 users. The results indicate that\nintegrating multi-modal information significantly enhances the relevance,\ncorrectness, and comprehensibility of the generated ACs. Moreover, practitioner\nevaluations confirm that our approach effectively reduces manual effort,\ncaptures nuanced stakeholder intent, and provides valuable criteria that domain\nexperts may overlook, demonstrating practical utility and significant potential\nfor industry adoption. This research underscores the potential of multi-modal\nRAG techniques in streamlining software validation processes and improving\ndevelopment efficiency. We also make our implementation and a dataset\navailable.", "AI": {"tldr": "\u63d0\u51faRAGcceptance M2RE\u65b9\u6cd5\u7528\u591a\u6a21\u6001\u6570\u636e\u751f\u6210\u8f6f\u4ef6\u9a8c\u6536\u6807\u51c6\uff0c\u5de5\u4e1a\u6848\u4f8b\u9a8c\u8bc1\u5176\u63d0\u5347\u6807\u51c6\u8d28\u91cf\u3001\u51cf\u5c11\u4eba\u5de5\uff0c\u51f8\u663e\u591a\u6a21\u6001RAG\u6280\u672f\u6f5c\u529b\u3002", "motivation": "\u624b\u52a8\u521b\u5efa\u51c6\u786e\u3001\u5168\u9762\u4e14\u660e\u786e\u7684\u8f6f\u4ef6\u9a8c\u6536\u6807\u51c6\u5177\u6709\u6311\u6218\u6027\uff0c\u5c24\u5176\u662f\u5728\u7528\u6237\u754c\u9762\u5bc6\u96c6\u578b\u5e94\u7528\u4e2d\uff0c\u9700\u7ed3\u5408\u591a\u6a21\u6001\u6570\u636e\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u63d0\u51faRAGcceptance M2RE\u65b9\u6cd5\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4ece\u591a\u6a21\u6001\u9700\u6c42\u6570\u636e\uff08\u5305\u62ec\u6587\u672c\u548c\u89c6\u89c9UI\u4fe1\u606f\uff09\u751f\u6210\u9a8c\u6536\u6807\u51c6\u3002", "result": "\u5de5\u4e1a\u6848\u4f8b\u8868\u660e\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u589e\u5f3a\u4e86\u751f\u6210\u7684\u9a8c\u6536\u6807\u51c6\u7684\u76f8\u5173\u6027\u3001\u6b63\u786e\u6027\u548c\u53ef\u7406\u89e3\u6027\uff0c\u5b9e\u8df5\u8bc4\u4f30\u786e\u8ba4\u8be5\u65b9\u6cd5\u51cf\u5c11\u4eba\u5de5\u3001\u6355\u6349\u5229\u76ca\u76f8\u5173\u8005\u610f\u56fe\u3002", "conclusion": "\u591a\u6a21\u6001RAG\u6280\u672f\u5728\u7b80\u5316\u8f6f\u4ef6\u9a8c\u8bc1\u6d41\u7a0b\u548c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u5b9e\u73b0\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2508.06576", "pdf": "https://arxiv.org/pdf/2508.06576", "abs": "https://arxiv.org/abs/2508.06576", "authors": ["Azmine Toushik Wasi"], "title": "GFlowNets for Learning Better Drug-Drug Interaction Representations", "categories": ["cs.LG", "q-bio.BM", "q-bio.MN"], "comment": "Accepted to ICANN 2025:AIDD", "summary": "Drug-drug interactions pose a significant challenge in clinical pharmacology,\nwith severe class imbalance among interaction types limiting the effectiveness\nof predictive models. Common interactions dominate datasets, while rare but\ncritical interactions remain underrepresented, leading to poor model\nperformance on infrequent cases. Existing methods often treat DDI prediction as\na binary problem, ignoring class-specific nuances and exacerbating bias toward\nfrequent interactions. To address this, we propose a framework combining\nGenerative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE)\nto generate synthetic samples for rare classes, improving model balance and\ngenerate effective and novel DDI pairs. Our approach enhances predictive\nperformance across interaction types, ensuring better clinical reliability.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408GFlowNet\u4e0eVGAE\u7684\u6846\u67b6\u89e3\u51b3\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u4e2d\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u5b58\u5728\u7c7b\u522b\u4e25\u91cd\u4e0d\u5e73\u8861\uff0c\u73b0\u6709\u65b9\u6cd5\u5c06\u5176\u4f5c\u4e3a\u4e8c\u5143\u95ee\u9898\u5904\u7406\uff0c\u5bfc\u81f4\u5bf9\u7f55\u89c1\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u6027\u80fd\u5dee\u3002", "method": "\u63d0\u51fa\u7ed3\u5408Generative Flow Networks (GFlowNet)\u4e0eVariational Graph Autoencoders (VGAE)\u7684\u6846\u67b6\uff0c\u4e3a\u7f55\u89c1\u7c7b\u522b\u751f\u6210\u5408\u6210\u6837\u672c\u3002", "result": "\u589e\u5f3a\u4e86\u5404\u76f8\u4e92\u4f5c\u7528\u7c7b\u578b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6539\u5584\u6a21\u578b\u5e73\u8861\uff0c\u751f\u6210\u6709\u6548\u7684\u65b0\u578b\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u5bf9\uff0c\u786e\u4fdd\u66f4\u597d\u7684\u4e34\u5e8a\u53ef\u9760\u6027\u3002"}}
{"id": "2508.02759", "pdf": "https://arxiv.org/pdf/2508.02759", "abs": "https://arxiv.org/abs/2508.02759", "authors": ["Eduardo Abi Jaber", "Louis-Amand G\u00e9rard"], "title": "Hedging with memory: shallow and deep learning with signatures", "categories": ["stat.ML", "cs.LG", "q-fin.CP", "q-fin.MF", "60L10, 91G20, 91G60"], "comment": null, "summary": "We investigate the use of path signatures in a machine learning context for\nhedging exotic derivatives under non-Markovian stochastic volatility models. In\na deep learning setting, we use signatures as features in feedforward neural\nnetworks and show that they outperform LSTMs in most cases, with orders of\nmagnitude less training compute. In a shallow learning setting, we compare two\nregression approaches: the first directly learns the hedging strategy from the\nexpected signature of the price process; the second models the dynamics of\nvolatility using a signature volatility model, calibrated on the expected\nsignature of the volatility. Solving the hedging problem in the calibrated\nsignature volatility model yields more accurate and stable results across\ndifferent payoffs and volatility dynamics.", "AI": {"tldr": "\u7814\u7a76\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u6ce2\u52a8\u7387\u6a21\u578b\u4e0b\uff0c\u8def\u5f84\u7b7e\u540d\u5728\u5bf9\u51b2\u5947\u5f02\u884d\u751f\u54c1\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7b7e\u540d\u7279\u5f81\u4f18\u4e8eLSTM\uff0c\u6d45\u5ea6\u5b66\u4e60\u4e2d\u7279\u5b9a\u65b9\u6cd5\u7ed3\u679c\u66f4\u4f18\u3002", "motivation": "\u63a2\u7a76\u8def\u5f84\u7b7e\u540d\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u6ce2\u52a8\u7387\u6a21\u578b\u4e0b\u5bf9\u51b2\u5947\u5f02\u884d\u751f\u54c1\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u3002", "method": "\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7528\u7b7e\u540d\u4f5c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\uff1b\u6d45\u5ea6\u5b66\u4e60\u4e2d\u6bd4\u8f83\u4e24\u79cd\u56de\u5f52\u65b9\u6cd5\uff0c\u4e00\u662f\u4ece\u4ef7\u683c\u8fc7\u7a0b\u671f\u671b\u7b7e\u540d\u76f4\u63a5\u5b66\u4e60\u5bf9\u51b2\u7b56\u7565\uff0c\u4e8c\u662f\u7528\u7b7e\u540d\u6ce2\u52a8\u7387\u6a21\u578b\u5efa\u6a21\u6ce2\u52a8\u7387\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7b7e\u540d\u7279\u5f81\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8eLSTM\uff0c\u8bad\u7ec3\u8ba1\u7b97\u91cf\u5c0f\uff1b\u6d45\u5ea6\u5b66\u4e60\u4e2d\u7528\u7b7e\u540d\u6ce2\u52a8\u7387\u6a21\u578b\u89e3\u51b3\u5bf9\u51b2\u95ee\u9898\u7ed3\u679c\u66f4\u51c6\u786e\u7a33\u5b9a\u3002", "conclusion": "\u8def\u5f84\u7b7e\u540d\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u6ce2\u52a8\u7387\u6a21\u578b\u4e0b\u5bf9\u51b2\u5947\u5f02\u884d\u751f\u54c1\u6709\u826f\u597d\u6548\u679c\uff0c\u7279\u5b9a\u65b9\u6cd5\u4f18\u52bf\u660e\u663e\u3002"}}
{"id": "2508.07049", "pdf": "https://arxiv.org/pdf/2508.07049", "abs": "https://arxiv.org/abs/2508.07049", "authors": ["Tran Tuan Kiet", "Nguyen Thang Loi", "Vo Nguyen Le Duy"], "title": "Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Anomaly detection (AD) plays a vital role across a wide range of domains, but\nits performance might deteriorate when applied to target domains with limited\ndata. Domain Adaptation (DA) offers a solution by transferring knowledge from a\nrelated source domain with abundant data. However, this adaptation process can\nintroduce additional uncertainty, making it difficult to draw statistically\nvalid conclusions from AD results. In this paper, we propose STAND-DA -- a\nnovel framework for statistically rigorous Autoencoder-based AD after\nRepresentation Learning-based DA. Built on the Selective Inference (SI)\nframework, STAND-DA computes valid $p$-values for detected anomalies and\nrigorously controls the false positive rate below a pre-specified level\n$\\alpha$ (e.g., 0.05). To address the computational challenges of applying SI\nto deep learning models, we develop the GPU-accelerated SI implementation,\nsignificantly enhancing both scalability and runtime performance. This\nadvancement makes SI practically feasible for modern, large-scale deep\narchitectures. Extensive experiments on synthetic and real-world datasets\nvalidate the theoretical results and computational efficiency of the proposed\nSTAND-DA method.", "AI": {"tldr": "\u63d0\u51fa STAND - DA \u6846\u67b6\u7528\u4e8e\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u9886\u57df\u9002\u5e94\u540e\u8fdb\u884c\u7edf\u8ba1\u4e25\u8c28\u7684\u57fa\u4e8e\u81ea\u7f16\u7801\u5668\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u5f00\u53d1 GPU \u52a0\u901f\u7684\u9009\u62e9\u6027\u63a8\u7406\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u7406\u8bba\u7ed3\u679c\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5f02\u5e38\u68c0\u6d4b\u5728\u76ee\u6807\u6570\u636e\u6709\u9650\u7684\u9886\u57df\u6027\u80fd\u53ef\u80fd\u4e0b\u964d\uff0c\u9886\u57df\u9002\u5e94\u867d\u80fd\u8f6c\u79fb\u77e5\u8bc6\u4f46\u4f1a\u5f15\u5165\u989d\u5916\u4e0d\u786e\u5b9a\u6027\uff0c\u96be\u4ee5\u4ece\u68c0\u6d4b\u7ed3\u679c\u5f97\u51fa\u7edf\u8ba1\u6709\u6548\u7ed3\u8bba\u3002", "method": "\u63d0\u51fa STAND - DA \u6846\u67b6\uff0c\u57fa\u4e8e\u9009\u62e9\u6027\u63a8\u7406\u6846\u67b6\u8ba1\u7b97\u6709\u6548 p \u503c\u5e76\u63a7\u5236\u8bef\u62a5\u7387\uff0c\u5f00\u53d1 GPU \u52a0\u901f\u7684\u9009\u62e9\u6027\u63a8\u7406\u5b9e\u73b0\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86 STAND - DA \u65b9\u6cd5\u7684\u7406\u8bba\u7ed3\u679c\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "STAND - DA \u65b9\u6cd5\u5728\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u9886\u57df\u9002\u5e94\u540e\u7684\u5f02\u5e38\u68c0\u6d4b\u4e2d\u662f\u6709\u6548\u7684\uff0cGPU \u52a0\u901f\u5b9e\u73b0\u4f7f\u9009\u62e9\u6027\u63a8\u7406\u5728\u73b0\u4ee3\u5927\u89c4\u6a21\u6df1\u5ea6\u67b6\u6784\u4e2d\u5207\u5b9e\u53ef\u884c\u3002"}}
{"id": "2508.07044", "pdf": "https://arxiv.org/pdf/2508.07044", "abs": "https://arxiv.org/abs/2508.07044", "authors": ["William Zerong Wang", "Dongfang Zhao"], "title": "Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption", "categories": ["cs.DB", "cs.AI", "cs.CR"], "comment": null, "summary": "In the era of generative AI, ensuring the privacy of music data presents\nunique challenges: unlike static artworks such as images, music data is\ninherently temporal and multimodal, and it is sampled, transformed, and remixed\nat an unprecedented scale. These characteristics make its core vector\nembeddings, i.e, the numerical representations of the music, highly susceptible\nto being learned, misused, or even stolen by models without accessing the\noriginal audio files. Traditional methods like copyright licensing and digital\nwatermarking offer limited protection for these abstract mathematical\nrepresentations, thus necessitating a stronger, e.g., cryptographic, approach\nto safeguarding the embeddings themselves. Standard encryption schemes, such as\nAES, render data unintelligible for computation, making such searches\nimpossible. While Fully Homomorphic Encryption (FHE) provides a plausible\nsolution by allowing arbitrary computations on ciphertexts, its substantial\nperformance overhead remains impractical for large-scale vector similarity\nsearches. Given this trade-off, we propose a more practical approach using\nAdditive Homomorphic Encryption (AHE) for vector similarity search. The primary\ncontributions of this paper are threefold: we analyze threat models unique to\nmusic information retrieval systems; we provide a theoretical analysis and\npropose an efficient AHE-based solution through inner products of music\nembeddings to deliver privacy-preserving similarity search; and finally, we\ndemonstrate the efficiency and practicality of the proposed approach through\nempirical evaluation and comparison to FHE schemes on real-world MP3 files.", "AI": {"tldr": "\u5728\u751f\u6210\u5f0fAI\u65f6\u4ee3\uff0c\u97f3\u4e50\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u6709\u9650\uff0c\u6807\u51c6\u52a0\u5bc6\u65b9\u6848\u6709\u7f3a\u9677\uff0c\u672c\u6587\u63d0\u51fa\u7528\u52a0\u6cd5\u540c\u6001\u52a0\u5bc6\uff08AHE\uff09\u8fdb\u884c\u5411\u91cf\u76f8\u4f3c\u5ea6\u641c\u7d22\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u5206\u6790\u548c\u8bc4\u4f30\u3002", "motivation": "\u751f\u6210\u5f0fAI\u65f6\u4ee3\u97f3\u4e50\u6570\u636e\u7684\u7279\u6027\u4f7f\u5176\u6838\u5fc3\u5411\u91cf\u5d4c\u5165\u6613\u88ab\u6ee5\u7528\uff0c\u4f20\u7edf\u4fdd\u62a4\u65b9\u6cd5\u6709\u9650\uff0c\u9700\u65b0\u7684\u52a0\u5bc6\u65b9\u6cd5\u4fdd\u62a4\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u52a0\u6cd5\u540c\u6001\u52a0\u5bc6\uff08AHE\uff09\u8fdb\u884c\u5411\u91cf\u76f8\u4f3c\u5ea6\u641c\u7d22\uff0c\u5206\u6790\u5a01\u80c1\u6a21\u578b\uff0c\u901a\u8fc7\u97f3\u4e50\u5d4c\u5165\u7684\u5185\u79ef\u7ed9\u51fa\u7406\u8bba\u5206\u6790\u548c\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u5bf9\u771f\u5b9eMP3\u6587\u4ef6\u7684\u5b9e\u8bc1\u8bc4\u4f30\u548c\u4e0eFHE\u65b9\u6848\u7684\u6bd4\u8f83\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u52a0\u6cd5\u540c\u6001\u52a0\u5bc6\uff08AHE\uff09\u4e3a\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u4e2d\u7684\u5411\u91cf\u76f8\u4f3c\u5ea6\u641c\u7d22\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u3002"}}
{"id": "2508.07309", "pdf": "https://arxiv.org/pdf/2508.07309", "abs": "https://arxiv.org/abs/2508.07309", "authors": ["Yi Chen", "Yuhong Jin", "Rongzhou Lin", "Yifan Jiang", "Xutao Mei", "Lei Houb", "Yilong Wang", "Ng Teng Yong", "Anxin Guo"], "title": "Harmonic balance-automatic differentiation method: an out-of-the-box and efficient solver for general nonlinear dynamics simulation", "categories": ["cs.CE"], "comment": "36 pages, 7 figures, 2 tables", "summary": "The Harmonic Balance-Alternating Frequency-Time domain (HB-AFT) method is\nextensively employed for dynamic response analysis of nonlinear systems.\nHowever, its application to high-dimensional complex systems is constrained by\nthe manual derivation of Jacobian matrices during Newton-Raphson iterations,\nwhich become computationally intractable or error-prone for intricate\nnonlinearities. The Harmonic Balance-Automatic Differentiation (HB-AD) method\nis proposed to address this limitation, in which AD is integrated with the\nharmonic balance framework. This approach eliminates all manual derivations by\nleveraging AD to compute exact Jacobians numerically, enabling generic and\nefficient analysis of high-dimensional complex nonlinear systems. The\nimplementation utilizes advanced deep learning frameworks for native parallel\ncomputing and CUDA acceleration, and combines AD with arc-length continuation,\nestablishing an out-of-the-box and high efficiency computational architecture.\nUsers need only supply the system's dynamic equations, HB-AD then autonomously\ntrace the complete panorama of periodic responses -- including stable/unstable\nsolution branches. Computational experiments on a rotor system with\nsqueeze-film damper (SFD) demonstrate HB-AD's capability in handling complex\nnonlinear expressions with automated Jacobian calculations. For a\nhigh-dimensional aero-engine rotor-bearing-casing system with complex bearing\nnonlinearities, HB-AD achieves 17-fold higher efficiency than traditional\nHB-AFT and 144-fold acceleration over the Newmark method. The HB-AD method is a\nsynergistic merger of computational mechanics and machine learning primitives,\ndelivers an easy to use, general-purpose, high efficiency platform for\nhigh-fidelity dynamic characterization of high-dimensional engineering systems.", "AI": {"tldr": "\u63d0\u51faHarmonic Balance - Automatic Differentiation (HB - AD)\u65b9\u6cd5\u89e3\u51b3\u4f20\u7edfHB - AFT\u65b9\u6cd5\u5728\u9ad8\u7ef4\u590d\u6742\u7cfb\u7edf\u5e94\u7528\u4e2d\u7684\u5c40\u9650\uff0c\u901a\u8fc7\u8ba1\u7b97\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u9ad8\u6548\u6027\uff0c\u4e3a\u9ad8\u7ef4\u5de5\u7a0b\u7cfb\u7edf\u63d0\u4f9b\u5206\u6790\u5e73\u53f0\u3002", "motivation": "\u4f20\u7edfHB - AFT\u65b9\u6cd5\u5728\u9ad8\u7ef4\u590d\u6742\u7cfb\u7edf\u5e94\u7528\u4e2d\u53d7\u725b\u987f - \u62c9\u592b\u900a\u8fed\u4ee3\u65f6\u624b\u52a8\u63a8\u5bfc\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u9650\u5236\uff0c\u8ba1\u7b97\u56f0\u96be\u4e14\u6613\u51fa\u9519\u3002", "method": "\u5c06\u81ea\u52a8\u5fae\u5206\uff08AD\uff09\u4e0e\u8c10\u6ce2\u5e73\u8861\u6846\u67b6\u7ed3\u5408\uff0c\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u5e76\u884c\u8ba1\u7b97\u548cCUDA\u52a0\u901f\uff0c\u7ed3\u5408AD\u4e0e\u5f27\u957f\u5ef6\u62d3\u6cd5\u3002", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660eHB - AD\u80fd\u5904\u7406\u590d\u6742\u975e\u7ebf\u6027\u8868\u8fbe\u5f0f\uff0c\u5bf9\u9ad8\u7ef4\u822a\u7a7a\u53d1\u52a8\u673a\u7cfb\u7edf\uff0c\u6bd4\u4f20\u7edfHB - AFT\u6548\u7387\u9ad817\u500d\uff0c\u6bd4Newmark\u65b9\u6cd5\u5feb144\u500d\u3002", "conclusion": "HB - AD\u65b9\u6cd5\u7ed3\u5408\u8ba1\u7b97\u529b\u5b66\u548c\u673a\u5668\u5b66\u4e60\u539f\u8bed\uff0c\u4e3a\u9ad8\u7ef4\u5de5\u7a0b\u7cfb\u7edf\u7684\u52a8\u6001\u7279\u6027\u5206\u6790\u63d0\u4f9b\u6613\u7528\u3001\u901a\u7528\u3001\u9ad8\u6548\u7684\u5e73\u53f0\u3002"}}
{"id": "2508.06824", "pdf": "https://arxiv.org/pdf/2508.06824", "abs": "https://arxiv.org/abs/2508.06824", "authors": ["Mohammad Kayed", "Manish Kacker", "Ruhai Wu", "Farhad Sadeh"], "title": "The impact of brand equity on vertical integration in franchise systems", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Brand equity and vertical integration are focal, strategic elements of a\nfranchise system that can profoundly influence franchise performance. Despite\nthe recognized importance of these two strategic levers and the longstanding\nresearch interest in the topic, our understanding of the interplay between\nbrand equity and vertical integration (company ownership of outlets) in a\nfranchise system remains incomplete. In this study, we revisit the\nfive-decade-old question of how brand equity affects vertical integration in a\nfranchise system and present some novel, nuanced insights into the topic.\nEvidence from a Bayesian Panel Vector Autoregressive model on a large panel\ndata set shows that brand equity has a powerful, lagging inverse effect on\nvertical integration, such that higher brand equity leads to less downstream\nvertical integration in a franchise system. Reverse causality analyses identify\na less pronounced but present reciprocal effect. Boundary conditions analyses\nreveal that the negative effect of brand equity on vertical integration is\nweaker in franchise systems with international presence and in retail-focused\n(vs. service-focused) franchises, and stronger in franchise systems with more\nfinancial resources. These findings (a) challenge traditional views (e.g.,\ntransaction cost theory, resource-based view, ownership redirection hypothesis)\non the topic by demonstrating a negative effect for brand equity on vertical\nintegration in franchise systems and showing that greater financial resources\namplify this effect, and (b) shed new light on the intricate dynamics (temporal\ncausation, reverse causation) and contingencies of this debated effect.\nManagerially, this research draws attention to the underrecognized strategic\nbenefit of brand equity in mitigating channel governance issues and advise\nagainst unnecessary vertical integration, especially when brand equity is\nrobust.", "AI": {"tldr": "\u7814\u7a76\u54c1\u724c\u8d44\u4ea7\u5bf9\u7279\u8bb8\u7ecf\u8425\u7cfb\u7edf\u5782\u76f4\u6574\u5408\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u54c1\u724c\u8d44\u4ea7\u5bf9\u5782\u76f4\u6574\u5408\u6709\u6ede\u540e\u7684\u53cd\u5411\u5f71\u54cd\uff0c\u8fd8\u5206\u6790\u4e86\u8fb9\u754c\u6761\u4ef6\uff0c\u6311\u6218\u4f20\u7edf\u89c2\u70b9\u5e76\u7ed9\u51fa\u7ba1\u7406\u5efa\u8bae\u3002", "motivation": "\u4ee5\u5f80\u5bf9\u54c1\u724c\u8d44\u4ea7\u548c\u5782\u76f4\u6574\u5408\u5728\u7279\u8bb8\u7ecf\u8425\u7cfb\u7edf\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\u7406\u89e3\u4e0d\u5b8c\u6574\uff0c\u91cd\u65b0\u63a2\u8ba8\u54c1\u724c\u8d44\u4ea7\u5982\u4f55\u5f71\u54cd\u5782\u76f4\u6574\u5408\u8fd9\u4e00\u5b58\u5728\u4e94\u5341\u5e74\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u9762\u677f\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\u5206\u6790\u5927\u578b\u9762\u677f\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u53cd\u5411\u56e0\u679c\u5206\u6790\u548c\u8fb9\u754c\u6761\u4ef6\u5206\u6790\u3002", "result": "\u54c1\u724c\u8d44\u4ea7\u5bf9\u5782\u76f4\u6574\u5408\u6709\u5f3a\u5927\u7684\u6ede\u540e\u53cd\u5411\u5f71\u54cd\uff0c\u53cd\u5411\u56e0\u679c\u5173\u7cfb\u8f83\u5f31\uff1b\u5728\u6709\u56fd\u9645\u4e1a\u52a1\u548c\u96f6\u552e\u4e3a\u4e3b\u7684\u7279\u8bb8\u7ecf\u8425\u7cfb\u7edf\u4e2d\uff0c\u54c1\u724c\u8d44\u4ea7\u5bf9\u5782\u76f4\u6574\u5408\u7684\u8d1f\u9762\u5f71\u54cd\u8f83\u5f31\uff0c\u8d22\u52a1\u8d44\u6e90\u591a\u7684\u7cfb\u7edf\u4e2d\u5f71\u54cd\u66f4\u5f3a\u3002", "conclusion": "\u6311\u6218\u4e86\u4f20\u7edf\u89c2\u70b9\uff0c\u63ed\u793a\u4e86\u590d\u6742\u52a8\u6001\u548c\u5076\u7136\u6027\uff1b\u6307\u51fa\u54c1\u724c\u8d44\u4ea7\u5728\u7f13\u89e3\u6e20\u9053\u6cbb\u7406\u95ee\u9898\u4e0a\u7684\u6218\u7565\u76ca\u5904\uff0c\u5efa\u8bae\u54c1\u724c\u8d44\u4ea7\u5f3a\u65f6\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5782\u76f4\u6574\u5408\u3002"}}
{"id": "2508.07317", "pdf": "https://arxiv.org/pdf/2508.07317", "abs": "https://arxiv.org/abs/2508.07317", "authors": ["Pedro Carrinho", "Hamid Moghadaspour", "Oscar Ferraz", "Jo\u00e3o Dinis Ferreira", "Yann Falevoz", "Vitor Silva", "Gabriel Falcao"], "title": "An Experimental Exploration of In-Memory Computing for Multi-Layer Perceptrons", "categories": ["cs.DC", "eess.SP"], "comment": "19 pages, 1 figures, and 2 tables", "summary": "In modern computer architectures, the performance of many memory-bound\nworkloads (e.g., machine learning, graph processing, databases) is limited by\nthe data movement bottleneck that emerges when transferring large amounts of\ndata between the main memory and the central processing unit (CPU).\nProcessing-in-memory is an emerging computing paradigm that aims to alleviate\nthis data movement bottleneck by performing computation close to or within the\nmemory units, where data resides. One example of a prevalent workload whose\nperformance is bound by the data movement bottleneck is the training and\ninference process of artificial neural networks. In this work, we analyze the\npotential of modern general-purpose PiM architectures to accelerate neural\nnetworks. To this end, we selected the UPMEM PiM system, the first commercially\navailable real-world general-purpose PiM architecture. We compared the\nimplementation of multilayer perceptrons (MLPs) in PiM with a sequential\nbaseline running on an Intel Xeon CPU. The UPMEM implementation achieves up to\n$259\\times$ better performance for inference of large batch sizes when compared\nagainst the CPU that exploits the size of the available PiM memory.\nAdditionally, two smaller MLPs were implemented using UPMEM's working SRAM\n(WRAM), a scratchpad memory, to evaluate their performance against a low-power\nNvidia Jetson graphics processing unit (GPU), providing further insights into\nthe efficiency of UPMEM's PiM for neural network inference. Results show that\nusing WRAM achieves kernel execution times for MLP inference of under $3$ ms,\nwhich is within the same order of magnitude as low-power GPUs.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u901a\u7528\u5904\u7406\u5185\u5b58\uff08PiM\uff09\u67b6\u6784\u52a0\u901f\u795e\u7ecf\u7f51\u7edc\u7684\u6f5c\u529b\uff0c\u4ee5UPMEM PiM\u7cfb\u7edf\u4e3a\u4f8b\uff0c\u4e0eCPU\u3001GPU\u5bf9\u6bd4\uff0c\u7ed3\u679c\u663e\u793a\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u73b0\u4ee3\u8ba1\u7b97\u673a\u67b6\u6784\u4e2d\uff0c\u5185\u5b58\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u53d7\u6570\u636e\u79fb\u52a8\u74f6\u9888\u9650\u5236\uff0c\u5904\u7406\u5185\u5b58\u8ba1\u7b97\u8303\u5f0f\u65e8\u5728\u7f13\u89e3\u8be5\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u5206\u6790\u901a\u7528PiM\u67b6\u6784\u52a0\u901f\u795e\u7ecf\u7f51\u7edc\u7684\u6f5c\u529b\u3002", "method": "\u9009\u62e9UPMEM PiM\u7cfb\u7edf\uff0c\u5c06\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u5728PiM\u4e0a\u7684\u5b9e\u73b0\u4e0e\u82f1\u7279\u5c14\u81f3\u5f3aCPU\u4e0a\u7684\u987a\u5e8f\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\uff1b\u4f7f\u7528UPMEM\u7684\u5de5\u4f5cSRAM\u5b9e\u73b0\u4e24\u4e2a\u8f83\u5c0f\u7684MLP\uff0c\u4e0e\u4f4e\u529f\u8017\u82f1\u4f1f\u8fbeJetson GPU\u5bf9\u6bd4\u3002", "result": "UPMEM\u5b9e\u73b0\u5bf9\u4e8e\u5927\u6279\u91cf\u63a8\u7406\u6027\u80fd\u6bd4CPU\u9ad8259\u500d\uff1b\u4f7f\u7528WRAM\u5b9e\u73b0MLP\u63a8\u7406\u7684\u5185\u6838\u6267\u884c\u65f6\u95f4\u4f4e\u4e8e3\u6beb\u79d2\uff0c\u4e0e\u4f4e\u529f\u8017GPU\u5904\u4e8e\u540c\u4e00\u6570\u91cf\u7ea7\u3002", "conclusion": "\u73b0\u4ee3\u901a\u7528PiM\u67b6\u6784\u5728\u52a0\u901f\u795e\u7ecf\u7f51\u7edc\u65b9\u9762\u6709\u8f83\u5927\u6f5c\u529b\uff0cUPMEM PiM\u7cfb\u7edf\u6027\u80fd\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2508.07077", "pdf": "https://arxiv.org/pdf/2508.07077", "abs": "https://arxiv.org/abs/2508.07077", "authors": ["Gustavo V. Nascimento", "Ivan R. Meneghini", "Val\u00e9ria Santos", "Eduardo Luz", "Gladston Moreira"], "title": "Enhancing Decision Space Diversity in Multi-Objective Evolutionary Optimization for the Diet Problem", "categories": ["cs.NE"], "comment": "12 pages", "summary": "Multi-objective evolutionary algorithms (MOEAs) are essential for solving\ncomplex optimization problems, such as the diet problem, where balancing\nconflicting objectives, like cost and nutritional content, is crucial. However,\nmost MOEAs focus on optimizing solutions in the objective space, often\nneglecting the diversity of solutions in the decision space, which is critical\nfor providing decision-makers with a wide range of choices. This paper\nintroduces an approach that directly integrates a Hamming distance-based\nmeasure of uniformity into the selection mechanism of a MOEA to enhance\ndecision space diversity. Experiments on a multi-objective formulation of the\ndiet problem demonstrate that our approach significantly improves decision\nspace diversity compared to NSGA-II, while maintaining comparable objective\nspace performance. The proposed method offers a generalizable strategy for\nintegrating decision space awareness into MOEAs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e00\u79cd\u5c06\u57fa\u4e8e\u6c49\u660e\u8ddd\u79bb\u7684\u5747\u5300\u6027\u5ea6\u91cf\u96c6\u6210\u5230\u591a\u76ee\u6807\u8fdb\u5316\u7b97\u6cd5\uff08MOEA\uff09\u9009\u62e9\u673a\u5236\u4e2d\u7684\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3a\u51b3\u7b56\u7a7a\u95f4\u591a\u6837\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u996e\u98df\u95ee\u9898\u4e0a\u6709\u6548\u3002", "motivation": "\u591a\u6570MOEA\u6ce8\u91cd\u76ee\u6807\u7a7a\u95f4\u4f18\u5316\uff0c\u5ffd\u7565\u51b3\u7b56\u7a7a\u95f4\u89e3\u7684\u591a\u6837\u6027\uff0c\u800c\u51b3\u7b56\u7a7a\u95f4\u591a\u6837\u6027\u5bf9\u51b3\u7b56\u8005\u63d0\u4f9b\u591a\u79cd\u9009\u62e9\u5f88\u5173\u952e\u3002", "method": "\u5c06\u57fa\u4e8e\u6c49\u660e\u8ddd\u79bb\u7684\u5747\u5300\u6027\u5ea6\u91cf\u76f4\u63a5\u96c6\u6210\u5230MOEA\u7684\u9009\u62e9\u673a\u5236\u4e2d\u3002", "result": "\u5728\u996e\u98df\u95ee\u9898\u7684\u591a\u76ee\u6807\u516c\u5f0f\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4NSGA - II\u663e\u8457\u63d0\u9ad8\u4e86\u51b3\u7b56\u7a7a\u95f4\u591a\u6837\u6027\uff0c\u4e14\u76ee\u6807\u7a7a\u95f4\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5c06\u51b3\u7b56\u7a7a\u95f4\u610f\u8bc6\u96c6\u6210\u5230MOEA\u4e2d\u63d0\u4f9b\u4e86\u53ef\u63a8\u5e7f\u7684\u7b56\u7565\u3002"}}
{"id": "2508.06585", "pdf": "https://arxiv.org/pdf/2508.06585", "abs": "https://arxiv.org/abs/2508.06585", "authors": ["Jayant Sravan Tamarapalli", "Rynaa Grover", "Nilay Pande", "Sahiti Yerramilli"], "title": "CountQA: How Well Do MLLMs Count in the Wild?", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in\nunderstanding visual scenes, yet they exhibit a critical lack in a fundamental\ncognitive skill: object counting. This blind spot severely limits their\nreliability in real-world applications. To date, this capability has been\nlargely unevaluated in complex scenarios, as existing benchmarks either feature\nsparse object densities or are confined to specific visual domains, failing to\ntest models under realistic conditions. Addressing this gap, we introduce\nCountQA, a challenging new benchmark designed to probe this deficiency.\nComprising over 1,500 question-answer pairs, CountQA features real-world images\nwith high object density, clutter, and occlusion. We investigate this weakness\nby evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the\ntop-performing model achieves a mere 42.9% accuracy, with performance declining\nas object counts rise. By providing a dedicated benchmark to diagnose and\nrectify this core weakness, CountQA paves the way for a new generation of MLLMs\nthat are not only descriptively fluent but also numerically grounded and\nspatially aware. We will open-source the dataset and code upon paper acceptance\nto foster further research.", "AI": {"tldr": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5b58\u5728\u7269\u4f53\u8ba1\u6570\u80fd\u529b\u7f3a\u9677\uff0c\u672c\u6587\u5f15\u5165CountQA\u57fa\u51c6\u6d4b\u8bd5\u8be5\u80fd\u529b\uff0c\u8bc4\u4f3015\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u6700\u4f73\u6a21\u578b\u51c6\u786e\u7387\u4ec542.9%\uff0c\u540e\u7eed\u5c06\u5f00\u6e90\u6570\u636e\u548c\u4ee3\u7801\u3002", "motivation": "MLLMs\u5728\u7269\u4f53\u8ba1\u6570\u8fd9\u4e00\u57fa\u672c\u8ba4\u77e5\u6280\u80fd\u4e0a\u5b58\u5728\u7f3a\u9677\uff0c\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5728\u590d\u6742\u573a\u666f\u4e0b\u8bc4\u4f30\u8be5\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u5f15\u5165\u5305\u542b\u8d851500\u4e2a\u95ee\u7b54\u5bf9\u3001\u5177\u6709\u9ad8\u7269\u4f53\u5bc6\u5ea6\u7b49\u7279\u70b9\u7684CountQA\u57fa\u51c6\uff0c\u5bf915\u4e2a\u8457\u540dMLLMs\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u51c6\u786e\u7387\u4ec542.9%\uff0c\u4e14\u968f\u7740\u7269\u4f53\u6570\u91cf\u589e\u52a0\uff0c\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "CountQA\u4e3a\u8bca\u65ad\u548c\u7ea0\u6b63MLLMs\u7684\u6838\u5fc3\u5f31\u70b9\u63d0\u4f9b\u4e86\u4e13\u95e8\u57fa\u51c6\uff0c\u6709\u671b\u63a8\u52a8\u65b0\u4e00\u4ee3\u517c\u5177\u63cf\u8ff0\u6d41\u7545\u6027\u3001\u6570\u503c\u57fa\u7840\u548c\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\u7684MLLMs\u53d1\u5c55\u3002"}}
{"id": "2508.07640", "pdf": "https://arxiv.org/pdf/2508.07640", "abs": "https://arxiv.org/abs/2508.07640", "authors": ["Chanh Nguyen", "Monowar Bhuyan", "Erik Elmroth"], "title": "Taming Cold Starts: Proactive Serverless Scheduling with Model Predictive Control", "categories": ["cs.DC", "cs.PF"], "comment": "8 pages, 8 figures, preprint accepted at MASCOTS 2025", "summary": "Serverless computing has transformed cloud application deployment by\nintroducing a fine-grained, event-driven execution model that abstracts away\ninfrastructure management. Its on-demand nature makes it especially appealing\nfor latency-sensitive and bursty workloads. However, the cold start problem,\ni.e., where the platform incurs significant delay when provisioning new\ncontainers, remains the Achilles' heel of such platforms.\n  This paper presents a predictive serverless scheduling framework based on\nModel Predictive Control to proactively mitigate cold starts, thereby improving\nend-to-end response time. By forecasting future invocations, the controller\njointly optimizes container prewarming and request dispatching, improving\nlatency while minimizing resource overhead.\n  We implement our approach on Apache OpenWhisk, deployed on a Kubernetes-based\ntestbed. Experimental results using real-world function traces and synthetic\nworkloads demonstrate that our method significantly outperforms\nstate-of-the-art baselines, achieving up to 85% lower tail latency and a 34%\nreduction in resource usage.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u9884\u6d4b\u6027\u65e0\u670d\u52a1\u5668\u8c03\u5ea6\u6846\u67b6\u51cf\u8f7b\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5b58\u5728\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5f71\u54cd\u5e73\u53f0\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u8be5\u95ee\u9898\u4ee5\u63d0\u5347\u7aef\u5230\u7aef\u54cd\u5e94\u65f6\u95f4\u3002", "method": "\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6784\u5efa\u9884\u6d4b\u6027\u65e0\u670d\u52a1\u5668\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u8c03\u7528\u8054\u5408\u4f18\u5316\u5bb9\u5668\u9884\u9884\u70ed\u548c\u8bf7\u6c42\u8c03\u5ea6\u3002", "result": "\u5728Apache OpenWhisk\u4e0a\u5b9e\u73b0\u8be5\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\uff0c\u5c3e\u5ef6\u8fdf\u6700\u591a\u964d\u4f4e85%\uff0c\u8d44\u6e90\u4f7f\u7528\u51cf\u5c1134%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u8f7b\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u63d0\u9ad8\u5ef6\u8fdf\u6027\u80fd\u5e76\u964d\u4f4e\u8d44\u6e90\u5f00\u9500\u3002"}}
{"id": "2508.06661", "pdf": "https://arxiv.org/pdf/2508.06661", "abs": "https://arxiv.org/abs/2508.06661", "authors": ["Keith Badger", "Marek Petrik", "Jefferson Huang"], "title": "Convergence of Fast Policy Iteration in Markov Games and Robust MDPs", "categories": ["cs.GT"], "comment": null, "summary": "Markov games and robust MDPs are closely related models that involve\ncomputing a pair of saddle point policies. As part of the long-standing effort\nto develop efficient algorithms for these models, the Filar-Tolwinski (FT)\nalgorithm has shown considerable promise. As our first contribution, we\ndemonstrate that FT may fail to converge to a saddle point and may loop\nindefinitely, even in small games. This observation contradicts the proof of\nFT's convergence to a saddle point in the original paper. As our second\ncontribution, we propose Residual Conditioned Policy Iteration (RCPI). RCPI\nbuilds on FT, but is guaranteed to converge to a saddle point. Our numerical\nresults show that RCPI outperforms other convergent algorithms by several\norders of magnitude.", "AI": {"tldr": "\u672c\u6587\u6307\u51faFilar - Tolwinski (FT)\u7b97\u6cd5\u53ef\u80fd\u65e0\u6cd5\u6536\u655b\u5230\u978d\u70b9\uff0c\u63d0\u51fa\u4e86Residual Conditioned Policy Iteration (RCPI)\u7b97\u6cd5\uff0c\u5b83\u57fa\u4e8eFT\u4e14\u80fd\u4fdd\u8bc1\u6536\u655b\u5230\u978d\u70b9\uff0c\u6570\u503c\u7ed3\u679c\u663e\u793aRCPI\u6027\u80fd\u8fdc\u8d85\u5176\u4ed6\u6536\u655b\u7b97\u6cd5\u3002", "motivation": "\u957f\u671f\u81f4\u529b\u4e8e\u4e3aMarkov\u6e38\u620f\u548c\u9c81\u68d2MDPs\u6a21\u578b\u5f00\u53d1\u9ad8\u6548\u7b97\u6cd5\uff0c\u53d1\u73b0FT\u7b97\u6cd5\u5b58\u5728\u95ee\u9898\u3002", "method": "\u5148\u5206\u6790FT\u7b97\u6cd5\u95ee\u9898\uff0c\u518d\u63d0\u51fa\u57fa\u4e8eFT\u7684RCPI\u7b97\u6cd5\u3002", "result": "RCPI\u80fd\u4fdd\u8bc1\u6536\u655b\u5230\u978d\u70b9\uff0c\u4e14\u5728\u6570\u503c\u7ed3\u679c\u4e0a\u6bd4\u5176\u4ed6\u6536\u655b\u7b97\u6cd5\u6027\u80fd\u597d\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "RCPI\u7b97\u6cd5\u5728\u89e3\u51b3Markov\u6e38\u620f\u548c\u9c81\u68d2MDPs\u6a21\u578b\u7684\u978d\u70b9\u7b56\u7565\u8ba1\u7b97\u95ee\u9898\u4e0a\u66f4\u6709\u6548\u3002"}}
{"id": "2508.07050", "pdf": "https://arxiv.org/pdf/2508.07050", "abs": "https://arxiv.org/abs/2508.07050", "authors": ["Wenhan Liu", "Xinyu Ma", "Weiwei Sun", "Yutao Zhu", "Yuchen Li", "Dawei Yin", "Zhicheng Dou"], "title": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": "21 pages", "summary": "Large Language Model (LLM) based listwise ranking has shown superior\nperformance in many passage ranking tasks. With the development of Large\nReasoning Models, many studies have demonstrated that step-by-step reasoning\nduring test-time helps improve listwise ranking performance. However, due to\nthe scarcity of reasoning-intensive training data, existing rerankers perform\npoorly in many complex ranking scenarios and the ranking ability of\nreasoning-intensive rerankers remains largely underdeveloped. In this paper, we\nfirst propose an automated reasoning-intensive training data synthesis\nframework, which sources training queries and passages from diverse domains and\napplies DeepSeek-R1 to generate high-quality training labels. A\nself-consistency data filtering mechanism is designed to ensure the data\nquality. To empower the listwise reranker with strong reasoning ability, we\nfurther propose a two-stage post-training approach, which includes a cold-start\nsupervised fine-tuning (SFT) stage for reasoning pattern learning and a\nreinforcement learning (RL) stage for further ranking ability enhancement.\nDuring the RL stage, based on the nature of listwise ranking, we design a\nmulti-view ranking reward, which is more effective than a ranking metric-based\nreward. Extensive experiments demonstrate that our trained reasoning-intensive\nreranker \\textbf{ReasonRank} outperforms existing baselines significantly and\nalso achieves much lower latency than pointwise reranker Rank1. \\textbf{Through\nfurther experiments, our ReasonRank has achieved state-of-the-art (SOTA)\nperformance 40.6 on the BRIGHT\nleaderboard\\footnote{https://brightbenchmark.github.io/}.} Our codes are\navailable at https://github.com/8421BCD/ReasonRank.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u63a8\u7406\u5bc6\u96c6\u578b\u8bad\u7ec3\u6570\u636e\u5408\u6210\u6846\u67b6\u548c\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u8bad\u7ec3\u51fa\u63a8\u7406\u5bc6\u96c6\u578b\u91cd\u6392\u5668ReasonRank\uff0c\u6027\u80fd\u8d85\u57fa\u7ebf\u4e14\u5ef6\u8fdf\u4f4e\uff0c\u5728BRIGHT\u6392\u884c\u699c\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u91cd\u6392\u5668\u56e0\u63a8\u7406\u5bc6\u96c6\u578b\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\uff0c\u5728\u590d\u6742\u6392\u540d\u573a\u666f\u8868\u73b0\u5dee\uff0c\u63a8\u7406\u5bc6\u96c6\u578b\u91cd\u6392\u5668\u6392\u540d\u80fd\u529b\u672a\u5145\u5206\u5f00\u53d1\u3002", "method": "\u63d0\u51fa\u81ea\u52a8\u5316\u63a8\u7406\u5bc6\u96c6\u578b\u8bad\u7ec3\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u8bbe\u8ba1\u81ea\u4e00\u81f4\u6027\u6570\u636e\u8fc7\u6ee4\u673a\u5236\uff1b\u63d0\u51fa\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\u51b7\u542f\u52a8\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\u548c\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\uff0c\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\u8bbe\u8ba1\u591a\u89c6\u56fe\u6392\u540d\u5956\u52b1\u3002", "result": "\u8bad\u7ec3\u7684ReasonRank\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5ef6\u8fdf\u4f4e\u4e8e\u70b9wise\u91cd\u6392\u5668Rank1\uff0c\u5728BRIGHT\u6392\u884c\u699c\u8fbeSOTA\u6027\u80fd40.6\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u91cd\u6392\u5668\u7684\u63a8\u7406\u548c\u6392\u540d\u80fd\u529b\uff0cReasonRank\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2508.07008", "pdf": "https://arxiv.org/pdf/2508.07008", "abs": "https://arxiv.org/abs/2508.07008", "authors": ["Anne Driemel", "Jan H\u00f6ckendorff", "Ioannis Psarros", "Christian Sohler"], "title": "A near-linear time approximation scheme for $(k,\\ell)$-median clustering under discrete Fr\u00e9chet distance", "categories": ["cs.DS"], "comment": null, "summary": "A time series of complexity $m$ is a sequence of $m$ real valued\nmeasurements. The discrete Fr\\'echet distance $d_{dF}(x,y)$ is a distance\nmeasure between two time series $x$ and $y$ of possibly different complexity.\nGiven a set of $n$ time series represented as $m$-dimensional vectors over the\nreals, the $(k,\\ell)$-median problem under discrete Fr\\'echet distance aims to\nfind a set $C$ of $k$ time series of complexity $\\ell$ such that $$\\sum_{x\\in\nP} \\min_{c\\in C} d_{dF}(x,c)$$ is minimized. In this paper, we give the first\nnear-linear time $(1+\\varepsilon)$-approximation algorithm for this problem\nwhen $\\ell$ and $\\varepsilon$ are constants but $k$ can be as large as\n$\\Omega(n)$. We obtain our result by introducing a new dimension reduction\ntechnique for discrete Fr\\'echet distance and then adapt an algorithm of\nCohen-Addad et al. (J. ACM 2021) to work on the dimension-reduced input. As a\nbyproduct we also improve the best coreset construction for $(k,\\ell)$-median\nunder discrete Fr\\'echet distance (Cohen-Addad et al., SODA 2025) and show that\nits size can be independent of the number of input time series \\emph{ and }\ntheir complexity.", "AI": {"tldr": "\u672c\u6587\u7ed9\u51fa\u4e86\u79bb\u6563Fr\u00e9chet\u8ddd\u79bb\u4e0b(k,\u2113)-\u4e2d\u4f4d\u6570\u95ee\u9898\u7684\u9996\u4e2a\u8fd1\u7ebf\u6027\u65f6\u95f4(1 + \u03b5)-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8fd8\u6539\u8fdb\u4e86\u6838\u5fc3\u96c6\u6784\u9020\u3002", "motivation": "\u89e3\u51b3\u79bb\u6563Fr\u00e9chet\u8ddd\u79bb\u4e0b(k,\u2113)-\u4e2d\u4f4d\u6570\u95ee\u9898\uff0c\u5728\u2113\u548c\u03b5\u4e3a\u5e38\u6570\u4f46k\u53ef\u8fbe\u03a9(n)\u7684\u60c5\u51b5\u4e0b\u627e\u5230\u9ad8\u6548\u7b97\u6cd5\u3002", "method": "\u5f15\u5165\u65b0\u7684\u79bb\u6563Fr\u00e9chet\u8ddd\u79bb\u964d\u7ef4\u6280\u672f\uff0c\u5e76\u9002\u914dCohen - Addad\u7b49\u4eba\u7684\u7b97\u6cd5\u5230\u964d\u7ef4\u8f93\u5165\u3002", "result": "\u5f97\u5230\u8fd1\u7ebf\u6027\u65f6\u95f4(1 + \u03b5)-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u6539\u8fdb\u4e86\u6838\u5fc3\u96c6\u6784\u9020\uff0c\u4f7f\u5176\u5927\u5c0f\u4e0e\u8f93\u5165\u65f6\u95f4\u5e8f\u5217\u6570\u91cf\u548c\u590d\u6742\u5ea6\u65e0\u5173\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u79bb\u6563Fr\u00e9chet\u8ddd\u79bb\u4e0b(k,\u2113)-\u4e2d\u4f4d\u6570\u95ee\u9898\uff0c\u5e76\u5728\u6838\u5fc3\u96c6\u6784\u9020\u4e0a\u53d6\u5f97\u6539\u8fdb\u3002"}}
{"id": "2508.06926", "pdf": "https://arxiv.org/pdf/2508.06926", "abs": "https://arxiv.org/abs/2508.06926", "authors": ["Feng Luo", "Kexing Ji", "Cuiyun Gao", "Shuzheng Gao", "Jia Feng", "Kui Liu", "Xin Xia", "Michael R. Lyu"], "title": "Integrating Rules and Semantics for LLM-Based C-to-Rust Translation", "categories": ["cs.SE"], "comment": "Accepted in ICSME 25 Industry Track", "summary": "Automated translation of legacy C code into Rust aims to ensure memory safety\nwhile reducing the burden of manual migration. Early approaches in code\ntranslation rely on static rule-based methods, but they suffer from limited\ncoverage due to dependence on predefined rule patterns. Recent works regard the\ntask as a sequence-to-sequence problem by leveraging large language models\n(LLMs). Although these LLM-based methods are capable of reducing unsafe code\nblocks, the translated code often exhibits issues in following Rust rules and\nmaintaining semantic consistency. On one hand, existing methods adopt a direct\nprompting strategy to translate the C code, which struggles to accommodate the\nsyntactic rules between C and Rust. On the other hand, this strategy makes it\ndifficult for LLMs to accurately capture the semantics of complex code. To\naddress these challenges, we propose IRENE, an LLM-based framework that\nIntegrates RulEs aNd sEmantics to enhance translation. IRENE consists of three\nmodules: 1) a rule-augmented retrieval module that selects relevant translation\nexamples based on rules generated from a static analyzer developed by us,\nthereby improving the handling of Rust rules; 2) a structured summarization\nmodule that produces a structured summary for guiding LLMs to enhance the\nsemantic understanding of C code; 3) an error-driven translation module that\nleverages compiler diagnostics to iteratively refine translations. We evaluate\nIRENE on two datasets (xCodeEval, a public dataset, and HW-Bench, an industrial\ndataset provided by Huawei) and eight LLMs, focusing on translation accuracy\nand safety.", "AI": {"tldr": "\u73b0\u6709C\u4ee3\u7801\u8f6cRust\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u63d0\u51faIRENE\u6846\u67b6\u63d0\u5347\u7ffb\u8bd1\u6548\u679c\u5e76\u8bc4\u4f30\u3002", "motivation": "\u65e9\u671fC\u4ee3\u7801\u8f6cRust\u65b9\u6cd5\u8986\u76d6\u6709\u9650\uff0cLLM - \u57fa\u4e8e\u65b9\u6cd5\u5728\u9075\u5faa\u89c4\u5219\u548c\u8bed\u4e49\u4e00\u81f4\u65b9\u9762\u6709\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faIRENE\u6846\u67b6\uff0c\u5305\u542b\u89c4\u5219\u589e\u5f3a\u68c0\u7d22\u3001\u7ed3\u6784\u5316\u603b\u7ed3\u3001\u9519\u8bef\u9a71\u52a8\u7ffb\u8bd1\u4e09\u4e2a\u6a21\u5757\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u548c\u516b\u4e2aLLM\u4e0a\u8bc4\u4f30\uff0c\u5173\u6ce8\u7ffb\u8bd1\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u672a\u660e\u786e\u7ed9\u51fa\u7ed3\u8bba\uff0c\u4f46\u6697\u793aIRENE\u6846\u67b6\u53ef\u80fd\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\u3002"}}
{"id": "2508.06587", "pdf": "https://arxiv.org/pdf/2508.06587", "abs": "https://arxiv.org/abs/2508.06587", "authors": ["A. Quadir", "M. Tanveer"], "title": "Hypergraph Neural Network with State Space Models for Node Classification", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, graph neural networks (GNNs) have gained significant\nattention for node classification tasks on graph-structured data. However,\ntraditional GNNs primarily focus on adjacency relationships between nodes,\noften overlooking the rich role-based characteristics that are crucial for\nlearning more expressive node representations. Existing methods for capturing\nrole-based features are largely unsupervised and fail to achieve optimal\nperformance in downstream tasks. To address these limitations, we propose a\nnovel hypergraph neural network with state space model (HGMN) that effectively\nintegrates role-aware representations into GNNs and the state space model. HGMN\nutilizes hypergraph construction techniques to model higher-order relationships\nand combines role-based and adjacency-based representations through a learnable\nmamba transformer mechanism. By leveraging two distinct hypergraph construction\nmethods-based on node degree and neighborhood levels, it strengthens the\nconnections among nodes with similar roles, enhancing the model's\nrepresentational power. Additionally, the inclusion of hypergraph convolution\nlayers enables the model to capture complex dependencies within hypergraph\nstructures. To mitigate the over-smoothing problem inherent in deep GNNs, we\nincorporate a residual network, ensuring improved stability and better feature\npropagation across layers. Extensive experiments conducted on one newly\nintroduced dataset and four benchmark datasets demonstrate the superiority of\nHGMN. The model achieves significant performance improvements on node\nclassification tasks compared to state-of-the-art GNN methods. These results\nhighlight HGMN's ability to provide enriched node representations by\neffectively embedding role-based features alongside adjacency information,\nmaking it a versatile and powerful tool for a variety of graph-based learning\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8d85\u56fe\u795e\u7ecf\u7f51\u7edcHGMN\u7528\u4e8e\u8282\u70b9\u5206\u7c7b\uff0c\u878d\u5408\u89d2\u8272\u611f\u77e5\u8868\u5f81\uff0c\u5728\u591a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709GNN\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfGNN\u5ffd\u89c6\u89d2\u8272\u7279\u5f81\uff0c\u73b0\u6709\u6355\u6349\u89d2\u8272\u7279\u5f81\u65b9\u6cd5\u591a\u65e0\u76d1\u7763\u4e14\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faHGMN\uff0c\u5229\u7528\u8d85\u56fe\u6784\u5efa\u6280\u672f\u3001\u53ef\u5b66\u4e60\u7684mamba transformer\u673a\u5236\u7ed3\u5408\u89d2\u8272\u548c\u90bb\u63a5\u8868\u5f81\uff0c\u4f7f\u7528\u57fa\u4e8e\u8282\u70b9\u5ea6\u548c\u90bb\u57df\u7ea7\u522b\u7684\u8d85\u56fe\u6784\u5efa\u65b9\u6cd5\uff0c\u52a0\u5165\u8d85\u56fe\u5377\u79ef\u5c42\u548c\u6b8b\u5dee\u7f51\u7edc\u3002", "result": "\u5728\u4e00\u4e2a\u65b0\u5f15\u5165\u6570\u636e\u96c6\u548c\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cHGMN\u5728\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709GNN\u65b9\u6cd5\u3002", "conclusion": "HGMN\u80fd\u6709\u6548\u5d4c\u5165\u89d2\u8272\u7279\u5f81\u548c\u90bb\u63a5\u4fe1\u606f\u63d0\u4f9b\u4e30\u5bcc\u8282\u70b9\u8868\u5f81\uff0c\u662f\u9002\u7528\u4e8e\u591a\u79cd\u56fe\u5b66\u4e60\u5e94\u7528\u7684\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2508.07151", "pdf": "https://arxiv.org/pdf/2508.07151", "abs": "https://arxiv.org/abs/2508.07151", "authors": ["Roshan Shah"], "title": "American Option Pricing Under Time-Varying Rough Volatility: A Signature-Based Hybrid Framework", "categories": ["q-fin.MF", "q-fin.CP", "91G60, 60G22, 65C30"], "comment": "16 pages, 5 figures, 23 total tables and equations (21 equations),\n  builds on Bayer, Pelizzari, and Zhu (2025) - Signature-based American Option\n  Pricing under Rough Volatility (arXiv:2501.06758). Includes equations and\n  full references", "summary": "We introduce a modular framework that extends the signature method to handle\nAmerican option pricing under evolving volatility roughness. Building on the\nsignature-pricing framework of Bayer et al. (2025), we add three practical\ninnovations. First, we train a gradient-boosted ensemble to estimate the\ntime-varying Hurst parameter H(t) from rolling windows of recent volatility\ndata. Second, we feed these forecasts into a regime switch that chooses either\na rough Bergomi or a calibrated Heston simulator, depending on the predicted\nroughness. Third, we accelerate signature-kernel evaluations with Random\nFourier Features (RFF), cutting computational cost while preserving accuracy.\nEmpirical tests on S&P 500 equity-index options reveal that the assumption of\npersistent roughness is frequently violated, particularly during stable market\nregimes when H(t) approaches or exceeds 0.5. The proposed hybrid framework\nprovides a flexible structure that adapts to changing volatility roughness,\nimproving performance over fixed-roughness baselines and reducing duality gaps\nin some regimes. By integrating a dynamic Hurst parameter estimation pipeline\nwith efficient kernel approximations, we propose to enable tractable, real-time\npricing of American options in dynamic volatility environments.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5757\u5316\u6846\u67b6\u6269\u5c55\u7b7e\u540d\u65b9\u6cd5\u5904\u7406\u968f\u6ce2\u52a8\u7387\u7c97\u7cd9\u5ea6\u53d8\u5316\u7684\u7f8e\u5f0f\u671f\u6743\u5b9a\u4ef7\uff0c\u6709\u4e09\u9879\u521b\u65b0\uff0c\u5b9e\u8bc1\u663e\u793a\u8be5\u6846\u67b6\u7075\u6d3b\u9002\u914d\u4e14\u6027\u80fd\u66f4\u597d\u3002", "motivation": "\u5904\u7406\u968f\u6ce2\u52a8\u7387\u7c97\u7cd9\u5ea6\u53d8\u5316\u7684\u7f8e\u5f0f\u671f\u6743\u5b9a\u4ef7\u95ee\u9898\u3002", "method": "\u57fa\u4e8eBayer\u7b49\u4eba\u7684\u7b7e\u540d\u5b9a\u4ef7\u6846\u67b6\uff0c\u589e\u52a0\u4e09\u9879\u521b\u65b0\uff1a\u8bad\u7ec3\u68af\u5ea6\u63d0\u5347\u96c6\u6210\u4f30\u8ba1\u65f6\u53d8Hurst\u53c2\u6570\uff1b\u6839\u636e\u9884\u6d4b\u7c97\u7cd9\u5ea6\u9009\u62e9\u6a21\u62df\u5668\uff1b\u7528\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u52a0\u901f\u7b7e\u540d\u6838\u8bc4\u4f30\u3002", "result": "\u5bf9\u6807\u51c6\u666e\u5c14500\u80a1\u6307\u671f\u6743\u7684\u5b9e\u8bc1\u6d4b\u8bd5\u8868\u660e\uff0c\u6301\u7eed\u7c97\u7cd9\u5ea6\u5047\u8bbe\u5e38\u88ab\u8fdd\u53cd\uff0c\u6df7\u5408\u6846\u67b6\u80fd\u9002\u5e94\u53d8\u5316\u7684\u6ce2\u52a8\u7387\u7c97\u7cd9\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u96c6\u6210\u52a8\u6001Hurst\u53c2\u6570\u4f30\u8ba1\u6d41\u7a0b\u548c\u9ad8\u6548\u6838\u8fd1\u4f3c\uff0c\u53ef\u5b9e\u73b0\u52a8\u6001\u6ce2\u52a8\u73af\u5883\u4e2d\u7f8e\u5f0f\u671f\u6743\u7684\u5b9e\u65f6\u5b9a\u4ef7\u3002"}}
{"id": "2508.07066", "pdf": "https://arxiv.org/pdf/2508.07066", "abs": "https://arxiv.org/abs/2508.07066", "authors": ["Chenxu Zhao", "Wei Qian", "Aobo Chen", "Mengdi Huai"], "title": "Membership Inference Attacks with False Discovery Rate Control", "categories": ["stat.ML", "cs.CV", "cs.LG"], "comment": null, "summary": "Recent studies have shown that deep learning models are vulnerable to\nmembership inference attacks (MIAs), which aim to infer whether a data record\nwas used to train a target model or not. To analyze and study these\nvulnerabilities, various MIA methods have been proposed. Despite the\nsignificance and popularity of MIAs, existing works on MIAs are limited in\nproviding guarantees on the false discovery rate (FDR), which refers to the\nexpected proportion of false discoveries among the identified positive\ndiscoveries. However, it is very challenging to ensure the false discovery rate\nguarantees, because the underlying distribution is usually unknown, and the\nestimated non-member probabilities often exhibit interdependence. To tackle the\nabove challenges, in this paper, we design a novel membership inference attack\nmethod, which can provide the guarantees on the false discovery rate.\nAdditionally, we show that our method can also provide the marginal probability\nguarantee on labeling true non-member data as member data. Notably, our method\ncan work as a wrapper that can be seamlessly integrated with existing MIA\nmethods in a post-hoc manner, while also providing the FDR control. We perform\nthe theoretical analysis for our method. Extensive experiments in various\nsettings (e.g., the black-box setting and the lifelong learning setting) are\nalso conducted to verify the desirable performance of our method.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MIAs\uff09\u65b9\u6cd5\u96be\u4ee5\u4fdd\u8bc1\u8bef\u53d1\u73b0\u7387\uff08FDR\uff09\u7684\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u80fd\u63d0\u4f9bFDR\u4fdd\u8bc1\u7684\u65b0\u578bMIA\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u73b0\u6709MIAs\u65b9\u6cd5\u5728\u63d0\u4f9b\u8bef\u53d1\u73b0\u7387\u4fdd\u8bc1\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u800c\u4fdd\u8bc1FDR\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u4f5c\u4e3a\u5305\u88c5\u5668\u4e0e\u73b0\u6709MIA\u65b9\u6cd5\u540e\u9a8c\u96c6\u6210\uff0c\u540c\u65f6\u63d0\u4f9bFDR\u63a7\u5236\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9bFDR\u4fdd\u8bc1\uff0c\u8fd8\u80fd\u63d0\u4f9b\u5c06\u771f\u5b9e\u975e\u6210\u5458\u6570\u636e\u6807\u8bb0\u4e3a\u6210\u5458\u6570\u636e\u7684\u8fb9\u9645\u6982\u7387\u4fdd\u8bc1\uff0c\u7406\u8bba\u5206\u6790\u548c\u591a\u573a\u666f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "conclusion": "\u6240\u8bbe\u8ba1\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709MIAs\u65b9\u6cd5\u5728FDR\u4fdd\u8bc1\u65b9\u9762\u7684\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2508.07087", "pdf": "https://arxiv.org/pdf/2508.07087", "abs": "https://arxiv.org/abs/2508.07087", "authors": ["Mohammadreza Daviran", "Brian Lin", "Davood Rafiei"], "title": "SQL-Exchange: Transforming SQL Queries Across Domains", "categories": ["cs.DB", "cs.AI", "cs.CL"], "comment": null, "summary": "We introduce SQL-Exchange, a framework for mapping SQL queries across\ndifferent database schemas by preserving the source query structure while\nadapting domain-specific elements to align with the target schema. We\ninvestigate the conditions under which such mappings are feasible and\nbeneficial, and examine their impact on enhancing the in-context learning\nperformance of text-to-SQL systems as a downstream task. Our comprehensive\nevaluation across multiple model families and benchmark datasets--assessing\nstructural alignment with source queries, execution validity on target\ndatabases, and semantic correctness--demonstrates that SQL-Exchange is\neffective across a wide range of schemas and query types. Our results further\nshow that using mapped queries as in-context examples consistently improves\ntext-to-SQL performance over using queries from the source schema.", "AI": {"tldr": "\u4ecb\u7ecdSQL - Exchange\u6846\u67b6\uff0c\u8bc4\u4f30\u5176\u6548\u679c\u5e76\u8bc1\u660e\u80fd\u63d0\u5347\u6587\u672c\u5230SQL\u7cfb\u7edf\u6027\u80fd", "motivation": "\u7814\u7a76\u4e0d\u540c\u6570\u636e\u5e93\u6a21\u5f0f\u95f4SQL\u67e5\u8be2\u6620\u5c04\u7684\u53ef\u884c\u6027\u548c\u76ca\u5904\uff0c\u63d0\u5347\u6587\u672c\u5230SQL\u7cfb\u7edf\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6027\u80fd", "method": "\u5f15\u5165SQL - Exchange\u6846\u67b6\u8fdb\u884c\u6620\u5c04\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u65cf\u548c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30", "result": "SQL - Exchange\u5728\u591a\u79cd\u6a21\u5f0f\u548c\u67e5\u8be2\u7c7b\u578b\u4e2d\u6709\u6548\uff0c\u4f7f\u7528\u6620\u5c04\u67e5\u8be2\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u793a\u4f8b\u80fd\u63d0\u5347\u6587\u672c\u5230SQL\u6027\u80fd", "conclusion": "SQL - Exchange\u6846\u67b6\u53ef\u884c\u4e14\u6709\u6548\uff0c\u80fd\u63d0\u5347\u6587\u672c\u5230SQL\u7cfb\u7edf\u6027\u80fd"}}
{"id": "2508.07476", "pdf": "https://arxiv.org/pdf/2508.07476", "abs": "https://arxiv.org/abs/2508.07476", "authors": ["Joseph Brunet", "Lisa Chestnutt", "Matthieu Chourrout", "Hector Dejea", "Vaishnavi Sabarigirivasan", "Peter D. Lee", "Andrew C. Cook"], "title": "Cardiotensor: A Python Library for Orientation Analysis and Tractography in 3D Cardiac Imaging", "categories": ["cs.CE"], "comment": "6 pages, 1 figure. Submitted to the Journal of Open Source Software\n  (JOSS). Documentation and source code available at\n  https://josephbrunet.github.io/cardiotensor", "summary": "Understanding the architecture of the human heart requires analysis of its\nmicrostructural organization across scales. With the advent of high-resolution\nimaging techniques such as synchrotron-based tomography, it has become possible\nto visualize entire hearts at micron-scale resolution. However, translating\nthese large, complex volumetric datasets into interpretable, quantitative\ndescriptors of cardiac organization remains a major challenge. Here we present\ncardiotensor, an open-source Python package designed to quantify 3D\ncardiomyocyte orientation in whole- or partial-heart imaging datasets. It\nprovides efficient, scalable implementations of structure tensor analysis,\nenabling extraction of directional metrics such as helical angle (HA),\nintrusion angle (IA), and fractional anisotropy (FA). The package supports\ndatasets reaching teravoxel-scale and is optimized for high-performance\ncomputing environments, including parallel and chunk-based processing\npipelines. In addition, cardiotensor includes tractography functionality to\nreconstruct continuous cardiomyocyte trajectories. This enables multi-scale\nmyoaggregate visualization down to the myocyte level, depending on resolution.\nThese capabilities enable detailed structural mapping of cardiac tissue,\nsupporting the assessment of anatomical continuity and regional organization.", "AI": {"tldr": "\u4ecb\u7ecd\u5f00\u6e90Python\u5305cardiotensor\uff0c\u53ef\u91cf\u5316\u5fc3\u810f\u6210\u50cf\u6570\u636e\u4e2d3D\u5fc3\u808c\u7ec6\u80de\u65b9\u5411\uff0c\u652f\u6301\u5927\u6570\u636e\u96c6\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\uff0c\u8fd8\u5177\u5907\u7ea4\u7ef4\u8ffd\u8e2a\u529f\u80fd\uff0c\u80fd\u8fdb\u884c\u5fc3\u810f\u7ec4\u7ec7\u8be6\u7ec6\u7ed3\u6784\u6620\u5c04\u3002", "motivation": "\u73b0\u6709\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\u6280\u672f\u53ef\u53ef\u89c6\u5316\u5fc3\u810f\uff0c\u4f46\u5c06\u590d\u6742\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u7684\u5fc3\u810f\u7ec4\u7ec7\u5b9a\u91cf\u63cf\u8ff0\u7b26\u4ecd\u662f\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u5de5\u5177\u89e3\u51b3\u3002", "method": "\u5f00\u53d1\u5f00\u6e90Python\u5305cardiotensor\uff0c\u91c7\u7528\u7ed3\u6784\u5f20\u91cf\u5206\u6790\u5e76\u5b9e\u73b0\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u7b97\u6cd5\uff0c\u652f\u6301\u5e76\u884c\u548c\u5206\u5757\u5904\u7406\uff0c\u5177\u5907\u7ea4\u7ef4\u8ffd\u8e2a\u529f\u80fd\u3002", "result": "cardiotensor\u80fd\u63d0\u53d6\u5982\u87ba\u65cb\u89d2\u3001\u4fb5\u5165\u89d2\u548c\u5404\u5411\u5f02\u6027\u5206\u6570\u7b49\u65b9\u5411\u6307\u6807\uff0c\u652f\u6301\u592a\u4f53\u7d20\u7ea7\u6570\u636e\u96c6\uff0c\u53ef\u8fdb\u884c\u591a\u5c3a\u5ea6\u5fc3\u808c\u805a\u96c6\u4f53\u53ef\u89c6\u5316\u3002", "conclusion": "cardiotensor\u53ef\u5b9e\u73b0\u5fc3\u810f\u7ec4\u7ec7\u7684\u8be6\u7ec6\u7ed3\u6784\u6620\u5c04\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30\u89e3\u5256\u8fde\u7eed\u6027\u548c\u533a\u57df\u7ec4\u7ec7\u60c5\u51b5\u3002"}}
{"id": "2508.06828", "pdf": "https://arxiv.org/pdf/2508.06828", "abs": "https://arxiv.org/abs/2508.06828", "authors": ["Wei Luo", "Siyuan Kang", "Qian Di"], "title": "Global Supply Chain Reallocation and Shift under Triple Crises: A U.S.-China Perspective", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "US-China trade tensions, the COVID-19 pandemic, and the Russia-Ukraine\nconflict have disrupted and reshaped global supply chains. Existing studies\ncaution that these tensions may not meaningfully reduce U.S. dependence on\nChina-linked supply chains. This study examines the drivers of this unmet\nreallocation under overlapping geopolitical and public health disruptions. It\ninvestigates how these shocks jointly reconfigured bilateral trade and global\nvalue chain (GVC) participation and positioning among the U.S., China, and\nmajor trading partners during 2016-2023. Using monthly bilateral trade data\nacross all sectors and multi-regional input-output tables for GVC\ndecomposition, we combine a multi-period event-study with structural analysis\nto evaluate trade-flow disruptions and shifts in participation and functional\npositioning within GVCs. We find that China's exports remained robust, expanded\nacross global markets, and sustained a rise in GVC participation, becoming more\nembedded in upstream segments through increased intermediate shipments to Asia\nand Europe. Meanwhile, U.S. imports increasingly shifted toward \"China+1\"\npartners, especially ASEAN, whose trade structures remain closely tied to\nChinese upstream supply chains. These strengthening triangular relationships\nreveal how global reallocation and GVCs have evolved around the U.S. and China\nacross successive shocks. Based on the evidence, we propose a supply chain\nresilience framework defined by three interacting dimensions: the level of GVC\nparticipation, the functional position within the value chain, and a country's\ncapacity to re-couple in the post-shock landscape, conditioned by market\ndiversification, economic complexity, and institutional capability. These\nfindings carry significant implications for trade policy and industrial\nstrategy in an era of geopolitical and geoeconomic fragmentation.", "AI": {"tldr": "\u7814\u7a76\u57282016 - 2023\u5e74\u5730\u7f18\u653f\u6cbb\u548c\u516c\u5171\u536b\u751f\u5e72\u6270\u4e0b\u4e2d\u7f8e\u53ca\u4e3b\u8981\u8d38\u6613\u4f19\u4f34\u53cc\u8fb9\u8d38\u6613\u548c\u5168\u7403\u4ef7\u503c\u94fe\u7684\u91cd\u6784\uff0c\u53d1\u73b0\u4e2d\u56fd\u51fa\u53e3\u7a33\u5065\uff0c\u7f8e\u56fd\u8fdb\u53e3\u5411\u201c\u4e2d\u56fd+1\u201d\u4f19\u4f34\u8f6c\u79fb\uff0c\u63d0\u51fa\u4f9b\u5e94\u94fe\u97e7\u6027\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8b66\u793a\u4e2d\u7f8e\u8d38\u6613\u7d27\u5f20\u7b49\u53ef\u80fd\u65e0\u6cd5\u6709\u6548\u964d\u4f4e\u7f8e\u56fd\u5bf9\u4e2d\u56fd\u4f9b\u5e94\u94fe\u4f9d\u8d56\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u672a\u5b9e\u73b0\u91cd\u65b0\u914d\u7f6e\u7684\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u4f7f\u7528\u5168\u884c\u4e1a\u6708\u5ea6\u53cc\u8fb9\u8d38\u6613\u6570\u636e\u548c\u591a\u533a\u57df\u6295\u5165\u4ea7\u51fa\u8868\u8fdb\u884c\u5168\u7403\u4ef7\u503c\u94fe\u5206\u89e3\uff0c\u7ed3\u5408\u591a\u671f\u4e8b\u4ef6\u7814\u7a76\u4e0e\u7ed3\u6784\u5206\u6790\u3002", "result": "\u4e2d\u56fd\u51fa\u53e3\u7a33\u5065\u3001\u5168\u7403\u5e02\u573a\u6269\u5f20\u3001\u5168\u7403\u4ef7\u503c\u94fe\u53c2\u4e0e\u5ea6\u4e0a\u5347\u4e14\u66f4\u5d4c\u5165\u4e0a\u6e38\uff1b\u7f8e\u56fd\u8fdb\u53e3\u8f6c\u5411\u201c\u4e2d\u56fd+1\u201d\u4f19\u4f34\uff0c\u8fd9\u4e9b\u4f19\u4f34\u4f9b\u5e94\u94fe\u4e0e\u4e2d\u56fd\u7d27\u5bc6\u76f8\u8fde\u3002", "conclusion": "\u63d0\u51fa\u7531\u5168\u7403\u4ef7\u503c\u94fe\u53c2\u4e0e\u5ea6\u3001\u4ef7\u503c\u94fe\u529f\u80fd\u4f4d\u7f6e\u548c\u540e\u51b2\u51fb\u65f6\u671f\u91cd\u65b0\u8026\u5408\u80fd\u529b\u4e09\u4e2a\u7ef4\u5ea6\u6784\u6210\u7684\u4f9b\u5e94\u94fe\u97e7\u6027\u6846\u67b6\uff0c\u5bf9\u8d38\u6613\u653f\u7b56\u548c\u4ea7\u4e1a\u6218\u7565\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.07472", "pdf": "https://arxiv.org/pdf/2508.07472", "abs": "https://arxiv.org/abs/2508.07472", "authors": ["Ramesh Adhikari", "Costas Busch", "Miroslav Popovic"], "title": "On the Efficiency of Dynamic Transaction Scheduling in Blockchain Sharding", "categories": ["cs.DC"], "comment": "15 pages, 2 figures, accepted as a regular paper at 39th\n  International Symposium on Distributed Computing (DISC 2025)", "summary": "Sharding is a technique to speed up transaction processing in blockchains,\nwhere the $n$ processing nodes in the blockchain are divided into $s$ disjoint\ngroups (shards) that can process transactions in parallel. We study dynamic\nscheduling problems on a shard graph $G_s$ where transactions arrive online\nover time and are not known in advance. Each transaction may access at most $k$\nshards, and we denote by $d$ the worst distance between a transaction and its\naccessing (destination) shards (the parameter $d$ is unknown to the shards). To\nhandle different values of $d$, we assume a locality sensitive decomposition of\n$G_s$ into clusters of shards, where every cluster has a leader shard that\nschedules transactions for the cluster. We first examine the simpler case of\nthe stateless model, where leaders are not aware of the current state of the\ntransaction accounts, and we prove a $O(d \\log^2 s \\cdot \\min\\{k, \\sqrt{s}\\})$\ncompetitive ratio for latency. We then consider the stateful model, where\nleader shards gather the current state of accounts, and we prove a $O(\\log\ns\\cdot \\min\\{k, \\sqrt{s}\\}+\\log^2 s)$ competitive ratio for latency. Each\nleader calculates the schedule in polynomial time for each transaction that it\nprocesses. We show that for any $\\epsilon > 0$, approximating the optimal\nschedule within a $(\\min\\{k, \\sqrt{s}\\})^{1 -\\epsilon}$ factor is NP-hard.\nHence, our bound for the stateful model is within a poly-log factor from the\nbest possibly achievable. To the best of our knowledge, this is the first work\nto establish provably efficient dynamic scheduling algorithms for blockchain\nsharding systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.07522", "pdf": "https://arxiv.org/pdf/2508.07522", "abs": "https://arxiv.org/abs/2508.07522", "authors": ["Jim O'Connor", "Derin Gezgin", "Gary B. Parker"], "title": "Evolutionary Optimization of Deep Learning Agents for Sparrow Mahjong", "categories": ["cs.NE"], "comment": "AAAI conference on Artificial Intelligence and Interactive Digital\n  Entertainment", "summary": "We present Evo-Sparrow, a deep learning-based agent for AI decision-making in\nSparrow Mahjong, trained by optimizing Long Short-Term Memory (LSTM) networks\nusing Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Our model\nevaluates board states and optimizes decision policies in a non-deterministic,\npartially observable game environment. Empirical analysis conducted over a\nsignificant number of simulations demonstrates that our model outperforms both\nrandom and rule-based agents, and achieves performance comparable to a Proximal\nPolicy Optimization (PPO) baseline, indicating strong strategic play and robust\npolicy quality. By combining deep learning with evolutionary optimization, our\napproach provides a computationally effective alternative to traditional\nreinforcement learning and gradient-based optimization methods. This research\ncontributes to the broader field of AI game playing, demonstrating the\nviability of hybrid learning strategies for complex stochastic games. These\nfindings also offer potential applications in adaptive decision-making and\nstrategic AI development beyond Sparrow Mahjong.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684Evo - Sparrow\u9ebb\u5c06AI\u51b3\u7b56\u4ee3\u7406\uff0c\u7ed3\u5408LSTM\u548cCMA - ES\uff0c\u5728\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3aAI\u6e38\u620f\u9886\u57df\u63d0\u4f9b\u65b0\u7b56\u7565\u3002", "motivation": "\u5728\u9ebb\u96c0\u9ebb\u5c06\u7684\u975e\u786e\u5b9a\u6027\u3001\u90e8\u5206\u53ef\u89c2\u5bdf\u6e38\u620f\u73af\u5883\u4e2d\u8fdb\u884cAI\u51b3\u7b56\uff0c\u63a2\u7d22\u66ff\u4ee3\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\u7684\u6709\u6548\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u534f\u65b9\u5dee\u77e9\u9635\u81ea\u9002\u5e94\u8fdb\u5316\u7b56\u7565\uff08CMA - ES\uff09\u4f18\u5316\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u8bad\u7ec3Evo - Sparrow\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u5927\u91cf\u6a21\u62df\u4e2d\u4f18\u4e8e\u968f\u673a\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u4ee3\u7406\uff0c\u6027\u80fd\u4e0e\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u57fa\u7ebf\u76f8\u5f53\u3002", "conclusion": "\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u8fdb\u5316\u4f18\u5316\u7684\u65b9\u6cd5\u662f\u590d\u6742\u968f\u673a\u6e38\u620f\u7684\u53ef\u884c\u6df7\u5408\u5b66\u4e60\u7b56\u7565\uff0c\u5bf9AI\u6e38\u620f\u9886\u57df\u6709\u8d21\u732e\uff0c\u5728\u5176\u4ed6\u9886\u57df\u4e5f\u6709\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2508.06668", "pdf": "https://arxiv.org/pdf/2508.06668", "abs": "https://arxiv.org/abs/2508.06668", "authors": ["Jessie Galasso"], "title": "Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis", "categories": ["cs.AI", "cs.IR", "cs.SE"], "comment": null, "summary": "Formal Concept Analysis (FCA) is a mathematical framework for knowledge\nrepresentation and discovery. It performs a hierarchical clustering over a set\nof objects described by attributes, resulting in conceptual structures in which\nobjects are organized depending on the attributes they share. These conceptual\nstructures naturally highlight commonalities and variabilities among similar\nobjects by categorizing them into groups which are then arranged by similarity,\nmaking it particularly appropriate for variability extraction and analysis.\nDespite the potential of FCA, determining which of its properties can be\nleveraged for variability-related tasks (and how) is not always\nstraightforward, partly due to the mathematical orientation of its foundational\nliterature. This paper attempts to bridge part of this gap by gathering a\nselection of properties of the framework which are essential to variability\nanalysis, and how they can be used to interpret diverse variability information\nwithin the resulting conceptual structures.", "AI": {"tldr": "\u672c\u6587\u805a\u7126FCA\u6846\u67b6\uff0c\u6536\u96c6\u5bf9\u53ef\u53d8\u6027\u5206\u6790\u81f3\u5173\u91cd\u8981\u7684\u5c5e\u6027\uff0c\u5e76\u8bf4\u660e\u5982\u4f55\u5728\u6982\u5ff5\u7ed3\u6784\u4e2d\u89e3\u91ca\u53ef\u53d8\u6027\u4fe1\u606f\uff0c\u4ee5\u5f25\u8865FCA\u5728\u53ef\u53d8\u6027\u76f8\u5173\u4efb\u52a1\u5e94\u7528\u4e0a\u7684\u5dee\u8ddd\u3002", "motivation": "FCA\u867d\u9002\u5408\u53ef\u53d8\u6027\u63d0\u53d6\u548c\u5206\u6790\uff0c\u4f46\u56e0\u57fa\u7840\u6587\u732e\u7684\u6570\u5b66\u5bfc\u5411\uff0c\u96be\u4ee5\u660e\u786e\u5176\u54ea\u4e9b\u5c5e\u6027\u53ef\u7528\u4e8e\u53ef\u53d8\u6027\u76f8\u5173\u4efb\u52a1\u53ca\u5982\u4f55\u4f7f\u7528\uff0c\u6545\u6709\u6b64\u7814\u7a76\u3002", "method": "\u6536\u96c6FCA\u6846\u67b6\u4e2d\u5bf9\u53ef\u53d8\u6027\u5206\u6790\u81f3\u5173\u91cd\u8981\u7684\u5c5e\u6027\uff0c\u5e76\u9610\u8ff0\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u5c5e\u6027\u5728\u6982\u5ff5\u7ed3\u6784\u4e2d\u89e3\u91ca\u4e0d\u540c\u7684\u53ef\u53d8\u6027\u4fe1\u606f\u3002", "result": "\u6587\u4e2d\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u4e2d\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2508.06702", "pdf": "https://arxiv.org/pdf/2508.06702", "abs": "https://arxiv.org/abs/2508.06702", "authors": ["Zhao Song", "The Anh Han"], "title": "Emergence of Cooperation and Commitment in Optional Prisoner's Dilemma", "categories": ["cs.GT"], "comment": null, "summary": "Commitment is a well-established mechanism for fostering cooperation in human\nsociety and multi-agent systems. However, existing research has predominantly\nfocused on the commitment that neglects the freedom of players to abstain from\nan interaction, limiting their applicability to many real-world scenarios where\nparticipation is often voluntary. In this paper, we present a two-stage game\nmodel to investigate the evolution of commitment-based behaviours and\ncooperation within the framework of the optional Prisoner's Dilemma game. In\nthe pre-game stage, players decide whether to accept a mutual commitment. Once\nin the game, they choose among cooperation, defection, or exiting, depending on\nthe formation of a pre-game commitment. We find that optional participation\nboosts commitment acceptance but fails to foster cooperation, leading instead\nto widespread exit behaviour. To address this, we then introduce and compare\ntwo institutional incentive approaches: i) a strict one (STRICT-COM) that\nrewards only committed players who cooperate in the game, and ii) a flexible\none (FLEXIBLE-COM) that rewards any committed players who do not defect in the\ngame. The results reveal that, while the strict approach is demonstrably better\nfor promoting cooperation as the flexible rule creates a loophole for an\nopportunistic exit after committing, the flexible rule offers an efficient\nalternative for enhancing social welfare when such opportunistic behaviour\nresults in a high gain. This study highlights the limitations of relying solely\non voluntary participation and commitment to resolving social dilemmas,\nemphasising the importance of well-designed institutional incentives to promote\ncooperation and social welfare effectively.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e24\u9636\u6bb5\u535a\u5f08\u6a21\u578b\u7814\u7a76\u53ef\u9009\u56da\u5f92\u56f0\u5883\u4e2d\u57fa\u4e8e\u627f\u8bfa\u7684\u884c\u4e3a\u548c\u5408\u4f5c\u6f14\u53d8\uff0c\u53d1\u73b0\u53ef\u9009\u53c2\u4e0e\u4e0d\u80fd\u4fc3\u8fdb\u5408\u4f5c\uff0c\u5bf9\u6bd4\u4e24\u79cd\u5236\u5ea6\u6fc0\u52b1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u8bbe\u8ba1\u826f\u597d\u5236\u5ea6\u6fc0\u52b1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5ffd\u89c6\u53c2\u4e0e\u8005\u4e0d\u53c2\u4e0e\u4e92\u52a8\u7684\u81ea\u7531\uff0c\u5176\u5e94\u7528\u4e8e\u73b0\u5b9e\u573a\u666f\u53d7\u9650\uff0c\u9700\u7814\u7a76\u53ef\u9009\u53c2\u4e0e\u4e0b\u627f\u8bfa\u884c\u4e3a\u548c\u5408\u4f5c\u7684\u6f14\u53d8\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u535a\u5f08\u6a21\u578b\uff0c\u5728\u53ef\u9009\u56da\u5f92\u56f0\u5883\u6846\u67b6\u4e0b\u7814\u7a76\uff0c\u540e\u5f15\u5165\u5e76\u6bd4\u8f83\u4e24\u79cd\u5236\u5ea6\u6fc0\u52b1\u65b9\u6cd5\u3002", "result": "\u53ef\u9009\u53c2\u4e0e\u589e\u52a0\u627f\u8bfa\u63a5\u53d7\u4f46\u4e0d\u80fd\u4fc3\u8fdb\u5408\u4f5c\uff0c\u4e25\u683c\u6fc0\u52b1\u65b9\u6cd5\u66f4\u5229\u4e8e\u4fc3\u8fdb\u5408\u4f5c\uff0c\u7075\u6d3b\u65b9\u6cd5\u5728\u673a\u4f1a\u4e3b\u4e49\u884c\u4e3a\u6536\u76ca\u9ad8\u65f6\u80fd\u63d0\u9ad8\u793e\u4f1a\u798f\u5229\u3002", "conclusion": "\u4ec5\u4f9d\u9760\u81ea\u613f\u53c2\u4e0e\u548c\u627f\u8bfa\u89e3\u51b3\u793e\u4f1a\u56f0\u5883\u6709\u5c40\u9650\uff0c\u8bbe\u8ba1\u826f\u597d\u7684\u5236\u5ea6\u6fc0\u52b1\u5bf9\u4fc3\u8fdb\u5408\u4f5c\u548c\u793e\u4f1a\u798f\u5229\u5f88\u91cd\u8981\u3002"}}
{"id": "2508.07210", "pdf": "https://arxiv.org/pdf/2508.07210", "abs": "https://arxiv.org/abs/2508.07210", "authors": ["Chenke Yin", "Li Fan", "Jia Wang", "Dongxiao Hu", "Haichao Zhang", "Chong Zhang", "Yang Xiang"], "title": "Uncertainty-Aware Semantic Decoding for LLM-Based Sequential Recommendation", "categories": ["cs.IR"], "comment": "Accepted by APWeb 2025", "summary": "Large language models have been widely applied to sequential recommendation\ntasks, yet during inference, they continue to rely on decoding strategies\ndeveloped for natural language processing. This creates a mismatch between\ntext-generation objectives and recommendation next item selection objectives.\nThis paper addresses this limitation by proposing an Uncertainty-aware Semantic\nDecoding (USD) framework that combines logit-based clustering with adaptive\nscoring to improve next-item predictions. Our approach clusters items with\nsimilar logit vectors into semantic equivalence groups, then redistributes\nprobability mass within these clusters and computes entropy across them to\ncontrol item scoring and sampling temperature during recommendation inference.\nExperiments on Amazon Product datasets (six domains) gains of 18.5\\% in HR@3,\n11.9\\% in NDCG@3, and 10.8\\% in MRR@3 compared to state-of-the-art baselines.\nHyperparameter analysis confirms the optimal parameters among various settings,\nand experiments on H\\&M, and Netflix datasets indicate that the framework can\nadapt to differing recommendation domains. The experimental results confirm\nthat integrating semantic clustering and uncertainty assessment yields more\nreliable and accurate recommendations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faUSD\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e8f\u5217\u63a8\u8350\u4efb\u52a1\u4e2d\u63a8\u7406\u7b56\u7565\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e8f\u5217\u63a8\u8350\u63a8\u7406\u65f6\u91c7\u7528\u7684\u89e3\u7801\u7b56\u7565\u4e0e\u63a8\u8350\u76ee\u6807\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51faUncertainty - aware Semantic Decoding (USD)\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u4e8e\u5bf9\u6570\u7684\u805a\u7c7b\u548c\u81ea\u9002\u5e94\u8bc4\u5206\u6539\u8fdb\u4e0b\u4e00\u9879\u9884\u6d4b\u3002", "result": "\u5728\u4e9a\u9a6c\u900a\u4ea7\u54c1\u6570\u636e\u96c6\u4e0a\u591a\u9879\u6307\u6807\u63d0\u5347\uff0c\u8d85\u53c2\u6570\u5206\u6790\u786e\u5b9a\u6700\u4f18\u53c2\u6570\uff0c\u5728H&M\u548cNetflix\u6570\u636e\u96c6\u8bc1\u660e\u6846\u67b6\u9002\u5e94\u6027\u3002", "conclusion": "\u6574\u5408\u8bed\u4e49\u805a\u7c7b\u548c\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u80fd\u4ea7\u751f\u66f4\u53ef\u9760\u51c6\u786e\u7684\u63a8\u8350\u3002"}}
{"id": "2508.07067", "pdf": "https://arxiv.org/pdf/2508.07067", "abs": "https://arxiv.org/abs/2508.07067", "authors": ["Honghao Lin", "Hoai-An Nguyen", "William Swartworth", "David P. Woodruff"], "title": "Unbiased Insights: Optimal Streaming Algorithms for $\\ell_p$ Sampling, the Forget Model, and Beyond", "categories": ["cs.DS"], "comment": null, "summary": "We study $\\ell_p$ sampling and frequency moment estimation in a single-pass\ninsertion-only data stream. For $p \\in (0,2)$, we present a nearly\nspace-optimal approximate $\\ell_p$ sampler that uses $\\widetilde{O}(\\log n\n\\log(1/\\delta))$ bits of space and for $p = 2$, we present a sampler with space\ncomplexity $\\widetilde{O}(\\log^2 n \\log(1/\\delta))$. This space complexity is\noptimal for $p \\in (0, 2)$ and improves upon prior work by a $\\log n$ factor.\nWe further extend our construction to a continuous $\\ell_p$ sampler, which\noutputs a valid sample index at every point during the stream.\n  Leveraging these samplers, we design nearly unbiased estimators for $F_p$ in\ndata streams that include forget operations, which reset individual element\nfrequencies and introduce significant non-linear challenges. As a result, we\nobtain near-optimal algorithms for estimating $F_p$ for all $p$ in this model,\noriginally proposed by Pavan, Chakraborty, Vinodchandran, and Meel [PODS'24],\nresolving all three open problems they posed.\n  Furthermore, we generalize this model to what we call the suffix-prefix\ndeletion model, and extend our techniques to estimate entropy as a corollary of\nour moment estimation algorithms. Finally, we show how to handle arbitrary\ncoordinate-wise functions during the stream, for any $g \\in \\mathbb{G}$, where\n$\\mathbb{G}$ includes all (linear or non-linear) contraction functions.", "AI": {"tldr": "\u7814\u7a76\u5355\u904d\u4ec5\u63d2\u5165\u6570\u636e\u6d41\u4e2d\u7684\u2113p\u91c7\u6837\u548c\u9891\u7387\u77e9\u4f30\u8ba1\uff0c\u7ed9\u51fa\u8fd1\u6700\u4f18\u7a7a\u95f4\u590d\u6742\u5ea6\u91c7\u6837\u5668\uff0c\u8bbe\u8ba1\u8fd1\u4e4e\u65e0\u504f\u4f30\u8ba1\u5668\uff0c\u89e3\u51b3\u5f00\u653e\u95ee\u9898\uff0c\u62d3\u5c55\u6a21\u578b\u5e76\u5904\u7406\u4efb\u610f\u5750\u6807\u51fd\u6570\u3002", "motivation": "\u89e3\u51b3\u5355\u904d\u4ec5\u63d2\u5165\u6570\u636e\u6d41\u4e2d\u2113p\u91c7\u6837\u3001\u9891\u7387\u77e9\u4f30\u8ba1\u95ee\u9898\uff0c\u5904\u7406\u542b\u9057\u5fd8\u64cd\u4f5c\u6570\u636e\u6d41\u53ca\u76f8\u5173\u5f00\u653e\u95ee\u9898\uff0c\u62d3\u5c55\u6a21\u578b\u5e76\u4f30\u8ba1\u71b5\u7b49\u3002", "method": "\u6784\u9020\u8fd1\u7a7a\u95f4\u6700\u4f18\u8fd1\u4f3c\u2113p\u91c7\u6837\u5668\uff0c\u5c06\u6784\u9020\u62d3\u5c55\u4e3a\u8fde\u7eed\u2113p\u91c7\u6837\u5668\uff0c\u5229\u7528\u91c7\u6837\u5668\u8bbe\u8ba1\u8fd1\u4e4e\u65e0\u504f\u4f30\u8ba1\u5668\uff0c\u62d3\u5c55\u6a21\u578b\u5e76\u8fd0\u7528\u77e9\u4f30\u8ba1\u7b97\u6cd5\u3002", "result": "\u5f97\u5230p\u2208(0, 2)\u65f6\u6700\u4f18\u7a7a\u95f4\u590d\u6742\u5ea6\u91c7\u6837\u5668\uff0c\u6bd4\u5148\u524d\u5de5\u4f5c\u6709\u6539\u8fdb\uff1b\u89e3\u51b3Pavan\u7b49\u4eba\u63d0\u51fa\u7684\u4e09\u4e2a\u5f00\u653e\u95ee\u9898\uff1b\u80fd\u5728\u65b0\u6a21\u578b\u4e2d\u4f30\u8ba1\u71b5\u548c\u5904\u7406\u4efb\u610f\u5750\u6807\u51fd\u6570\u3002", "conclusion": "\u63d0\u51fa\u8fd1\u6700\u4f18\u7b97\u6cd5\u89e3\u51b3\u6570\u636e\u6d41\u4e2d\u2113p\u91c7\u6837\u3001\u9891\u7387\u77e9\u4f30\u8ba1\u7b49\u4e00\u7cfb\u5217\u95ee\u9898\uff0c\u62d3\u5c55\u6a21\u578b\u53ca\u5e94\u7528\u3002"}}
{"id": "2508.06942", "pdf": "https://arxiv.org/pdf/2508.06942", "abs": "https://arxiv.org/abs/2508.06942", "authors": ["Zhenchang Xing", "Yang Liu", "Zhuo Cheng", "Qing Huang", "Dehai Zhao", "Daniel Sun", "Chenhua Liu"], "title": "When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust \"APIs'' for Human-AI Interaction", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "With the growing capabilities of large language models (LLMs), they are\nincreasingly applied in areas like intelligent customer service, code\ngeneration, and knowledge management. Natural language (NL) prompts act as the\n``APIs'' for human-LLM interaction. To improve prompt quality, best practices\nfor prompt engineering (PE) have been developed, including writing guidelines\nand templates. Building on this, we propose Controlled NL for Prompt (CNL-P),\nwhich not only incorporates PE best practices but also draws on key principles\nfrom software engineering (SE). CNL-P introduces precise grammar structures and\nstrict semantic norms, further eliminating NL's ambiguity, allowing for a\ndeclarative but structured and accurate expression of user intent. This helps\nLLMs better interpret and execute the prompts, leading to more consistent and\nhigher-quality outputs. We also introduce an NL2CNL-P conversion tool based on\nLLMs, enabling users to write prompts in NL, which are then transformed into\nCNL-P format, thus lowering the learning curve of CNL-P. In particular, we\ndevelop a linting tool that checks CNL-P prompts for syntactic and semantic\naccuracy, applying static analysis techniques to NL for the first time.\nExtensive experiments demonstrate that CNL-P enhances the quality of LLM\nresponses through the novel and organic synergy of PE and SE. We believe that\nCNL-P can bridge the gap between emerging PE and traditional SE, laying the\nfoundation for a new programming paradigm centered around NL.", "AI": {"tldr": "\u63d0\u51faControlled NL for Prompt (CNL - P)\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\uff0c\u8fd8\u5f00\u53d1\u8f6c\u6362\u548c\u68c0\u67e5\u5de5\u5177\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u63d0\u5347LLM\u54cd\u5e94\u8d28\u91cf\uff0c\u6709\u671b\u5f00\u521b\u4ee5\u81ea\u7136\u8bed\u8a00\u4e3a\u4e2d\u5fc3\u7684\u7f16\u7a0b\u8303\u5f0f\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u589e\u591a\uff0c\u4e3a\u63d0\u5347\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8d28\u91cf\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u6700\u4f73\u5b9e\u8df5\u548c\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\u3002", "method": "\u63d0\u51faCNL - P\uff0c\u5f15\u5165\u7cbe\u786e\u8bed\u6cd5\u548c\u8bed\u4e49\u89c4\u8303\uff1b\u5f00\u53d1\u57fa\u4e8eLLM\u7684NL2CNL - P\u8f6c\u6362\u5de5\u5177\uff1b\u5f00\u53d1\u9759\u6001\u5206\u6790\u7684\u68c0\u67e5\u5de5\u5177\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cCNL - P\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u8f6f\u4ef6\u5de5\u7a0b\u7684\u534f\u540c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "CNL - P\u80fd\u5f25\u5408\u65b0\u5174\u63d0\u793a\u5de5\u7a0b\u548c\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5dee\u8ddd\uff0c\u4e3a\u4ee5\u81ea\u7136\u8bed\u8a00\u4e3a\u4e2d\u5fc3\u7684\u65b0\u7f16\u7a0b\u8303\u5f0f\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.06588", "pdf": "https://arxiv.org/pdf/2508.06588", "abs": "https://arxiv.org/abs/2508.06588", "authors": ["Zian Zhai", "Fan Li", "Xingyu Tan", "Xiaoyang Wang", "Wenjie Zhang"], "title": "Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Vector Quantization (VQ) has recently emerged as a promising approach for\nlearning discrete representations of graph-structured data. However, a\nfundamental challenge, i.e., codebook collapse, remains underexplored in the\ngraph domain, significantly limiting the expressiveness and generalization of\ngraph tokens.In this paper, we present the first empirical study showing that\ncodebook collapse consistently occurs when applying VQ to graph data, even with\nmitigation strategies proposed in vision or language domains. To understand why\ngraph VQ is particularly vulnerable to collapse, we provide a theoretical\nanalysis and identify two key factors: early assignment imbalances caused by\nredundancy in graph features and structural patterns, and self-reinforcing\noptimization loops in deterministic VQ. To address these issues, we propose\nRGVQ, a novel framework that integrates graph topology and feature similarity\nas explicit regularization signals to enhance codebook utilization and promote\ntoken diversity. RGVQ introduces soft assignments via Gumbel-Softmax\nreparameterization, ensuring that all codewords receive gradient updates. In\naddition, RGVQ incorporates a structure-aware contrastive regularization to\npenalize the token co-assignments among similar node pairs. Extensive\nexperiments demonstrate that RGVQ substantially improves codebook utilization\nand consistently boosts the performance of state-of-the-art graph VQ backbones\nacross multiple downstream tasks, enabling more expressive and transferable\ngraph token representations.", "AI": {"tldr": "\u7814\u7a76\u56fe\u6570\u636e\u5411\u91cf\u91cf\u5316\uff08VQ\uff09\u4e2d\u7801\u672c\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u51faRGVQ\u6846\u67b6\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u56fe\u6570\u636eVQ\u5b58\u5728\u7801\u672c\u5d29\u6e83\u6311\u6218\uff0c\u9650\u5236\u56fe\u4ee4\u724c\u8868\u8fbe\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e14\u73b0\u6709\u7f13\u89e3\u7b56\u7565\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u8fdb\u884c\u7406\u8bba\u5206\u6790\u627e\u51fa\u56feVQ\u6613\u5d29\u6e83\u7684\u4e24\u4e2a\u5173\u952e\u56e0\u7d20\uff0c\u63d0\u51faRGVQ\u6846\u67b6\uff0c\u5f15\u5165\u8f6f\u5206\u914d\u548c\u7ed3\u6784\u611f\u77e5\u5bf9\u6bd4\u6b63\u5219\u5316\u3002", "result": "RGVQ\u5927\u5e45\u63d0\u9ad8\u7801\u672c\u5229\u7528\u7387\uff0c\u63d0\u5347\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u73b0\u6709\u56feVQ\u9aa8\u5e72\u7f51\u7edc\u6027\u80fd\u3002", "conclusion": "RGVQ\u80fd\u4f7f\u56fe\u4ee4\u724c\u8868\u793a\u66f4\u5177\u8868\u8fbe\u6027\u548c\u53ef\u8fc1\u79fb\u6027\u3002"}}
{"id": "2508.07876", "pdf": "https://arxiv.org/pdf/2508.07876", "abs": "https://arxiv.org/abs/2508.07876", "authors": ["Juan-Pablo Ortega", "Florian Rossmannek"], "title": "Stochastic dynamics learning with state-space systems", "categories": ["stat.ML", "cs.LG", "math.DS", "math.ST", "stat.TH", "37B02, 37B55, 37H05, 37N35, 62M10, 68T05"], "comment": null, "summary": "This work advances the theoretical foundations of reservoir computing (RC) by\nproviding a unified treatment of fading memory and the echo state property\n(ESP) in both deterministic and stochastic settings. We investigate state-space\nsystems, a central model class in time series learning, and establish that\nfading memory and solution stability hold generically -- even in the absence of\nthe ESP -- offering a robust explanation for the empirical success of RC models\nwithout strict contractivity conditions. In the stochastic case, we critically\nassess stochastic echo states, proposing a novel distributional perspective\nrooted in attractor dynamics on the space of probability distributions, which\nleads to a rich and coherent theory. Our results extend and generalize previous\nwork on non-autonomous dynamical systems, offering new insights into causality,\nstability, and memory in RC models. This lays the groundwork for reliable\ngenerative modeling of temporal data in both deterministic and stochastic\nregimes.", "AI": {"tldr": "\u672c\u6587\u7edf\u4e00\u5904\u7406\u786e\u5b9a\u548c\u968f\u673a\u73af\u5883\u4e0b\u7684\u6e10\u6d88\u8bb0\u5fc6\u4e0e\u56de\u58f0\u72b6\u6001\u5c5e\u6027\uff0c\u7814\u7a76\u72b6\u6001\u7a7a\u95f4\u7cfb\u7edf\uff0c\u63d0\u51fa\u968f\u673a\u56de\u58f0\u72b6\u6001\u7684\u65b0\u89c6\u89d2\uff0c\u62d3\u5c55\u548c\u63a8\u5e7f\u4e86\u5148\u524d\u5de5\u4f5c\uff0c\u4e3a\u65f6\u5e8f\u6570\u636e\u751f\u6210\u5efa\u6a21\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u63a8\u52a8\u50a8\u5c42\u8ba1\u7b97\uff08RC\uff09\u7684\u7406\u8bba\u57fa\u7840\u53d1\u5c55\uff0c\u89e3\u91caRC\u6a21\u578b\u5728\u65e0\u4e25\u683c\u6536\u7f29\u6761\u4ef6\u4e0b\u7684\u5b9e\u8bc1\u6210\u529f\u539f\u56e0\u3002", "method": "\u7edf\u4e00\u5904\u7406\u786e\u5b9a\u548c\u968f\u673a\u73af\u5883\u4e0b\u7684\u6e10\u6d88\u8bb0\u5fc6\u4e0e\u56de\u58f0\u72b6\u6001\u5c5e\u6027\uff0c\u7814\u7a76\u72b6\u6001\u7a7a\u95f4\u7cfb\u7edf\uff0c\u5bf9\u968f\u673a\u56de\u58f0\u72b6\u6001\u8fdb\u884c\u8bc4\u4f30\u5e76\u63d0\u51fa\u57fa\u4e8e\u6982\u7387\u5206\u5e03\u7a7a\u95f4\u5438\u5f15\u5b50\u52a8\u529b\u5b66\u7684\u65b0\u89c6\u89d2\u3002", "result": "\u8868\u660e\u6e10\u6d88\u8bb0\u5fc6\u548c\u89e3\u51b3\u65b9\u6848\u7a33\u5b9a\u6027\u666e\u904d\u6210\u7acb\uff0c\u63d0\u51fa\u65b0\u7684\u5206\u5e03\u89c6\u89d2\u5f62\u6210\u4e30\u5bcc\u8fde\u8d2f\u7684\u7406\u8bba\uff0c\u62d3\u5c55\u548c\u63a8\u5e7f\u4e86\u5148\u524d\u5de5\u4f5c\u3002", "conclusion": "\u4e3a\u786e\u5b9a\u548c\u968f\u673a\u72b6\u6001\u4e0b\u7684\u65f6\u5e8f\u6570\u636e\u53ef\u9760\u751f\u6210\u5efa\u6a21\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.07218", "pdf": "https://arxiv.org/pdf/2508.07218", "abs": "https://arxiv.org/abs/2508.07218", "authors": ["Yunjun Gao", "Ruijie Zhao", "Zhonggen Li", "Baihua Zheng", "Yifan Zhu", "Zhaoqing Chen"], "title": "Accelerating High-Dimensional Nearest Neighbor Search with Dynamic Query Preference", "categories": ["cs.DB"], "comment": null, "summary": "Approximate Nearest Neighbor Search (ANNS) is a crucial operation in\ndatabases and artificial intelligence. Current graph-based ANNS methods, such\nas HNSW and NSG, have shown remarkable performance but are designed under the\nassumption of a uniform query distribution. However, in practical scenarios,\nuser preferences and query temporal dynamics lead to some queries being\nsearched for more frequently than others. To fully utilize these\ncharacteristics, we propose DQF, a novel Dual-Index Query Framework. This\nframework comprises a dual-layer index structure and a dynamic search strategy\nbased on a decision tree. The dual-layer index structure comprises a hot index\nfor high-frequency nodes and a full index for the entire dataset, allowing for\nthe separate management of hot and cold queries. Furthermore, we propose a\ndynamic search strategy that employs a decision tree to adapt to the specific\ncharacteristics of each query. The decision tree evaluates whether a query is\nof the high-frequency type to detect the opportunities for early termination on\nthe dual-layer, avoiding unnecessary searches in the full index. Experimental\nresults on four real-world datasets demonstrate that the Dual-Index Query\nFramework achieves a significant speedup of 2.0-5.7x over state-of-the-art\nalgorithms while maintaining a 95% recall rate. Importantly, it does not\nrequire full index reconstruction when query distributions change, underscoring\nits efficiency and practicality in dynamic query distribution scenarios.", "AI": {"tldr": "\u63d0\u51faDQF\u53cc\u7d22\u5f15\u67e5\u8be2\u6846\u67b6\u7528\u4e8e\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff0c\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\u6bd4\u73b0\u6709\u7b97\u6cd5\u63d0\u901f2.0 - 5.7\u500d\uff0c\u4fdd\u630195%\u53ec\u56de\u7387\uff0c\u4e14\u67e5\u8be2\u5206\u5e03\u53d8\u5316\u65f6\u65e0\u9700\u91cd\u5efa\u5168\u91cf\u7d22\u5f15\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u65b9\u6cd5\u5047\u8bbe\u67e5\u8be2\u5206\u5e03\u5747\u5300\uff0c\u800c\u5b9e\u9645\u4e2d\u67e5\u8be2\u9891\u7387\u6709\u5dee\u5f02\uff0c\u4e3a\u5229\u7528\u8be5\u7279\u6027\u63d0\u51fa\u65b0\u6846\u67b6\u3002", "method": "\u63d0\u51faDQF\u6846\u67b6\uff0c\u5305\u542b\u53cc\u5c42\u7d22\u5f15\u7ed3\u6784\uff08\u9ad8\u9891\u8282\u70b9\u70ed\u7d22\u5f15\u548c\u5168\u91cf\u6570\u636e\u96c6\u5168\u7d22\u5f15\uff09\u548c\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u52a8\u6001\u641c\u7d22\u7b56\u7565\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cDQF\u6846\u67b6\u6bd4\u73b0\u6709\u7b97\u6cd5\u63d0\u901f2.0 - 5.7\u500d\uff0c\u4fdd\u630195%\u53ec\u56de\u7387\uff0c\u67e5\u8be2\u5206\u5e03\u53d8\u5316\u65f6\u65e0\u9700\u91cd\u5efa\u5168\u91cf\u7d22\u5f15\u3002", "conclusion": "DQF\u6846\u67b6\u5728\u52a8\u6001\u67e5\u8be2\u5206\u5e03\u573a\u666f\u4e0b\u6709\u6548\u4e14\u5b9e\u7528\u3002"}}
{"id": "2508.07831", "pdf": "https://arxiv.org/pdf/2508.07831", "abs": "https://arxiv.org/abs/2508.07831", "authors": ["Moritz Flaschel", "Denisa Martonov\u00e1", "Carina Veil", "Ellen Kuhl"], "title": "Material Fingerprinting: A shortcut to material model discovery without solving optimization problems", "categories": ["cs.CE", "cond-mat.mtrl-sci"], "comment": null, "summary": "We propose Material Fingerprinting, a new method for the rapid discovery of\nmechanical material models from direct or indirect data that avoids solving\npotentially non-convex optimization problems. The core assumption of Material\nFingerprinting is that each material exhibits a unique response when subjected\nto a standardized experimental setup. We can interpret this response as the\nmaterial's fingerprint, essentially a unique identifier that encodes all\npertinent information about the material's mechanical characteristics.\nConsequently, once we have established a database containing fingerprints and\ntheir corresponding mechanical models during an offline phase, we can rapidly\ncharacterize an unseen material in an online phase. This is accomplished by\nmeasuring its fingerprint and employing a pattern recognition algorithm to\nidentify the best matching fingerprint in the database. In our study, we\nexplore this concept in the context of hyperelastic materials, demonstrating\nthe applicability of Material Fingerprinting across different experimental\nsetups. Initially, we examine Material Fingerprinting through experiments\ninvolving homogeneous deformation fields, which provide direct strain-stress\ndata pairs. We then extend this concept to experiments involving complexly\nshaped specimens with heterogeneous deformation fields, which provide indirect\ndisplacement and reaction force measurements. We show that, in both cases,\nMaterial Fingerprinting is an efficient tool for model discovery, bypassing the\nchallenges of potentially non-convex optimization. We believe that Material\nFingerprinting provides a powerful and generalizable framework for rapid\nmaterial model identification across a wide range of experimental designs and\nmaterial behaviors, paving the way for numerous future developments.", "AI": {"tldr": "\u63d0\u51faMaterial Fingerprinting\u65b9\u6cd5\u7528\u4e8e\u5feb\u901f\u53d1\u73b0\u673a\u68b0\u6750\u6599\u6a21\u578b\uff0c\u907f\u514d\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u5728\u8d85\u5f39\u6027\u6750\u6599\u7814\u7a76\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u4ece\u76f4\u63a5\u6216\u95f4\u63a5\u6570\u636e\u4e2d\u5feb\u901f\u53d1\u73b0\u673a\u68b0\u6750\u6599\u6a21\u578b\u65f6\u53ef\u80fd\u9047\u5230\u7684\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002", "method": "\u5efa\u7acb\u5305\u542b\u6307\u7eb9\u53ca\u5176\u5bf9\u5e94\u673a\u68b0\u6a21\u578b\u7684\u6570\u636e\u5e93\uff0c\u5728\u7ebf\u9636\u6bb5\u6d4b\u91cf\u672a\u77e5\u6750\u6599\u6307\u7eb9\u5e76\u901a\u8fc7\u6a21\u5f0f\u8bc6\u522b\u7b97\u6cd5\u5339\u914d\u3002\u5148\u5728\u5747\u5300\u53d8\u5f62\u573a\u5b9e\u9a8c\u4e2d\u7814\u7a76\uff0c\u518d\u6269\u5c55\u5230\u590d\u6742\u5f62\u72b6\u8bd5\u6837\u7684\u975e\u5747\u5300\u53d8\u5f62\u573a\u5b9e\u9a8c\u3002", "result": "\u5728\u4e24\u79cd\u5b9e\u9a8c\u60c5\u51b5\u4e0b\uff0cMaterial Fingerprinting\u90fd\u662f\u6709\u6548\u7684\u6a21\u578b\u53d1\u73b0\u5de5\u5177\uff0c\u7ed5\u8fc7\u4e86\u975e\u51f8\u4f18\u5316\u6311\u6218\u3002", "conclusion": "Material Fingerprinting\u4e3a\u5e7f\u6cdb\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u6750\u6599\u884c\u4e3a\u7684\u5feb\u901f\u6750\u6599\u6a21\u578b\u8bc6\u522b\u63d0\u4f9b\u5f3a\u5927\u4e14\u901a\u7528\u7684\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.07082", "pdf": "https://arxiv.org/pdf/2508.07082", "abs": "https://arxiv.org/abs/2508.07082", "authors": ["Jonathan Benchimol", "Inon Gamrasni", "Michael Kahn", "Sigal Ribon", "Yossi Saadon", "Noam Ben-Ze'ev", "Asaf Segal", "Yitzchak Shizgal"], "title": "The Interaction Between Domestic Monetary Policy and Macroprudential Policy in Israel", "categories": ["econ.GN", "q-fin.EC", "q-fin.GN", "stat.AP"], "comment": null, "summary": "The global financial crisis (GFC) triggered the use of macroprudential\npolicies imposed on the banking sector. Using bank-level panel data for Israel\nfor the period 2004-2019, we find that domestic macroprudential measures\nchanged the composition of bank credit growth but did not affect the total\ncredit growth rate. Specifically, we show that macroprudential measures\ntargeted at the housing sector moderated housing credit growth but tended to\nincrease business credit growth. We also find that accommodative monetary\npolicy surprises tended to increase bank credit growth before the GFC. We show\nthat accommodative monetary policy surprises increased consumer credit when\ninteracting with macroprudential policies targeting the housing market.\nAccommodative monetary policy interacted with nonhousing macroprudential\nmeasures to increase total credit.", "AI": {"tldr": "\u5229\u7528\u4ee5\u8272\u5217\u94f6\u884c\u6570\u636e\u7814\u7a76\u53d1\u73b0\uff0c\u56fd\u5185\u5b8f\u89c2\u5ba1\u614e\u63aa\u65bd\u6539\u53d8\u94f6\u884c\u4fe1\u8d37\u589e\u957f\u6784\u6210\u4f46\u4e0d\u5f71\u54cd\u603b\u4fe1\u8d37\u589e\u957f\u7387\uff0c\u5bbd\u677e\u8d27\u5e01\u653f\u7b56\u4e0e\u5b8f\u89c2\u5ba1\u614e\u653f\u7b56\u76f8\u4e92\u4f5c\u7528\u5f71\u54cd\u4e0d\u540c\u7c7b\u578b\u4fe1\u8d37\u3002", "motivation": "\u5168\u7403\u91d1\u878d\u5371\u673a\u4fc3\u4f7f\u5bf9\u94f6\u884c\u4e1a\u5b9e\u65bd\u5b8f\u89c2\u5ba1\u614e\u653f\u7b56\uff0c\u7814\u7a76\u5176\u5bf9\u94f6\u884c\u4fe1\u8d37\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u75282004 - 2019\u5e74\u4ee5\u8272\u5217\u94f6\u884c\u5c42\u9762\u7684\u9762\u677f\u6570\u636e\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u5b8f\u89c2\u5ba1\u614e\u63aa\u65bd\u6539\u53d8\u4fe1\u8d37\u6784\u6210\uff0c\u9488\u5bf9\u4f4f\u623f\u90e8\u95e8\u7684\u63aa\u65bd\u6291\u5236\u4f4f\u623f\u4fe1\u8d37\u3001\u589e\u52a0\u5546\u4e1a\u4fe1\u8d37\uff1b\u5bbd\u677e\u8d27\u5e01\u653f\u7b56\u610f\u5916\u5728\u5371\u673a\u524d\u589e\u52a0\u94f6\u884c\u4fe1\u8d37\uff0c\u4e0e\u4f4f\u623f\u5e02\u573a\u5b8f\u89c2\u5ba1\u614e\u653f\u7b56\u76f8\u4e92\u4f5c\u7528\u589e\u52a0\u6d88\u8d39\u4fe1\u8d37\uff0c\u4e0e\u975e\u4f4f\u623f\u5b8f\u89c2\u5ba1\u614e\u63aa\u65bd\u76f8\u4e92\u4f5c\u7528\u589e\u52a0\u603b\u4fe1\u8d37\u3002", "conclusion": "\u5b8f\u89c2\u5ba1\u614e\u63aa\u65bd\u548c\u8d27\u5e01\u653f\u7b56\u5bf9\u94f6\u884c\u4fe1\u8d37\u6709\u4e0d\u540c\u5f71\u54cd\uff0c\u4e14\u4e24\u8005\u76f8\u4e92\u4f5c\u7528\u5f71\u54cd\u4e0d\u540c\u7c7b\u578b\u4fe1\u8d37\u3002"}}
{"id": "2508.07605", "pdf": "https://arxiv.org/pdf/2508.07605", "abs": "https://arxiv.org/abs/2508.07605", "authors": ["Zhong Zheng", "Michael E. Papka", "Zhiling Lan"], "title": "Coordinated Power Management on Heterogeneous Systems", "categories": ["cs.DC"], "comment": null, "summary": "Performance prediction is essential for energy-efficient computing in\nheterogeneous computing systems that integrate CPUs and GPUs. However,\ntraditional performance modeling methods often rely on exhaustive offline\nprofiling, which becomes impractical due to the large setting space and the\nhigh cost of profiling large-scale applications. In this paper, we present\nOPEN, a framework consists of offline and online phases. The offline phase\ninvolves building a performance predictor and constructing an initial dense\nmatrix. In the online phase, OPEN performs lightweight online profiling, and\nleverages the performance predictor with collaborative filtering to make\nperformance prediction. We evaluate OPEN on multiple heterogeneous systems,\nincluding those equipped with A100 and A30 GPUs. Results show that OPEN\nachieves prediction accuracy up to 98.29\\%. This demonstrates that OPEN\neffectively reduces profiling cost while maintaining high accuracy, making it\npractical for power-aware performance modeling in modern HPC environments.\nOverall, OPEN provides a lightweight solution for performance prediction under\npower constraints, enabling better runtime decisions in power-aware computing\nenvironments.", "AI": {"tldr": "\u63d0\u51faOPEN\u6846\u67b6\u7528\u4e8e\u5f02\u6784\u8ba1\u7b97\u7cfb\u7edf\u6027\u80fd\u9884\u6d4b\uff0c\u5728\u591a\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u51c6\u786e\u7387\u8fbe98.29%\uff0c\u80fd\u964d\u4f4e\u5206\u6790\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u6027\u80fd\u5efa\u6a21\u65b9\u6cd5\u4f9d\u8d56\u79bb\u7ebf\u5206\u6790\uff0c\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u56e0\u8bbe\u7f6e\u7a7a\u95f4\u5927\u3001\u6210\u672c\u9ad8\u800c\u4e0d\u5b9e\u7528\u3002", "method": "\u6846\u67b6\u5206\u79bb\u7ebf\u548c\u5728\u7ebf\u9636\u6bb5\uff0c\u79bb\u7ebf\u6784\u5efa\u6027\u80fd\u9884\u6d4b\u5668\u548c\u521d\u59cb\u5bc6\u96c6\u77e9\u9635\uff0c\u5728\u7ebf\u8fdb\u884c\u8f7b\u91cf\u7ea7\u5206\u6790\u5e76\u7ed3\u5408\u534f\u540c\u8fc7\u6ee4\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u5f02\u6784\u7cfb\u7edf\u8bc4\u4f30\u4e2d\uff0cOPEN\u9884\u6d4b\u51c6\u786e\u7387\u8fbe98.29%\u3002", "conclusion": "OPEN\u80fd\u6709\u6548\u964d\u4f4e\u5206\u6790\u6210\u672c\u5e76\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u4e3a\u529f\u7387\u53d7\u9650\u4e0b\u6027\u80fd\u9884\u6d4b\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07691", "pdf": "https://arxiv.org/pdf/2508.07691", "abs": "https://arxiv.org/abs/2508.07691", "authors": ["Tomohiro Harada", "Enrique Alba", "Gabriel Luque"], "title": "Energy and Quality of Surrogate-Assisted Search Algorithms: a First Analysis", "categories": ["cs.NE"], "comment": "8 pages, 8 figures, 2024 IEEE Congress on Evolutionary Computation\n  (CEC)", "summary": "Solving complex real problems often demands advanced algorithms, and then\ncontinuous improvements in the internal operations of a search technique are\nneeded. Hybrid algorithms, parallel techniques, theoretical advances, and much\nmore are needed to transform a general search algorithm into an efficient,\nuseful one in practice. In this paper, we study how surrogates are helping\nmetaheuristics from an important and understudied point of view: their energy\nprofile. Even if surrogates are a great idea for substituting a time-demanding\ncomplex fitness function, the energy profile, general efficiency, and accuracy\nof the resulting surrogate-assisted metaheuristic still need considerable\nresearch. In this work, we make a first step in analyzing particle swarm\noptimization in different versions (including pre-trained and retrained neural\nnetworks as surrogates) for its energy profile (for both processor and memory),\nplus a further study on the surrogate accuracy to properly drive the search\ntowards an acceptable solution. Our conclusions shed new light on this topic\nand could be understood as the first step towards a methodology for assessing\nsurrogate-assisted algorithms not only accounting for time or numerical\nefficiency but also for energy and surrogate accuracy for a better, more\nholistic characterization of optimization and learning techniques.", "AI": {"tldr": "\u672c\u6587\u4ece\u80fd\u91cf\u6d88\u8017\u89d2\u5ea6\u7814\u7a76\u66ff\u4ee3\u6a21\u578b\u5bf9\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u5e2e\u52a9\uff0c\u5206\u6790\u4e0d\u540c\u7248\u672c\u7c92\u5b50\u7fa4\u4f18\u5316\u7b97\u6cd5\u7684\u80fd\u91cf\u6d88\u8017\u548c\u66ff\u4ee3\u6a21\u578b\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u95ee\u9898\u9700\u6539\u8fdb\u641c\u7d22\u7b97\u6cd5\uff0c\u66ff\u4ee3\u8f85\u52a9\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u80fd\u91cf\u6d88\u8017\u3001\u6548\u7387\u548c\u51c6\u786e\u6027\u5c1a\u9700\u7814\u7a76\u3002", "method": "\u5206\u6790\u4e0d\u540c\u7248\u672c\uff08\u542b\u9884\u8bad\u7ec3\u548c\u518d\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u66ff\u4ee3\u6a21\u578b\uff09\u7684\u7c92\u5b50\u7fa4\u4f18\u5316\u7b97\u6cd5\u7684\u5904\u7406\u5668\u548c\u5185\u5b58\u80fd\u91cf\u6d88\u8017\uff0c\u7814\u7a76\u66ff\u4ee3\u6a21\u578b\u51c6\u786e\u6027\u4ee5\u5f15\u5bfc\u641c\u7d22\u3002", "result": "\u5f97\u51fa\u76f8\u5173\u7ed3\u8bba\uff0c\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "conclusion": "\u7ed3\u8bba\u4e3a\u8bc4\u4f30\u66ff\u4ee3\u8f85\u52a9\u7b97\u6cd5\u63d0\u4f9b\u65b0\u601d\u8def\uff0c\u8003\u8651\u80fd\u91cf\u548c\u66ff\u4ee3\u6a21\u578b\u51c6\u786e\u6027\u4ee5\u66f4\u5168\u9762\u523b\u753b\u4f18\u5316\u548c\u5b66\u4e60\u6280\u672f\u3002"}}
{"id": "2508.06674", "pdf": "https://arxiv.org/pdf/2508.06674", "abs": "https://arxiv.org/abs/2508.06674", "authors": ["Weijie Shi", "Yue Cui", "Hao Chen", "Jiaming Li", "Mengze Li", "Jia Zhu", "Jiajie Xu", "Xiaofang Zhou"], "title": "Zero-Shot Cellular Trajectory Map Matching", "categories": ["cs.AI"], "comment": null, "summary": "Cellular Trajectory Map-Matching (CTMM) aims to align cellular location\nsequences to road networks, which is a necessary preprocessing in\nlocation-based services on web platforms like Google Maps, including navigation\nand route optimization. Current approaches mainly rely on ID-based features and\nregion-specific data to learn correlations between cell towers and roads,\nlimiting their adaptability to unexplored areas. To enable high-accuracy CTMM\nwithout additional training in target regions, Zero-shot CTMM requires to\nextract not only region-adaptive features, but also sequential and location\nuncertainty to alleviate positioning errors in cellular data. In this paper, we\npropose a pixel-based trajectory calibration assistant for zero-shot CTMM,\nwhich takes advantage of transferable geospatial knowledge to calibrate\npixelated trajectory, and then guide the path-finding process at the road\nnetwork level. To enhance knowledge sharing across similar regions, a Gaussian\nmixture model is incorporated into VAE, enabling the identification of\nscenario-adaptive experts through soft clustering. To mitigate high positioning\nerrors, a spatial-temporal awareness module is designed to capture sequential\nfeatures and location uncertainty, thereby facilitating the inference of\napproximate user positions. Finally, a constrained path-finding algorithm is\nemployed to reconstruct the road ID sequence, ensuring topological validity\nwithin the road network. This process is guided by the calibrated trajectory\nwhile optimizing for the shortest feasible path, thus minimizing unnecessary\ndetours. Extensive experiments demonstrate that our model outperforms existing\nmethods in zero-shot CTMM by 16.8\\%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u50cf\u7d20\u8f68\u8ff9\u6821\u51c6\u52a9\u624b\u7528\u4e8e\u96f6\u6837\u672cCTMM\uff0c\u901a\u8fc7\u7ed3\u5408\u5730\u7406\u77e5\u8bc6\u3001\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u3001\u65f6\u7a7a\u611f\u77e5\u6a21\u5757\u548c\u7ea6\u675f\u5bfb\u8def\u7b97\u6cd5\uff0c\u63d0\u5347\u96f6\u6837\u672cCTMM\u6027\u80fd\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd516.8%\u3002", "motivation": "\u73b0\u6709CTMM\u65b9\u6cd5\u4f9d\u8d56\u7279\u5b9a\u533a\u57df\u6570\u636e\uff0c\u9002\u5e94\u6027\u5dee\uff0c\u9700\u5b9e\u73b0\u65e0\u989d\u5916\u8bad\u7ec3\u7684\u9ad8\u7cbe\u5ea6\u96f6\u6837\u672cCTMM\u3002", "method": "\u63d0\u51fa\u50cf\u7d20\u8f68\u8ff9\u6821\u51c6\u52a9\u624b\uff0c\u7ed3\u5408\u53ef\u8fc1\u79fb\u5730\u7406\u77e5\u8bc6\u6821\u51c6\u8f68\u8ff9\uff1b\u5c06\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u878d\u5165VAE\u8fdb\u884c\u8f6f\u805a\u7c7b\uff1b\u8bbe\u8ba1\u65f6\u7a7a\u611f\u77e5\u6a21\u5757\u6355\u6349\u5e8f\u5217\u7279\u5f81\u548c\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\uff1b\u91c7\u7528\u7ea6\u675f\u5bfb\u8def\u7b97\u6cd5\u91cd\u5efa\u9053\u8defID\u5e8f\u5217\u3002", "result": "\u6a21\u578b\u5728\u96f6\u6837\u672cCTMM\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u63d0\u534716.8%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u96f6\u6837\u672cCTMM\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.07145", "pdf": "https://arxiv.org/pdf/2508.07145", "abs": "https://arxiv.org/abs/2508.07145", "authors": ["Ivan Geffner", "Erez Karpas", "Moshe Tennenholtz"], "title": "When Competition Helps: Achieving Optimal Traffic Flow with Multiple Autonomous Planners", "categories": ["cs.GT"], "comment": null, "summary": "The inefficiency of selfish routing in congested networks is a classical\nproblem in algorithmic game theory, often captured by the Price of Anarchy\n(i.e., the ratio between the social cost of decentralized decisions and that of\na centrally optimized solution.) With the advent of autonomous vehicles,\ncapable of receiving and executing centrally assigned routes, it is natural to\nask whether their deployment can eliminate this inefficiency. At first glance,\na central authority could simply compute an optimal traffic assignment and\ninstruct each vehicle to follow its assigned path. However, this vision\noverlooks critical challenges: routes must be individually rational (no vehicle\nhas an incentive to deviate), and in practice, multiple planning agents (e.g.,\ndifferent companies) may coexist and compete. Surprisingly, we show that such\ncompetition is not merely an obstacle but a necessary ingredient for achieving\noptimal outcomes. In this work, we design a routing mechanism that embraces\ncompetition and converges to an optimal assignment, starting from the classical\nPigou network as a foundational case.", "AI": {"tldr": "\u7814\u7a76\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u90e8\u7f72\u80fd\u5426\u6d88\u9664\u62e5\u5835\u7f51\u7edc\u81ea\u79c1\u8def\u7531\u4f4e\u6548\u95ee\u9898\uff0c\u8bbe\u8ba1\u542b\u7ade\u4e89\u7684\u8def\u7531\u673a\u5236\u8fbe\u6700\u4f18\u5206\u914d\u3002", "motivation": "\u63a2\u8ba8\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u90e8\u7f72\u80fd\u5426\u6d88\u9664\u62e5\u5835\u7f51\u7edc\u81ea\u79c1\u8def\u7531\u7684\u4f4e\u6548\u6027\u3002", "method": "\u4ece\u7ecf\u5178Pigou\u7f51\u7edc\u51fa\u53d1\uff0c\u8bbe\u8ba1\u4e00\u79cd\u63a5\u7eb3\u7ade\u4e89\u7684\u8def\u7531\u673a\u5236\u3002", "result": "\u8868\u660e\u7ade\u4e89\u4e0d\u53ea\u662f\u969c\u788d\uff0c\u8fd8\u662f\u5b9e\u73b0\u6700\u4f18\u7ed3\u679c\u7684\u5fc5\u8981\u56e0\u7d20\uff0c\u8bbe\u8ba1\u7684\u673a\u5236\u80fd\u6536\u655b\u5230\u6700\u4f18\u5206\u914d\u3002", "conclusion": "\u542b\u7ade\u4e89\u7684\u8def\u7531\u673a\u5236\u53ef\u89e3\u51b3\u62e5\u5835\u7f51\u7edc\u81ea\u79c1\u8def\u7531\u7684\u4f4e\u6548\u95ee\u9898\u3002"}}
{"id": "2508.07223", "pdf": "https://arxiv.org/pdf/2508.07223", "abs": "https://arxiv.org/abs/2508.07223", "authors": ["Guanchen Wang", "Mingming Ha", "Tianbao Ma", "Linxun Chen", "Zhaojie Liu", "Guorui Zhou", "Kun Gai"], "title": "Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "In recent years, there has been growing interest in leveraging the impressive\ngeneralization capabilities and reasoning ability of large language models\n(LLMs) to improve the performance of recommenders. With this operation,\nrecommenders can access and learn the additional world knowledge and reasoning\ninformation via LLMs. However, in general, for different users and items, the\nworld knowledge derived from LLMs suffers from issues of hallucination, content\nredundant, and information homogenization. Directly feeding the generated\nresponse embeddings into the recommendation model can lead to unavoidable\nperformance deterioration. To address these challenges, we propose a Knowledge\nSelection \\& Exploitation Recommendation (KSER) framework, which effectively\nselect and extracts the high-quality knowledge from LLMs. The framework\nconsists of two key components: a knowledge filtering module and a embedding\nspaces alignment module. In the knowledge filtering module, a Embedding\nSelection Filter Network (ESFNet) is designed to assign adaptive weights to\ndifferent knowledge chunks in different knowledge fields. In the space\nalignment module, an attention-based architecture is proposed to align the\nsemantic embeddings from LLMs with the feature space used to train the\nrecommendation models. In addition, two training\nstrategies--\\textbf{all-parameters training} and \\textbf{extractor-only\ntraining}--are proposed to flexibly adapt to different downstream tasks and\napplication scenarios, where the extractor-only training strategy offers a\nnovel perspective on knowledge-augmented recommendation. Experimental results\nvalidate the necessity and effectiveness of both the knowledge filtering and\nalignment modules, and further demonstrate the efficiency and effectiveness of\nthe extractor-only training strategy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faKSER\u6846\u67b6\u89e3\u51b3LLM\u77e5\u8bc6\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u542b\u77e5\u8bc6\u8fc7\u6ee4\u548c\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\u6a21\u5757\u53ca\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u65f6\uff0c\u5176\u63d0\u4f9b\u7684\u77e5\u8bc6\u5b58\u5728\u5e7b\u89c9\u3001\u5197\u4f59\u548c\u4fe1\u606f\u540c\u8d28\u5316\u95ee\u9898\uff0c\u76f4\u63a5\u4f7f\u7528\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faKSER\u6846\u67b6\uff0c\u5305\u542b\u77e5\u8bc6\u8fc7\u6ee4\u6a21\u5757\uff08ESFNet\u5206\u914d\u6743\u91cd\uff09\u548c\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\u6a21\u5757\uff08\u57fa\u4e8e\u6ce8\u610f\u529b\u67b6\u6784\u5bf9\u9f50\u8bed\u4e49\u5d4c\u5165\uff09\uff0c\u5e76\u63d0\u51fa\u5168\u53c2\u6570\u8bad\u7ec3\u548c\u4ec5\u63d0\u53d6\u5668\u8bad\u7ec3\u4e24\u79cd\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u77e5\u8bc6\u8fc7\u6ee4\u548c\u5bf9\u9f50\u6a21\u5757\u7684\u5fc5\u8981\u6027\u548c\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u4ec5\u63d0\u53d6\u5668\u8bad\u7ec3\u7b56\u7565\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002", "conclusion": "KSER\u6846\u67b6\u53ca\u8bad\u7ec3\u7b56\u7565\u80fd\u6709\u6548\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2508.07446", "pdf": "https://arxiv.org/pdf/2508.07446", "abs": "https://arxiv.org/abs/2508.07446", "authors": ["Daniel Brous", "David Shmoys"], "title": "Optimizing Districting Plans to Maximize Majority-Minority Districts via IPs and Local Search", "categories": ["cs.DS", "cs.AI", "cs.CY"], "comment": "12 pages, 4 figures, 1 table", "summary": "In redistricting litigation, effective enforcement of the Voting Rights Act\nhas often involved providing the court with districting plans that display a\nlarger number of majority-minority districts than the current proposal (as was\ntrue, for example, in what followed Allen v. Milligan concerning the\ncongressional districting plan for Alabama in 2023). Recent work by Cannon et\nal. proposed a heuristic algorithm for generating plans to optimize\nmajority-minority districts, which they called short bursts; that algorithm\nrelies on a sophisticated random walk over the space of all plans,\ntransitioning in bursts, where the initial plan for each burst is the most\nsuccessful plan from the previous burst. We propose a method based on integer\nprogramming, where we build upon another previous work, the stochastic\nhierarchical partitioning algorithm, which heuristically generates a robust set\nof potential districts (viewed as columns in a standard set partitioning\nformulation); that approach was designed to optimize a different notion of\nfairness across a statewide plan. We design a new column generation algorithm\nto find plans via integer programming that outperforms short bursts on multiple\ndata sets in generating statewide plans with significantly more\nmajority-minority districts. These results also rely on a new local\nre-optimization algorithm to iteratively improve on any baseline solution, as\nwell as an algorithm to increase the compactness of districts in plans\ngenerated (without impacting the number of majority-minority districts).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6574\u6570\u89c4\u5212\u7684\u65b9\u6cd5\u751f\u6210\u9009\u533a\u5212\u5206\u65b9\u6848\uff0c\u5728\u751f\u6210\u591a\u6570\u5c11\u6570\u65cf\u88d4\u9009\u533a\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5e76\u4ecb\u7ecd\u4e86\u76f8\u5173\u4f18\u5316\u7b97\u6cd5\u3002", "motivation": "\u5728\u9009\u533a\u5212\u5206\u8bc9\u8bbc\u4e2d\uff0c\u4e3a\u6709\u6548\u6267\u884c\u300a\u9009\u4e3e\u6743\u6cd5\u6848\u300b\uff0c\u9700\u63d0\u4f9b\u542b\u66f4\u591a\u591a\u6570\u5c11\u6570\u65cf\u88d4\u9009\u533a\u7684\u5212\u5206\u65b9\u6848\uff0c\u73b0\u6709\u542f\u53d1\u5f0f\u7b97\u6cd5\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8e\u6574\u6570\u89c4\u5212\uff0c\u6539\u8fdb\u968f\u673a\u5206\u5c42\u5206\u533a\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u65b0\u7684\u5217\u751f\u6210\u7b97\u6cd5\uff0c\u8fd8\u6709\u5c40\u90e8\u91cd\u65b0\u4f18\u5316\u7b97\u6cd5\u548c\u63d0\u9ad8\u9009\u533a\u7d27\u51d1\u5ea6\u7684\u7b97\u6cd5\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u751f\u6210\u7684\u5168\u5dde\u5212\u5206\u65b9\u6848\u4e2d\u591a\u6570\u5c11\u6570\u65cf\u88d4\u9009\u533a\u6570\u91cf\u663e\u8457\u66f4\u591a\uff0c\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6574\u6570\u89c4\u5212\u7684\u65b9\u6cd5\u5728\u751f\u6210\u591a\u6570\u5c11\u6570\u65cf\u88d4\u9009\u533a\u7684\u5168\u5dde\u5212\u5206\u65b9\u6848\u4e0a\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2508.06589", "pdf": "https://arxiv.org/pdf/2508.06589", "abs": "https://arxiv.org/abs/2508.06589", "authors": ["Xinglin Zhao", "Yanwen Wang", "Xiaobo Liu", "Yanrong Hao", "Rui Cao", "Xin Wen"], "title": "A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Computer-aided diagnosis (CAD) systems play a crucial role in analyzing\nneuroimaging data for neurological and psychiatric disorders. However,\nsmall-sample studies suffer from low reproducibility, while large-scale\ndatasets introduce confounding heterogeneity due to multiple disease subtypes\nbeing labeled under a single category. To address these challenges, we propose\na novel federated learning framework tailored for neuroimaging CAD systems. Our\napproach includes a dynamic navigation module that routes samples to the most\nsuitable local models based on latent subtype representations, and a\nmeta-integration module that combines predictions from heterogeneous local\nmodels into a unified diagnostic output. We evaluated our framework using a\ncomprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100\nhealthy controls across multiple study cohorts. Experimental results\ndemonstrate significant improvements in diagnostic accuracy and robustness\ncompared to traditional methods. Specifically, our framework achieved an\naverage accuracy of 74.06\\% across all tested sites, showcasing its\neffectiveness in handling subtype heterogeneity and enhancing model\ngeneralizability. Ablation studies further confirmed the importance of both the\ndynamic navigation and meta-integration modules in improving performance. By\naddressing data heterogeneity and subtype confounding, our framework advances\nreliable and reproducible neuroimaging CAD systems, offering significant\npotential for personalized medicine and clinical decision-making in neurology\nand psychiatry.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u795e\u7ecf\u5f71\u50cf\u8ba1\u7b97\u673a\u8f85\u52a9\u8bca\u65ad\u7cfb\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\uff0c\u80fd\u5e94\u5bf9\u6570\u636e\u5f02\u8d28\u6027\u548c\u4e9a\u578b\u6df7\u6dc6\u95ee\u9898\u3002", "motivation": "\u5c0f\u6837\u672c\u7814\u7a76\u53ef\u91cd\u590d\u6027\u4f4e\uff0c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5b58\u5728\u4e9a\u578b\u6df7\u6dc6\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u795e\u7ecf\u5f71\u50cf\u8ba1\u7b97\u673a\u8f85\u52a9\u8bca\u65ad\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u542b\u52a8\u6001\u5bfc\u822a\u6a21\u5757\u548c\u5143\u96c6\u6210\u6a21\u5757\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\u8bca\u65ad\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\uff0c\u5e73\u5747\u51c6\u786e\u7387\u8fbe74.06%\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e24\u6a21\u5757\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u89e3\u51b3\u4e86\u6570\u636e\u5f02\u8d28\u6027\u548c\u4e9a\u578b\u6df7\u6dc6\u95ee\u9898\uff0c\u63a8\u52a8\u4e86\u53ef\u9760\u4e14\u53ef\u91cd\u590d\u7684\u795e\u7ecf\u5f71\u50cfCAD\u7cfb\u7edf\u53d1\u5c55\uff0c\u5728\u795e\u7ecf\u548c\u7cbe\u795e\u533b\u5b66\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.07914", "pdf": "https://arxiv.org/pdf/2508.07914", "abs": "https://arxiv.org/abs/2508.07914", "authors": ["Olivier Jeunen"], "title": "Meta Off-Policy Estimation", "categories": ["stat.ML", "cs.IR", "cs.LG", "stat.ME"], "comment": "To appear in the Nineteenth ACM Conference on Recommender Systems\n  (RecSys '25)", "summary": "Off-policy estimation (OPE) methods enable unbiased offline evaluation of\nrecommender systems, directly estimating the online reward some target policy\nwould have obtained, from offline data and with statistical guarantees. The\ntheoretical elegance of the framework combined with practical successes have\nled to a surge of interest, with many competing estimators now available to\npractitioners and researchers. Among these, Doubly Robust methods provide a\nprominent strategy to combine value- and policy-based estimators.\n  In this work, we take an alternative perspective to combine a set of OPE\nestimators and their associated confidence intervals into a single, more\naccurate estimate. Our approach leverages a correlated fixed-effects\nmeta-analysis framework, explicitly accounting for dependencies among\nestimators that arise due to shared data. This yields a best linear unbiased\nestimate (BLUE) of the target policy's value, along with an appropriately\nconservative confidence interval that reflects inter-estimator correlation. We\nvalidate our method on both simulated and real-world data, demonstrating\nimproved statistical efficiency over existing individual estimators.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u76f8\u5173\u56fa\u5b9a\u6548\u5e94\u5143\u5206\u6790\u6846\u67b6\u7ed3\u5408\u4e00\u7ec4\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff08OPE\uff09\u4f30\u8ba1\u91cf\u53ca\u5176\u7f6e\u4fe1\u533a\u95f4\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u7edf\u8ba1\u6548\u7387\u4f18\u4e8e\u73b0\u6709\u5355\u4e2a\u4f30\u8ba1\u91cf\u3002", "motivation": "\u73b0\u6709\u4f17\u591aOPE\u4f30\u8ba1\u91cf\uff0cDoubly Robust\u65b9\u6cd5\u662f\u7ed3\u5408\u57fa\u4e8e\u4ef7\u503c\u548c\u57fa\u4e8e\u7b56\u7565\u4f30\u8ba1\u91cf\u7684\u7a81\u51fa\u7b56\u7565\uff0c\u672c\u6587\u4ece\u53e6\u4e00\u4e2a\u89d2\u5ea6\u7ed3\u5408\u4e00\u7ec4OPE\u4f30\u8ba1\u91cf\u4ee5\u83b7\u5f97\u66f4\u51c6\u786e\u4f30\u8ba1\u3002", "method": "\u5229\u7528\u76f8\u5173\u56fa\u5b9a\u6548\u5e94\u5143\u5206\u6790\u6846\u67b6\uff0c\u660e\u786e\u8003\u8651\u56e0\u5171\u4eab\u6570\u636e\u5728\u4f30\u8ba1\u91cf\u95f4\u4ea7\u751f\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5f97\u5230\u76ee\u6807\u7b56\u7565\u4ef7\u503c\u7684\u6700\u4f73\u7ebf\u6027\u65e0\u504f\u4f30\u8ba1\uff08BLUE\uff09\u53ca\u4fdd\u5b88\u7f6e\u4fe1\u533a\u95f4\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u7edf\u8ba1\u6548\u7387\u4f18\u4e8e\u73b0\u6709\u5355\u4e2a\u4f30\u8ba1\u91cf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ed3\u5408OPE\u4f30\u8ba1\u91cf\u7684\u65b9\u6cd5\u80fd\u63d0\u9ad8\u7edf\u8ba1\u6548\u7387\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u7b56\u7565\u3002"}}
{"id": "2508.07427", "pdf": "https://arxiv.org/pdf/2508.07427", "abs": "https://arxiv.org/abs/2508.07427", "authors": ["Emanuele Cavalleri", "Paolo Perlasca", "Marco Mesiti"], "title": "RNA-KG v2.0: An RNA-centered Knowledge Graph with Properties", "categories": ["cs.DB", "q-bio.QM"], "comment": null, "summary": "RNA-KG is a recently developed knowledge graph that integrates the\ninteractions involving coding and non-coding RNA molecules extracted from\npublic data sources. It can be used to support the classification of new\nmolecules, identify new interactions through the use of link prediction\nmethods, and reveal hidden patterns among the represented entities. In this\npaper, we propose RNA-KG v2.0, a new release of RNA-KG that integrates around\n100M manually curated interactions sourced from 91 linked open data\nrepositories and ontologies. Relationships are characterized by standardized\nproperties that capture the specific context (e.g., cell line, tissue,\npathological state) in which they have been identified. In addition, the nodes\nare enriched with detailed attributes, such as descriptions, synonyms, and\nmolecular sequences sourced from platforms such as OBO ontologies, NCBI\nrepositories, RNAcentral, and Ensembl. The enhanced repository enables the\nexpression of advanced queries that take into account the context in which the\nexperiments were conducted. It also supports downstream applications in RNA\nresearch, including \"context-aware\" link prediction techniques that combine\nboth topological and semantic information.", "AI": {"tldr": "\u63d0\u51faRNA-KG v2.0\uff0c\u6574\u5408\u7ea61\u4ebf\u624b\u52a8\u6574\u7406\u7684\u4ea4\u4e92\u4fe1\u606f\uff0c\u652f\u6301\u9ad8\u7ea7\u67e5\u8be2\u548c\u4e0b\u6e38\u5e94\u7528\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709RNA-KG\uff0c\u6574\u5408\u66f4\u591a\u6570\u636e\u3001\u4e30\u5bcc\u8282\u70b9\u5c5e\u6027\u4ee5\u652f\u6301\u66f4\u9ad8\u7ea7\u5e94\u7528\u3002", "method": "\u4ece91\u4e2a\u5173\u8054\u5f00\u653e\u6570\u636e\u4ed3\u5e93\u548c\u672c\u4f53\u6574\u5408\u624b\u52a8\u6574\u7406\u7684\u4ea4\u4e92\u4fe1\u606f\uff0c\u4e3a\u5173\u7cfb\u548c\u8282\u70b9\u6dfb\u52a0\u6807\u51c6\u5316\u5c5e\u6027\u548c\u8be6\u7ec6\u4fe1\u606f\u3002", "result": "\u6784\u5efaRNA-KG v2.0\uff0c\u53ef\u8fdb\u884c\u8003\u8651\u5b9e\u9a8c\u4e0a\u4e0b\u6587\u7684\u9ad8\u7ea7\u67e5\u8be2\uff0c\u652f\u6301\u7ed3\u5408\u62d3\u6251\u548c\u8bed\u4e49\u4fe1\u606f\u7684\u201c\u4e0a\u4e0b\u6587\u611f\u77e5\u201d\u94fe\u63a5\u9884\u6d4b\u6280\u672f\u3002", "conclusion": "RNA-KG v2.0\u589e\u5f3a\u4e86\u77e5\u8bc6\u5e93\uff0c\u80fd\u66f4\u597d\u652f\u6301RNA\u7814\u7a76\u7684\u4e0b\u6e38\u5e94\u7528\u3002"}}
{"id": "2508.06563", "pdf": "https://arxiv.org/pdf/2508.06563", "abs": "https://arxiv.org/abs/2508.06563", "authors": ["Utsav Kumar Nareti", "Divyansh Gupta", "Chandranath Adak", "Soumi Chattopadhyay", "Emma Riese", "Tanujit Chakraborty", "Mayank Agarwal", "Satendra Kumar"], "title": "Assessing Engineering Student Perceptions of Introductory CS Courses in an Indian Context", "categories": ["cs.CY", "cs.CE", "cs.PL"], "comment": null, "summary": "Understanding student perceptions of assessment is vital for designing\ninclusive and effective learning environments, especially in technical\neducation. This study explores engineering students' perceptions of assessment\npractices in an introductory computer science/ programming course, and its\nassociated laboratory within an Indian engineering institute context. A total\nof 318 first-year Bachelor of Technology students participated in a weekly\n25-statement Likert-scale survey conducted over nine weeks. Using descriptive\nstatistics and non-parametric tests (Mann-Whitney U and Kruskal-Wallis), the\nanalysis reveals that students largely perceive lab assignments as effective\nlearning activities and view exams and projects as authentic and\nskill-enhancing. Students appreciated the role of instructors in shaping course\ncontent and found teaching assistants to be approachable and helpful, despite\nsome inconsistencies. The study also finds significant variations in students'\nacademic performance and assessment perceptions based on prior programming\nexperience, technology familiarity, gender, and academic branch. Notably, the\nperformance data did not follow a Gaussian distribution, challenging common\nassumptions in grade modeling. A comparative analysis with European cohorts\nhighlights both universal patterns and contextual differences, offering\nvaluable insights for designing inclusive and equitable assessment strategies\nin programming education.", "AI": {"tldr": "\u7814\u7a76\u5370\u5ea6\u5de5\u7a0b\u5b66\u9662\u8ba1\u7b97\u673a\u79d1\u5b66\u5165\u95e8\u8bfe\u7a0b\u5b66\u751f\u5bf9\u8bc4\u4f30\u5b9e\u8df5\u7684\u770b\u6cd5\uff0c\u53d1\u73b0\u5b66\u751f\u5bf9\u4e0d\u540c\u8bc4\u4f30\u65b9\u5f0f\u7684\u6001\u5ea6\u53ca\u5f71\u54cd\u56e0\u7d20\uff0c\u8fd8\u4e0e\u6b27\u6d32\u5b66\u751f\u5bf9\u6bd4\u3002", "motivation": "\u7406\u89e3\u5b66\u751f\u5bf9\u8bc4\u4f30\u7684\u770b\u6cd5\uff0c\u4e3a\u6280\u672f\u6559\u80b2\u8bbe\u8ba1\u5305\u5bb9\u6709\u6548\u7684\u5b66\u4e60\u73af\u5883\u3002", "method": "\u5bf9318\u540d\u4e00\u5e74\u7ea7\u5b66\u751f\u8fdb\u884c\u4e5d\u5468\u768425\u9879Likert\u91cf\u8868\u8c03\u67e5\uff0c\u7528\u63cf\u8ff0\u6027\u7edf\u8ba1\u548c\u975e\u53c2\u6570\u68c0\u9a8c\u5206\u6790\u3002", "result": "\u5b66\u751f\u8ba4\u4e3a\u5b9e\u9a8c\u4f5c\u4e1a\u662f\u6709\u6548\u5b66\u4e60\u6d3b\u52a8\uff0c\u8003\u8bd5\u548c\u9879\u76ee\u80fd\u63d0\u5347\u6280\u80fd\uff1b\u5b66\u751f\u8868\u73b0\u548c\u8bc4\u4f30\u770b\u6cd5\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\uff1b\u6210\u7ee9\u6570\u636e\u4e0d\u5448\u9ad8\u65af\u5206\u5e03\uff1b\u4e0e\u6b27\u6d32\u5b66\u751f\u6709\u5f02\u540c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7f16\u7a0b\u6559\u80b2\u8bbe\u8ba1\u5305\u5bb9\u516c\u5e73\u7684\u8bc4\u4f30\u7b56\u7565\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2508.07974", "pdf": "https://arxiv.org/pdf/2508.07974", "abs": "https://arxiv.org/abs/2508.07974", "authors": ["Rob Van Eynde", "Kevin J. Dillman", "Jefim Vogel", "Daniel W. O'Neill"], "title": "What is required for a post-growth model?", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Post-growth has emerged as an umbrella term for various sustainability\nvisions that advocate the pursuit of environmental sustainability, social\nequity, and human wellbeing, while questioning the continued pursuit of\neconomic growth. Although there are increasing calls to include post-growth\nscenarios in high-level assessments, a coherent framework with what is required\nto model post-growth adequately remains absent. This article addresses this gap\nby: (1) identifying the minimum requirements for post-growth models, and (2)\nestablishing a set of model elements for representing specific policy themes.\nDrawing on a survey of modellers and on relevant post-growth literature, we\ndevelop a framework of minimum requirements for post-growth modelling that\nintegrates three spheres: biophysical, economic, and social, and links them to\npost-growth goals. Within the biophysical sphere, we argue that embeddedness\nrequires the inclusion of resource use and pollution, environmental limits, and\nfeedback mechanisms from the environment onto society. Within the economic\nsphere, models should disaggregate households, incorporate limits to\ntechnological change and decoupling, include different types of government\ninterventions, and calculate GDP or output endogenously. Within the social\nsphere, models should represent time use, material and non-material need\nsatisfiers, and the affordability of essential goods and services. Specific\npolicies and transformation scenarios require additional features, such as\nsectoral disaggregation or representation of the financial system. Our\nframework guides the development of models that can simulate both post-growth\nand pro-growth policies and scenarios, an urgently needed tool for informing\npolicymakers and stakeholders about the full range of options for pursuing\nsustainability, equity, and wellbeing.", "AI": {"tldr": "\u6587\u7ae0\u9488\u5bf9\u540e\u589e\u957f\u60c5\u666f\u5efa\u6a21\u7f3a\u4e4f\u8fde\u8d2f\u6846\u67b6\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u540e\u589e\u957f\u5efa\u6a21\u6700\u4f4e\u8981\u6c42\u6846\u67b6\uff0c\u80fd\u6307\u5bfc\u6a21\u62df\u540e\u589e\u957f\u548c\u4fc3\u589e\u957f\u653f\u7b56\u53ca\u60c5\u666f\u3002", "motivation": "\u5f53\u524d\u867d\u547c\u5401\u5c06\u540e\u589e\u957f\u60c5\u666f\u7eb3\u5165\u9ad8\u7ea7\u8bc4\u4f30\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u540e\u589e\u957f\u8fdb\u884c\u5145\u5206\u5efa\u6a21\u6240\u9700\u7684\u8fde\u8d2f\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5bf9\u5efa\u6a21\u8005\u7684\u8c03\u67e5\u548c\u76f8\u5173\u540e\u589e\u957f\u6587\u732e\uff0c\u5f00\u53d1\u5305\u542b\u751f\u7269\u7269\u7406\u3001\u7ecf\u6d4e\u548c\u793e\u4f1a\u4e09\u4e2a\u9886\u57df\u7684\u540e\u589e\u957f\u5efa\u6a21\u6700\u4f4e\u8981\u6c42\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u6574\u5408\u4e09\u4e2a\u9886\u57df\u5e76\u4e0e\u540e\u589e\u957f\u76ee\u6807\u76f8\u8054\u7cfb\u7684\u6846\u67b6\uff0c\u4e0d\u540c\u9886\u57df\u6709\u5404\u81ea\u7684\u5efa\u6a21\u8981\u6c42\uff0c\u7279\u5b9a\u653f\u7b56\u548c\u8f6c\u578b\u60c5\u666f\u9700\u989d\u5916\u7279\u5f81\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u548c\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u8ffd\u6c42\u53ef\u6301\u7eed\u6027\u3001\u516c\u5e73\u548c\u798f\u7949\u5168\u9762\u9009\u9879\u7684\u8feb\u5207\u9700\u8981\u7684\u5de5\u5177\u3002"}}
{"id": "2508.08091", "pdf": "https://arxiv.org/pdf/2508.08091", "abs": "https://arxiv.org/abs/2508.08091", "authors": ["Matias Barandiaran", "James Stovold"], "title": "Growing Reservoirs with Developmental Graph Cellular Automata", "categories": ["cs.NE", "cs.AI"], "comment": "Accepted to ALIFE 2025", "summary": "Developmental Graph Cellular Automata (DGCA) are a novel model for\nmorphogenesis, capable of growing directed graphs from single-node seeds. In\nthis paper, we show that DGCAs can be trained to grow reservoirs. Reservoirs\nare grown with two types of targets: task-driven (using the NARMA family of\ntasks) and task-independent (using reservoir metrics).\n  Results show that DGCAs are able to grow into a variety of specialized,\nlife-like structures capable of effectively solving benchmark tasks,\nstatistically outperforming `typical' reservoirs on the same task. Overall,\nthese lay the foundation for the development of DGCA systems that produce\nplastic reservoirs and for modeling functional, adaptive morphogenesis.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u53d1\u80b2\u56fe\u5143\u80de\u81ea\u52a8\u673a\uff08DGCA\uff09\u53ef\u88ab\u8bad\u7ec3\u751f\u6210\u50a8\u5c42\uff0c\u80fd\u5f62\u6210\u591a\u79cd\u7ed3\u6784\u89e3\u51b3\u57fa\u51c6\u4efb\u52a1\uff0c\u4e3a\u76f8\u5173\u7cfb\u7edf\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u63a2\u7d22DGCA\u5728\u751f\u6210\u50a8\u5c42\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4ee5\u63a8\u52a8DGCA\u7cfb\u7edf\u53d1\u5c55\u548c\u529f\u80fd\u3001\u9002\u5e94\u6027\u5f62\u6001\u53d1\u751f\u5efa\u6a21\u3002", "method": "\u5c06DGCAs\u8bad\u7ec3\u751f\u6210\u50a8\u5c42\uff0c\u8bbe\u7f6e\u4efb\u52a1\u9a71\u52a8\uff08\u4f7f\u7528NARMA\u7cfb\u5217\u4efb\u52a1\uff09\u548c\u4efb\u52a1\u72ec\u7acb\uff08\u4f7f\u7528\u50a8\u5c42\u6307\u6807\uff09\u4e24\u79cd\u76ee\u6807\u3002", "result": "DGCAs\u80fd\u751f\u957f\u6210\u591a\u79cd\u7c7b\u4f3c\u751f\u547d\u7684\u4e13\u95e8\u5316\u7ed3\u6784\uff0c\u6709\u6548\u89e3\u51b3\u57fa\u51c6\u4efb\u52a1\uff0c\u5728\u76f8\u540c\u4efb\u52a1\u4e0a\u7edf\u8ba1\u8868\u73b0\u4f18\u4e8e\u2018\u5178\u578b\u2019\u50a8\u5c42\u3002", "conclusion": "\u4e3a\u4ea7\u751f\u53ef\u5851\u6027\u50a8\u5c42\u7684DGCA\u7cfb\u7edf\u53d1\u5c55\u548c\u529f\u80fd\u6027\u3001\u9002\u5e94\u6027\u5f62\u6001\u53d1\u751f\u5efa\u6a21\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.06706", "pdf": "https://arxiv.org/pdf/2508.06706", "abs": "https://arxiv.org/abs/2508.06706", "authors": ["Jaikrishna Manojkumar Patil", "Nathaniel Lee", "Al Mehdi Saadat Chowdhury", "YooJung Choi", "Paulo Shakarian"], "title": "Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Rule-based methods for knowledge graph completion provide explainable results\nbut often require a significantly large number of rules to achieve competitive\nperformance. This can hinder explainability due to overwhelmingly large rule\nsets. We discover rule contexts (meaningful subsets of rules that work\ntogether) from training data and use learned probability distribution (i.e.\nprobabilistic circuits) over these rule contexts to more rapidly achieve\nperformance of the full rule set. Our approach achieves a 70-96% reduction in\nnumber of rules used while outperforming baseline by up to 31$\\times$ when\nusing equivalent minimal number of rules and preserves 91% of peak baseline\nperformance even when comparing our minimal rule sets against baseline's full\nrule sets. We show that our framework is grounded in well-known semantics of\nprobabilistic logic, does not require independence assumptions, and that our\ntractable inference procedure provides both approximate lower bounds and exact\nprobability of a given query. The efficacy of our method is validated by\nempirical studies on 8 standard benchmark datasets where we show competitive\nperformance by using only a fraction of the rules required by AnyBURL's\nstandard inference method, the current state-of-the-art for rule-based\nknowledge graph completion. This work may have further implications for general\nprobabilistic reasoning over learned sets of rules.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u8bad\u7ec3\u6570\u636e\u53d1\u73b0\u89c4\u5219\u4e0a\u4e0b\u6587\uff0c\u5e76\u5229\u7528\u6982\u7387\u7535\u8def\u63d0\u5347\u57fa\u4e8e\u89c4\u5219\u7684\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6027\u80fd\uff0c\u51cf\u5c11\u89c4\u5219\u4f7f\u7528\u91cf\u3002", "motivation": "\u57fa\u4e8e\u89c4\u5219\u7684\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\u9700\u5927\u91cf\u89c4\u5219\uff0c\u5e9e\u5927\u89c4\u5219\u96c6\u5f71\u54cd\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u63d0\u5347\u6548\u7387\u3002", "method": "\u4ece\u8bad\u7ec3\u6570\u636e\u53d1\u73b0\u89c4\u5219\u4e0a\u4e0b\u6587\uff0c\u5229\u7528\u6982\u7387\u7535\u8def\u5b66\u4e60\u89c4\u5219\u4e0a\u4e0b\u6587\u6982\u7387\u5206\u5e03\u3002", "result": "\u89c4\u5219\u4f7f\u7528\u91cf\u51cf\u5c1170 - 96%\uff0c\u540c\u7b49\u6700\u5c11\u89c4\u5219\u4e0b\u6027\u80fd\u8d85\u57fa\u7ebf31\u500d\uff0c\u4e0e\u57fa\u7ebf\u5b8c\u6574\u89c4\u5219\u96c6\u76f8\u6bd4\u4fdd\u755991%\u5cf0\u503c\u6027\u80fd\uff0c\u57288\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u65b9\u6cd5\u57fa\u4e8e\u6982\u7387\u903b\u8f91\u8bed\u4e49\uff0c\u65e0\u9700\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u63a8\u7406\u8fc7\u7a0b\u53ef\u63d0\u4f9b\u8fd1\u4f3c\u4e0b\u754c\u548c\u7cbe\u786e\u6982\u7387\uff0c\u5bf9\u89c4\u5219\u96c6\u4e0a\u7684\u6982\u7387\u63a8\u7406\u6709\u8fdb\u4e00\u6b65\u610f\u4e49\u3002"}}
{"id": "2508.07147", "pdf": "https://arxiv.org/pdf/2508.07147", "abs": "https://arxiv.org/abs/2508.07147", "authors": ["Ivan Geffner", "Caspar Oesterheld", "Vincent Conitzer"], "title": "Maximizing Social Welfare with Side Payments", "categories": ["cs.GT", "econ.TH"], "comment": null, "summary": "We examine normal-form games in which players may \\emph{pre-commit} to\noutcome-contingent transfers before choosing their actions. In the one-shot\nversion of this model, Jackson and Wilkie showed that side contracting can\nbackfire: even a game with a Pareto-optimal Nash equilibrium can devolve into\ninefficient equilibria once unbounded, simultaneous commitments are allowed.\nThe root cause is a prisoner's dilemma effect, where each player can exploit\nher commitment power to reshape the equilibrium in her favor, harming overall\nwelfare.\n  To circumvent this problem we introduce a \\emph{staged-commitment} protocol.\nPlayers may pledge transfers only in small, capped increments over multiple\nrounds, and the phase continues only with unanimous consent. We prove that,\nstarting from any finite game $\\Gamma$ with a non-degenerate Nash equilibrium\n$\\vec{\\sigma}$, this protocol implements every welfare-maximizing payoff\nprofile that \\emph{strictly} Pareto-improves $\\vec{\\sigma}$. Thus, gradual and\nbounded commitments restore the full efficiency potential of side payments\nwhile avoiding the inefficiencies identified by Jackson and Wilkie.", "AI": {"tldr": "\u7814\u7a76\u73a9\u5bb6\u53ef\u9884\u5148\u627f\u8bfa\u7ed3\u679c\u76f8\u5173\u8f6c\u79fb\u652f\u4ed8\u7684\u6807\u51c6\u578b\u535a\u5f08\uff0c\u9488\u5bf9Jackson\u548cWilkie\u6a21\u578b\u7684\u4f4e\u6548\u95ee\u9898\u5f15\u5165\u5206\u9636\u6bb5\u627f\u8bfa\u534f\u8bae\uff0c\u8bc1\u660e\u8be5\u534f\u8bae\u80fd\u5b9e\u73b0\u798f\u5229\u6700\u5927\u5316\u3002", "motivation": "Jackson\u548cWilkie\u6a21\u578b\u4e2d\u65e0\u9650\u5236\u7684\u540c\u65f6\u627f\u8bfa\u4f1a\u4f7f\u535a\u5f08\u9677\u5165\u4f4e\u6548\u5747\u8861\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u5f15\u5165\u5206\u9636\u6bb5\u627f\u8bfa\u534f\u8bae\uff0c\u73a9\u5bb6\u5728\u591a\u8f6e\u4e2d\u4ee5\u5c0f\u7684\u3001\u6709\u4e0a\u9650\u7684\u589e\u91cf\u627f\u8bfa\u8f6c\u79fb\u652f\u4ed8\uff0c\u4e14\u9700\u4e00\u81f4\u540c\u610f\u624d\u80fd\u7ee7\u7eed\u3002", "result": "\u4ece\u4efb\u4f55\u5177\u6709\u975e\u9000\u5316\u7eb3\u4ec0\u5747\u8861\u7684\u6709\u9650\u535a\u5f08\u5f00\u59cb\uff0c\u8be5\u534f\u8bae\u80fd\u5b9e\u73b0\u4e25\u683c\u5e15\u7d2f\u6258\u6539\u8fdb\u8be5\u5747\u8861\u7684\u6bcf\u4e2a\u798f\u5229\u6700\u5927\u5316\u652f\u4ed8\u914d\u7f6e\u3002", "conclusion": "\u6e10\u8fdb\u4e14\u6709\u754c\u7684\u627f\u8bfa\u80fd\u6062\u590d\u65c1\u652f\u4ed8\u7684\u5168\u90e8\u6548\u7387\u6f5c\u529b\uff0c\u907f\u514dJackson\u548cWilkie\u6240\u6307\u51fa\u7684\u4f4e\u6548\u95ee\u9898\u3002"}}
{"id": "2508.07241", "pdf": "https://arxiv.org/pdf/2508.07241", "abs": "https://arxiv.org/abs/2508.07241", "authors": ["Amit Jaspal", "Kapil Dalwani", "Ajantha Ramineni"], "title": "SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations", "categories": ["cs.IR", "cs.AI"], "comment": "4 pages, 2 figures, 2 tables, recsys 2025", "summary": "Most industry scale recommender systems face critical cold start challenges\nnew items lack interaction history, making it difficult to distribute them in a\npersonalized manner. Standard collaborative filtering models underperform due\nto sparse engagement signals, while content only approaches lack user specific\nrelevance. We propose SocRipple, a novel two stage retrieval framework tailored\nfor coldstart item distribution in social graph based platforms. Stage 1\nleverages the creators social connections for targeted initial exposure. Stage\n2 builds on early engagement signals and stable user embeddings learned from\nhistorical interactions to \"ripple\" outwards via K Nearest Neighbor (KNN)\nsearch. Large scale experiments on a major video platform show that SocRipple\nboosts cold start item distribution by +36% while maintaining user engagement\nrate on cold start items, effectively balancing new item exposure with\npersonalized recommendations.", "AI": {"tldr": "\u63d0\u51faSocRipple\u6846\u67b6\u89e3\u51b3\u793e\u4ea4\u5e73\u53f0\u51b7\u542f\u52a8\u9879\u76ee\u5206\u53d1\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u63d0\u5347\u5206\u53d1\u6548\u679c\u5e76\u5e73\u8861\u65b0\u9879\u66dd\u5149\u4e0e\u4e2a\u6027\u5316\u63a8\u8350\u3002", "motivation": "\u884c\u4e1a\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u51b7\u542f\u52a8\u6311\u6218\uff0c\u6807\u51c6\u534f\u540c\u8fc7\u6ee4\u548c\u4ec5\u57fa\u4e8e\u5185\u5bb9\u7684\u65b9\u6cd5\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u68c0\u7d22\u6846\u67b6SocRipple\uff0c\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u521b\u4f5c\u8005\u793e\u4ea4\u8fde\u63a5\u8fdb\u884c\u521d\u59cb\u66dd\u5149\uff0c\u7b2c\u4e8c\u9636\u6bb5\u57fa\u4e8e\u65e9\u671f\u53c2\u4e0e\u4fe1\u53f7\u548c\u5386\u53f2\u4ea4\u4e92\u5b66\u4e60\u7684\u7528\u6237\u5d4c\u5165\u901a\u8fc7KNN\u641c\u7d22\u5411\u5916\u6269\u5c55\u3002", "result": "\u5728\u5927\u578b\u89c6\u9891\u5e73\u53f0\u5b9e\u9a8c\u4e2d\uff0cSocRipple\u4f7f\u51b7\u542f\u52a8\u9879\u76ee\u5206\u53d1\u63d0\u534736%\uff0c\u5e76\u4fdd\u6301\u7528\u6237\u5bf9\u51b7\u542f\u52a8\u9879\u76ee\u7684\u53c2\u4e0e\u7387\u3002", "conclusion": "SocRipple\u80fd\u6709\u6548\u5e73\u8861\u65b0\u9879\u66dd\u5149\u4e0e\u4e2a\u6027\u5316\u63a8\u8350\u3002"}}
{"id": "2508.07783", "pdf": "https://arxiv.org/pdf/2508.07783", "abs": "https://arxiv.org/abs/2508.07783", "authors": ["Yotam Kenneth-Mordoch", "Robert Krauthgamer"], "title": "Simple Algorithms for Fully Dynamic Edge Connectivity", "categories": ["cs.DS"], "comment": null, "summary": "In the fully dynamic edge connectivity problem, the input is a simple graph\n$G$ undergoing edge insertions and deletions, and the goal is to maintain its\nedge connectivity, denoted $\\lambda_G$. We present two simple randomized\nalgorithms solving this problem. The first algorithm maintains the edge\nconnectivity in worst-case update time $\\tilde{O}(n)$ per edge update, matching\nthe known bound but with simpler analysis. Our second algorithm achieves\nworst-case update time $\\tilde{O}(n/\\lambda_G)$ and worst-case query time\n$\\tilde{O}(n^2/\\lambda_G^2)$, which is the first algorithm with worst-case\nupdate and query time $o(n)$ for large edge connectivity, namely, $\\lambda_G =\n\\omega(\\sqrt{n})$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.07169", "pdf": "https://arxiv.org/pdf/2508.07169", "abs": "https://arxiv.org/abs/2508.07169", "authors": ["Burak Yeti\u015ftiren", "Hong Jin Kang", "Miryung Kim"], "title": "From Noise to Knowledge: Interactive Summaries for Developer Alerts", "categories": ["cs.SE"], "comment": null, "summary": "Programmers using bug-finding tools often review their reported warnings one\nby one. Based on the insight that identifying recurring themes and\nrelationships can enhance the cognitive process of sensemaking, we propose\nCLARITY, which supports interpreting tool-generated warnings through\ninteractive inquiry. CLARITY derives summary rules for custom grouping of\nrelated warnings with active feedback. As users mark warnings as interesting or\nuninteresting, CLARITY's rule inference algorithm surfaces common symptoms,\nhighlighting structural similarities in containment, subtyping, invoked\nmethods, accessed fields, and expressions.\n  We demonstrate CLARITY on Infer and SpotBugs warnings across two mature Java\nprojects. In a within-subject user study with 14 participants, users\narticulated root causes for similar uninteresting warnings faster and with more\nconfidence using CLARITY. We observed significant individual variation in\ndesired grouping, reinforcing the need for customizable sensemaking. Simulation\nshows that with rule-level feedback, only 11.8 interactions are needed on\naverage to align all inferred rules with a simulated user's labels (vs. 17.8\nwithout). Our evaluation suggests that CLARITY's active learning-based\nsummarization enhances interactive warning sensemaking.", "AI": {"tldr": "\u63d0\u51faCLARITY\u5de5\u5177\u652f\u6301\u4ea4\u4e92\u5f0f\u67e5\u8be2\u89e3\u91ca\u5de5\u5177\u751f\u6210\u7684\u8b66\u544a\uff0c\u5728Java\u9879\u76ee\u9a8c\u8bc1\uff0c\u7528\u6237\u7814\u7a76\u548c\u6a21\u62df\u8868\u660e\u5176\u6709\u6548", "motivation": "\u5f53\u524d\u7a0b\u5e8f\u5458\u9010\u4e2a\u5ba1\u67e5\u8b66\u544a\uff0c\u8bc6\u522b\u91cd\u590d\u4e3b\u9898\u548c\u5173\u7cfb\u53ef\u589e\u5f3a\u8ba4\u77e5\u7406\u89e3\uff0c\u9700\u8981\u652f\u6301\u4ea4\u4e92\u5f0f\u67e5\u8be2\u7684\u5de5\u5177", "method": "\u63d0\u51faCLARITY\uff0c\u901a\u8fc7\u4e3b\u52a8\u53cd\u9988\u63a8\u5bfc\u81ea\u5b9a\u4e49\u5206\u7ec4\u89c4\u5219\uff0c\u8fdb\u884c\u7528\u6237\u7814\u7a76\u548c\u6a21\u62df", "result": "\u7528\u6237\u4f7f\u7528CLARITY\u80fd\u66f4\u5feb\u66f4\u81ea\u4fe1\u9610\u660e\u6839\u56e0\uff0c\u6a21\u62df\u663e\u793a\u89c4\u5219\u7ea7\u53cd\u9988\u51cf\u5c11\u4ea4\u4e92\u6b21\u6570", "conclusion": "CLARITY\u57fa\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7684\u603b\u7ed3\u589e\u5f3a\u4e86\u4ea4\u4e92\u5f0f\u8b66\u544a\u7406\u89e3"}}
{"id": "2508.06591", "pdf": "https://arxiv.org/pdf/2508.06591", "abs": "https://arxiv.org/abs/2508.06591", "authors": ["Rachel K. Luu", "Jingyu Deng", "Mohammed Shahrudin Ibrahim", "Nam-Joon Cho", "Ming Dao", "Subra Suresh", "Markus J. Buehler"], "title": "Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.mtrl-sci", "cond-mat.other", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have reshaped the research landscape by enabling\nnew approaches to knowledge retrieval and creative ideation. Yet their\napplication in discipline-specific experimental science, particularly in highly\nmulti-disciplinary domains like materials science, remains limited. We present\na first-of-its-kind framework that integrates generative AI with literature\nfrom hitherto-unconnected fields such as plant science, biomimetics, and\nmaterials engineering to extract insights and design experiments for materials.\nWe focus on humidity-responsive systems such as pollen-based materials and\nRhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and\nadaptive performance. Using a suite of AI tools, including a fine-tuned model\n(BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a\nHierarchical Sampling strategy, we extract structure-property relationships and\ntranslate them into new classes of bioinspired materials. Structured inference\nprotocols generate and evaluate hundreds of hypotheses from a single query,\nsurfacing novel and experimentally tractable ideas. We validate our approach\nthrough real-world implementation: LLM-generated procedures, materials designs,\nand mechanical predictions were tested in the laboratory, culminating in the\nfabrication of a novel pollen-based adhesive with tunable morphology and\nmeasured shear strength, establishing a foundation for future plant-derived\nadhesive design. This work demonstrates how AI-assisted ideation can drive\nreal-world materials design and enable effective human-AI collaboration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u751f\u6210\u5f0fAI\u4e0e\u591a\u9886\u57df\u6587\u732e\u7ed3\u5408\u7684\u6846\u67b6\u7528\u4e8e\u6750\u6599\u8bbe\u8ba1\uff0c\u4ee5\u6e7f\u5ea6\u54cd\u5e94\u7cfb\u7edf\u4e3a\u4f8b\uff0c\u7528AI\u5de5\u5177\u63d0\u53d6\u5173\u7cfb\u3001\u751f\u6210\u5047\u8bbe\uff0c\u7ecf\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\u5236\u9020\u51fa\u65b0\u578b\u82b1\u7c89\u57fa\u7c98\u5408\u5242\uff0c\u5c55\u793a\u4e86AI\u8f85\u52a9\u6784\u601d\u5bf9\u6750\u6599\u8bbe\u8ba1\u7684\u63a8\u52a8\u4f5c\u7528\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u5b66\u79d1\u5b9e\u9a8c\u79d1\u5b66\u5c24\u5176\u662f\u6750\u6599\u79d1\u5b66\u591a\u5b66\u79d1\u9886\u57df\u5e94\u7528\u6709\u9650\uff0c\u9700\u63a2\u7d22\u5176\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u6574\u5408\u751f\u6210\u5f0fAI\u4e0e\u591a\u9886\u57df\u6587\u732e\u7684\u6846\u67b6\uff0c\u501f\u52a9BioinspiredLLM\u7b49AI\u5de5\u5177\uff0c\u7528\u7ed3\u6784\u5316\u63a8\u7406\u534f\u8bae\u751f\u6210\u548c\u8bc4\u4f30\u5047\u8bbe\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\uff0c\u5236\u9020\u51fa\u5177\u6709\u53ef\u8c03\u5f62\u6001\u548c\u6d4b\u91cf\u526a\u5207\u5f3a\u5ea6\u7684\u65b0\u578b\u82b1\u7c89\u57fa\u7c98\u5408\u5242\u3002", "conclusion": "AI\u8f85\u52a9\u6784\u601d\u53ef\u63a8\u52a8\u73b0\u5b9e\u4e16\u754c\u6750\u6599\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\u3002"}}
{"id": "2508.07928", "pdf": "https://arxiv.org/pdf/2508.07928", "abs": "https://arxiv.org/abs/2508.07928", "authors": ["Bogdan Butyrin", "Artemy Rubtsov", "Alexey Naumov", "Vladimir Ulyanov", "Sergey Samsonov"], "title": "Gaussian Approximation for Two-Timescale Linear Stochastic Approximation", "categories": ["stat.ML", "cs.LG", "math.OC", "math.PR", "math.ST", "stat.TH", "60F05, 62L20"], "comment": null, "summary": "In this paper, we establish non-asymptotic bounds for accuracy of normal\napproximation for linear two-timescale stochastic approximation (TTSA)\nalgorithms driven by martingale difference or Markov noise. Focusing on both\nthe last iterate and Polyak-Ruppert averaging regimes, we derive bounds for\nnormal approximation in terms of the convex distance between probability\ndistributions. Our analysis reveals a non-trivial interaction between the fast\nand slow timescales: the normal approximation rate for the last iterate\nimproves as the timescale separation increases, while it decreases in the\nPolyak-Ruppert averaged setting. We also provide the high-order moment bounds\nfor the error of linear TTSA algorithm, which may be of independent interest.", "AI": {"tldr": "\u672c\u6587\u4e3a\u7ebf\u6027\u53cc\u65f6\u95f4\u5c3a\u5ea6\u968f\u673a\u903c\u8fd1\uff08TTSA\uff09\u7b97\u6cd5\u7684\u6b63\u6001\u903c\u8fd1\u7cbe\u5ea6\u5efa\u7acb\u4e86\u975e\u6e10\u8fd1\u754c\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u8fed\u4ee3\u65b9\u5f0f\u4e0b\u7684\u903c\u8fd1\u60c5\u51b5\u5e76\u7ed9\u51fa\u9ad8\u9636\u77e9\u754c\u3002", "motivation": "\u4e3a\u7ebf\u6027TTSA\u7b97\u6cd5\u7684\u6b63\u6001\u903c\u8fd1\u7cbe\u5ea6\u5efa\u7acb\u975e\u6e10\u8fd1\u754c\uff0c\u7814\u7a76\u4e0d\u540c\u8fed\u4ee3\u65b9\u5f0f\u4e0b\u7684\u903c\u8fd1\u60c5\u51b5\u3002", "method": "\u63a8\u5bfc\u6982\u7387\u5206\u5e03\u51f8\u8ddd\u79bb\u4e0b\u7684\u6b63\u6001\u903c\u8fd1\u754c\uff0c\u5206\u6790\u5feb\u6162\u65f6\u95f4\u5c3a\u5ea6\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u5feb\u6162\u65f6\u95f4\u5c3a\u5ea6\u5b58\u5728\u975e\u5e73\u51e1\u76f8\u4e92\u4f5c\u7528\uff0c\u6700\u540e\u8fed\u4ee3\u7684\u6b63\u6001\u903c\u8fd1\u7387\u968f\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u589e\u52a0\u800c\u63d0\u9ad8\uff0c\u5728Polyak - Ruppert\u5e73\u5747\u8bbe\u7f6e\u4e0b\u964d\u4f4e\uff0c\u8fd8\u7ed9\u51fa\u4e86\u7ebf\u6027TTSA\u7b97\u6cd5\u8bef\u5dee\u7684\u9ad8\u9636\u77e9\u754c\u3002", "conclusion": "\u6210\u529f\u5efa\u7acb\u975e\u6e10\u8fd1\u754c\uff0c\u63ed\u793a\u4e86\u5feb\u6162\u65f6\u95f4\u5c3a\u5ea6\u5bf9\u6b63\u6001\u903c\u8fd1\u7387\u7684\u5f71\u54cd\uff0c\u9ad8\u9636\u77e9\u754c\u6709\u72ec\u7acb\u7814\u7a76\u4ef7\u503c\u3002"}}
{"id": "2508.07551", "pdf": "https://arxiv.org/pdf/2508.07551", "abs": "https://arxiv.org/abs/2508.07551", "authors": ["Danushka Liyanage", "Shubham Pandey", "Joshua Goldstein", "Michael Cahill", "Akon Dey", "Alan Fekete", "Uwe R\u00f6hm"], "title": "A Benchmark for Databases with Varying Value Lengths", "categories": ["cs.DB", "E.2"], "comment": "Seventeenth TPC Technology Conference on Performance Evaluation &\n  Benchmarking (TPCTC 2025) Keywords: Key-value stores, Benchmarking,\n  Throughput, Latency", "summary": "The performance of database management systems (DBMS) is traditionally\nevaluated using benchmarks that focus on workloads with (almost) fixed record\nlengths. However, some real-world workloads in key/value stores, document\ndatabases, and graph databases exhibit significant variability in value\nlengths, which can lead to performance anomalies, particularly when popular\nrecords grow disproportionately large. Existing benchmarks fail to account for\nthis variability, leaving an important aspect of DBMS behavior underexplored.\n  In this paper, we address this gap by extending the Yahoo! Cloud Serving\nBenchmark (YCSB) to include an \"extend\" operation, which appends data to record\nfields, simulating the growth of values over time. Using this modified\nbenchmark, we have measured the performance of three popular DBMS backends:\nMongoDB, MariaDB with the InnoDB storage engine, and MariaDB with the MyRocks\nstorage engine. Our experiments alternate between extending values and\nexecuting query workloads, revealing significant performance differences driven\nby storage engine design and their handling of variable-sized values.\n  Our key contribution is the introduction of a novel benchmarking approach to\nevaluate the impact of growing value sizes and isolate the effect of querying\ndata with a distribution of data sizes from any cost associated with accessing\ndata after a history of updates. This highlights the need for more\nrepresentative benchmarks that capture the dynamic nature of real-world\nworkloads, providing valuable guidance for both practitioners and researchers.", "AI": {"tldr": "\u73b0\u6709\u6570\u636e\u5e93\u57fa\u51c6\u6d4b\u8bd5\u672a\u8003\u8651\u503c\u957f\u5ea6\u53d8\u5316\uff0c\u672c\u6587\u6269\u5c55YCSB\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e09\u79cd\u6570\u636e\u5e93\u540e\u7aef\u6027\u80fd\uff0c\u63d0\u51fa\u65b0\u57fa\u51c6\u65b9\u6cd5\uff0c\u5f3a\u8c03\u9700\u66f4\u5177\u4ee3\u8868\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u5e93\u57fa\u51c6\u6d4b\u8bd5\u672a\u8003\u8651\u73b0\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u503c\u957f\u5ea6\u7684\u663e\u8457\u53d8\u5316\uff0c\u5bfc\u81f4\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u884c\u4e3a\u7684\u91cd\u8981\u65b9\u9762\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u6269\u5c55YCSB\u57fa\u51c6\u6d4b\u8bd5\uff0c\u589e\u52a0\u201cextend\u201d\u64cd\u4f5c\u6a21\u62df\u503c\u968f\u65f6\u95f4\u589e\u957f\uff0c\u7528\u4fee\u6539\u540e\u7684\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30MongoDB\u3001\u5e26InnoDB\u5b58\u50a8\u5f15\u64ce\u7684MariaDB\u548c\u5e26MyRocks\u5b58\u50a8\u5f15\u64ce\u7684MariaDB\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u4e0d\u540c\u5b58\u50a8\u5f15\u64ce\u8bbe\u8ba1\u53ca\u5176\u5bf9\u53ef\u53d8\u5927\u5c0f\u503c\u7684\u5904\u7406\u65b9\u5f0f\u5bfc\u81f4\u7684\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u5f15\u5165\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5177\u4ee3\u8868\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u53cd\u6620\u73b0\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u7684\u52a8\u6001\u7279\u6027\uff0c\u4e3a\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2508.06985", "pdf": "https://arxiv.org/pdf/2508.06985", "abs": "https://arxiv.org/abs/2508.06985", "authors": ["Jiawei Zhang", "Yifei Zhang", "Baozhao Yi", "Yao Ren", "Qi Jiao", "Hanyu Bai", "Weiran Jiang", "Ziyou Song"], "title": "Discovery Learning accelerates battery design evaluation", "categories": ["cs.LG", "cs.CE", "cs.SY", "eess.SY", "physics.comp-ph"], "comment": "Main text, 20 pages, 5 figures", "summary": "Fast and reliable validation of novel designs in complex physical systems\nsuch as batteries is critical to accelerating technological innovation.\nHowever, battery research and development remain bottlenecked by the\nprohibitively high time and energy costs required to evaluate numerous new\ndesign candidates, particularly in battery prototyping and life testing.\nDespite recent progress in data-driven battery lifetime prediction, existing\nmethods require labeled data of target designs to improve accuracy and cannot\nmake reliable predictions until after prototyping, thus falling far short of\nthe efficiency needed to enable rapid feedback for battery design. Here, we\nintroduce Discovery Learning (DL), a scientific machine-learning paradigm that\nintegrates active learning, physics-guided learning, and zero-shot learning\ninto a human-like reasoning loop, drawing inspiration from learning theories in\neducational psychology. DL can learn from historical battery designs and\nactively reduce the need for prototyping, thus enabling rapid lifetime\nevaluation for unobserved material-design combinations without requiring\nadditional data labeling. To test DL, we present 123 industrial-grade\nlarge-format lithium-ion pouch cells, spanning eight material-design\ncombinations and diverse cycling protocols. Trained solely on public datasets\nof small-capacity cylindrical cells, DL achieves 7.2% test error in predicting\nthe average cycle life under unknown device variability. This results in\nsavings of 98% in time and 95% in energy compared to industrial practices. This\nwork highlights the potential of uncovering insights from historical designs to\ninform and accelerate the development of next-generation battery technologies.\nDL represents a key advance toward efficient data-driven modeling and helps\nrealize the promise of machine learning for accelerating scientific discovery\nand engineering innovation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDiscovery Learning (DL) \u8303\u5f0f\u7528\u4e8e\u7535\u6c60\u5bff\u547d\u8bc4\u4f30\uff0c\u80fd\u51cf\u5c11\u539f\u578b\u5236\u4f5c\u9700\u6c42\uff0c\u8282\u7701\u65f6\u95f4\u548c\u80fd\u6e90\uff0c\u52a9\u529b\u7535\u6c60\u6280\u672f\u53d1\u5c55\u3002", "motivation": "\u7535\u6c60\u7814\u53d1\u53d7\u8bc4\u4f30\u65b0\u8bbe\u8ba1\u7684\u9ad8\u65f6\u95f4\u548c\u80fd\u6e90\u6210\u672c\u74f6\u9888\u9650\u5236\uff0c\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6548\u7387\u4e0d\u8db3\uff0c\u65e0\u6cd5\u4e3a\u7535\u6c60\u8bbe\u8ba1\u63d0\u4f9b\u5feb\u901f\u53cd\u9988\u3002", "method": "\u5f15\u5165DL\u8303\u5f0f\uff0c\u5c06\u4e3b\u52a8\u5b66\u4e60\u3001\u7269\u7406\u5f15\u5bfc\u5b66\u4e60\u548c\u96f6\u6837\u672c\u5b66\u4e60\u96c6\u6210\u5230\u7c7b\u4eba\u63a8\u7406\u5faa\u73af\u4e2d\uff0c\u4ece\u5386\u53f2\u7535\u6c60\u8bbe\u8ba1\u4e2d\u5b66\u4e60\u3002", "result": "\u5728123\u4e2a\u5de5\u4e1a\u7ea7\u5927\u5c3a\u5bf8\u9502\u79bb\u5b50\u8f6f\u5305\u7535\u6c60\u6d4b\u8bd5\u4e2d\uff0c\u4ec5\u5728\u5c0f\u5bb9\u91cf\u5706\u67f1\u5f62\u7535\u6c60\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0cDL\u9884\u6d4b\u5e73\u5747\u5faa\u73af\u5bff\u547d\u7684\u6d4b\u8bd5\u8bef\u5dee\u4e3a7.2%\uff0c\u76f8\u6bd4\u5de5\u4e1a\u5b9e\u8df5\u8282\u770198%\u65f6\u95f4\u548c95%\u80fd\u6e90\u3002", "conclusion": "DL\u6709\u6f5c\u529b\u4ece\u5386\u53f2\u8bbe\u8ba1\u4e2d\u6316\u6398\u89c1\u89e3\uff0c\u63a8\u52a8\u4e0b\u4e00\u4ee3\u7535\u6c60\u6280\u672f\u53d1\u5c55\uff0c\u662f\u9ad8\u6548\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u7684\u5173\u952e\u8fdb\u5c55\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u548c\u5de5\u7a0b\u521b\u65b0\u7684\u613f\u666f\u3002"}}
{"id": "2508.07703", "pdf": "https://arxiv.org/pdf/2508.07703", "abs": "https://arxiv.org/abs/2508.07703", "authors": ["Adri Bhattacharya", "Pritam Goswami", "Evangelos Bampas", "Partha Sarathi Mandal"], "title": "Perpetual exploration in anonymous synchronous networks with a Byzantine black hole", "categories": ["cs.DC", "cs.MA"], "comment": "This paper has been accepted at DISC 2025", "summary": "In this paper, we investigate: ``How can a group of initially co-located\nmobile agents perpetually explore an unknown graph, when one stationary node\noccasionally behaves maliciously, under an adversary's control?'' We call this\nnode a ``Byzantine black hole (BBH)'' and at any given round it may choose to\ndestroy all visiting agents, or none. This subtle power can drastically\nundermine classical exploration strategies designed for an always active black\nhole. We study this perpetual exploration problem in the presence of at most\none BBH, without initial knowledge of the network size. Since the underlying\ngraph may be 1-connected, perpetual exploration of the entire graph may be\ninfeasible. We thus define two variants: \\pbmPerpExpl\\ and \\pbmPerpExplHome. In\nthe former, the agents are tasked to perform perpetual exploration of at least\none component, obtained after the exclusion of the BBH. In the latter, the\nagents are tasked to perform perpetual exploration of the component which\ncontains the \\emph{home} node, where agents are initially co-located.\nNaturally, \\pbmPerpExplHome\\ is a special case of \\pbmPerpExpl. Agents operate\nunder a synchronous scheduler and communicate in a face-to-face model. Our goal\nis to determine the minimum number of agents necessary and sufficient to solve\nthese problems. In acyclic networks, we obtain optimal algorithms that solve\n\\pbmPerpExpl\\ with $4$ agents, and \\pbmPerpExplHome\\ with $6$ agents in trees.\nThe lower bounds hold even in path graphs. In general graphs, we give a\nnon-trivial lower bound of $2\\Delta-1$ agents for \\pbmPerpExpl, and an upper\nbound of $3\\Delta+3$ agents for \\pbmPerpExplHome. To our knowledge, this is the\nfirst study of a black-hole variant in arbitrary networks without initial\ntopological knowledge.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.06501", "pdf": "https://arxiv.org/pdf/2508.06501", "abs": "https://arxiv.org/abs/2508.06501", "authors": ["PK Douglas"], "title": "Computing with Canonical Microcircuits", "categories": ["q-bio.NC", "cs.AI", "cs.NE"], "comment": "20 pages, 13 figures", "summary": "The human brain represents the only known example of general intelligence\nthat naturally aligns with human values. On a mere 20-watt power budget, the\nbrain achieves robust learning and adaptive decision-making in ways that\ncontinue to elude advanced AI systems. Inspired by the brain, we present a\ncomputational architecture based on canonical microcircuits (CMCs) -\nstereotyped patterns of neurons found ubiquitously throughout the cortex. We\nimplement these circuits as neural ODEs comprising spiny stellate, inhibitory,\nand pyramidal neurons, forming an 8-dimensional dynamical system with\nbiologically plausible recurrent connections. Our experiments show that even a\nsingle CMC node achieves 97.8 percent accuracy on MNIST, while hierarchical\nconfigurations - with learnable inter-regional connectivity and recurrent\nconnections - yield improved performance on more complex image benchmarks.\nNotably, our approach achieves competitive results using substantially fewer\nparameters than conventional deep learning models. Phase space analysis\nrevealed distinct dynamical trajectories for different input classes,\nhighlighting interpretable, emergent behaviors observed in biological systems.\nThese findings suggest that neuromorphic computing approaches can improve both\nefficiency and interpretability in artificial neural networks, offering new\ndirections for parameter-efficient architectures grounded in the computational\nprinciples of the human brain.", "AI": {"tldr": "\u53d7\u5927\u8111\u542f\u53d1\u63d0\u51fa\u57fa\u4e8e\u89c4\u8303\u5fae\u7535\u8def\uff08CMCs\uff09\u7684\u8ba1\u7b97\u67b6\u6784\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u53c2\u6570\u5c11\u4e14\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u65b0\u65b9\u5411\u3002", "motivation": "\u4eba\u7c7b\u5927\u8111\u4ee5\u4f4e\u529f\u8017\u5b9e\u73b0\u5f3a\u5927\u5b66\u4e60\u548c\u51b3\u7b56\u80fd\u529b\uff0c\u5f53\u524d\u5148\u8fdbAI\u7cfb\u7edf\u96be\u4ee5\u4f01\u53ca\uff0c\u53d7\u6b64\u542f\u53d1\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u57fa\u4e8eCMCs\u6784\u5efa\u8ba1\u7b97\u67b6\u6784\uff0c\u5c06\u5176\u5b9e\u73b0\u4e3a\u5305\u542b\u7279\u5b9a\u795e\u7ecf\u5143\u7684\u795e\u7ecfODEs\uff0c\u5f62\u62108\u7ef4\u52a8\u529b\u7cfb\u7edf\uff0c\u6709\u751f\u7269\u5408\u7406\u7684\u5faa\u73af\u8fde\u63a5\u3002", "result": "\u5355\u4e2aCMC\u8282\u70b9\u5728MNIST\u4e0a\u51c6\u786e\u7387\u8fbe97.8%\uff0c\u5206\u5c42\u914d\u7f6e\u5728\u66f4\u590d\u6742\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u63d0\u5347\uff0c\u4f7f\u7528\u53c2\u6570\u8fdc\u5c11\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u76f8\u7a7a\u95f4\u5206\u6790\u663e\u793a\u4e0d\u540c\u8f93\u5165\u7c7b\u6709\u4e0d\u540c\u52a8\u6001\u8f68\u8ff9\u3002", "conclusion": "\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u65b9\u6cd5\u53ef\u63d0\u9ad8\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u57fa\u4e8e\u4eba\u8111\u8ba1\u7b97\u539f\u7406\u7684\u53c2\u6570\u9ad8\u6548\u67b6\u6784\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.06716", "pdf": "https://arxiv.org/pdf/2508.06716", "abs": "https://arxiv.org/abs/2508.06716", "authors": ["Blair Johnson", "Clayton Kerce", "Faramarz Fekri"], "title": "GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "Differentiable inductive logic programming (ILP) techniques have proven\neffective at finding approximate rule-based solutions to link prediction and\nnode classification problems on knowledge graphs; however, the common\nassumption of chain-like rule structure can hamper the performance and\ninterpretability of existing approaches. We introduce GLIDR, a differentiable\nrule learning method that models the inference of logic rules with more\nexpressive syntax than previous methods. GLIDR uses a differentiable message\npassing inference algorithm that generalizes previous chain-like rule learning\nmethods to allow rules with features like branches and cycles. GLIDR has a\nsimple and expressive rule search space which is parameterized by a limit on\nthe maximum number of free variables that may be included in a rule. Explicit\nlogic rules can be extracted from the weights of a GLIDR model for use with\nsymbolic solvers. We demonstrate that GLIDR can significantly outperform\nexisting rule learning methods on knowledge graph completion tasks and even\ncompete with embedding methods despite the inherent disadvantage of being a\nstructure-only prediction method. We show that rules extracted from GLIDR\nretain significant predictive performance, and that GLIDR is highly robust to\ntraining data noise. Finally, we demonstrate that GLIDR can be chained with\ndeep neural networks and optimized end-to-end for rule learning on arbitrary\ndata modalities.", "AI": {"tldr": "\u4ecb\u7ecdGLIDR\u65b9\u6cd5\uff0c\u5b83\u6bd4\u4ee5\u5f80\u65b9\u6cd5\u6709\u66f4\u5177\u8868\u73b0\u529b\u7684\u89c4\u5219\u8bed\u6cd5\uff0c\u5728\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u89c4\u5219\u53ef\u63d0\u53d6\uff0c\u5bf9\u566a\u58f0\u9c81\u68d2\uff0c\u8fd8\u80fd\u4e0e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u3002", "motivation": "\u73b0\u6709\u53ef\u5fae\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u6280\u672f\u4e2d\u5e38\u89c1\u7684\u94fe\u72b6\u89c4\u5219\u7ed3\u6784\u5047\u8bbe\u4f1a\u5f71\u54cd\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f15\u5165GLIDR\uff0c\u4f7f\u7528\u53ef\u5fae\u6d88\u606f\u4f20\u9012\u63a8\u7406\u7b97\u6cd5\uff0c\u63a8\u5e7f\u94fe\u72b6\u89c4\u5219\u5b66\u4e60\u65b9\u6cd5\uff0c\u89c4\u5219\u641c\u7d22\u7a7a\u95f4\u7b80\u5355\u4e14\u7531\u6700\u5927\u81ea\u7531\u53d8\u91cf\u6570\u53c2\u6570\u5316\uff0c\u53ef\u4ece\u6a21\u578b\u6743\u91cd\u4e2d\u63d0\u53d6\u89c4\u5219\u3002", "result": "GLIDR\u5728\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u89c4\u5219\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u53d6\u7684\u89c4\u5219\u6709\u663e\u8457\u9884\u6d4b\u6027\u80fd\uff0c\u5bf9\u8bad\u7ec3\u6570\u636e\u566a\u58f0\u9ad8\u5ea6\u9c81\u68d2\uff0c\u53ef\u4e0e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7aef\u5230\u7aef\u4f18\u5316\u3002", "conclusion": "GLIDR\u662f\u4e00\u79cd\u6709\u6548\u7684\u89c4\u5219\u5b66\u4e60\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\uff0c\u8fd8\u80fd\u4e0e\u5176\u4ed6\u6a21\u578b\u7ed3\u5408\u7528\u4e8e\u4efb\u610f\u6570\u636e\u6a21\u6001\u7684\u89c4\u5219\u5b66\u4e60\u3002"}}
{"id": "2508.07699", "pdf": "https://arxiv.org/pdf/2508.07699", "abs": "https://arxiv.org/abs/2508.07699", "authors": ["Hang Ren", "Xiaozhen Sun", "Tianzi Ma", "Jiajia Zhang", "Xuan Wang"], "title": "Last-Iterate Convergence in Adaptive Regret Minimization for Approximate Extensive-Form Perfect Equilibrium", "categories": ["cs.GT"], "comment": null, "summary": "The Nash Equilibrium (NE) assumes rational play in imperfect-information\nExtensive-Form Games (EFGs) but fails to ensure optimal strategies for\noff-equilibrium branches of the game tree, potentially leading to suboptimal\noutcomes in practical settings. To address this, the Extensive-Form Perfect\nEquilibrium (EFPE), a refinement of NE, introduces controlled perturbations to\nmodel potential player errors. However, existing EFPE-finding algorithms, which\ntypically rely on average strategy convergence and fixed perturbations, face\nsignificant limitations: computing average strategies incurs high computational\ncosts and approximation errors, while fixed perturbations create a trade-off\nbetween NE approximation accuracy and the convergence rate of NE refinements.\n  To tackle these challenges, we propose an efficient adaptive regret\nminimization algorithm for computing approximate EFPE, achieving last-iterate\nconvergence in two-player zero-sum EFGs. Our approach introduces Reward\nTransformation Counterfactual Regret Minimization (RTCFR) to solve perturbed\ngames and defines a novel metric, the Information Set Nash Equilibrium (ISNE),\nto dynamically adjust perturbations. Theoretical analysis confirms convergence\nto EFPE, and experimental results demonstrate that our method significantly\noutperforms state-of-the-art algorithms in both NE and EFPE-finding tasks.", "AI": {"tldr": "\u73b0\u6709\u6c42Extensive - Form Perfect Equilibrium (EFPE)\u7b97\u6cd5\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51fa\u9ad8\u6548\u81ea\u9002\u5e94\u540e\u6094\u6700\u5c0f\u5316\u7b97\u6cd5\u8ba1\u7b97\u8fd1\u4f3cEFPE\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "Nash Equilibrium (NE)\u5728\u6e38\u620f\u6811\u975e\u5747\u8861\u5206\u652f\u4e0d\u80fd\u4fdd\u8bc1\u6700\u4f18\u7b56\u7565\uff0c\u73b0\u6709EFPE\u6c42\u89e3\u7b97\u6cd5\u6709\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u8fd1\u4f3c\u8bef\u5dee\u5927\u7b49\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u9ad8\u6548\u81ea\u9002\u5e94\u540e\u6094\u6700\u5c0f\u5316\u7b97\u6cd5\uff0c\u5f15\u5165Reward Transformation Counterfactual Regret Minimization (RTCFR)\u6c42\u89e3\u6270\u52a8\u6e38\u620f\uff0c\u5b9a\u4e49\u65b0\u6307\u6807Information Set Nash Equilibrium (ISNE)\u52a8\u6001\u8c03\u6574\u6270\u52a8\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u6536\u655b\u5230EFPE\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728NE\u548cEFPE\u6c42\u89e3\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6c42EFPE\u7b97\u6cd5\u5c40\u9650\uff0c\u5728\u76f8\u5173\u4efb\u52a1\u4e2d\u6709\u66f4\u597d\u8868\u73b0\u3002"}}
{"id": "2508.07342", "pdf": "https://arxiv.org/pdf/2508.07342", "abs": "https://arxiv.org/abs/2508.07342", "authors": ["Kepu Zhang", "Teng Shi", "Weijie Yu", "Jun Xu"], "title": "PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Personalized retrieval-augmented generation (RAG) aims to produce\nuser-tailored responses by incorporating retrieved user profiles alongside the\ninput query. Existing methods primarily focus on improving retrieval and rely\non large language models (LLMs) to implicitly integrate the retrieved context\nwith the query. However, such models are often sensitive to retrieval quality\nand may generate responses that are misaligned with user preferences. To\naddress this limitation, we propose PrLM, a reinforcement learning framework\nthat trains LLMs to explicitly reason over retrieved user profiles. Guided by a\ncontrastively trained personalization reward model, PrLM effectively learns\nfrom user responses without requiring annotated reasoning paths. Experiments on\nthree personalized text generation datasets show that PrLM outperforms existing\nmethods and remains robust across varying numbers of retrieved profiles and\ndifferent retrievers.", "AI": {"tldr": "\u63d0\u51faPrLM\u6846\u67b6\u89e3\u51b3\u73b0\u6709\u4e2a\u6027\u5316\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u68c0\u7d22\u8d28\u91cf\u4e14\u54cd\u5e94\u53ef\u80fd\u4e0e\u7528\u6237\u504f\u597d\u4e0d\u7b26\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u68c0\u7d22\u8d28\u91cf\uff0c\u751f\u6210\u54cd\u5e94\u53ef\u80fd\u4e0e\u7528\u6237\u504f\u597d\u4e0d\u7b26\u3002", "method": "\u63d0\u51faPrLM\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u8bad\u7ec3\u7684\u4e2a\u6027\u5316\u5956\u52b1\u6a21\u578b\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u68c0\u7d22\u5230\u7684\u7528\u6237\u8d44\u6599\u8fdb\u884c\u663e\u5f0f\u63a8\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u4e2a\u6027\u5316\u6587\u672c\u751f\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPrLM\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u4e0d\u540c\u6570\u91cf\u7684\u68c0\u7d22\u8d44\u6599\u548c\u4e0d\u540c\u68c0\u7d22\u5668\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "PrLM\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u662f\u4e00\u79cd\u66f4\u4f18\u7684\u4e2a\u6027\u5316\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u3002"}}
{"id": "2508.07823", "pdf": "https://arxiv.org/pdf/2508.07823", "abs": "https://arxiv.org/abs/2508.07823", "authors": ["Yang Hu"], "title": "Nearly Optimal Bounds for Stochastic Online Sorting", "categories": ["cs.DS"], "comment": null, "summary": "In the online sorting problem, we have an array $A$ of $n$ cells, and receive\na stream of $n$ items $x_1,\\dots,x_n\\in [0,1]$. When an item arrives, we need\nto immediately and irrevocably place it into an empty cell. The goal is to\nminimize the sum of absolute differences between adjacent items, which is\ncalled the \\emph{cost} of the algorithm. It has been shown by Aamand,\nAbrahamsen, Beretta, and Kleist (SODA 2023) that when the stream\n$x_1,\\dots,x_n$ is generated adversarially, the optimal cost bound for any\ndeterministic algorithm is $\\Theta(\\sqrt{n})$.\n  In this paper, we study the stochastic version of online sorting, where the\ninput items $x_1,\\dots,x_n$ are sampled uniformly at random. Despite the\nintuition that the stochastic version should yield much better cost bounds, the\nprevious best algorithm for stochastic online sorting by Abrahamsen, Bercea,\nBeretta, Klausen and Kozma (ESA 2024) only achieves $\\tilde{O}(n^{1/4})$ cost,\nwhich seems far from optimal. We show that stochastic online sorting indeed\nallows for much more efficient algorithms, by presenting an algorithm that\nachieves expected cost $\\log n\\cdot 2^{O(\\log^* n)}$. We also prove a cost\nlower bound of $\\Omega(\\log n)$, thus show that our algorithm is nearly\noptimal.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.07180", "pdf": "https://arxiv.org/pdf/2508.07180", "abs": "https://arxiv.org/abs/2508.07180", "authors": ["Zhe Zhang", "Runlin Liu", "Aishan Liu", "Xingyu Liu", "Xiang Gao", "Hailong Sun"], "title": "Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "As large language models LLMs) become increasingly integrated into software\ndevelopment workflows, rigorously evaluating their performance on complex,\nreal-world code generation tasks has become essential. However, existing\nbenchmarks often suffer from data contamination and limited test rigor,\nconstraining their ability to reveal model failures effectively. To address\nthese, we present CODE2BENCH, a end-to-end pipeline for dynamically\nconstructing robust and contamination-resistant benchmarks from real-world\nGitHub repositories. Specifically, CODE2BENCH introduces three key innovations:\n(1) Automated Dynamism, achieved through periodic ingestion of recent code to\nminimize training data contamination; (2) Scope Graph-based dependency\nanalysis, which enables structured classification of functions into benchmark\ninstances with controlled dependency levels (distinguishing between\nSelf-Contained (SC) tasks for cross-language evaluation and Weakly\nSelf-Contained (WSC) tasks involving permitted library usage); and (3)\nProperty-Based Testing (PBT) for the automated synthesis of rigorous test\nsuites to enable thorough functional verification. Using this pipeline, we\nconstruct CODE2BENCH-2505, the first benchmark derived from 880 recent Python\nprojects spanning diverse domains, comprising 1,163 code generation tasks with\n100% average branch coverage on ground-truth implementations. Extensive\nevaluation of 16 LLMs using CODE2BENCH-2505 reveals that models consistently\nstruggle with SC tasks requiring complex, non-standard logic and cross-language\ntransfer, while showing relatively stronger performance on WSC tasks in Python.\nOur work introduces a contamination-resistant, language-agnostic methodology\nfor dynamic benchmark construction, offering a principled foundation for the\ncomprehensive and realistic evaluation of LLMs on real-world software\ndevelopment tasks.", "AI": {"tldr": "\u63d0\u51faCODE2BENCH\u6784\u5efa\u6297\u6c61\u67d3\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u5176\u6784\u5efaCODE2BENCH - 2505\u8bc4\u4f3016\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u8868\u73b0\u4e0d\u540c\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u6d4b\u8bd5\u4e25\u8c28\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u9700\u6709\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u73b0\u5b9e\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51faCODE2BENCH\uff0c\u5305\u542b\u81ea\u52a8\u52a8\u6001\u66f4\u65b0\u3001\u57fa\u4e8e\u4f5c\u7528\u57df\u56fe\u7684\u4f9d\u8d56\u5206\u6790\u548c\u57fa\u4e8e\u5c5e\u6027\u7684\u6d4b\u8bd5\uff0c\u7528\u5176\u6784\u5efaCODE2BENCH - 2505\u3002", "result": "\u8bc4\u4f3016\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6a21\u578b\u5728\u590d\u6742\u975e\u6807\u51c6\u903b\u8f91\u548c\u8de8\u8bed\u8a00\u7684SC\u4efb\u52a1\u8868\u73b0\u5dee\uff0c\u5728Python\u7684WSC\u4efb\u52a1\u8868\u73b0\u8f83\u597d\u3002", "conclusion": "\u63d0\u51fa\u6297\u6c61\u67d3\u3001\u8bed\u8a00\u65e0\u5173\u7684\u52a8\u6001\u57fa\u51c6\u6784\u5efa\u65b9\u6cd5\uff0c\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2508.06601", "pdf": "https://arxiv.org/pdf/2508.06601", "abs": "https://arxiv.org/abs/2508.06601", "authors": ["Kyle O'Brien", "Stephen Casper", "Quentin Anthony", "Tomek Korbak", "Robert Kirk", "Xander Davies", "Ishan Mishra", "Geoffrey Irving", "Yarin Gal", "Stella Biderman"], "title": "Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "https://deepignorance.ai/", "summary": "Open-weight AI systems offer unique benefits, including enhanced\ntransparency, open research, and decentralized access. However, they are\nvulnerable to tampering attacks which can efficiently elicit harmful behaviors\nby modifying weights or activations. Currently, there is not yet a robust\nscience of open-weight model risk management. Existing safety fine-tuning\nmethods and other post-training techniques have struggled to make LLMs\nresistant to more than a few dozen steps of adversarial fine-tuning. In this\npaper, we investigate whether filtering text about dual-use topics from\ntraining data can prevent unwanted capabilities and serve as a more\ntamper-resistant safeguard. We introduce a multi-stage pipeline for scalable\ndata filtering and show that it offers a tractable and effective method for\nminimizing biothreat proxy knowledge in LLMs. We pretrain multiple\n6.9B-parameter models from scratch and find that they exhibit substantial\nresistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M\ntokens of biothreat-related text -- outperforming existing post-training\nbaselines by over an order of magnitude -- with no observed degradation to\nunrelated capabilities. However, while filtered models lack internalized\ndangerous knowledge, we find that they can still leverage such information when\nit is provided in context (e.g., via search tool augmentation), demonstrating a\nneed for a defense-in-depth approach. Overall, these findings help to establish\npretraining data curation as a promising layer of defense for open-weight AI\nsystems.", "AI": {"tldr": "\u7814\u7a76\u8fc7\u6ee4\u8bad\u7ec3\u6570\u636e\u4e2d\u4e24\u7528\u4e3b\u9898\u6587\u672c\u80fd\u5426\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u6297\u7be1\u6539\uff0c\u63d0\u51fa\u591a\u9636\u6bb5\u6570\u636e\u8fc7\u6ee4\u7ba1\u9053\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u6297\u653b\u51fb\u8868\u73b0\u597d\uff0c\u8fd8\u6307\u51fa\u9700\u6df1\u5ea6\u9632\u5fa1\u3002", "motivation": "\u5f00\u653e\u6743\u91cdAI\u7cfb\u7edf\u6613\u53d7\u7be1\u6539\u653b\u51fb\uff0c\u73b0\u6709\u7684\u5b89\u5168\u5fae\u8c03\u7b49\u65b9\u6cd5\u96be\u4ee5\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u62b5\u6297\u591a\u8f6e\u5bf9\u6297\u6027\u5fae\u8c03\uff0c\u4e14\u7f3a\u4e4f\u6709\u6548\u7684\u98ce\u9669\u7ba1\u7406\u79d1\u5b66\u3002", "method": "\u5f15\u5165\u591a\u9636\u6bb5\u53ef\u6269\u5c55\u6570\u636e\u8fc7\u6ee4\u7ba1\u9053\uff0c\u4ece\u5934\u9884\u8bad\u7ec3\u591a\u4e2a69\u4ebf\u53c2\u6570\u6a21\u578b\u3002", "result": "\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u591a\u8fbe10000\u6b65\u548c3\u4ebf\u4e2a\u751f\u7269\u5a01\u80c1\u76f8\u5173\u6587\u672c\u6807\u8bb0\u7684\u5bf9\u6297\u6027\u5fae\u8c03\u653b\u51fb\u8868\u73b0\u51fa\u663e\u8457\u6297\u6027\uff0c\u8fdc\u8d85\u73b0\u6709\u540e\u8bad\u7ec3\u57fa\u7ebf\uff0c\u4e14\u4e0d\u5f71\u54cd\u65e0\u5173\u80fd\u529b\u3002\u4f46\u8fc7\u6ee4\u6a21\u578b\u5728\u6709\u4e0a\u4e0b\u6587\u4fe1\u606f\u65f6\u4ecd\u80fd\u5229\u7528\u5371\u9669\u77e5\u8bc6\u3002", "conclusion": "\u9884\u8bad\u7ec3\u6570\u636e\u7b5b\u9009\u662f\u5f00\u653e\u6743\u91cdAI\u7cfb\u7edf\u6709\u524d\u666f\u7684\u9632\u5fa1\u624b\u6bb5\uff0c\u540c\u65f6\u9700\u8981\u6df1\u5ea6\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2508.07982", "pdf": "https://arxiv.org/pdf/2508.07982", "abs": "https://arxiv.org/abs/2508.07982", "authors": ["Leonardo V. Santoro", "Victor M. Panaretos"], "title": "Likelihood Ratio Tests by Kernel Gaussian Embedding", "categories": ["stat.ML", "cs.LG", "stat.ME", "62G10, 62G20, 62H15, 62H20, 60G15, 46E22"], "comment": null, "summary": "We propose a novel kernel-based nonparametric two-sample test, employing the\ncombined use of kernel mean and kernel covariance embedding. Our test builds on\nrecent results showing how such combined embeddings map distinct probability\nmeasures to mutually singular Gaussian measures on the kernel's RKHS.\nLeveraging this result, we construct a test statistic based on the relative\nentropy between the Gaussian embeddings, i.e.\\ the likelihood ratio. The\nlikelihood ratio is specifically tailored to detect equality versus singularity\nof two Gaussians, and satisfies a ``$0/\\infty$\" law, in that it vanishes under\nthe null and diverges under the alternative. To implement the test in finite\nsamples, we introduce a regularised version, calibrated by way of permutation.\nWe prove consistency, establish uniform power guarantees under mild conditions,\nand discuss how our framework unifies and extends prior approaches based on\nspectrally regularized MMD. Empirical results on synthetic and real data\ndemonstrate remarkable gains in power compared to state-of-the-art methods,\nparticularly in high-dimensional and weak-signal regimes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6838\u5747\u503c\u548c\u6838\u534f\u65b9\u5dee\u5d4c\u5165\u7684\u975e\u53c2\u6570\u53cc\u6837\u672c\u68c0\u9a8c\uff0c\u6784\u5efa\u4f3c\u7136\u6bd4\u7edf\u8ba1\u91cf\uff0c\u5f15\u5165\u6b63\u5219\u5316\u7248\u672c\uff0c\u8bc1\u660e\u4e00\u81f4\u6027\u548c\u529f\u6548\u4fdd\u8bc1\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u3002", "motivation": "\u63d0\u51fa\u65b0\u7684\u6838\u57fa\u975e\u53c2\u6570\u53cc\u6837\u672c\u68c0\u9a8c\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u6838\u5747\u503c\u548c\u6838\u534f\u65b9\u5dee\u5d4c\u5165\uff0c\u57fa\u4e8e\u9ad8\u65af\u5d4c\u5165\u7684\u76f8\u5bf9\u71b5\u6784\u5efa\u4f3c\u7136\u6bd4\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff0c\u5f15\u5165\u6b63\u5219\u5316\u7248\u672c\u5e76\u901a\u8fc7\u7f6e\u6362\u6821\u51c6\u3002", "result": "\u8bc1\u660e\u4e86\u4e00\u81f4\u6027\uff0c\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u6709\u7edf\u4e00\u529f\u6548\u4fdd\u8bc1\uff0c\u5b9e\u9a8c\u663e\u793a\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u9ad8\u7ef4\u548c\u5f31\u4fe1\u53f7\u573a\u666f\u6709\u663e\u8457\u529f\u6548\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u7edf\u4e00\u5e76\u6269\u5c55\u4e86\u57fa\u4e8e\u8c31\u6b63\u5219\u5316MMD\u7684\u5148\u524d\u65b9\u6cd5\uff0c\u65b0\u68c0\u9a8c\u65b9\u6cd5\u6027\u80fd\u4f18\u8d8a\u3002"}}
{"id": "2508.07654", "pdf": "https://arxiv.org/pdf/2508.07654", "abs": "https://arxiv.org/abs/2508.07654", "authors": ["Fei Ye", "Jiapan Liu", "Yinan Jing", "Zhenying He", "Weirao Wang", "X. Sean Wang"], "title": "MLego: Interactive and Scalable Topic Exploration Through Model Reuse", "categories": ["cs.DB", "cs.IR"], "comment": "14 pages", "summary": "With massive texts on social media, users and analysts often rely on topic\nmodeling techniques to quickly extract key themes and gain insights.\nTraditional topic modeling techniques, such as Latent Dirichlet Allocation\n(LDA), provide valuable insights but are computationally expensive, making them\nimpractical for real-time data analysis. Although recent advances in\ndistributed training and fast sampling methods have improved efficiency,\nreal-time topic exploration remains a significant challenge. In this paper, we\npresent MLego, an interactive query framework designed to support real-time\ntopic modeling analysis by leveraging model materialization and reuse. Instead\nof retraining models from scratch, MLego efficiently merges materialized topic\nmodels to construct approximate results at interactive speeds. To further\nenhance efficiency, we introduce a hierarchical plan search strategy for single\nqueries and an optimized query reordering technique for batch queries. We\nintegrate MLego into a visual analytics prototype system, enabling users to\nexplore large-scale textual datasets through interactive queries. Extensive\nexperiments demonstrate that MLego significantly reduces computation costs\nwhile maintaining high-quality topic modeling results. MLego enhances existing\nvisual analytics approaches, which primarily focus on user-driven topic\nmodeling, by enabling real-time, query-driven exploration. This complements\ntraditional methods and bridges the gap between scalable topic modeling and\ninteractive data analysis.", "AI": {"tldr": "\u63d0\u51fa\u4ea4\u4e92\u5f0f\u67e5\u8be2\u6846\u67b6MLego\u652f\u6301\u5b9e\u65f6\u4e3b\u9898\u5efa\u6a21\u5206\u6790\uff0c\u901a\u8fc7\u5408\u5e76\u7269\u5316\u4e3b\u9898\u6a21\u578b\u63d0\u9ad8\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u6301\u9ad8\u8d28\u91cf\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u4e3b\u9898\u5efa\u6a21\u6280\u672f\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5b9e\u65f6\u4e3b\u9898\u63a2\u7d22\u4ecd\u662f\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u65b9\u6cd5\u652f\u6301\u5b9e\u65f6\u5206\u6790\u3002", "method": "\u63d0\u51faMLego\u6846\u67b6\uff0c\u5229\u7528\u6a21\u578b\u7269\u5316\u548c\u91cd\u7528\uff0c\u5408\u5e76\u7269\u5316\u4e3b\u9898\u6a21\u578b\u6784\u5efa\u8fd1\u4f3c\u7ed3\u679c\uff0c\u5f15\u5165\u5206\u5c42\u8ba1\u5212\u641c\u7d22\u7b56\u7565\u548c\u67e5\u8be2\u91cd\u6392\u5e8f\u6280\u672f\uff0c\u96c6\u6210\u5230\u53ef\u89c6\u5316\u5206\u6790\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eMLego\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u4e3b\u9898\u5efa\u6a21\u7ed3\u679c\u3002", "conclusion": "MLego\u589e\u5f3a\u73b0\u6709\u53ef\u89c6\u5316\u5206\u6790\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5b9e\u65f6\u3001\u67e5\u8be2\u9a71\u52a8\u63a2\u7d22\uff0c\u5f25\u8865\u53ef\u6269\u5c55\u4e3b\u9898\u5efa\u6a21\u548c\u4ea4\u4e92\u5f0f\u6570\u636e\u5206\u6790\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.07697", "pdf": "https://arxiv.org/pdf/2508.07697", "abs": "https://arxiv.org/abs/2508.07697", "authors": ["Hao Liu", "Chun Yang", "Zhang xiaoxing", "Xiaobin Zhu"], "title": "Semantic-Enhanced Time-Series Forecasting via Large Language Models", "categories": ["cs.LG", "cs.CE"], "comment": "14 pages,9 figures", "summary": "Time series forecasting plays a significant role in finance, energy,\nmeteorology, and IoT applications. Recent studies have leveraged the\ngeneralization capabilities of large language models (LLMs) to adapt to time\nseries forecasting, achieving promising performance. However, existing studies\nfocus on token-level modal alignment, instead of bridging the intrinsic\nmodality gap between linguistic knowledge structures and time series data\npatterns, greatly limiting the semantic representation. To address this issue,\nwe propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent\nperiodicity and anomalous characteristics of time series to embed into the\nsemantic space to enhance the token embedding. This process enhances the\ninterpretability of tokens for LLMs, thereby activating the potential of LLMs\nfor temporal sequence analysis. Moreover, existing Transformer-based LLMs excel\nat capturing long-range dependencies but are weak at modeling short-term\nanomalies in time-series data. Hence, we propose a plugin module embedded\nwithin self-attention that models long-term and short-term dependencies to\neffectively adapt LLMs to time-series analysis. Our approach freezes the LLM\nand reduces the sequence dimensionality of tokens, greatly reducing\ncomputational consumption. Experiments demonstrate the superiority performance\nof our SE-LLM against the state-of-the-art (SOTA) methods.", "AI": {"tldr": "\u63d0\u51faSE - LLM\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u7ed3\u5408\u5468\u671f\u6027\u4e0e\u5f02\u5e38\u7279\u5f81\u589e\u5f3a\u8bed\u4e49\u5d4c\u5165\uff0c\u6dfb\u52a0\u63d2\u4ef6\u6a21\u5757\u5904\u7406\u957f\u77ed\u671f\u4f9d\u8d56\uff0c\u964d\u4f4e\u8ba1\u7b97\u91cf\uff0c\u5b9e\u9a8c\u6548\u679c\u4f18\u4e8eSOTA\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u805a\u7126\u4e8etoken\u7ea7\u6a21\u6001\u5bf9\u9f50\uff0c\u672a\u5f25\u5408\u8bed\u8a00\u77e5\u8bc6\u7ed3\u6784\u4e0e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u6a21\u5f0f\u7684\u5185\u5728\u6a21\u6001\u5dee\u8ddd\uff0c\u9650\u5236\u8bed\u4e49\u8868\u793a\uff1bTransformer - based LLMs\u5728\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u77ed\u671f\u5f02\u5e38\u80fd\u529b\u5f31\u3002", "method": "\u63d0\u51faSemantic - Enhanced LLM (SE - LLM)\uff0c\u63a2\u7d22\u65f6\u95f4\u5e8f\u5217\u56fa\u6709\u5468\u671f\u6027\u548c\u5f02\u5e38\u7279\u5f81\u5d4c\u5165\u8bed\u4e49\u7a7a\u95f4\u589e\u5f3atoken\u5d4c\u5165\uff1b\u63d0\u51fa\u63d2\u4ef6\u6a21\u5757\u5d4c\u5165\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5904\u7406\u957f\u77ed\u671f\u4f9d\u8d56\uff1b\u51bb\u7ed3LLM\u5e76\u964d\u4f4etoken\u5e8f\u5217\u7ef4\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSE - LLM\u6027\u80fd\u4f18\u4e8e\u73b0\u6709SOTA\u65b9\u6cd5\u3002", "conclusion": "SE - LLM\u80fd\u6709\u6548\u5f25\u5408\u8bed\u8a00\u77e5\u8bc6\u4e0e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u6a21\u6001\u5dee\u8ddd\uff0c\u5904\u7406\u957f\u77ed\u671f\u4f9d\u8d56\uff0c\u964d\u4f4e\u8ba1\u7b97\u91cf\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.08166", "pdf": "https://arxiv.org/pdf/2508.08166", "abs": "https://arxiv.org/abs/2508.08166", "authors": ["Ercio Mu\u00f1oz", "Dario Sansone", "Jo\u00e3o Tampellini"], "title": "Relative Income and Gender Norms: Evidence from Latin America", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Using data from over 500,000 dual-earner households in Mexico, we provide\nevidence of discontinuities in the distribution of relative income within\nhouseholds in Latin America. Similar to high-income countries, we observe a\nsharp drop at the 50% threshold, where the wife earns more than the husband,\nbut the discontinuity is up to five times larger and has increased over time.\nThese patterns are robust to excluding equal earners, self-employed\nindividuals, or couples in the same occupation/industry. Discontinuities\npersist across subgroups, including couples with or without children, married\nor unmarried partners, and those with older wives or female household heads. We\nalso find comparable discontinuities in Brazil and Panama, as well as among\nsome same-sex couples. Moreover, women who are primary earners continue to\nsupply more non-market labor than their male partners, although the gap is\nnarrower than in households where the woman is the secondary earner.", "AI": {"tldr": "\u5229\u7528\u58a8\u897f\u54e5\u8d8550\u4e07\u53cc\u6536\u5165\u5bb6\u5ead\u6570\u636e\uff0c\u53d1\u73b0\u62c9\u7f8e\u5bb6\u5ead\u76f8\u5bf9\u6536\u5165\u5206\u5e03\u5728\u59bb\u5b50\u6536\u5165\u8d85\u4e08\u592b\u5904\u6709\u4e0d\u8fde\u7eed\u6027\uff0c\u8be5\u73b0\u8c61\u5728\u5df4\u897f\u3001\u5df4\u62ff\u9a6c\u53ca\u90e8\u5206\u540c\u6027\u4f34\u4fa3\u4e2d\u4e5f\u5b58\u5728\uff0c\u4e14\u4e3b\u6323\u94b1\u5973\u6027\u4ecd\u627f\u62c5\u66f4\u591a\u975e\u5e02\u573a\u52b3\u52a8\u3002", "motivation": "\u7814\u7a76\u62c9\u7f8e\u5bb6\u5ead\u5185\u90e8\u76f8\u5bf9\u6536\u5165\u5206\u5e03\u7684\u7279\u5f81\u53ca\u89c4\u5f8b\u3002", "method": "\u4f7f\u7528\u58a8\u897f\u54e5\u8d8550\u4e07\u53cc\u6536\u5165\u5bb6\u5ead\u7684\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u6392\u9664\u90e8\u5206\u7fa4\u4f53\u4ee5\u9a8c\u8bc1\u7ed3\u679c\u7a33\u5065\u6027\uff0c\u5e76\u5bf9\u6bd4\u4e0d\u540c\u5b50\u7fa4\u4f53\u60c5\u51b5\uff0c\u8fd8\u7814\u7a76\u4e86\u5df4\u897f\u3001\u5df4\u62ff\u9a6c\u53ca\u540c\u6027\u4f34\u4fa3\u60c5\u51b5\u3002", "result": "\u5728\u62c9\u7f8e\u5bb6\u5ead\u76f8\u5bf9\u6536\u5165\u5206\u5e03\u4e2d\uff0c\u59bb\u5b50\u6536\u5165\u8d85\u4e08\u592b\u768450%\u9608\u503c\u5904\u6709\u660e\u663e\u4e0d\u8fde\u7eed\u6027\u4e14\u6bd4\u9ad8\u6536\u5165\u56fd\u5bb6\u5927\u4e14\u968f\u65f6\u95f4\u589e\u52a0\uff0c\u8be5\u73b0\u8c61\u5728\u591a\u4e2a\u5b50\u7fa4\u4f53\u548c\u5176\u4ed6\u56fd\u5bb6\u53ca\u90e8\u5206\u540c\u6027\u4f34\u4fa3\u4e2d\u6301\u7eed\u5b58\u5728\uff0c\u4e3b\u6323\u94b1\u5973\u6027\u4ecd\u627f\u62c5\u66f4\u591a\u975e\u5e02\u573a\u52b3\u52a8\u4f46\u5dee\u8ddd\u7f29\u5c0f\u3002", "conclusion": "\u62c9\u7f8e\u5bb6\u5ead\u76f8\u5bf9\u6536\u5165\u5206\u5e03\u5b58\u5728\u7279\u5b9a\u4e0d\u8fde\u7eed\u6027\uff0c\u4e14\u5973\u6027\u5373\u4f7f\u6210\u4e3a\u4e3b\u8981\u6536\u5165\u8005\u4ecd\u627f\u62c5\u8f83\u591a\u975e\u5e02\u573a\u52b3\u52a8\u3002"}}
{"id": "2508.07744", "pdf": "https://arxiv.org/pdf/2508.07744", "abs": "https://arxiv.org/abs/2508.07744", "authors": ["Ingo Friese", "Jochen Klaffer", "Mandy Galkow-Schneider", "Sergiy Melnyk", "Qiuheng Zhou", "Hans Dieter Schotten"], "title": "Over-the-Top Resource Broker System for Split Computing: An Approach to Distribute Cloud Computing Infrastructure", "categories": ["cs.DC", "cs.NI", "eess.SP"], "comment": null, "summary": "6G network architectures will usher in a wave of innovative services and\ncapabilities, introducing concepts like split computing and dynamic processing\nnodes. This implicates a paradigm where accessing resources seamlessly aligns\nwith diverse processing node characteristics, ensuring a uniform interface. In\nthis landscape, the identity of the operator becomes inconsequential, paving\nthe way for a collaborative ecosystem where multiple providers contribute to a\nshared pool of resources. At the core of this vision is the guarantee of\nspecific performance parameters, precisely tailored to the location and service\nrequirements. A consistent layer, as the abstraction of the complexities of\ndifferent infrastructure providers, is needed to simplify service deployment.\nOne promising approach is the introduction of an over-the-top broker for\nresource allocation, which streamlines the integration of these services into\nthe network and cloud infrastructure of the future. This paper explores the\nrole of the broker in two split computing scenarios. By abstracting the\ncomplexities of various infrastructures, the broker proves to be a versatile\nsolution applicable not only to cloud environments but also to networks and\nbeyond. Additionally, a detailed discussion of a proof-of-concept\nimplementation provides insights into the broker's actual architectural\nframework.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba86G\u7f51\u7edc\u67b6\u6784\u4e2d\u8d44\u6e90\u5206\u914d\u7684OTP\u4ee3\u7406\u89d2\u8272\uff0c\u5206\u6790\u5176\u5728\u4e24\u79cd\u62c6\u5206\u8ba1\u7b97\u573a\u666f\u7684\u4f5c\u7528\u5e76\u7ed9\u51fa\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\u3002", "motivation": "6G\u7f51\u7edc\u67b6\u6784\u5e26\u6765\u521b\u65b0\u670d\u52a1\u548c\u80fd\u529b\uff0c\u9700\u89e3\u51b3\u8d44\u6e90\u65e0\u7f1d\u8bbf\u95ee\u3001\u591a\u63d0\u4f9b\u5546\u534f\u4f5c\u53ca\u6027\u80fd\u4fdd\u969c\u7b49\u95ee\u9898\uff0c\u7b80\u5316\u670d\u52a1\u90e8\u7f72\u3002", "method": "\u5f15\u5165OTP\u4ee3\u7406\u8fdb\u884c\u8d44\u6e90\u5206\u914d\uff0c\u63a2\u8ba8\u5176\u5728\u4e24\u79cd\u62c6\u5206\u8ba1\u7b97\u573a\u666f\u7684\u4f5c\u7528\uff0c\u8fdb\u884c\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\u3002", "result": "\u4ee3\u7406\u53ef\u62bd\u8c61\u57fa\u7840\u8bbe\u65bd\u590d\u6742\u6027\uff0c\u662f\u9002\u7528\u4e8e\u4e91\u3001\u7f51\u7edc\u7b49\u73af\u5883\u7684\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "OTP\u4ee3\u7406\u57286G\u7f51\u7edc\u8d44\u6e90\u5206\u914d\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u80fd\u7b80\u5316\u670d\u52a1\u90e8\u7f72\u3002"}}
{"id": "2508.06817", "pdf": "https://arxiv.org/pdf/2508.06817", "abs": "https://arxiv.org/abs/2508.06817", "authors": ["Yutong Wu", "Peilin He", "Tananun Songdechakraiwut"], "title": "Data-Efficient Neural Training with Dynamic Connectomes", "categories": ["q-bio.NC", "cs.NE"], "comment": "15 pages, 3 figures, 8 tables", "summary": "The study of dynamic functional connectomes has provided valuable insights\ninto how patterns of brain activity change over time. Neural networks process\ninformation through artificial neurons, conceptually inspired by patterns of\nactivation in the brain. However, their hierarchical structure and\nhigh-dimensional parameter space pose challenges for understanding and\ncontrolling training dynamics. In this study, we introduce a novel approach to\ncharacterize training dynamics in neural networks by representing evolving\nneural activations as functional connectomes and extracting dynamic signatures\nof activity throughout training. Our results show that these signatures\neffectively capture key transitions in the functional organization of the\nnetwork. Building on this analysis, we propose the use of a time series of\nfunctional connectomes as an intrinsic indicator of learning progress, enabling\na principled early stopping criterion. Our framework performs robustly across\nbenchmarks and provides new insights into neural network training dynamics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u795e\u7ecf\u6fc0\u6d3b\u8868\u793a\u4e3a\u529f\u80fd\u8fde\u63a5\u7ec4\u4ee5\u8868\u5f81\u8bad\u7ec3\u52a8\u6001\uff0c\u6b64\u65b9\u6cd5\u53ef\u6355\u6349\u7f51\u7edc\u529f\u80fd\u7ec4\u7ec7\u8f6c\u53d8\uff0c\u8fd8\u53ef\u4f5c\u4e3a\u5b66\u4e60\u8fdb\u5ea6\u6307\u6807\u5b9e\u73b0\u63d0\u524d\u505c\u6b62\u8bad\u7ec3\uff0c\u6846\u67b6\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u7ed9\u7406\u89e3\u548c\u63a7\u5236\u8bad\u7ec3\u52a8\u6001\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u6765\u8868\u5f81\u8bad\u7ec3\u52a8\u6001\u3002", "method": "\u5c06\u4e0d\u65ad\u6f14\u53d8\u7684\u795e\u7ecf\u6fc0\u6d3b\u8868\u793a\u4e3a\u529f\u80fd\u8fde\u63a5\u7ec4\uff0c\u5e76\u63d0\u53d6\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6d3b\u52a8\u52a8\u6001\u7279\u5f81\u3002", "result": "\u6240\u63d0\u53d6\u7684\u7279\u5f81\u80fd\u6709\u6548\u6355\u6349\u7f51\u7edc\u529f\u80fd\u7ec4\u7ec7\u7684\u5173\u952e\u8f6c\u53d8\uff0c\u57fa\u4e8e\u6b64\u63d0\u51fa\u7684\u529f\u80fd\u8fde\u63a5\u7ec4\u65f6\u95f4\u5e8f\u5217\u53ef\u4f5c\u4e3a\u5b66\u4e60\u8fdb\u5ea6\u7684\u5185\u5728\u6307\u6807\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2508.06736", "pdf": "https://arxiv.org/pdf/2508.06736", "abs": "https://arxiv.org/abs/2508.06736", "authors": ["Alican Yilmaz", "Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "title": "ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Solving Mixed-Integer Programming (MIP) problems often requires substantial\ncomputational resources due to their combinatorial nature. Parallelization has\nemerged as a critical strategy to accelerate solution times and enhance\nscalability to tackle large, complex instances. This paper investigates the\nparallelization capabilities of Balans, a recently proposed multi-armed\nbandits-based adaptive large neighborhood search for MIPs. While Balans's\nmodular architecture inherently supports parallel exploration of diverse\nparameter configurations, this potential has not been thoroughly examined. To\naddress this gap, we introduce ParBalans, an extension that leverages both\nsolver-level and algorithmic-level parallelism to improve performance on\nchallenging MIP instances. Our experimental results demonstrate that ParBalans\nexhibits competitive performance compared to the state-of-the-art commercial\nsolver Gurobi, particularly on hard optimization benchmarks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76Balans\u5e76\u884c\u5316\u80fd\u529b\uff0c\u63d0\u51fa\u6269\u5c55ParBalans\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u6311\u6218\u6027MIP\u5b9e\u4f8b\u4e0a\u8868\u73b0\u6709\u7ade\u4e89\u529b\u3002", "motivation": "MIP\u95ee\u9898\u6c42\u89e3\u9700\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0cBalans\u5e76\u884c\u6f5c\u529b\u672a\u5145\u5206\u7814\u7a76\uff0c\u8981\u63d0\u5347\u6311\u6218\u6027MIP\u5b9e\u4f8b\u6c42\u89e3\u6027\u80fd\u3002", "method": "\u5f15\u5165ParBalans\uff0c\u5229\u7528\u6c42\u89e3\u5668\u7ea7\u548c\u7b97\u6cd5\u7ea7\u5e76\u884c\u3002", "result": "ParBalans\u4e0e\u5546\u4e1a\u6c42\u89e3\u5668Gurobi\u76f8\u6bd4\u6709\u7ade\u4e89\u529b\uff0c\u5728\u786c\u4f18\u5316\u57fa\u51c6\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "ParBalans\u80fd\u6709\u6548\u5229\u7528\u5e76\u884c\u6027\uff0c\u63d0\u5347\u6311\u6218\u6027MIP\u5b9e\u4f8b\u6c42\u89e3\u6027\u80fd\u3002"}}
{"id": "2508.08036", "pdf": "https://arxiv.org/pdf/2508.08036", "abs": "https://arxiv.org/abs/2508.08036", "authors": ["Xiaojia Han", "Wenjing Liu", "Qizhi Fang"], "title": "Truthful Two-Obnoxious-Facility Location Games with Optional Preferences and Minimum Distance Constraint", "categories": ["cs.GT"], "comment": null, "summary": "In this paper, we study a truthful two-obnoxious-facility location problem,\nin which each agent has a private location in [0, 1] and a public optional\npreference over two obnoxious facilities, and there is a minimum distance\nconstraint d between the two facilities. Each agent wants to be as far away as\npossible from the facilities that affect her, and the utility of each agent is\nthe total distance from her to these facilities. The goal is to decide how to\nplace the facilities in [0, 1] so as to incentivize agents to report their\nprivate locations truthfully as well as maximize the social utility. First, we\nconsider the special setting where d = 0, that is, the two facilities can be\nlocated at any point in [0, 1]. We propose a deterministic strategyproof\nmechanism with approximation ratio of at most 4 and a randomized strategyproof\nmechanism with approximation ratio of at most 2, respectively. Then we study\nthe general setting. We propose a deterministic strategyproof mechanism with\napproximation ratio of at most 8 and a randomized strategyproof mechanism with\napproximation ratio of at most 4, respectively. Furthermore, we provide lower\nbounds of 2 and 14/13 on the approximation ratio for any deterministic and any\nrandomized strategyproof mechanism, respectively.", "AI": {"tldr": "\u7814\u7a76\u5e26\u6700\u5c0f\u8ddd\u79bb\u7ea6\u675f\u7684\u53cc\u538c\u6076\u8bbe\u65bd\u9009\u5740\u95ee\u9898\uff0c\u7ed9\u51fa\u4e0d\u540c\u60c5\u51b5\u4e0b\u7684\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\u8bc1\u660e\u673a\u5236\u53ca\u8fd1\u4f3c\u6bd4\uff0c\u8fd8\u7ed9\u51fa\u8fd1\u4f3c\u6bd4\u4e0b\u754c\u3002", "motivation": "\u89e3\u51b3\u53cc\u538c\u6076\u8bbe\u65bd\u9009\u5740\u4e2d\u6fc0\u52b1\u4ee3\u7406\u5982\u5b9e\u62a5\u544a\u4f4d\u7f6e\u5e76\u6700\u5927\u5316\u793e\u4f1a\u6548\u7528\u7684\u95ee\u9898\u3002", "method": "\u5148\u8003\u8651\u7279\u6b8a\u60c5\u51b5d = 0\uff0c\u63d0\u51fa\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\u8bc1\u660e\u673a\u5236\uff1b\u518d\u7814\u7a76\u4e00\u822c\u60c5\u51b5\uff0c\u540c\u6837\u63d0\u51fa\u76f8\u5e94\u673a\u5236\uff0c\u5e76\u7ed9\u51fa\u8fd1\u4f3c\u6bd4\u4e0b\u754c\u3002", "result": "\u7279\u6b8a\u60c5\u51b5\uff1a\u786e\u5b9a\u6027\u673a\u5236\u8fd1\u4f3c\u6bd4\u81f3\u591a4\uff0c\u968f\u673a\u673a\u5236\u8fd1\u4f3c\u6bd4\u81f3\u591a2\uff1b\u4e00\u822c\u60c5\u51b5\uff1a\u786e\u5b9a\u6027\u673a\u5236\u8fd1\u4f3c\u6bd4\u81f3\u591a8\uff0c\u968f\u673a\u673a\u5236\u8fd1\u4f3c\u6bd4\u81f3\u591a4\uff1b\u8fd1\u4f3c\u6bd4\u4e0b\u754c\uff1a\u786e\u5b9a\u6027\u4e3a2\uff0c\u968f\u673a\u4e3a14/13\u3002", "conclusion": "\u4e3a\u53cc\u538c\u6076\u8bbe\u65bd\u9009\u5740\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u673a\u5236\u548c\u8fd1\u4f3c\u6bd4\u5206\u6790\u3002"}}
{"id": "2508.07399", "pdf": "https://arxiv.org/pdf/2508.07399", "abs": "https://arxiv.org/abs/2508.07399", "authors": ["Yu Ye", "Junchen Fu", "Yu Song", "Kaiwen Zheng", "Joemon M. Jose"], "title": "Are Multimodal Embeddings Truly Beneficial for Recommendation? A Deep Dive into Whole vs. Individual Modalities", "categories": ["cs.IR"], "comment": null, "summary": "Multimodal recommendation (MMRec) has emerged as a mainstream paradigm,\ntypically leveraging text and visual embeddings extracted from pre-trained\nmodels such as Sentence-BERT, Vision Transformers, and ResNet. This approach is\nfounded on the intuitive assumption that incorporating multimodal embeddings\ncan enhance recommendation performance. However, despite its popularity, this\nassumption lacks comprehensive empirical verification. This presents a critical\nresearch gap. To address it, we pose the central research question of this\npaper: Are multimodal embeddings truly beneficial for recommendation? To answer\nthis question, we conduct a large-scale empirical study examining the role of\ntext and visual embeddings in modern MMRec models, both as a whole and\nindividually. Specifically, we pose two key research questions: (1) Do\nmultimodal embeddings as a whole improve recommendation performance? (2) Is\neach individual modality - text and image - useful when used alone? To isolate\nthe effect of individual modalities - text or visual - we employ a modality\nknockout strategy by setting the corresponding embeddings to either constant\nvalues or random noise. To ensure the scale and comprehensiveness of our study,\nwe evaluate 14 widely used state-of-the-art MMRec models. Our findings reveal\nthat: (1) multimodal embeddings generally enhance recommendation performance -\nparticularly when integrated through more sophisticated graph-based fusion\nmodels. Surprisingly, commonly adopted baseline models with simple fusion\nschemes, such as VBPR and BM3, show only limited gains. (2) The text modality\nalone achieves performance comparable to the full multimodal setting in most\ncases, whereas the image modality alone does not. These results offer\nfoundational insights and practical guidance for the MMRec community. We will\nrelease our code and datasets to facilitate future research.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u591a\u6a21\u6001\u5d4c\u5165\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u5d4c\u5165\u603b\u4f53\u63d0\u5347\u63a8\u8350\u6027\u80fd\uff0c\u6587\u672c\u6a21\u6001\u5355\u72ec\u4f7f\u7528\u6548\u679c\u8f83\u597d\uff0c\u56fe\u50cf\u6a21\u6001\u5355\u72ec\u4f7f\u7528\u4e0d\u4f73\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u63a8\u8350\u4e2d\uff0c\u591a\u6a21\u6001\u5d4c\u5165\u80fd\u63d0\u5347\u63a8\u8350\u6027\u80fd\u7684\u5047\u8bbe\u7f3a\u4e4f\u5168\u9762\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u5b58\u5728\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6a21\u6001\u5254\u9664\u7b56\u7565\uff0c\u5c06\u5bf9\u5e94\u5d4c\u5165\u8bbe\u4e3a\u5e38\u6570\u503c\u6216\u968f\u673a\u566a\u58f0\uff0c\u8bc4\u4f3014\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5148\u8fdb\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u3002", "result": "\u591a\u6a21\u6001\u5d4c\u5165\u603b\u4f53\u63d0\u5347\u63a8\u8350\u6027\u80fd\uff0c\u590d\u6742\u56fe\u878d\u5408\u6a21\u578b\u6548\u679c\u66f4\u597d\uff1b\u6587\u672c\u6a21\u6001\u5355\u72ec\u4f7f\u7528\u6027\u80fd\u4e0e\u5168\u591a\u6a21\u6001\u76f8\u5f53\uff0c\u56fe\u50cf\u6a21\u6001\u5355\u72ec\u4f7f\u7528\u4e0d\u4f73\u3002", "conclusion": "\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u63a8\u8350\u793e\u533a\u63d0\u4f9b\u57fa\u7840\u89c1\u89e3\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u5c06\u53d1\u5e03\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2508.08078", "pdf": "https://arxiv.org/pdf/2508.08078", "abs": "https://arxiv.org/abs/2508.08078", "authors": ["Jun-Ting Hsieh", "Daniel Z. Lee", "Sidhanth Mohanty", "Aaron Putterman", "Rachel Yun Zhang"], "title": "Sparsifying Cayley Graphs on Every Group", "categories": ["cs.DS", "math.CO"], "comment": null, "summary": "A classic result in graph theory, due to Batson, Spielman, and Srivastava\n(STOC 2009) shows that every graph admits a $(1 \\pm \\varepsilon)$ cut (or\nspectral) sparsifier which preserves only $O(n / \\varepsilon^2)$ reweighted\nedges. However, when applying this result to \\emph{Cayley graphs}, the\nresulting sparsifier is no longer necessarily a Cayley graph -- it can be an\narbitrary subset of edges.\n  Thus, a recent line of inquiry, and one which has only seen minor progress,\nasks: for any group $G$, do all Cayley graphs over the group $G$ admit\nsparsifiers which preserve only $\\mathrm{polylog}(|G|)/\\varepsilon^2$ many\nre-weighted generators?\n  As our primary contribution, we answer this question in the affirmative,\npresenting a proof of the existence of such Cayley graph spectral sparsifiers,\nalong with an efficient algorithm for finding them. Our algorithm even extends\nto \\emph{directed} Cayley graphs, if we instead ask only for cut sparsification\ninstead of spectral sparsification.\n  We additionally study the sparsification of linear equations over non-abelian\ngroups. In contrast to the abelian case, we show that for non-abelian valued\nequations, super-polynomially many linear equations must be preserved in order\nto approximately preserve the number of satisfied equations for any input.\nTogether with our Cayley graph sparsification result, this provides a formal\nseparation between Cayley graph sparsification and sparsifying linear\nequations.", "AI": {"tldr": "\u6587\u7ae0\u8bc1\u660e\u4e86Cayley\u56fe\u5b58\u5728\u8c31\u7a00\u758f\u5668\u53ca\u9ad8\u6548\u67e5\u627e\u7b97\u6cd5\uff0c\u8fd8\u7814\u7a76\u975e\u963f\u8d1d\u5c14\u7fa4\u7ebf\u6027\u65b9\u7a0b\u7a00\u758f\u5316\u5e76\u7ed9\u51fa\u4e0eCayley\u56fe\u7a00\u758f\u5316\u7684\u5f62\u5f0f\u5206\u79bb\u3002", "motivation": "\u524d\u4eba\u7ed3\u679c\u5e94\u7528\u4e8eCayley\u56fe\u65f6\u7a00\u758f\u5668\u4e0d\u4e00\u5b9a\u662fCayley\u56fe\uff0c\u63a2\u7a76Cayley\u56fe\u662f\u5426\u5b58\u5728\u4ec5\u4fdd\u7559\u7279\u5b9a\u6570\u91cf\u91cd\u52a0\u6743\u751f\u6210\u5143\u7684\u7a00\u758f\u5668\u3002", "method": "\u63d0\u51fa\u8bc1\u660e\u5b58\u5728Cayley\u56fe\u8c31\u7a00\u758f\u5668\u7684\u65b9\u6cd5\u53ca\u9ad8\u6548\u67e5\u627e\u7b97\u6cd5\uff0c\u7814\u7a76\u975e\u963f\u8d1d\u5c14\u7fa4\u7ebf\u6027\u65b9\u7a0b\u7a00\u758f\u5316\u3002", "result": "\u80af\u5b9a\u56de\u7b54Cayley\u56fe\u7a00\u758f\u5668\u95ee\u9898\uff0c\u7b97\u6cd5\u53ef\u6269\u5c55\u5230\u6709\u5411Cayley\u56fe\u7684\u5272\u7a00\u758f\u5316\uff1b\u975e\u963f\u8d1d\u5c14\u503c\u65b9\u7a0b\u9700\u4fdd\u7559\u8d85\u591a\u9879\u5f0f\u6570\u91cf\u65b9\u7a0b\u3002", "conclusion": "Cayley\u56fe\u7a00\u758f\u5316\u548c\u7ebf\u6027\u65b9\u7a0b\u7a00\u758f\u5316\u5b58\u5728\u5f62\u5f0f\u4e0a\u7684\u5206\u79bb\u3002"}}
{"id": "2508.07198", "pdf": "https://arxiv.org/pdf/2508.07198", "abs": "https://arxiv.org/abs/2508.07198", "authors": ["Burak Yeti\u015ftiren", "Hong Jin Kang", "Miryung Kim"], "title": "TraceLens: Question-Driven Debugging for Taint Flow Understanding", "categories": ["cs.SE"], "comment": null, "summary": "Taint analysis is a security analysis technique used to track the flow of\npotentially dangerous data through an application and its dependent libraries.\nInvestigating why certain unexpected flows appear and why expected flows are\nmissing is an important sensemaking process during end-user taint analysis.\nExisting taint analysis tools often do not provide this end-user debugging\ncapability, where developers can ask why, why-not, and what-if questions about\ndataflows and reason about the impact of configuring sources and sinks, and\nmodels of 3rd-party libraries that abstract permissible and impermissible data\nflows. Furthermore, a tree-view or a list-view used in existing\ntaint-analyzer's visualization makes it difficult to reason about the global\nimpact on connectivity between multiple sources and sinks.\n  Inspired by the insight that sensemaking tool-generated results can be\nsignificantly improved by a QA inquiry process, we propose TraceLens, a first\nend-user question-answer style debugging interface for taint analysis. It\nenables a user to ask why, why-not, and what-if questions to investigate the\nexistence of suspicious flows, the non-existence of expected flows, and the\nglobal impact of third-party library models. TraceLens performs speculative\nwhat-if analysis, to help a user in debugging how different connectivity\nassumptions affect overall results. A user study with 12 participants shows\nthat participants using TraceLens achieved 21% higher accuracy on average,\ncompared to CodeQL. They also reported a 45% reduction in mental demand\n(NASA-TLX) and rated higher confidence in identifying relevant flows using\nTraceLens.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u6c61\u70b9\u5206\u6790\u7684TraceLens\u95ee\u7b54\u5f0f\u8c03\u8bd5\u754c\u9762\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u5176\u6bd4CodeQL\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u6c61\u70b9\u5206\u6790\u5de5\u5177\u7f3a\u4e4f\u7aef\u7528\u6237\u8c03\u8bd5\u80fd\u529b\uff0c\u53ef\u89c6\u5316\u65b9\u5f0f\u96be\u5206\u6790\u5168\u5c40\u5f71\u54cd\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faTraceLens\uff0c\u652f\u6301\u7528\u6237\u95eewhy\u3001why - not\u3001what - if\u95ee\u9898\uff0c\u8fdb\u884c\u63a8\u6d4b\u6027what - if\u5206\u6790\u3002", "result": "12\u4eba\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528TraceLens\u5e73\u5747\u51c6\u786e\u7387\u6bd4CodeQL\u9ad821%\uff0c\u5fc3\u7406\u9700\u6c42\u964d\u4f4e45%\uff0c\u8bc6\u522b\u76f8\u5173\u6d41\u4fe1\u5fc3\u66f4\u9ad8\u3002", "conclusion": "TraceLens\u80fd\u6709\u6548\u63d0\u5347\u6c61\u70b9\u5206\u6790\u7684\u8c03\u8bd5\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.06614", "pdf": "https://arxiv.org/pdf/2508.06614", "abs": "https://arxiv.org/abs/2508.06614", "authors": ["Fangjun Hu", "Guangkuo Liu", "Yifan Zhang", "Xun Gao"], "title": "Local Diffusion Models and Phases of Data Distributions", "categories": ["cs.LG", "cond-mat.stat-mech", "quant-ph"], "comment": "8+22 pages, 4+3 figures", "summary": "As a class of generative artificial intelligence frameworks inspired by\nstatistical physics, diffusion models have shown extraordinary performance in\nsynthesizing complicated data distributions through a denoising process\ngradually guided by score functions. Real-life data, like images, is often\nspatially structured in low-dimensional spaces. However, ordinary diffusion\nmodels ignore this local structure and learn spatially global score functions,\nwhich are often computationally expensive. In this work, we introduce a new\nperspective on the phases of data distributions, which provides insight into\nconstructing local denoisers with reduced computational costs. We define two\ndistributions as belonging to the same data distribution phase if they can be\nmutually connected via spatially local operations such as local denoisers.\nThen, we show that the reverse denoising process consists of an early trivial\nphase and a late data phase, sandwiching a rapid phase transition where local\ndenoisers must fail. To diagnose such phase transitions, we prove an\ninformation-theoretic bound on the fidelity of local denoisers based on\nconditional mutual information, and conduct numerical experiments in a\nreal-world dataset. This work suggests simpler and more efficient architectures\nof diffusion models: far from the phase transition point, we can use small\nlocal neural networks to compute the score function; global neural networks are\nonly necessary around the narrow time interval of phase transitions. This\nresult also opens up new directions for studying phases of data distributions,\nthe broader science of generative artificial intelligence, and guiding the\ndesign of neural networks inspired by physics concepts.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u6570\u636e\u5206\u5e03\u9636\u6bb5\u65b0\u89c6\u89d2\uff0c\u5206\u6790\u6269\u6563\u6a21\u578b\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\u9636\u6bb5\uff0c\u8bc1\u660e\u4fe1\u606f\u8bba\u754c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u63d0\u51fa\u66f4\u9ad8\u6548\u6269\u6563\u6a21\u578b\u67b6\u6784\u3002", "motivation": "\u666e\u901a\u6269\u6563\u6a21\u578b\u5ffd\u7565\u6570\u636e\u5c40\u90e8\u7ed3\u6784\uff0c\u5b66\u4e60\u5168\u5c40\u5f97\u5206\u51fd\u6570\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u6784\u5efa\u4f4e\u6210\u672c\u5c40\u90e8\u53bb\u566a\u5668\u3002", "method": "\u5b9a\u4e49\u6570\u636e\u5206\u5e03\u76f8\u540c\u9636\u6bb5\uff0c\u5206\u6790\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\u9636\u6bb5\uff0c\u8bc1\u660e\u57fa\u4e8e\u6761\u4ef6\u4e92\u4fe1\u606f\u7684\u5c40\u90e8\u53bb\u566a\u5668\u4fdd\u771f\u5ea6\u4fe1\u606f\u8bba\u754c\uff0c\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u3002", "result": "\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\u5305\u542b\u65e9\u671f\u5e73\u51e1\u9636\u6bb5\u3001\u665a\u671f\u6570\u636e\u9636\u6bb5\u548c\u5feb\u901f\u76f8\u53d8\u9636\u6bb5\uff0c\u8fdc\u79bb\u76f8\u53d8\u70b9\u53ef\u7528\u5c0f\u5c40\u90e8\u795e\u7ecf\u7f51\u7edc\uff0c\u76f8\u53d8\u70b9\u9644\u8fd1\u9700\u5168\u5c40\u795e\u7ecf\u7f51\u7edc\u3002", "conclusion": "\u63d0\u51fa\u66f4\u7b80\u5355\u9ad8\u6548\u7684\u6269\u6563\u6a21\u578b\u67b6\u6784\uff0c\u4e3a\u6570\u636e\u5206\u5e03\u9636\u6bb5\u7814\u7a76\u3001\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u548c\u53d7\u7269\u7406\u6982\u5ff5\u542f\u53d1\u7684\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u5f00\u8f9f\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.06548", "pdf": "https://arxiv.org/pdf/2508.06548", "abs": "https://arxiv.org/abs/2508.06548", "authors": ["Zhanye Luo", "Yuefeng Han", "Xiufan Yu"], "title": "Factor Augmented Supervised Learning with Text Embeddings", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Large language models (LLMs) generate text embeddings from text data,\nproducing vector representations that capture the semantic meaning and\ncontextual relationships of words. However, the high dimensionality of these\nembeddings often impedes efficiency and drives up computational cost in\ndownstream tasks. To address this, we propose AutoEncoder-Augmented Learning\nwith Text (AEALT), a supervised, factor-augmented framework that incorporates\ndimension reduction directly into pre-trained LLM workflows. First, we extract\nembeddings from text documents; next, we pass them through a supervised\naugmented autoencoder to learn low-dimensional, task-relevant latent factors.\nBy modeling the nonlinear structure of complex embeddings, AEALT outperforms\nconventional deep-learning approaches that rely on raw embeddings. We validate\nits broad applicability with extensive experiments on classification, anomaly\ndetection, and prediction tasks using multiple real-world public datasets.\nNumerical results demonstrate that AEALT yields substantial gains over both\nvanilla embeddings and several standard dimension reduction methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAEALT\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u5d4c\u5165\u9ad8\u7ef4\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u5d4c\u5165\u7684\u9ad8\u7ef4\u6027\u963b\u788d\u4e0b\u6e38\u4efb\u52a1\u6548\u7387\u5e76\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51faAEALT\u6846\u67b6\uff0c\u5148\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u5d4c\u5165\uff0c\u518d\u901a\u8fc7\u76d1\u7763\u589e\u5f3a\u81ea\u52a8\u7f16\u7801\u5668\u5b66\u4e60\u4f4e\u7ef4\u3001\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u6f5c\u5728\u56e0\u5b50\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u516c\u5171\u6570\u636e\u96c6\u7684\u5206\u7c7b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u9884\u6d4b\u4efb\u52a1\u4e0a\u5b9e\u9a8c\uff0cAEALT\u6bd4\u539f\u59cb\u5d4c\u5165\u548c\u51e0\u79cd\u6807\u51c6\u964d\u7ef4\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "AEALT\u901a\u8fc7\u5bf9\u590d\u6742\u5d4c\u5165\u7684\u975e\u7ebf\u6027\u7ed3\u6784\u5efa\u6a21\uff0c\u4f18\u4e8e\u4f9d\u8d56\u539f\u59cb\u5d4c\u5165\u7684\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2508.08054", "pdf": "https://arxiv.org/pdf/2508.08054", "abs": "https://arxiv.org/abs/2508.08054", "authors": ["Andrew Kang", "Sainyam Galhotra"], "title": "TQL: Towards Type-Driven Data Discovery", "categories": ["cs.DB", "cs.PL"], "comment": "2024 IEEE BigData paper", "summary": "Existing query languages for data discovery exhibit system-driven designs\nthat emphasize database features and functionality over user needs. We propose\na re-prioritization of the client through an introduction of a language-driven\napproach to data discovery systems that can leverage powerful results from\nprogramming languages research. In this paper, we describe TQL, a flexible and\npractical query language which incorporates a type-like system to encompass\ndownstream transformation-context in its discovery queries. The syntax and\nsemantics of TQL (including the underlying evaluation model), are formally\ndefined, and a sketch of its implementation is also provided. Additionally, we\nprovide comparisons to existing languages for data retrieval and data discovery\nto examine the advantages of TQL's expanded expressive power in real-life\nsettings.", "AI": {"tldr": "\u63d0\u51fa\u4ee5\u8bed\u8a00\u9a71\u52a8\u65b9\u6cd5\u91cd\u65b0\u8c03\u6574\u6570\u636e\u53d1\u73b0\u7cfb\u7edf\u4f18\u5148\u7ea7\uff0c\u4ecb\u7ecdTQL\u67e5\u8be2\u8bed\u8a00\uff0c\u5b9a\u4e49\u5176\u8bed\u6cd5\u3001\u8bed\u4e49\u5e76\u4e0e\u73b0\u6709\u8bed\u8a00\u6bd4\u8f83\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u53d1\u73b0\u67e5\u8be2\u8bed\u8a00\u4ee5\u7cfb\u7edf\u9a71\u52a8\u8bbe\u8ba1\uff0c\u5f3a\u8c03\u6570\u636e\u5e93\u7279\u6027\u800c\u5ffd\u89c6\u7528\u6237\u9700\u6c42\uff0c\u9700\u91cd\u65b0\u8c03\u6574\u5ba2\u6237\u7aef\u4f18\u5148\u7ea7\u3002", "method": "\u5f15\u5165\u8bed\u8a00\u9a71\u52a8\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u5305\u542b\u7c7b\u578b\u7cfb\u7edf\u7684\u7075\u6d3b\u5b9e\u7528\u67e5\u8be2\u8bed\u8a00TQL\uff0c\u660e\u786e\u5b9a\u4e49\u5176\u8bed\u6cd5\u3001\u8bed\u4e49\u53ca\u8bc4\u4f30\u6a21\u578b\u5e76\u7ed9\u51fa\u5b9e\u73b0\u6982\u8981\u3002", "result": "\u5b9a\u4e49\u4e86TQL\u7684\u8bed\u6cd5\u3001\u8bed\u4e49\u548c\u8bc4\u4f30\u6a21\u578b\uff0c\u7ed9\u51fa\u5b9e\u73b0\u6982\u8981\uff0c\u5e76\u4e0e\u73b0\u6709\u8bed\u8a00\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "TQL\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u5177\u6709\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u80fd\u66f4\u597d\u6ee1\u8db3\u6570\u636e\u53d1\u73b0\u9700\u6c42\u3002"}}
{"id": "2508.08129", "pdf": "https://arxiv.org/pdf/2508.08129", "abs": "https://arxiv.org/abs/2508.08129", "authors": ["Philip Caplan", "Otis Milliken", "Toby Pouler", "Zeyi Tong", "Col McDermott", "Sam Millay"], "title": "A Lagrangian method for solving the spherical shallow water equations using power diagrams", "categories": ["physics.flu-dyn", "cs.CE", "physics.comp-ph"], "comment": null, "summary": "Numerical simulations of the air in the atmosphere and water in the oceans\nare essential for numerical weather prediction. The state-of-the-art for\nperforming these fluid simulations relies on an Eulerian viewpoint, in which\nthe fluid domain is discretized into a mesh, and the governing equations\ndescribe the fluid motion as it passes through each cell of the mesh. However,\nit is unclear whether a Lagrangian viewpoint, in which the fluid is discretized\nby a collection of particles, can outperform Eulerian simulations in global\natmospheric simulations. To date, Lagrangian approaches have shown promise, but\ntend to produce smoother solutions. In this work, a new Lagrangian method is\ndeveloped to simulate the atmosphere in which particles are represented with\nspherical power cells. We introduce an efficient algorithm for computing these\ncells which are then used to discretize the spherical shallow water equations.\nMass conservation is enforced by solving a semi-discrete optimal transport\nproblem and a semi-implicit time stepping procedure is used to advance the\nsolution in time. We note that, in contrast to previous work, artificial\nviscosity is not needed to stabilize the simulation. The performance of the\nspherical Voronoi diagram calculation is first assessed, which shows that\nspherical Voronoi diagrams of 100 million sites can be computed in under 2\nminutes on a single machine. The new simulation method is then evaluated on\nstandard benchmark test cases, which shows that momentum and energy\nconservation of this new method is comparable to the latest Lagrangian approach\nfor simulating the spherical shallow water equations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u6a21\u62df\u5927\u6c14\uff0c\u7528\u7403\u5f62\u5e42\u80de\u8868\u793a\u7c92\u5b50\uff0c\u8bc4\u4f30\u4e86\u8ba1\u7b97\u6027\u80fd\u548c\u6a21\u62df\u65b9\u6cd5\u6548\u679c\u3002", "motivation": "\u4e0d\u786e\u5b9a\u62c9\u683c\u6717\u65e5\u89c2\u70b9\u5728\u5168\u7403\u5927\u6c14\u6a21\u62df\u4e2d\u662f\u5426\u80fd\u4f18\u4e8e\u6b27\u62c9\u6a21\u62df\uff0c\u73b0\u6709\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u6709\u524d\u666f\u4f46\u89e3\u8f83\u5e73\u6ed1\u3002", "method": "\u5f00\u53d1\u65b0\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\uff0c\u7528\u7403\u5f62\u5e42\u80de\u8868\u793a\u7c92\u5b50\uff0c\u8ba1\u7b97\u5e42\u80de\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u6c42\u89e3\u534a\u79bb\u6563\u6700\u4f18\u4f20\u8f93\u95ee\u9898\u4fdd\u8bc1\u8d28\u91cf\u5b88\u6052\uff0c\u7528\u534a\u9690\u5f0f\u65f6\u95f4\u6b65\u63a8\u8fdb\u6c42\u89e3\u3002", "result": "10000 \u4e07\u4e2a\u7ad9\u70b9\u7684\u7403\u5f62 Voronoi \u56fe\u53ef\u5728\u5355\u53f0\u673a\u5668 2 \u5206\u949f\u5185\u8ba1\u7b97\u5b8c\u6210\uff0c\u65b0\u65b9\u6cd5\u52a8\u91cf\u548c\u80fd\u91cf\u5b88\u6052\u4e0e\u6700\u65b0\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u65b0\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u5728\u5927\u6c14\u6a21\u62df\u4e2d\u6709\u4e00\u5b9a\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u7c98\u6027\u6765\u7a33\u5b9a\u6a21\u62df\u3002"}}
{"id": "2508.08184", "pdf": "https://arxiv.org/pdf/2508.08184", "abs": "https://arxiv.org/abs/2508.08184", "authors": ["Isabella Di Filippo", "Bruno Escobar", "Juan Facal"], "title": "Remote Work and Women's Labor Supply: The New Gender Division at Home", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "We study how increases in remote work opportunities for men affect their\nspouses' labor supply. Exploiting variation in the change in work-from-home\n(WFH) exposure across occupations before and after the COVID-19 pandemic, we\nfind that women whose husbands experienced larger WFH increases are over 2\npercentage points more likely to be employed, equivalent to a 4% rise relative\nto pre-pandemic levels. Evidence from time-use diaries and childcare\nquestionnaires suggests these effects are driven by intra-household\nreallocation of child-caring time: women are less likely to engage in primary\nchildcare activities, while men working at home partially compensate by\ncovering more for their spouse. These results highlight the role of\nintra-household spillovers and bargaining in shaping the labor market\nconsequences of remote work.", "AI": {"tldr": "\u7814\u7a76\u7537\u6027\u8fdc\u7a0b\u5de5\u4f5c\u673a\u4f1a\u589e\u52a0\u5bf9\u914d\u5076\u5c31\u4e1a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6709\u79ef\u6781\u4f5c\u7528\u4e14\u6e90\u4e8e\u5bb6\u5ead\u5185\u80b2\u513f\u65f6\u95f4\u91cd\u65b0\u5206\u914d\u3002", "motivation": "\u63a2\u7a76\u7537\u6027\u8fdc\u7a0b\u5de5\u4f5c\u673a\u4f1a\u589e\u52a0\u5bf9\u5176\u914d\u5076\u52b3\u52a8\u529b\u4f9b\u7ed9\u7684\u5f71\u54cd\u3002", "method": "\u5229\u7528\u65b0\u51a0\u75ab\u60c5\u524d\u540e\u4e0d\u540c\u804c\u4e1a\u5728\u5bb6\u5de5\u4f5c\u66b4\u9732\u53d8\u5316\u7684\u5dee\u5f02\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u4e08\u592b\u5728\u5bb6\u5de5\u4f5c\u673a\u4f1a\u589e\u52a0\u8f83\u591a\u7684\u5973\u6027\u5c31\u4e1a\u53ef\u80fd\u6027\u63d0\u9ad8\u8d852\u4e2a\u767e\u5206\u70b9\uff0c\u76f8\u5f53\u4e8e\u75ab\u60c5\u524d\u6c34\u5e73\u76844%\uff0c\u539f\u56e0\u662f\u5bb6\u5ead\u5185\u80b2\u513f\u65f6\u95f4\u91cd\u65b0\u5206\u914d\u3002", "conclusion": "\u5f3a\u8c03\u5bb6\u5ead\u5185\u90e8\u6ea2\u51fa\u6548\u5e94\u548c\u8bae\u4ef7\u5728\u5851\u9020\u8fdc\u7a0b\u5de5\u4f5c\u52b3\u52a8\u529b\u5e02\u573a\u540e\u679c\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2508.07756", "pdf": "https://arxiv.org/pdf/2508.07756", "abs": "https://arxiv.org/abs/2508.07756", "authors": ["Hanze Zhang", "Rong Chen", "Haibo Chen"], "title": "Towards Lock Modularization for Heterogeneous Environments", "categories": ["cs.DC"], "comment": null, "summary": "Modern hardware environments are becoming increasingly heterogeneous, leading\nto the emergence of applications specifically designed to exploit this\nheterogeneity. Efficiently adopting locks in these applications poses distinct\nchallenges. The uneven distribution of resources in such environments can\ncreate bottlenecks for lock operations, severely hindering application\nperformance. Existing solutions are often tailored to specific types of\nhardware, which underutilizes resources on other components within\nheterogeneous environments.\n  This paper introduces a new design principle: decomposing locks across\nhardware components to fully utilize unevenly distributed resources in\nheterogeneous environments. Following this principle, we propose lock\nmodularization, a systematic approach that decomposes a lock into independent\nmodules and assigns them to appropriate hardware components. This approach\naligns the resource requirements of lock modules with the attributes of\nspecific hardware components, maximizing strengths while minimizing weaknesses.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5f02\u6784\u786c\u4ef6\u73af\u5883\u4e2d\u9501\u4f7f\u7528\u7684\u6311\u6218\uff0c\u63d0\u51fa\u9501\u6a21\u5757\u5316\u65b9\u6cd5\u4ee5\u5145\u5206\u5229\u7528\u8d44\u6e90\u3002", "motivation": "\u73b0\u4ee3\u5f02\u6784\u786c\u4ef6\u73af\u5883\u4e0b\uff0c\u9ad8\u6548\u91c7\u7528\u9501\u5b58\u5728\u6311\u6218\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8d44\u6e90\u3002", "method": "\u5f15\u5165\u5206\u89e3\u9501\u5230\u786c\u4ef6\u7ec4\u4ef6\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u63d0\u51fa\u9501\u6a21\u5757\u5316\u65b9\u6cd5\uff0c\u5c06\u9501\u5206\u89e3\u4e3a\u72ec\u7acb\u6a21\u5757\u5e76\u5206\u914d\u5230\u5408\u9002\u786c\u4ef6\u7ec4\u4ef6\u3002", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2508.07163", "pdf": "https://arxiv.org/pdf/2508.07163", "abs": "https://arxiv.org/abs/2508.07163", "authors": ["Kamal Acharya", "Iman Sharifi", "Mehul Lad", "Liang Sun", "Houbing Song"], "title": "Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey", "categories": ["cs.RO", "cs.AI", "cs.NE"], "comment": "9 pages, 4 figures, IJCAI-2025 (accepted)", "summary": "Neurosymbolic AI combines neural network adaptability with symbolic\nreasoning, promising an approach to address the complex regulatory,\noperational, and safety challenges in Advanced Air Mobility (AAM). This survey\nreviews its applications across key AAM domains such as demand forecasting,\naircraft design, and real-time air traffic management. Our analysis reveals a\nfragmented research landscape where methodologies, including Neurosymbolic\nReinforcement Learning, have shown potential for dynamic optimization but still\nface hurdles in scalability, robustness, and compliance with aviation\nstandards. We classify current advancements, present relevant case studies, and\noutline future research directions aimed at integrating these approaches into\nreliable, transparent AAM systems. By linking advanced AI techniques with AAM's\noperational demands, this work provides a concise roadmap for researchers and\npractitioners developing next-generation air mobility solutions.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u795e\u7ecf\u7b26\u53f7AI\u5728\u9ad8\u7ea7\u7a7a\u4e2d\u4ea4\u901a\uff08AAM\uff09\u7684\u5e94\u7528\uff0c\u5206\u6790\u7814\u7a76\u73b0\u72b6\u5e76\u6307\u51fa\u6311\u6218\uff0c\u63d0\u4f9b\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u8def\u7ebf\u56fe\u3002", "motivation": "\u7ed3\u5408\u795e\u7ecf\u7b26\u53f7AI\u4e0eAAM\uff0c\u89e3\u51b3AAM\u4e2d\u590d\u6742\u7684\u76d1\u7ba1\u3001\u8fd0\u8425\u548c\u5b89\u5168\u6311\u6218\u3002", "method": "\u5bf9\u795e\u7ecf\u7b26\u53f7AI\u5728AAM\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u8fdb\u884c\u7efc\u8ff0\uff0c\u5206\u6790\u7814\u7a76\u73b0\u72b6\uff0c\u5206\u7c7b\u5f53\u524d\u8fdb\u5c55\uff0c\u5c55\u793a\u6848\u4f8b\u3002", "result": "\u7814\u7a76\u9886\u57df\u5206\u6563\uff0c\u795e\u7ecf\u7b26\u53f7\u5f3a\u5316\u5b66\u4e60\u7b49\u65b9\u6cd5\u6709\u52a8\u6001\u4f18\u5316\u6f5c\u529b\uff0c\u4f46\u5728\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u7b26\u5408\u822a\u7a7a\u6807\u51c6\u65b9\u9762\u6709\u969c\u788d\u3002", "conclusion": "\u4e3a\u5f00\u53d1\u4e0b\u4e00\u4ee3\u7a7a\u4e2d\u4ea4\u901a\u89e3\u51b3\u65b9\u6848\u7684\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2508.06746", "pdf": "https://arxiv.org/pdf/2508.06746", "abs": "https://arxiv.org/abs/2508.06746", "authors": ["Xin Tang", "Qian Chen", "Fengshun Li", "Youchun Gong", "Yinqiu Liu", "Wen Tian", "Shaowen Qin", "Xiaohuan Li"], "title": "Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism", "categories": ["cs.AI"], "comment": null, "summary": "With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in\nsensitive applications, such as urban monitoring, emergency response, and\nsecure sensing, ensuring reliable connectivity and covert communication has\nbecome increasingly vital. However, dynamic mobility and exposure risks pose\nsignificant challenges. To tackle these challenges, this paper proposes a\nself-organizing UAV network framework combining Graph Diffusion-based Policy\nOptimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The\nGDPO method uses generative AI to dynamically generate sparse but\nwell-connected topologies, enabling flexible adaptation to changing node\ndistributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game\n(SG)-based incentive mechanism guides self-interested UAVs to choose relay\nbehaviors and neighbor links that support cooperation and enhance covert\ncommunication. Extensive experiments are conducted to validate the\neffectiveness of the proposed framework in terms of model convergence, topology\ngeneration quality, and enhancement of covert communication performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408GDPO\u4e0eSG\u6fc0\u52b1\u673a\u5236\u7684\u81ea\u7ec4\u7ec7\u65e0\u4eba\u673a\u7f51\u7edc\u6846\u67b6\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u65e0\u4eba\u673a\u7f51\u7edc\u5728\u654f\u611f\u5e94\u7528\u4e2d\u9700\u6c42\u589e\u957f\uff0c\u52a8\u6001\u79fb\u52a8\u6027\u548c\u66b4\u9732\u98ce\u9669\u5e26\u6765\u786e\u4fdd\u53ef\u9760\u8fde\u63a5\u548c\u9690\u853d\u901a\u4fe1\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u56fe\u6269\u6563\u7b56\u7565\u4f18\u5316\uff08GDPO\uff09\u4e0e\u57fa\u4e8e\u65af\u5854\u514b\u5c14\u4f2f\u683c\u535a\u5f08\uff08SG\uff09\u6fc0\u52b1\u673a\u5236\u7684\u81ea\u7ec4\u7ec7\u65e0\u4eba\u673a\u7f51\u7edc\u6846\u67b6\uff0cGDPO\u7528\u751f\u6210\u5f0fAI\u751f\u6210\u62d3\u6251\uff0cSG\u6fc0\u52b1\u673a\u5236\u5f15\u5bfc\u65e0\u4eba\u673a\u534f\u4f5c\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6846\u67b6\u5728\u6a21\u578b\u6536\u655b\u3001\u62d3\u6251\u751f\u6210\u8d28\u91cf\u548c\u9690\u853d\u901a\u4fe1\u6027\u80fd\u63d0\u5347\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u7ed3\u5408GDPO\u4e0eSG\u6fc0\u52b1\u673a\u5236\u7684\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u65e0\u4eba\u673a\u7f51\u7edc\u9762\u4e34\u7684\u6311\u6218\u3002"}}
{"id": "2508.08045", "pdf": "https://arxiv.org/pdf/2508.08045", "abs": "https://arxiv.org/abs/2508.08045", "authors": ["Xinru Xu", "Wenjing Liu", "Qizhi Fang"], "title": "Constrained Distributed Heterogeneous Two-Facility Location Problems with Max-Variant Cost", "categories": ["cs.GT"], "comment": null, "summary": "We study a constrained distributed heterogeneous two-facility location\nproblem, where a set of agents with private locations on the real line are\ndivided into disjoint groups. The constraint means that the facilities can only\nbe built in a given multiset of candidate locations and at most one facility\ncan be built at each candidate location. Given the locations of the two\nfacilities, the cost of an agent is the distance from her location to the\nfarthest facility (referred to as max-variant). Our goal is to design\nstrategyproof distributed mechanisms that can incentivize all agents to\ntruthfully report their locations and approximately optimize some social\nobjective. A distributed mechanism consists of two steps: for each group, the\nmechanism chooses two candidate locations as the representatives of the group\nbased only on the locations reported by agents therein; then, it outputs two\nfacility locations among all the representatives. We focus on a class of\ndeterministic strategyproof distributed mechanisms and analyze upper and lower\nbounds on the distortion under the Average-of-Average cost (average of the\naverage individual cost of agents in each group), the Max-of-Max cost (maximum\nindividual cost among all agents), the Average-of-Max cost (average of the\nmaximum individual cost among all agents in each group) and the Max-of-Average\ncost (maximum of the average individual cost of all agents in each group).\nUnder four social objectives, we obtain constant upper and lower distortion\nbounds.", "AI": {"tldr": "\u7814\u7a76\u7ea6\u675f\u5206\u5e03\u5f0f\u5f02\u6784\u53cc\u8bbe\u65bd\u9009\u5740\u95ee\u9898\uff0c\u8bbe\u8ba1\u7b56\u7565\u8bc1\u660e\u5206\u5e03\u5f0f\u673a\u5236\uff0c\u5206\u6790\u56db\u79cd\u793e\u4f1a\u76ee\u6807\u4e0b\u7684\u5931\u771f\u4e0a\u4e0b\u754c\u5e76\u83b7\u5e38\u6570\u754c\u3002", "motivation": "\u8bbe\u8ba1\u80fd\u6fc0\u52b1\u4ee3\u7406\u5982\u5b9e\u62a5\u544a\u4f4d\u7f6e\u5e76\u8fd1\u4f3c\u4f18\u5316\u793e\u4f1a\u76ee\u6807\u7684\u7b56\u7565\u8bc1\u660e\u5206\u5e03\u5f0f\u673a\u5236\u3002", "method": "\u5148\u4e3a\u6bcf\u7ec4\u9009\u4e24\u4e2a\u5019\u9009\u4f4d\u7f6e\u4f5c\u4ee3\u8868\uff0c\u518d\u4ece\u4ee3\u8868\u4e2d\u9009\u4e24\u4e2a\u8bbe\u65bd\u4f4d\u7f6e\uff0c\u805a\u7126\u786e\u5b9a\u6027\u7b56\u7565\u8bc1\u660e\u5206\u5e03\u5f0f\u673a\u5236\u3002", "result": "\u5728\u56db\u79cd\u793e\u4f1a\u76ee\u6807\u4e0b\u83b7\u5f97\u4e86\u5e38\u6570\u4e0a\u754c\u548c\u4e0b\u754c\u7684\u5931\u771f\u754c\u9650\u3002", "conclusion": "\u8bbe\u8ba1\u7684\u673a\u5236\u5728\u56db\u79cd\u793e\u4f1a\u76ee\u6807\u4e0b\u80fd\u6709\u6548\u63a7\u5236\u5931\u771f\uff0c\u6709\u4e00\u5b9a\u7684\u7406\u8bba\u4ef7\u503c\u3002"}}
{"id": "2508.07574", "pdf": "https://arxiv.org/pdf/2508.07574", "abs": "https://arxiv.org/abs/2508.07574", "authors": ["Kevin Zielnicki", "Ko-Jen Hsiao"], "title": "Orthogonal Low Rank Embedding Stabilization", "categories": ["cs.IR"], "comment": null, "summary": "The instability of embedding spaces across model retraining cycles presents\nsignificant challenges to downstream applications using user or item embeddings\nderived from recommendation systems as input features. This paper introduces a\nnovel orthogonal low-rank transformation methodology designed to stabilize the\nuser/item embedding space, ensuring consistent embedding dimensions across\nretraining sessions. Our approach leverages a combination of efficient low-rank\nsingular value decomposition and orthogonal Procrustes transformation to map\nembeddings into a standardized space. This transformation is computationally\nefficient, lossless, and lightweight, preserving the dot product and inference\nquality while reducing operational burdens. Unlike existing methods that modify\ntraining objectives or embedding structures, our approach maintains the\nintegrity of the primary model application and can be seamlessly integrated\nwith other stabilization techniques.", "AI": {"tldr": "\u63d0\u51fa\u6b63\u4ea4\u4f4e\u79e9\u53d8\u6362\u65b9\u6cd5\u7a33\u5b9a\u7528\u6237/\u7269\u54c1\u5d4c\u5165\u7a7a\u95f4\uff0c\u8ba1\u7b97\u9ad8\u6548\u4e14\u65e0\u635f\u3002", "motivation": "\u6a21\u578b\u518d\u8bad\u7ec3\u5468\u671f\u4e2d\u5d4c\u5165\u7a7a\u95f4\u4e0d\u7a33\u5b9a\u7ed9\u4e0b\u6e38\u5e94\u7528\u5e26\u6765\u6311\u6218\u3002", "method": "\u7ed3\u5408\u4f4e\u79e9\u5947\u5f02\u503c\u5206\u89e3\u548c\u6b63\u4ea4Procrustes\u53d8\u6362\uff0c\u5c06\u5d4c\u5165\u6620\u5c04\u5230\u6807\u51c6\u5316\u7a7a\u95f4\u3002", "result": "\u8be5\u53d8\u6362\u8ba1\u7b97\u9ad8\u6548\u3001\u65e0\u635f\u3001\u8f7b\u91cf\u7ea7\uff0c\u4fdd\u7559\u70b9\u79ef\u548c\u63a8\u7406\u8d28\u91cf\uff0c\u51cf\u8f7b\u64cd\u4f5c\u8d1f\u62c5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4fdd\u6301\u4e3b\u6a21\u578b\u5e94\u7528\u5b8c\u6574\u6027\uff0c\u53ef\u4e0e\u5176\u4ed6\u7a33\u5b9a\u6280\u672f\u65e0\u7f1d\u96c6\u6210\u3002"}}
{"id": "2508.08169", "pdf": "https://arxiv.org/pdf/2508.08169", "abs": "https://arxiv.org/abs/2508.08169", "authors": ["Arpon Basu", "Pravesh K. Kothari", "Yang P. Liu", "Raghu Meka"], "title": "Sparsifying Sums of Positive Semidefinite Matrices", "categories": ["cs.DS"], "comment": "29 pages", "summary": "In this paper, we revisit spectral sparsification for sums of arbitrary\npositive semidefinite (PSD) matrices. Concretely, for any collection of PSD\nmatrices $\\mathcal{A} = \\{A_1, A_2, \\ldots, A_r\\} \\subset \\mathbb{R}^{n \\times\nn}$, given any subset $T \\subseteq [r]$, our goal is to find sparse weights\n$\\mu \\in \\mathbb{R}_{\\geq 0}^r$ such that $(1 - \\epsilon) \\sum_{i \\in T} A_i\n\\preceq \\sum_{i \\in T} \\mu_i A_i \\preceq (1 + \\epsilon) \\sum_{i \\in T} A_i.$\nThis generalizes spectral sparsification of graphs which corresponds to\n$\\mathcal{A}$ being the set of Laplacians of edges. It also captures\nsparsifying Cayley graphs by choosing a subset of generators. The former has\nbeen extensively studied with optimal sparsifiers known. The latter has\nreceived attention recently and was solved for a few special groups (e.g.,\n$\\mathbb{F}_2^n$).\n  Prior work shows any sum of PSD matrices can be sparsified down to $O(n)$\nelements. This bound however turns out to be too coarse and in particular\nyields no non-trivial bound for building Cayley sparsifiers for Cayley graphs.\n  In this work, we develop a new, instance-specific (i.e., specific to a given\ncollection $\\mathcal{A}$) theory of PSD matrix sparsification based on a new\nparameter $N^*(\\mathcal{A})$ which we call connectivity threshold that\ngeneralizes the threshold of the number of edges required to make a graph\nconnected.\n  Our main result gives a sparsifier that uses at most\n$O(\\epsilon^{-2}N^*(\\mathcal{A}) (\\log n)(\\log r))$ matrices and is\nconstructible in randomized polynomial time. We also show that we need\n$N^*(\\mathcal{A})$ elements to sparsify for any $\\epsilon < 0.99$.\n  As the main application of our framework, we prove that any Cayley graph can\nbe sparsified to $O(\\epsilon^{-2}\\log^4 N)$ generators. Previously, a\nnon-trivial bound on Cayley sparsifiers was known only in the case when the\ngroup is $\\mathbb{F}_2^n$.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u63a2\u8ba8\u4efb\u610f\u534a\u6b63\u5b9a\u77e9\u9635\u548c\u7684\u8c31\u7a00\u758f\u5316\uff0c\u63d0\u51fa\u57fa\u4e8e\u8fde\u901a\u9608\u503c\u7684\u65b0\u7406\u8bba\uff0c\u7ed9\u51fa\u7a00\u758f\u5316\u5668\u6784\u9020\u65b9\u6cd5\u548c\u5e94\u7528\u3002", "motivation": "\u5df2\u6709\u8c31\u7a00\u758f\u5316\u65b9\u6cd5\u5bf9\u4efb\u610f\u534a\u6b63\u5b9a\u77e9\u9635\u548c\u7684\u7a00\u758f\u5316\u754c\u592a\u7c97\uff0c\u4e14\u65e0\u6cd5\u4e3aCayley\u56fe\u6784\u5efa\u975e\u5e73\u51e1\u754c\u3002", "method": "\u57fa\u4e8e\u65b0\u53c2\u6570\u8fde\u901a\u9608\u503c$N^*(\\mathcal{A})$\uff0c\u5f00\u53d1\u7279\u5b9a\u5b9e\u4f8b\u7684\u534a\u6b63\u5b9a\u77e9\u9635\u7a00\u758f\u5316\u7406\u8bba\u3002", "result": "\u5f97\u5230\u6700\u591a\u4f7f\u7528$O(\\epsilon^{-2}N^*(\\mathcal{A}) (\\log n)(\\log r))$\u4e2a\u77e9\u9635\u7684\u7a00\u758f\u5316\u5668\uff0c\u53ef\u5728\u968f\u673a\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6784\u9020\uff0c\u4e14\u8bc1\u660e\u7a00\u758f\u5316\u81f3\u5c11\u9700\u8981$N^*(\\mathcal{A})$\u4e2a\u5143\u7d20\uff1b\u8bc1\u660e\u4efb\u610fCayley\u56fe\u53ef\u7a00\u758f\u5230$O(\\epsilon^{-2}\\log^4 N)$\u4e2a\u751f\u6210\u5143\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u7406\u8bba\u548c\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u89e3\u51b3\u5df2\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5728Cayley\u56fe\u7a00\u758f\u5316\u4e0a\u6709\u91cd\u8981\u5e94\u7528\u3002"}}
{"id": "2508.07371", "pdf": "https://arxiv.org/pdf/2508.07371", "abs": "https://arxiv.org/abs/2508.07371", "authors": ["Yi Zhong", "Hongchao Liu", "Di ZHao"], "title": "AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation", "categories": ["cs.SE", "cs.AI"], "comment": "16pages,6figures", "summary": "As the complexity of software systems continues to increase, the demand for\nautomated testing and maintenance tools is growing exponentially. To meet this\nurgent need, we propose a new assertion generation method based on Hardware\nDescription Language (HDL). This method combines a lightweight,\nparameter-adjustable large language model (LLM) with the Unsloth platform to\nautomatically generate test cases, thereby significantly reducing training\ncosts without sacrificing accuracy or generalization performance. Empirical\nevaluation shows that our method can efficiently generate assertions that\nstrictly conform to the hardware logic. This framework provides a robust and\nflexible solution to modern software testing and maintenance challenges.\nhttps://github.com/liusu-orange/AutoAssert-1 and\nhttps://gitee.com/OpenBPU/auto-assert1 are the locations of the source code.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eHDL\u7684\u65ad\u8a00\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408LLM\u548cUnsloth\u5e73\u53f0\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u964d\u4f4e\u6210\u672c\u4e14\u6709\u6548\uff0c\u63d0\u4f9b\u8f6f\u4ef6\u6d4b\u8bd5\u7ef4\u62a4\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u5bf9\u81ea\u52a8\u5316\u6d4b\u8bd5\u548c\u7ef4\u62a4\u5de5\u5177\u9700\u6c42\u6fc0\u589e\uff0c\u9700\u6ee1\u8db3\u6b64\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\uff08HDL\uff09\u7684\u65ad\u8a00\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u3001\u53c2\u6570\u53ef\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548cUnsloth\u5e73\u53f0\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u4e25\u683c\u7b26\u5408\u786c\u4ef6\u903b\u8f91\u7684\u65ad\u8a00\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u73b0\u4ee3\u8f6f\u4ef6\u6d4b\u8bd5\u548c\u7ef4\u62a4\u6311\u6218\u63d0\u4f9b\u4e86\u5f3a\u5927\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06622", "pdf": "https://arxiv.org/pdf/2508.06622", "abs": "https://arxiv.org/abs/2508.06622", "authors": ["Jeremiah Birrell", "Reza Ebrahimi"], "title": "Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels", "categories": ["cs.LG", "stat.ML"], "comment": "25 pages, 2 figures", "summary": "We introduce ANTIDOTE, a new class of objectives for learning under noisy\nlabels which are defined in terms of a relaxation over an\ninformation-divergence neighborhood. Using convex duality, we provide a\nreformulation as an adversarial training method that has similar computational\ncost to training with standard cross-entropy loss. We show that our approach\nadaptively reduces the influence of the samples with noisy labels during\nlearning, exhibiting a behavior that is analogous to forgetting those samples.\nANTIDOTE is effective in practical environments where label noise is inherent\nin the training data or where an adversary can alter the training labels.\nExtensive empirical evaluations on different levels of symmetric, asymmetric,\nhuman annotation, and real-world label noise show that ANTIDOTE outperforms\nleading comparable losses in the field and enjoys a time complexity that is\nvery close to that of the standard cross entropy loss.", "AI": {"tldr": "\u4ecb\u7ecdANTIDOTE\u76ee\u6807\u51fd\u6570\u7528\u4e8e\u566a\u58f0\u6807\u7b7e\u5b66\u4e60\uff0c\u901a\u8fc7\u51f8\u5bf9\u5076\u8f6c\u5316\u4e3a\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u540c\u7c7b\u65b9\u6cd5\u4e14\u65f6\u95f4\u590d\u6742\u5ea6\u63a5\u8fd1\u6807\u51c6\u4ea4\u53c9\u71b5\u635f\u5931\u3002", "motivation": "\u89e3\u51b3\u566a\u58f0\u6807\u7b7e\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u56fa\u6709\u6807\u7b7e\u566a\u58f0\u6216\u5bf9\u624b\u53ef\u66f4\u6539\u8bad\u7ec3\u6807\u7b7e\u7684\u5b9e\u9645\u73af\u5883\u4e2d\u6709\u6548\u5b66\u4e60\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4fe1\u606f\u6563\u5ea6\u90bb\u57df\u677e\u5f1b\u5b9a\u4e49\u7684ANTIDOTE\u76ee\u6807\u51fd\u6570\uff0c\u5229\u7528\u51f8\u5bf9\u5076\u5c06\u5176\u91cd\u65b0\u8868\u8ff0\u4e3a\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "ANTIDOTE\u80fd\u81ea\u9002\u5e94\u51cf\u5c11\u566a\u58f0\u6807\u7b7e\u6837\u672c\u5f71\u54cd\uff0c\u5728\u4e0d\u540c\u7c7b\u578b\u6807\u7b7e\u566a\u58f0\u7684\u5927\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u8868\u73b0\u4f18\u4e8e\u8be5\u9886\u57df\u9886\u5148\u7684\u53ef\u6bd4\u635f\u5931\u51fd\u6570\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u63a5\u8fd1\u6807\u51c6\u4ea4\u53c9\u71b5\u635f\u5931\u3002", "conclusion": "ANTIDOTE\u662f\u4e00\u79cd\u6709\u6548\u7684\u566a\u58f0\u6807\u7b7e\u5b66\u4e60\u76ee\u6807\u51fd\u6570\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u826f\u597d\u8868\u73b0\u3002"}}
{"id": "2508.08074", "pdf": "https://arxiv.org/pdf/2508.08074", "abs": "https://arxiv.org/abs/2508.08074", "authors": ["Andrew Kang", "Yashnil Saha", "Sainyam Galhotra"], "title": "Towards General-Purpose Data Discovery: A Programming Languages Approach", "categories": ["cs.DB", "cs.PL"], "comment": null, "summary": "Efficient and effective data discovery is critical for many modern\napplications in machine learning and data science. One major bottleneck to the\ndevelopment of a general-purpose data discovery tool is the absence of an\nexpressive formal language, and corresponding implementation, for\ncharacterizing and solving generic discovery queries. To this end, we present\nTQL, a domain-specific language for data discovery well-designed to leverage\nand exploit the results of programming languages research in both its syntax\nand semantics. In this paper, we fully and formally characterize the core\nlanguage through an algebraic model, Imperative Relational Algebra with Types\n(ImpRAT), and implement a modular proof-of-concept system prototype.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u6570\u636e\u53d1\u73b0\u7684\u7279\u5b9a\u9886\u57df\u8bed\u8a00TQL\uff0c\u7528\u4ee3\u6570\u6a21\u578b\u523b\u753b\u6838\u5fc3\u8bed\u8a00\u5e76\u5b9e\u73b0\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edf\u539f\u578b", "motivation": "\u901a\u7528\u6570\u636e\u53d1\u73b0\u5de5\u5177\u53d1\u5c55\u7684\u4e3b\u8981\u74f6\u9888\u662f\u7f3a\u4e4f\u8868\u8fbe\u6027\u7684\u5f62\u5f0f\u8bed\u8a00\u53ca\u5bf9\u5e94\u5b9e\u73b0\u6765\u523b\u753b\u548c\u89e3\u51b3\u901a\u7528\u53d1\u73b0\u67e5\u8be2", "method": "\u901a\u8fc7\u4ee3\u6570\u6a21\u578bImperative Relational Algebra with Types (ImpRAT)\u5168\u9762\u6b63\u5f0f\u5730\u523b\u753b\u6838\u5fc3\u8bed\u8a00\uff0c\u5e76\u5b9e\u73b0\u6a21\u5757\u5316\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edf\u539f\u578b", "result": "\u5b9e\u73b0\u4e86TQL\u53ca\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edf\u539f\u578b", "conclusion": "\u63d0\u51fa\u7684TQL\u80fd\u5229\u7528\u7f16\u7a0b\u8bed\u8a00\u7814\u7a76\u6210\u679c\u89e3\u51b3\u6570\u636e\u53d1\u73b0\u4e2d\u8bed\u8a00\u8868\u8fbe\u95ee\u9898"}}
{"id": "2508.06500", "pdf": "https://arxiv.org/pdf/2508.06500", "abs": "https://arxiv.org/abs/2508.06500", "authors": ["Jonathan Brandt", "Astrid Bensmann", "Richard Hanke-Rauschenbach"], "title": "Negative redispatch power for green hydrogen production: Game changer or lame duck? A German perspective", "categories": ["q-fin.GN", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Following years of controversial discussions about the risks of market-based\nredispatch, the German transmission network operators finally installed\nregional redispatch markets by the end of 2024. Since water electrolysers are\neligible market participants, the otherwise downwards redispatched renewable\nenergy can be used for green hydrogen production in compliance with European\nlaw. To show how different price levels in regional redispatch markets affect\ngreen hydrogen production cost and thus the incentive for electrolyser market\nparticipation, we use historic redispatch time series and evaluate various\npower purchase scenarios. Our results show that low price levels can lead to\nnotable production cost reductions, potentially counteracting uncertainties in\nredispatch power availability and thus incentivising system-beneficial\nelectrolyser siting. In contrast, the possibility of high price levels can\nnullify an increase in the competitiveness of German and European green\nhydrogen through production cost reductions and discourage market\nparticipation.", "AI": {"tldr": "\u5fb7\u56fd\u8f93\u7535\u7f51\u7edc\u8fd0\u8425\u55462024\u5e74\u5e95\u5b89\u88c5\u533a\u57df\u518d\u8c03\u5ea6\u5e02\u573a\uff0c\u7814\u7a76\u4e0d\u540c\u4ef7\u683c\u6c34\u5e73\u5bf9\u7eff\u6c22\u751f\u4ea7\u6210\u672c\u53ca\u7535\u89e3\u69fd\u53c2\u4e0e\u5e02\u573a\u7684\u5f71\u54cd\uff0c\u4f4e\u4ef7\u683c\u53ef\u964d\u6210\u672c\uff0c\u9ad8\u4ef7\u683c\u6709\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8\u533a\u57df\u518d\u8c03\u5ea6\u5e02\u573a\u4e0d\u540c\u4ef7\u683c\u6c34\u5e73\u5bf9\u7eff\u6c22\u751f\u4ea7\u6210\u672c\u53ca\u7535\u89e3\u69fd\u53c2\u4e0e\u5e02\u573a\u6fc0\u52b1\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u5386\u53f2\u518d\u8c03\u5ea6\u65f6\u95f4\u5e8f\u5217\u8bc4\u4f30\u5404\u79cd\u7535\u529b\u8d2d\u4e70\u60c5\u666f\u3002", "result": "\u4f4e\u4ef7\u683c\u6c34\u5e73\u53ef\u663e\u8457\u964d\u4f4e\u751f\u4ea7\u6210\u672c\uff0c\u6fc0\u52b1\u7535\u89e3\u69fd\u9009\u5740\uff1b\u9ad8\u4ef7\u683c\u6c34\u5e73\u4f1a\u62b5\u6d88\u6210\u672c\u964d\u4f4e\u5e26\u6765\u7684\u7ade\u4e89\u529b\u63d0\u5347\uff0c\u963b\u788d\u5e02\u573a\u53c2\u4e0e\u3002", "conclusion": "\u533a\u57df\u518d\u8c03\u5ea6\u5e02\u573a\u4ef7\u683c\u6c34\u5e73\u5bf9\u7eff\u6c22\u751f\u4ea7\u548c\u7535\u89e3\u69fd\u5e02\u573a\u53c2\u4e0e\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2508.07934", "pdf": "https://arxiv.org/pdf/2508.07934", "abs": "https://arxiv.org/abs/2508.07934", "authors": ["Lorenzo La Corte", "Syed Aftab Rashid", "Andrei-Marian Dan"], "title": "Performance Evaluation of Brokerless Messaging Libraries", "categories": ["cs.DC", "cs.NI"], "comment": "11 pages, 9 figures", "summary": "Messaging systems are essential for efficiently transferring large volumes of\ndata, ensuring rapid response times and high-throughput communication. The\nstate-of-the-art on messaging systems mainly focuses on the performance\nevaluation of brokered messaging systems, which use an intermediate broker to\nguarantee reliability and quality of service. However, over the past decade,\nbrokerless messaging systems have emerged, eliminating the single point of\nfailure and trading off reliability guarantees for higher performance. Still,\nthe state-of-the-art on evaluating the performance of brokerless systems is\nscarce. In this work, we solely focus on brokerless messaging systems. First,\nwe perform a qualitative analysis of several possible candidates, to find the\nmost promising ones. We then design and implement an extensive open-source\nbenchmarking suite to systematically and fairly evaluate the performance of the\nchosen libraries, namely, ZeroMQ, NanoMsg, and NanoMsg-Next-Generation (NNG).\nWe evaluate these libraries considering different metrics and workload\nconditions, and provide useful insights into their limitations. Our analysis\nenables practitioners to select the most suitable library for their\nrequirements.", "AI": {"tldr": "\u8bba\u6587\u805a\u7126\u65e0\u4ee3\u7406\u6d88\u606f\u7cfb\u7edf\uff0c\u5b9a\u6027\u5206\u6790\u540e\u8bbe\u8ba1\u5f00\u6e90\u57fa\u51c6\u5957\u4ef6\u8bc4\u4f30ZeroMQ\u3001NanoMsg\u548cNNG\u5e93\u6027\u80fd\uff0c\u4e3a\u4ece\u4e1a\u8005\u9009\u62e9\u5408\u9002\u5e93\u63d0\u4f9b\u4f9d\u636e\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u6709\u4ee3\u7406\u6d88\u606f\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\uff0c\u65e0\u4ee3\u7406\u6d88\u606f\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\u7814\u7a76\u7a00\u7f3a\uff0c\u6545\u5f00\u5c55\u5bf9\u65e0\u4ee3\u7406\u6d88\u606f\u7cfb\u7edf\u7684\u7814\u7a76\u3002", "method": "\u5148\u5bf9\u5019\u9009\u7cfb\u7edf\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u627e\u51fa\u6700\u6709\u524d\u666f\u7684\u7cfb\u7edf\uff0c\u518d\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u5f00\u6e90\u57fa\u51c6\u5957\u4ef6\uff0c\u4ece\u4e0d\u540c\u6307\u6807\u548c\u5de5\u4f5c\u8d1f\u8f7d\u6761\u4ef6\u8bc4\u4f30\u6240\u9009\u5e93\u3002", "result": "\u5bf9ZeroMQ\u3001NanoMsg\u548cNNG\u5e93\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u53d1\u73b0\u5176\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u6709\u52a9\u4e8e\u4ece\u4e1a\u8005\u6839\u636e\u81ea\u8eab\u9700\u6c42\u9009\u62e9\u6700\u5408\u9002\u7684\u5e93\u3002"}}
{"id": "2508.08080", "pdf": "https://arxiv.org/pdf/2508.08080", "abs": "https://arxiv.org/abs/2508.08080", "authors": ["Cas Oude Hoekstra", "Floris den Hengst"], "title": "Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles", "categories": ["cs.LG", "cs.NE", "stat.AP"], "comment": null, "summary": "Symbolic Regression (SR) is a well-established framework for generating\ninterpretable or white-box predictive models. Although SR has been successfully\napplied to create interpretable estimates of the average of the outcome, it is\ncurrently not well understood how it can be used to estimate the relationship\nbetween variables at other points in the distribution of the target variable.\nSuch estimates of e.g. the median or an extreme value provide a fuller picture\nof how predictive variables affect the outcome and are necessary in\nhigh-stakes, safety-critical application domains. This study introduces\nSymbolic Quantile Regression (SQR), an approach to predict conditional\nquantiles with SR. In an extensive evaluation, we find that SQR outperforms\ntransparent models and performs comparably to a strong black-box baseline\nwithout compromising transparency. We also show how SQR can be used to explain\ndifferences in the target distribution by comparing models that predict extreme\nand central outcomes in an airline fuel usage case study. We conclude that SQR\nis suitable for predicting conditional quantiles and understanding interesting\nfeature influences at varying quantiles.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7b26\u53f7\u5206\u4f4d\u6570\u56de\u5f52\uff08SQR\uff09\u65b9\u6cd5\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u9884\u6d4b\u6761\u4ef6\u5206\u4f4d\u6570\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u9002\u7528\u4e8e\u76f8\u5173\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u7b26\u53f7\u56de\u5f52\uff08SR\uff09\u4e0d\u660e\u786e\u5982\u4f55\u5728\u76ee\u6807\u53d8\u91cf\u5206\u5e03\u5176\u4ed6\u70b9\u4f30\u8ba1\u53d8\u91cf\u5173\u7cfb\uff0c\u800c\u5206\u4f4d\u6570\u4f30\u8ba1\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5fc5\u8981\uff0c\u56e0\u6b64\u7814\u7a76\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u7b26\u53f7\u5206\u4f4d\u6570\u56de\u5f52\uff08SQR\uff09\u65b9\u6cd5\u6765\u7528SR\u9884\u6d4b\u6761\u4ef6\u5206\u4f4d\u6570\u3002", "result": "SQR\u4f18\u4e8e\u900f\u660e\u6a21\u578b\uff0c\u4e0e\u5f3a\u9ed1\u76d2\u57fa\u7ebf\u8868\u73b0\u76f8\u5f53\u4e14\u4e0d\u635f\u5931\u900f\u660e\u5ea6\uff0c\u5728\u822a\u7a7a\u71c3\u6cb9\u4f7f\u7528\u6848\u4f8b\u4e2d\u53ef\u89e3\u91ca\u76ee\u6807\u5206\u5e03\u5dee\u5f02\u3002", "conclusion": "SQR\u9002\u7528\u4e8e\u9884\u6d4b\u6761\u4ef6\u5206\u4f4d\u6570\u548c\u7406\u89e3\u4e0d\u540c\u5206\u4f4d\u6570\u4e0a\u7279\u5f81\u7684\u5f71\u54cd\u3002"}}
{"id": "2508.07595", "pdf": "https://arxiv.org/pdf/2508.07595", "abs": "https://arxiv.org/abs/2508.07595", "authors": ["Yunze Luo", "Yinjie Jiang", "Gaode Chen", "Xinghua Zhang", "Jun Zhang", "Jian Liang", "Kaigui Bian"], "title": "Towards Comprehensible Recommendation with Large Language Model Fine-tuning", "categories": ["cs.IR"], "comment": "11 pages, 6 figures", "summary": "Recommender systems have become increasingly ubiquitous in daily life. While\ntraditional recommendation approaches primarily rely on ID-based\nrepresentations or item-side content features, they often fall short in\ncapturing the underlying semantics aligned with user preferences (e.g.,\nrecommendation reasons for items), leading to a semantic-collaborative gap.\nRecently emerged LLM-based feature extraction approaches also face a key\nchallenge: how to ensure that LLMs possess recommendation-aligned reasoning\ncapabilities and can generate accurate, personalized reasons to mitigate the\nsemantic-collaborative gap. To address these issues, we propose a novel Content\nUnderstanding from a Collaborative Perspective framework (CURec), which\ngenerates collaborative-aligned content features for more comprehensive\nrecommendations. \\method first aligns the LLM with recommendation objectives\nthrough pretraining, equipping it with instruction-following and\nchain-of-thought reasoning capabilities. Next, we design a reward model\ninspired by traditional recommendation architectures to evaluate the quality of\nthe recommendation reasons generated by the LLM. Finally, using the reward\nsignals, CURec fine-tunes the LLM through RL and corrects the generated reasons\nto ensure their accuracy. The corrected reasons are then integrated into a\ndownstream recommender model to enhance comprehensibility and recommendation\nperformance. Extensive experiments on public benchmarks demonstrate the\nsuperiority of CURec over existing methods.", "AI": {"tldr": "\u63d0\u51faCURec\u6846\u67b6\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u8bed\u4e49\u534f\u4f5c\u5dee\u8ddd\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u65b9\u6cd5\u96be\u6355\u6349\u4e0e\u7528\u6237\u504f\u597d\u4e00\u81f4\u7684\u8bed\u4e49\uff0c\u5b58\u5728\u8bed\u4e49\u534f\u4f5c\u5dee\u8ddd\uff0c\u65b0\u5174\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u4e5f\u9762\u4e34\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u63a8\u8350\u5bf9\u9f50\u63a8\u7406\u80fd\u529b\u7684\u6311\u6218\u3002", "method": "\u5148\u901a\u8fc7\u9884\u8bad\u7ec3\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u63a8\u8350\u76ee\u6807\u5bf9\u9f50\uff0c\u8bbe\u8ba1\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u63a8\u8350\u7406\u7531\u8d28\u91cf\uff0c\u5229\u7528\u5956\u52b1\u4fe1\u53f7\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u4fee\u6b63\u540e\u7684\u7406\u7531\u96c6\u6210\u5230\u4e0b\u6e38\u63a8\u8350\u6a21\u578b\u3002", "result": "\u5728\u516c\u5171\u57fa\u51c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660eCURec\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CURec\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u7684\u8bed\u4e49\u534f\u4f5c\u5dee\u8ddd\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2508.07486", "pdf": "https://arxiv.org/pdf/2508.07486", "abs": "https://arxiv.org/abs/2508.07486", "authors": ["Morteza Ziabakhsh", "Kiyan Rezaee", "Sadegh Eskandari", "Seyed Amir Hossein Tabatabaei", "Mohammad M. Ghassemi"], "title": "Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering", "categories": ["cs.SE", "cs.AI", "cs.CV"], "comment": null, "summary": "Modern software systems are increasingly shifting from monolithic\narchitectures to microservices to enhance scalability, maintainability, and\ndeployment flexibility. Existing microservice extraction methods typically rely\non hard clustering, assigning each software component to a single microservice.\nThis approach often increases inter-service coupling and reduces intra-service\ncohesion. We propose Mo2oM (Monolithic to Overlapping Microservices), a\nframework that formulates microservice extraction as a soft clustering problem,\nallowing components to belong probabilistically to multiple microservices. This\napproach is inspired by expert-driven decompositions, where practitioners\nintentionally replicate certain software components across services to reduce\ncommunication overhead. Mo2oM combines deep semantic embeddings with structural\ndependencies extracted from methodcall graphs to capture both functional and\narchitectural relationships. A graph neural network-based soft clustering\nalgorithm then generates the final set of microservices. We evaluate Mo2oM on\nfour open-source monolithic benchmarks and compare it against eight\nstate-of-the-art baselines. Our results demonstrate that Mo2oM achieves\nimprovements of up to 40.97% in structural modularity (balancing cohesion and\ncoupling), 58% in inter-service call percentage (communication overhead),\n26.16% in interface number (modularity and decoupling), and 38.96% in\nnon-extreme distribution (service size balance) across all benchmarks.", "AI": {"tldr": "\u63d0\u51faMo2oM\u6846\u67b6\u5c06\u5355\u4f53\u5e94\u7528\u63d0\u53d6\u4e3a\u91cd\u53e0\u5fae\u670d\u52a1\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5fae\u670d\u52a1\u63d0\u53d6\u65b9\u6cd5\u91c7\u7528\u786c\u805a\u7c7b\uff0c\u589e\u52a0\u4e86\u670d\u52a1\u95f4\u8026\u5408\uff0c\u964d\u4f4e\u4e86\u670d\u52a1\u5185\u5185\u805a\uff0c\u9700\u8981\u66f4\u597d\u7684\u63d0\u53d6\u65b9\u6cd5\u3002", "method": "\u5c06\u5fae\u670d\u52a1\u63d0\u53d6\u8868\u8ff0\u4e3a\u8f6f\u805a\u7c7b\u95ee\u9898\uff0c\u7ed3\u5408\u6df1\u5ea6\u8bed\u4e49\u5d4c\u5165\u548c\u65b9\u6cd5\u8c03\u7528\u56fe\u7684\u7ed3\u6784\u4f9d\u8d56\uff0c\u4f7f\u7528\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8f6f\u805a\u7c7b\u7b97\u6cd5\u3002", "result": "\u5728\u56db\u4e2a\u5f00\u6e90\u5355\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\uff0c\u5728\u7ed3\u6784\u6a21\u5757\u5316\u3001\u670d\u52a1\u95f4\u8c03\u7528\u767e\u5206\u6bd4\u3001\u63a5\u53e3\u6570\u91cf\u548c\u975e\u6781\u7aef\u5206\u5e03\u7b49\u6307\u6807\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Mo2oM\u6846\u67b6\u5728\u5fae\u670d\u52a1\u63d0\u53d6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u6709\u6548\u63d0\u5347\u591a\u4e2a\u5173\u952e\u6307\u6807\u3002"}}
{"id": "2508.06635", "pdf": "https://arxiv.org/pdf/2508.06635", "abs": "https://arxiv.org/abs/2508.06635", "authors": ["Yewon Byun", "Shantanu Gupta", "Zachary C. Lipton", "Rachel Leah Childers", "Bryan Wilder"], "title": "Using Imperfect Synthetic Data in Downstream Inference Tasks", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Predictions and generations from large language models are increasingly being\nexplored as an aid to computational social science and human subject research\nin limited data regimes. While previous technical work has explored the\npotential to use model-predicted labels for unlabeled data in a principled\nmanner, there is increasing interest in using large language models to generate\nentirely new synthetic samples (also termed as synthetic simulations), such as\nin responses to surveys. However, it is not immediately clear by what means\npractitioners can combine such data with real data and yet produce\nstatistically valid conclusions upon them. In this work, we introduce a new\nestimator based on generalized method of moments, providing a\nhyperparameter-free solution with strong theoretical guarantees to address the\nchallenge at hand. Surprisingly, we find that interactions between the moment\nresiduals of synthetic data and those of real data can improve estimates of the\ntarget parameter. We empirically validate the finite-sample performance of our\nestimator across different regression tasks in computational social science\napplications, demonstrating large empirical gains.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u57fa\u4e8e\u5e7f\u4e49\u77e9\u4f30\u8ba1\u7684\u65b0\u4f30\u8ba1\u5668\uff0c\u7ed3\u5408\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u6570\u636e\uff0c\u5728\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u5e94\u7528\u4e2d\u9a8c\u8bc1\u5176\u6709\u9650\u6837\u672c\u6027\u80fd\uff0c\u53d6\u5f97\u663e\u8457\u5b9e\u8bc1\u589e\u76ca\u3002", "motivation": "\u6b64\u524d\u867d\u6709\u7814\u7a76\u63a2\u7d22\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u6807\u7b7e\u548c\u751f\u6210\u5408\u6210\u6837\u672c\uff0c\u4f46\u4e0d\u6e05\u695a\u5982\u4f55\u5c06\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u7ed3\u5408\u4ee5\u5f97\u51fa\u7edf\u8ba1\u6709\u6548\u7ed3\u8bba\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5e7f\u4e49\u77e9\u4f30\u8ba1\u7684\u65b0\u4f30\u8ba1\u5668\uff0c\u662f\u65e0\u8d85\u53c2\u6570\u4e14\u6709\u5f3a\u7406\u8bba\u4fdd\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u53d1\u73b0\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u6570\u636e\u7684\u77e9\u6b8b\u5dee\u76f8\u4e92\u4f5c\u7528\u53ef\u6539\u5584\u76ee\u6807\u53c2\u6570\u4f30\u8ba1\uff0c\u5728\u4e0d\u540c\u56de\u5f52\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u4f30\u8ba1\u5668\u6709\u9650\u6837\u672c\u6027\u80fd\uff0c\u6709\u8f83\u5927\u5b9e\u8bc1\u589e\u76ca\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b0\u4f30\u8ba1\u5668\u80fd\u6709\u6548\u89e3\u51b3\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u7ed3\u5408\u5e76\u5f97\u51fa\u7edf\u8ba1\u6709\u6548\u7ed3\u8bba\u7684\u95ee\u9898\u3002"}}
{"id": "2508.08076", "pdf": "https://arxiv.org/pdf/2508.08076", "abs": "https://arxiv.org/abs/2508.08076", "authors": ["Mohammad Hossein Moslemi", "Amir Mousavi", "Behshid Behkamal", "Mostafa Milani"], "title": "Heterogeneity in Entity Matching: A Survey and Experimental Analysis", "categories": ["cs.DB", "68P20 68P20 68P20", "H.2.8; H.2.4; I.2.7"], "comment": "Survey and experimental analysis on heterogeneous entity matching", "summary": "Entity matching (EM) is a fundamental task in data integration and analytics,\nessential for identifying records that refer to the same real-world entity\nacross diverse sources. In practice, datasets often differ widely in structure,\nformat, schema, and semantics, creating substantial challenges for EM. We refer\nto this setting as Heterogeneous EM (HEM). This survey offers a unified\nperspective on HEM by introducing a taxonomy, grounded in prior work, that\ndistinguishes two primary categories -- representation and semantic\nheterogeneity -- and their subtypes. The taxonomy provides a systematic lens\nfor understanding how variations in data form and meaning shape the complexity\nof matching tasks. We then connect this framework to the FAIR principles --\nFindability, Accessibility, Interoperability, and Reusability -- demonstrating\nhow they both reveal the challenges of HEM and suggest strategies for\nmitigating them. Building on this foundation, we critically review recent EM\nmethods, examining their ability to address different heterogeneity types, and\nconduct targeted experiments on state-of-the-art models to evaluate their\nrobustness and adaptability under semantic heterogeneity. Our analysis uncovers\npersistent limitations in current approaches and points to promising directions\nfor future research, including multimodal matching, human-in-the-loop\nworkflows, deeper integration with large language models and knowledge graphs,\nand fairness-aware evaluation in heterogeneous settings.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5f02\u6784\u5b9e\u4f53\u5339\u914d\uff08HEM\uff09\u8fdb\u884c\u7efc\u8ff0\uff0c\u63d0\u51fa\u5206\u7c7b\u6cd5\uff0c\u8fde\u63a5FAIR\u539f\u5219\uff0c\u8bc4\u4f30\u73b0\u6709\u65b9\u6cd5\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5b9e\u9645\u4e2d\u6570\u636e\u96c6\u7ed3\u6784\u3001\u683c\u5f0f\u3001\u6a21\u5f0f\u548c\u8bed\u4e49\u5dee\u5f02\u5927\uff0c\u7ed9\u5b9e\u4f53\u5339\u914d\uff08EM\uff09\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u5bf9\u5f02\u6784\u5b9e\u4f53\u5339\u914d\uff08HEM\uff09\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5148\u524d\u5de5\u4f5c\u7684\u5206\u7c7b\u6cd5\u533a\u5206\u4e24\u79cd\u4e3b\u8981\u5f02\u8d28\u6027\u7c7b\u522b\u53ca\u5b50\u7c7b\u578b\uff1b\u5c06\u6846\u67b6\u4e0eFAIR\u539f\u5219\u76f8\u8054\u7cfb\uff1b\u6279\u5224\u6027\u56de\u987e\u8fd1\u671fEM\u65b9\u6cd5\uff1b\u5bf9\u5148\u8fdb\u6a21\u578b\u8fdb\u884c\u9488\u5bf9\u6027\u5b9e\u9a8c\u3002", "result": "\u5206\u6790\u53d1\u73b0\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u6301\u7eed\u5c40\u9650\u6027\u3002", "conclusion": "\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u591a\u6a21\u6001\u5339\u914d\u3001\u4eba\u5728\u73af\u5de5\u4f5c\u6d41\u3001\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u6df1\u5ea6\u96c6\u6210\u3001\u5f02\u6784\u73af\u5883\u4e0b\u7684\u516c\u5e73\u611f\u77e5\u8bc4\u4f30\u3002"}}
{"id": "2508.06509", "pdf": "https://arxiv.org/pdf/2508.06509", "abs": "https://arxiv.org/abs/2508.06509", "authors": ["Rafael Prieto-Curiel", "Dieter Grass", "Stefan Wrzaczek", "Gian Maria Campedelli", "Gernot Tragler", "Gustav Feichtinger"], "title": "Reducing Cartel Violence: The Mexican Dilemma Between Social and Security Spending", "categories": ["physics.soc-ph", "econ.GN", "q-fin.EC"], "comment": "50 pages, 16 figures", "summary": "Organised crime in Mexico threatens societal stability and public safety,\ndriving pervasive violence and economic disruption. Despite security\ninvestments and social programs designed in part to reduce involvement in\ncrime, cartel power and violence continue to persist. This study evaluates\nexisting policies and introduces a novel framework using optimal control theory\nto analyse cartel dynamics. Specifically, by modelling resource allocation\nbetween security measures and social programs, we identify optimal strategies\nto mitigate the impacts of cartels. Findings reveal that Mexico's largest\ncartel imposes an annual economic burden exceeding \\text{US\\$ } 19 billion, 2.5\ntimes the government's investment in science and technology. We further\ndemonstrate that current budget allocations between social and security\nprograms are nearly optimal yet insufficient to reduce cartel violence\nsignificantly. In light of these findings, we demonstrate that achieving\nmeaningful harm reduction would require a significantly larger budget and would\ntake over a decade, even with increased funding.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u58a8\u897f\u54e5\u6253\u51fb\u6709\u7ec4\u7ec7\u72af\u7f6a\u7684\u73b0\u6709\u653f\u7b56\uff0c\u7528\u6700\u4f18\u63a7\u5236\u7406\u8bba\u5206\u6790\uff0c\u53d1\u73b0\u6700\u5927\u5361\u7279\u5c14\u5e74\u7ecf\u6d4e\u8d1f\u62c5\u8d85190\u4ebf\u7f8e\u5143\uff0c\u5f53\u524d\u9884\u7b97\u5206\u914d\u63a5\u8fd1\u6700\u4f18\u4f46\u4e0d\u8db3\u4ee5\u663e\u8457\u51cf\u5c11\u66b4\u529b\uff0c\u5927\u5e45\u51cf\u5c11\u5371\u5bb3\u9700\u66f4\u591a\u9884\u7b97\u548c\u8d85\u5341\u5e74\u65f6\u95f4\u3002", "motivation": "\u58a8\u897f\u54e5\u6709\u7ec4\u7ec7\u72af\u7f6a\u5a01\u80c1\u793e\u4f1a\u7a33\u5b9a\u4e0e\u516c\u5171\u5b89\u5168\uff0c\u73b0\u6709\u5b89\u5168\u6295\u8d44\u548c\u793e\u4f1a\u9879\u76ee\u672a\u80fd\u6709\u6548\u904f\u5236\u5361\u7279\u5c14\u52bf\u529b\u4e0e\u66b4\u529b\u3002", "method": "\u4f7f\u7528\u6700\u4f18\u63a7\u5236\u7406\u8bba\u6784\u5efa\u6846\u67b6\uff0c\u5bf9\u5b89\u5168\u63aa\u65bd\u548c\u793e\u4f1a\u9879\u76ee\u7684\u8d44\u6e90\u5206\u914d\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u58a8\u897f\u54e5\u6700\u5927\u5361\u7279\u5c14\u5e74\u7ecf\u6d4e\u8d1f\u62c5\u8d85190\u4ebf\u7f8e\u5143\uff0c\u662f\u653f\u5e9c\u79d1\u6280\u6295\u8d442.5\u500d\uff1b\u5f53\u524d\u793e\u4f1a\u548c\u5b89\u5168\u9879\u76ee\u9884\u7b97\u5206\u914d\u63a5\u8fd1\u6700\u4f18\uff0c\u4f46\u4e0d\u8db3\u4ee5\u663e\u8457\u51cf\u5c11\u5361\u7279\u5c14\u66b4\u529b\u3002", "conclusion": "\u8981\u5b9e\u73b0\u6709\u610f\u4e49\u7684\u5371\u5bb3\u51cf\u5c11\uff0c\u9700\u8981\u5927\u5e45\u589e\u52a0\u9884\u7b97\uff0c\u4e14\u5373\u4fbf\u589e\u52a0\u8d44\u91d1\u4e5f\u9700\u8d85\u5341\u5e74\u65f6\u95f4\u3002"}}
{"id": "2508.08022", "pdf": "https://arxiv.org/pdf/2508.08022", "abs": "https://arxiv.org/abs/2508.08022", "authors": ["Roopkatha Banerjee", "Sampath Koti", "Gyanendra Singh", "Anirban Chakraborty", "Gurunath Gurrala", "Bhushan Jagyasi", "Yogesh Simmhan"], "title": "Optimizing Federated Learning for Scalable Power-demand Forecasting in Microgrids", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Real-time monitoring of power consumption in cities and micro-grids through\nthe Internet of Things (IoT) can help forecast future demand and optimize grid\noperations. But moving all consumer-level usage data to the cloud for\npredictions and analysis at fine time scales can expose activity patterns.\nFederated Learning~(FL) is a privacy-sensitive collaborative DNN training\napproach that retains data on edge devices, trains the models on private data\nlocally, and aggregates the local models in the cloud. But key challenges\nexist: (i) clients can have non-independently identically distributed~(non-IID)\ndata, and (ii) the learning should be computationally cheap while scaling to\n1000s of (unseen) clients. In this paper, we develop and evaluate several\noptimizations to FL training across edge and cloud for time-series demand\nforecasting in micro-grids and city-scale utilities using DNNs to achieve a\nhigh prediction accuracy while minimizing the training cost. We showcase the\nbenefit of using exponentially weighted loss while training and show that it\nfurther improves the prediction of the final model. Finally, we evaluate these\nstrategies by validating over 1000s of clients for three states in the US from\nthe OpenEIA corpus, and performing FL both in a pseudo-distributed setting and\na Pi edge cluster. The results highlight the benefits of the proposed methods\nover baselines like ARIMA and DNNs trained for individual consumers, which are\nnot scalable.", "AI": {"tldr": "\u672c\u6587\u4e3a\u5fae\u7535\u7f51\u548c\u57ce\u5e02\u7ea7\u516c\u7528\u4e8b\u4e1a\u7684\u65f6\u95f4\u5e8f\u5217\u9700\u6c42\u9884\u6d4b\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u8bad\u7ec3\u7684\u4f18\u5316\u65b9\u6848\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u5b9e\u65f6\u76d1\u6d4b\u57ce\u5e02\u548c\u5fae\u7535\u7f51\u7684\u7535\u529b\u6d88\u8017\u53ef\u5e2e\u52a9\u9884\u6d4b\u9700\u6c42\u548c\u4f18\u5316\u7535\u7f51\u8fd0\u8425\uff0c\u4f46\u5c06\u6570\u636e\u79fb\u81f3\u4e91\u7aef\u5206\u6790\u4f1a\u66b4\u9732\u6d3b\u52a8\u6a21\u5f0f\uff0c\u4e14\u73b0\u6709FL\u5b58\u5728\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u6311\u6218\u3002", "method": "\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86\u8de8\u8fb9\u7f18\u548c\u4e91\u7684FL\u8bad\u7ec3\u4f18\u5316\u65b9\u6848\uff0c\u4f7f\u7528\u6307\u6570\u52a0\u6743\u635f\u5931\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u901a\u8fc7\u5bf9\u7f8e\u56fd\u4e09\u4e2a\u5dde\u8d85\u5343\u4e2a\u5ba2\u6237\u7aef\u9a8c\u8bc1\uff0c\u5728\u4f2a\u5206\u5e03\u5f0f\u8bbe\u7f6e\u548cPi\u8fb9\u7f18\u96c6\u7fa4\u4e2d\u8fdb\u884cFL\uff0c\u7ed3\u679c\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8eARIMA\u548c\u4e3a\u5355\u4e2a\u6d88\u8d39\u8005\u8bad\u7ec3\u7684DNN\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u4f18\u5316\u65b9\u6848\u80fd\u5728\u5fae\u7535\u7f51\u548c\u57ce\u5e02\u7ea7\u516c\u7528\u4e8b\u4e1a\u7684\u9700\u6c42\u9884\u6d4b\u4e2d\u5b9e\u73b0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u3002"}}
{"id": "2508.06754", "pdf": "https://arxiv.org/pdf/2508.06754", "abs": "https://arxiv.org/abs/2508.06754", "authors": ["Vanessa Figueiredo"], "title": "A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks", "categories": ["cs.AI", "I.2.7"], "comment": null, "summary": "We introduce a modular prompting framework that supports safer and more\nadaptive use of large language models (LLMs) across dynamic, user-centered\ntasks. Grounded in human learning theory, particularly the Zone of Proximal\nDevelopment (ZPD), our method combines a natural language boundary prompt with\na control schema encoded with fuzzy scaffolding logic and adaptation rules.\nThis architecture enables LLMs to modulate behavior in response to user state\nwithout requiring fine-tuning or external orchestration. In a simulated\nintelligent tutoring setting, the framework improves scaffolding quality,\nadaptivity, and instructional alignment across multiple models, outperforming\nstandard prompting baselines. Evaluation is conducted using rubric-based LLM\ngraders at scale. While initially developed for education, the framework has\nshown promise in other interaction-heavy domains, such as procedural content\ngeneration for games. Designed for safe deployment, it provides a reusable\nmethodology for structuring interpretable, goal-aligned LLM behavior in\nuncertain or evolving contexts.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5757\u5316\u63d0\u793a\u6846\u67b6\uff0c\u652f\u6301\u5728\u52a8\u6001\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u4efb\u52a1\u4e2d\u66f4\u5b89\u5168\u3001\u81ea\u9002\u5e94\u5730\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6a21\u62df\u8f85\u5bfc\u573a\u666f\u8868\u73b0\u51fa\u8272\u4e14\u6709\u5176\u4ed6\u9886\u57df\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u4efb\u52a1\u4e2d\u66f4\u5b89\u5168\u3001\u81ea\u9002\u5e94\u7684\u4f7f\u7528\u3002", "method": "\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u8fb9\u754c\u63d0\u793a\u3001\u6a21\u7cca\u652f\u67b6\u903b\u8f91\u548c\u9002\u5e94\u89c4\u5219\u7684\u63a7\u5236\u6a21\u5f0f\uff0c\u57fa\u4e8e\u4eba\u7c7b\u5b66\u4e60\u7406\u8bba\u3002", "result": "\u5728\u6a21\u62df\u667a\u80fd\u8f85\u5bfc\u573a\u666f\u4e2d\uff0c\u63d0\u5347\u4e86\u652f\u67b6\u8d28\u91cf\u3001\u9002\u5e94\u6027\u548c\u6559\u5b66\u4e00\u81f4\u6027\uff0c\u4f18\u4e8e\u6807\u51c6\u63d0\u793a\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0d\u786e\u5b9a\u6216\u4e0d\u65ad\u53d8\u5316\u7684\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u89e3\u91ca\u3001\u76ee\u6807\u4e00\u81f4\u7684\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u590d\u7528\u65b9\u6cd5\u3002"}}
{"id": "2508.06685", "pdf": "https://arxiv.org/pdf/2508.06685", "abs": "https://arxiv.org/abs/2508.06685", "authors": ["Chaoqian Wang", "Wei Zhang", "Xinwei Wang", "Attila Szolnoki"], "title": "Inter-role reciprocity in evolutionary trust game on square lattices", "categories": ["physics.soc-ph", "cs.GT", "nlin.CG"], "comment": "10 pages, 7 figures", "summary": "Simulating bipartite games, such as the trust game, is not straightforward\ndue to the lack of a natural way to distinguish roles in a single population.\nThe square lattice topology can provide a simple yet elegant solution by\nalternating trustors and trustees. For even lattice sizes, it creates two\ndisjoint diagonal sub-lattices for strategy learning, while game interactions\ncan take place on the original lattice. This setup ensures a minimal spatial\nstructure that allows interactions across roles and learning within roles. By\nsimulations on this setup, we detect an inter-role spatial reciprocity\nmechanism, through which trust can emerge. In particular, a moderate return\nratio allows investing trustors and trustworthy trustees to form inter-role\nclusters and thus save trust. If the return is too high, it harms the survival\nof trustees; if too low, it harms trustors. The proposed simulation framework\nis also applicable to any bipartite game to uncover potential inter-role\nspatial mechanisms across various scenarios.", "AI": {"tldr": "\u5229\u7528\u65b9\u5f62\u6676\u683c\u62d3\u6251\u6a21\u62df\u53cc\u8fb9\u535a\u5f08\uff0c\u53d1\u73b0\u89d2\u8272\u95f4\u7a7a\u95f4\u4e92\u60e0\u673a\u5236\u4f7f\u4fe1\u4efb\u51fa\u73b0\uff0c\u6a21\u62df\u6846\u67b6\u9002\u7528\u4e8e\u53cc\u8fb9\u535a\u5f08\u3002", "motivation": "\u53cc\u8fb9\u535a\u5f08\u6a21\u62df\u56e0\u5355\u4e00\u79cd\u7fa4\u7f3a\u4e4f\u533a\u5206\u89d2\u8272\u7684\u81ea\u7136\u65b9\u5f0f\u800c\u4e0d\u76f4\u63a5\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u91c7\u7528\u65b9\u5f62\u6676\u683c\u62d3\u6251\uff0c\u4e3a\u7b56\u7565\u5b66\u4e60\u521b\u5efa\u4e24\u4e2a\u4e0d\u76f8\u4ea4\u7684\u5bf9\u89d2\u5b50\u6676\u683c\uff0c\u5728\u539f\u6676\u683c\u4e0a\u8fdb\u884c\u6e38\u620f\u4ea4\u4e92\uff0c\u5e76\u8fdb\u884c\u6a21\u62df\u3002", "result": "\u68c0\u6d4b\u5230\u89d2\u8272\u95f4\u7a7a\u95f4\u4e92\u60e0\u673a\u5236\u4f7f\u4fe1\u4efb\u51fa\u73b0\uff0c\u9002\u5ea6\u56de\u62a5\u7387\u80fd\u8ba9\u6295\u8d44\u8005\u548c\u53d7\u6258\u4eba\u5f62\u6210\u89d2\u8272\u95f4\u96c6\u7fa4\uff0c\u8fc7\u9ad8\u6216\u8fc7\u4f4e\u56de\u62a5\u7387\u5206\u522b\u635f\u5bb3\u53d7\u6258\u4eba\u6216\u4fe1\u4efb\u8005\u751f\u5b58\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u62df\u6846\u67b6\u9002\u7528\u4e8e\u4efb\u4f55\u53cc\u8fb9\u535a\u5f08\uff0c\u53ef\u63ed\u793a\u4e0d\u540c\u573a\u666f\u4e0b\u6f5c\u5728\u7684\u89d2\u8272\u95f4\u7a7a\u95f4\u673a\u5236\u3002"}}
{"id": "2508.07613", "pdf": "https://arxiv.org/pdf/2508.07613", "abs": "https://arxiv.org/abs/2508.07613", "authors": ["Zhengrui Xu", "Zhe Yang", "Zhengxiao Guo", "Shukai Liu", "Luocheng Lin", "Xiaoyan Liu", "Yongqi Liu", "Han Li"], "title": "UMRE: A Unified Monotonic Transformation for Ranking Ensemble in Recommender Systems", "categories": ["cs.IR"], "comment": null, "summary": "Industrial recommender systems commonly rely on ensemble sorting (ES) to\ncombine predictions from multiple behavioral objectives. Traditionally, this\nprocess depends on manually designed nonlinear transformations (e.g.,\npolynomial or exponential functions) and hand-tuned fusion weights to balance\ncompeting goals -- an approach that is labor-intensive and frequently\nsuboptimal in achieving Pareto efficiency. In this paper, we propose a novel\nUnified Monotonic Ranking Ensemble (UMRE) framework to address the limitations\nof traditional methods in ensemble sorting. UMRE replaces handcrafted\ntransformations with Unconstrained Monotonic Neural Networks (UMNN), which\nlearn expressive, strictly monotonic functions through the integration of\npositive neural integrals. Subsequently, a lightweight ranking model is\nemployed to fuse the prediction scores, assigning personalized weights to each\nprediction objective. To balance competing goals, we further introduce a Pareto\noptimality strategy that adaptively coordinates task weights during training.\nUMRE eliminates manual tuning, maintains ranking consistency, and achieves\nfine-grained personalization. Experimental results on two public recommendation\ndatasets (Kuairand and Tenrec) and online A/B tests demonstrate impressive\nperformance and generalization capabilities.", "AI": {"tldr": "\u63d0\u51faUMRE\u6846\u67b6\u89e3\u51b3\u4f20\u7edf\u96c6\u6210\u6392\u5e8f\u65b9\u6cd5\u5c40\u9650\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u96c6\u6210\u6392\u5e8f\u4f9d\u8d56\u624b\u52a8\u8bbe\u8ba1\u53d8\u6362\u548c\u8c03\u53c2\uff0c\u52b3\u52a8\u5bc6\u96c6\u4e14\u96be\u8fbe\u5e15\u7d2f\u6258\u6700\u4f18\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u7528UMNN\u66ff\u4ee3\u624b\u5de5\u53d8\u6362\uff0c\u7528\u8f7b\u91cf\u7ea7\u6392\u5e8f\u6a21\u578b\u878d\u5408\u9884\u6d4b\u5206\u6570\uff0c\u5f15\u5165\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u5e73\u8861\u76ee\u6807\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c\u7ebf\u4e0aA/B\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "UMRE\u6d88\u9664\u624b\u52a8\u8c03\u53c2\uff0c\u4fdd\u6301\u6392\u5e8f\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u4e2a\u6027\u5316\u3002"}}
{"id": "2508.06655", "pdf": "https://arxiv.org/pdf/2508.06655", "abs": "https://arxiv.org/abs/2508.06655", "authors": ["Qiheng Lu", "Nicholas D. Sidiropoulos", "Aritra Konar"], "title": "The Vertex-Attribute-Constrained Densest $k$-Subgraph Problem", "categories": ["cs.SI", "cs.DS"], "comment": null, "summary": "Dense subgraph mining is a fundamental technique in graph mining, commonly\napplied in fraud detection, community detection, product recommendation, and\ndocument summarization. In such applications, we are often interested in\nidentifying communities, recommendations, or summaries that reflect different\nconstituencies, styles or genres, and points of view. For this task, we\nintroduce a new variant of the Densest $k$-Subgraph (D$k$S) problem that\nincorporates the attribute values of vertices. The proposed\nVertex-Attribute-Constrained Densest $k$-Subgraph (VAC-D$k$S) problem retains\nthe NP-hardness and inapproximability properties of the classical D$k$S.\nNevertheless, we prove that a suitable continuous relaxation of VAC-D$k$S is\ntight and can be efficiently tackled using a projection-free Frank--Wolfe\nalgorithm. We also present an insightful analysis of the optimization landscape\nof the relaxed problem. Extensive experimental results demonstrate the\neffectiveness of our proposed formulation and algorithm, and its ability to\nscale up to large graphs. We further elucidate the properties of VAC-D$k$S\nversus classical D$k$S in a political network mining application, where\nVAC-D$k$S identifies a balanced and more meaningful set of politicians\nrepresenting different ideological camps, in contrast to the classical D$k$S\nsolution which is unbalanced and rather mundane.", "AI": {"tldr": "\u63d0\u51fa\u9876\u70b9\u5c5e\u6027\u7ea6\u675f\u7684\u6700\u5bc6k\u5b50\u56fe\uff08VAC - DkS\uff09\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u8fde\u7eed\u677e\u5f1b\u95ee\u9898\u53ef\u901a\u8fc7\u65e0\u6295\u5f71Frank - Wolfe\u7b97\u6cd5\u89e3\u51b3\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u4e14\u53ef\u5904\u7406\u5927\u56fe\uff0c\u5728\u653f\u6cbb\u7f51\u7edc\u6316\u6398\u4e2d\u8868\u73b0\u4f18\u4e8e\u7ecf\u5178DkS\u3002", "motivation": "\u5728\u56fe\u6316\u6398\u5e94\u7528\u4e2d\uff0c\u9700\u8bc6\u522b\u53cd\u6620\u4e0d\u540c\u7279\u5f81\u7684\u793e\u533a\u3001\u63a8\u8350\u6216\u6458\u8981\uff0c\u56e0\u6b64\u5f15\u5165\u7ed3\u5408\u9876\u70b9\u5c5e\u6027\u503c\u7684\u65b0DkS\u95ee\u9898\u53d8\u79cd\u3002", "method": "\u8bc1\u660eVAC - DkS\u5408\u9002\u7684\u8fde\u7eed\u677e\u5f1b\u95ee\u9898\u662f\u7d27\u7684\uff0c\u4f7f\u7528\u65e0\u6295\u5f71Frank - Wolfe\u7b97\u6cd5\u89e3\u51b3\u8be5\u677e\u5f1b\u95ee\u9898\uff0c\u5e76\u5206\u6790\u677e\u5f1b\u95ee\u9898\u7684\u4f18\u5316\u683c\u5c40\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u63d0\u51fa\u7684\u516c\u5f0f\u548c\u7b97\u6cd5\u6709\u6548\uff0c\u80fd\u5904\u7406\u5927\u56fe\uff1b\u5728\u653f\u6cbb\u7f51\u7edc\u6316\u6398\u5e94\u7528\u4e2d\uff0cVAC - DkS\u80fd\u8bc6\u522b\u51fa\u66f4\u5e73\u8861\u3001\u66f4\u6709\u610f\u4e49\u7684\u653f\u6cbb\u5bb6\u96c6\u5408\u3002", "conclusion": "\u63d0\u51fa\u7684VAC - DkS\u95ee\u9898\u53ca\u89e3\u51b3\u65b9\u6cd5\u6709\u6548\uff0c\u5728\u5904\u7406\u5927\u56fe\u548c\u7279\u5b9a\u5e94\u7528\u4e2d\u6709\u4f18\u52bf\u3002"}}
{"id": "2508.07881", "pdf": "https://arxiv.org/pdf/2508.07881", "abs": "https://arxiv.org/abs/2508.07881", "authors": ["Henna Tammia", "Benjamin K\u00e4m\u00e4", "Ella Peltonen"], "title": "Adopting Road-Weather Open Data in Route Recommendation Engine", "categories": ["cs.SE"], "comment": null, "summary": "Digitraffic, Finland's open road data interface, provides access to\nnationwide road sensors with more than 2,300 real-time attributes from 1,814\nstations. However, efficiently utilizing such a versatile data API for a\npractical application requires a deeper understanding of the data qualities,\npreprocessing phases, and machine learning tools. This paper discusses the\nchallenges of large-scale road weather and traffic data. We go through the\nroad-weather-related attributes from DigiTraffic as a practical example of\nprocesses required to work with such a dataset. In addition, we provide a\nmethodology for efficient data utilization for the target application, a\npersonalized road recommendation engine based on a simple routing application.\nWe validate our solution based on real-world data, showing we can efficiently\nidentify and recommend personalized routes for three different driver profiles.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u82ac\u5170\u5f00\u653e\u9053\u8def\u6570\u636e\u63a5\u53e3Digitraffic\u6570\u636e\u5229\u7528\u6311\u6218\uff0c\u4ee5\u9053\u8def\u5929\u6c14\u5c5e\u6027\u4e3a\u4f8b\uff0c\u7ed9\u51fa\u9ad8\u6548\u6570\u636e\u5229\u7528\u65b9\u6cd5\u5e76\u9a8c\u8bc1\u53ef\u63a8\u8350\u4e2a\u6027\u5316\u8def\u7ebf\u3002", "motivation": "\u6709\u6548\u5229\u7528Digitraffic\u6570\u636e\u63a5\u53e3\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\uff0c\u9700\u6df1\u5165\u4e86\u89e3\u6570\u636e\u8d28\u91cf\u3001\u9884\u5904\u7406\u9636\u6bb5\u548c\u673a\u5668\u5b66\u4e60\u5de5\u5177\u3002", "method": "\u4ee5Digitraffic\u4e2d\u4e0e\u9053\u8def\u5929\u6c14\u76f8\u5173\u7684\u5c5e\u6027\u4e3a\u4f8b\uff0c\u4e3a\u57fa\u4e8e\u7b80\u5355\u8def\u7531\u5e94\u7528\u7684\u4e2a\u6027\u5316\u9053\u8def\u63a8\u8350\u5f15\u64ce\u63d0\u4f9b\u9ad8\u6548\u6570\u636e\u5229\u7528\u65b9\u6cd5\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u9a8c\u8bc1\u4e86\u8be5\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u4e3a\u4e09\u79cd\u4e0d\u540c\u7684\u9a7e\u9a76\u5458\u914d\u7f6e\u6587\u4ef6\u9ad8\u6548\u8bc6\u522b\u548c\u63a8\u8350\u4e2a\u6027\u5316\u8def\u7ebf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5229\u7528Digitraffic\u6570\u636e\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u9053\u8def\u63a8\u8350\u3002"}}
{"id": "2508.06627", "pdf": "https://arxiv.org/pdf/2508.06627", "abs": "https://arxiv.org/abs/2508.06627", "authors": ["Mosbah Aouad", "Anirudh Choudhary", "Awais Farooq", "Steven Nevers", "Lusine Demirkhanyan", "Bhrandon Harris", "Suguna Pappu", "Christopher Gondi", "Ravishankar Iyer"], "title": "Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and\nearly detection remains a major clinical challenge due to the absence of\nspecific symptoms and reliable biomarkers. In this work, we propose a new\nmultimodal approach that integrates longitudinal diagnosis code histories and\nroutinely collected laboratory measurements from electronic health records to\ndetect PDAC up to one year prior to clinical diagnosis. Our method combines\nneural controlled differential equations to model irregular lab time series,\npretrained language models and recurrent networks to learn diagnosis code\ntrajectory representations, and cross-attention mechanisms to capture\ninteractions between the two modalities. We develop and evaluate our approach\non a real-world dataset of nearly 4,700 patients and achieve significant\nimprovements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods.\nFurthermore, our model identifies diagnosis codes and laboratory panels\nassociated with elevated PDAC risk, including both established and new\nbiomarkers. Our code is available at\nhttps://github.com/MosbahAouad/EarlyPDAC-MML.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u65b9\u6cd5\u7ed3\u5408\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u68c0\u6d4b\u80f0\u817a\u764c\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6548\u679c\u4f18\u4e14\u627e\u5230\u76f8\u5173\u751f\u7269\u6807\u5fd7\u7269\u3002", "motivation": "\u80f0\u817a\u764c\u81f4\u547d\u4e14\u65e9\u671f\u68c0\u6d4b\u56e0\u7f3a\u4e4f\u7279\u5b9a\u75c7\u72b6\u548c\u53ef\u9760\u751f\u7269\u6807\u5fd7\u7269\u800c\u56f0\u96be\u3002", "method": "\u7ed3\u5408\u795e\u7ecf\u53d7\u63a7\u5fae\u5206\u65b9\u7a0b\u3001\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3001\u5faa\u73af\u7f51\u7edc\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7eb5\u5411\u8bca\u65ad\u4ee3\u7801\u5386\u53f2\u548c\u5b9e\u9a8c\u5ba4\u6d4b\u91cf\u6570\u636e\u3002", "result": "\u5728\u8fd14700\u540d\u60a3\u8005\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cAUC\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad86.5% - 15.5%\uff0c\u6a21\u578b\u8bc6\u522b\u51fa\u4e0e\u80f0\u817a\u764c\u98ce\u9669\u5347\u9ad8\u76f8\u5173\u7684\u8bca\u65ad\u4ee3\u7801\u548c\u5b9e\u9a8c\u5ba4\u6307\u6807\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u6a21\u6001\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u524d\u68c0\u6d4b\u80f0\u817a\u764c\uff0c\u6709\u8f83\u597d\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2508.06776", "pdf": "https://arxiv.org/pdf/2508.06776", "abs": "https://arxiv.org/abs/2508.06776", "authors": ["Amit Pandey"], "title": "Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "14 pages", "summary": "We present Zero-Direction Probing (ZDP), a theory-only framework for\ndetecting model drift from null directions of transformer activations without\ntask labels or output evaluations. Under assumptions A1--A6, we prove: (i) the\nVariance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound\nfor low-rank updates, and (iv) a logarithmic-regret guarantee for online\nnull-space trackers. We derive a Spectral Null-Leakage (SNL) metric with\nnon-asymptotic tail bounds and a concentration inequality, yielding a-priori\nthresholds for drift under a Gaussian null model. These results show that\nmonitoring right/left null spaces of layer activations and their Fisher\ngeometry provides concrete, testable guarantees on representational change.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u4efb\u52a1\u6807\u7b7e\u548c\u8f93\u51fa\u8bc4\u4f30\u7684\u7406\u8bba\u6846\u67b6Zero - Direction Probing (ZDP)\u68c0\u6d4b\u6a21\u578b\u6f02\u79fb\uff0c\u8bc1\u660e\u591a\u4e2a\u5b9a\u7406\uff0c\u63a8\u5bfcSNL\u6307\u6807\uff0c\u8868\u660e\u76d1\u6d4b\u96f6\u7a7a\u95f4\u53ef\u4fdd\u8bc1\u68c0\u6d4b\u8868\u793a\u53d8\u5316\u3002", "motivation": "\u5728\u65e0\u4efb\u52a1\u6807\u7b7e\u548c\u8f93\u51fa\u8bc4\u4f30\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u6a21\u578b\u6f02\u79fb\u3002", "method": "\u63d0\u51faZero - Direction Probing (ZDP)\u6846\u67b6\uff0c\u5728\u5047\u8bbeA1 - A6\u4e0b\u8bc1\u660e\u591a\u4e2a\u5b9a\u7406\uff0c\u63a8\u5bfcSpectral Null - Leakage (SNL)\u6307\u6807\u3002", "result": "\u8bc1\u660e\u4e86Variance -- Leak\u5b9a\u7406\u3001Fisher Null - Conservation\u3001\u4f4e\u79e9\u66f4\u65b0\u7684Rank -- Leak\u754c\u548c\u5728\u7ebf\u96f6\u7a7a\u95f4\u8ddf\u8e2a\u5668\u7684\u5bf9\u6570\u9057\u61be\u4fdd\u8bc1\uff0c\u63a8\u5bfc\u6709\u975e\u6e10\u8fd1\u5c3e\u754c\u548c\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u7684SNL\u6307\u6807\u3002", "conclusion": "\u76d1\u6d4b\u5c42\u6fc0\u6d3b\u7684\u5de6\u53f3\u96f6\u7a7a\u95f4\u53ca\u5176Fisher\u51e0\u4f55\u80fd\u4e3a\u8868\u793a\u53d8\u5316\u63d0\u4f9b\u5177\u4f53\u53ef\u6d4b\u8bd5\u7684\u4fdd\u8bc1\u3002"}}
{"id": "2508.08064", "pdf": "https://arxiv.org/pdf/2508.08064", "abs": "https://arxiv.org/abs/2508.08064", "authors": ["Marco Bernardo", "Federico Calandra", "Andrea Esposito", "Francesco Fabris"], "title": "On the Operational Resilience of CBDC: Threats and Prospects of Formal Validation for Offline Payments", "categories": ["cs.DC"], "comment": null, "summary": "Information and communication technologies are by now employed in most\nactivities, including economics and finance. Despite the extraordinary power of\nmodern computers and the vast amount of memory, some results of theoretical\ncomputer science imply the impossibility of certifying software quality in\ngeneral. With the exception of safety-critical systems, this has primarily\nconcerned the information processed by confined systems, with limited\nsocio-economic consequences. In the emerging era of technologies for exchanging\ndigital money and tokenized assets over the Internet - such as central bank\ndigital currencies (CBDCs) - even a minor bug could trigger a financial\ncollapse. Although the aforementioned impossibility results cannot be overcome\nin an absolute sense, there exist formal methods that can provide assertions of\ncomputing systems correctness. We advocate their use to validate the\noperational resilience of software infrastructures enabling CBDCs, with special\nemphasis on offline payments as they constitute a very critical issue.", "AI": {"tldr": "\u56e0\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u9650\u5236\u8f6f\u4ef6\u8d28\u91cf\u96be\u8ba4\u8bc1\uff0cCBDC\u65f6\u4ee3\u5c0f\u9519\u8bef\u6216\u81f4\u91d1\u878d\u5d29\u6e83\uff0c\u63d0\u5021\u7528\u5f62\u5f0f\u5316\u65b9\u6cd5\u9a8c\u8bc1CBDC\u8f6f\u4ef6\u57fa\u7840\u8bbe\u65bd\u8fd0\u8425\u5f39\u6027\uff0c\u5c24\u5176\u5173\u6ce8\u79bb\u7ebf\u652f\u4ed8\u3002", "motivation": "\u5728CBDC\u65f6\u4ee3\uff0c\u5373\u4f7f\u5c0f\u8f6f\u4ef6\u9519\u8bef\u4e5f\u53ef\u80fd\u5f15\u53d1\u91d1\u878d\u5d29\u6e83\uff0c\u800c\u73b0\u6709\u7406\u8bba\u9650\u5236\u8f6f\u4ef6\u8d28\u91cf\u8ba4\u8bc1\u3002", "method": "\u4f7f\u7528\u5f62\u5f0f\u5316\u65b9\u6cd5\u5bf9\u652f\u6301CBDC\u7684\u8f6f\u4ef6\u57fa\u7840\u8bbe\u65bd\u7684\u8fd0\u884c\u5f39\u6027\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u679c\u3002", "conclusion": "\u5e94\u4f7f\u7528\u5f62\u5f0f\u5316\u65b9\u6cd5\u9a8c\u8bc1CBDC\u8f6f\u4ef6\u57fa\u7840\u8bbe\u65bd\u7684\u8fd0\u8425\u5f39\u6027\uff0c\u7279\u522b\u5173\u6ce8\u79bb\u7ebf\u652f\u4ed8\u3002"}}
{"id": "2508.06823", "pdf": "https://arxiv.org/pdf/2508.06823", "abs": "https://arxiv.org/abs/2508.06823", "authors": ["Xuan Zhao", "Jun Tao"], "title": "Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation", "categories": ["cs.AI"], "comment": "Accepted by IEEE VIS 2025", "summary": "Exploring volumetric data is crucial for interpreting scientific datasets.\nHowever, selecting optimal viewpoints for effective navigation can be\nchallenging, particularly for users without extensive domain expertise or\nfamiliarity with 3D navigation. In this paper, we propose a novel framework\nthat leverages natural language interaction to enhance volumetric data\nexploration. Our approach encodes volumetric blocks to capture and\ndifferentiate underlying structures. It further incorporates a CLIP Score\nmechanism, which provides semantic information to the blocks to guide\nnavigation. The navigation is empowered by a reinforcement learning framework\nthat leverage these semantic cues to efficiently search for and identify\ndesired viewpoints that align with the user's intent. The selected viewpoints\nare evaluated using CLIP Score to ensure that they best reflect the user\nqueries. By automating viewpoint selection, our method improves the efficiency\nof volumetric data navigation and enhances the interpretability of complex\nscientific phenomena.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u63d0\u5347\u4f53\u6570\u636e\u63a2\u7d22\u6548\u7387\u7684\u6846\u67b6\uff0c\u53ef\u81ea\u52a8\u9009\u89c6\u89d2\uff0c\u63d0\u9ad8\u5bfc\u822a\u6548\u7387\u548c\u73b0\u8c61\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u9009\u62e9\u6709\u6548\u5bfc\u822a\u7684\u6700\u4f73\u89c6\u89d2\u6709\u6311\u6218\uff0c\u5c24\u5176\u5bf9\u975e\u4e13\u4e1a\u548c\u4e0d\u719f\u60893D\u5bfc\u822a\u7684\u7528\u6237\u3002", "method": "\u5bf9\u4f53\u6570\u636e\u5757\u7f16\u7801\uff0c\u5f15\u5165CLIP Score\u673a\u5236\u63d0\u4f9b\u8bed\u4e49\u4fe1\u606f\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7ed3\u5408\u8bed\u4e49\u7ebf\u7d22\u641c\u7d22\u89c6\u89d2\uff0c\u5e76\u7528CLIP Score\u8bc4\u4f30\u89c6\u89d2\u3002", "result": "\u80fd\u81ea\u52a8\u9009\u62e9\u7b26\u5408\u7528\u6237\u610f\u56fe\u7684\u89c6\u89d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4f53\u6570\u636e\u5bfc\u822a\u6548\u7387\uff0c\u589e\u5f3a\u4e86\u590d\u6742\u79d1\u5b66\u73b0\u8c61\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.07138", "pdf": "https://arxiv.org/pdf/2508.07138", "abs": "https://arxiv.org/abs/2508.07138", "authors": ["Yashwant Krishna Pagoti", "Arunesh Sinha", "Shamik Sural"], "title": "Strategic Incentivization for Locally Differentially Private Federated Learning", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "In Federated Learning (FL), multiple clients jointly train a machine learning\nmodel by sharing gradient information, instead of raw data, with a server over\nmultiple rounds. To address the possibility of information leakage in spite of\nsharing only the gradients, Local Differential Privacy (LDP) is often used. In\nLDP, clients add a selective amount of noise to the gradients before sending\nthe same to the server. Although such noise addition protects the privacy of\nclients, it leads to a degradation in global model accuracy. In this paper, we\nmodel this privacy-accuracy trade-off as a game, where the sever incentivizes\nthe clients to add a lower degree of noise for achieving higher accuracy, while\nthe clients attempt to preserve their privacy at the cost of a potential loss\nin accuracy. A token based incentivization mechanism is introduced in which the\nquantum of tokens credited to a client in an FL round is a function of the\ndegree of perturbation of its gradients. The client can later access a newly\nupdated global model only after acquiring enough tokens, which are to be\ndeducted from its balance. We identify the players, their actions and payoff,\nand perform a strategic analysis of the game. Extensive experiments were\ncarried out to study the impact of different parameters.", "AI": {"tldr": "\u672c\u6587\u5c06\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1 - \u51c6\u786e\u6027\u6743\u8861\u5efa\u6a21\u4e3a\u535a\u5f08\uff0c\u5f15\u5165\u57fa\u4e8e\u4ee4\u724c\u7684\u6fc0\u52b1\u673a\u5236\uff0c\u5e76\u8fdb\u884c\u6218\u7565\u5206\u6790\u548c\u5b9e\u9a8c\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u4f7f\u7528\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u6dfb\u52a0\u566a\u58f0\u5bfc\u81f4\u5168\u5c40\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\u3002", "method": "\u5c06\u9690\u79c1 - \u51c6\u786e\u6027\u6743\u8861\u5efa\u6a21\u4e3a\u535a\u5f08\uff0c\u5f15\u5165\u57fa\u4e8e\u4ee4\u724c\u7684\u6fc0\u52b1\u673a\u5236\uff0c\u6839\u636e\u68af\u5ea6\u6270\u52a8\u7a0b\u5ea6\u7ed9\u5ba2\u6237\u7aef\u5206\u914d\u4ee4\u724c\uff0c\u5ba2\u6237\u7aef\u9700\u79ef\u7d2f\u8db3\u591f\u4ee4\u724c\u624d\u80fd\u8bbf\u95ee\u66f4\u65b0\u540e\u7684\u5168\u5c40\u6a21\u578b\uff0c\u540c\u65f6\u8fdb\u884c\u6218\u7565\u5206\u6790\u3002", "result": "\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u7814\u7a76\u4e0d\u540c\u53c2\u6570\u7684\u5f71\u54cd\u3002", "conclusion": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2508.07748", "pdf": "https://arxiv.org/pdf/2508.07748", "abs": "https://arxiv.org/abs/2508.07748", "authors": ["Anton Klenitskiy", "Artem Fatkulin", "Daria Denisova", "Anton Pembek", "Alexey Vasilev"], "title": "Encode Me If You Can: Learning Universal User Representations via Event Sequence Autoencoding", "categories": ["cs.IR"], "comment": null, "summary": "Building universal user representations that capture the essential aspects of\nuser behavior is a crucial task for modern machine learning systems. In\nreal-world applications, a user's historical interactions often serve as the\nfoundation for solving a wide range of predictive tasks, such as churn\nprediction, recommendations, or lifetime value estimation. Using a\ntask-independent user representation that is effective across all such tasks\ncan reduce the need for task-specific feature engineering and model retraining,\nleading to more scalable and efficient machine learning pipelines. The goal of\nthe RecSys Challenge 2025 by Synerise was to develop such Universal Behavioral\nProfiles from logs of past user behavior, which included various types of\nevents such as product purchases, page views, and search queries. We propose a\nmethod that transforms the entire user interaction history into a single\nchronological sequence and trains a GRU-based autoencoder to reconstruct this\nsequence from a fixed-size vector. If the model can accurately reconstruct the\nsequence, the latent vector is expected to capture the key behavioral patterns.\nIn addition to this core model, we explored several alternative methods for\ngenerating user embeddings and combined them by concatenating their output\nvectors into a unified representation. This ensemble strategy further improved\ngeneralization across diverse downstream tasks and helped our team,\nai_lab_recsys, achieve second place in the RecSys Challenge 2025.", "AI": {"tldr": "\u6587\u7ae0\u805a\u7126\u6784\u5efa\u901a\u7528\u7528\u6237\u8868\u793a\uff0c\u63d0\u51fa\u5c06\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u8f6c\u4e3a\u5e8f\u5217\uff0c\u7528GRU\u81ea\u7f16\u7801\u5668\u8bad\u7ec3\uff0c\u7ed3\u5408\u591a\u79cd\u65b9\u6cd5\u751f\u6210\u7edf\u4e00\u8868\u793a\uff0c\u52a9\u56e2\u961f\u83b7RecSys Challenge 2025\u4e9a\u519b\u3002", "motivation": "\u6784\u5efa\u80fd\u6355\u6349\u7528\u6237\u884c\u4e3a\u5173\u952e\u65b9\u9762\u7684\u901a\u7528\u7528\u6237\u8868\u793a\uff0c\u51cf\u5c11\u7279\u5b9a\u4efb\u52a1\u7279\u5f81\u5de5\u7a0b\u548c\u6a21\u578b\u518d\u8bad\u7ec3\u9700\u6c42\uff0c\u5b9e\u73b0\u66f4\u5177\u6269\u5c55\u6027\u548c\u6548\u7387\u7684\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u3002", "method": "\u5c06\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u8f6c\u4e3a\u65f6\u95f4\u5e8f\u5217\uff0c\u7528GRU\u81ea\u7f16\u7801\u5668\u4ece\u56fa\u5b9a\u5927\u5c0f\u5411\u91cf\u91cd\u6784\u5e8f\u5217\uff1b\u63a2\u7d22\u591a\u79cd\u751f\u6210\u7528\u6237\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u62fc\u63a5\u8f93\u51fa\u5411\u91cf\u5f62\u6210\u7edf\u4e00\u8868\u793a\u3002", "result": "\u56e2\u961f\uff08ai_lab_recsys\uff09\u5728RecSys Challenge 2025\u4e2d\u83b7\u5f97\u7b2c\u4e8c\u540d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u96c6\u6210\u7b56\u7565\u6709\u6548\uff0c\u80fd\u63d0\u5347\u5728\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.06857", "pdf": "https://arxiv.org/pdf/2508.06857", "abs": "https://arxiv.org/abs/2508.06857", "authors": ["Mengxue Jia", "Zhihua Allen-Zhao", "You Zhao", "Sanyang Liu"], "title": "A Joint Sparse Self-Representation Learning Method for Multiview Clustering", "categories": ["cs.CV", "cs.DS"], "comment": null, "summary": "Multiview clustering (MC) aims to group samples using consistent and\ncomplementary information across various views. The subspace clustering, as a\nfundamental technique of MC, has attracted significant attention. In this\npaper, we propose a novel joint sparse self-representation learning model for\nMC, where a featured difference is the extraction of view-specific local\ninformation by introducing cardinality (i.e., $\\ell_0$-norm) constraints\ninstead of Graph-Laplacian regularization. Specifically, under each view,\ncardinality constraints directly restrict the samples used in the\nself-representation stage to extract reliable local and global structure\ninformation, while the low-rank constraint aids in revealing a global coherent\nstructure in the consensus affinity matrix during merging. The attendant\nchallenge is that Augmented Lagrange Method (ALM)-based alternating\nminimization algorithms cannot guarantee convergence when applied directly to\nour nonconvex, nonsmooth model, thus resulting in poor generalization ability.\nTo address it, we develop an alternating quadratic penalty (AQP) method with\nglobal convergence, where two subproblems are iteratively solved by closed-form\nsolutions. Empirical results on six standard datasets demonstrate the\nsuperiority of our model and AQP method, compared to eight state-of-the-art\nalgorithms.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u591a\u89c6\u56fe\u805a\u7c7b\u7684\u8054\u5408\u7a00\u758f\u81ea\u8868\u793a\u5b66\u4e60\u6a21\u578b\u53ca\u4ea4\u66ff\u4e8c\u6b21\u60e9\u7f5a\uff08AQP\uff09\u65b9\u6cd5\uff0c\u5728\u516d\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u516b\u79cd\u5148\u8fdb\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u89c6\u56fe\u805a\u7c7b\u5b50\u7a7a\u95f4\u805a\u7c7b\u6280\u672f\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u63d0\u53d6\u5c40\u90e8\u548c\u5168\u5c40\u7ed3\u6784\u4fe1\u606f\uff0c\u4e14\u539f\u7b97\u6cd5\u5e94\u7528\u4e8e\u975e\u51f8\u975e\u5149\u6ed1\u6a21\u578b\u65f6\u4e0d\u80fd\u4fdd\u8bc1\u6536\u655b\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u63d0\u51fa\u8054\u5408\u7a00\u758f\u81ea\u8868\u793a\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u57fa\u6570\u7ea6\u675f\u63d0\u53d6\u7279\u5b9a\u89c6\u56fe\u5c40\u90e8\u4fe1\u606f\uff0c\u4f4e\u79e9\u7ea6\u675f\u63ed\u793a\u5168\u5c40\u7ed3\u6784\uff1b\u5f00\u53d1\u6709\u5168\u5c40\u6536\u655b\u6027\u7684\u4ea4\u66ff\u4e8c\u6b21\u60e9\u7f5a\uff08AQP\uff09\u65b9\u6cd5\u8fed\u4ee3\u6c42\u89e3\u5b50\u95ee\u9898\u3002", "result": "\u5728\u516d\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u6a21\u578b\u548c AQP \u65b9\u6cd5\u4f18\u4e8e\u516b\u79cd\u5148\u8fdb\u7b97\u6cd5\u3002", "conclusion": "\u6240\u63d0\u6a21\u578b\u548c AQP \u65b9\u6cd5\u5728\u591a\u89c6\u56fe\u805a\u7c7b\u4e2d\u6709\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.07935", "pdf": "https://arxiv.org/pdf/2508.07935", "abs": "https://arxiv.org/abs/2508.07935", "authors": ["Jingwen Zhou", "Jieshan Chen", "Qinghua Lu", "Dehai Zhao", "Liming Zhu"], "title": "SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Model (LLM) agentic systems are software systems powered by\nLLMs that autonomously reason, plan, and execute multi-step workflows to\nachieve human goals, rather than merely executing predefined steps. During\nexecution, these workflows frequently encounter exceptions. Existing exception\nhandling solutions often treat exceptions superficially, failing to trace\nexecution-phase exceptions to their reasoning-phase root causes. Furthermore,\ntheir recovery logic is brittle, lacking structured escalation pathways when\ninitial attempts fail. To tackle these challenges, we first present a\ncomprehensive taxonomy of 36 exception types across 12 agent artifacts.\nBuilding on this, we propose SHIELDA (Structured Handling of Exceptions in\nLLM-Driven Agentic Workflows), a modular runtime exception handling framework\nfor LLM agentic workflows. SHIELDA uses an exception classifier to select a\npredefined exception handling pattern from a handling pattern registry. These\npatterns are then executed via a structured handling executor, comprising local\nhandling, flow control, and state recovery, to enable phase-aware recovery by\nlinking exceptions to their root causes and facilitating composable strategies.\nWe validate SHIELDA's effectiveness through a case study on the AutoPR agent,\ndemonstrating effective, cross-phase recovery from a reasoning-induced\nexception.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4ee3\u7406\u7cfb\u7edf\u5de5\u4f5c\u6d41\u5904\u7406\u5f02\u5e38\u65f6\u5b58\u5728\u95ee\u9898\uff0c\u63d0\u51faSHIELDA\u6846\u67b6\u89e3\u51b3\uff0c\u5e76\u7528AutoPR\u4ee3\u7406\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7cfb\u7edf\u5f02\u5e38\u5904\u7406\u65b9\u6848\u5904\u7406\u8868\u9762\uff0c\u672a\u8ffd\u6eaf\u6839\u6e90\u4e14\u6062\u590d\u903b\u8f91\u8106\u5f31\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa36\u79cd\u5f02\u5e38\u7c7b\u578b\u7684\u5206\u7c7b\u6cd5\uff0c\u6784\u5efaSHIELDA\u6a21\u5757\u5316\u8fd0\u884c\u65f6\u5f02\u5e38\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5f02\u5e38\u5206\u7c7b\u5668\u9009\u5904\u7406\u6a21\u5f0f\uff0c\u7531\u7ed3\u6784\u5316\u6267\u884c\u5668\u6267\u884c\u3002", "result": "\u901a\u8fc7AutoPR\u4ee3\u7406\u6848\u4f8b\u9a8c\u8bc1SHIELDA\u80fd\u6709\u6548\u4ece\u63a8\u7406\u5f15\u53d1\u7684\u5f02\u5e38\u4e2d\u8de8\u9636\u6bb5\u6062\u590d\u3002", "conclusion": "SHIELDA\u6846\u67b6\u53ef\u6709\u6548\u5904\u7406\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7cfb\u7edf\u5de5\u4f5c\u6d41\u5f02\u5e38\uff0c\u5b9e\u73b0\u8de8\u9636\u6bb5\u6062\u590d\u3002"}}
{"id": "2508.07179", "pdf": "https://arxiv.org/pdf/2508.07179", "abs": "https://arxiv.org/abs/2508.07179", "authors": ["Jiaqi Yin", "Yi-Wei Chen", "Meng-Lung Lee", "Xiya Liu"], "title": "Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": null, "summary": "Enterprise data pipelines, characterized by complex transformations across\nmultiple programming languages, often cause a semantic disconnect between\noriginal metadata and downstream data. This \"semantic drift\" compromises data\nreproducibility and governance, and impairs the utility of services like\nretrieval-augmented generation (RAG) and text-to-SQL systems. To address this,\na novel framework is proposed for the automated extraction of fine-grained\nschema lineage from multilingual enterprise pipeline scripts. This method\nidentifies four key components: source schemas, source tables, transformation\nlogic, and aggregation operations, creating a standardized representation of\ndata transformations. For the rigorous evaluation of lineage quality, this\npaper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that\nassesses both structural correctness and semantic fidelity. A new benchmark is\nalso presented, comprising 1,700 manually annotated lineages from real-world\nindustrial scripts. Experiments were conducted with 12 language models, from\n1.3B to 32B small language models (SLMs) to large language models (LLMs) like\nGPT-4o and GPT-4.1. The results demonstrate that the performance of schema\nlineage extraction scales with model size and the sophistication of prompting\ntechniques. Specially, a 32B open-source model, using a single reasoning trace,\ncan achieve performance comparable to the GPT series under standard prompting.\nThis finding suggests a scalable and economical approach for deploying\nschema-aware agents in practical applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u81ea\u52a8\u5316\u63d0\u53d6\u4f01\u4e1a\u591a\u8bed\u8a00\u6570\u636e\u7ba1\u9053\u811a\u672c\u7ec6\u7c92\u5ea6\u6a21\u5f0f\u6cbf\u88ad\u7684\u6846\u67b6\uff0c\u5f15\u5165\u8bc4\u4f30\u6307\u6807SLiCE\u548c\u65b0\u57fa\u51c6\uff0c\u5b9e\u9a8c\u8868\u660e\u6a21\u5f0f\u6cbf\u88ad\u63d0\u53d6\u6027\u80fd\u4e0e\u6a21\u578b\u5927\u5c0f\u548c\u63d0\u793a\u6280\u672f\u6709\u5173\uff0c32B\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4f01\u4e1a\u6570\u636e\u7ba1\u9053\u5b58\u5728\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\uff0c\u5f71\u54cd\u6570\u636e\u53ef\u91cd\u590d\u6027\u3001\u6cbb\u7406\u53ca\u76f8\u5173\u670d\u52a1\u6548\u7528\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u81ea\u52a8\u5316\u63d0\u53d6\u7ec6\u7c92\u5ea6\u6a21\u5f0f\u6cbf\u88ad\u7684\u6846\u67b6\uff0c\u8bc6\u522b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1b\u5f15\u5165\u8bc4\u4f30\u6307\u6807SLiCE\uff1b\u7ed9\u51fa\u65b0\u57fa\u51c6\uff1b\u752812\u79cd\u8bed\u8a00\u6a21\u578b\u505a\u5b9e\u9a8c\u3002", "result": "\u6a21\u5f0f\u6cbf\u88ad\u63d0\u53d6\u6027\u80fd\u968f\u6a21\u578b\u5927\u5c0f\u548c\u63d0\u793a\u6280\u672f\u590d\u6742\u5ea6\u63d0\u5347\uff1b32B\u5f00\u6e90\u6a21\u578b\u5728\u6807\u51c6\u63d0\u793a\u4e0b\u6027\u80fd\u53ef\u4e0eGPT\u7cfb\u5217\u5ab2\u7f8e\u3002", "conclusion": "\u5b58\u5728\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u7684\u65b9\u6cd5\u7528\u4e8e\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u90e8\u7f72\u6a21\u5f0f\u611f\u77e5\u4ee3\u7406\u3002"}}
{"id": "2508.06524", "pdf": "https://arxiv.org/pdf/2508.06524", "abs": "https://arxiv.org/abs/2508.06524", "authors": ["Lei Jiang", "Fan Chen"], "title": "CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.DC", "cs.LG"], "comment": "8 pages", "summary": "Neural scaling laws have driven the development of increasingly large\nlanguage models (LLMs) by linking accuracy improvements to growth in parameter\ncount, dataset size, and compute. However, these laws overlook the carbon\nemissions that scale exponentially with LLM size. This paper presents\n\\textit{CarbonScaling}, an analytical framework that extends neural scaling\nlaws to incorporate both operational and embodied carbon in LLM training. By\nintegrating models for neural scaling, GPU hardware evolution, parallelism\noptimization, and carbon estimation, \\textit{CarbonScaling} quantitatively\nconnects model accuracy to carbon footprint. Results show that while a\npower-law relationship between accuracy and carbon holds, real-world\ninefficiencies significantly increase the scaling factor. Hardware technology\nscaling reduces carbon emissions for small to mid-sized models, but offers\ndiminishing returns for extremely large LLMs due to communication overhead and\nunderutilized GPUs. Training optimizations-especially aggressive critical batch\nsize scaling-help alleviate this inefficiency. \\textit{CarbonScaling} offers\nkey insights for training more sustainable and carbon-efficient LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCarbonScaling\u6846\u67b6\u5c06\u78b3\u6392\u653e\u7eb3\u5165\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\uff0c\u5206\u6790\u6a21\u578b\u51c6\u786e\u7387\u4e0e\u78b3\u8db3\u8ff9\u5173\u7cfb\uff0c\u4e3a\u8bad\u7ec3\u53ef\u6301\u7eed\u548c\u78b3\u9ad8\u6548\u5927\u6a21\u578b\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u5ffd\u7565\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u968f\u6a21\u578b\u89c4\u6a21\u6307\u6570\u589e\u957f\u7684\u78b3\u6392\u653e\uff0c\u9700\u5c06\u78b3\u6392\u653e\u7eb3\u5165\u8003\u8651\u3002", "method": "\u63d0\u51faCarbonScaling\u5206\u6790\u6846\u67b6\uff0c\u6574\u5408\u795e\u7ecf\u7f29\u653e\u3001GPU\u786c\u4ef6\u6f14\u53d8\u3001\u5e76\u884c\u4f18\u5316\u548c\u78b3\u4f30\u7b97\u6a21\u578b\u3002", "result": "\u51c6\u786e\u7387\u548c\u78b3\u6392\u653e\u5b58\u5728\u5e42\u5f8b\u5173\u7cfb\uff0c\u73b0\u5b9e\u4f4e\u6548\u6027\u589e\u52a0\u7f29\u653e\u56e0\u5b50\uff1b\u786c\u4ef6\u6280\u672f\u7f29\u653e\u5bf9\u4e2d\u5c0f\u6a21\u578b\u51cf\u5c11\u78b3\u6392\u653e\uff0c\u5bf9\u8d85\u5927\u6a21\u578b\u6548\u679c\u9012\u51cf\uff1b\u8bad\u7ec3\u4f18\u5316\u53ef\u7f13\u89e3\u4f4e\u6548\u6027\u3002", "conclusion": "CarbonScaling\u4e3a\u8bad\u7ec3\u66f4\u53ef\u6301\u7eed\u548c\u78b3\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2508.06832", "pdf": "https://arxiv.org/pdf/2508.06832", "abs": "https://arxiv.org/abs/2508.06832", "authors": ["Haifeng Li", "Wang Guo", "Haiyang Wu", "Mengwei Wu", "Jipeng Zhang", "Qing Zhu", "Yu Liu", "Xin Huang", "Chao Tao"], "title": "Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges", "categories": ["cs.AI"], "comment": null, "summary": "The mainstream paradigm of remote sensing image interpretation has long been\ndominated by vision-centered models, which rely on visual features for semantic\nunderstanding. However, these models face inherent limitations in handling\nmulti-modal reasoning, semantic abstraction, and interactive decision-making.\nWhile recent advances have introduced Large Language Models (LLMs) into remote\nsensing workflows, existing studies primarily focus on downstream applications,\nlacking a unified theoretical framework that explains the cognitive role of\nlanguage. This review advocates a paradigm shift from vision-centered to\nlanguage-centered remote sensing interpretation. Drawing inspiration from the\nGlobal Workspace Theory (GWT) of human cognition, We propose a\nlanguage-centered framework for remote sensing interpretation that treats LLMs\nas the cognitive central hub integrating perceptual, task, knowledge and action\nspaces to enable unified understanding, reasoning, and decision-making. We\nfirst explore the potential of LLMs as the central cognitive component in\nremote sensing interpretation, and then summarize core technical challenges,\nincluding unified multimodal representation, knowledge association, and\nreasoning and decision-making. Furthermore, we construct a global\nworkspace-driven interpretation mechanism and review how language-centered\nsolutions address each challenge. Finally, we outline future research\ndirections from four perspectives: adaptive alignment of multimodal data, task\nunderstanding under dynamic knowledge constraints, trustworthy reasoning, and\nautonomous interaction. This work aims to provide a conceptual foundation for\nthe next generation of remote sensing interpretation systems and establish a\nroadmap toward cognition-driven intelligent geospatial analysis.", "AI": {"tldr": "\u6587\u7ae0\u5021\u5bfc\u4ece\u4ee5\u89c6\u89c9\u4e3a\u4e2d\u5fc3\u8f6c\u5411\u4ee5\u8bed\u8a00\u4e3a\u4e2d\u5fc3\u7684\u9065\u611f\u5f71\u50cf\u89e3\u8bd1\u8303\u5f0f\uff0c\u63d0\u51fa\u57fa\u4e8e\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\u7684\u8bed\u8a00\u4e2d\u5fc3\u6846\u67b6\uff0c\u603b\u7ed3\u6311\u6218\u3001\u6784\u5efa\u673a\u5236\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u4ee5\u89c6\u89c9\u4e3a\u4e2d\u5fc3\u7684\u9065\u611f\u5f71\u50cf\u89e3\u8bd1\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u7b49\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u73b0\u6709\u5f15\u5165\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u8bed\u8a00\u7684\u8ba4\u77e5\u4f5c\u7528\u3002", "method": "\u501f\u9274\u4eba\u7c7b\u8ba4\u77e5\u7684\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff0c\u63d0\u51fa\u4ee5\u8bed\u8a00\u4e3a\u4e2d\u5fc3\u7684\u9065\u611f\u5f71\u50cf\u89e3\u8bd1\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8ba4\u77e5\u4e2d\u5fc3\u67a2\u7ebd\uff0c\u6574\u5408\u591a\u4e2a\u7a7a\u95f4\u3002", "result": "\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9065\u611f\u89e3\u8bd1\u4e2d\u7684\u6f5c\u529b\uff0c\u603b\u7ed3\u6838\u5fc3\u6280\u672f\u6311\u6218\uff0c\u6784\u5efa\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u9a71\u52a8\u7684\u89e3\u8bd1\u673a\u5236\u3002", "conclusion": "\u4e3a\u4e0b\u4e00\u4ee3\u9065\u611f\u5f71\u50cf\u89e3\u8bd1\u7cfb\u7edf\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\uff0c\u4e3a\u8ba4\u77e5\u9a71\u52a8\u7684\u667a\u80fd\u5730\u7406\u7a7a\u95f4\u5206\u6790\u5236\u5b9a\u8def\u7ebf\u56fe\u3002"}}
{"id": "2508.07676", "pdf": "https://arxiv.org/pdf/2508.07676", "abs": "https://arxiv.org/abs/2508.07676", "authors": ["Chenchen Lin", "Xuehe Wang"], "title": "Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks", "categories": ["cs.LG", "cs.DC", "cs.GT"], "comment": "Accepted by ECAI25", "summary": "Federated learning (FL) enables collaborative model training across\ndecentralized clients without sharing local data, thereby enhancing privacy and\nfacilitating collaboration among clients connected via social networks.\nHowever, these social connections introduce privacy externalities: a client's\nprivacy loss depends not only on its privacy protection strategy but also on\nthe privacy decisions of others, propagated through the network via multi-hop\ninteractions. In this work, we propose a socially-aware privacy-preserving FL\nmechanism that systematically quantifies indirect privacy leakage through a\nmulti-hop propagation model. We formulate the server-client interaction as a\ntwo-stage Stackelberg game, where the server, as the leader, optimizes\nincentive policies, and clients, as followers, strategically select their\nprivacy budgets, which determine their privacy-preserving levels by controlling\nthe magnitude of added noise. To mitigate information asymmetry in networked\nprivacy estimation, we introduce a mean-field estimator to approximate the\naverage external privacy risk. We theoretically prove the existence and\nconvergence of the fixed point of the mean-field estimator and derive\nclosed-form expressions for the Stackelberg Nash Equilibrium. Despite being\ndesigned from a client-centric incentive perspective, our mechanism achieves\napproximately-optimal social welfare, as revealed by Price of Anarchy (PoA)\nanalysis. Experiments on diverse datasets demonstrate that our approach\nsignificantly improves client utilities and reduces server costs while\nmaintaining model performance, outperforming both Social-Agnostic (SA)\nbaselines and methods that account for social externalities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u793e\u4f1a\u611f\u77e5\u7684\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u673a\u5236\uff0c\u91cf\u5316\u95f4\u63a5\u9690\u79c1\u6cc4\u6f0f\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u4f18\u5316\u6fc0\u52b1\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u5ba2\u6237\u6548\u7528\u3001\u964d\u4f4e\u670d\u52a1\u5668\u6210\u672c\u548c\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u4e2d\u793e\u4f1a\u8fde\u63a5\u5f15\u5165\u9690\u79c1\u5916\u90e8\u6027\u95ee\u9898\uff0c\u5ba2\u6237\u9690\u79c1\u635f\u5931\u53d7\u4ed6\u4eba\u9690\u79c1\u51b3\u7b56\u5f71\u54cd\uff0c\u9700\u8981\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u591a\u8df3\u4f20\u64ad\u6a21\u578b\u91cf\u5316\u95f4\u63a5\u9690\u79c1\u6cc4\u6f0f\uff0c\u5c06\u670d\u52a1\u5668 - \u5ba2\u6237\u7aef\u4ea4\u4e92\u6784\u5efa\u4e3a\u4e24\u9636\u6bb5Stackelberg\u535a\u5f08\uff0c\u5f15\u5165\u5e73\u5747\u573a\u4f30\u8ba1\u5668\u7f13\u89e3\u4fe1\u606f\u4e0d\u5bf9\u79f0\uff0c\u7406\u8bba\u8bc1\u660e\u5e73\u5747\u573a\u4f30\u8ba1\u5668\u4e0d\u52a8\u70b9\u5b58\u5728\u4e0e\u6536\u655b\u6027\uff0c\u63a8\u5bfcStackelberg\u7eb3\u4ec0\u5747\u8861\u7684\u95ed\u5f0f\u89e3\u3002", "result": "\u901a\u8fc7\u65e0\u653f\u5e9c\u4ef7\u683c\u5206\u6790\u8868\u660e\u8be5\u673a\u5236\u80fd\u5b9e\u73b0\u8fd1\u4f3c\u6700\u4f18\u793e\u4f1a\u798f\u5229\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\u53ef\u663e\u8457\u63d0\u5347\u5ba2\u6237\u6548\u7528\u3001\u964d\u4f4e\u670d\u52a1\u5668\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4f18\u4e8e\u76f8\u5173\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u793e\u4f1a\u611f\u77e5\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u673a\u5236\u6709\u6548\uff0c\u80fd\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u89e3\u51b3\u9690\u79c1\u5916\u90e8\u6027\u95ee\u9898\uff0c\u5e73\u8861\u5404\u65b9\u5229\u76ca\u3002"}}
{"id": "2508.07856", "pdf": "https://arxiv.org/pdf/2508.07856", "abs": "https://arxiv.org/abs/2508.07856", "authors": ["Danil Gusak", "Nikita Sukhorukov", "Evgeny Frolov"], "title": "Recommendation Is a Dish Better Served Warm", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted for ACM RecSys 2025. Author's version. The final published\n  version will be available at the ACM Digital Library", "summary": "In modern recommender systems, experimental settings typically include\nfiltering out cold users and items based on a minimum interaction threshold.\nHowever, these thresholds are often chosen arbitrarily and vary widely across\nstudies, leading to inconsistencies that can significantly affect the\ncomparability and reliability of evaluation results. In this paper, we\nsystematically explore the cold-start boundary by examining the criteria used\nto determine whether a user or an item should be considered cold. Our\nexperiments incrementally vary the number of interactions for different items\nduring training, and gradually update the length of user interaction histories\nduring inference. We investigate the thresholds across several widely used\ndatasets, commonly represented in recent papers from top-tier conferences, and\non multiple established recommender baselines. Our findings show that\ninconsistent selection of cold-start thresholds can either result in the\nunnecessary removal of valuable data or lead to the misclassification of cold\ninstances as warm, introducing more noise into the system.", "AI": {"tldr": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u4e2d\u51b7\u542f\u52a8\u9608\u503c\u9009\u62e9\u968f\u610f\u5f71\u54cd\u8bc4\u4f30\u7ed3\u679c\uff0c\u672c\u6587\u7cfb\u7edf\u63a2\u7d22\u51b7\u542f\u52a8\u8fb9\u754c\uff0c\u53d1\u73b0\u9608\u503c\u9009\u62e9\u4e0d\u4e00\u81f4\u4f1a\u5e26\u6765\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u4e2d\u51b7\u542f\u52a8\u9608\u503c\u9009\u62e9\u968f\u610f\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u53ef\u6bd4\u6027\u548c\u53ef\u9760\u6027\u53d7\u5f71\u54cd\uff0c\u9700\u8981\u7cfb\u7edf\u63a2\u7d22\u51b7\u542f\u52a8\u8fb9\u754c\u3002", "method": "\u5728\u8bad\u7ec3\u65f6\u5bf9\u4e0d\u540c\u7269\u54c1\u7684\u4ea4\u4e92\u6570\u91cf\u8fdb\u884c\u589e\u91cf\u53d8\u5316\uff0c\u63a8\u7406\u65f6\u9010\u6b65\u66f4\u65b0\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u957f\u5ea6\uff0c\u5728\u591a\u4e2a\u5e38\u7528\u6570\u636e\u96c6\u548c\u63a8\u8350\u57fa\u7ebf\u6a21\u578b\u4e0a\u7814\u7a76\u9608\u503c\u3002", "result": "\u4e0d\u4e00\u81f4\u7684\u51b7\u542f\u52a8\u9608\u503c\u9009\u62e9\u4f1a\u5bfc\u81f4\u6709\u4ef7\u503c\u6570\u636e\u88ab\u4e0d\u5fc5\u8981\u79fb\u9664\u6216\u51b7\u5b9e\u4f8b\u88ab\u8bef\u5206\u7c7b\u4e3a\u70ed\u5b9e\u4f8b\uff0c\u7ed9\u7cfb\u7edf\u5f15\u5165\u66f4\u591a\u566a\u58f0\u3002", "conclusion": "\u51b7\u542f\u52a8\u9608\u503c\u7684\u4e0d\u4e00\u81f4\u9009\u62e9\u4f1a\u5bf9\u63a8\u8350\u7cfb\u7edf\u4ea7\u751f\u4e0d\u826f\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u5408\u7406\u5730\u786e\u5b9a\u9608\u503c\u3002"}}
{"id": "2508.07015", "pdf": "https://arxiv.org/pdf/2508.07015", "abs": "https://arxiv.org/abs/2508.07015", "authors": ["Hannes Ihalainen", "Dieter Vandesande", "Andr\u00e9 Schidler", "Jeremias Berg", "Bart Bogaerts", "Matti J\u00e4rvisalo"], "title": "Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach", "categories": ["cs.AI", "cs.DS"], "comment": null, "summary": "The implicit hitting set (IHS) approach offers a general framework for\nsolving computationally hard combinatorial optimization problems declaratively.\nIHS iterates between a decision oracle used for extracting sources of\ninconsistency and an optimizer for computing so-called hitting sets (HSs) over\nthe accumulated sources of inconsistency. While the decision oracle is\nlanguage-specific, the optimizers is usually instantiated through integer\nprogramming.\n  We explore alternative algorithmic techniques for hitting set optimization\nbased on different ways of employing pseudo-Boolean (PB) reasoning as well as\nstochastic local search. We extensively evaluate the practical feasibility of\nthe alternatives in particular in the context of pseudo-Boolean (0-1 IP)\noptimization as one of the most recent instantiations of IHS. Highlighting a\ntrade-off between efficiency and reliability, while a commercial IP solver\nturns out to remain the most effective way to instantiate HS computations, it\ncan cause correctness issues due to numerical instability; in fact, we show\nthat exact HS computations instantiated via PB reasoning can be made\ncompetitive with a numerically exact IP solver. Furthermore, the use of PB\nreasoning as a basis for HS computations allows for obtaining certificates for\nthe correctness of IHS computations, generally applicable to any IHS\ninstantiation in which reasoning in the declarative language at hand can be\ncaptured in the PB-based proof format we employ.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u4f2a\u5e03\u5c14\u63a8\u7406\u548c\u968f\u673a\u5c40\u90e8\u641c\u7d22\u7684\u9690\u5f0f\u547d\u4e2d\u96c6\u4f18\u5316\u66ff\u4ee3\u7b97\u6cd5\uff0c\u8bc4\u4f30\u5176\u5b9e\u7528\u6027\uff0c\u6307\u51fa\u5546\u4e1aIP\u6c42\u89e3\u5668\u867d\u6709\u6548\u4f46\u6709\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4f2a\u5e03\u5c14\u63a8\u7406\u53ef\u4f7f\u7cbe\u786e\u547d\u4e2d\u96c6\u8ba1\u7b97\u5177\u6709\u7ade\u4e89\u529b\u5e76\u80fd\u63d0\u4f9b\u6b63\u786e\u6027\u8bc1\u660e\u3002", "motivation": "\u63a2\u7d22\u57fa\u4e8e\u4e0d\u540c\u4f2a\u5e03\u5c14\u63a8\u7406\u548c\u968f\u673a\u5c40\u90e8\u641c\u7d22\u65b9\u5f0f\u7684\u547d\u4e2d\u96c6\u4f18\u5316\u66ff\u4ee3\u7b97\u6cd5\uff0c\u8bc4\u4f30\u5176\u5728\u4f2a\u5e03\u5c14\u4f18\u5316\u4e2d\u4f5c\u4e3a\u9690\u5f0f\u547d\u4e2d\u96c6\u6700\u65b0\u5b9e\u4f8b\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u4e0d\u540c\u7684\u4f2a\u5e03\u5c14\u63a8\u7406\u548c\u968f\u673a\u5c40\u90e8\u641c\u7d22\u65b9\u5f0f\u8fdb\u884c\u547d\u4e2d\u96c6\u4f18\u5316\uff0c\u5e76\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\u3002", "result": "\u5546\u4e1aIP\u6c42\u89e3\u5668\u4ecd\u662f\u6700\u6709\u6548\u7684\u547d\u4e2d\u96c6\u8ba1\u7b97\u65b9\u5f0f\uff0c\u4f46\u5b58\u5728\u6570\u503c\u4e0d\u7a33\u5b9a\u5bfc\u81f4\u7684\u6b63\u786e\u6027\u95ee\u9898\uff0c\u57fa\u4e8e\u4f2a\u5e03\u5c14\u63a8\u7406\u7684\u7cbe\u786e\u547d\u4e2d\u96c6\u8ba1\u7b97\u53ef\u4e0e\u6570\u503c\u7cbe\u786e\u7684IP\u6c42\u89e3\u5668\u7ade\u4e89\uff0c\u4e14\u80fd\u4e3a\u9690\u5f0f\u547d\u4e2d\u96c6\u8ba1\u7b97\u63d0\u4f9b\u6b63\u786e\u6027\u8bc1\u660e\u3002", "conclusion": "\u4f2a\u5e03\u5c14\u63a8\u7406\u53ef\u4f7f\u9690\u5f0f\u547d\u4e2d\u96c6\u8ba1\u7b97\u66f4\u5177\u7ade\u4e89\u529b\u5e76\u63d0\u4f9b\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u9002\u7528\u4e8e\u80fd\u4ee5\u57fa\u4e8e\u4f2a\u5e03\u5c14\u7684\u8bc1\u660e\u683c\u5f0f\u6355\u83b7\u58f0\u660e\u6027\u8bed\u8a00\u63a8\u7406\u7684\u4efb\u4f55\u9690\u5f0f\u547d\u4e2d\u96c6\u5b9e\u4f8b\u3002"}}
{"id": "2508.07966", "pdf": "https://arxiv.org/pdf/2508.07966", "abs": "https://arxiv.org/abs/2508.07966", "authors": ["Philipp Eibl", "Sadra Sabouri", "Souti Chattopadhyay"], "title": "Exploring the Challenges and Opportunities of AI-assisted Codebase Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Recent AI code assistants have significantly improved their ability to\nprocess more complex contexts and generate entire codebases based on a textual\ndescription, compared to the popular snippet-level generation. These codebase\nAI assistants (CBAs) can also extend or adapt codebases, allowing users to\nfocus on higher-level design and deployment decisions. While prior work has\nextensively studied the impact of snippet-level code generation, this new class\nof codebase generation models is relatively unexplored. Despite initial\nanecdotal reports of excitement about these agents, they remain less frequently\nadopted compared to snippet-level code assistants. To utilize CBAs better, we\nneed to understand how developers interact with CBAs, and how and why CBAs fall\nshort of developers' needs. In this paper, we explored these gaps through a\ncounterbalanced user study and interview with (n = 16) students and developers\nworking on coding tasks with CBAs. We found that participants varied the\ninformation in their prompts, like problem description (48% of prompts),\nrequired functionality (98% of prompts), code structure (48% of prompts), and\ntheir prompt writing process. Despite various strategies, the overall\nsatisfaction score with generated codebases remained low (mean = 2.8, median =\n3, on a scale of one to five). Participants mentioned functionality as the most\ncommon factor for dissatisfaction (77% of instances), alongside poor code\nquality (42% of instances) and communication issues (25% of instances). We\ndelve deeper into participants' dissatisfaction to identify six underlying\nchallenges that participants faced when using CBAs, and extracted five barriers\nto incorporating CBAs into their workflows. Finally, we surveyed 21 commercial\nCBAs to compare their capabilities with participant challenges and present\ndesign opportunities for more efficient and useful CBAs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7528\u6237\u7814\u7a76\u548c\u8bbf\u8c08\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u4f7f\u7528\u4ee3\u7801\u5e93AI\u52a9\u624b\uff08CBAs\uff09\u751f\u6210\u4ee3\u7801\u5e93\u7684\u6ee1\u610f\u5ea6\u4f4e\uff0c\u5206\u6790\u4e86\u539f\u56e0\u5e76\u8c03\u67e5\u5546\u4e1aCBAs\u63d0\u51fa\u8bbe\u8ba1\u673a\u4f1a\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u4ee3\u7801\u7247\u6bb5\u751f\u6210\uff0c\u65b0\u7684\u4ee3\u7801\u5e93\u751f\u6210\u6a21\u578b\u7814\u7a76\u5c11\u4e14\u91c7\u7528\u7387\u4f4e\uff0c\u4e3a\u66f4\u597d\u5229\u7528CBAs\uff0c\u9700\u4e86\u89e3\u5f00\u53d1\u8005\u4ea4\u4e92\u60c5\u51b5\u548c\u5176\u4e0d\u8db3\u3002", "method": "\u8fdb\u884c\u5e73\u8861\u7684\u7528\u6237\u7814\u7a76\u548c\u5bf916\u540d\u5b66\u751f\u4e0e\u5f00\u53d1\u8005\u7684\u8bbf\u8c08\uff0c\u8c03\u67e521\u4e2a\u5546\u4e1aCBAs\u3002", "result": "\u53c2\u4e0e\u8005\u63d0\u793a\u4fe1\u606f\u591a\u6837\uff0c\u4f46\u5bf9\u751f\u6210\u4ee3\u7801\u5e93\u6ee1\u610f\u5ea6\u4f4e\uff0c\u529f\u80fd\u3001\u4ee3\u7801\u8d28\u91cf\u548c\u6c9f\u901a\u95ee\u9898\u662f\u4e0d\u6ee1\u4e3b\u56e0\uff0c\u8fd8\u53d1\u73b0\u4f7f\u7528CBAs\u76846\u4e2a\u6311\u6218\u548c5\u4e2a\u969c\u788d\u3002", "conclusion": "\u6839\u636e\u53c2\u4e0e\u8005\u6311\u6218\u4e0e\u5546\u4e1aCBAs\u80fd\u529b\u5bf9\u6bd4\uff0c\u63d0\u51fa\u66f4\u9ad8\u6548\u6709\u7528\u7684CBAs\u8bbe\u8ba1\u673a\u4f1a\u3002"}}
{"id": "2508.06638", "pdf": "https://arxiv.org/pdf/2508.06638", "abs": "https://arxiv.org/abs/2508.06638", "authors": ["Muyan Anna Li", "Aditi Gautam"], "title": "Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series", "categories": ["cs.LG", "cs.AI", "14J60 (Primary) 14F05, 14J26 (Secondary)", "F.2.2; I.2.0"], "comment": "20 pages, 11 figures", "summary": "As time series data become increasingly prevalent in domains such as\nmanufacturing, IT, and infrastructure monitoring, anomaly detection must adapt\nto nonstationary environments where statistical properties shift over time.\nTraditional static thresholds are easily rendered obsolete by regime shifts,\nconcept drift, or multi-scale changes. To address these challenges, we\nintroduce and empirically evaluate two novel adaptive thresholding frameworks:\nSegmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence\nSegments (MACS). Both leverage statistical online learning and segmentation\nprinciples for local, contextually sensitive adaptation, maintaining guarantees\non false alarm rates even under evolving distributions. Our experiments across\nWafer Manufacturing benchmark datasets show significant F1-score improvement\ncompared to traditional percentile and rolling quantile approaches. This work\ndemonstrates that robust, statistically principled adaptive thresholds enable\nreliable, interpretable, and timely detection of diverse real-world anomalies.", "AI": {"tldr": "\u63d0\u51faSCS\u548cMACS\u4e24\u79cd\u81ea\u9002\u5e94\u9608\u503c\u6846\u67b6\u7528\u4e8e\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793aF1\u5206\u6570\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u591a\u9886\u57df\u65e5\u76ca\u666e\u904d\uff0c\u4f20\u7edf\u9759\u6001\u9608\u503c\u65e0\u6cd5\u9002\u5e94\u975e\u5e73\u7a33\u73af\u5883\u7684\u7edf\u8ba1\u7279\u5f81\u53d8\u5316\u3002", "method": "\u5f15\u5165\u5e76\u5b9e\u8bc1\u8bc4\u4f30Segmented Confidence Sequences (SCS)\u548cMulti-Scale Adaptive Confidence Segments (MACS)\u4e24\u79cd\u81ea\u9002\u5e94\u9608\u503c\u6846\u67b6\uff0c\u5229\u7528\u7edf\u8ba1\u5728\u7ebf\u5b66\u4e60\u548c\u5206\u5272\u539f\u5219\u8fdb\u884c\u5c40\u90e8\u3001\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u81ea\u9002\u5e94\u8c03\u6574\u3002", "result": "\u5728Wafer Manufacturing\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u767e\u5206\u4f4d\u6570\u548c\u6eda\u52a8\u5206\u4f4d\u6570\u65b9\u6cd5\u76f8\u6bd4\uff0cF1\u5206\u6570\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u57fa\u4e8e\u7edf\u8ba1\u539f\u7406\u7684\u9c81\u68d2\u81ea\u9002\u5e94\u9608\u503c\u80fd\u591f\u5b9e\u73b0\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u5404\u79cd\u5f02\u5e38\u7684\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u53ca\u65f6\u68c0\u6d4b\u3002"}}
{"id": "2508.07270", "pdf": "https://arxiv.org/pdf/2508.07270", "abs": "https://arxiv.org/abs/2508.07270", "authors": ["Xiang Xiang", "Qinhao Zhou", "Zhuo Xu", "Jing Ma", "Jiaxin Dai", "Yifan Liang", "Hanlin Li"], "title": "OpenHAIV: A Framework Towards Practical Open-World Learning", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV", "stat.ML"], "comment": "Codes, results, and OpenHAIV documentation available at\n  https://haiv-lab.github.io/openhaiv", "summary": "Substantial progress has been made in various techniques for open-world\nrecognition. Out-of-distribution (OOD) detection methods can effectively\ndistinguish between known and unknown classes in the data, while incremental\nlearning enables continuous model knowledge updates. However, in open-world\nscenarios, these approaches still face limitations. Relying solely on OOD\ndetection does not facilitate knowledge updates in the model, and incremental\nfine-tuning typically requires supervised conditions, which significantly\ndeviate from open-world settings. To address these challenges, this paper\nproposes OpenHAIV, a novel framework that integrates OOD detection, new class\ndiscovery, and incremental continual fine-tuning into a unified pipeline. This\nframework allows models to autonomously acquire and update knowledge in\nopen-world environments. The proposed framework is available at\nhttps://haiv-lab.github.io/openhaiv .", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOpenHAIV\u6846\u67b6\uff0c\u6574\u5408OOD\u68c0\u6d4b\u3001\u65b0\u7c7b\u53d1\u73b0\u548c\u589e\u91cf\u6301\u7eed\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u5728\u5f00\u653e\u4e16\u754c\u81ea\u4e3b\u83b7\u53d6\u548c\u66f4\u65b0\u77e5\u8bc6\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u4e16\u754c\u8bc6\u522b\u6280\u672f\uff08OOD\u68c0\u6d4b\u548c\u589e\u91cf\u5b66\u4e60\uff09\u5b58\u5728\u5c40\u9650\uff0cOOD\u68c0\u6d4b\u4e0d\u5229\u4e8e\u6a21\u578b\u77e5\u8bc6\u66f4\u65b0\uff0c\u589e\u91cf\u5fae\u8c03\u9700\u76d1\u7763\u6761\u4ef6\uff0c\u504f\u79bb\u5f00\u653e\u4e16\u754c\u8bbe\u5b9a\u3002", "method": "\u63d0\u51faOpenHAIV\u6846\u67b6\uff0c\u5c06OOD\u68c0\u6d4b\u3001\u65b0\u7c7b\u53d1\u73b0\u548c\u589e\u91cf\u6301\u7eed\u5fae\u8c03\u6574\u5408\u5230\u7edf\u4e00\u6d41\u7a0b\u3002", "result": "\u672a\u63d0\u53ca\u660e\u786e\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u7ed9\u51fa\u6846\u67b6\u5f00\u6e90\u5730\u5740https://haiv-lab.github.io/openhaiv \u3002", "conclusion": "OpenHAIV\u6846\u67b6\u53ef\u8ba9\u6a21\u578b\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u81ea\u4e3b\u83b7\u53d6\u548c\u66f4\u65b0\u77e5\u8bc6\u3002"}}
{"id": "2508.07742", "pdf": "https://arxiv.org/pdf/2508.07742", "abs": "https://arxiv.org/abs/2508.07742", "authors": ["Meghyn Bienvenu", "Camille Bourgaux", "Katsumi Inoue", "Robin Jean"], "title": "A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases", "categories": ["cs.LO", "cs.AI", "cs.DB"], "comment": "This is an extended version of a paper appearing at the 22nd\n  International Conference on Principles of Knowledge Representation and\n  Reasoning (KR 2025). 24 pages", "summary": "Repair-based semantics have been extensively studied as a means of obtaining\nmeaningful answers to queries posed over inconsistent knowledge bases (KBs).\nWhile several works have considered how to exploit a priority relation between\nfacts to select optimal repairs, the question of how to specify such\npreferences remains largely unaddressed. This motivates us to introduce a\ndeclarative rule-based framework for specifying and computing a priority\nrelation between conflicting facts. As the expressed preferences may contain\nundesirable cycles, we consider the problem of determining when a set of\npreference rules always yields an acyclic relation, and we also explore a\npragmatic approach that extracts an acyclic relation by applying various cycle\nremoval techniques. Towards an end-to-end system for querying inconsistent KBs,\nwe present a preliminary implementation and experimental evaluation of the\nframework, which employs answer set programming to evaluate the preference\nrules, apply the desired cycle resolution techniques to obtain a priority\nrelation, and answer queries under prioritized-repair semantics.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\uff0c\u5f15\u5165\u57fa\u4e8e\u89c4\u5219\u7684\u6846\u67b6\u6765\u6307\u5b9a\u548c\u8ba1\u7b97\u51b2\u7a81\u4e8b\u5b9e\u95f4\u7684\u4f18\u5148\u7ea7\u5173\u7cfb\uff0c\u8003\u8651\u65e0\u73af\u6027\u95ee\u9898\u5e76\u7ed9\u51fa\u53bb\u9664\u5faa\u73af\u7684\u65b9\u6cd5\uff0c\u8fd8\u8fdb\u884c\u4e86\u521d\u6b65\u5b9e\u73b0\u548c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u672a\u5145\u5206\u89e3\u51b3\u5982\u4f55\u6307\u5b9a\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u4e2d\u4e8b\u5b9e\u95f4\u4f18\u5148\u7ea7\u504f\u597d\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u89c4\u5219\u7684\u6846\u67b6\uff0c\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\u8bc4\u4f30\u504f\u597d\u89c4\u5219\uff0c\u5e94\u7528\u5faa\u73af\u53bb\u9664\u6280\u672f\u83b7\u5f97\u4f18\u5148\u7ea7\u5173\u7cfb\u3002", "result": "\u5bf9\u6846\u67b6\u8fdb\u884c\u4e86\u521d\u6b65\u5b9e\u73b0\u548c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u6784\u5efa\u67e5\u8be2\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\u3002"}}
{"id": "2508.06767", "pdf": "https://arxiv.org/pdf/2508.06767", "abs": "https://arxiv.org/abs/2508.06767", "authors": ["Arman Dogru", "R. Irem Bor-Yaliniz", "Nimal Gamini Senarath"], "title": "PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.MA", "cs.RO"], "comment": null, "summary": "Digital Twins (DTs) are transforming industries through advanced data\nprocessing and analysis, positioning the world of DTs, Digital World, as a\ncornerstone of nextgeneration technologies including embodied AI. As robotics\nand automated systems scale, efficient data-sharing frameworks and robust\nalgorithms become critical. We explore the pivotal role of data handling in\nnext-gen networks, focusing on dynamics between application and network\nproviders (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with\nPriority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL)\nbased multi-agent path finding (MAPF). By adopting a Centralized Training with\nDecentralized Execution (CTDE) framework and asynchronous actor-learner\narchitectures, PANAMA accelerates training while enabling autonomous task\nexecution by embodied AI. Our approach demonstrates superior pathfinding\nperformance in accuracy, speed, and scalability compared to existing\nbenchmarks. Through simulations, we highlight optimized data-sharing strategies\nfor scalable, automated systems, ensuring resilience in complex, real-world\nenvironments. PANAMA bridges the gap between network-aware decision-making and\nrobust multi-agent coordination, advancing the synergy between DTs, wireless\nnetworks, and AI-driven automation.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u6570\u5b57\u5b6a\u751f\u751f\u6001\u7cfb\u7edf\u4e2d\u6570\u636e\u5904\u7406\uff0c\u63d0\u51faPANAMA\u7b97\u6cd5\uff0c\u5728\u8def\u5f84\u89c4\u5212\u6027\u80fd\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u5316\u6570\u636e\u5171\u4eab\u7b56\u7565\uff0c\u4fc3\u8fdb\u6570\u5b57\u5b6a\u751f\u3001\u65e0\u7ebf\u7f51\u7edc\u548cAI\u81ea\u52a8\u5316\u534f\u540c\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u548c\u81ea\u52a8\u5316\u7cfb\u7edf\u89c4\u6a21\u6269\u5927\uff0c\u9700\u8981\u9ad8\u6548\u6570\u636e\u5171\u4eab\u6846\u67b6\u548c\u5f3a\u5927\u7b97\u6cd5\uff0c\u63a2\u7d22\u4e0b\u4e00\u4ee3\u7f51\u7edc\u4e2d\u6570\u636e\u5904\u7406\u7684\u5173\u952e\u4f5c\u7528\u3002", "method": "\u5f15\u5165PANAMA\u7b97\u6cd5\uff0c\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u4e0e\u5206\u6563\u6267\u884c\u6846\u67b6\u548c\u5f02\u6b65\u6f14\u5458 - \u5b66\u4e60\u8005\u67b6\u6784\u3002", "result": "PANAMA\u5728\u8def\u5f84\u89c4\u5212\u7684\u51c6\u786e\u6027\u3001\u901f\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u901a\u8fc7\u6a21\u62df\u7a81\u51fa\u4e86\u53ef\u6269\u5c55\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u4f18\u5316\u6570\u636e\u5171\u4eab\u7b56\u7565\u3002", "conclusion": "PANAMA\u5f25\u5408\u4e86\u7f51\u7edc\u611f\u77e5\u51b3\u7b56\u548c\u5f3a\u5927\u591a\u667a\u80fd\u4f53\u534f\u8c03\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63a8\u52a8\u6570\u5b57\u5b6a\u751f\u3001\u65e0\u7ebf\u7f51\u7edc\u548cAI\u9a71\u52a8\u81ea\u52a8\u5316\u7684\u534f\u540c\u53d1\u5c55\u3002"}}
{"id": "2508.06836", "pdf": "https://arxiv.org/pdf/2508.06836", "abs": "https://arxiv.org/abs/2508.06836", "authors": ["Xutong Zhao", "Yaqi Xie"], "title": "Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning", "categories": ["cs.AI"], "comment": "Accepted at AISTATS 2025", "summary": "Cooperative multi-agent reinforcement learning (MARL) aims to coordinate\nmultiple agents to achieve a common goal. A key challenge in MARL is credit\nassignment, which involves assessing each agent's contribution to the shared\nreward. Given the diversity of tasks, agents may perform different types of\ncoordination, with rewards attributed to diverse and often overlapping agent\nsubsets. In this work, we formalize the credit assignment level as the number\nof agents cooperating to obtain a reward, and address scenarios with multiple\ncoexisting levels. We introduce a multi-level advantage formulation that\nperforms explicit counterfactual reasoning to infer credits across distinct\nlevels. Our method, Multi-level Advantage Credit Assignment (MACA), captures\nagent contributions at multiple levels by integrating advantage functions that\nreason about individual, joint, and correlated actions. Utilizing an\nattention-based framework, MACA identifies correlated agent relationships and\nconstructs multi-level advantages to guide policy learning. Comprehensive\nexperiments on challenging Starcraft v1\\&v2 tasks demonstrate MACA's superior\nperformance, underscoring its efficacy in complex credit assignment scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u7ea7\u522b\u4f18\u52bf\u4fe1\u7528\u5206\u914d\u65b9\u6cd5MACA\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u4fe1\u7528\u5206\u914d\u662f\u5173\u952e\u6311\u6218\uff0c\u4efb\u52a1\u591a\u6837\uff0c\u5956\u52b1\u5206\u914d\u590d\u6742\uff0c\u9700\u5904\u7406\u591a\u7ea7\u522b\u5171\u5b58\u7684\u573a\u666f\u3002", "method": "\u5f62\u5f0f\u5316\u4fe1\u7528\u5206\u914d\u7ea7\u522b\uff0c\u5f15\u5165\u591a\u7ea7\u522b\u4f18\u52bf\u516c\u5f0f\u8fdb\u884c\u53cd\u4e8b\u5b9e\u63a8\u7406\uff0c\u5229\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6846\u67b6\u8bc6\u522b\u76f8\u5173\u667a\u80fd\u4f53\u5173\u7cfb\uff0c\u6784\u5efa\u591a\u7ea7\u522b\u4f18\u52bf\u6307\u5bfc\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u661f\u9645\u4e89\u9738v1\u548cv2\u4efb\u52a1\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660eMACA\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "MACA\u5728\u590d\u6742\u4fe1\u7528\u5206\u914d\u573a\u666f\u4e2d\u6709\u6548\u3002"}}
{"id": "2508.07956", "pdf": "https://arxiv.org/pdf/2508.07956", "abs": "https://arxiv.org/abs/2508.07956", "authors": ["Yuqin Dai", "Shuo Yang", "Guoqing Wang", "Yong Deng", "Zhanwei Zhang", "Jun Yin", "Pengyu Zeng", "Zhenzhe Ying", "Changhua Meng", "Can Yi", "Yuchen Zhou", "Weiqiang Wang", "Shuai Lu"], "title": "Careful Queries, Credible Results: Teaching RAG Models Advanced Web Search Tools with Reinforcement Learning", "categories": ["cs.IR"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating up-to-date external knowledge, yet real-world web environments\npresent unique challenges. These limitations manifest as two key challenges:\npervasive misinformation in the web environment, which introduces unreliable or\nmisleading content that can degrade retrieval accuracy, and the\nunderutilization of web tools, which, if effectively employed, could enhance\nquery precision and help mitigate this noise, ultimately improving the\nretrieval results in RAG systems. To address these issues, we propose\nWebFilter, a novel RAG framework that generates source-restricted queries and\nfilters out unreliable content. This approach combines a retrieval filtering\nmechanism with a behavior- and outcome-driven reward strategy, optimizing both\nquery formulation and retrieval outcomes. Extensive experiments demonstrate\nthat WebFilter improves answer quality and retrieval precision, outperforming\nexisting RAG methods on both in-domain and out-of-domain benchmarks.", "AI": {"tldr": "\u63d0\u51faWebFilter\u6846\u67b6\u89e3\u51b3RAG\u7cfb\u7edf\u5728\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u6311\u6218\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "RAG\u7cfb\u7edf\u5728\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u9762\u4e34\u7f51\u7edc\u4fe1\u606f\u8bef\u5bfc\u548c\u7f51\u7edc\u5de5\u5177\u5229\u7528\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u9700\u63d0\u5347\u68c0\u7d22\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faWebFilter\u6846\u67b6\uff0c\u7ed3\u5408\u68c0\u7d22\u8fc7\u6ee4\u673a\u5236\u4e0e\u884c\u4e3a\u548c\u7ed3\u679c\u9a71\u52a8\u7684\u5956\u52b1\u7b56\u7565\u3002", "result": "WebFilter\u5728\u5185\u5916\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u4e86\u7b54\u6848\u8d28\u91cf\u548c\u68c0\u7d22\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u73b0\u6709RAG\u65b9\u6cd5\u3002", "conclusion": "WebFilter\u80fd\u6709\u6548\u89e3\u51b3RAG\u7cfb\u7edf\u5728\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.08171", "pdf": "https://arxiv.org/pdf/2508.08171", "abs": "https://arxiv.org/abs/2508.08171", "authors": ["Pedro Orvalho", "Marta Kwiatkowska"], "title": "PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C", "categories": ["cs.SE", "cs.AI"], "comment": "14 pages, 6 tables, 1 figure", "summary": "Python has become the dominant language for general-purpose programming, yet\nit lacks robust tools for formal verification. In contrast, programmers working\nin languages such as C benefit from mature model checkers, for example CBMC,\nwhich enable exhaustive symbolic reasoning and fault localisation. The inherent\ncomplexity of Python, coupled with the verbosity and low-level nature of\nexisting transpilers (e.g., Cython), have historically limited the\napplicability of formal verification to Python programs.\n  In this paper, we propose PyVeritas, a novel framework that leverages Large\nLanguage Models (LLMs) for high-level transpilation from Python to C, followed\nby bounded model checking and MaxSAT-based fault localisation in the generated\nC code. PyVeritas enables verification and bug localisation for Python code\nusing existing model checking tools for C. Our empirical evaluation on two\nPython benchmarks demonstrates that LLM-based transpilation can achieve a high\ndegree of accuracy, up to 80--90% for some LLMs, enabling effective development\nenvironment that supports assertion-based verification and interpretable fault\ndiagnosis for small yet non-trivial Python programs.", "AI": {"tldr": "\u63d0\u51faPyVeritas\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06Python\u8f6cC\uff0c\u7ed3\u5408C\u6a21\u578b\u68c0\u67e5\u5de5\u5177\u9a8c\u8bc1Python\u4ee3\u7801\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u8f83\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "Python\u7f3a\u4e4f\u5f3a\u5927\u7684\u5f62\u5f0f\u9a8c\u8bc1\u5de5\u5177\uff0c\u73b0\u6709Python\u8f6c\u8bd1\u5668\u590d\u6742\uff0c\u9650\u5236\u4e86\u5f62\u5f0f\u9a8c\u8bc1\u5728Python\u7a0b\u5e8f\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faPyVeritas\u6846\u67b6\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06Python\u8f6cC\uff0c\u5bf9\u751f\u6210\u7684C\u4ee3\u7801\u8fdb\u884c\u6709\u754c\u6a21\u578b\u68c0\u67e5\u548c\u57fa\u4e8eMaxSAT\u7684\u6545\u969c\u5b9a\u4f4d\u3002", "result": "\u5728\u4e24\u4e2aPython\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6c\u8bd1\u8fbe\u523080 - 90%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "PyVeritas\u80fd\u4e3a\u5c0f\u578b\u975e\u5e73\u51e1Python\u7a0b\u5e8f\u63d0\u4f9b\u57fa\u4e8e\u65ad\u8a00\u7684\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u7684\u6545\u969c\u8bca\u65ad\u3002"}}
{"id": "2508.06641", "pdf": "https://arxiv.org/pdf/2508.06641", "abs": "https://arxiv.org/abs/2508.06641", "authors": ["Jonas S Almeida", "Daniel E Russ", "Susana Vinga", "Ines Duarte", "Lee Mason", "Praphulla Bhawsar", "Aaron Ge", "Arlindo Oliveira", "Jeya Balaji Balasubramanian"], "title": "Fractal Language Modelling by Universal Sequence Maps (USM)", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "q-bio.QM"], "comment": "16 pages, 8 figures", "summary": "Motivation: With the advent of Language Models using Transformers,\npopularized by ChatGPT, there is a renewed interest in exploring encoding\nprocedures that numerically represent symbolic sequences at multiple scales and\nembedding dimensions. The challenge that encoding addresses is the need for\nmechanisms that uniquely retain contextual information about the succession of\nindividual symbols, which can then be modeled by nonlinear formulations such as\nneural networks.\n  Context: Universal Sequence Maps(USM) are iterated functions that bijectively\nencode symbolic sequences onto embedded numerical spaces. USM is composed of\ntwo Chaos Game Representations (CGR), iterated forwardly and backwardly, that\ncan be projected into the frequency domain (FCGR). The corresponding USM\ncoordinates can be used to compute a Chebyshev distance metric as well as k-mer\nfrequencies, without having to recompute the embedded numeric coordinates, and,\nparadoxically, allowing for non-integers values of k.\n  Results: This report advances the bijective fractal encoding by Universal\nSequence Maps (USM) by resolving seeding biases affecting the iterated process.\nThe resolution had two results, the first expected, the second an intriguing\noutcome: 1) full reconciliation of numeric positioning with sequence identity;\nand 2) uncovering the nature of USM as an efficient numeric process converging\ntowards a steady state sequence embedding solution. We illustrate these results\nfor genomic sequences because of the convenience of a planar representation\ndefined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,\nthe application to alphabet of arbitrary cardinality was found to be\nstraightforward.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u901a\u7528\u5e8f\u5217\u6620\u5c04\uff08USM\uff09\u53cc\u5c04\u5206\u5f62\u7f16\u7801\uff0c\u89e3\u51b3\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u7684\u79cd\u5b50\u504f\u5dee\u95ee\u9898\uff0c\u53d6\u5f97\u5b9a\u4f4d\u4e0e\u5e8f\u5217\u8eab\u4efd\u5339\u914d\u53ca\u53d1\u73b0 USM \u6536\u655b\u7279\u6027\u7684\u6210\u679c\uff0c\u4e14\u9002\u7528\u4e8e\u4efb\u610f\u57fa\u6570\u5b57\u6bcd\u8868\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e Transformer \u7684\u8bed\u8a00\u6a21\u578b\u5174\u8d77\uff0c\u4eba\u4eec\u5bf9\u591a\u5c3a\u5ea6\u548c\u5d4c\u5165\u7ef4\u5ea6\u7684\u7b26\u53f7\u5e8f\u5217\u7f16\u7801\u7a0b\u5e8f\u91cd\u71c3\u5174\u8da3\uff0c\u7f16\u7801\u9700\u89e3\u51b3\u4fdd\u7559\u7b26\u53f7\u5e8f\u5217\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u901a\u7528\u5e8f\u5217\u6620\u5c04\uff08USM\uff09\uff0c\u5b83\u7531\u4e24\u4e2a\u6df7\u6c8c\u6e38\u620f\u8868\u793a\uff08CGR\uff09\u524d\u540e\u8fed\u4ee3\u7ec4\u6210\uff0c\u53ef\u6295\u5f71\u5230\u9891\u57df\uff08FCGR\uff09\uff0c\u7528\u5176\u5750\u6807\u8ba1\u7b97\u5207\u6bd4\u96ea\u592b\u8ddd\u79bb\u548c k - \u5143\u9891\u7387\u3002", "result": "\u89e3\u51b3\u5f71\u54cd\u8fed\u4ee3\u8fc7\u7a0b\u7684\u79cd\u5b50\u504f\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u6570\u503c\u5b9a\u4f4d\u4e0e\u5e8f\u5217\u8eab\u4efd\u5b8c\u5168\u5339\u914d\uff0c\u53d1\u73b0 USM \u662f\u6536\u655b\u4e8e\u7a33\u6001\u5e8f\u5217\u5d4c\u5165\u89e3\u7684\u9ad8\u6548\u6570\u503c\u8fc7\u7a0b\uff0c\u5bf9\u57fa\u56e0\u7ec4\u5e8f\u5217\u8fdb\u884c\u4e86\u8bf4\u660e\u4e14\u9002\u7528\u4e8e\u4efb\u610f\u57fa\u6570\u5b57\u6bcd\u8868\u3002", "conclusion": "\u901a\u7528\u5e8f\u5217\u6620\u5c04\uff08USM\uff09\u5728\u89e3\u51b3\u79cd\u5b50\u504f\u5dee\u540e\uff0c\u80fd\u6709\u6548\u5b9e\u73b0\u53cc\u5c04\u5206\u5f62\u7f16\u7801\uff0c\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u6536\u655b\u7279\u6027\u3002"}}
{"id": "2508.07392", "pdf": "https://arxiv.org/pdf/2508.07392", "abs": "https://arxiv.org/abs/2508.07392", "authors": ["Nikita Puchkin", "Denis Suchkov", "Alexey Naumov", "Denis Belomestny"], "title": "Tight Bounds for Schr\u00f6dinger Potential Estimation in Unpaired Image-to-Image Translation Problems", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": "54 pages, 4 figures", "summary": "Modern methods of generative modelling and unpaired image-to-image\ntranslation based on Schr\\\"odinger bridges and stochastic optimal control\ntheory aim to transform an initial density to a target one in an optimal way.\nIn the present paper, we assume that we only have access to i.i.d. samples from\ninitial and final distributions. This makes our setup suitable for both\ngenerative modelling and unpaired image-to-image translation. Relying on the\nstochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as\nthe reference one and estimate the corresponding Schr\\\"odinger potential.\nIntroducing a risk function as the Kullback-Leibler divergence between\ncouplings, we derive tight bounds on generalization ability of an empirical\nrisk minimizer in a class of Schr\\\"odinger potentials including Gaussian\nmixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we\nalmost achieve fast rates of convergence up to some logarithmic factors in\nfavourable scenarios. We also illustrate performance of the suggested approach\nwith numerical experiments.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u859b\u5b9a\u8c14\u6865\u548c\u968f\u673a\u6700\u4f18\u63a7\u5236\u7406\u8bba\uff0c\u5728\u4ec5\u6709\u521d\u59cb\u548c\u6700\u7ec8\u5206\u5e03\u7684\u72ec\u7acb\u540c\u5206\u5e03\u6837\u672c\u60c5\u51b5\u4e0b\uff0c\u9009\u62e9\u5965\u6069\u65af\u5766 - \u4e4c\u4f26\u8d1d\u514b\u8fc7\u7a0b\u4f30\u8ba1\u859b\u5b9a\u8c14\u52bf\uff0c\u63a8\u5bfc\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5668\u6cdb\u5316\u80fd\u529b\u7684\u8fb9\u754c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u5728\u4ec5\u6709\u521d\u59cb\u548c\u6700\u7ec8\u5206\u5e03\u7684\u72ec\u7acb\u540c\u5206\u5e03\u6837\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4ece\u521d\u59cb\u5bc6\u5ea6\u5230\u76ee\u6807\u5bc6\u5ea6\u7684\u6700\u4f18\u8f6c\u6362\uff0c\u9002\u7528\u4e8e\u751f\u6210\u5f0f\u5efa\u6a21\u548c\u65e0\u914d\u5bf9\u56fe\u50cf\u5230\u56fe\u50cf\u7684\u8f6c\u6362\u3002", "method": "\u91c7\u7528\u968f\u673a\u6700\u4f18\u63a7\u5236\u65b9\u6cd5\uff0c\u9009\u62e9\u5965\u6069\u65af\u5766 - \u4e4c\u4f26\u8d1d\u514b\u8fc7\u7a0b\u4f5c\u4e3a\u53c2\u8003\u8fc7\u7a0b\u6765\u4f30\u8ba1\u859b\u5b9a\u8c14\u52bf\uff0c\u5f15\u5165\u98ce\u9669\u51fd\u6570\uff08\u8026\u5408\u4e4b\u95f4\u7684KL\u6563\u5ea6\uff09\u3002", "result": "\u63a8\u5bfc\u4e86\u5305\u62ec\u9ad8\u65af\u6df7\u5408\u5728\u5185\u7684\u859b\u5b9a\u8c14\u52bf\u7c7b\u4e2d\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5668\u6cdb\u5316\u80fd\u529b\u7684\u7d27\u5bc6\u8fb9\u754c\uff0c\u5728\u6709\u5229\u60c5\u51b5\u4e0b\u51e0\u4e4e\u5b9e\u73b0\u4e86\u5feb\u6536\u655b\u901f\u7387\uff08\u9664\u4e86\u4e00\u4e9b\u5bf9\u6570\u56e0\u5b50\uff09\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5177\u6709\u4e00\u5b9a\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.08061", "pdf": "https://arxiv.org/pdf/2508.08061", "abs": "https://arxiv.org/abs/2508.08061", "authors": ["Sven Weinzierl", "Sandra Zilker", "Annina Liessmann", "Martin K\u00e4ppel", "Weixin Wang", "Martin Matzner"], "title": "From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations", "categories": ["cs.LG", "cs.CL", "cs.DB"], "comment": null, "summary": "Event logs reflect the behavior of business processes that are mapped in\norganizational information systems. Predictive process monitoring (PPM)\ntransforms these data into value by creating process-related predictions that\nprovide the insights required for proactive interventions at process runtime.\nExisting PPM techniques require sufficient amounts of event data or other\nrelevant resources that might not be readily available, preventing some\norganizations from utilizing PPM. The transfer learning-based PPM technique\npresented in this paper allows organizations without suitable event data or\nother relevant resources to implement PPM for effective decision support. The\ntechnique is instantiated in two real-life use cases, based on which numerical\nexperiments are performed using event logs for IT service management processes\nin an intra- and inter-organizational setting. The results of the experiments\nsuggest that knowledge of one business process can be transferred to a similar\nbusiness process in the same or a different organization to enable effective\nPPM in the target context. With the proposed technique, organizations can\nbenefit from transfer learning in an intra- and inter-organizational setting,\nwhere resources like pre-trained models are transferred within and across\norganizational boundaries.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8fc1\u79fb\u5b66\u4e60\u7684PPM\u6280\u672f\uff0c\u901a\u8fc7\u5b9e\u4f8b\u548c\u5b9e\u9a8c\u8868\u660e\u8be5\u6280\u672f\u53ef\u8ba9\u7f3a\u4e4f\u8d44\u6e90\u7684\u7ec4\u7ec7\u5b9e\u73b0\u6709\u6548PPM\uff0c\u77e5\u8bc6\u53ef\u8de8\u7ec4\u7ec7\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709PPM\u6280\u672f\u9700\u8981\u5927\u91cf\u4e8b\u4ef6\u6570\u636e\u6216\u76f8\u5173\u8d44\u6e90\uff0c\u90e8\u5206\u7ec4\u7ec7\u96be\u4ee5\u5229\u7528\uff0c\u56e0\u6b64\u63d0\u51fa\u65b0\u7684\u6280\u672f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8fc1\u79fb\u5b66\u4e60\u7684PPM\u6280\u672f\uff0c\u5728\u4e24\u4e2a\u5b9e\u9645\u7528\u4f8b\u4e2d\u5b9e\u4f8b\u5316\uff0c\u5e76\u4f7f\u7528IT\u670d\u52a1\u7ba1\u7406\u6d41\u7a0b\u7684\u4e8b\u4ef6\u65e5\u5fd7\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u4e00\u4e2a\u4e1a\u52a1\u6d41\u7a0b\u7684\u77e5\u8bc6\u53ef\u8f6c\u79fb\u5230\u76f8\u540c\u6216\u4e0d\u540c\u7ec4\u7ec7\u7684\u7c7b\u4f3c\u4e1a\u52a1\u6d41\u7a0b\uff0c\u5b9e\u73b0\u76ee\u6807\u73af\u5883\u4e0b\u7684\u6709\u6548PPM\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6280\u672f\u53ef\u8ba9\u7ec4\u7ec7\u5728\u5185\u90e8\u548c\u8de8\u7ec4\u7ec7\u73af\u5883\u4e2d\u4ece\u8fc1\u79fb\u5b66\u4e60\u4e2d\u53d7\u76ca\uff0c\u8d44\u6e90\u53ef\u8de8\u7ec4\u7ec7\u8fb9\u754c\u8f6c\u79fb\u3002"}}
{"id": "2508.06851", "pdf": "https://arxiv.org/pdf/2508.06851", "abs": "https://arxiv.org/abs/2508.06851", "authors": ["Pengfei Zhou", "Xiaopeng Peng", "Fanrui Zhang", "Zhaopan Xu", "Jiaxin Ai", "Yansheng Qiu", "Chuanhao Li", "Zhen Li", "Ming Li", "Yukang Feng", "Jianwen Sun", "Haoquan Zhang", "Zizhen Li", "Xiaofeng Mao", "Zekai Li", "Wangbo Zhao", "Kai Wang", "Xiaojun Chang", "Wenqi Shao", "Yang You", "Kaipeng Zhang"], "title": "MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams", "categories": ["cs.AI", "cs.CY"], "comment": "35 pages, 33 figures", "summary": "Multimodal large language models (MLLMs), which integrate language and visual\ncues for problem-solving, are crucial for advancing artificial general\nintelligence (AGI). However, current benchmarks for measuring the intelligence\nof MLLMs suffer from limited scale, narrow coverage, and unstructured\nknowledge, offering only static and undifferentiated evaluations. To bridge\nthis gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark\nbuilt from real-world K-12 exams spanning six disciplines with 141K instances\nand 6,225 knowledge points organized in a six-layer taxonomy. Covering five\nquestion formats with difficulty and year annotations, it enables comprehensive\nevaluation to capture the extent to which MLLMs perform over four dimensions:\n1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts,\nand 4) knowledge-driven reasoning. We propose a novel dynamic evaluation\nframework that introduces unfamiliar visual, textual, and question form shifts\nto challenge model generalization while improving benchmark objectivity and\nlongevity by mitigating data contamination. We further evaluate knowledge-point\nreference-augmented generation (KP-RAG) to examine the role of knowledge in\nproblem-solving. Key findings reveal limitations in current MLLMs in multiple\naspects and provide guidance for enhancing model robustness, interpretability,\nand AI-assisted education.", "AI": {"tldr": "\u63d0\u51faMDK12 - Bench\u57fa\u51c6\u548c\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63ed\u793a\u5176\u5c40\u9650\u5e76\u4e3a\u6539\u8fdb\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u89c4\u6a21\u6709\u9650\u3001\u8986\u76d6\u7a84\u548c\u77e5\u8bc6\u65e0\u7ed3\u6784\u7b49\u95ee\u9898\uff0c\u9700\u66f4\u597d\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165MDK12 - Bench\u57fa\u51c6\uff0c\u63d0\u51fa\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc4\u4f30\u77e5\u8bc6\u70b9\u53c2\u8003\u589e\u5f3a\u751f\u6210\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "conclusion": "\u7814\u7a76\u4e3a\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u6559\u80b2\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2508.07975", "pdf": "https://arxiv.org/pdf/2508.07975", "abs": "https://arxiv.org/abs/2508.07975", "authors": ["Stefano Campese", "Alessandro Moschitti", "Ivano Lauriola"], "title": "Improving Document Retrieval Coherence for Semantically Equivalent Queries", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Dense Retrieval (DR) models have proven to be effective for Document\nRetrieval and Information Grounding tasks. Usually, these models are trained\nand optimized for improving the relevance of top-ranked documents for a given\nquery. Previous work has shown that popular DR models are sensitive to the\nquery and document lexicon: small variations of it may lead to a significant\ndifference in the set of retrieved documents. In this paper, we propose a\nvariation of the Multi-Negative Ranking loss for training DR that improves the\ncoherence of models in retrieving the same documents with respect to\nsemantically similar queries. The loss penalizes discrepancies between the\ntop-k ranked documents retrieved for diverse but semantic equivalent queries.\nWe conducted extensive experiments on various datasets, MS-MARCO, Natural\nQuestions, BEIR, and TREC DL 19/20. The results show that (i) models optimizes\nby our loss are subject to lower sensitivity, and, (ii) interestingly, higher\naccuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdbDense Retrieval (DR) \u6a21\u578b\u8bad\u7ec3\u635f\u5931\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u964d\u4f4e\u6a21\u578b\u654f\u611f\u6027\u5e76\u63d0\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u6d41\u884c\u7684DR\u6a21\u578b\u5bf9\u67e5\u8be2\u548c\u6587\u6863\u8bcd\u6c47\u654f\u611f\uff0c\u5c0f\u53d8\u5316\u4f1a\u5bfc\u81f4\u68c0\u7d22\u6587\u6863\u96c6\u5dee\u5f02\u5927\uff0c\u9700\u63d0\u9ad8\u6a21\u578b\u5728\u8bed\u4e49\u76f8\u4f3c\u67e5\u8be2\u65f6\u68c0\u7d22\u6587\u6863\u7684\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cdMulti - Negative Ranking\u635f\u5931\u51fd\u6570\u7684\u53d8\u4f53\uff0c\u60e9\u7f5a\u8bed\u4e49\u7b49\u4ef7\u4f46\u4e0d\u540c\u67e5\u8be2\u4e0btop - k\u6392\u540d\u6587\u6863\u7684\u5dee\u5f02\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u6a21\u578b\u7ecf\u8be5\u635f\u5931\u51fd\u6570\u4f18\u5316\u540e\u654f\u611f\u6027\u964d\u4f4e\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u3002", "conclusion": "\u6240\u63d0\u635f\u5931\u51fd\u6570\u80fd\u63d0\u5347DR\u6a21\u578b\u6027\u80fd\uff0c\u964d\u4f4e\u654f\u611f\u6027\u5e76\u63d0\u9ad8\u51c6\u786e\u7387\u3002"}}
{"id": "2508.06647", "pdf": "https://arxiv.org/pdf/2508.06647", "abs": "https://arxiv.org/abs/2508.06647", "authors": ["Andrey Sidorenko", "Paul Tiwald"], "title": "Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN", "categories": ["cs.LG"], "comment": null, "summary": "Synthetic data generation has become essential for securely sharing and\nanalyzing sensitive data sets. Traditional anonymization techniques, however,\noften fail to adequately preserve privacy. We introduce the Tabular\nAuto-Regressive Generative Network (TabularARGN), a neural network architecture\nspecifically designed for generating high-quality synthetic tabular data. Using\na discretization-based auto-regressive approach, TabularARGN achieves high data\nfidelity while remaining computationally efficient. We evaluate TabularARGN\nagainst existing synthetic data generation methods, showing competitive results\nin statistical similarity, machine learning utility, and detection robustness.\nWe further perform an in-depth privacy evaluation using systematic\nmembership-inference attacks, highlighting the robustness and effective\nprivacy-utility balance of our approach.", "AI": {"tldr": "\u4ecb\u7ecdTabularARGN\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u8868\u683c\u6570\u636e\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6709\u7ade\u4e89\u529b\u4e14\u9690\u79c1-\u6548\u7528\u5e73\u8861\u597d", "motivation": "\u4f20\u7edf\u533f\u540d\u6280\u672f\u96be\u4ee5\u5145\u5206\u4fdd\u62a4\u9690\u79c1\uff0c\u9700\u6709\u6548\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5", "method": "\u63d0\u51faTabularARGN\uff0c\u91c7\u7528\u57fa\u4e8e\u79bb\u6563\u5316\u7684\u81ea\u56de\u5f52\u65b9\u6cd5", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u5728\u7edf\u8ba1\u76f8\u4f3c\u6027\u3001\u673a\u5668\u5b66\u4e60\u6548\u7528\u548c\u68c0\u6d4b\u9c81\u68d2\u6027\u4e0a\u6709\u7ade\u4e89\u529b\uff0c\u9690\u79c1\u8bc4\u4f30\u663e\u793a\u5176\u9c81\u68d2\u4e14\u6709\u826f\u597d\u9690\u79c1-\u6548\u7528\u5e73\u8861", "conclusion": "TabularARGN\u662f\u4e00\u79cd\u6709\u6548\u751f\u6210\u5408\u6210\u8868\u683c\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u80fd\u5b9e\u73b0\u8f83\u597d\u9690\u79c1-\u6548\u7528\u5e73\u8861"}}
{"id": "2508.07465", "pdf": "https://arxiv.org/pdf/2508.07465", "abs": "https://arxiv.org/abs/2508.07465", "authors": ["Tiantian Yang", "Zhiqian Chen"], "title": "MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification", "categories": ["cs.LG", "q-bio.GN", "stat.ML", "62R07"], "comment": "11 pages, 6 figures", "summary": "Integrating multi-omics data, such as DNA methylation, mRNA expression, and\nmicroRNA (miRNA) expression, offers a comprehensive view of the biological\nmechanisms underlying disease. However, the high dimensionality and complex\ninteractions among omics layers present major challenges for predictive\nmodeling. We propose Multi-Omics integration with Tree-generated Graph Neural\nNetwork (MOTGNN), a novel and interpretable framework for binary disease\nclassification. MOTGNN employs eXtreme Gradient Boosting (XGBoost) to perform\nomics-specific supervised graph construction, followed by modality-specific\nGraph Neural Networks (GNNs) for hierarchical representation learning, and a\ndeep feedforward network for cross-omics integration. On three real-world\ndisease datasets, MOTGNN outperforms state-of-the-art baselines by 5-10% in\naccuracy, ROC-AUC, and F1-score, and remains robust to severe class imbalance\n(e.g., 87.2% vs. 33.4% F1 on imbalanced data). The model maintains\ncomputational efficiency through sparse graphs (2.1-2.8 edges per node) and\nprovides built-in interpretability, revealing both top-ranked biomarkers and\nthe relative contributions of each omics modality. These results highlight\nMOTGNN's potential to improve both predictive accuracy and interpretability in\nmulti-omics disease modeling.", "AI": {"tldr": "\u63d0\u51faMOTGNN\u6846\u67b6\u7528\u4e8e\u4e8c\u5143\u75be\u75c5\u5206\u7c7b\uff0c\u5728\u4e09\u4e2a\u771f\u5b9e\u75be\u75c5\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u6709\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u591a\u7ec4\u5b66\u6570\u636e\u9ad8\u7ef4\u6027\u548c\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u7ed9\u9884\u6d4b\u5efa\u6a21\u5e26\u6765\u6311\u6218\uff0c\u9700\u65b0\u65b9\u6cd5\u8fdb\u884c\u75be\u75c5\u5206\u7c7b\u3002", "method": "\u91c7\u7528XGBoost\u8fdb\u884c\u7ec4\u5b66\u7279\u5b9a\u7684\u76d1\u7763\u56fe\u6784\u5efa\uff0c\u4f7f\u7528\u6a21\u6001\u7279\u5b9a\u7684GNN\u8fdb\u884c\u5206\u5c42\u8868\u793a\u5b66\u4e60\uff0c\u7528\u6df1\u5ea6\u524d\u9988\u7f51\u7edc\u8fdb\u884c\u8de8\u7ec4\u5b66\u96c6\u6210\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cMOTGNN\u5728\u51c6\u786e\u7387\u3001ROC - AUC\u548cF1\u5206\u6570\u4e0a\u6bd4\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u9ad85 - 10%\uff0c\u5bf9\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u60c5\u51b5\u6709\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u7a00\u758f\u56fe\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u5e76\u5177\u6709\u5185\u7f6e\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "MOTGNN\u5728\u591a\u7ec4\u5b66\u75be\u75c5\u5efa\u6a21\u4e2d\u53ef\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.06972", "pdf": "https://arxiv.org/pdf/2508.06972", "abs": "https://arxiv.org/abs/2508.06972", "authors": ["Dan Ivanov", "Tristan Freiberg", "Haruna Isah"], "title": "DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning", "categories": ["cs.AI", "cs.CR", "cs.DC", "cs.LG"], "comment": "12 pages, 8 figures, and 10 tables", "summary": "DSperse is a modular framework for distributed machine learning inference\nwith strategic cryptographic verification. Operating within the emerging\nparadigm of distributed zero-knowledge machine learning, DSperse avoids the\nhigh cost and rigidity of full-model circuitization by enabling targeted\nverification of strategically chosen subcomputations. These verifiable\nsegments, or \"slices\", may cover part or all of the inference pipeline, with\nglobal consistency enforced through audit, replication, or economic incentives.\nThis architecture supports a pragmatic form of trust minimization, localizing\nzero-knowledge proofs to the components where they provide the greatest value.\nWe evaluate DSperse using multiple proving systems and report empirical results\non memory usage, runtime, and circuit behavior under sliced and unsliced\nconfigurations. By allowing proof boundaries to align flexibly with the model's\nlogical structure, DSperse supports scalable, targeted verification strategies\nsuited to diverse deployment needs.", "AI": {"tldr": "DSperse\u662f\u7528\u4e8e\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u63a8\u7406\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u53ef\u8fdb\u884c\u7b56\u7565\u6027\u52a0\u5bc6\u9a8c\u8bc1\uff0c\u80fd\u7075\u6d3b\u652f\u6301\u53ef\u6269\u5c55\u3001\u6709\u9488\u5bf9\u6027\u7684\u9a8c\u8bc1\u7b56\u7565\u3002", "motivation": "\u907f\u514d\u5206\u5e03\u5f0f\u96f6\u77e5\u8bc6\u673a\u5668\u5b66\u4e60\u4e2d\u5168\u6a21\u578b\u7535\u8def\u5316\u7684\u9ad8\u6210\u672c\u548c\u50f5\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u4fe1\u4efb\u6700\u5c0f\u5316\u3002", "method": "\u901a\u8fc7\u5bf9\u7b56\u7565\u6027\u9009\u62e9\u7684\u5b50\u8ba1\u7b97\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u9a8c\u8bc1\uff0c\u8bbe\u7f6e\u53ef\u9a8c\u8bc1\u7684\u201c\u5207\u7247\u201d\uff0c\u5e76\u901a\u8fc7\u5ba1\u8ba1\u3001\u590d\u5236\u6216\u7ecf\u6d4e\u6fc0\u52b1\u6765\u786e\u4fdd\u5168\u5c40\u4e00\u81f4\u6027\u3002", "result": "\u4f7f\u7528\u591a\u79cd\u8bc1\u660e\u7cfb\u7edf\u8bc4\u4f30DSperse\uff0c\u62a5\u544a\u4e86\u5207\u7247\u548c\u672a\u5207\u7247\u914d\u7f6e\u4e0b\u7684\u5185\u5b58\u4f7f\u7528\u3001\u8fd0\u884c\u65f6\u95f4\u548c\u7535\u8def\u884c\u4e3a\u7684\u5b9e\u8bc1\u7ed3\u679c\u3002", "conclusion": "DSperse\u5141\u8bb8\u8bc1\u660e\u8fb9\u754c\u4e0e\u6a21\u578b\u7684\u903b\u8f91\u7ed3\u6784\u7075\u6d3b\u5bf9\u9f50\uff0c\u652f\u6301\u9002\u5408\u4e0d\u540c\u90e8\u7f72\u9700\u6c42\u7684\u53ef\u6269\u5c55\u3001\u6709\u9488\u5bf9\u6027\u7684\u9a8c\u8bc1\u7b56\u7565\u3002"}}
{"id": "2508.06859", "pdf": "https://arxiv.org/pdf/2508.06859", "abs": "https://arxiv.org/abs/2508.06859", "authors": ["Shuo Tang", "Jian Xu", "Jiadong Zhang", "Yi Chen", "Qizhao Jin", "Lingdong Shen", "Chenglin Liu", "Shiming Xiang"], "title": "MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Timely and accurate severe weather warnings are critical for disaster\nmitigation. However, current forecasting systems remain heavily reliant on\nmanual expert interpretation, introducing subjectivity and significant\noperational burdens. With the rapid development of AI technologies, the\nend-to-end \"AI weather station\" is gradually emerging as a new trend in\npredicting severe weather events. Three core challenges impede the development\nof end-to-end AI severe weather system: (1) scarcity of severe weather event\nsamples; (2) imperfect alignment between high-dimensional meteorological data\nand textual warnings; (3) existing multimodal language models are unable to\nhandle high-dimensional meteorological data and struggle to fully capture the\ncomplex dependencies across temporal sequences, vertical pressure levels, and\nspatial dimensions. To address these challenges, we introduce MP-Bench, the\nfirst large-scale temporal multimodal dataset for severe weather events\nprediction, comprising 421,363 pairs of raw multi-year meteorological data and\ncorresponding text caption, covering a wide range of severe weather scenarios\nacross China. On top of this dataset, we develop a meteorology multimodal large\nmodel (MMLM) that directly ingests 4D meteorological inputs. In addition, it is\ndesigned to accommodate the unique characteristics of 4D meteorological data\nflow, incorporating three plug-and-play adaptive fusion modules that enable\ndynamic feature extraction and integration across temporal sequences, vertical\npressure layers, and spatial dimensions. Extensive experiments on MP-Bench\ndemonstrate that MMLM performs exceptionally well across multiple tasks,\nhighlighting its effectiveness in severe weather understanding and marking a\nkey step toward realizing automated, AI-driven weather forecasting systems. Our\nsource code and dataset will be made publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5927\u89c4\u6a21\u6570\u636e\u96c6MP - Bench\u548c\u6c14\u8c61\u591a\u6a21\u6001\u5927\u6a21\u578bMMLM\u7528\u4e8e\u6076\u52a3\u5929\u6c14\u9884\u6d4b\uff0c\u5b9e\u9a8c\u8bc1\u660eMMLM\u6548\u679c\u597d\uff0c\u5c06\u516c\u5f00\u4ee3\u7801\u548c\u6570\u636e\u3002", "motivation": "\u5f53\u524d\u6076\u52a3\u5929\u6c14\u9884\u62a5\u4f9d\u8d56\u4eba\u5de5\uff0c\u5b58\u5728\u4e3b\u89c2\u6027\u548c\u64cd\u4f5c\u8d1f\u62c5\uff0c\u7aef\u5230\u7aefAI\u6076\u52a3\u5929\u6c14\u7cfb\u7edf\u53d1\u5c55\u9762\u4e34\u6837\u672c\u7a00\u7f3a\u3001\u6570\u636e\u4e0e\u9884\u8b66\u6587\u672c\u5bf9\u9f50\u4e0d\u4f73\u3001\u73b0\u6709\u6a21\u578b\u5904\u7406\u9ad8\u7ef4\u6c14\u8c61\u6570\u636e\u80fd\u529b\u4e0d\u8db3\u7b49\u6311\u6218\u3002", "method": "\u5f15\u5165\u5927\u89c4\u6a21\u6570\u636e\u96c6MP - Bench\uff0c\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\u5f00\u53d1\u6c14\u8c61\u591a\u6a21\u6001\u5927\u6a21\u578bMMLM\uff0c\u878d\u5165\u4e09\u4e2a\u5373\u63d2\u5373\u7528\u81ea\u9002\u5e94\u878d\u5408\u6a21\u5757\u3002", "result": "\u5728MP - Bench\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660eMMLM\u5728\u591a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "MMLM\u5728\u6076\u52a3\u5929\u6c14\u7406\u89e3\u4e0a\u6709\u6548\uff0c\u662f\u5b9e\u73b0\u81ea\u52a8\u5316AI\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\u7684\u5173\u952e\u4e00\u6b65\u3002"}}
{"id": "2508.07995", "pdf": "https://arxiv.org/pdf/2508.07995", "abs": "https://arxiv.org/abs/2508.07995", "authors": ["Meixiu Long", "Duolin Sun", "Dan Yang", "Junjie Wang", "Yue Shen", "Jian Wang", "Peng Wei", "Jinjie Gu", "Jiahai Wang"], "title": "DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation has achieved strong performance on\nknowledge-intensive tasks where query-document relevance can be identified\nthrough direct lexical or semantic matches. However, many real-world queries\ninvolve abstract reasoning, analogical thinking, or multi-step inference, which\nexisting retrievers often struggle to capture. To address this challenge, we\npresent \\textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive\ninformation retrieval. DIVER consists of four components: document processing\nto improve input quality, LLM-driven query expansion via iterative document\ninteraction, a reasoning-enhanced retriever fine-tuned on synthetic\nmulti-domain data with hard negatives, and a pointwise reranker that combines\nLLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark,\nDIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original\nqueries, consistently outperforming competitive reasoning-aware models. These\nresults demonstrate the effectiveness of reasoning-aware retrieval strategies\nin complex real-world tasks. Our code and retrieval model will be released\nsoon.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u68c0\u7d22\u7ba1\u9053DIVER\u7528\u4e8e\u63a8\u7406\u5bc6\u96c6\u578b\u4fe1\u606f\u68c0\u7d22\uff0c\u5728BRIGHT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u63a8\u7406\u611f\u77e5\u68c0\u7d22\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u5668\u96be\u4ee5\u5904\u7406\u6d89\u53ca\u62bd\u8c61\u63a8\u7406\u3001\u7c7b\u6bd4\u601d\u7ef4\u6216\u591a\u6b65\u63a8\u7406\u7684\u73b0\u5b9e\u67e5\u8be2\uff0c\u9700\u8981\u65b0\u7684\u68c0\u7d22\u65b9\u6cd5\u3002", "method": "DIVER\u7531\u6587\u6863\u5904\u7406\u3001\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u67e5\u8be2\u6269\u5c55\u3001\u63a8\u7406\u589e\u5f3a\u7684\u68c0\u7d22\u5668\u3001\u70b9\u5f0f\u91cd\u6392\u5668\u56db\u4e2a\u7ec4\u4ef6\u7ec4\u6210\u3002", "result": "\u5728BRIGHT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDIVER\u5728\u539f\u59cb\u67e5\u8be2\u4e0a\u8fbe\u5230\u4e8641.6\u548c28.9\u7684nDCG@10\u5f97\u5206\uff0c\u59cb\u7ec8\u4f18\u4e8e\u6709\u7ade\u4e89\u529b\u7684\u63a8\u7406\u611f\u77e5\u6a21\u578b\u3002", "conclusion": "\u63a8\u7406\u611f\u77e5\u7684\u68c0\u7d22\u7b56\u7565\u5728\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u4ee3\u7801\u548c\u68c0\u7d22\u6a21\u578b\u5373\u5c06\u53d1\u5e03\u3002"}}
{"id": "2508.07203", "pdf": "https://arxiv.org/pdf/2508.07203", "abs": "https://arxiv.org/abs/2508.07203", "authors": ["Prashant Sharma"], "title": "Civil Servants as Builders: Enabling Non-IT Staff to Develop Secure Python and R Tools", "categories": ["cs.HC", "cs.CR", "cs.SE"], "comment": "Post-proceedings paper presented at LIMITS 2025: 11th Workshop on\n  Computing within Limits, 2025-06-26/27, Online", "summary": "Current digital government literature focuses on professional in-house IT\nteams, specialized digital service teams, vendor-developed systems, or\nproprietary low-code/no-code tools. Almost no scholarship addresses a growing\nmiddle ground: technically skilled civil servants outside formal IT roles who\ncan write real code but lack a sanctioned, secure path to deploy their work.\nThis paper introduces a limits-aware, open-source and replicable platform that\nenables such public servants to develop, peer review, and deploy small-scale,\ndomain-specific applications within government networks via a sandboxed,\nauditable workflow. By combining Jupyter Notebooks, preapproved open-source\nlibraries, and lightweight governance, the platform works within institutional\nconstraints such as procurement rules and IT security policies while avoiding\nvendor lock-in. Unlike low/no-code approaches, it preserves and enhances civil\nservants' programming skills, keeping them technically competitive with their\nprivate-sector peers. This contribution fills a critical gap, offering a\nreplicable model for public-sector skill retention, resilience, and bottom-up\ndigital transformation.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5f00\u6e90\u5e73\u53f0\uff0c\u4f7f\u975e IT \u5c97\u4f4d\u7684\u6280\u672f\u578b\u516c\u52a1\u5458\u80fd\u5728\u653f\u5e9c\u7f51\u7edc\u5185\u5f00\u53d1\u3001\u5ba1\u6838\u548c\u90e8\u7f72\u7279\u5b9a\u9886\u57df\u5e94\u7528\uff0c\u586b\u8865\u4e86\u76f8\u5173\u7814\u7a76\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u6570\u5b57\u653f\u5e9c\u7814\u7a76\u5f88\u5c11\u5173\u6ce8\u975e IT \u5c97\u4f4d\u4f46\u6709\u7f16\u7a0b\u6280\u80fd\u7684\u516c\u52a1\u5458\uff0c\u7f3a\u4e4f\u8ba9\u4ed6\u4eec\u5b89\u5168\u90e8\u7f72\u5de5\u4f5c\u7684\u9014\u5f84\u3002", "method": "\u7ed3\u5408 Jupyter Notebooks\u3001\u9884\u6279\u51c6\u7684\u5f00\u6e90\u5e93\u548c\u8f7b\u91cf\u7ea7\u6cbb\u7406\uff0c\u901a\u8fc7\u6c99\u76d2\u5316\u3001\u53ef\u5ba1\u8ba1\u7684\u5de5\u4f5c\u6d41\u7a0b\u5b9e\u73b0\u3002", "result": "\u8be5\u5e73\u53f0\u80fd\u5728\u5236\u5ea6\u7ea6\u675f\u4e0b\u5de5\u4f5c\uff0c\u907f\u514d\u4f9b\u5e94\u5546\u9501\u5b9a\uff0c\u4fdd\u7559\u548c\u63d0\u5347\u516c\u52a1\u5458\u7f16\u7a0b\u6280\u80fd\u3002", "conclusion": "\u6b64\u5e73\u53f0\u586b\u8865\u4e86\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u516c\u5171\u90e8\u95e8\u6280\u80fd\u4fdd\u7559\u3001\u9002\u5e94\u80fd\u529b\u548c\u81ea\u4e0b\u800c\u4e0a\u7684\u6570\u5b57\u5316\u8f6c\u578b\u63d0\u4f9b\u53ef\u590d\u5236\u6a21\u578b\u3002"}}
{"id": "2508.06659", "pdf": "https://arxiv.org/pdf/2508.06659", "abs": "https://arxiv.org/abs/2508.06659", "authors": ["Fernando Martinez-Lopez", "Tao Li", "Yingdong Lu", "Juntao Chen"], "title": "In-Context Reinforcement Learning via Communicative World Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) agents often struggle to generalize to new tasks\nand contexts without updating their parameters, mainly because their learned\nrepresentations and policies are overfit to the specifics of their training\nenvironments. To boost agents' in-context RL (ICRL) ability, this work\nformulates ICRL as a two-agent emergent communication problem and introduces\nCORAL (Communicative Representation for Adaptive RL), a framework that learns a\ntransferable communicative context by decoupling latent representation learning\nfrom control. In CORAL, an Information Agent (IA) is pre-trained as a world\nmodel on a diverse distribution of tasks. Its objective is not to maximize task\nreward, but to build a world model and distill its understanding into concise\nmessages. The emergent communication protocol is shaped by a novel Causal\nInfluence Loss, which measures the effect that the message has on the next\naction. During deployment, the previously trained IA serves as a fixed\ncontextualizer for a new Control Agent (CA), which learns to solve tasks by\ninterpreting the provided communicative context. Our experiments demonstrate\nthat this approach enables the CA to achieve significant gains in sample\nefficiency and successfully perform zero-shot adaptation with the help of\npre-trained IA in entirely unseen sparse-reward environments, validating the\nefficacy of learning a transferable communicative representation.", "AI": {"tldr": "\u4e3a\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u63d0\u51faCORAL\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u53ef\u63d0\u9ad8\u6837\u672c\u6548\u7387\u548c\u5b9e\u73b0\u96f6\u6837\u672c\u9002\u5e94\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u4e0d\u66f4\u65b0\u53c2\u6570\u65f6\u96be\u4ee5\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u548c\u73af\u5883\uff0c\u65e8\u5728\u63d0\u5347\u5176\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u5c06\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u8868\u8ff0\u4e3a\u53cc\u667a\u80fd\u4f53\u901a\u4fe1\u95ee\u9898\uff0c\u5f15\u5165CORAL\u6846\u67b6\uff0c\u4fe1\u606f\u667a\u80fd\u4f53\u9884\u8bad\u7ec3\u6784\u5efa\u4e16\u754c\u6a21\u578b\u5e76\u751f\u6210\u6d88\u606f\uff0c\u56e0\u679c\u5f71\u54cd\u635f\u5931\u5851\u9020\u901a\u4fe1\u534f\u8bae\uff0c\u63a7\u5236\u667a\u80fd\u4f53\u5229\u7528\u6d88\u606f\u89e3\u51b3\u4efb\u52a1\u3002", "result": "\u63a7\u5236\u667a\u80fd\u4f53\u5728\u6837\u672c\u6548\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u80fd\u5728\u672a\u89c1\u7684\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u5b9e\u73b0\u96f6\u6837\u672c\u9002\u5e94\u3002", "conclusion": "\u5b66\u4e60\u53ef\u8fc1\u79fb\u7684\u901a\u4fe1\u8868\u793a\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2508.07473", "pdf": "https://arxiv.org/pdf/2508.07473", "abs": "https://arxiv.org/abs/2508.07473", "authors": ["Zijian Liu"], "title": "Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "Part of this work is in submission", "summary": "In Online Convex Optimization (OCO), when the stochastic gradient has a\nfinite variance, many algorithms provably work and guarantee a sublinear\nregret. However, limited results are known if the gradient estimate has a heavy\ntail, i.e., the stochastic gradient only admits a finite $\\mathsf{p}$-th\ncentral moment for some $\\mathsf{p}\\in\\left(1,2\\right]$. Motivated by it, this\nwork examines different old algorithms for OCO (e.g., Online Gradient Descent)\nin the more challenging heavy-tailed setting. Under the standard bounded domain\nassumption, we establish new regrets for these classical methods without any\nalgorithmic modification. Remarkably, these regret bounds are fully optimal in\nall parameters (can be achieved even without knowing $\\mathsf{p}$), suggesting\nthat OCO with heavy tails can be solved effectively without any extra operation\n(e.g., gradient clipping). Our new results have several applications. A\nparticularly interesting one is the first provable convergence result for\nnonsmooth nonconvex optimization under heavy-tailed noise without gradient\nclipping. Furthermore, we explore broader settings (e.g., smooth OCO) and\nextend our ideas to optimistic algorithms to handle different cases\nsimultaneously.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u7ebf\u51f8\u4f18\u5316\uff08OCO\uff09\u5728\u91cd\u5c3e\u68af\u5ea6\u4f30\u8ba1\u4e0b\u7684\u60c5\u51b5\uff0c\u4e3a\u7ecf\u5178\u7b97\u6cd5\u5efa\u7acb\u65b0\u7684\u540e\u6094\u754c\uff0c\u65e0\u9700\u7b97\u6cd5\u4fee\u6539\uff0c\u7ed3\u679c\u5177\u6709\u591a\u79cd\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u5728\u7ebf\u51f8\u4f18\u5316\u7b97\u6cd5\u5728\u968f\u673a\u68af\u5ea6\u6709\u6709\u9650\u65b9\u5dee\u65f6\u6548\u679c\u597d\uff0c\u4f46\u5728\u68af\u5ea6\u4f30\u8ba1\u4e3a\u91cd\u5c3e\u5206\u5e03\u65f6\u7814\u7a76\u6709\u9650\uff0c\u6545\u5f00\u5c55\u6b64\u9879\u7814\u7a76\u3002", "method": "\u5728\u6807\u51c6\u6709\u754c\u57df\u5047\u8bbe\u4e0b\uff0c\u5bf9\u7ecf\u5178OCO\u7b97\u6cd5\uff08\u5982\u5728\u7ebf\u68af\u5ea6\u4e0b\u964d\uff09\u8fdb\u884c\u7814\u7a76\uff0c\u4e0d\u505a\u7b97\u6cd5\u4fee\u6539\u3002", "result": "\u4e3a\u7ecf\u5178\u65b9\u6cd5\u5efa\u7acb\u65b0\u7684\u540e\u6094\u754c\uff0c\u8fd9\u4e9b\u754c\u5728\u6240\u6709\u53c2\u6570\u4e0a\u662f\u6700\u4f18\u7684\uff0c\u65e0\u9700\u989d\u5916\u64cd\u4f5c\uff1b\u5f97\u5230\u975e\u5149\u6ed1\u975e\u51f8\u4f18\u5316\u5728\u91cd\u5c3e\u566a\u58f0\u4e0b\u65e0\u68af\u5ea6\u88c1\u526a\u7684\u9996\u4e2a\u53ef\u8bc1\u660e\u6536\u655b\u7ed3\u679c\uff1b\u62d3\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u8bbe\u7f6e\u548c\u4e50\u89c2\u7b97\u6cd5\u3002", "conclusion": "\u5728\u7ebf\u51f8\u4f18\u5316\u5728\u91cd\u5c3e\u60c5\u51b5\u4e0b\u53ef\u6709\u6548\u89e3\u51b3\uff0c\u65e0\u9700\u989d\u5916\u64cd\u4f5c\u3002"}}
{"id": "2508.07423", "pdf": "https://arxiv.org/pdf/2508.07423", "abs": "https://arxiv.org/abs/2508.07423", "authors": ["Fotis I. Giasemis"], "title": "Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures", "categories": ["hep-ex", "cs.AI", "cs.DC", "cs.LG", "physics.data-an"], "comment": "PhD thesis, Chapters 8 and 9 include results from work performed in\n  collaboration with Anthony Correia", "summary": "As the particle physics community needs higher and higher precisions in order\nto test our current model of the subatomic world, larger and larger datasets\nare necessary. With upgrades scheduled for the detectors of colliding-beam\nexperiments around the world, and specifically at the Large Hadron Collider at\nCERN, more collisions and more complex interactions are expected. This directly\nimplies an increase in data produced and consequently in the computational\nresources needed to process them. At CERN, the amount of data produced is\ngargantuan. This is why the data have to be heavily filtered and selected in\nreal time before being permanently stored. This data can then be used to\nperform physics analyses, in order to expand our current understanding of the\nuniverse and improve the Standard Model of physics. This real-time filtering,\nknown as triggering, involves complex processing happening often at frequencies\nas high as 40 MHz. This thesis contributes to understanding how machine\nlearning models can be efficiently deployed in such environments, in order to\nmaximize throughput and minimize energy consumption. Inevitably, modern\nhardware designed for such tasks and contemporary algorithms are needed in\norder to meet the challenges posed by the stringent, high-frequency data rates.\nIn this work, I present our graph neural network-based pipeline, developed for\ncharged particle track reconstruction at the LHCb experiment at CERN. The\npipeline was implemented end-to-end inside LHCb's first-level trigger, entirely\non GPUs. Its performance was compared against the classical tracking algorithms\ncurrently in production at LHCb. The pipeline was also accelerated on the FPGA\narchitecture, and its performance in terms of power consumption and processing\nspeed was compared against the GPU implementation.", "AI": {"tldr": "\u7c92\u5b50\u7269\u7406\u9700\u9ad8\u7cbe\u5ea6\uff0c\u4ea7\u751f\u5927\u91cf\u6570\u636e\uff0c\u9700\u5b9e\u65f6\u8fc7\u6ee4\u3002\u672c\u6587\u7814\u7a76\u5982\u4f55\u5728\u8be5\u73af\u5883\u9ad8\u6548\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4ecb\u7ecd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6d41\u6c34\u7ebf\u5e76\u4e0e\u7ecf\u5178\u7b97\u6cd5\u53ca\u4e0d\u540c\u786c\u4ef6\u5b9e\u73b0\u5bf9\u6bd4\u3002", "motivation": "\u7c92\u5b50\u7269\u7406\u5bf9\u7cbe\u5ea6\u8981\u6c42\u63d0\u5347\u4ea7\u751f\u5927\u91cf\u6570\u636e\uff0c\u9700\u5b9e\u65f6\u8fc7\u6ee4\u6570\u636e\uff0c\u8981\u89e3\u51b3\u5982\u4f55\u5728\u8be5\u73af\u5883\u9ad8\u6548\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u63d0\u9ad8\u541e\u5410\u91cf\u548c\u964d\u4f4e\u80fd\u8017\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6d41\u6c34\u7ebf\u7528\u4e8eCERN\u7684LHCb\u5b9e\u9a8c\u7684\u5e26\u7535\u7c92\u5b50\u8f68\u8ff9\u91cd\u5efa\uff0c\u5728GPU\u4e0a\u5b9e\u73b0\u7aef\u5230\u7aef\u6d41\u7a0b\uff0c\u8fd8\u5728FPGA\u67b6\u6784\u4e0a\u8fdb\u884c\u52a0\u901f\u3002", "result": "\u5c06\u8be5\u6d41\u6c34\u7ebf\u4e0eLHCb\u5f53\u524d\u4f7f\u7528\u7684\u7ecf\u5178\u8ddf\u8e2a\u7b97\u6cd5\u5bf9\u6bd4\uff0c\u6bd4\u8f83\u4e86FPGA\u548cGPU\u5b9e\u73b0\u7684\u529f\u8017\u548c\u5904\u7406\u901f\u5ea6\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\uff0c\u4f46\u65e8\u5728\u5c55\u793a\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6d41\u6c34\u7ebf\u5728\u8be5\u573a\u666f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4ee5\u63a2\u7d22\u9ad8\u6548\u5904\u7406\u6570\u636e\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.06894", "pdf": "https://arxiv.org/pdf/2508.06894", "abs": "https://arxiv.org/abs/2508.06894", "authors": ["Giovanni Varricchione", "Toryn Q. Klassen", "Natasha Alechina", "Mehdi Dastani", "Brian Logan", "Sheila A. McIlraith"], "title": "Pushdown Reward Machines for Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "68T05"], "comment": null, "summary": "Reward machines (RMs) are automata structures that encode (non-Markovian)\nreward functions for reinforcement learning (RL). RMs can reward any behaviour\nrepresentable in regular languages and, when paired with RL algorithms that\nexploit RM structure, have been shown to significantly improve sample\nefficiency in many domains. In this work, we present pushdown reward machines\n(pdRMs), an extension of reward machines based on deterministic pushdown\nautomata. pdRMs can recognize and reward temporally extended behaviours\nrepresentable in deterministic context-free languages, making them more\nexpressive than reward machines. We introduce two variants of pdRM-based\npolicies, one which has access to the entire stack of the pdRM, and one which\ncan only access the top $k$ symbols (for a given constant $k$) of the stack. We\npropose a procedure to check when the two kinds of policies (for a given\nenvironment, pdRM, and constant $k$) achieve the same optimal expected reward.\nWe then provide theoretical results establishing the expressive power of pdRMs,\nand space complexity results about the proposed learning problems. Finally, we\nprovide experimental results showing how agents can be trained to perform tasks\nrepresentable in deterministic context-free languages using pdRMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e0b\u63a8\u5956\u52b1\u673a\u5668\uff08pdRMs\uff09\uff0c\u4ecb\u7ecd\u57fa\u4e8epdRM\u7684\u4e24\u79cd\u7b56\u7565\uff0c\u7ed9\u51fa\u68c0\u67e5\u7b56\u7565\u83b7\u5f97\u76f8\u540c\u6700\u4f18\u671f\u671b\u5956\u52b1\u7684\u65b9\u6cd5\uff0c\u63d0\u4f9b\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u5956\u52b1\u673a\u5668\uff08RMs\uff09\u53ea\u80fd\u5956\u52b1\u6b63\u5219\u8bed\u8a00\u8868\u793a\u7684\u884c\u4e3a\uff0c\u4e3a\u4e86\u80fd\u8bc6\u522b\u548c\u5956\u52b1\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u8868\u793a\u7684\u884c\u4e3a\uff0c\u63d0\u51fapdRMs\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u786e\u5b9a\u6027\u4e0b\u63a8\u81ea\u52a8\u673a\u7684pdRMs\uff0c\u5f15\u5165\u4e24\u79cd\u57fa\u4e8epdRM\u7684\u7b56\u7565\uff0c\u7ed9\u51fa\u68c0\u67e5\u7b56\u7565\u83b7\u5f97\u76f8\u540c\u6700\u4f18\u671f\u671b\u5956\u52b1\u7684\u7a0b\u5e8f\u3002", "result": "\u63d0\u4f9b\u4e86pdRMs\u8868\u8fbe\u80fd\u529b\u7684\u7406\u8bba\u7ed3\u679c\u548c\u5b66\u4e60\u95ee\u9898\u7684\u7a7a\u95f4\u590d\u6742\u5ea6\u7ed3\u679c\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u4f7f\u7528pdRMs\u8bad\u7ec3\u667a\u80fd\u4f53\u5b8c\u6210\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u8868\u793a\u7684\u4efb\u52a1\u3002", "conclusion": "pdRMs\u6bd4\u5956\u52b1\u673a\u5668\u66f4\u5177\u8868\u8fbe\u80fd\u529b\uff0c\u53ef\u7528\u4e8e\u8bad\u7ec3\u667a\u80fd\u4f53\u5b8c\u6210\u66f4\u590d\u6742\u7684\u4efb\u52a1\u3002"}}
{"id": "2508.08042", "pdf": "https://arxiv.org/pdf/2508.08042", "abs": "https://arxiv.org/abs/2508.08042", "authors": ["Van-Khang Nguyen", "Duc-Hoang Pham", "Huy-Son Nguyen", "Cam-Van Thi Nguyen", "Hoang-Quynh Le", "Duc-Trong Le"], "title": "Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Recommendation systems have faced significant challenges in cold-start\nscenarios, where new items with a limited history of interaction need to be\neffectively recommended to users. Though multimodal data (e.g., images, text,\naudio, etc.) offer rich information to address this issue, existing approaches\noften employ simplistic integration methods such as concatenation, average\npooling, or fixed weighting schemes, which fail to capture the complex\nrelationships between modalities. Our study proposes a novel Mixture of Experts\n(MoE) framework for multimodal cold-start recommendation, named MAMEX, which\ndynamically leverages latent representation from different modalities. MAMEX\nutilizes modality-specific expert networks and introduces a learnable gating\nmechanism that adaptively weights the contribution of each modality based on\nits content characteristics. This approach enables MAMEX to emphasize the most\ninformative modalities for each item while maintaining robustness when certain\nmodalities are less relevant or missing. Extensive experiments on benchmark\ndatasets show that MAMEX outperforms state-of-the-art methods in cold-start\nscenarios, with superior accuracy and adaptability. For reproducibility, the\ncode has been made available on Github https://github.com/L2R-UET/MAMEX.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faMAMEX\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u51b7\u542f\u52a8\u63a8\u8350\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u51b7\u542f\u52a8\u63a8\u8350\u65b9\u6cd5\u96c6\u6210\u65b9\u5f0f\u7b80\u5355\uff0c\u65e0\u6cd5\u6355\u6349\u6a21\u6001\u95f4\u590d\u6742\u5173\u7cfb\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u51b7\u542f\u52a8\u6311\u6218\u3002", "method": "\u63d0\u51faMAMEX\u6846\u67b6\uff0c\u5229\u7528\u7279\u5b9a\u6a21\u6001\u4e13\u5bb6\u7f51\u7edc\u548c\u53ef\u5b66\u4e60\u95e8\u63a7\u673a\u5236\uff0c\u6839\u636e\u5185\u5bb9\u7279\u5f81\u81ea\u9002\u5e94\u52a0\u6743\u5404\u6a21\u6001\u8d21\u732e\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cMAMEX\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MAMEX\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u51b7\u542f\u52a8\u63a8\u8350\u95ee\u9898\uff0c\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.07468", "pdf": "https://arxiv.org/pdf/2508.07468", "abs": "https://arxiv.org/abs/2508.07468", "authors": ["Stefan Szeider"], "title": "CP-Agent: Agentic Constraint Programming", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "Translating natural language problem descriptions into formal constraint\nmodels remains a fundamental challenge in constraint programming, requiring\ndeep expertise in both the problem domain and modeling frameworks. Previous\napproaches to automating this translation have employed fixed workflows with\npredetermined modeling steps, failing on a significant number of benchmark\nproblems. We present a new approach using a pure agentic strategy without any\nfixed pipeline. We developed a general-purpose Python coding agent based on the\nReAct (Reason and Act) principle, utilizing a persistent IPython kernel for\nstateful code execution and iterative development. Rather than embedding\nconstraint programming logic into the agent architecture, domain-specific\nexpertise is injected solely through a carefully crafted project prompt. The\nagent combines this prompt-encoded knowledge with access to file operations and\ncode execution tools, enabling it to test hypotheses, debug failures, and\nverify solutions dynamically. Implemented in just a few hundred lines of code,\nthis architecture successfully solves all 101 problems of the CP-Bench\nconstraint programming benchmark set. The results suggest that constraint\nmodeling tasks require the combination of general coding tools and domain\nexpertise encoded in prompts, rather than specialized agent architectures or\npredefined workflows.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u56fa\u5b9a\u6d41\u7a0b\u7684\u7eaf\u4ee3\u7406\u7b56\u7565\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u5230\u7ea6\u675f\u6a21\u578b\u7684\u7ffb\u8bd1\u95ee\u9898\uff0c\u5b9e\u73b0\u4ee3\u7801\u5c11\u4e14\u89e3\u51b3\u57fa\u51c6\u96c6\u6240\u6709\u95ee\u9898\u3002", "motivation": "\u4ee5\u5f80\u81ea\u52a8\u5316\u7ffb\u8bd1\u65b9\u6cd5\u91c7\u7528\u56fa\u5b9a\u5de5\u4f5c\u6d41\uff0c\u5728\u5927\u91cf\u57fa\u51c6\u95ee\u9898\u4e0a\u5931\u8d25\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eReAct\u539f\u5219\u5f00\u53d1\u901a\u7528Python\u7f16\u7801\u4ee3\u7406\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9879\u76ee\u63d0\u793a\u6ce8\u5165\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u7ed3\u5408\u6587\u4ef6\u64cd\u4f5c\u548c\u4ee3\u7801\u6267\u884c\u5de5\u5177\u52a8\u6001\u6d4b\u8bd5\u3001\u8c03\u8bd5\u548c\u9a8c\u8bc1\u3002", "result": "\u7528\u51e0\u767e\u884c\u4ee3\u7801\u5b9e\u73b0\u7684\u67b6\u6784\u6210\u529f\u89e3\u51b3CP - Bench\u7ea6\u675f\u7f16\u7a0b\u57fa\u51c6\u96c6\u7684101\u4e2a\u95ee\u9898\u3002", "conclusion": "\u7ea6\u675f\u5efa\u6a21\u4efb\u52a1\u9700\u7ed3\u5408\u901a\u7528\u7f16\u7801\u5de5\u5177\u548c\u63d0\u793a\u4e2d\u7f16\u7801\u7684\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u800c\u975e\u4e13\u95e8\u7684\u4ee3\u7406\u67b6\u6784\u6216\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2508.06663", "pdf": "https://arxiv.org/pdf/2508.06663", "abs": "https://arxiv.org/abs/2508.06663", "authors": ["Yuan-Hung Chao", "Chia-Hsun Lu", "Chih-Ya Shen"], "title": "Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks", "categories": ["cs.LG"], "comment": "6 pages, 3 tables", "summary": "Graph Neural Networks (GNNs) have shown strong performance on\ngraph-structured data, but their reliance on graph connectivity often limits\nscalability and efficiency. Kolmogorov-Arnold Networks (KANs), a recent\narchitecture with learnable univariate functions, offer strong nonlinear\nexpressiveness and efficient inference. In this work, we integrate KANs into\nthree popular GNN architectures-GAT, SGC, and APPNP-resulting in three new\nmodels: KGAT, KSGC, and KAPPNP. We further adopt a multi-teacher knowledge\namalgamation framework, where knowledge from multiple KAN-based GNNs is\ndistilled into a graph-independent KAN student model. Experiments on benchmark\ndatasets show that the proposed models improve node classification accuracy,\nand the knowledge amalgamation approach significantly boosts student model\nperformance. Our findings highlight the potential of KANs for enhancing GNN\nexpressiveness and for enabling efficient, graph-free inference.", "AI": {"tldr": "\u672c\u6587\u5c06KANs\u96c6\u6210\u5230\u4e09\u79cd\u6d41\u884cGNN\u67b6\u6784\u4e2d\u5f97\u5230\u65b0\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u591a\u6559\u5e08\u77e5\u8bc6\u878d\u5408\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u65b0\u6a21\u578b\u63d0\u5347\u4e86\u8282\u70b9\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u77e5\u8bc6\u878d\u5408\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5b66\u751f\u6a21\u578b\u6027\u80fd\u3002", "motivation": "GNN\u4f9d\u8d56\u56fe\u8fde\u63a5\u6027\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\uff0c\u800cKANs\u6709\u5f3a\u975e\u7ebf\u6027\u8868\u8fbe\u80fd\u529b\u548c\u9ad8\u6548\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u60f3\u5c06KANs\u96c6\u6210\u5230GNN\u4e2d\u63d0\u5347\u6027\u80fd\u3002", "method": "\u5c06KANs\u96c6\u6210\u5230GAT\u3001SGC\u548cAPPNP\u4e09\u79cdGNN\u67b6\u6784\u4e2d\u5f97\u5230KGAT\u3001KSGC\u548cKAPPNP\uff1b\u91c7\u7528\u591a\u6559\u5e08\u77e5\u8bc6\u878d\u5408\u6846\u67b6\uff0c\u5c06\u591a\u4e2a\u57fa\u4e8eKAN\u7684GNN\u77e5\u8bc6\u63d0\u70bc\u5230\u65e0\u56feKAN\u5b66\u751f\u6a21\u578b\u4e2d\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u63d0\u9ad8\u4e86\u8282\u70b9\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u77e5\u8bc6\u878d\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5b66\u751f\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "KANs\u6709\u589e\u5f3aGNN\u8868\u8fbe\u80fd\u529b\u548c\u5b9e\u73b0\u9ad8\u6548\u65e0\u56fe\u63a8\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.07490", "pdf": "https://arxiv.org/pdf/2508.07490", "abs": "https://arxiv.org/abs/2508.07490", "authors": ["Ricardo Matos", "Luis Roque", "Vitor Cerqueira"], "title": "N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Deep learning approaches are increasingly relevant for time series\nforecasting tasks. Methods such as N-BEATS, which is built on stacks of\nmultilayer perceptrons (MLPs) blocks, have achieved state-of-the-art results on\nbenchmark datasets and competitions. N-BEATS is also more interpretable\nrelative to other deep learning approaches, as it decomposes forecasts into\ndifferent time series components, such as trend and seasonality. In this work,\nwe present N-BEATS-MOE, an extension of N-BEATS based on a Mixture-of-Experts\n(MoE) layer. N-BEATS-MOE employs a dynamic block weighting strategy based on a\ngating network which allows the model to better adapt to the characteristics of\neach time series. We also hypothesize that the gating mechanism provides\nadditional interpretability by identifying which expert is most relevant for\neach series. We evaluate our method across 12 benchmark datasets against\nseveral approaches, achieving consistent improvements on several datasets,\nespecially those composed of heterogeneous time series.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eMixture - of - Experts\u5c42\u7684N - BEATS\u6269\u5c55\u6a21\u578bN - BEATS - MOE\uff0c\u8bc4\u4f30\u663e\u793a\u5728\u591a\u4e2a\u6570\u636e\u96c6\u6709\u6539\u8fdb\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u6a21\u578b\u66f4\u597d\u9002\u5e94\u5404\u65f6\u95f4\u5e8f\u5217\u7279\u5f81\uff0c\u5e76\u589e\u52a0\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faN - BEATS - MOE\uff0c\u91c7\u7528\u57fa\u4e8e\u95e8\u63a7\u7f51\u7edc\u7684\u52a8\u6001\u5757\u52a0\u6743\u7b56\u7565\u3002", "result": "\u572812\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u5c24\u5176\u662f\u5f02\u8d28\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u6709\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "N - BEATS - MOE\u80fd\u66f4\u597d\u9002\u5e94\u65f6\u95f4\u5e8f\u5217\u7279\u5f81\uff0c\u95e8\u63a7\u673a\u5236\u53ef\u80fd\u589e\u52a0\u53ef\u89e3\u91ca\u6027\uff0c\u4e14\u5728\u591a\u4e2a\u6570\u636e\u96c6\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2508.07505", "pdf": "https://arxiv.org/pdf/2508.07505", "abs": "https://arxiv.org/abs/2508.07505", "authors": ["Yueyang Quan", "Chang Wang", "Shengjie Zhai", "Minghong Fang", "Zhuqing Liu"], "title": "Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": "To appear in ACM MobiHoc 2025", "summary": "Decentralized min-max optimization allows multi-agent systems to\ncollaboratively solve global min-max optimization problems by facilitating the\nexchange of model updates among neighboring agents, eliminating the need for a\ncentral server. However, sharing model updates in such systems carry a risk of\nexposing sensitive data to inference attacks, raising significant privacy\nconcerns. To mitigate these privacy risks, differential privacy (DP) has become\na widely adopted technique for safeguarding individual data. Despite its\nadvantages, implementing DP in decentralized min-max optimization poses\nchallenges, as the added noise can hinder convergence, particularly in\nnon-convex scenarios with complex agent interactions in min-max optimization\nproblems. In this work, we propose an algorithm called DPMixSGD (Differential\nPrivate Minmax Hybrid Stochastic Gradient Descent), a novel privacy-preserving\nalgorithm specifically designed for non-convex decentralized min-max\noptimization. Our method builds on the state-of-the-art STORM-based algorithm,\none of the fastest decentralized min-max solutions. We rigorously prove that\nthe noise added to local gradients does not significantly compromise\nconvergence performance, and we provide theoretical bounds to ensure privacy\nguarantees. To validate our theoretical findings, we conduct extensive\nexperiments across various tasks and models, demonstrating the effectiveness of\nour approach.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u975e\u51f8\u53bb\u4e2d\u5fc3\u5316\u6700\u5c0f - \u6700\u5927\u4f18\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u7b97\u6cd5DPMixSGD\uff0c\u8bc1\u660e\u566a\u58f0\u4e0d\u5f71\u54cd\u6536\u655b\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u6700\u5c0f - \u6700\u5927\u4f18\u5316\u5171\u4eab\u6a21\u578b\u66f4\u65b0\u6709\u9690\u79c1\u98ce\u9669\uff0c\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u5728\u5176\u4e2d\u5b9e\u65bd\u6709\u6536\u655b\u95ee\u9898\u3002", "method": "\u57fa\u4e8eSTORM\u7b97\u6cd5\u63d0\u51faDPMixSGD\u7b97\u6cd5\uff0c\u8bc1\u660e\u6dfb\u52a0\u566a\u58f0\u4e0d\u5f71\u54cd\u6536\u655b\u6027\u80fd\u5e76\u7ed9\u51fa\u9690\u79c1\u4fdd\u8bc1\u7406\u8bba\u754c\u9650\u3002", "result": "\u901a\u8fc7\u591a\u4efb\u52a1\u548c\u591a\u6a21\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "DPMixSGD\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u975e\u51f8\u53bb\u4e2d\u5fc3\u5316\u6700\u5c0f - \u6700\u5927\u4f18\u5316\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u6536\u655b\u95ee\u9898\u3002"}}
{"id": "2508.06899", "pdf": "https://arxiv.org/pdf/2508.06899", "abs": "https://arxiv.org/abs/2508.06899", "authors": ["Yanchen Deng", "Xinrun Wang", "Bo An"], "title": "GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization", "categories": ["cs.AI", "cs.DM"], "comment": null, "summary": "Local search is an important class of incomplete algorithms for solving\nDistributed Constraint Optimization Problems (DCOPs) but it often converges to\npoor local optima. While GDBA provides a comprehensive rule set to escape\npremature convergence, its empirical benefits remain marginal on general-valued\nproblems. In this work, we systematically examine GDBA and identify three\nfactors that potentially lead to its inferior performance, i.e.,\nover-aggressive constraint violation conditions, unbounded penalty\naccumulation, and uncoordinated penalty updates. To address these issues, we\npropose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs\nthat incorporates an adaptive violation condition to selectively penalize\nconstraints with high cost, a penalty evaporation mechanism to control the\nmagnitude of penalization, and a synchronization scheme for coordinated penalty\nupdates. We theoretically show that the penalty values are bounded, and agents\nplay a potential game in our DGLS. Our extensive empirical results on various\nstandard benchmarks demonstrate the great superiority of DGLS over\nstate-of-the-art baselines. Particularly, compared to Damped Max-sum with high\ndamping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance\non general-valued problems, and outperforms it by significant margins\n(\\textbf{3.77\\%--66.3\\%}) on structured problems in terms of anytime results.", "AI": {"tldr": "\u672c\u6587\u6307\u51faGDBA\u5728\u89e3\u51b3DCOPs\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\uff0c\u63d0\u51faDGLS\u6846\u67b6\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u7279\u6027\uff0c\u5b9e\u9a8c\u663e\u793aDGLS\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u5e38\u6536\u655b\u5230\u8f83\u5dee\u5c40\u90e8\u6700\u4f18\uff0cGDBA\u5728\u4e00\u822c\u503c\u95ee\u9898\u4e0a\u6539\u8fdb\u6548\u679c\u6709\u9650\uff0c\u9700\u6539\u8fdb\u7b97\u6cd5\u6027\u80fd\u3002", "method": "\u63d0\u51faDGLS\u6846\u67b6\uff0c\u5305\u542b\u81ea\u9002\u5e94\u8fdd\u89c4\u6761\u4ef6\u3001\u60e9\u7f5a\u84b8\u53d1\u673a\u5236\u548c\u540c\u6b65\u65b9\u6848\u3002", "result": "\u7406\u8bba\u8bc1\u660eDGLS\u4e2d\u60e9\u7f5a\u503c\u6709\u754c\uff0c\u4ee3\u7406\u53c2\u4e0e\u6f5c\u5728\u535a\u5f08\uff1b\u5b9e\u9a8c\u8868\u660eDGLS\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u7ed3\u6784\u5316\u95ee\u9898\u4e0a\u663e\u8457\u8d85\u8d8aDamped Max - sum\u3002", "conclusion": "DGLS\u662f\u89e3\u51b3DCOPs\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5177\u6709\u5f88\u5927\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.08088", "pdf": "https://arxiv.org/pdf/2508.08088", "abs": "https://arxiv.org/abs/2508.08088", "authors": ["Jiejun Tan", "Zhicheng Dou", "Yan Yu", "Jiehan Cheng", "Qiang Ju", "Jian Xie", "Ji-Rong Wen"], "title": "HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "Code and datasets are available at\n  https://github.com/plageon/HierSearch", "summary": "Recently, large reasoning models have demonstrated strong mathematical and\ncoding abilities, and deep search leverages their reasoning capabilities in\nchallenging information retrieval tasks. Existing deep search works are\ngenerally limited to a single knowledge source, either local or the Web.\nHowever, enterprises often require private deep search systems that can\nleverage search tools over both local and the Web corpus. Simply training an\nagent equipped with multiple search tools using flat reinforcement learning\n(RL) is a straightforward idea, but it has problems such as low training data\nefficiency and poor mastery of complex tools. To address the above issue, we\npropose a hierarchical agentic deep search framework, HierSearch, trained with\nhierarchical RL. At the low level, a local deep search agent and a Web deep\nsearch agent are trained to retrieve evidence from their corresponding domains.\nAt the high level, a planner agent coordinates low-level agents and provides\nthe final answer. Moreover, to prevent direct answer copying and error\npropagation, we design a knowledge refiner that filters out hallucinations and\nirrelevant evidence returned by low-level agents. Experiments show that\nHierSearch achieves better performance compared to flat RL, and outperforms\nvarious deep search and multi-source retrieval-augmented generation baselines\nin six benchmarks across general, finance, and medical domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5206\u5c42\u4ee3\u7406\u6df1\u5ea6\u641c\u7d22\u6846\u67b6HierSearch\u4ee5\u89e3\u51b3\u73b0\u6709\u5355\u6e90\u6df1\u5ea6\u641c\u7d22\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u6241\u5e73\u5f3a\u5316\u5b66\u4e60\u53ca\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u641c\u7d22\u5c40\u9650\u4e8e\u5355\u4e00\u77e5\u8bc6\u6e90\uff0c\u4f01\u4e1a\u9700\u8981\u80fd\u5229\u7528\u672c\u5730\u548c\u7f51\u7edc\u8bed\u6599\u7684\u79c1\u6709\u6df1\u5ea6\u641c\u7d22\u7cfb\u7edf\uff0c\u800c\u7b80\u5355\u7684\u6241\u5e73\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5b58\u5728\u6570\u636e\u6548\u7387\u4f4e\u548c\u5de5\u5177\u638c\u63e1\u5dee\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faHierSearch\u6846\u67b6\uff0c\u7528\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5e95\u5c42\u6709\u672c\u5730\u548c\u7f51\u7edc\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\uff0c\u9ad8\u5c42\u6709\u89c4\u5212\u4ee3\u7406\u534f\u8c03\u5e76\u7ed9\u51fa\u6700\u7ec8\u7b54\u6848\uff0c\u8fd8\u8bbe\u8ba1\u77e5\u8bc6\u7cbe\u70bc\u5668\u8fc7\u6ee4\u65e0\u5173\u8bc1\u636e\u3002", "result": "HierSearch\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u6241\u5e73\u5f3a\u5316\u5b66\u4e60\u548c\u591a\u79cd\u6df1\u5ea6\u641c\u7d22\u53ca\u591a\u6e90\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "HierSearch\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6df1\u5ea6\u641c\u7d22\u95ee\u9898\uff0c\u5728\u591a\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2508.07745", "pdf": "https://arxiv.org/pdf/2508.07745", "abs": "https://arxiv.org/abs/2508.07745", "authors": ["Jiongchi Yu", "Xiaofei Xie", "Qiang Hu", "Yuhan Ma", "Ziming Zhao"], "title": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": "23 pages", "summary": "Insider threats, which can lead to severe losses, remain a major security\nconcern. While machine learning-based insider threat detection (ITD) methods\nhave shown promising results, their progress is hindered by the scarcity of\nhigh-quality data. Enterprise data is sensitive and rarely accessible, while\npublicly available datasets, when limited in scale due to cost, lack sufficient\nreal-world coverage; and when purely synthetic, they fail to capture rich\nsemantics and realistic user behavior. To address this, we propose Chimera, the\nfirst large language model (LLM)-based multi-agent framework that automatically\nsimulates both benign and malicious insider activities and collects diverse\nlogs across diverse enterprise environments. Chimera models each employee with\nagents that have role-specific behavior and integrates modules for group\nmeetings, pairwise interactions, and autonomous scheduling, capturing realistic\norganizational dynamics. It incorporates 15 types of insider attacks (e.g., IP\ntheft, system sabotage) and has been deployed to simulate activities in three\nsensitive domains: technology company, finance corporation, and medical\ninstitution, producing a new dataset, ChimeraLog. We assess ChimeraLog via\nhuman studies and quantitative analysis, confirming its diversity, realism, and\npresence of explainable threat patterns. Evaluations of existing ITD methods\nshow an average F1-score of 0.83, which is significantly lower than 0.99 on the\nCERT dataset, demonstrating ChimeraLog's higher difficulty and utility for\nadvancing ITD research.", "AI": {"tldr": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u65b9\u6cd5\u53d7\u9ad8\u8d28\u91cf\u6570\u636e\u7a00\u7f3a\u963b\u788d\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6Chimera\u6a21\u62df\u6d3b\u52a8\u5e76\u751f\u6210\u6570\u636e\u96c6ChimeraLog\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6709\u66f4\u9ad8\u96be\u5ea6\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u65b9\u6cd5\u56e0\u9ad8\u8d28\u91cf\u6570\u636e\u7a00\u7f3a\u800c\u8fdb\u5c55\u53d7\u963b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faChimera\u6846\u67b6\uff0c\u7528\u6709\u7279\u5b9a\u89d2\u8272\u884c\u4e3a\u7684\u667a\u80fd\u4f53\u6a21\u62df\u5458\u5de5\uff0c\u96c6\u6210\u591a\u79cd\u6a21\u5757\uff0c\u5305\u542b15\u79cd\u5185\u90e8\u653b\u51fb\u7c7b\u578b\uff0c\u5728\u4e09\u4e2a\u654f\u611f\u9886\u57df\u6a21\u62df\u6d3b\u52a8\u751f\u6210ChimeraLog\u3002", "result": "\u901a\u8fc7\u4eba\u7c7b\u7814\u7a76\u548c\u5b9a\u91cf\u5206\u6790\u786e\u8ba4ChimeraLog\u7684\u591a\u6837\u6027\u3001\u771f\u5b9e\u6027\u548c\u53ef\u89e3\u91ca\u5a01\u80c1\u6a21\u5f0f\uff0c\u73b0\u6709ITD\u65b9\u6cd5\u5728ChimeraLog\u4e0aF1\u5206\u6570\u5e73\u5747\u4e3a0.83\uff0c\u4f4e\u4e8e\u5728CERT\u6570\u636e\u96c6\u4e0a\u76840.99\u3002", "conclusion": "ChimeraLog\u6709\u66f4\u9ad8\u96be\u5ea6\u548c\u5b9e\u7528\u6027\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u7814\u7a76\u3002"}}
{"id": "2508.06676", "pdf": "https://arxiv.org/pdf/2508.06676", "abs": "https://arxiv.org/abs/2508.06676", "authors": ["Chia-Hsun Lu", "Guan-Jhih Wu", "Ya-Chi Ho", "Chih-Ya Shen"], "title": "Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation", "categories": ["cs.LG"], "comment": "6 pages, 3 figures, 6 tables", "summary": "With the increasing importance of protecting intellectual property in machine\nlearning, watermarking techniques have gained significant attention. As\nadvanced models are increasingly deployed in domains such as social network\nanalysis, the need for robust model protection becomes even more critical.\nWhile existing watermarking methods have demonstrated effectiveness for\nconventional deep neural networks, they often fail to adapt to the novel\narchitecture, Kolmogorov-Arnold Networks (KAN), which feature learnable\nactivation functions. KAN holds strong potential for modeling complex\nrelationships in network-structured data. However, their unique design also\nintroduces new challenges for watermarking. Therefore, we propose a novel\nwatermarking method, Discrete Cosine Transform-based Activation Watermarking\n(DCT-AW), tailored for KAN. Leveraging the learnable activation functions of\nKAN, our method embeds watermarks by perturbing activation outputs using\ndiscrete cosine transform, ensuring compatibility with diverse tasks and\nachieving task independence. Experimental results demonstrate that DCT-AW has a\nsmall impact on model performance and provides superior robustness against\nvarious watermark removal attacks, including fine-tuning, pruning, and\nretraining after pruning.", "AI": {"tldr": "\u9488\u5bf9Kolmogorov - Arnold Networks (KAN)\u63d0\u51fa\u79bb\u6563\u4f59\u5f26\u53d8\u6362\u6fc0\u6d3b\u6c34\u5370\u65b9\u6cd5DCT - AW\uff0c\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u5c0f\u4e14\u6297\u653b\u51fb\u80fd\u529b\u5f3a\u3002", "motivation": "\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8eKAN\uff0c\u800cKAN\u5728\u7f51\u7edc\u7ed3\u6784\u6570\u636e\u5efa\u6a21\u6709\u6f5c\u529b\uff0c\u9700\u65b0\u6c34\u5370\u65b9\u6cd5\u4fdd\u62a4\u5176\u77e5\u8bc6\u4ea7\u6743\u3002", "method": "\u63d0\u51faDCT - AW\u65b9\u6cd5\uff0c\u5229\u7528KAN\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\uff0c\u901a\u8fc7\u79bb\u6563\u4f59\u5f26\u53d8\u6362\u6270\u52a8\u6fc0\u6d3b\u8f93\u51fa\u6765\u5d4c\u5165\u6c34\u5370\u3002", "result": "DCT - AW\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u5c0f\uff0c\u5728\u5bf9\u6297\u5fae\u8c03\u3001\u526a\u679d\u548c\u526a\u679d\u540e\u518d\u8bad\u7ec3\u7b49\u6c34\u5370\u53bb\u9664\u653b\u51fb\u65f6\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "DCT - AW\u9002\u7528\u4e8eKAN\uff0c\u80fd\u6709\u6548\u4fdd\u62a4\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\uff0c\u5177\u6709\u826f\u597d\u7684\u517c\u5bb9\u6027\u548c\u6297\u653b\u51fb\u80fd\u529b\u3002"}}
{"id": "2508.07495", "pdf": "https://arxiv.org/pdf/2508.07495", "abs": "https://arxiv.org/abs/2508.07495", "authors": ["Agus Sudjianto", "Alice J. Liu"], "title": "Decomposing Global AUC into Cluster-Level Contributions for Localized Model Diagnostics", "categories": ["stat.AP", "stat.ML"], "comment": null, "summary": "The Area Under the ROC Curve (AUC) is a widely used performance metric for\nbinary classifiers. However, as a global ranking statistic, the AUC aggregates\nmodel behavior over the entire dataset, masking localized weaknesses in\nspecific subpopulations. In high-stakes applications such as credit approval\nand fraud detection, these weaknesses can lead to financial risk or operational\nfailures. In this paper, we introduce a formal decomposition of global AUC into\nintra- and inter-cluster components. This allows practitioners to evaluate\nclassifier performance within and across clusters of data, enabling granular\ndiagnostics and subgroup analysis. We also compare the AUC with additive\nperformance metrics such as the Brier score and log loss, which support\ndecomposability and direct attribution. Our framework enhances model\ndevelopment and validation practice by providing additional insights to detect\nmodel weakness for model risk management.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u5168\u5c40AUC\u5206\u89e3\u4e3a\u7c07\u5185\u548c\u7c07\u95f4\u7ec4\u4ef6\uff0c\u8fd8\u5bf9\u6bd4AUC\u4e0e\u5176\u4ed6\u53ef\u5206\u89e3\u6307\u6807\uff0c\u4e3a\u6a21\u578b\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "AUC\u4f5c\u4e3a\u5168\u5c40\u6392\u540d\u7edf\u8ba1\u91cf\u4f1a\u63a9\u76d6\u7279\u5b9a\u5b50\u7fa4\u4f53\u7684\u5c40\u90e8\u5f31\u70b9\uff0c\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u53ef\u80fd\u5bfc\u81f4\u8d22\u52a1\u98ce\u9669\u6216\u8fd0\u8425\u5931\u8d25\u3002", "method": "\u5c06\u5168\u5c40AUC\u5f62\u5f0f\u5206\u89e3\u4e3a\u7c07\u5185\u548c\u7c07\u95f4\u7ec4\u4ef6\uff0c\u5e76\u5bf9\u6bd4AUC\u4e0e\u53ef\u5206\u89e3\u7684\u6307\u6807\u5982Brier\u5206\u6570\u548c\u5bf9\u6570\u635f\u5931\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u6570\u636e\u7c07\u5185\u548c\u7c07\u95f4\u5206\u7c7b\u5668\u6027\u80fd\u7684\u8bc4\u4f30\uff0c\u53ef\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bca\u65ad\u548c\u5b50\u7ec4\u5206\u6790\u3002", "conclusion": "\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u989d\u5916\u89c1\u89e3\u6765\u68c0\u6d4b\u6a21\u578b\u5f31\u70b9\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u5f00\u53d1\u548c\u9a8c\u8bc1\u5b9e\u8df5\u3002"}}
{"id": "2508.06931", "pdf": "https://arxiv.org/pdf/2508.06931", "abs": "https://arxiv.org/abs/2508.06931", "authors": ["Wangyue Lu", "Lun Du", "Sirui Li", "Ke Weng", "Haozhe Sun", "Hengyu Liu", "Minghe Yu", "Tiancheng Zhang", "Ge Yu"], "title": "Automated Formalization via Conceptual Retrieval-Augmented LLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Interactive theorem provers (ITPs) require manual formalization, which is\nlabor-intensive and demands expert knowledge. While automated formalization\noffers a potential solution, it faces two major challenges: model hallucination\n(e.g., undefined predicates, symbol misuse, and version incompatibility) and\nthe semantic gap caused by ambiguous or missing premises in natural language\ndescriptions. To address these issues, we propose CRAMF, a Concept-driven\nRetrieval-Augmented Mathematical Formalization framework. CRAMF enhances\nLLM-based autoformalization by retrieving formal definitions of core\nmathematical concepts, providing contextual grounding during code generation.\nHowever, applying retrieval-augmented generation (RAG) in this setting is\nnon-trivial due to the lack of structured knowledge bases, the polymorphic\nnature of mathematical concepts, and the high precision required in formal\nretrieval. We introduce a framework for automatically constructing a\nconcept-definition knowledge base from Mathlib4, the standard mathematical\nlibrary for the Lean 4 theorem prover, indexing over 26,000 formal definitions\nand 1,000+ core mathematical concepts. To address conceptual polymorphism, we\npropose contextual query augmentation with domain- and application-level\nsignals. In addition, we design a dual-channel hybrid retrieval strategy with\nreranking to ensure accurate and relevant definition retrieval. Experiments on\nminiF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that\nCRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding\nconsistent improvements in translation accuracy, achieving up to 62.1% and an\naverage of 29.9% relative improvement.", "AI": {"tldr": "\u9488\u5bf9\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u5668\u624b\u52a8\u5f62\u5f0f\u5316\u96be\u9898\uff0c\u63d0\u51faCRAMF\u6846\u67b6\uff0c\u6784\u5efa\u77e5\u8bc6\u5e93\u3001\u89e3\u51b3\u6982\u5ff5\u591a\u6001\u95ee\u9898\u5e76\u8bbe\u8ba1\u68c0\u7d22\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u63d0\u5347\u7ffb\u8bd1\u51c6\u786e\u7387\u3002", "motivation": "\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u5668\u624b\u52a8\u5f62\u5f0f\u5316\u52b3\u52a8\u5bc6\u96c6\u4e14\u9700\u4e13\u4e1a\u77e5\u8bc6\uff0c\u81ea\u52a8\u5f62\u5f0f\u5316\u5b58\u5728\u6a21\u578b\u5e7b\u89c9\u548c\u8bed\u4e49\u5dee\u8ddd\u95ee\u9898\u3002", "method": "\u63d0\u51faCRAMF\u6846\u67b6\uff0c\u4eceMathlib4\u6784\u5efa\u6982\u5ff5 - \u5b9a\u4e49\u77e5\u8bc6\u5e93\uff0c\u63d0\u51fa\u4e0a\u4e0b\u6587\u67e5\u8be2\u589e\u5f3a\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u53cc\u901a\u9053\u6df7\u5408\u68c0\u7d22\u91cd\u6392\u7b56\u7565\u3002", "result": "\u5728miniF2F\u3001ProofNet\u548cAdvancedMath\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCRAMF\u53ef\u96c6\u6210\u5230\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u5668\u4e2d\uff0c\u7ffb\u8bd1\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534762.1%\uff0c\u5e73\u5747\u63d0\u534729.9%\u3002", "conclusion": "CRAMF\u80fd\u6709\u6548\u89e3\u51b3\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u6311\u6218\uff0c\u63d0\u5347\u5f62\u5f0f\u5316\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.06495", "pdf": "https://arxiv.org/pdf/2508.06495", "abs": "https://arxiv.org/abs/2508.06495", "authors": ["Juliana Resplande Sant'anna Gomes", "Arlindo Rodrigues Galv\u00e3o Filho"], "title": "Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Master Thesis in Computer Science at Federal University on Goias\n  (UFG). Written in Portuguese", "summary": "The accelerated dissemination of disinformation often outpaces the capacity\nfor manual fact-checking, highlighting the urgent need for Semi-Automated\nFact-Checking (SAFC) systems. Within the Portuguese language context, there is\na noted scarcity of publicly available datasets that integrate external\nevidence, an essential component for developing robust AFC systems, as many\nexisting resources focus solely on classification based on intrinsic text\nfeatures. This dissertation addresses this gap by developing, applying, and\nanalyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,\nMuMiN-PT) with external evidence. The approach simulates a user's verification\nprocess, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)\nto extract the main claim from texts and search engine APIs (Google Search API,\nGoogle FactCheck Claims Search API) to retrieve relevant external documents\n(evidence). Additionally, a data validation and preprocessing framework,\nincluding near-duplicate detection, is introduced to enhance the quality of the\nbase corpora.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u8461\u8404\u7259\u8bed\u7f3a\u4e4f\u542b\u5916\u90e8\u8bc1\u636e\u7684\u516c\u5f00\u6570\u636e\u96c6\u95ee\u9898\uff0c\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u641c\u7d22\u5f15\u64ceAPI\u4e3a\u65b0\u95fb\u8bed\u6599\u6dfb\u52a0\u5916\u90e8\u8bc1\u636e\u7684\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u6570\u636e\u9a8c\u8bc1\u548c\u9884\u5904\u7406\u6846\u67b6\u3002", "motivation": "\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u5feb\uff0c\u4eba\u5de5\u4e8b\u5b9e\u6838\u67e5\u96be\uff0c\u8461\u8404\u7259\u8bed\u7f3a\u4e4f\u542b\u5916\u90e8\u8bc1\u636e\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u96be\u4ee5\u5f00\u53d1\u5f3a\u5927\u7684\u534a\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\uff08SAFC\uff09\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08Gemini 1.5 Flash\uff09\u63d0\u53d6\u6587\u672c\u4e3b\u8981\u58f0\u660e\uff0c\u7528\u641c\u7d22\u5f15\u64ceAPI\u68c0\u7d22\u76f8\u5173\u5916\u90e8\u6587\u6863\uff0c\u5f15\u5165\u6570\u636e\u9a8c\u8bc1\u548c\u9884\u5904\u7406\u6846\u67b6\u63d0\u5347\u8bed\u6599\u8d28\u91cf\u3002", "result": "\u672a\u63d0\u53ca\u3002", "conclusion": "\u672a\u63d0\u53ca\u3002"}}
{"id": "2508.08101", "pdf": "https://arxiv.org/pdf/2508.08101", "abs": "https://arxiv.org/abs/2508.08101", "authors": ["Yeana Lee Bond", "Mungyeong Choe", "Baker Kasim Hasan", "Arsh Siddiqui", "Myounghoon Jeon"], "title": "ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience", "categories": ["cs.HC", "cs.AI", "cs.SE"], "comment": "Submitted to International Journal of Human-Computer Studies. Bond\n  and Choe: Drafting, Review, Editing, Validation, Software, Methodology,\n  Investigation, Data Analysis, Conceptualization, Experiment training. Hasan\n  and Siddiqui: Experimental and Data Analysis Support. Jeon: Supervision,\n  Review, Resources, Project Admin, Methodology, Conceptualization. Total 34\n  pages", "summary": "Studies on in-vehicle conversational agents have traditionally relied on\npre-scripted prompts or limited voice commands, constraining natural\ndriver-agent interaction. To resolve this issue, the present study explored the\npotential of a ChatGPT-based in-vehicle agent capable of carrying continuous,\nmulti-turn dialogues. Forty drivers participated in our experiment using a\nmotion-based driving simulator, comparing three conditions (No agent,\nPre-scripted agent, and ChatGPT-based agent) as a within-subjects variable.\nResults showed that the ChatGPT-based agent condition led to more stable\ndriving performance across multiple metrics. Participants demonstrated lower\nvariability in longitudinal acceleration, lateral acceleration, and lane\ndeviation compared to the other two conditions. In subjective evaluations, the\nChatGPT-based agent also received significantly higher ratings in competence,\nanimacy, affective trust, and preference compared to the Pre-scripted agent.\nOur thematic analysis of driver-agent conversations revealed diverse\ninteraction patterns in topics, including driving assistance/questions,\nentertainment requests, and anthropomorphic interactions. Our results highlight\nthe potential of LLM-powered in-vehicle conversational agents to enhance\ndriving safety and user experience through natural, context-rich interactions.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u57fa\u4e8eChatGPT\u7684\u8f66\u8f7d\u5bf9\u8bdd\u4ee3\u7406\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u9a7e\u9a76\u5b89\u5168\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u8f66\u8f7d\u5bf9\u8bdd\u4ee3\u7406\u4f9d\u8d56\u9884\u811a\u672c\u63d0\u793a\u6216\u6709\u9650\u8bed\u97f3\u547d\u4ee4\uff0c\u9650\u5236\u81ea\u7136\u4ea4\u4e92\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "40\u540d\u53f8\u673a\u4f7f\u7528\u57fa\u4e8e\u8fd0\u52a8\u7684\u9a7e\u9a76\u6a21\u62df\u5668\uff0c\u8fdb\u884c\u65e0\u4ee3\u7406\u3001\u9884\u811a\u672c\u4ee3\u7406\u548c\u57fa\u4e8eChatGPT\u4ee3\u7406\u4e09\u79cd\u6761\u4ef6\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u57fa\u4e8eChatGPT\u7684\u4ee3\u7406\u4f7f\u9a7e\u9a76\u8868\u73b0\u66f4\u7a33\u5b9a\uff0c\u4e3b\u89c2\u8bc4\u4ef7\u66f4\u9ad8\uff0c\u5bf9\u8bdd\u4e3b\u9898\u591a\u6837\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u8f66\u8f7d\u5bf9\u8bdd\u4ee3\u7406\u53ef\u901a\u8fc7\u81ea\u7136\u3001\u4e30\u5bcc\u4e0a\u4e0b\u6587\u7684\u4ea4\u4e92\u63d0\u5347\u9a7e\u9a76\u5b89\u5168\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.06692", "pdf": "https://arxiv.org/pdf/2508.06692", "abs": "https://arxiv.org/abs/2508.06692", "authors": ["Md. Akmol Masud", "Md Abrar Jahin", "Mahmud Hasan"], "title": "Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) is a machine learning technique that often suffers\nfrom training instability due to the diverse nature of client data. Although\nutility-based client selection methods like Oort are used to converge by\nprioritizing high-loss clients, they frequently experience significant drops in\naccuracy during later stages of training. We propose a theoretical\nHeteRo-Select framework designed to maintain high performance and ensure\nlong-term training stability. We provide a theoretical analysis showing that\nwhen client data is very different (high heterogeneity), choosing a smart\nsubset of client participation can reduce communication more effectively\ncompared to full participation. Our HeteRo-Select method uses a clear,\nstep-by-step scoring system that considers client usefulness, fairness, update\nspeed, and data variety. It also shows convergence guarantees under strong\nregularization. Our experimental results on the CIFAR-10 dataset under\nsignificant label skew ($\\alpha=0.1$) support the theoretical findings. The\nHeteRo-Select method performs better than existing approaches in terms of peak\naccuracy, final accuracy, and training stability. Specifically, HeteRo-Select\nachieves a peak accuracy of $74.75\\%$, a final accuracy of $72.76\\%$, and a\nminimal stability drop of $1.99\\%$. In contrast, Oort records a lower peak\naccuracy of $73.98\\%$, a final accuracy of $71.25\\%$, and a larger stability\ndrop of $2.73\\%$. The theoretical foundations and empirical performance in our\nstudy make HeteRo-Select a reliable solution for real-world heterogeneous FL\nproblems.", "AI": {"tldr": "\u63d0\u51faHeteRo - Select\u6846\u67b6\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u56e0\u5ba2\u6237\u7aef\u6570\u636e\u591a\u6837\u6027\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u73b0\u6709\u57fa\u4e8e\u6548\u7528\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u65b9\u6cd5\u540e\u671f\u51c6\u786e\u7387\u4e0b\u964d\u3002", "method": "\u63d0\u51faHeteRo - Select\u6846\u67b6\uff0c\u91c7\u7528\u8003\u8651\u5ba2\u6237\u7aef\u6709\u7528\u6027\u3001\u516c\u5e73\u6027\u3001\u66f4\u65b0\u901f\u5ea6\u548c\u6570\u636e\u591a\u6837\u6027\u7684\u8bc4\u5206\u7cfb\u7edf\uff0c\u6709\u5f3a\u6b63\u5219\u5316\u4e0b\u7684\u6536\u655b\u4fdd\u8bc1\u3002", "result": "\u5728CIFAR - 10\u6570\u636e\u96c6\u663e\u8457\u6807\u7b7e\u504f\u659c\u60c5\u51b5\u4e0b\uff0cHeteRo - Select\u5728\u5cf0\u503c\u51c6\u786e\u7387\u3001\u6700\u7ec8\u51c6\u786e\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8eOort\u3002", "conclusion": "HeteRo - Select\u662f\u89e3\u51b3\u73b0\u5b9e\u4e2d\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u95ee\u9898\u7684\u53ef\u9760\u65b9\u6848\u3002"}}
{"id": "2508.07518", "pdf": "https://arxiv.org/pdf/2508.07518", "abs": "https://arxiv.org/abs/2508.07518", "authors": ["Sichen Zhao", "Wei Shao", "Jeffrey Chan", "Ziqi Xu", "Flora Salim"], "title": "FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted as a Research Paper (short) at ACM SIGSPATIAL 2025. This\n  arXiv version is the full version of the paper", "summary": "As deep spatio-temporal neural networks are increasingly utilised in urban\ncomputing contexts, the deployment of such methods can have a direct impact on\nusers of critical urban infrastructure, such as public transport, emergency\nservices, and traffic management systems. While many spatio-temporal methods\nfocus on improving accuracy, fairness has recently gained attention due to\ngrowing evidence that biased predictions in spatio-temporal applications can\ndisproportionately disadvantage certain demographic or geographic groups,\nthereby reinforcing existing socioeconomic inequalities and undermining the\nethical deployment of AI in public services. In this paper, we propose a novel\nframework, FairDRL-ST, based on disentangled representation learning, to\naddress fairness concerns in spatio-temporal prediction, with a particular\nfocus on mobility demand forecasting. By leveraging adversarial learning and\ndisentangled representation learning, our framework learns to separate\nattributes that contain sensitive information. Unlike existing methods that\nenforce fairness through supervised learning, which may lead to\novercompensation and degraded performance, our framework achieves fairness in\nan unsupervised manner with minimal performance loss. We apply our framework to\nreal-world urban mobility datasets and demonstrate its ability to close\nfairness gaps while delivering competitive predictive performance compared to\nstate-of-the-art fairness-aware methods.", "AI": {"tldr": "\u63d0\u51faFairDRL - ST\u6846\u67b6\u89e3\u51b3\u65f6\u7a7a\u9884\u6d4b\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u65f6\u7a7a\u65b9\u6cd5\u591a\u5173\u6ce8\u51c6\u786e\u6027\uff0c\u800c\u65f6\u7a7a\u5e94\u7528\u4e2d\u5b58\u5728\u9884\u6d4b\u504f\u5dee\u4f1a\u52a0\u5267\u793e\u4f1a\u4e0d\u5e73\u7b49\uff0c\u9700\u89e3\u51b3\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u89e3\u7ea0\u7f20\u8868\u793a\u5b66\u4e60\u7684FairDRL - ST\u6846\u67b6\uff0c\u5229\u7528\u5bf9\u6297\u5b66\u4e60\u548c\u89e3\u7ea0\u7f20\u8868\u793a\u5b66\u4e60\u5206\u79bb\u542b\u654f\u611f\u4fe1\u606f\u7684\u5c5e\u6027\uff0c\u4ee5\u65e0\u76d1\u7763\u65b9\u5f0f\u5b9e\u73b0\u516c\u5e73\u6027\u3002", "result": "\u5e94\u7528\u4e8e\u771f\u5b9e\u57ce\u5e02\u79fb\u52a8\u6570\u636e\u96c6\uff0c\u80fd\u7f29\u5c0f\u516c\u5e73\u6027\u5dee\u8ddd\uff0c\u4e14\u9884\u6d4b\u6027\u80fd\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "FairDRL - ST\u6846\u67b6\u53ef\u6709\u6548\u89e3\u51b3\u65f6\u7a7a\u9884\u6d4b\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u4e14\u6027\u80fd\u635f\u5931\u5c0f\u3002"}}
{"id": "2508.07873", "pdf": "https://arxiv.org/pdf/2508.07873", "abs": "https://arxiv.org/abs/2508.07873", "authors": ["Samaneh Mohammadi", "Vasileios Tsouvalas", "Iraklis Symeonidis", "Ali Balador", "Tanir Ozcelebi", "Francesco Flammini", "Nirvana Meratnia"], "title": "EFU: Enforcing Federated Unlearning via Functional Encryption", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": null, "summary": "Federated unlearning (FU) algorithms allow clients in federated settings to\nexercise their ''right to be forgotten'' by removing the influence of their\ndata from a collaboratively trained model. Existing FU methods maintain data\nprivacy by performing unlearning locally on the client-side and sending\ntargeted updates to the server without exposing forgotten data; yet they often\nrely on server-side cooperation, revealing the client's intent and identity\nwithout enforcement guarantees - compromising autonomy and unlearning privacy.\nIn this work, we propose EFU (Enforced Federated Unlearning), a\ncryptographically enforced FU framework that enables clients to initiate\nunlearning while concealing its occurrence from the server. Specifically, EFU\nleverages functional encryption to bind encrypted updates to specific\naggregation functions, ensuring the server can neither perform unauthorized\ncomputations nor detect or skip unlearning requests. To further mask behavioral\nand parameter shifts in the aggregated model, we incorporate auxiliary\nunlearning losses based on adversarial examples and parameter importance\nregularization. Extensive experiments show that EFU achieves near-random\naccuracy on forgotten data while maintaining performance comparable to full\nretraining across datasets and neural architectures - all while concealing\nunlearning intent from the server. Furthermore, we demonstrate that EFU is\nagnostic to the underlying unlearning algorithm, enabling secure,\nfunction-hiding, and verifiable unlearning for any client-side FU mechanism\nthat issues targeted updates.", "AI": {"tldr": "\u63d0\u51faEFU\u6846\u67b6\u5b9e\u73b0\u5ba2\u6237\u7aef\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u9690\u85cf\u9057\u5fd8\u6570\u636e\u610f\u56fe\u7684\u65e0\u5b66\u4e60\uff0c\u5b9e\u9a8c\u663e\u793a\u6548\u679c\u826f\u597d\u4e14\u5bf9\u5e95\u5c42\u7b97\u6cd5\u65e0\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u65e0\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u670d\u52a1\u5668\u5408\u4f5c\uff0c\u4f1a\u66b4\u9732\u5ba2\u6237\u7aef\u610f\u56fe\u548c\u8eab\u4efd\uff0c\u635f\u5bb3\u81ea\u4e3b\u6027\u548c\u65e0\u5b66\u4e60\u9690\u79c1\u3002", "method": "\u63d0\u51faEFU\u6846\u67b6\uff0c\u5229\u7528\u529f\u80fd\u52a0\u5bc6\u7ed1\u5b9a\u52a0\u5bc6\u66f4\u65b0\u5230\u7279\u5b9a\u805a\u5408\u51fd\u6570\uff0c\u7ed3\u5408\u57fa\u4e8e\u5bf9\u6297\u6837\u672c\u548c\u53c2\u6570\u91cd\u8981\u6027\u6b63\u5219\u5316\u7684\u8f85\u52a9\u65e0\u5b66\u4e60\u635f\u5931\u3002", "result": "\u5728\u9057\u5fd8\u6570\u636e\u4e0a\u8fbe\u5230\u63a5\u8fd1\u968f\u673a\u7684\u51c6\u786e\u7387\uff0c\u6027\u80fd\u4e0e\u5168\u91cd\u8bad\u7ec3\u76f8\u5f53\uff0c\u80fd\u9690\u85cf\u65e0\u5b66\u4e60\u610f\u56fe\u3002", "conclusion": "EFU\u5bf9\u5e95\u5c42\u65e0\u5b66\u4e60\u7b97\u6cd5\u5177\u6709\u65e0\u5173\u6027\uff0c\u53ef\u4e3a\u4efb\u4f55\u53d1\u5e03\u5b9a\u5411\u66f4\u65b0\u7684\u5ba2\u6237\u7aef\u8054\u90a6\u65e0\u5b66\u4e60\u673a\u5236\u5b9e\u73b0\u5b89\u5168\u3001\u9690\u85cf\u529f\u80fd\u548c\u53ef\u9a8c\u8bc1\u7684\u65e0\u5b66\u4e60\u3002"}}
{"id": "2508.06939", "pdf": "https://arxiv.org/pdf/2508.06939", "abs": "https://arxiv.org/abs/2508.06939", "authors": ["Hiba Najjar", "Deepak Pathak", "Marlon Nuske", "Andreas Dengel"], "title": "Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multimodal learning enables various machine learning tasks to benefit from\ndiverse data sources, effectively mimicking the interplay of different factors\nin real-world applications, particularly in agriculture. While the\nheterogeneous nature of involved data modalities may necessitate the design of\ncomplex architectures, the model interpretability is often overlooked. In this\nstudy, we leverage the intrinsic explainability of Transformer-based models to\nexplain multimodal learning networks, focusing on the task of crop yield\nprediction at the subfield level. The large datasets used cover various crops,\nregions, and years, and include four different input modalities: multispectral\nsatellite and weather time series, terrain elevation maps and soil properties.\nBased on the self-attention mechanism, we estimate feature attributions using\ntwo methods, namely the Attention Rollout (AR) and Generic Attention (GA), and\nevaluate their performance against Shapley-based model-agnostic estimations,\nShapley Value Sampling (SVS). Additionally, we propose the Weighted Modality\nActivation (WMA) method to assess modality attributions and compare it with SVS\nattributions. Our findings indicate that Transformer-based models outperform\nother architectures, specifically convolutional and recurrent networks,\nachieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field\nlevels, respectively. AR is shown to provide more robust and reliable temporal\nattributions, as confirmed through qualitative and quantitative evaluation,\ncompared to GA and SVS values. Information about crop phenology stages was\nleveraged to interpret the explanation results in the light of established\nagronomic knowledge. Furthermore, modality attributions revealed varying\npatterns across the two methods compared.[...]", "AI": {"tldr": "\u672c\u6587\u5229\u7528Transformer\u6a21\u578b\u89e3\u91ca\u591a\u6a21\u6001\u5b66\u4e60\u7f51\u7edc\u8fdb\u884c\u4e9a\u7530\u5757\u7ea7\u4f5c\u7269\u4ea7\u91cf\u9884\u6d4b\uff0c\u5bf9\u6bd4\u4e0d\u540c\u7279\u5f81\u548c\u6a21\u6001\u5f52\u56e0\u65b9\u6cd5\uff0c\u53d1\u73b0Transformer\u6a21\u578b\u8868\u73b0\u66f4\u4f18\uff0cAR\u5f52\u56e0\u66f4\u53ef\u9760\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5e38\u88ab\u5ffd\u89c6\uff0c\u7814\u7a76\u65e8\u5728\u5229\u7528Transformer\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u89e3\u91ca\u591a\u6a21\u6001\u5b66\u4e60\u7f51\u7edc\u8fdb\u884c\u4f5c\u7269\u4ea7\u91cf\u9884\u6d4b\u3002", "method": "\u4f7f\u7528\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7528AR\u548cGA\u4f30\u8ba1\u7279\u5f81\u5f52\u56e0\uff0c\u4e0eSVS\u5bf9\u6bd4\uff1b\u63d0\u51faWMA\u8bc4\u4f30\u6a21\u6001\u5f52\u56e0\u5e76\u4e0eSVS\u5bf9\u6bd4\u3002", "result": "Transformer\u6a21\u578b\u4f18\u4e8e\u5377\u79ef\u548c\u5faa\u73af\u7f51\u7edc\uff1bAR\u6bd4GA\u548cSVS\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u65f6\u95f4\u5f52\u56e0\uff1b\u6a21\u6001\u5f52\u56e0\u5728\u4e24\u79cd\u65b9\u6cd5\u4e2d\u6709\u4e0d\u540c\u6a21\u5f0f\u3002", "conclusion": "Transformer\u6a21\u578b\u5728\u4f5c\u7269\u4ea7\u91cf\u9884\u6d4b\u4e2d\u6709\u4f18\u52bf\uff0cAR\u65b9\u6cd5\u5728\u7279\u5f81\u5f52\u56e0\u4e0a\u66f4\u53ef\u9760\u3002"}}
{"id": "2508.06600", "pdf": "https://arxiv.org/pdf/2508.06600", "abs": "https://arxiv.org/abs/2508.06600", "authors": ["Zijian Chen", "Xueguang Ma", "Shengyao Zhuang", "Ping Nie", "Kai Zou", "Andrew Liu", "Joshua Green", "Kshama Patel", "Ruoxi Meng", "Mingyi Su", "Sahel Sharifymoghaddam", "Yanxi Li", "Haoran Hong", "Xinyu Shi", "Xuye Liu", "Nandan Thakur", "Crystina Zhang", "Luyu Gao", "Wenhu Chen", "Jimmy Lin"], "title": "BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Deep-Research agents, which integrate large language models (LLMs) with\nsearch tools, have shown success in improving the effectiveness of handling\ncomplex queries that require iterative search planning and reasoning over\nsearch results. Evaluations on current benchmarks like BrowseComp relies on\nblack-box live web search APIs, have notable limitations in (1) fairness:\ndynamic and opaque web APIs hinder fair comparisons and reproducibility of deep\nresearch methods; (2) transparency: lack of control over the document corpus\nmakes it difficult to isolate retriever contributions. In other words, the\ncurrent evaluations may compare a complete deep research system at a given\ntime, but they do not foster well-controlled experiments to provide insights\ninto the capability of underlying deep research LLMs. To address these\nchallenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,\nemploying a fixed, carefully curated corpus. Each query in BrowseComp-Plus\nincludes human-verified supporting documents and mined challenging negatives,\nenabling controlled experimentation. The benchmark is shown to be effective in\ndistinguishing the performance of deep research systems. For instance, the\nopen-source model Search-R1, when paired with the BM25 retriever, achieves\n3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with\nthe Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with\nfewer search calls. This benchmark allows comprehensive evaluation and\ndisentangled analysis of deep research agents and retrieval methods, fostering\ninsights into retrieval effectiveness, citation accuracy, and context\nengineering in Deep-Research system.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eBrowseComp\u7684\u57fa\u51c6\u6d4b\u8bd5BrowseComp-Plus\uff0c\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u95ee\u9898\u5e76\u6709\u6548\u533a\u5206\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9ed1\u76d2\u5b9e\u65f6\u7f51\u7edc\u641c\u7d22API\u7684\u57fa\u51c6\u6d4b\u8bd5\u5728\u516c\u5e73\u6027\u548c\u900f\u660e\u5ea6\u4e0a\u6709\u5c40\u9650\uff0c\u96be\u4ee5\u5bf9\u6df1\u5ea6\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u8fdb\u884c\u53ef\u63a7\u5b9e\u9a8c", "method": "\u5f15\u5165\u57fa\u4e8eBrowseComp\u7684BrowseComp-Plus\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528\u56fa\u5b9a\u7cbe\u5fc3\u7b56\u5212\u7684\u8bed\u6599\u5e93\uff0c\u6bcf\u4e2a\u67e5\u8be2\u5305\u542b\u4eba\u5de5\u9a8c\u8bc1\u7684\u652f\u6301\u6587\u6863\u548c\u6316\u6398\u7684\u6311\u6218\u6027\u8d1f\u6837\u672c", "result": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u6709\u6548\u533a\u5206\u7cfb\u7edf\u6027\u80fd\uff0c\u5982Search - R1\u642d\u914dBM25\u68c0\u7d22\u5668\u51c6\u786e\u73873.86%\uff0cGPT - 5\u4e3a55.9%\uff0cGPT - 5\u642d\u914dQwen3 - Embedding - 8B\u68c0\u7d22\u5668\u51c6\u786e\u7387\u8fbe70.1%\u4e14\u641c\u7d22\u8c03\u7528\u66f4\u5c11", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u53ef\u5bf9\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u548c\u68c0\u7d22\u65b9\u6cd5\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u548c\u89e3\u8026\u5206\u6790\uff0c\u52a9\u529b\u6df1\u5165\u4e86\u89e3\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u7684\u68c0\u7d22\u6709\u6548\u6027\u3001\u5f15\u7528\u51c6\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u5de5\u7a0b"}}
{"id": "2508.08151", "pdf": "https://arxiv.org/pdf/2508.08151", "abs": "https://arxiv.org/abs/2508.08151", "authors": ["Moses Openja", "Paolo Arcaini", "Foutse Khomh", "Fuyuki Ishikawa"], "title": "FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "Deep neural networks (DNNs) are being utilized in various aspects of our\ndaily lives, including high-stakes decision-making applications that impact\nindividuals. However, these systems reflect and amplify bias from the data used\nduring training and testing, potentially resulting in biased behavior and\ninaccurate decisions. For instance, having different misclassification rates\nbetween white and black sub-populations. However, effectively and efficiently\nidentifying and correcting biased behavior in DNNs is a challenge. This paper\nintroduces FairFLRep, an automated fairness-aware fault localization and repair\ntechnique that identifies and corrects potentially bias-inducing neurons in DNN\nclassifiers. FairFLRep focuses on adjusting neuron weights associated with\nsensitive attributes, such as race or gender, that contribute to unfair\ndecisions. By analyzing the input-output relationships within the network,\nFairFLRep corrects neurons responsible for disparities in predictive quality\nparity. We evaluate FairFLRep on four image classification datasets using two\nDNN classifiers, and four tabular datasets with a DNN model. The results show\nthat FairFLRep consistently outperforms existing methods in improving fairness\nwhile preserving accuracy. An ablation study confirms the importance of\nconsidering fairness during both fault localization and repair stages. Our\nfindings also show that FairFLRep is more efficient than the baseline\napproaches in repairing the network.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecdFairFLRep\u6280\u672f\u8bc6\u522b\u548c\u7ea0\u6b63DNN\u5206\u7c7b\u5668\u4e2d\u6f5c\u5728\u5bfc\u81f4\u504f\u5dee\u7684\u795e\u7ecf\u5143\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u63d0\u5347\u516c\u5e73\u6027\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u4e14\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u9ad8\u6548\u3002", "motivation": "DNN\u7cfb\u7edf\u4f1a\u53cd\u6620\u548c\u653e\u5927\u6570\u636e\u4e2d\u7684\u504f\u5dee\uff0c\u5bfc\u81f4\u6709\u504f\u5dee\u884c\u4e3a\u548c\u4e0d\u51c6\u786e\u51b3\u7b56\uff0c\u6709\u6548\u8bc6\u522b\u548c\u7ea0\u6b63\u5176\u504f\u5dee\u884c\u4e3a\u662f\u6311\u6218\u3002", "method": "\u5f15\u5165FairFLRep\u6280\u672f\uff0c\u8c03\u6574\u4e0e\u654f\u611f\u5c5e\u6027\u76f8\u5173\u7684\u795e\u7ecf\u5143\u6743\u91cd\uff0c\u5206\u6790\u7f51\u7edc\u8f93\u5165 - \u8f93\u51fa\u5173\u7cfb\u6765\u7ea0\u6b63\u5bfc\u81f4\u9884\u6d4b\u8d28\u91cf\u5dee\u5f02\u7684\u795e\u7ecf\u5143\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0cFairFLRep\u5728\u63d0\u5347\u516c\u5e73\u6027\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u8003\u8651\u516c\u5e73\u6027\u7684\u91cd\u8981\u6027\uff1b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u4fee\u590d\u7f51\u7edc\u66f4\u9ad8\u6548\u3002", "conclusion": "FairFLRep\u80fd\u6709\u6548\u8bc6\u522b\u548c\u7ea0\u6b63DNN\u4e2d\u7684\u504f\u5dee\uff0c\u5728\u63d0\u5347\u516c\u5e73\u6027\u548c\u6548\u7387\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.06704", "pdf": "https://arxiv.org/pdf/2508.06704", "abs": "https://arxiv.org/abs/2508.06704", "authors": ["Hager Radi Abdelwahed", "M\u00e9lisande Teng", "Robin Zbinden", "Laura Pollock", "Hugo Larochelle", "Devis Tuia", "David Rolnick"], "title": "CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations", "categories": ["cs.LG"], "comment": null, "summary": "Species distribution models (SDMs) are widely used to predict species'\ngeographic distributions, serving as critical tools for ecological research and\nconservation planning. Typically, SDMs relate species occurrences to\nenvironmental variables representing abiotic factors, such as temperature,\nprecipitation, and soil properties. However, species distributions are also\nstrongly influenced by biotic interactions with other species, which are often\noverlooked. While some methods partially address this limitation by\nincorporating biotic interactions, they often assume symmetrical pairwise\nrelationships between species and require consistent co-occurrence data. In\npractice, species observations are sparse, and the availability of information\nabout the presence or absence of other species varies significantly across\nlocations. To address these challenges, we propose CISO, a deep learning-based\nmethod for species distribution modeling Conditioned on Incomplete Species\nObservations. CISO enables predictions to be conditioned on a flexible number\nof species observations alongside environmental variables, accommodating the\nvariability and incompleteness of available biotic data. We demonstrate our\napproach using three datasets representing different species groups: sPlotOpen\nfor plants, SatBird for birds, and a new dataset, SatButterfly, for\nbutterflies. Our results show that including partial biotic information\nimproves predictive performance on spatially separate test sets. When\nconditioned on a subset of species within the same dataset, CISO outperforms\nalternative methods in predicting the distribution of the remaining species.\nFurthermore, we show that combining observations from multiple datasets can\nimprove performance. CISO is a promising ecological tool, capable of\nincorporating incomplete biotic information and identifying potential\ninteractions between species from disparate taxa.", "AI": {"tldr": "\u4f20\u7edf\u7269\u79cd\u5206\u5e03\u6a21\u578b\uff08SDMs\uff09\u5e38\u5ffd\u7565\u751f\u7269\u76f8\u4e92\u4f5c\u7528\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684CISO\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u5176\u80fd\u7ed3\u5408\u4e0d\u5b8c\u6574\u751f\u7269\u4fe1\u606f\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfSDMs\u5e38\u5ffd\u7565\u751f\u7269\u76f8\u4e92\u4f5c\u7528\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6cd5\u5b58\u5728\u5047\u8bbe\u5c40\u9650\u4e14\u4f9d\u8d56\u5b8c\u6574\u5171\u73b0\u6570\u636e\uff0c\u800c\u5b9e\u9645\u7269\u79cd\u89c2\u6d4b\u7a00\u758f\u3001\u4fe1\u606f\u4e0d\u4e00\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684CISO\u65b9\u6cd5\uff0c\u53ef\u7ed3\u5408\u53ef\u53d8\u6570\u91cf\u7269\u79cd\u89c2\u6d4b\u548c\u73af\u5883\u53d8\u91cf\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u7eb3\u5165\u90e8\u5206\u751f\u7269\u4fe1\u606f\u53ef\u63d0\u5347\u7a7a\u95f4\u5206\u79bb\u6d4b\u8bd5\u96c6\u7684\u9884\u6d4b\u6027\u80fd\uff1b\u4ee5\u5b50\u7269\u79cd\u4e3a\u6761\u4ef6\u65f6\uff0cCISO\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff1b\u7ed3\u5408\u591a\u6570\u636e\u96c6\u89c2\u6d4b\u53ef\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "CISO\u662f\u6709\u524d\u666f\u7684\u751f\u6001\u5de5\u5177\uff0c\u80fd\u7ed3\u5408\u4e0d\u5b8c\u6574\u751f\u7269\u4fe1\u606f\uff0c\u8bc6\u522b\u4e0d\u540c\u5206\u7c7b\u7fa4\u7269\u79cd\u95f4\u6f5c\u5728\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2508.07556", "pdf": "https://arxiv.org/pdf/2508.07556", "abs": "https://arxiv.org/abs/2508.07556", "authors": ["Stephan Rabanser"], "title": "Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "comment": "PhD Thesis", "summary": "Machine learning (ML) systems are increasingly deployed in high-stakes\ndomains where reliability is paramount. This thesis investigates how\nuncertainty estimation can enhance the safety and trustworthiness of ML,\nfocusing on selective prediction -- where models abstain when confidence is\nlow.\n  We first show that a model's training trajectory contains rich uncertainty\nsignals that can be exploited without altering its architecture or loss. By\nensembling predictions from intermediate checkpoints, we propose a lightweight,\npost-hoc abstention method that works across tasks, avoids the cost of deep\nensembles, and achieves state-of-the-art selective prediction performance.\nCrucially, this approach is fully compatible with differential privacy (DP),\nallowing us to study how privacy noise affects uncertainty quality. We find\nthat while many methods degrade under DP, our trajectory-based approach remains\nrobust, and we introduce a framework for isolating the privacy-uncertainty\ntrade-off. Next, we then develop a finite-sample decomposition of the selective\nclassification gap -- the deviation from the oracle accuracy-coverage curve --\nidentifying five interpretable error sources and clarifying which interventions\ncan close the gap. This explains why calibration alone cannot fix ranking\nerrors, motivating methods that improve uncertainty ordering. Finally, we show\nthat uncertainty signals can be adversarially manipulated to hide errors or\ndeny service while maintaining high accuracy, and we design defenses combining\ncalibration audits with verifiable inference.\n  Together, these contributions advance reliable ML by improving, evaluating,\nand safeguarding uncertainty estimation, enabling models that not only make\naccurate predictions -- but also know when to say \"I do not know\".", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u7528\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u63d0\u5347\u673a\u5668\u5b66\u4e60\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u63d0\u51fa\u57fa\u4e8e\u8bad\u7ec3\u8f68\u8ff9\u7684\u9009\u62e9\u6027\u9884\u6d4b\u65b9\u6cd5\uff0c\u5206\u6790\u8bef\u5dee\u6e90\uff0c\u8fd8\u5e94\u5bf9\u4e86\u5bf9\u6297\u64cd\u7eb5\u95ee\u9898\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u9886\u57df\u9700\u63d0\u5347\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u7814\u7a76\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4ee5\u6539\u8fdb\u9009\u62e9\u6027\u9884\u6d4b\u3002", "method": "\u5229\u7528\u6a21\u578b\u8bad\u7ec3\u8f68\u8ff9\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\uff0c\u96c6\u6210\u4e2d\u95f4\u68c0\u67e5\u70b9\u9884\u6d4b\uff1b\u5bf9\u9009\u62e9\u6027\u5206\u7c7b\u5dee\u8ddd\u8fdb\u884c\u6709\u9650\u6837\u672c\u5206\u89e3\uff1b\u7ed3\u5408\u6821\u51c6\u5ba1\u8ba1\u548c\u53ef\u9a8c\u8bc1\u63a8\u7406\u8bbe\u8ba1\u9632\u5fa1\u673a\u5236\u3002", "result": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u4e8b\u540e\u5f03\u6743\u65b9\u6cd5\uff0c\u5728\u5dee\u5206\u9690\u79c1\u4e0b\u8868\u73b0\u7a33\u5065\uff1b\u660e\u786e\u9009\u62e9\u6027\u5206\u7c7b\u5dee\u8ddd\u7684\u4e94\u4e2a\u53ef\u89e3\u91ca\u8bef\u5dee\u6e90\uff1b\u53d1\u73b0\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\u4f1a\u88ab\u5bf9\u6297\u64cd\u7eb5\u5e76\u8bbe\u8ba1\u4e86\u9632\u5fa1\u63aa\u65bd\u3002", "conclusion": "\u7814\u7a76\u5728\u6539\u8fdb\u3001\u8bc4\u4f30\u548c\u4fdd\u969c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u9762\u63a8\u52a8\u4e86\u53ef\u9760\u673a\u5668\u5b66\u4e60\u7684\u53d1\u5c55\uff0c\u4f7f\u6a21\u578b\u80fd\u51c6\u786e\u9884\u6d4b\u5e76\u77e5\u9053\u4f55\u65f6\u5e94\u5f03\u6743\u3002"}}
{"id": "2508.07879", "pdf": "https://arxiv.org/pdf/2508.07879", "abs": "https://arxiv.org/abs/2508.07879", "authors": ["Oscar Ferraz", "Bruno Coutinho", "Gabriel Falcao", "Marco Gomes", "Francisco A. Monteiro", "Vitor Silva"], "title": "GPU-Accelerated Syndrome Decoding for Quantum LDPC Codes below the 63 $\u03bc$s Latency Threshold", "categories": ["quant-ph", "cs.DC"], "comment": "7 pages, 3 figures, 1 table", "summary": "This paper presents a GPU-accelerated decoder for quantum low-density\nparity-check (QLDPC) codes that achieves sub-$63$ $\\mu$s latency, below the\nsurface code decoder's real-time threshold demonstrated on Google's Willow\nquantum processor. While surface codes have demonstrated below-threshold\nperformance, the encoding rates approach zero as code distances increase,\nposing challenges for scalability. Recently proposed QLDPC codes, such as those\nby Panteleev and Kalachev, offer constant-rate encoding and asymptotic goodness\nbut introduce higher decoding complexity. To address such limitation, this work\npresents a parallelized belief propagation decoder leveraging syndrome\ninformation on commodity GPU hardware. Parallelism was exploited to maximize\nperformance within the limits of target latency, allowing decoding latencies\nunder $50$ $\\mu$s for [[$784$, $24$, $24$]] codes and as low as $23.3$ $\\mu$s\nfor smaller codes, meeting the tight timing constraints of superconducting\nqubit cycles. These results show that real-time, scalable decoding of\nasymptotically good quantum codes is achievable using widely available\ncommodity hardware, advancing the feasibility of fault-tolerant quantum\ncomputation beyond surface codes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGPU\u52a0\u901f\u7684\u91cf\u5b50\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\uff08QLDPC\uff09\u7801\u89e3\u7801\u5668\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\uff0c\u8bc1\u660e\u7528\u901a\u7528\u786c\u4ef6\u53ef\u5b9e\u73b0\u6e10\u8fd1\u826f\u597d\u91cf\u5b50\u7801\u5b9e\u65f6\u53ef\u6269\u5c55\u89e3\u7801\u3002", "motivation": "\u8868\u9762\u7801\u7f16\u7801\u7387\u968f\u7801\u8ddd\u589e\u52a0\u8d8b\u8fd1\u4e8e\u96f6\uff0c\u6269\u5c55\u6027\u6709\u6311\u6218\uff1b\u65b0\u63d0\u51fa\u7684QLDPC\u7801\u89e3\u7801\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u89e3\u51b3\u5176\u89e3\u7801\u95ee\u9898\u3002", "method": "\u5728\u901a\u7528GPU\u786c\u4ef6\u4e0a\u5229\u7528\u7efc\u5408\u5f81\u4fe1\u606f\u5b9e\u73b0\u5e76\u884c\u5316\u7f6e\u4fe1\u4f20\u64ad\u89e3\u7801\u5668\uff0c\u5728\u76ee\u6807\u5ef6\u8fdf\u9650\u5236\u5185\u5229\u7528\u5e76\u884c\u6027\u6700\u5927\u5316\u6027\u80fd\u3002", "result": "[[784, 24, 24]]\u7801\u89e3\u7801\u5ef6\u8fdf\u4f4e\u4e8e50 \u03bcs\uff0c\u8f83\u5c0f\u7801\u4f4e\u81f323.3 \u03bcs\u3002", "conclusion": "\u4f7f\u7528\u901a\u7528\u786c\u4ef6\u53ef\u5b9e\u73b0\u6e10\u8fd1\u826f\u597d\u91cf\u5b50\u7801\u7684\u5b9e\u65f6\u53ef\u6269\u5c55\u89e3\u7801\uff0c\u63a8\u8fdb\u4e86\u8d85\u8d8a\u8868\u9762\u7801\u7684\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u53ef\u884c\u6027\u3002"}}
{"id": "2508.06950", "pdf": "https://arxiv.org/pdf/2508.06950", "abs": "https://arxiv.org/abs/2508.06950", "authors": ["Sarah Schr\u00f6der", "Thekla Morgenroth", "Ulrike Kuhl", "Valerie Vaquet", "Benjamin Paa\u00dfen"], "title": "Large Language Models Do Not Simulate Human Psychology", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs),such as ChatGPT, are increasingly used in\nresearch, ranging from simple writing assistance to complex data annotation\ntasks. Recently, some research has suggested that LLMs may even be able to\nsimulate human psychology and can, hence, replace human participants in\npsychological studies. We caution against this approach. We provide conceptual\narguments against the hypothesis that LLMs simulate human psychology. We then\npresent empiric evidence illustrating our arguments by demonstrating that\nslight changes to wording that correspond to large changes in meaning lead to\nnotable discrepancies between LLMs' and human responses, even for the recent\nCENTAUR model that was specifically fine-tuned on psychological responses.\nAdditionally, different LLMs show very different responses to novel items,\nfurther illustrating their lack of reliability. We conclude that LLMs do not\nsimulate human psychology and recommend that psychological researchers should\ntreat LLMs as useful but fundamentally unreliable tools that need to be\nvalidated against human responses for every new application.", "AI": {"tldr": "\u6587\u7ae0\u8b66\u793a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u66ff\u4ee3\u5fc3\u7406\u5b66\u7814\u7a76\u4e2d\u7684\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u505a\u6cd5\uff0c\u6307\u51fa\u5176\u4e0d\u80fd\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\uff0c\u5efa\u8bae\u7814\u7a76\u8005\u5c06\u5176\u4f5c\u4e3a\u9700\u9a8c\u8bc1\u7684\u5de5\u5177\u3002", "motivation": "\u9488\u5bf9\u8fd1\u671f\u4e00\u4e9b\u7814\u7a76\u8ba4\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\u3001\u53ef\u66ff\u4ee3\u5fc3\u7406\u5b66\u7814\u7a76\u4e2d\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u89c2\u70b9\uff0c\u63d0\u51fa\u53cd\u5bf9\u610f\u89c1\u3002", "method": "\u5148\u7ed9\u51fa\u6982\u5ff5\u6027\u8bba\u8bc1\uff0c\u518d\u901a\u8fc7\u4e3e\u4f8b\u8bf4\u660e\u63aa\u8f9e\u53d8\u5316\u5bfc\u81f4\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4eba\u7c7b\u53cd\u5e94\u7684\u5dee\u5f02\uff0c\u4ee5\u53ca\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u65b0\u95ee\u9898\u53cd\u5e94\u4e0d\u540c\u3002", "result": "\u5373\u4f7f\u4e13\u95e8\u9488\u5bf9\u5fc3\u7406\u53cd\u5e94\u5fae\u8c03\u7684CENTAUR\u6a21\u578b\uff0c\u63aa\u8f9e\u53d8\u5316\u4e5f\u4f1a\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4eba\u7c7b\u53cd\u5e94\u6709\u663e\u8457\u5dee\u5f02\uff0c\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u65b0\u95ee\u9898\u53cd\u5e94\u4e0d\u540c\uff0c\u7f3a\u4e4f\u53ef\u9760\u6027\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u80fd\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\uff0c\u5fc3\u7406\u5b66\u7814\u7a76\u8005\u5e94\u5c06\u5176\u89c6\u4e3a\u9700\u9488\u5bf9\u65b0\u5e94\u7528\u5bf9\u7167\u4eba\u7c7b\u53cd\u5e94\u8fdb\u884c\u9a8c\u8bc1\u7684\u6709\u7528\u4f46\u4e0d\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2508.06743", "pdf": "https://arxiv.org/pdf/2508.06743", "abs": "https://arxiv.org/abs/2508.06743", "authors": ["Connor Brown"], "title": "Analysis of Schedule-Free Nonconvex Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "First-order methods underpin most large-scale learning algorithms, yet their\nclassical convergence guarantees hinge on carefully scheduled step-sizes that\ndepend on the total horizon $T$, which is rarely known in advance. The\nSchedule-Free (SF) method promises optimal performance with hyperparameters\nthat are independent of $T$ by interpolating between Polyak--Ruppert averaging\nand momentum, but nonconvex analysis of SF has been limited or reliant on\nstrong global assumptions. We introduce a robust Lyapunov framework that, under\nonly $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step\ndescent inequality. This yields horizon-agnostic bounds in the nonconvex\nsetting: $O(1/\\log T)$ for constant step + PR averaging, $O(\\log T/T)$ for a\nlinearly growing step-size, and a continuum of $O(T^{-(1-\\alpha)})$ rates for\npolynomial averaging. We complement these proofs with Performance Estimation\nProblem (PEP) experiments that numerically validate our rates and suggest that\nour $O(1/\\log T)$ bound on the original nonconvex SF algorithm may tighten to\n$O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex\noptimization and charts future directions for optimal nonconvex rates.", "AI": {"tldr": "\u63d0\u51fa\u9c81\u68d2\u674e\u96c5\u666e\u8bfa\u592b\u6846\u67b6\u5206\u6790\u65e0\u8c03\u5ea6\uff08SF\uff09\u65b9\u6cd5\uff0c\u5f97\u51fa\u975e\u51f8\u73af\u5883\u4e0b\u4e0e\u8fed\u4ee3\u6b21\u6570\u65e0\u5173\u7684\u6536\u655b\u754c\uff0c\u5e76\u7528PEP\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u4e00\u9636\u65b9\u6cd5\u6536\u655b\u4f9d\u8d56\u63d0\u524d\u672a\u77e5\u7684\u603b\u8fed\u4ee3\u6b21\u6570T\uff0cSF\u65b9\u6cd5\u5728\u975e\u51f8\u5206\u6790\u4e0a\u6709\u9650\u6216\u4f9d\u8d56\u5f3a\u5168\u5c40\u5047\u8bbe\u3002", "method": "\u5f15\u5165\u9c81\u68d2\u674e\u96c5\u666e\u8bfa\u592b\u6846\u67b6\uff0c\u5c06SF\u5206\u6790\u7b80\u5316\u4e3a\u5355\u6b65\u4e0b\u964d\u4e0d\u7b49\u5f0f\uff0c\u7ed3\u5408PEP\u5b9e\u9a8c\u3002", "result": "\u5f97\u5230\u975e\u51f8\u73af\u5883\u4e0b\u4e0e\u8fed\u4ee3\u6b21\u6570\u65e0\u5173\u7684\u6536\u655b\u754c\uff0c\u5982\u5e38\u6570\u6b65\u957f+PR\u5e73\u5747\u4e3aO(1/log T)\u7b49\uff0cPEP\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6536\u655b\u901f\u7387\u3002", "conclusion": "\u5c06SF\u7684\u65e0\u8fed\u4ee3\u6b21\u6570\u4f9d\u8d56\u4fdd\u8bc1\u6269\u5c55\u5230\u5e73\u6ed1\u975e\u51f8\u4f18\u5316\uff0c\u4e3a\u6700\u4f18\u975e\u51f8\u901f\u7387\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2508.07713", "pdf": "https://arxiv.org/pdf/2508.07713", "abs": "https://arxiv.org/abs/2508.07713", "authors": ["Jinghan Yang", "Jiayu Weng"], "title": "Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information", "categories": ["cs.LG", "stat.ML"], "comment": "Under Working", "summary": "Deep neural networks can memorize corrupted labels, making data quality\ncritical for model performance, yet real-world datasets are frequently\ncompromised by both label noise and input noise. This paper proposes a mutual\ninformation-based framework for data selection under hybrid noise scenarios\nthat quantifies statistical dependencies between inputs and labels. We compute\neach sample's pointwise contribution to the overall mutual information and find\nthat lower contributions indicate noisy or mislabeled instances. Empirical\nvalidation on MNIST with different synthetic noise settings demonstrates that\nthe method effectively filters low-quality samples. Under label corruption,\ntraining on high-MI samples improves classification accuracy by up to 15\\%\ncompared to random sampling. Furthermore, the method exhibits robustness to\nbenign input modifications, preserving semantically valid data while filtering\ntruly corrupted samples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u6570\u636e\u9009\u62e9\u6846\u67b6\uff0c\u5728MNIST\u4e0a\u9a8c\u8bc1\u80fd\u6709\u6548\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u6837\u672c\uff0c\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f1a\u8bb0\u5fc6\u9519\u8bef\u6807\u7b7e\uff0c\u73b0\u5b9e\u6570\u636e\u96c6\u5e38\u53d7\u6807\u7b7e\u548c\u8f93\u5165\u566a\u58f0\u5f71\u54cd\uff0c\u6570\u636e\u8d28\u91cf\u5bf9\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u6846\u67b6\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u6837\u672c\u5bf9\u6574\u4f53\u4e92\u4fe1\u606f\u7684\u9010\u70b9\u8d21\u732e\uff0c\u4f4e\u8d21\u732e\u8868\u793a\u6709\u566a\u58f0\u6216\u9519\u8bef\u6807\u7b7e\u7684\u5b9e\u4f8b\u3002", "result": "\u5728\u4e0d\u540c\u5408\u6210\u566a\u58f0\u8bbe\u7f6e\u7684MNIST\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u6837\u672c\uff0c\u5728\u6807\u7b7e\u635f\u574f\u65f6\uff0c\u7528\u9ad8\u4e92\u4fe1\u606f\u6837\u672c\u8bad\u7ec3\u6bd4\u968f\u673a\u91c7\u6837\u5206\u7c7b\u51c6\u786e\u7387\u6700\u591a\u63d0\u9ad815%\uff0c\u4e14\u5bf9\u826f\u6027\u8f93\u5165\u4fee\u6539\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u5728\u6df7\u5408\u566a\u58f0\u573a\u666f\u4e0b\u6709\u6548\u8fdb\u884c\u6570\u636e\u9009\u62e9\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.08068", "pdf": "https://arxiv.org/pdf/2508.08068", "abs": "https://arxiv.org/abs/2508.08068", "authors": ["Yuval Efron", "Joachim Neu", "Toniann Pitassi"], "title": "Fully-Fluctuating Participation in Sleepy Consensus", "categories": ["cs.CR", "cs.DC"], "comment": null, "summary": "Proof-of-work allows Bitcoin to boast security amidst arbitrary fluctuations\nin participation of miners throughout time, so long as, at any point in time, a\nmajority of hash power is honest. In recent years, however, the pendulum has\nshifted in favor of proof-of-stake-based consensus protocols. There, the sleepy\nmodel is the most prominent model for handling fluctuating participation of\nnodes. However, to date, no protocol in the sleepy model rivals Bitcoin in its\nrobustness to drastic fluctuations in participation levels, with\nstate-of-the-art protocols making various restrictive assumptions. In this\nwork, we present a new adversary model, called external adversary. Intuitively,\nin our model, corrupt nodes do not divulge information about their secret keys.\nIn this model, we show that protocols in the sleepy model can meaningfully\nclaim to remain secure against fully fluctuating participation, without\ncompromising efficiency or corruption resilience. Our adversary model is quite\nnatural, and arguably naturally captures the process via which malicious\nbehavior arises in protocols, as opposed to traditional worst-case modeling. On\ntop of which, the model is also theoretically appealing, circumventing a\nbarrier established in a recent work of Malkhi, Momose, and Ren.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u5bf9\u624b\u6a21\u578b\u201c\u5916\u90e8\u5bf9\u624b\u201d\uff0c\u8868\u660e\u7761\u7720\u6a21\u578b\u534f\u8bae\u5728\u6b64\u6a21\u578b\u4e0b\u53ef\u5e94\u5bf9\u8282\u70b9\u53c2\u4e0e\u5ea6\u6ce2\u52a8\u5e76\u4fdd\u8bc1\u5b89\u5168\u3002", "motivation": "\u73b0\u6709\u7761\u7720\u6a21\u578b\u534f\u8bae\u5728\u5e94\u5bf9\u8282\u70b9\u53c2\u4e0e\u5ea6\u5927\u5e45\u6ce2\u52a8\u65f6\u4e0d\u5982\u6bd4\u7279\u5e01\u5065\u58ee\uff0c\u4e14\u6709\u8bf8\u591a\u9650\u5236\u5047\u8bbe\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u5bf9\u624b\u6a21\u578b\u201c\u5916\u90e8\u5bf9\u624b\u201d\uff0c\u6b64\u6a21\u578b\u4e2d\u8150\u8d25\u8282\u70b9\u4e0d\u6cc4\u9732\u5bc6\u94a5\u4fe1\u606f\u3002", "result": "\u5728\u65b0\u6a21\u578b\u4e0b\uff0c\u7761\u7720\u6a21\u578b\u534f\u8bae\u80fd\u5728\u4e0d\u727a\u7272\u6548\u7387\u548c\u6297\u8150\u8d25\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\uff0c\u5e94\u5bf9\u5168\u6ce2\u52a8\u53c2\u4e0e\u60c5\u51b5\u3002", "conclusion": "\u65b0\u5bf9\u624b\u6a21\u578b\u81ea\u7136\u4e14\u80fd\u6355\u83b7\u534f\u8bae\u4e2d\u6076\u610f\u884c\u4e3a\u4ea7\u751f\u8fc7\u7a0b\uff0c\u8fd8\u89c4\u907f\u4e86\u524d\u4eba\u7814\u7a76\u7684\u969c\u788d\uff0c\u6709\u7406\u8bba\u5438\u5f15\u529b\u3002"}}
{"id": "2508.06960", "pdf": "https://arxiv.org/pdf/2508.06960", "abs": "https://arxiv.org/abs/2508.06960", "authors": ["Keyu Li", "Mohan Jiang", "Dayuan Fu", "Yunze Wu", "Xiangkun Hu", "Dequan Wang", "Pengfei Liu"], "title": "DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "The rapid advancement of large language models has fundamentally shifted the\nbottleneck in AI development from computational power to data availability-with\ncountless valuable datasets remaining hidden across specialized repositories,\nresearch appendices, and domain platforms. As reasoning capabilities and deep\nresearch methodologies continue to evolve, a critical question emerges: can AI\nagents transcend conventional search to systematically discover any dataset\nthat meets specific user requirements, enabling truly autonomous demand-driven\ndata curation? We introduce DatasetResearch, the first comprehensive benchmark\nevaluating AI agents' ability to discover and synthesize datasets from 208\nreal-world demands across knowledge-intensive and reasoning-intensive tasks.\nOur tri-dimensional evaluation framework reveals a stark reality: even advanced\ndeep research systems achieve only 22% score on our challenging\nDatasetResearch-pro subset, exposing the vast gap between current capabilities\nand perfect dataset discovery. Our analysis uncovers a fundamental\ndichotomy-search agents excel at knowledge tasks through retrieval breadth,\nwhile synthesis agents dominate reasoning challenges via structured\ngeneration-yet both catastrophically fail on \"corner cases\" outside existing\ndistributions. These findings establish the first rigorous baseline for dataset\ndiscovery agents and illuminate the path toward AI systems capable of finding\nany dataset in the digital universe. Our benchmark and comprehensive analysis\nprovide the foundation for the next generation of self-improving AI systems and\nare publicly available at https://github.com/GAIR-NLP/DatasetResearch.", "AI": {"tldr": "\u4ecb\u7ecdDatasetResearch\u57fa\u51c6\u8bc4\u4f30AI\u4ee3\u7406\u53d1\u73b0\u548c\u5408\u6210\u6570\u636e\u96c6\u7684\u80fd\u529b\uff0c\u63ed\u793a\u5f53\u524d\u80fd\u529b\u4e0e\u5b8c\u7f8e\u6570\u636e\u96c6\u53d1\u73b0\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u6570\u636e\u96c6\u53d1\u73b0\u4ee3\u7406\u5efa\u7acb\u57fa\u7ebf\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\uff0cAI\u5f00\u53d1\u74f6\u9888\u8f6c\u5411\u6570\u636e\u53ef\u7528\u6027\uff0c\u9700\u8bc4\u4f30AI\u4ee3\u7406\u80fd\u5426\u7cfb\u7edf\u53d1\u73b0\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u7684\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165DatasetResearch\u57fa\u51c6\uff0c\u91c7\u7528\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\u8bc4\u4f30AI\u4ee3\u7406\u4ece208\u4e2a\u73b0\u5b9e\u9700\u6c42\u4e2d\u53d1\u73b0\u548c\u5408\u6210\u6570\u636e\u96c6\u7684\u80fd\u529b\u3002", "result": "\u5148\u8fdb\u7684\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5728DatasetResearch - pro\u5b50\u96c6\u4e0a\u4ec5\u83b722%\u7684\u5206\u6570\uff0c\u641c\u7d22\u548c\u5408\u6210\u4ee3\u7406\u5404\u6709\u4f18\u52bf\u4f46\u90fd\u5728\u2018\u6781\u7aef\u60c5\u51b5\u2019\u4e0b\u5931\u8d25\u3002", "conclusion": "\u4e3a\u6570\u636e\u96c6\u53d1\u73b0\u4ee3\u7406\u5efa\u7acb\u4e86\u4e25\u683c\u57fa\u7ebf\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u6211\u6539\u8fdbAI\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\uff0c\u57fa\u51c6\u548c\u5206\u6790\u7ed3\u679c\u516c\u5f00\u3002"}}
{"id": "2508.06880", "pdf": "https://arxiv.org/pdf/2508.06880", "abs": "https://arxiv.org/abs/2508.06880", "authors": ["Philipp Christmann", "Gerhard Weikum"], "title": "The ReQAP System for Question Answering over Personal Information", "categories": ["cs.CL", "cs.IR"], "comment": "Accepted at CIKM 2025 (demonstration paper)", "summary": "Personal information is abundant on users' devices, from structured data in\ncalendar, shopping records or fitness tools, to unstructured contents in mail\nand social media posts. This works presents the ReQAP system that supports\nusers with answers for complex questions that involve filters, joins and\naggregation over heterogeneous sources. The unique trait of ReQAP is that it\nrecursively decomposes questions and incrementally builds an operator tree for\nexecution. Both the question interpretation and the individual operators make\nsmart use of light-weight language models, with judicious fine-tuning. The demo\nshowcases the rich functionality for advanced user questions, and also offers\ndetailed tracking of how the answers are computed by the operators in the\nexecution tree. Being able to trace answers back to the underlying sources is\nvital for human comprehensibility and user trust in the system.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdReQAP\u7cfb\u7edf\uff0c\u53ef\u652f\u6301\u7528\u6237\u56de\u7b54\u6d89\u53ca\u5f02\u6784\u6e90\u8fc7\u6ee4\u3001\u8fde\u63a5\u548c\u805a\u5408\u7684\u590d\u6742\u95ee\u9898\uff0c\u6709\u9012\u5f52\u5206\u89e3\u95ee\u9898\u548c\u589e\u91cf\u6784\u5efa\u64cd\u4f5c\u6811\u7684\u7279\u70b9\uff0c\u6f14\u793a\u5c55\u793a\u5176\u529f\u80fd\u548c\u7b54\u6848\u8ba1\u7b97\u8fc7\u7a0b\u3002", "motivation": "\u89e3\u51b3\u7528\u6237\u5bf9\u8bbe\u5907\u4e0a\u5f02\u6784\u6e90\u6570\u636e\u63d0\u51fa\u590d\u6742\u95ee\u9898\u83b7\u53d6\u7b54\u6848\u7684\u9700\u6c42\u3002", "method": "\u9012\u5f52\u5206\u89e3\u95ee\u9898\uff0c\u589e\u91cf\u6784\u5efa\u64cd\u4f5c\u6811\u6267\u884c\uff0c\u95ee\u9898\u89e3\u91ca\u548c\u5355\u4e2a\u64cd\u4f5c\u5229\u7528\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u5e76\u5fae\u8c03\u3002", "result": "\u6f14\u793a\u5c55\u793a\u4e86\u7cfb\u7edf\u9488\u5bf9\u9ad8\u7ea7\u7528\u6237\u95ee\u9898\u7684\u4e30\u5bcc\u529f\u80fd\uff0c\u53ef\u8be6\u7ec6\u8ffd\u8e2a\u7b54\u6848\u8ba1\u7b97\u8fc7\u7a0b\u3002", "conclusion": "\u80fd\u591f\u5c06\u7b54\u6848\u8ffd\u6eaf\u5230\u6e90\u6570\u636e\u5bf9\u63d0\u9ad8\u7cfb\u7edf\u7684\u53ef\u7406\u89e3\u6027\u548c\u7528\u6237\u4fe1\u4efb\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.06765", "pdf": "https://arxiv.org/pdf/2508.06765", "abs": "https://arxiv.org/abs/2508.06765", "authors": ["Xingke Yang", "Liang Li", "Sicong Li", "Liwei Guan", "Hao Wang", "Xiaoqi Qi", "Jiang Liu", "Xin Fu", "Miao Pan"], "title": "Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning", "categories": ["cs.LG"], "comment": null, "summary": "Collaboratively fine-tuning (FT) large language models (LLMs) over\nheterogeneous mobile devices fosters immense potential applications of\npersonalized intelligence. However, such a vision faces critical system\nchallenges. Conventional federated LLM FT approaches place prohibitive\ncomputational and memory burdens on mobile hardware, and their synchronous\nmodel aggregation protocols stall for slower devices. In this paper, we propose\nFed MobiLLM, a novel design to facilitate efficient federated LLM FT across\nmobile devices with diverse computing/communication speeds and local model\narchitectures. In particular, Fed MobiLLM implements a pioneering\nserver-assisted federated side-tuning paradigm. Briefly, mobile devices perform\nlightweight forward propagation computations on local data using their frozen\npre-scaled backbone LLMs, and then upload selected intermediate activations.\nThe server trains a shared side-network independently, eliminating client-side\nbackpropagation and enabling asynchronous updates. To bridge model\nheterogeneity across different devices, we introduce an adaptive layer-wise\nfeature alignment method, which ensures consistent representations for\ncollaboratively tuning a shared side network. Extensive experimental results\ndemonstrate that Fed MobiLLM can maintain robust fine-tuning performance while\nachieving extremely low on-device memory, with at least 95.2% reduction in\ncomputation overhead, 93.2% reduction in communication costs and 5.1x faster\nconvergence compared to existing methods, validating its efficacy for practical\nLLM adaptation over heterogeneous mobile devices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFed MobiLLM\u7528\u4e8e\u8de8\u5f02\u6784\u79fb\u52a8\u8bbe\u5907\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8054\u5408\u5fae\u8c03\uff0c\u91c7\u7528\u670d\u52a1\u5668\u8f85\u52a9\u7684\u8054\u90a6\u4fa7\u8c03\u8303\u5f0f\uff0c\u6709\u81ea\u9002\u5e94\u7279\u5f81\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u3001\u5f00\u9500\u4f4e\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\u5728\u79fb\u52a8\u786c\u4ef6\u4e0a\u8ba1\u7b97\u548c\u5185\u5b58\u8d1f\u62c5\u5927\uff0c\u540c\u6b65\u6a21\u578b\u805a\u5408\u534f\u8bae\u53d7\u6162\u8bbe\u5907\u5f71\u54cd\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u5f02\u6784\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u5fae\u8c03\u95ee\u9898\u3002", "method": "\u63d0\u51faFed MobiLLM\uff0c\u5b9e\u73b0\u670d\u52a1\u5668\u8f85\u52a9\u7684\u8054\u90a6\u4fa7\u8c03\u8303\u5f0f\uff0c\u79fb\u52a8\u8bbe\u5907\u7528\u51bb\u7ed3\u9884\u7f29\u653e\u4e3b\u5e72LLM\u8fdb\u884c\u524d\u5411\u4f20\u64ad\uff0c\u4e0a\u4f20\u4e2d\u95f4\u6fc0\u6d3b\uff0c\u670d\u52a1\u5668\u8bad\u7ec3\u5171\u4eab\u4fa7\u7f51\u7edc\uff1b\u5f15\u5165\u81ea\u9002\u5e94\u5c42\u7279\u5f81\u5bf9\u9f50\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cFed MobiLLM\u80fd\u4fdd\u6301\u7a33\u5065\u5fae\u8c03\u6027\u80fd\uff0c\u8bbe\u5907\u5185\u5b58\u6781\u4f4e\uff0c\u8ba1\u7b97\u5f00\u9500\u81f3\u5c11\u964d\u4f4e95.2%\uff0c\u901a\u4fe1\u6210\u672c\u964d\u4f4e93.2%\uff0c\u6536\u655b\u901f\u5ea6\u5feb5.1\u500d\u3002", "conclusion": "Fed MobiLLM\u5bf9\u5f02\u6784\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u5b9e\u9645\u5927\u8bed\u8a00\u6a21\u578b\u9002\u914d\u6709\u6548\u3002"}}
{"id": "2508.07746", "pdf": "https://arxiv.org/pdf/2508.07746", "abs": "https://arxiv.org/abs/2508.07746", "authors": ["Fengdi Che"], "title": "A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Offline reinforcement learning (RL) aims to optimize the return given a fixed\ndataset of agent trajectories without additional interactions with the\nenvironment. While algorithm development has progressed rapidly, significant\ntheoretical advances have also been made in understanding the fundamental\nchallenges of offline RL. However, bridging these theoretical insights with\npractical algorithm design remains an ongoing challenge. In this survey, we\nexplore key intuitions derived from theoretical work and their implications for\noffline RL algorithms.\n  We begin by listing the conditions needed for the proofs, including function\nrepresentation and data coverage assumptions. Function representation\nconditions tell us what to expect for generalization, and data coverage\nassumptions describe the quality requirement of the data. We then examine\ncounterexamples, where offline RL is not solvable without an impractically\nlarge amount of data. These cases highlight what cannot be achieved for all\nalgorithms and the inherent hardness of offline RL. Building on techniques to\nmitigate these challenges, we discuss the conditions that are sufficient for\noffline RL. These conditions are not merely assumptions for theoretical proofs,\nbut they also reveal the limitations of these algorithms and remind us to\nsearch for novel solutions when the conditions cannot be satisfied.", "AI": {"tldr": "\u672c\u6587\u662f\u5173\u4e8e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u7efc\u8ff0\uff0c\u63a2\u8ba8\u7406\u8bba\u89c1\u89e3\u5bf9\u7b97\u6cd5\u8bbe\u8ba1\u7684\u5f71\u54cd\u3002", "motivation": "\u5f25\u5408\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7406\u8bba\u89c1\u89e3\u4e0e\u5b9e\u9645\u7b97\u6cd5\u8bbe\u8ba1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5148\u5217\u51fa\u7406\u8bba\u8bc1\u660e\u6240\u9700\u6761\u4ef6\uff0c\u518d\u5206\u6790\u53cd\u4f8b\uff0c\u6700\u540e\u8ba8\u8bba\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u5145\u5206\u6761\u4ef6\u3002", "result": "\u660e\u786e\u4e86\u7406\u8bba\u8bc1\u660e\u6761\u4ef6\u3001\u7b97\u6cd5\u5c40\u9650\u6027\u53ca\u5e94\u5bf9\u6311\u6218\u7684\u6280\u672f\u3002", "conclusion": "\u8fd9\u4e9b\u6761\u4ef6\u4e0d\u4ec5\u7528\u4e8e\u7406\u8bba\u8bc1\u660e\uff0c\u8fd8\u63d0\u9192\u5728\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\u5bfb\u627e\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06963", "pdf": "https://arxiv.org/pdf/2508.06963", "abs": "https://arxiv.org/abs/2508.06963", "authors": ["Changqing Li", "Tianlin Li", "Xiaohan Zhang", "Aishan Liu", "Li Pan"], "title": "MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) face persistent and evolving trustworthiness\nissues, motivating developers to seek automated and flexible repair methods\nthat enable convenient deployment across diverse scenarios. Existing repair\nmethods like supervised fine-tuning (SFT) and reinforcement learning with human\nfeedback (RLHF) are costly and slow, while prompt engineering lacks robustness\nand scalability. Representation engineering, which steers model behavior by\ninjecting targeted concept vectors during inference, offers a lightweight,\ntraining-free alternative. However, current approaches depend on manually\ncrafted samples and fixed steering strategies, limiting automation and\nadaptability. To overcome these challenges, we propose MASteer, the first\nend-to-end framework for trustworthiness repair in LLMs based on representation\nengineering. MASteer integrates two core components: AutoTester, a multi-agent\nsystem that generates diverse, high-quality steer samples tailored to developer\nneeds; and AutoRepairer, which constructs adaptive steering strategies with\nanchor vectors for automated, context-aware strategy selection during\ninference. Experiments on standard and customized trustworthiness tasks show\nMASteer consistently outperforms baselines, improving metrics by 15.36% on\nLLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model\ncapabilities. MASteer demonstrates strong robustness, generalization, and\npractical value for scalable, efficient trustworthiness repair.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8868\u5f81\u5de5\u7a0b\u7684\u7aef\u5230\u7aef\u6846\u67b6MASteer\u4fee\u590d\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u73b0\u6709\u4fee\u590d\u65b9\u6cd5\u6709\u6210\u672c\u9ad8\u3001\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u7b49\u7f3a\u70b9\uff0c\u5f53\u524d\u8868\u5f81\u5de5\u7a0b\u65b9\u6cd5\u81ea\u52a8\u5316\u548c\u9002\u5e94\u6027\u6709\u9650\u3002", "method": "\u63d0\u51faMASteer\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u5b9a\u5236\u6837\u672c\u7684AutoTester\u548c\u6784\u5efa\u81ea\u9002\u5e94\u8f6c\u5411\u7b56\u7565\u7684AutoRepairer\u3002", "result": "\u5728\u6807\u51c6\u548c\u5b9a\u5236\u53ef\u4fe1\u5ea6\u4efb\u52a1\u4e0a\uff0cMASteer\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5728LLaMA - 3.1 - 8B - Chat\u548cQwen - 3 - 8B - Chat\u4e0a\u5206\u522b\u63d0\u5347\u6307\u680715.36%\u548c4.21%\uff0c\u5e76\u4fdd\u6301\u6a21\u578b\u901a\u7528\u80fd\u529b\u3002", "conclusion": "MASteer\u5177\u6709\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u6027\u548c\u5b9e\u7528\u4ef7\u503c\uff0c\u53ef\u7528\u4e8e\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u7684\u53ef\u4fe1\u5ea6\u4fee\u590d\u3002"}}
{"id": "2508.06971", "pdf": "https://arxiv.org/pdf/2508.06971", "abs": "https://arxiv.org/abs/2508.06971", "authors": ["Mohamed Basem", "Islam Oshallah", "Ali Hamdi", "Khaled Shaban", "Hozaifa Kassab"], "title": "Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction", "categories": ["cs.CL", "cs.IR"], "comment": "8 pages , 4 figures , Accepted in Aiccsa 2025 ,\n  https://conferences.sigappfr.org/aiccsa2025/", "summary": "Quranic Question Answering presents unique challenges due to the linguistic\ncomplexity of Classical Arabic and the semantic richness of religious texts. In\nthis paper, we propose a novel two-stage framework that addresses both passage\nretrieval and answer extraction. For passage retrieval, we ensemble fine-tuned\nArabic language models to achieve superior ranking performance. For answer\nextraction, we employ instruction-tuned large language models with few-shot\nprompting to overcome the limitations of fine-tuning on small datasets. Our\napproach achieves state-of-the-art results on the Quran QA 2023 Shared Task,\nwith a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of\n0.669 for extraction, substantially outperforming previous methods. These\nresults demonstrate that combining model ensembling and instruction-tuned\nlanguage models effectively addresses the challenges of low-resource question\nanswering in specialized domains.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\u5904\u7406\u53e4\u5170\u7ecf\u95ee\u7b54\u95ee\u9898\uff0c\u5728\u76f8\u5173\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u7ed3\u679c\uff0c\u8bc1\u660e\u7ed3\u5408\u6a21\u578b\u96c6\u6210\u548c\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u6709\u6548\u3002", "motivation": "\u53e4\u5170\u7ecf\u95ee\u7b54\u56e0\u53e4\u5178\u963f\u62c9\u4f2f\u8bed\u7684\u8bed\u8a00\u590d\u6742\u6027\u548c\u5b97\u6559\u6587\u672c\u7684\u8bed\u4e49\u4e30\u5bcc\u6027\u5e26\u6765\u72ec\u7279\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5728\u6bb5\u843d\u68c0\u7d22\u65f6\u96c6\u6210\u5fae\u8c03\u7684\u963f\u62c9\u4f2f\u8bed\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u7b54\u6848\u63d0\u53d6\u65f6\u4f7f\u7528\u5c11\u91cf\u6837\u672c\u63d0\u793a\u7684\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728Quran QA 2023\u5171\u4eab\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u7ed3\u679c\uff0c\u68c0\u7d22\u7684MAP@10\u4e3a0.3128\u3001MRR@10\u4e3a0.5763\uff0c\u63d0\u53d6\u7684pAP@10\u4e3a0.669\uff0c\u5927\u5e45\u8d85\u8d8a\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408\u6a21\u578b\u96c6\u6210\u548c\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u80fd\u6709\u6548\u5e94\u5bf9\u4e13\u4e1a\u9886\u57df\u4f4e\u8d44\u6e90\u95ee\u7b54\u6311\u6218\u3002"}}
{"id": "2508.08222", "pdf": "https://arxiv.org/pdf/2508.08222", "abs": "https://arxiv.org/abs/2508.08222", "authors": ["Tong Yang", "Yu Huang", "Yingbin Liang", "Yuejie Chi"], "title": "Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "math.OC", "stat.ML"], "comment": "submitted for consideration of publication in May", "summary": "Transformers have demonstrated remarkable capabilities in multi-step\nreasoning tasks. However, understandings of the underlying mechanisms by which\nthey acquire these abilities through training remain limited, particularly from\na theoretical standpoint. This work investigates how transformers learn to\nsolve symbolic multi-step reasoning problems through chain-of-thought\nprocesses, focusing on path-finding in trees. We analyze two intertwined tasks:\na backward reasoning task, where the model outputs a path from a goal node to\nthe root, and a more complex forward reasoning task, where the model implements\ntwo-stage reasoning by first identifying the goal-to-root path and then\nreversing it to produce the root-to-goal path. Our theoretical analysis,\ngrounded in the dynamics of gradient descent, shows that trained one-layer\ntransformers can provably solve both tasks with generalization guarantees to\nunseen trees. In particular, our multi-phase training dynamics for forward\nreasoning elucidate how different attention heads learn to specialize and\ncoordinate autonomously to solve the two subtasks in a single autoregressive\npath. These results provide a mechanistic explanation of how trained\ntransformers can implement sequential algorithmic procedures. Moreover, they\noffer insights into the emergence of reasoning abilities, suggesting that when\ntasks are structured to take intermediate chain-of-thought steps, even shallow\nmulti-head transformers can effectively solve problems that would otherwise\nrequire deeper architectures.", "AI": {"tldr": "\u7814\u7a76Transformer\u5982\u4f55\u901a\u8fc7\u601d\u7ef4\u94fe\u8fc7\u7a0b\u89e3\u51b3\u7b26\u53f7\u591a\u6b65\u63a8\u7406\u95ee\u9898\uff0c\u7528\u7406\u8bba\u5206\u6790\u8bc1\u660e\u5355\u5c42Transformer\u53ef\u89e3\u51b3\u4efb\u52a1\u5e76\u6709\u6cdb\u5316\u6027\uff0c\u89e3\u91ca\u63a8\u7406\u80fd\u529b\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u5bf9Transformer\u901a\u8fc7\u8bad\u7ec3\u83b7\u5f97\u591a\u6b65\u63a8\u7406\u80fd\u529b\u7684\u5e95\u5c42\u673a\u5236\uff0c\u5c24\u5176\u662f\u7406\u8bba\u5c42\u9762\u7406\u89e3\u6709\u9650\uff0c\u9700\u6df1\u5165\u7814\u7a76\u3002", "method": "\u805a\u7126\u6811\u4e2d\u7684\u8def\u5f84\u67e5\u627e\uff0c\u5206\u6790\u53cd\u5411\u63a8\u7406\u548c\u66f4\u590d\u6742\u7684\u6b63\u5411\u63a8\u7406\u4e24\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u4efb\u52a1\uff0c\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d\u52a8\u529b\u5b66\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u8bad\u7ec3\u540e\u7684\u5355\u5c42Transformer\u80fd\u89e3\u51b3\u4e24\u4e2a\u4efb\u52a1\u5e76\u5bf9\u672a\u89c1\u6811\u6709\u6cdb\u5316\u6027\uff0c\u591a\u9636\u6bb5\u8bad\u7ec3\u52a8\u6001\u9610\u660e\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u5982\u4f55\u81ea\u4e3b\u4e13\u95e8\u5316\u548c\u534f\u8c03\u4ee5\u89e3\u51b3\u5b50\u4efb\u52a1\u3002", "conclusion": "\u89e3\u91ca\u4e86\u8bad\u7ec3\u540e\u7684Transformer\u5b9e\u73b0\u987a\u5e8f\u7b97\u6cd5\u7a0b\u5e8f\u7684\u673a\u5236\uff0c\u8868\u660e\u7ed3\u6784\u5316\u4efb\u52a1\u4f7f\u6d45\u591a\u5934Transformer\u4e5f\u80fd\u89e3\u51b3\u9700\u66f4\u6df1\u67b6\u6784\u7684\u95ee\u9898\u3002"}}
{"id": "2508.07016", "pdf": "https://arxiv.org/pdf/2508.07016", "abs": "https://arxiv.org/abs/2508.07016", "authors": ["Jianfei Wu", "Wenmian Yang", "Bingning Liu", "Weijia Jia"], "title": "TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Time series forecasting is critical across various domains, such as weather,\nfinance and real estate forecasting, as accurate forecasts support informed\ndecision-making and risk mitigation. While recent deep learning models have\nimproved predictive capabilities, they often overlook time-lagged\ncross-correlations between related sequences, which are crucial for capturing\ncomplex temporal relationships. To address this, we propose the Time-Lagged\nCross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances\nforecasting accuracy by effectively integrating time-lagged cross-correlated\nsequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW)\nalgorithm to capture lagged correlations and a contrastive learning-based\nencoder to efficiently approximate SSDTW distances.\n  Experimental results on weather, finance and real estate time series datasets\ndemonstrate the effectiveness of our framework. On the weather dataset, SSDTW\nreduces mean squared error (MSE) by 16.01% compared with single-sequence\nmethods, while the contrastive learning encoder (CLE) further decreases MSE by\n17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE\nreduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by\n21.29% and 8.62%, respectively. Additionally, the contrastive learning approach\ndecreases SSDTW computational time by approximately 99%, ensuring scalability\nand real-time applicability across multiple time series forecasting tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTLCCSP\u6846\u67b6\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u964d\u4f4e\u4e86\u5747\u65b9\u8bef\u5dee\u5e76\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5e38\u5ffd\u7565\u76f8\u5173\u5e8f\u5217\u95f4\u7684\u65f6\u6ede\u4e92\u76f8\u5173\u6027\uff0c\u800c\u8fd9\u5bf9\u6355\u6349\u590d\u6742\u65f6\u95f4\u5173\u7cfb\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u6539\u8fdb\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faTLCCSP\u6846\u67b6\uff0c\u91c7\u7528SSDTW\u7b97\u6cd5\u6355\u6349\u6ede\u540e\u76f8\u5173\u6027\uff0c\u4f7f\u7528\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u7f16\u7801\u5668\u8fd1\u4f3cSSDTW\u8ddd\u79bb\u3002", "result": "\u5728\u5929\u6c14\u3001\u91d1\u878d\u548c\u623f\u5730\u4ea7\u6570\u636e\u96c6\u4e0a\uff0cSSDTW\u548c\u5bf9\u6bd4\u5b66\u4e60\u7f16\u7801\u5668\u5747\u964d\u4f4e\u4e86\u5747\u65b9\u8bef\u5dee\uff0c\u4e14\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u51cf\u5c11\u7ea699%\u7684\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "TLCCSP\u6846\u67b6\u6709\u6548\uff0c\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5177\u5907\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u65f6\u9002\u7528\u6027\u3002"}}
{"id": "2508.06980", "pdf": "https://arxiv.org/pdf/2508.06980", "abs": "https://arxiv.org/abs/2508.06980", "authors": ["Aswin Paul", "Moein Khajehnejad", "Forough Habibollahi", "Brett J. Kagan", "Adeel Razi"], "title": "Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model", "categories": ["cs.AI"], "comment": "18 pages, 8 figures", "summary": "With recent and rapid advancements in artificial intelligence (AI),\nunderstanding the foundation of purposeful behaviour in autonomous agents is\ncrucial for developing safe and efficient systems. While artificial neural\nnetworks have dominated the path to AI, recent studies are exploring the\npotential of biologically based systems, such as networks of living biological\nneuronal networks. Along with promises of high power and data efficiency, these\nsystems may also inform more explainable and biologically plausible models. In\nthis work, we propose a framework rooted in active inference, a general theory\nof behaviour, to model decision-making in embodied agents. Using\nexperiment-informed generative models, we simulate decision-making processes in\na simulated game-play environment, mirroring experimental setups that use\nbiological neurons. Our results demonstrate learning in these agents, providing\ninsights into the role of memory-based learning and predictive planning in\nintelligent decision-making. This work contributes to the growing field of\nexplainable AI by offering a biologically grounded and scalable approach to\nunderstanding purposeful behaviour in agents.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u6846\u67b6\u6765\u5efa\u6a21\u5177\u8eab\u667a\u80fd\u4f53\u51b3\u7b56\uff0c\u6a21\u62df\u6e38\u620f\u73af\u5883\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7ed3\u679c\u5c55\u793a\u4e86\u667a\u80fd\u4f53\u5b66\u4e60\u60c5\u51b5\uff0c\u4e3a\u53ef\u89e3\u91caAI\u505a\u8d21\u732e\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\uff0c\u7406\u89e3\u81ea\u4e3b\u667a\u80fd\u4f53\u6709\u76ee\u7684\u884c\u4e3a\u57fa\u7840\u5bf9\u5f00\u53d1\u5b89\u5168\u9ad8\u6548\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4e14\u751f\u7269\u7cfb\u7edf\u6709\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u5b9e\u9a8c\u4fe1\u606f\u751f\u6210\u6a21\u578b\uff0c\u5728\u6a21\u62df\u6e38\u620f\u73af\u5883\u4e2d\u6a21\u62df\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u5c55\u793a\u4e86\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u60c5\u51b5\uff0c\u63ed\u793a\u4e86\u57fa\u4e8e\u8bb0\u5fc6\u7684\u5b66\u4e60\u548c\u9884\u6d4b\u89c4\u5212\u5728\u667a\u80fd\u51b3\u7b56\u4e2d\u7684\u4f5c\u7528\u3002", "conclusion": "\u4e3a\u53ef\u89e3\u91caAI\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u7269\u5b66\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u7406\u89e3\u667a\u80fd\u4f53\u6709\u76ee\u7684\u7684\u884c\u4e3a\u3002"}}
{"id": "2508.07286", "pdf": "https://arxiv.org/pdf/2508.07286", "abs": "https://arxiv.org/abs/2508.07286", "authors": ["Jian Chen", "Jinbao Tian", "Yankui Li", "Zhou Li"], "title": "Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Accurate information extraction from specialized texts is a critical\nchallenge, particularly for named entity recognition (NER) in the architecture,\nengineering, and construction (AEC) domain to support automated rule checking\n(ARC). The performance of standard pre-trained models is often constrained by\nthe domain gap, as they struggle to interpret the specialized terminology and\ncomplex relational contexts inherent in AEC texts. Although this issue can be\nmitigated by further pre-training on large, human-curated domain corpora, as\nexemplified by methods like ARCBERT, this approach is both labor-intensive and\ncost-prohibitive. Consequently, leveraging large language models (LLMs) for\nautomated knowledge generation has emerged as a promising alternative. However,\nthe optimal strategy for generating knowledge that can genuinely enhance\nsmaller, efficient models remains an open question. To address this, we propose\nARCE (augmented RoBERTa with contextualized elucidations), a novel approach\nthat systematically explores and optimizes this generation process. ARCE\nemploys an LLM to first generate a corpus of simple, direct explanations, which\nwe term Cote, and then uses this corpus to incrementally pre-train a RoBERTa\nmodel prior to its fine-tuning on the downstream task. Our extensive\nexperiments show that ARCE establishes a new state-of-the-art on a benchmark\nAEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a\nkey finding: simple, explanation-based knowledge proves surprisingly more\neffective than complex, role-based rationales for this task. The code is\npublicly available at:https://github.com/nxcc-lab/ARCE.", "AI": {"tldr": "\u63d0\u51faARCE\u65b9\u6cd5\u89e3\u51b3AEC\u9886\u57dfNER\u95ee\u9898\uff0c\u5b9e\u9a8c\u53d6\u5f97\u65b0SOTA\uff0c\u7b80\u5355\u89e3\u91ca\u578b\u77e5\u8bc6\u66f4\u6709\u6548\u3002", "motivation": "\u6807\u51c6\u9884\u8bad\u7ec3\u6a21\u578b\u5728AEC\u9886\u57df\u56e0\u9886\u57df\u5dee\u8ddd\u8868\u73b0\u53d7\u9650\uff0c\u8fdb\u4e00\u6b65\u9884\u8bad\u7ec3\u4eba\u529b\u6210\u672c\u9ad8\uff0c\u5982\u4f55\u7528LLM\u751f\u6210\u77e5\u8bc6\u63d0\u5347\u5c0f\u6a21\u578b\u5f85\u63a2\u7d22\u3002", "method": "\u63d0\u51faARCE\u65b9\u6cd5\uff0c\u7528LLM\u751f\u6210\u7b80\u5355\u89e3\u91ca\u8bed\u6599Cote\uff0c\u7528\u5176\u5bf9RoBERTa\u6a21\u578b\u589e\u91cf\u9884\u8bad\u7ec3\u540e\u5fae\u8c03\u3002", "result": "ARCE\u5728AEC\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u65b0SOTA\uff0cMacro - F1\u5206\u657077.20%\u3002", "conclusion": "\u7b80\u5355\u7684\u57fa\u4e8e\u89e3\u91ca\u7684\u77e5\u8bc6\u6bd4\u590d\u6742\u7684\u57fa\u4e8e\u89d2\u8272\u7684\u63a8\u7406\u5728\u8be5\u4efb\u52a1\u4e2d\u66f4\u6709\u6548\u3002"}}
{"id": "2508.06783", "pdf": "https://arxiv.org/pdf/2508.06783", "abs": "https://arxiv.org/abs/2508.06783", "authors": ["Noel Teku", "Fengwei Tian", "Payel Bhattacharjee", "Souradip Chakraborty", "Amrit Singh Bedi", "Ravi Tandon"], "title": "PROPS: Progressively Private Self-alignment of Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.IT", "math.IT"], "comment": null, "summary": "Alignment is a key step in developing Large Language Models (LLMs) using\nhuman feedback to ensure adherence to human values and societal norms.\nDependence on human feedback raises privacy concerns about how much a labeler's\npreferences may reveal about their personal values, beliefs, and personality\ntraits. Existing approaches, such as Differentially Private SGD (DP-SGD),\nprovide rigorous privacy guarantees by privatizing gradients during fine-tuning\nand alignment but can provide more privacy than necessary as human preferences\nare tied only to labels of (prompt, response) pairs and can degrade model\nutility. This work focuses on LLM alignment with preference-level privacy,\nwhich preserves the privacy of preference labels provided by humans. We propose\nPROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving\nalignment framework where privately aligned models in previous stages can serve\nas labelers for supplementing training data in the subsequent stages of\nalignment. We present theoretical guarantees for PROPS as well as comprehensive\nvalidation using multiple models (Pythia and GPT) and datasets (AlpacaEval,\nAnthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over\nexisting methods while still providing high privacy. For the same privacy\nbudget, alignment via PROPS can achieve up to 3x higher win-rates compared to\nDP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based\nalignment.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4e2d\u7684\u504f\u597d\u7ea7\u9690\u79c1\u95ee\u9898\uff0c\u63d0\u51faPROPS\u6846\u67b6\uff0c\u7ecf\u591a\u6a21\u578b\u548c\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u4fdd\u8bc1\u9ad8\u9690\u79c1\u540c\u65f6\u6709\u66f4\u597d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4f9d\u8d56\u4eba\u7c7b\u53cd\u9988\u5b58\u5728\u9690\u79c1\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u53ef\u80fd\u63d0\u4f9b\u8fc7\u5ea6\u9690\u79c1\u5e76\u964d\u4f4e\u6a21\u578b\u6548\u7528\u3002", "method": "\u63d0\u51faPROPS\u591a\u9636\u6bb5\u9690\u79c1\u4fdd\u62a4\u5bf9\u9f50\u6846\u67b6\uff0c\u524d\u9636\u6bb5\u7684\u79c1\u6709\u5bf9\u9f50\u6a21\u578b\u53ef\u4e3a\u540e\u7eed\u9636\u6bb5\u8865\u5145\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728\u76f8\u540c\u9690\u79c1\u9884\u7b97\u4e0b\uff0cPROPS\u5bf9\u9f50\u7684\u80dc\u7387\u6bd4DP - SGD\u9ad83\u500d\uff0c\u6bd4\u57fa\u4e8e\u968f\u673a\u54cd\u5e94\uff08RR\uff09\u7684\u5bf9\u9f50\u9ad82.5\u500d\u3002", "conclusion": "PROPS\u6846\u67b6\u5728\u4fdd\u8bc1\u9ad8\u9690\u79c1\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u66f4\u597d\u7684\u6548\u7528\u3002"}}
{"id": "2508.07308", "pdf": "https://arxiv.org/pdf/2508.07308", "abs": "https://arxiv.org/abs/2508.07308", "authors": ["Cristian Cosentino", "Annamaria Defilippo", "Marco Dossena", "Christopher Irwin", "Sara Joubbi", "Pietro Li\u00f2"], "title": "HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "HealthBranches is a novel benchmark dataset for medical Question-Answering\n(Q&A), specifically designed to evaluate complex reasoning in Large Language\nModels (LLMs). This dataset is generated through a semi-automated pipeline that\ntransforms explicit decision pathways from medical source into realistic\npatient cases with associated questions and answers. Covering 4,063 case\nstudies across 17 healthcare topics, each data point is based on clinically\nvalidated reasoning chains. HealthBranches supports both open-ended and\nmultiple-choice question formats and uniquely includes the full reasoning path\nfor each Q&A. Its structured design enables robust evaluation of LLMs'\nmulti-step inference capabilities, including their performance in structured\nRetrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a\nfoundation for the development of more trustworthy, interpretable, and\nclinically reliable LLMs in high-stakes domains while also serving as a\nvaluable resource for educational purposes.", "AI": {"tldr": "\u63d0\u51fa\u533b\u7597\u95ee\u7b54\u57fa\u51c6\u6570\u636e\u96c6HealthBranches\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u6709\u591a\u79cd\u7279\u6027\u548c\u7528\u9014\u3002", "motivation": "\u8bbe\u8ba1\u65b0\u7684\u533b\u7597\u95ee\u7b54\u57fa\u51c6\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u534a\u81ea\u52a8\u5316\u6d41\u7a0b\u5c06\u533b\u5b66\u6e90\u4e2d\u7684\u660e\u786e\u51b3\u7b56\u8def\u5f84\u8f6c\u5316\u4e3a\u5b9e\u9645\u60a3\u8005\u6848\u4f8b\u53ca\u76f8\u5173\u95ee\u7b54\u3002", "result": "\u751f\u6210\u6db5\u76d617\u4e2a\u533b\u7597\u4e3b\u98984063\u4e2a\u6848\u4f8b\u7814\u7a76\u7684\u6570\u636e\u96c6\uff0c\u652f\u6301\u591a\u79cd\u95ee\u7b54\u683c\u5f0f\u4e14\u5305\u542b\u5b8c\u6574\u63a8\u7406\u8def\u5f84\u3002", "conclusion": "HealthBranches\u4e3a\u9ad8\u98ce\u9669\u9886\u57df\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u4e34\u5e8a\u53ef\u9760\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5960\u5b9a\u57fa\u7840\uff0c\u4e5f\u53ef\u7528\u4e8e\u6559\u80b2\u3002"}}
{"id": "2508.06784", "pdf": "https://arxiv.org/pdf/2508.06784", "abs": "https://arxiv.org/abs/2508.06784", "authors": ["Junjing Zheng", "Chengliang Song", "Weidong Jiang", "Xinyu Zhang"], "title": "Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "High-dimensional data, particularly in the form of high-order tensors,\npresents a major challenge in self-supervised learning. While MLP-based\nautoencoders (AE) are commonly employed, their dependence on flattening\noperations exacerbates the curse of dimensionality, leading to excessively\nlarge model sizes, high computational overhead, and challenging optimization\nfor deep structural feature capture. Although existing tensor networks\nalleviate computational burdens through tensor decomposition techniques, most\nexhibit limited capability in learning non-linear relationships. To overcome\nthese limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder\n(MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear\nframework and employs a Pick-and-Unfold strategy, facilitating flexible\nper-mode encoding of high-order tensors via recursive unfold-encode-fold\noperations, effectively integrating tensor structural priors. Notably, MA-NTAE\nexhibits linear growth in computational complexity with tensor order and\nproportional growth with mode dimensions. Extensive experiments demonstrate\nMA-NTAE's performance advantages over standard AE and current tensor networks\nin compression and clustering tasks, which become increasingly pronounced for\nhigher-order, higher-dimensional tensors.", "AI": {"tldr": "\u63d0\u51faMode - Aware Non - linear Tucker Autoencoder (MA - NTAE)\u5904\u7406\u9ad8\u7ef4\u5f20\u91cf\u81ea\u76d1\u7763\u5b66\u4e60\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u538b\u7f29\u548c\u805a\u7c7b\u4efb\u52a1\u4e0a\u6709\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709MLP - based autoencoders\u5904\u7406\u9ad8\u7ef4\u5f20\u91cf\u6709\u7ef4\u6570\u707e\u96be\u95ee\u9898\uff0c\u73b0\u6709\u5f20\u91cf\u7f51\u7edc\u5b66\u4e60\u975e\u7ebf\u6027\u5173\u7cfb\u80fd\u529b\u6709\u9650\u3002", "method": "\u5c06\u7ecf\u5178Tucker\u5206\u89e3\u63a8\u5e7f\u5230\u975e\u7ebf\u6027\u6846\u67b6\uff0c\u91c7\u7528Pick - and - Unfold\u7b56\u7565\uff0c\u901a\u8fc7\u9012\u5f52\u5c55\u5f00 - \u7f16\u7801 - \u6298\u53e0\u64cd\u4f5c\u5bf9\u9ad8\u9636\u5f20\u91cf\u8fdb\u884c\u7075\u6d3b\u7684\u9010\u6a21\u5f0f\u7f16\u7801\u3002", "result": "MA - NTAE\u8ba1\u7b97\u590d\u6742\u5ea6\u968f\u5f20\u91cf\u9636\u6570\u7ebf\u6027\u589e\u957f\uff0c\u968f\u6a21\u5f0f\u7ef4\u5ea6\u6210\u6bd4\u4f8b\u589e\u957f\uff0c\u5728\u538b\u7f29\u548c\u805a\u7c7b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6807\u51c6AE\u548c\u5f53\u524d\u5f20\u91cf\u7f51\u7edc\u3002", "conclusion": "MA - NTAE\u80fd\u6709\u6548\u5904\u7406\u9ad8\u7ef4\u5f20\u91cf\u81ea\u76d1\u7763\u5b66\u4e60\u95ee\u9898\uff0c\u5c24\u5176\u5728\u9ad8\u9636\u3001\u9ad8\u7ef4\u5f20\u91cf\u4e0a\u4f18\u52bf\u660e\u663e\u3002"}}
{"id": "2508.07022", "pdf": "https://arxiv.org/pdf/2508.07022", "abs": "https://arxiv.org/abs/2508.07022", "authors": ["Shengtao Wen", "Haodong Chen", "Yadong Wang", "Zhongying Pan", "Xiang Chen", "Yu Tian", "Bo Qian", "Dong Liang", "Sheng-Jun Huang"], "title": "MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": "Under Review", "summary": "Knowledge editing (KE) provides a scalable approach for updating factual\nknowledge in large language models without full retraining. While previous\nstudies have demonstrated effectiveness in general domains and medical QA\ntasks, little attention has been paid to KE in multimodal medical scenarios.\nUnlike text-only settings, medical KE demands integrating updated knowledge\nwith visual reasoning to support safe and interpretable clinical decisions. To\naddress this gap, we propose MultiMedEdit, the first benchmark tailored to\nevaluating KE in clinical multimodal tasks. Our framework spans both\nunderstanding and reasoning task types, defines a three-dimensional metric\nsuite (reliability, generality, and locality), and supports cross-paradigm\ncomparisons across general and domain-specific models. We conduct extensive\nexperiments under single-editing and lifelong-editing settings. Results suggest\nthat current methods struggle with generalization and long-tail reasoning,\nparticularly in complex clinical workflows. We further present an efficiency\nanalysis (e.g., edit latency, memory footprint), revealing practical trade-offs\nin real-world deployment across KE paradigms. Overall, MultiMedEdit not only\nreveals the limitations of current approaches but also provides a solid\nfoundation for developing clinically robust knowledge editing techniques in the\nfuture.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4e34\u5e8a\u591a\u6a21\u6001\u4efb\u52a1\u77e5\u8bc6\u7f16\u8f91\u7684\u57fa\u51c6MultiMedEdit\uff0c\u63ed\u793a\u5f53\u524d\u65b9\u6cd5\u5c40\u9650\u6027\u5e76\u4e3a\u672a\u6765\u6280\u672f\u53d1\u5c55\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5c11\u5173\u6ce8\u591a\u6a21\u6001\u533b\u7597\u573a\u666f\u7684\u77e5\u8bc6\u7f16\u8f91\uff0c\u533b\u7597KE\u9700\u7ed3\u5408\u66f4\u65b0\u77e5\u8bc6\u4e0e\u89c6\u89c9\u63a8\u7406\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\uff0c\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u63d0\u51faMultiMedEdit\u57fa\u51c6\uff0c\u8986\u76d6\u7406\u89e3\u548c\u63a8\u7406\u4efb\u52a1\u7c7b\u578b\uff0c\u5b9a\u4e49\u4e09\u7ef4\u5ea6\u91cf\u5957\u4ef6\uff0c\u652f\u6301\u8de8\u8303\u5f0f\u6bd4\u8f83\uff0c\u5728\u5355\u7f16\u8f91\u548c\u7ec8\u8eab\u7f16\u8f91\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5f53\u524d\u65b9\u6cd5\u5728\u6cdb\u5316\u548c\u957f\u5c3e\u63a8\u7406\u4e0a\u6709\u56f0\u96be\uff0c\u5c24\u5176\u662f\u590d\u6742\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u6548\u7387\u5206\u6790\u63ed\u793aKE\u8303\u5f0f\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6743\u8861\u3002", "conclusion": "MultiMedEdit\u63ed\u793a\u5f53\u524d\u65b9\u6cd5\u5c40\u9650\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u4e34\u5e8a\u9c81\u68d2\u7684\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.06800", "pdf": "https://arxiv.org/pdf/2508.06800", "abs": "https://arxiv.org/abs/2508.06800", "authors": ["Rui Liu", "Haolin Zuo", "Zheng Lian", "Hongyu Yuan", "Qi Fan"], "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Missing modalities have recently emerged as a critical research direction in\nmultimodal emotion recognition (MER). Conventional approaches typically address\nthis issue through missing modality reconstruction. However, these methods fail\nto account for variations in reconstruction difficulty across different\nsamples, consequently limiting the model's ability to handle hard samples\neffectively. To overcome this limitation, we propose a novel Hardness-Aware\nDynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates\nin two key stages: first, it estimates the hardness level of each sample, and\nsecond, it strategically emphasizes hard samples during training to enhance\nmodel performance on these challenging instances. Specifically, we first\nintroduce a Multi-view Hardness Evaluation mechanism that quantifies\nreconstruction difficulty by considering both Direct Hardness (modality\nreconstruction errors) and Indirect Hardness (cross-modal mutual information).\nMeanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy\nthat dynamically adjusts the training curriculum by retrieving samples with\nsimilar semantic information and balancing the learning focus between easy and\nhard instances. Extensive experiments on benchmark datasets demonstrate that\nHARDY-MER consistently outperforms existing methods in missing-modality\nscenarios. Our code will be made publicly available at\nhttps://github.com/HARDY-MER/HARDY-MER.", "AI": {"tldr": "\u63d0\u51faHARDY - MER\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u4e2d\u7f3a\u5931\u6a21\u6001\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7f3a\u5931\u6a21\u6001\u91cd\u5efa\u65b9\u6cd5\u672a\u8003\u8651\u6837\u672c\u91cd\u5efa\u96be\u5ea6\u5dee\u5f02\uff0c\u96be\u4ee5\u6709\u6548\u5904\u7406\u96be\u6837\u672c\u3002", "method": "\u63d0\u51faHARDY - MER\u6846\u67b6\uff0c\u5206\u4e24\u6b65\uff1a\u4e00\u662f\u7528\u591a\u89c6\u56fe\u786c\u5ea6\u8bc4\u4f30\u673a\u5236\u91cf\u5316\u6837\u672c\u96be\u5ea6\uff1b\u4e8c\u662f\u91c7\u7528\u57fa\u4e8e\u68c0\u7d22\u7684\u52a8\u6001\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u8c03\u6574\u8bad\u7ec3\u8bfe\u7a0b\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660eHARDY - MER\u5728\u7f3a\u5931\u6a21\u6001\u573a\u666f\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "HARDY - MER\u80fd\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u7f3a\u5931\u6a21\u6001\u95ee\u9898\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u3002"}}
{"id": "2508.07043", "pdf": "https://arxiv.org/pdf/2508.07043", "abs": "https://arxiv.org/abs/2508.07043", "authors": ["Orion Li", "Vinayak Agarwal", "Summer Zhou", "Ashwin Gopinath", "Timothy Kassis"], "title": "K-Dense Analyst: Towards Fully Automated Scientific Analysis", "categories": ["cs.AI", "cs.MA", "q-bio.GN", "q-bio.QM"], "comment": null, "summary": "The complexity of modern bioinformatics analysis has created a critical gap\nbetween data generation and developing scientific insights. While large\nlanguage models (LLMs) have shown promise in scientific reasoning, they remain\nfundamentally limited when dealing with real-world analytical workflows that\ndemand iterative computation, tool integration and rigorous validation. We\nintroduce K-Dense Analyst, a hierarchical multi-agent system that achieves\nautonomous bioinformatics analysis through a dual-loop architecture. K-Dense\nAnalyst, part of the broader K-Dense platform, couples planning with validated\nexecution using specialized agents to decompose complex objectives into\nexecutable, verifiable tasks within secure computational environments. On\nBixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense\nAnalyst achieves 29.2% accuracy, surpassing the best-performing language model\n(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what\nis widely considered the most powerful LLM available. Remarkably, K-Dense\nAnalyst achieves this performance using Gemini 2.5 Pro, which attains only\n18.3% accuracy when used directly, demonstrating that our architectural\ninnovations unlock capabilities far beyond the underlying model's baseline\nperformance. Our insights demonstrate that autonomous scientific reasoning\nrequires more than enhanced language models, it demands purpose-built systems\nthat can bridge the gap between high-level scientific objectives and low-level\ncomputational execution. These results represent a significant advance toward\nfully autonomous computational biologists capable of accelerating discovery\nacross the life sciences.", "AI": {"tldr": "\u63d0\u51faK - Dense Analyst\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7528\u4e8e\u81ea\u4e3b\u751f\u7269\u4fe1\u606f\u5b66\u5206\u6790\uff0c\u5728BixBench\u4e0a\u8868\u73b0\u8d85GPT - 5\uff0c\u8bc1\u660e\u81ea\u4e3b\u79d1\u5b66\u63a8\u7406\u9700\u4e13\u7528\u7cfb\u7edf\u3002", "motivation": "\u73b0\u4ee3\u751f\u7269\u4fe1\u606f\u5b66\u5206\u6790\u590d\u6742\uff0c\u6570\u636e\u751f\u6210\u4e0e\u79d1\u5b66\u6d1e\u5bdf\u5b58\u5728\u5dee\u8ddd\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u5b9e\u9645\u5206\u6790\u5de5\u4f5c\u6d41\u6709\u5c40\u9650\u3002", "method": "\u5f15\u5165K - Dense Analyst\uff0c\u91c7\u7528\u53cc\u5faa\u73af\u67b6\u6784\uff0c\u901a\u8fc7\u4e13\u4e1a\u667a\u80fd\u4f53\u5c06\u590d\u6742\u76ee\u6807\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u3001\u53ef\u9a8c\u8bc1\u4efb\u52a1\u3002", "result": "\u5728BixBench\u4e0a\uff0cK - Dense Analyst\u51c6\u786e\u7387\u8fbe29.2%\uff0c\u8d85GPT - 5 6.3\u4e2a\u767e\u5206\u70b9\uff0c\u7528Gemini 2.5 Pro\u5b9e\u73b0\u8fdc\u8d85\u5176\u76f4\u63a5\u4f7f\u7528\u7684\u6027\u80fd\u3002", "conclusion": "\u81ea\u4e3b\u79d1\u5b66\u63a8\u7406\u9700\u4e13\u7528\u7cfb\u7edf\uff0c\u8be5\u6210\u679c\u5411\u5168\u81ea\u4e3b\u8ba1\u7b97\u751f\u7269\u5b66\u5bb6\u8fc8\u8fdb\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2508.06806", "pdf": "https://arxiv.org/pdf/2508.06806", "abs": "https://arxiv.org/abs/2508.06806", "authors": ["Xiao Huang", "Xu Liu", "Enze Zhang", "Tong Yu", "Shuai Li"], "title": "Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML2025", "summary": "Offline-to-online Reinforcement Learning (O2O RL) aims to perform online\nfine-tuning on an offline pre-trained policy to minimize costly online\ninteractions. Existing work used offline datasets to generate data that conform\nto the online data distribution for data augmentation. However, generated data\nstill exhibits a gap with the online data, limiting overall performance. To\naddress this, we propose a new data augmentation approach, Classifier-Free\nDiffusion Generation (CFDG). Without introducing additional classifier training\noverhead, CFDG leverages classifier-free guidance diffusion to significantly\nenhance the generation quality of offline and online data with different\ndistributions. Additionally, it employs a reweighting method to enable more\ngenerated data to align with the online data, enhancing performance while\nmaintaining the agent's stability. Experimental results show that CFDG\noutperforms replaying the two data types or using a standard diffusion model to\ngenerate new data. Our method is versatile and can be integrated with existing\noffline-to-online RL algorithms. By implementing CFDG to popular methods IQL,\nPEX and APL, we achieve a notable 15% average improvement in empirical\nperformance on the D4RL benchmark such as MuJoCo and AntMaze.", "AI": {"tldr": "\u63d0\u51faCFDG\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7528\u4e8e\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u80fd\u4e0e\u73b0\u6709\u7b97\u6cd5\u96c6\u6210\uff0c\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u63d0\u534715%\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u751f\u6210\u6570\u636e\u4e0e\u5728\u7ebf\u6570\u636e\u6709\u5dee\u8ddd\uff0c\u9650\u5236\u6574\u4f53\u6027\u80fd\u3002", "method": "\u63d0\u51faClassifier-Free Diffusion Generation (CFDG)\u65b9\u6cd5\uff0c\u5229\u7528\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u6269\u6563\u63d0\u5347\u4e0d\u540c\u5206\u5e03\u6570\u636e\u751f\u6210\u8d28\u91cf\uff0c\u91c7\u7528\u91cd\u52a0\u6743\u65b9\u6cd5\u4f7f\u751f\u6210\u6570\u636e\u66f4\u7b26\u5408\u5728\u7ebf\u6570\u636e\u5206\u5e03\u3002", "result": "CFDG\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u56de\u653e\u4e24\u79cd\u6570\u636e\u6216\u4f7f\u7528\u6807\u51c6\u6269\u6563\u6a21\u578b\u751f\u6210\u65b0\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u96c6\u6210\u5230\u6d41\u884c\u65b9\u6cd5\u4e2d\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u5e73\u5747\u63d0\u534715%\u6027\u80fd\u3002", "conclusion": "CFDG\u65b9\u6cd5\u6709\u6548\u4e14\u901a\u7528\uff0c\u53ef\u4e0e\u73b0\u6709\u79bb\u7ebf\u5230\u5728\u7ebfRL\u7b97\u6cd5\u96c6\u6210\u3002"}}
{"id": "2508.07063", "pdf": "https://arxiv.org/pdf/2508.07063", "abs": "https://arxiv.org/abs/2508.07063", "authors": ["Naseem Machlovi", "Maryam Saleki", "Innocent Ababio", "Ruhul Amin"], "title": "Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach", "categories": ["cs.AI"], "comment": null, "summary": "As AI systems become more integrated into daily life, the need for safer and\nmore reliable moderation has never been greater. Large Language Models (LLMs)\nhave demonstrated remarkable capabilities, surpassing earlier models in\ncomplexity and performance. Their evaluation across diverse tasks has\nconsistently showcased their potential, enabling the development of adaptive\nand personalized agents. However, despite these advancements, LLMs remain prone\nto errors, particularly in areas requiring nuanced moral reasoning. They\nstruggle with detecting implicit hate, offensive language, and gender biases\ndue to the subjective and context-dependent nature of these issues. Moreover,\ntheir reliance on training data can inadvertently reinforce societal biases,\nleading to inconsistencies and ethical concerns in their outputs. To explore\nthe limitations of LLMs in this role, we developed an experimental framework\nbased on state-of-the-art (SOTA) models to assess human emotions and offensive\nbehaviors. The framework introduces a unified benchmark dataset encompassing 49\ndistinct categories spanning the wide spectrum of human emotions, offensive and\nhateful text, and gender and racial biases. Furthermore, we introduced SafePhi,\na QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and\noutperforming benchmark moderators by achieving a Macro F1 score of 0.89, where\nOpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This\nresearch also highlights the critical domains where LLM moderators consistently\nunderperformed, pressing the need to incorporate more heterogeneous and\nrepresentative data with human-in-the-loop, for better model robustness and\nexplainability.", "AI": {"tldr": "\u968f\u7740AI\u878d\u5165\u751f\u6d3b\uff0c\u5bf9\u5b89\u5168\u53ef\u9760\u5ba1\u6838\u7684\u9700\u6c42\u589e\u52a0\u3002\u7814\u7a76\u6307\u51faLLMs\u5b58\u5728\u4e0d\u8db3\uff0c\u5f00\u53d1\u5b9e\u9a8c\u6846\u67b6\u8bc4\u4f30\uff0c\u63a8\u51faSafePhi\u8868\u73b0\u4f73\uff0c\u5f3a\u8c03\u9700\u6539\u8fdb\u6570\u636e\u63d0\u5347\u6a21\u578b\u3002", "motivation": "AI\u878d\u5165\u751f\u6d3b\u540e\uff0cLLMs\u867d\u6709\u80fd\u529b\u4f46\u5728\u5ba1\u6838\u65b9\u9762\u5b58\u5728\u6613\u51fa\u9519\u3001\u5f3a\u5316\u504f\u89c1\u7b49\u95ee\u9898\uff0c\u9700\u63a2\u7d22\u5176\u5728\u5ba1\u6838\u89d2\u8272\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eSOTA\u6a21\u578b\u7684\u5b9e\u9a8c\u6846\u67b6\uff0c\u5f15\u5165\u5305\u542b49\u4e2a\u7c7b\u522b\u7684\u7edf\u4e00\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u63a8\u51faQLoRA\u5fae\u8c03\u7248SafePhi\u3002", "result": "SafePhi\u7684Macro F1\u5206\u6570\u8fbe0.89\uff0c\u4f18\u4e8eOpenAI Moderator\u548cLlama Guard\u3002", "conclusion": "\u5f3a\u8c03\u5e94\u7eb3\u5165\u66f4\u591a\u5f02\u8d28\u548c\u6709\u4ee3\u8868\u6027\u7684\u6570\u636e\u5e76\u7ed3\u5408\u4eba\u5de5\uff0c\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.07980", "pdf": "https://arxiv.org/pdf/2508.07980", "abs": "https://arxiv.org/abs/2508.07980", "authors": ["Alan Said"], "title": "Early Explorations of Recommender Systems for Physical Activity and Well-being", "categories": ["cs.HC", "cs.IR"], "comment": "Second International Workshop on Recommender Systems for\n  Sustainability and Social Good (RecSoGood) in conjunction with ACM RecSys\n  2025", "summary": "As recommender systems increasingly guide physical actions, often through\nwearables and coaching tools, new challenges arise around how users interpret,\ntrust, and respond to this advice. This paper introduces a conceptual framework\nfor tangible recommendations that influence users' bodies, routines, and\nwell-being. We describe three design dimensions: trust and interpretation,\nintent alignment, and consequence awareness. These highlight key limitations in\napplying conventional recommender logic to embodied settings. Through examples\nand design reflections, we outline how future systems can support long-term\nwell-being, behavioral alignment, and socially responsible personalization.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u6709\u5f62\u63a8\u8350\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u6307\u51fa\u4f20\u7edf\u63a8\u8350\u903b\u8f91\u5e94\u7528\u5c40\u9650\u5e76\u7ed9\u51fa\u672a\u6765\u7cfb\u7edf\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u63a8\u8350\u7cfb\u7edf\u6307\u5bfc\u8eab\u4f53\u884c\u52a8\uff0c\u51fa\u73b0\u7528\u6237\u5bf9\u5efa\u8bae\u7684\u89e3\u8bfb\u3001\u4fe1\u4efb\u548c\u54cd\u5e94\u95ee\u9898\uff0c\u9700\u65b0\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u8bbe\u8ba1\u7ef4\u5ea6\uff0c\u7ed3\u5408\u5b9e\u4f8b\u548c\u8bbe\u8ba1\u53cd\u601d\u3002", "result": "\u660e\u786e\u5c06\u4f20\u7edf\u63a8\u8350\u903b\u8f91\u5e94\u7528\u4e8e\u5177\u8eab\u573a\u666f\u7684\u5173\u952e\u5c40\u9650\u3002", "conclusion": "\u6307\u660e\u672a\u6765\u7cfb\u7edf\u53ef\u652f\u6301\u957f\u671f\u798f\u7949\u3001\u884c\u4e3a\u5bf9\u9f50\u548c\u793e\u4f1a\u8d23\u4efb\u4e2a\u6027\u5316\u3002"}}
{"id": "2508.06813", "pdf": "https://arxiv.org/pdf/2508.06813", "abs": "https://arxiv.org/abs/2508.06813", "authors": ["Brendan R. Hogan", "Will Brown", "Adel Boyarsky", "Anderson Schneider", "Yuriy Nevmyvaka"], "title": "Technical Report: Full-Stack Fine-Tuning for the Q Programming Language", "categories": ["cs.LG"], "comment": "40 pages", "summary": "Even though large language models are becoming increasingly capable, it is\nstill unreasonable to expect them to excel at tasks that are under-represented\non the Internet. Leveraging LLMs for specialized applications, particularly in\nniche programming languages and private domains, remains challenging and\nlargely unsolved. In this work, we address this gap by presenting a\ncomprehensive, open-source approach for adapting LLMs to the Q programming\nlanguage, a popular tool in quantitative finance that is much less present on\nthe Internet compared to Python, C, Java, and other ``mainstream\" languages and\nis therefore not a strong suit of general-purpose AI models. We introduce a new\nLeetcode style evaluation dataset for Q, benchmark major frontier models on the\ndataset, then do pretraining, supervised fine tuning, and reinforcement\nlearning to train a suite of reasoning and non-reasoning models based on the\nQwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our\nbest model achieves a pass@1 accuracy of 59 percent on our Q benchmark,\nsurpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.\nAdditionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.\nIn addition to releasing models, code, and data, we provide a detailed\nblueprint for dataset construction, model pretraining, supervised fine-tuning,\nand reinforcement learning. Our methodology is broadly applicable, and we\ndiscuss how these techniques can be extended to other tasks, including those\nwhere evaluation may rely on soft or subjective signals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9002\u5e94Q\u7f16\u7a0b\u8bed\u8a00\u7684\u5f00\u6e90\u65b9\u6cd5\uff0c\u8bad\u7ec3\u7cfb\u5217\u6a21\u578b\uff0c\u6700\u4f73\u6a21\u578b\u8868\u73b0\u8d85\u524d\u6cbf\u6a21\u578b\uff0c\u8fd8\u63d0\u4f9b\u8be6\u7ec6\u65b9\u6848\u53ca\u63a8\u5e7f\u8ba8\u8bba\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e92\u8054\u7f51\u6570\u636e\u5c11\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0cQ\u8bed\u8a00\u5728\u4e92\u8054\u7f51\u6570\u636e\u5c11\uff0c\u901a\u7528AI\u6a21\u578b\u4e0d\u64c5\u957f\uff0c\u9700\u9002\u914d\u3002", "method": "\u5f15\u5165Q\u8bed\u8a00\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u5bf9\u524d\u6cbf\u6a21\u578b\u505a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8eQwen - 2.5\u7cfb\u5217\u8fdb\u884c\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u3001\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63a8\u7406\u548c\u975e\u63a8\u7406\u6a21\u578b\u3002", "result": "\u6700\u4f73\u6a21\u578b\u5728Q\u57fa\u51c6\u6d4b\u8bd5\u4e2dpass@1\u51c6\u786e\u7387\u8fbe59%\uff0c\u8d85Claude Opus - 4 29.5%\uff0c\u6240\u6709\u6a21\u578b\u8d85GPT - 4.1\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u6a21\u578b\u3001\u4ee3\u7801\u3001\u6570\u636e\u53ca\u8be6\u7ec6\u65b9\u6848\uff0c\u65b9\u6cd5\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5176\u4ed6\u4efb\u52a1\u3002"}}
{"id": "2508.07107", "pdf": "https://arxiv.org/pdf/2508.07107", "abs": "https://arxiv.org/abs/2508.07107", "authors": ["Timothy Oluwapelumi Adeyemi", "Nadiah Fahad AlOtaibi"], "title": "Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention", "categories": ["cs.AI", "cs.CY", "K.3.1; I.2.6; H.4"], "comment": "10 pages, 1 figure, 3 tables", "summary": "Accurate prediction of student performance is essential for timely academic\nintervention. However, most machine learning models in education are static and\ncannot adapt when new data, such as post-intervention outcomes, become\navailable. To address this limitation, we propose a Feedback-Driven Decision\nSupport System (DSS) with a closed-loop architecture that enables continuous\nmodel refinement. The system integrates a LightGBM-based regressor with\nincremental retraining, allowing educators to input updated student results,\nwhich automatically trigger model updates. This adaptive mechanism improves\nprediction accuracy by learning from real-world academic progress. The platform\nfeatures a Flask-based web interface for real-time interaction and incorporates\nSHAP for explainability, ensuring transparency. Experimental results show a\n10.7\\% reduction in RMSE after retraining, with consistent upward adjustments\nin predicted scores for intervened students. By transforming static predictors\ninto self-improving systems, our approach advances educational analytics toward\nhuman-centered, data-driven, and responsive AI. The framework is designed for\nintegration into LMS and institutional dashboards.", "AI": {"tldr": "\u63d0\u51fa\u53cd\u9988\u9a71\u52a8\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u6539\u8fdb\u5b66\u751f\u6210\u7ee9\u9884\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793a\u964d\u4f4eRMSE\u3002", "motivation": "\u591a\u6570\u6559\u80b2\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9759\u6001\uff0c\u65e0\u6cd5\u9002\u5e94\u65b0\u6570\u636e\uff0c\u9700\u6301\u7eed\u6539\u8fdb\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u95ed\u73af\u67b6\u6784\u7684\u53cd\u9988\u9a71\u52a8\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u96c6\u6210LightGBM\u56de\u5f52\u5668\u5e76\u589e\u91cf\u518d\u8bad\u7ec3\uff0c\u6709Flask\u754c\u9762\u548cSHAP\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u518d\u8bad\u7ec3\u540eRMSE\u964d\u4f4e10.7%\uff0c\u5e72\u9884\u5b66\u751f\u9884\u6d4b\u5206\u6570\u4e0a\u8c03\u3002", "conclusion": "\u5c06\u9759\u6001\u9884\u6d4b\u5668\u8f6c\u4e3a\u81ea\u6539\u8fdb\u7cfb\u7edf\uff0c\u63a8\u52a8\u6559\u80b2\u5206\u6790\u5411\u4ee5\u4eba\u4e3a\u4e3b\u3001\u6570\u636e\u9a71\u52a8\u548c\u54cd\u5e94\u5f0fAI\u53d1\u5c55\uff0c\u6846\u67b6\u53ef\u96c6\u6210\u5230LMS\u548c\u673a\u6784\u4eea\u8868\u76d8\u3002"}}
{"id": "2508.06827", "pdf": "https://arxiv.org/pdf/2508.06827", "abs": "https://arxiv.org/abs/2508.06827", "authors": ["Ishwar Balappanawar", "Venkata Hasith Vattikuti", "Greta Kintzley", "Ronan Azimi-Mancel", "Satvik Golechha"], "title": "Who's the Evil Twin? Differential Auditing for Undesired Behavior", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "main section: 8 pages, 4 figures, 1 table total: 34 pages, 44\n  figures, 12 tables", "summary": "Detecting hidden behaviors in neural networks poses a significant challenge\ndue to minimal prior knowledge and potential adversarial obfuscation. We\nexplore this problem by framing detection as an adversarial game between two\nteams: the red team trains two similar models, one trained solely on benign\ndata and the other trained on data containing hidden harmful behavior, with the\nperformance of both being nearly indistinguishable on the benign dataset. The\nblue team, with limited to no information about the harmful behaviour, tries to\nidentify the compromised model. We experiment using CNNs and try various blue\nteam strategies, including Gaussian noise analysis, model diffing, integrated\ngradients, and adversarial attacks under different levels of hints provided by\nthe red team. Results show high accuracy for adversarial-attack-based methods\n(100\\% correct prediction, using hints), which is very promising, whilst the\nother techniques yield more varied performance. During our LLM-focused rounds,\nwe find that there are not many parallel methods that we could apply from our\nstudy with CNNs. Instead, we find that effective LLM auditing methods require\nsome hints about the undesired distribution, which can then used in standard\nblack-box and open-weight methods to probe the models further and reveal their\nmisalignment. We open-source our auditing games (with the model and data) and\nhope that our findings contribute to designing better audits.", "AI": {"tldr": "\u672c\u6587\u5c06\u795e\u7ecf\u7f51\u7edc\u9690\u85cf\u884c\u4e3a\u68c0\u6d4b\u6784\u5efa\u4e3a\u7ea2\u84dd\u5bf9\u6297\u6e38\u620f\uff0c\u7528CNN\u5b9e\u9a8c\u591a\u79cd\u68c0\u6d4b\u7b56\u7565\uff0c\u5bf9\u6297\u653b\u51fb\u6cd5\u51c6\u786e\u7387\u9ad8\uff0cLLM\u5ba1\u8ba1\u9700\u63d0\u793a\u4fe1\u606f\uff0c\u8fd8\u5f00\u6e90\u5ba1\u8ba1\u6e38\u620f\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u9690\u85cf\u884c\u4e3a\u68c0\u6d4b\u56e0\u5148\u9a8c\u77e5\u8bc6\u5c11\u548c\u5bf9\u6297\u6df7\u6dc6\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u5c06\u68c0\u6d4b\u6784\u5efa\u4e3a\u7ea2\u84dd\u5bf9\u6297\u6e38\u620f\uff0c\u7ea2\u961f\u8bad\u7ec3\u6b63\u5e38\u548c\u542b\u6709\u5bb3\u884c\u4e3a\u6a21\u578b\uff0c\u84dd\u961f\u5728\u4fe1\u606f\u6709\u9650\u4e0b\u8bc6\u522b\uff1b\u7528CNN\u5b9e\u9a8c\uff0c\u5c1d\u8bd5\u9ad8\u65af\u566a\u58f0\u5206\u6790\u3001\u6a21\u578b\u5dee\u5f02\u6bd4\u8f83\u7b49\u7b56\u7565\uff1b\u5728LLM\u8f6e\u6b21\u63a2\u7d22\u9002\u7528\u65b9\u6cd5\u3002", "result": "\u5bf9\u6297\u653b\u51fb\u6cd5\u51c6\u786e\u7387\u8fbe100%\uff0c\u5176\u4ed6\u7b56\u7565\u6548\u679c\u4e0d\u4e00\uff1bLLM\u5ba1\u8ba1\u9700\u5173\u4e8e\u4e0d\u826f\u5206\u5e03\u7684\u63d0\u793a\u4fe1\u606f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u597d\u7684\u5ba1\u8ba1\uff0c\u5f00\u6e90\u5ba1\u8ba1\u6e38\u620f\u671f\u671b\u63a8\u52a8\u76f8\u5173\u5de5\u4f5c\u3002"}}
{"id": "2508.07186", "pdf": "https://arxiv.org/pdf/2508.07186", "abs": "https://arxiv.org/abs/2508.07186", "authors": ["Amit Dhanda"], "title": "Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "We propose a novel framework for summarizing structured enterprise data\nacross multiple dimensions using large language model (LLM)-based agents.\nTraditional table-to-text models often lack the capacity to reason across\nhierarchical structures and context-aware deltas, which are essential in\nbusiness reporting tasks. Our method introduces a multi-agent pipeline that\nextracts, analyzes, and summarizes multi-dimensional data using agents for\nslicing, variance detection, context construction, and LLM-based generation.\nOur results show that the proposed framework outperforms traditional\napproaches, achieving 83\\% faithfulness to underlying data, superior coverage\nof significant changes, and high relevance scores (4.4/5) for decision-critical\ninsights. The improvements are especially pronounced in categories involving\nsubtle trade-offs, such as increased revenue due to price changes amid\ndeclining unit volumes, which competing methods either overlook or address with\nlimited specificity. We evaluate the framework on Kaggle datasets and\ndemonstrate significant improvements in faithfulness, relevance, and insight\nquality over baseline table summarization approaches.", "AI": {"tldr": "\u63d0\u51fa\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u603b\u7ed3\u4f01\u4e1a\u591a\u7ef4\u7ed3\u6784\u5316\u6570\u636e\u7684\u6846\u67b6\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8868\u8f6c\u6587\u672c\u6a21\u578b\u7f3a\u4e4f\u8de8\u5c42\u6b21\u7ed3\u6784\u63a8\u7406\u548c\u611f\u77e5\u4e0a\u4e0b\u6587\u5dee\u5f02\u7684\u80fd\u529b\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5546\u4e1a\u62a5\u544a\u9700\u6c42\u3002", "method": "\u5f15\u5165\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff0c\u5229\u7528\u5207\u7247\u3001\u65b9\u5dee\u68c0\u6d4b\u3001\u4e0a\u4e0b\u6587\u6784\u5efa\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u667a\u80fd\u4f53\u63d0\u53d6\u3001\u5206\u6790\u548c\u603b\u7ed3\u591a\u7ef4\u6570\u636e\u3002", "result": "\u8be5\u6846\u67b6\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u6570\u636e\u5fe0\u5b9e\u5ea6\u8fbe83%\uff0c\u5bf9\u91cd\u5927\u53d8\u5316\u8986\u76d6\u7387\u9ad8\uff0c\u51b3\u7b56\u5173\u952e\u6d1e\u5bdf\u76f8\u5173\u6027\u5f97\u52064.4/5\uff0c\u5728\u6d89\u53ca\u5fae\u5999\u6743\u8861\u7684\u7c7b\u522b\u4e2d\u6539\u8fdb\u660e\u663e\u3002", "conclusion": "\u5728Kaggle\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u5fe0\u5b9e\u5ea6\u3001\u76f8\u5173\u6027\u548c\u6d1e\u5bdf\u8d28\u91cf\u4e0a\u6bd4\u57fa\u7ebf\u8868\u603b\u7ed3\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2508.06871", "pdf": "https://arxiv.org/pdf/2508.06871", "abs": "https://arxiv.org/abs/2508.06871", "authors": ["Aleksandar Todorov", "Juan Cardenas-Cartagena", "Rafael F. Cunha", "Marco Zullich", "Matthia Sabatelli"], "title": "Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Plasticity loss, a diminishing capacity to adapt as training progresses, is a\ncritical challenge in deep reinforcement learning. We examine this issue in\nmulti-task reinforcement learning (MTRL), where higher representational\nflexibility is crucial for managing diverse and potentially conflicting task\ndemands. We systematically explore how sparsification methods, particularly\nGradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance\nplasticity and consequently improve performance in MTRL agents. We evaluate\nthese approaches across distinct MTRL architectures (shared backbone, Mixture\nof Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks,\ncomparing against dense baselines, and a comprehensive range of alternative\nplasticity-inducing or regularization methods. Our results demonstrate that\nboth GMP and SET effectively mitigate key indicators of plasticity degradation,\nsuch as neuron dormancy and representational collapse. These plasticity\nimprovements often correlate with enhanced multi-task performance, with sparse\nagents frequently outperforming dense counterparts and achieving competitive\nresults against explicit plasticity interventions. Our findings offer insights\ninto the interplay between plasticity, network sparsity, and MTRL designs,\nhighlighting dynamic sparsification as a robust but context-sensitive tool for\ndeveloping more adaptable MTRL systems.", "AI": {"tldr": "\u7814\u7a76\u7a00\u758f\u5316\u65b9\u6cd5\uff08GMP\u548cSET\uff09\u5728\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\uff08MTRL\uff09\u4e2d\u589e\u5f3a\u53ef\u5851\u6027\u3001\u63d0\u5347\u6027\u80fd\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u80fd\u7f13\u89e3\u53ef\u5851\u6027\u9000\u5316\uff0c\u63d0\u5347\u591a\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u8bad\u7ec3\u65f6\u53ef\u5851\u6027\u635f\u5931\u7684\u95ee\u9898\uff0c\u5728MTRL\u4e2d\u66f4\u9ad8\u7684\u8868\u5f81\u7075\u6d3b\u6027\u5f88\u5173\u952e\u3002", "method": "\u7cfb\u7edf\u63a2\u7d22GMP\u548cSET\u4e24\u79cd\u7a00\u758f\u5316\u65b9\u6cd5\uff0c\u5728\u4e0d\u540cMTRL\u67b6\u6784\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u5bc6\u96c6\u57fa\u7ebf\u53ca\u591a\u79cd\u66ff\u4ee3\u65b9\u6cd5\u5bf9\u6bd4\u3002", "result": "GMP\u548cSET\u80fd\u6709\u6548\u7f13\u89e3\u53ef\u5851\u6027\u9000\u5316\u7684\u5173\u952e\u6307\u6807\uff0c\u63d0\u5347\u591a\u4efb\u52a1\u6027\u80fd\uff0c\u7a00\u758f\u4ee3\u7406\u5e38\u4f18\u4e8e\u5bc6\u96c6\u4ee3\u7406\u3002", "conclusion": "\u63ed\u793a\u4e86\u53ef\u5851\u6027\u3001\u7f51\u7edc\u7a00\u758f\u6027\u548cMTRL\u8bbe\u8ba1\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u52a8\u6001\u7a00\u758f\u5316\u662f\u5f00\u53d1\u66f4\u5177\u9002\u5e94\u6027MTRL\u7cfb\u7edf\u7684\u6709\u6548\u4f46\u9700\u8003\u8651\u4e0a\u4e0b\u6587\u7684\u5de5\u5177\u3002"}}
{"id": "2508.07292", "pdf": "https://arxiv.org/pdf/2508.07292", "abs": "https://arxiv.org/abs/2508.07292", "authors": ["Yi Tang", "Kaini Wang", "Yang Chen", "Guangquan Zhou"], "title": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Developing general artificial intelligence (AI) systems to support endoscopic\nimage diagnosis is an emerging research priority. Existing methods based on\nlarge-scale pretraining often lack unified coordination across tasks and\nstruggle to handle the multi-step processes required in complex clinical\nworkflows. While AI agents have shown promise in flexible instruction parsing\nand tool integration across domains, their potential in endoscopy remains\nunderexplored. To address this gap, we propose EndoAgent, the first\nmemory-guided agent for vision-to-decision endoscopic analysis that integrates\niterative reasoning with adaptive tool selection and collaboration. Built on a\ndual-memory design, it enables sophisticated decision-making by ensuring\nlogical coherence through short-term action tracking and progressively\nenhancing reasoning acuity through long-term experiential learning. To support\ndiverse clinical tasks, EndoAgent integrates a suite of expert-designed tools\nwithin a unified reasoning loop. We further introduce EndoAgentBench, a\nbenchmark of 5,709 visual question-answer pairs that assess visual\nunderstanding and language generation capabilities in realistic scenarios.\nExtensive experiments show that EndoAgent consistently outperforms both general\nand medical multimodal models, exhibiting its strong flexibility and reasoning\ncapabilities.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u7528\u4e8e\u5185\u7aa5\u955c\u56fe\u50cf\u5206\u6790\u7684\u8bb0\u5fc6\u5f15\u5bfc\u4ee3\u7406EndoAgent\uff0c\u5e76\u5f15\u5165EndoAgentBench\u57fa\u51c6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\u5728\u8de8\u4efb\u52a1\u534f\u8c03\u548c\u5904\u7406\u590d\u6742\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0cAI\u4ee3\u7406\u5728\u5185\u7aa5\u955c\u9886\u57df\u7684\u6f5c\u529b\u672a\u5145\u5206\u6316\u6398\u3002", "method": "\u63d0\u51faEndoAgent\uff0c\u91c7\u7528\u53cc\u5185\u5b58\u8bbe\u8ba1\uff0c\u96c6\u6210\u8fed\u4ee3\u63a8\u7406\u3001\u81ea\u9002\u5e94\u5de5\u5177\u9009\u62e9\u4e0e\u534f\u4f5c\uff0c\u5728\u7edf\u4e00\u63a8\u7406\u5faa\u73af\u4e2d\u96c6\u6210\u4e13\u5bb6\u8bbe\u8ba1\u5de5\u5177\uff1b\u5f15\u5165EndoAgentBench\u57fa\u51c6\u3002", "result": "EndoAgent\u5728\u5b9e\u9a8c\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u901a\u7528\u548c\u533b\u5b66\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u7075\u6d3b\u6027\u548c\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "EndoAgent\u662f\u4e00\u79cd\u6709\u6548\u7684\u5185\u7aa5\u955c\u56fe\u50cf\u5206\u6790\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.06885", "pdf": "https://arxiv.org/pdf/2508.06885", "abs": "https://arxiv.org/abs/2508.06885", "authors": ["Anthony Bellotti", "Xindi Zhao"], "title": "Conformal Prediction and Trustworthy AI", "categories": ["cs.LG"], "comment": "Preprint for an essay to be published in The Importance of Being\n  Learnable (Enhancing the Learnability and Reliability of Machine Learning\n  Algorithms) Essays Dedicated to Alexander Gammerman on His 80th Birthday,\n  LNCS Springer Nature Switzerland AG ed. Nguyen K.A. and Luo Z", "summary": "Conformal predictors are machine learning algorithms developed in the 1990's\nby Gammerman, Vovk, and their research team, to provide set predictions with\nguaranteed confidence level. Over recent years, they have grown in popularity\nand have become a mainstream methodology for uncertainty quantification in the\nmachine learning community. From its beginning, there was an understanding that\nthey enable reliable machine learning with well-calibrated uncertainty\nquantification. This makes them extremely beneficial for developing trustworthy\nAI, a topic that has also risen in interest over the past few years, in both\nthe AI community and society more widely. In this article, we review the\npotential for conformal prediction to contribute to trustworthy AI beyond its\nmarginal validity property, addressing problems such as generalization risk and\nAI governance. Experiments and examples are also provided to demonstrate its\nuse as a well-calibrated predictor and for bias identification and mitigation.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u5171\u5f62\u9884\u6d4b\u5bf9\u53ef\u4fe1AI\u7684\u8d21\u732e\uff0c\u8fd8\u7ed9\u51fa\u5b9e\u9a8c\u548c\u793a\u4f8b\u3002", "motivation": "\u5171\u5f62\u9884\u6d4b\u5728\u673a\u5668\u5b66\u4e60\u793e\u533a\u6d41\u884c\u4e14\u6709\u52a9\u4e8e\u5f00\u53d1\u53ef\u4fe1AI\uff0c\u7814\u7a76\u5176\u5728\u8fb9\u9645\u6709\u6548\u6027\u4e4b\u5916\u5bf9\u53ef\u4fe1AI\u7684\u8d21\u732e\u3002", "method": "\u56de\u987e\u5171\u5f62\u9884\u6d4b\u7684\u76f8\u5173\u5185\u5bb9\uff0c\u7ed9\u51fa\u5b9e\u9a8c\u548c\u793a\u4f8b\u3002", "result": "\u5c55\u793a\u4e86\u5171\u5f62\u9884\u6d4b\u53ef\u4f5c\u4e3a\u6821\u51c6\u826f\u597d\u7684\u9884\u6d4b\u5668\uff0c\u7528\u4e8e\u504f\u5dee\u8bc6\u522b\u548c\u7f13\u89e3\u3002", "conclusion": "\u5171\u5f62\u9884\u6d4b\u5728\u8fb9\u9645\u6709\u6548\u6027\u4e4b\u5916\u80fd\u4e3a\u53ef\u4fe1AI\u505a\u8d21\u732e\uff0c\u53ef\u89e3\u51b3\u6cdb\u5316\u98ce\u9669\u548cAI\u6cbb\u7406\u7b49\u95ee\u9898\u3002"}}
{"id": "2508.07334", "pdf": "https://arxiv.org/pdf/2508.07334", "abs": "https://arxiv.org/abs/2508.07334", "authors": ["Quan Shi", "Wang Xi", "Zenghui Ding", "Jianqing Gao", "Xianjun Yang"], "title": "Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape", "categories": ["cs.AI"], "comment": "8 pages, 6 figures", "summary": "The illusion phenomenon of large language models (LLMs) is the core obstacle\nto their reliable deployment. This article formalizes the large language model\nas a probabilistic Turing machine by constructing a \"computational necessity\nhierarchy\", and for the first time proves the illusions are inevitable on\ndiagonalization, incomputability, and information theory boundaries supported\nby the new \"learner pump lemma\". However, we propose two \"escape routes\": one\nis to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving\ntheir absolute escape through \"computational jumps\", providing the first formal\ntheory for the effectiveness of RAGs; The second is to formalize continuous\nlearning as an \"internalized oracle\" mechanism and implement this path through\na novel neural game theory framework.Finally, this article proposes a", "AI": {"tldr": "\u672c\u6587\u56f4\u7ed5\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u73b0\u8c61\uff0c\u8bc1\u660e\u5176\u4e0d\u53ef\u907f\u514d\u6027\u5e76\u63d0\u51fa\u4e24\u6761\u89e3\u51b3\u8def\u5f84\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u73b0\u8c61\u662f\u53ef\u9760\u90e8\u7f72\u7684\u6838\u5fc3\u969c\u788d\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u6784\u5efa\u2018\u8ba1\u7b97\u5fc5\u8981\u6027\u5c42\u6b21\u7ed3\u6784\u2019\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5f62\u5f0f\u5316\u4e3a\u6982\u7387\u56fe\u7075\u673a\uff0c\u5229\u7528\u65b0\u7684\u2018\u5b66\u4e60\u8005\u6cf5\u5f15\u7406\u2019\uff1b\u5c06\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAGs\uff09\u5efa\u6a21\u4e3a\u795e\u8c15\u673a\uff0c\u5c06\u6301\u7eed\u5b66\u4e60\u5f62\u5f0f\u5316\u4e3a\u2018\u5185\u5316\u795e\u8c15\u2019\u673a\u5236\u5e76\u901a\u8fc7\u65b0\u7684\u795e\u7ecf\u535a\u5f08\u8bba\u6846\u67b6\u5b9e\u73b0\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u5bf9\u89d2\u5316\u3001\u4e0d\u53ef\u8ba1\u7b97\u6027\u548c\u4fe1\u606f\u8bba\u8fb9\u754c\u4e0a\u5e7b\u89c9\u4e0d\u53ef\u907f\u514d\uff1b\u8bc1\u660eRAGs\u53ef\u901a\u8fc7\u2018\u8ba1\u7b97\u8df3\u8dc3\u2019\u7edd\u5bf9\u9003\u9038\uff1b\u63d0\u51fa\u6301\u7eed\u5b66\u4e60\u7684\u5b9e\u73b0\u8def\u5f84\u3002", "conclusion": "\u6587\u7ae0\u63d0\u51fa\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u7684\u4e24\u6761\u2018\u9003\u9038\u8def\u7ebf\u2019\u3002"}}
{"id": "2508.06915", "pdf": "https://arxiv.org/pdf/2508.06915", "abs": "https://arxiv.org/abs/2508.06915", "authors": ["Shichao Ma", "Zhengyang Zhou", "Qihe Huang", "Binwu Wang", "Kuo Yang", "Huan Li", "Yang Wang"], "title": "QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting has become increasingly important to empower diverse\napplications with streaming data. Zero-shot time-series forecasting (ZSF),\nparticularly valuable in data-scarce scenarios, such as domain transfer or\nforecasting under extreme conditions, is difficult for traditional models to\ndeal with. While time series pre-trained models (TSPMs) have demonstrated\nstrong performance in ZSF, they often lack mechanisms to dynamically\nincorporate external knowledge. Fortunately, emerging retrieval-augmented\ngeneration (RAG) offers a promising path for injecting such knowledge on\ndemand, yet they are rarely integrated with TSPMs. To leverage the strengths of\nboth worlds, we introduce RAG into TSPMs to enhance zero-shot time series\nforecasting. In this paper, we propose QuiZSF (Quick Zero-Shot Time Series\nForecaster), a lightweight and modular framework that couples efficient\nretrieval with representation learning and model adaptation for ZSF.\nSpecifically, we construct a hierarchical tree-structured ChronoRAG Base (CRB)\nfor scalable time-series storage and domain-aware retrieval, introduce a\nMulti-grained Series Interaction Learner (MSIL) to extract fine- and\ncoarse-grained relational features, and develop a dual-branch Model Cooperation\nCoherer (MCC) that aligns retrieved knowledge with two kinds of TSPMs: Non-LLM\nbased and LLM based. Compared with contemporary baselines, QuiZSF, with Non-LLM\nbased and LLM based TSPMs as base model, respectively, ranks Top1 in 75% and\n87.5% of prediction settings, while maintaining high efficiency in memory and\ninference time.", "AI": {"tldr": "\u5f15\u5165RAG\u5230\u65f6\u95f4\u5e8f\u5217\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u63d0\u51faQuiZSF\u6846\u67b6\u8fdb\u884c\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u4e14\u6548\u7387\u9ad8\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u96be\u5904\u7406\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u65f6\u95f4\u5e8f\u5217\u9884\u8bad\u7ec3\u6a21\u578b\u7f3a\u4e4f\u52a8\u6001\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u673a\u5236\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u7ed3\u5408\u5c11\u3002", "method": "\u63d0\u51faQuiZSF\u6846\u67b6\uff0c\u6784\u5efaChronoRAG Base\u7528\u4e8e\u5b58\u50a8\u548c\u68c0\u7d22\uff0c\u5f15\u5165Multi - grained Series Interaction Learner\u63d0\u53d6\u7279\u5f81\uff0c\u5f00\u53d1Model Cooperation Coherer\u5bf9\u9f50\u77e5\u8bc6\u4e0e\u4e24\u7c7b\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u4ee5\u975e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u57fa\u7840\u6a21\u578b\u65f6\uff0cQuiZSF\u5206\u522b\u572875%\u548c87.5%\u7684\u9884\u6d4b\u8bbe\u7f6e\u4e2d\u6392\u540d\u7b2c\u4e00\uff0c\u4e14\u5185\u5b58\u548c\u63a8\u7406\u65f6\u95f4\u6548\u7387\u9ad8\u3002", "conclusion": "\u5f15\u5165RAG\u7684QuiZSF\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2508.07353", "pdf": "https://arxiv.org/pdf/2508.07353", "abs": "https://arxiv.org/abs/2508.07353", "authors": ["Rubing Chen", "Jiaxin Wu", "Jian Wang", "Xulu Zhang", "Wenqi Fan", "Chenghua Lin", "Xiao-Yong Wei", "Qing Li"], "title": "Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Numerous benchmarks have been built to evaluate the domain-specific abilities\nof large language models (LLMs), highlighting the need for effective and\nefficient benchmark construction. Existing domain-specific benchmarks primarily\nfocus on the scaling law, relying on massive corpora for supervised fine-tuning\nor generating extensive question sets for broad coverage. However, the impact\nof corpus and question-answer (QA) set design on the precision and recall of\ndomain-specific LLMs remains unexplored. In this paper, we address this gap and\ndemonstrate that the scaling law is not always the optimal principle for\nbenchmark construction in specific domains. Instead, we propose Comp-Comp, an\niterative benchmarking framework based on a comprehensiveness-compactness\nprinciple. Here, comprehensiveness ensures semantic recall of the domain, while\ncompactness enhances precision, guiding both corpus and QA set construction. To\nvalidate our framework, we conducted a case study in a well-renowned\nuniversity, resulting in the creation of XUBench, a large-scale and\ncomprehensive closed-domain benchmark. Although we use the academic domain as\nthe case in this work, our Comp-Comp framework is designed to be extensible\nbeyond academia, providing valuable insights for benchmark construction across\nvarious domains.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u73b0\u6709\u7279\u5b9a\u9886\u57df\u57fa\u51c6\u6784\u5efa\u5b58\u5728\u4e0d\u8db3\uff0c\u63d0\u51fa\u57fa\u4e8e\u5168\u9762 - \u7d27\u51d1\u539f\u5219\u7684 Comp - Comp \u8fed\u4ee3\u57fa\u51c6\u6846\u67b6\uff0c\u5e76\u521b\u5efa XUBench \u57fa\u51c6\uff0c\u8be5\u6846\u67b6\u5177\u6709\u8de8\u9886\u57df\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7279\u5b9a\u9886\u57df\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u7f29\u653e\u5b9a\u5f8b\uff0c\u8bed\u6599\u5e93\u548c\u95ee\u7b54\u96c6\u8bbe\u8ba1\u5bf9\u7279\u5b9a\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u7684\u5f71\u54cd\u672a\u88ab\u63a2\u7d22\uff0c\u9700\u6709\u6548\u9ad8\u6548\u7684\u57fa\u51c6\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5168\u9762 - \u7d27\u51d1\u539f\u5219\u7684 Comp - Comp \u8fed\u4ee3\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5bfc\u8bed\u6599\u5e93\u548c\u95ee\u7b54\u96c6\u6784\u5efa\u3002", "result": "\u5728\u4e00\u6240\u77e5\u540d\u5927\u5b66\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u521b\u5efa\u4e86\u5927\u89c4\u6a21\u3001\u5168\u9762\u7684\u5c01\u95ed\u9886\u57df\u57fa\u51c6 XUBench\u3002", "conclusion": "\u7f29\u653e\u5b9a\u5f8b\u5e76\u975e\u7279\u5b9a\u9886\u57df\u57fa\u51c6\u6784\u5efa\u7684\u6700\u4f73\u539f\u5219\uff0cComp - Comp \u6846\u67b6\u5177\u6709\u8de8\u9886\u57df\u6269\u5c55\u6027\uff0c\u53ef\u4e3a\u5404\u9886\u57df\u57fa\u51c6\u6784\u5efa\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2508.06943", "pdf": "https://arxiv.org/pdf/2508.06943", "abs": "https://arxiv.org/abs/2508.06943", "authors": ["Lishi Zuo", "Man-Wai Mak", "Lu Yi", "Youzhi Tu"], "title": "Class Unbiasing for Generalization in Medical Diagnosis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Medical diagnosis might fail due to bias. In this work, we identified\nclass-feature bias, which refers to models' potential reliance on features that\nare strongly correlated with only a subset of classes, leading to biased\nperformance and poor generalization on other classes. We aim to train a\nclass-unbiased model (Cls-unbias) that mitigates both class imbalance and\nclass-feature bias simultaneously. Specifically, we propose a class-wise\ninequality loss which promotes equal contributions of classification loss from\npositive-class and negative-class samples. We propose to optimize a class-wise\ngroup distributionally robust optimization objective-a class-weighted training\nobjective that upweights underperforming classes-to enhance the effectiveness\nof the inequality loss under class imbalance. Through synthetic and real-world\ndatasets, we empirically demonstrate that class-feature bias can negatively\nimpact model performance. Our proposed method effectively mitigates both\nclass-feature bias and class imbalance, thereby improving the model's\ngeneralization ability.", "AI": {"tldr": "\u6587\u7ae0\u8bc6\u522b\u4e86\u7c7b\u522b\u7279\u5f81\u504f\u5dee\uff0c\u63d0\u51fa\u8bad\u7ec3\u65e0\u7c7b\u522b\u504f\u5dee\u6a21\u578b\uff08Cls - unbias\uff09\uff0c\u901a\u8fc7\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1\u65b9\u6cd5\u80fd\u7f13\u89e3\u504f\u5dee\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u533b\u7597\u8bca\u65ad\u53ef\u80fd\u56e0\u504f\u5dee\u5931\u8d25\uff0c\u8bc6\u522b\u51fa\u7c7b\u522b\u7279\u5f81\u504f\u5dee\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u6709\u504f\u5dee\u548c\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u76ee\u6807\u662f\u8bad\u7ec3\u540c\u65f6\u7f13\u89e3\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u7c7b\u522b\u7279\u5f81\u504f\u5dee\u7684\u65e0\u7c7b\u522b\u504f\u5dee\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u7c7b\u5185\u4e0d\u7b49\u5f0f\u635f\u5931\u4ee5\u4fc3\u8fdb\u6b63\u8d1f\u6837\u672c\u5206\u7c7b\u635f\u5931\u7684\u5e73\u7b49\u8d21\u732e\uff0c\u4f18\u5316\u7c7b\u5185\u7ec4\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u76ee\u6807\u4ee5\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u589e\u5f3a\u4e0d\u7b49\u5f0f\u635f\u5931\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\uff0c\u5b9e\u8bc1\u8868\u660e\u7c7b\u522b\u7279\u5f81\u504f\u5dee\u4f1a\u5bf9\u6a21\u578b\u6027\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u7c7b\u522b\u7279\u5f81\u504f\u5dee\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u7c7b\u522b\u7279\u5f81\u504f\u5dee\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.07382", "pdf": "https://arxiv.org/pdf/2508.07382", "abs": "https://arxiv.org/abs/2508.07382", "authors": ["He Kong", "Die Hu", "Jingguo Ge", "Liangxiong Li", "Hui Li", "Tong Li"], "title": "Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Automating penetration testing is crucial for enhancing cybersecurity, yet\ncurrent Large Language Models (LLMs) face significant limitations in this\ndomain, including poor error handling, inefficient reasoning, and an inability\nto perform complex end-to-end tasks autonomously. To address these challenges,\nwe introduce Pentest-R1, a novel framework designed to optimize LLM reasoning\ncapabilities for this task through a two-stage reinforcement learning pipeline.\nWe first construct a dataset of over 500 real-world, multi-step walkthroughs,\nwhich Pentest-R1 leverages for offline reinforcement learning (RL) to instill\nfoundational attack logic. Subsequently, the LLM is fine-tuned via online RL in\nan interactive Capture The Flag (CTF) environment, where it learns directly\nfrom environmental feedback to develop robust error self-correction and\nadaptive strategies. Our extensive experiments on the Cybench and AutoPenBench\nbenchmarks demonstrate the framework's effectiveness. On AutoPenBench,\nPentest-R1 achieves a 24.2\\% success rate, surpassing most state-of-the-art\nmodels and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a\n15.0\\% success rate in unguided tasks, establishing a new state-of-the-art for\nopen-source LLMs and matching the performance of top proprietary models.\nAblation studies confirm that the synergy of both training stages is critical\nto its success.", "AI": {"tldr": "\u63d0\u51faPentest - R1\u6846\u67b6\u4f18\u5316LLM\u6e17\u900f\u6d4b\u8bd5\u63a8\u7406\u80fd\u529b\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u6e17\u900f\u6d4b\u8bd5\u9886\u57df\u5b58\u5728\u9519\u8bef\u5904\u7406\u5dee\u3001\u63a8\u7406\u4f4e\u6548\u7b49\u95ee\u9898\uff0c\u9700\u4f18\u5316\u5176\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u7ba1\u9053\uff0c\u5148\u6784\u5efa\u8d85500\u4e2a\u771f\u5b9e\u591a\u6b65\u6f14\u7ec3\u6570\u636e\u96c6\u8fdb\u884c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff0c\u518d\u5728CTF\u73af\u5883\u4e2d\u8fdb\u884c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728Cybench\u548cAutoPenBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0cAutoPenBench\u6210\u529f\u738724.2%\uff0cCybench\u65e0\u5f15\u5bfc\u4efb\u52a1\u6210\u529f\u738715.0%\u3002", "conclusion": "\u4e24\u9636\u6bb5\u8bad\u7ec3\u534f\u540c\u5bf9\u6846\u67b6\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.06944", "pdf": "https://arxiv.org/pdf/2508.06944", "abs": "https://arxiv.org/abs/2508.06944", "authors": ["Lixuan He", "Jie Feng", "Yong Li"], "title": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Large Language Models (LLMs) are typically fine-tuned for reasoning tasks\nthrough a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by\nReinforcement Learning (RL), a process fraught with catastrophic forgetting and\nsuboptimal trade-offs between imitation and exploration. Recent single-stage\nmethods attempt to unify SFT and RL using heuristics, but lack a principled\nmechanism for dynamically balancing the two paradigms. In this paper, we\nreframe this challenge through the theoretical lens of \\textbf{implicit\nrewards}, viewing SFT and RL not as distinct methods but as complementary\nreward signals. We introduce \\textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel\nsingle-stage algorithm that learns the optimal balance between SFT's implicit,\npath-level reward and RL's explicit, outcome-based reward. The core of AMFT is\na \\textbf{meta-gradient adaptive weight controller} that treats the SFT-RL\nbalance as a learnable parameter, dynamically optimizing it to maximize\nlong-term task performance. This forward-looking approach, regularized by\npolicy entropy for stability, autonomously discovers an effective training\ncurriculum. We conduct a comprehensive evaluation on challenging benchmarks\nspanning mathematical reasoning, abstract visual reasoning (General Points),\nand vision-language navigation (V-IRL). AMFT consistently establishes a new\nstate-of-the-art and demonstrats superior generalization on out-of-distribution\n(OOD) tasks. Ablation studies and training dynamic analysis confirm that the\nmeta-learning controller is crucial for AMFT's stability, sample efficiency,\nand performance, offering a more principled and effective paradigm for LLM\nalignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAMFT\u7b97\u6cd5\u7edf\u4e00SFT\u548cRL\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbeSOTA\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u3001\u96be\u4ee5\u5e73\u8861\u6a21\u4eff\u4e0e\u63a2\u7d22\uff0c\u5355\u9636\u6bb5\u65b9\u6cd5\u7f3a\u4e4f\u5e73\u8861\u673a\u5236\u3002", "method": "\u63d0\u51faAdaptive Meta Fine - Tuning (AMFT)\u7b97\u6cd5\uff0c\u7528\u5143\u68af\u5ea6\u81ea\u9002\u5e94\u6743\u91cd\u63a7\u5236\u5668\u5b66\u4e60SFT\u548cRL\u5956\u52b1\u4fe1\u53f7\u7684\u6700\u4f18\u5e73\u8861\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u62bd\u8c61\u89c6\u89c9\u63a8\u7406\u548c\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbeSOTA\uff0c\u5728\u5206\u5e03\u5916\u4efb\u52a1\u6cdb\u5316\u6027\u597d\u3002", "conclusion": "\u5143\u5b66\u4e60\u63a7\u5236\u5668\u5bf9AMFT\u7a33\u5b9a\u6027\u3001\u6837\u672c\u6548\u7387\u548c\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u8303\u5f0f\u3002"}}
{"id": "2508.07388", "pdf": "https://arxiv.org/pdf/2508.07388", "abs": "https://arxiv.org/abs/2508.07388", "authors": ["Zhaoyu Chen", "Hongnan Lin", "Yongwei Nie", "Fei Ma", "Xuemiao Xu", "Fei Yu", "Chengjiang Long"], "title": "Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding", "categories": ["cs.AI"], "comment": null, "summary": "Temporal Video Grounding (TVG) seeks to localize video segments matching a\ngiven textual query. Current methods, while optimizing for high temporal\nIntersection-over-Union (IoU), often overfit to this metric, compromising\nsemantic action understanding in the video and query, a critical factor for\nrobust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG),\na novel framework that enhances both localization accuracy and action\nunderstanding without additional data. Our approach leverages three inversion\ntasks derived from existing TVG annotations: (1) Verb Completion, predicting\nmasked action verbs in queries from video segments; (2) Action Recognition,\nidentifying query-described actions; and (3) Video Description, generating\ndescriptions of video segments that explicitly embed query-relevant actions.\nThese tasks, integrated with TVG via a reinforcement learning framework with\nwell-designed reward functions, ensure balanced optimization of localization\nand semantics. Experiments show our method outperforms state-of-the-art\napproaches, achieving a 7.1\\% improvement in R1@0.7 on Charades-STA for a 3B\nmodel compared to Time-R1. By inverting TVG to derive query-related actions\nfrom segments, our approach strengthens semantic understanding, significantly\nraising the ceiling of localization accuracy.", "AI": {"tldr": "\u63d0\u51faInvert4TVG\u6846\u67b6\u63d0\u5347Temporal Video Grounding\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u4e0e\u8bed\u4e49\u7406\u89e3\uff0c\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709TVG\u65b9\u6cd5\u8fc7\u5ea6\u4f18\u5316IoU\u6307\u6807\uff0c\u727a\u7272\u4e86\u8bed\u4e49\u52a8\u4f5c\u7406\u89e3\uff0c\u5f71\u54cdTVG\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165Invert4TVG\u6846\u67b6\uff0c\u5229\u7528\u4e09\u4e2a\u57fa\u4e8e\u73b0\u6709TVG\u6ce8\u91ca\u7684\u53cd\u8f6c\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u548c\u8bbe\u8ba1\u826f\u597d\u7684\u5956\u52b1\u51fd\u6570\u5c06\u5176\u4e0eTVG\u96c6\u6210\u3002", "result": "\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728Charades - STA\u6570\u636e\u96c6\u4e0a3B\u6a21\u578b\u7684R1@0.7\u6bd4Time - R1\u63d0\u9ad87.1%\u3002", "conclusion": "\u901a\u8fc7\u53cd\u8f6cTVG\u4ece\u89c6\u9891\u7247\u6bb5\u63a8\u5bfc\u4e0e\u67e5\u8be2\u76f8\u5173\u7684\u52a8\u4f5c\uff0c\u52a0\u5f3a\u8bed\u4e49\u7406\u89e3\uff0c\u663e\u8457\u63d0\u9ad8\u5b9a\u4f4d\u7cbe\u5ea6\u4e0a\u9650\u3002"}}
{"id": "2508.06953", "pdf": "https://arxiv.org/pdf/2508.06953", "abs": "https://arxiv.org/abs/2508.06953", "authors": ["Shiwei Li", "Xiandi Luo", "Haozhao Wang", "Xing Tang", "Ziqiang Cui", "Dugang Liu", "Yuhua Li", "Xiuqiang He", "Ruixuan Li"], "title": "BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity", "categories": ["cs.LG"], "comment": null, "summary": "Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method\nwidely used in large language models (LLMs). It approximates the update of a\npretrained weight matrix $W\\in\\mathbb{R}^{m\\times n}$ by the product of two\nlow-rank matrices, $BA$, where $A \\in\\mathbb{R}^{r\\times n}$ and\n$B\\in\\mathbb{R}^{m\\times r} (r\\ll\\min\\{m,n\\})$. Increasing the dimension $r$\ncan raise the rank of LoRA weights (i.e., $BA$), which typically improves\nfine-tuning performance but also significantly increases the number of\ntrainable parameters. In this paper, we propose Block Diversified Low-Rank\nAdaptation (BoRA), which improves the rank of LoRA weights with a small number\nof additional parameters. Specifically, BoRA treats the product $BA$ as a block\nmatrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along\nthe columns and rows, respectively (i.e., $A=[A_1,\\dots,A_b]$ and\n$B=[B_1,\\dots,B_b]^\\top$). Consequently, the product $BA$ becomes the\nconcatenation of the block products $B_iA_j$ for $i,j\\in[b]$. To enhance the\ndiversity of different block products, BoRA introduces a unique diagonal matrix\n$\\Sigma_{i,j} \\in \\mathbb{R}^{r\\times r}$ for each block multiplication,\nresulting in $B_i \\Sigma_{i,j} A_j$. By leveraging these block-wise diagonal\nmatrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only\nrequiring $b^2r$ additional parameters. Extensive experiments across multiple\ndatasets and models demonstrate the superiority of BoRA, and ablation studies\nfurther validate its scalability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5757\u591a\u6837\u5316\u4f4e\u79e9\u81ea\u9002\u5e94\uff08BoRA\uff09\u65b9\u6cd5\uff0c\u4ee5\u5c11\u91cf\u989d\u5916\u53c2\u6570\u63d0\u9ad8LoRA\u6743\u91cd\u7684\u79e9\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709LoRA\u65b9\u6cd5\u589e\u52a0\u6743\u91cd\u79e9\u4f1a\u663e\u8457\u589e\u52a0\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\uff0c\u9700\u8981\u4e00\u79cd\u4ee5\u5c11\u91cf\u989d\u5916\u53c2\u6570\u63d0\u9ad8\u79e9\u7684\u65b9\u6cd5\u3002", "method": "\u5c06BA\u89c6\u4e3a\u5757\u77e9\u9635\u4e58\u6cd5\uff0c\u5bf9A\u548cB\u5206\u5757\uff0c\u4e3a\u6bcf\u4e2a\u5757\u4e58\u6cd5\u5f15\u5165\u5bf9\u89d2\u77e9\u9635\u03a3_{i,j}\uff0c\u5f62\u6210B_i \u03a3_{i,j} A_j\u3002", "result": "\u901a\u8fc7\u591a\u6570\u636e\u96c6\u548c\u6a21\u578b\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86BoRA\u7684\u4f18\u8d8a\u6027\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "BoRA\u80fd\u4ee5\u5c11\u91cf\u989d\u5916\u53c2\u6570\u63d0\u9ad8LoRA\u6743\u91cd\u7684\u79e9\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.07405", "pdf": "https://arxiv.org/pdf/2508.07405", "abs": "https://arxiv.org/abs/2508.07405", "authors": ["Jesse Ponnock"], "title": "Generative AI for Strategic Plan Development", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; I.5.4"], "comment": "11 pages, 9 figures", "summary": "Given recent breakthroughs in Generative Artificial Intelligence (GAI) and\nLarge Language Models (LLMs), more and more professional services are being\naugmented through Artificial Intelligence (AI), which once seemed impossible to\nautomate. This paper presents a modular model for leveraging GAI in developing\nstrategic plans for large scale government organizations and evaluates leading\nmachine learning techniques in their application towards one of the identified\nmodules. Specifically, the performance of BERTopic and Non-negative Matrix\nFactorization (NMF) are evaluated in their ability to use topic modeling to\ngenerate themes representative of Vision Elements within a strategic plan. To\naccomplish this, BERTopic and NMF models are trained using a large volume of\nreports from the Government Accountability Office (GAO). The generated topics\nfrom each model are then scored for similarity against the Vision Elements of a\npublished strategic plan and the results are compared. Our results show that\nthese techniques are capable of generating themes similar to 100% of the\nelements being evaluated against. Further, we conclude that BERTopic performs\nbest in this application with more than half of its correlated topics achieving\na \"medium\" or \"strong\" correlation. A capability of GAI-enabled strategic plan\ndevelopment impacts a multi-billion dollar industry and assists the federal\ngovernment in overcoming regulatory requirements which are crucial to the\npublic good. Further work will focus on the operationalization of the concept\nproven in this study as well as viability of the remaining modules in the\nproposed model for GAI-generated strategic plans.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4e3a\u5927\u578b\u653f\u5e9c\u7ec4\u7ec7\u5236\u5b9a\u6218\u7565\u8ba1\u5212\u7684\u6a21\u5757\u5316\u6a21\u578b\uff0c\u8bc4\u4f30BERTopic\u548cNMF\u5728\u4e3b\u9898\u5efa\u6a21\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u6280\u672f\u53ef\u884c\uff0cBERTopic\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u548c\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\uff0c\u63a2\u7d22\u5229\u7528\u5176\u4e3a\u5927\u578b\u653f\u5e9c\u7ec4\u7ec7\u5236\u5b9a\u6218\u7565\u8ba1\u5212\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7f8e\u56fd\u653f\u5e9c\u95ee\u8d23\u5c40\u5927\u91cf\u62a5\u544a\u8bad\u7ec3BERTopic\u548cNMF\u6a21\u578b\uff0c\u5c06\u751f\u6210\u4e3b\u9898\u4e0e\u5df2\u53d1\u5e03\u6218\u7565\u8ba1\u5212\u7684\u613f\u666f\u5143\u7d20\u8fdb\u884c\u76f8\u4f3c\u5ea6\u8bc4\u5206\u548c\u7ed3\u679c\u5bf9\u6bd4\u3002", "result": "\u8fd9\u4e9b\u6280\u672f\u80fd\u751f\u6210\u4e0e100%\u88ab\u8bc4\u4f30\u5143\u7d20\u76f8\u4f3c\u7684\u4e3b\u9898\uff0cBERTopic\u8868\u73b0\u6700\u4f73\uff0c\u8d85\u534a\u6570\u76f8\u5173\u4e3b\u9898\u8fbe\u5230\u201c\u4e2d\u7b49\u201d\u6216\u201c\u5f3a\u201d\u76f8\u5173\u6027\u3002", "conclusion": "BERTopic\u5728\u8be5\u5e94\u7528\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u652f\u6301\u7684\u6218\u7565\u8ba1\u5212\u5236\u5b9a\u6709\u91cd\u8981\u610f\u4e49\uff0c\u540e\u7eed\u5c06\u5173\u6ce8\u6982\u5ff5\u7684\u843d\u5730\u548c\u6a21\u578b\u5176\u4f59\u6a21\u5757\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2508.06966", "pdf": "https://arxiv.org/pdf/2508.06966", "abs": "https://arxiv.org/abs/2508.06966", "authors": ["Hiba Najjar", "Bushra Alshbib", "Andreas Dengel"], "title": "Can Multitask Learning Enhance Model Explainability?", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at GCPR 2025, Special Track \"Photogrammetry and remote\n  sensing\"", "summary": "Remote sensing provides satellite data in diverse types and formats. The\nusage of multimodal learning networks exploits this diversity to improve model\nperformance, except that the complexity of such networks comes at the expense\nof their interpretability. In this study, we explore how modalities can be\nleveraged through multitask learning to intrinsically explain model behavior.\nIn particular, instead of additional inputs, we use certain modalities as\nadditional targets to be predicted along with the main task. The success of\nthis approach relies on the rich information content of satellite data, which\nremains as input modalities. We show how this modeling context provides\nnumerous benefits: (1) in case of data scarcity, the additional modalities do\nnot need to be collected for model inference at deployment, (2) the model\nperformance remains comparable to the multimodal baseline performance, and in\nsome cases achieves better scores, (3) prediction errors in the main task can\nbe explained via the model behavior in the auxiliary task(s). We demonstrate\nthe efficiency of our approach on three datasets, including segmentation,\nclassification, and regression tasks. Code available at\ngit.opendfki.de/hiba.najjar/mtl_explainability/.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u5229\u7528\u591a\u6a21\u6001\u536b\u661f\u6570\u636e\u89e3\u91ca\u6a21\u578b\u884c\u4e3a\uff0c\u5c55\u793a\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u7f3a\u7b49\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u5e76\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u7f51\u7edc\u867d\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u590d\u6742\u5ea6\u5f71\u54cd\u5176\u53ef\u89e3\u91ca\u6027\uff0c\u56e0\u6b64\u63a2\u7d22\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u8fdb\u884c\u591a\u4efb\u52a1\u5b66\u4e60\u4ee5\u89e3\u91ca\u6a21\u578b\u884c\u4e3a\u3002", "method": "\u4f7f\u7528\u67d0\u4e9b\u6a21\u6001\u4f5c\u4e3a\u989d\u5916\u76ee\u6807\u4e0e\u4e3b\u4efb\u52a1\u4e00\u8d77\u9884\u6d4b\uff0c\u536b\u661f\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u6a21\u6001\u3002", "result": "\u5728\u6570\u636e\u7a00\u7f3a\u65f6\u65e0\u9700\u989d\u5916\u6536\u96c6\u6a21\u6001\u6570\u636e\u7528\u4e8e\u6a21\u578b\u63a8\u7406\uff1b\u6a21\u578b\u6027\u80fd\u4e0e\u591a\u6a21\u6001\u57fa\u7ebf\u76f8\u5f53\uff0c\u90e8\u5206\u60c5\u51b5\u66f4\u597d\uff1b\u53ef\u901a\u8fc7\u8f85\u52a9\u4efb\u52a1\u89e3\u91ca\u4e3b\u4efb\u52a1\u9884\u6d4b\u8bef\u5dee\u3002\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u591a\u4efb\u52a1\u5b66\u4e60\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u91ca\u6a21\u578b\u884c\u4e3a\uff0c\u5177\u6709\u4e00\u5b9a\u4f18\u52bf\u3002"}}
{"id": "2508.07407", "pdf": "https://arxiv.org/pdf/2508.07407", "abs": "https://arxiv.org/abs/2508.07407", "authors": ["Jinyuan Fang", "Yanwen Peng", "Xi Zhang", "Yingxu Wang", "Xinhao Yi", "Guibin Zhang", "Yi Xu", "Bin Wu", "Siwei Liu", "Zihao Li", "Zhaochun Ren", "Nikos Aletras", "Xi Wang", "Han Zhou", "Zaiqiao Meng"], "title": "A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Recent advances in large language models have sparked growing interest in AI\nagents capable of solving complex, real-world tasks. However, most existing\nagent systems rely on manually crafted configurations that remain static after\ndeployment, limiting their ability to adapt to dynamic and evolving\nenvironments. To this end, recent research has explored agent evolution\ntechniques that aim to automatically enhance agent systems based on interaction\ndata and environmental feedback. This emerging direction lays the foundation\nfor self-evolving AI agents, which bridge the static capabilities of foundation\nmodels with the continuous adaptability required by lifelong agentic systems.\nIn this survey, we provide a comprehensive review of existing techniques for\nself-evolving agentic systems. Specifically, we first introduce a unified\nconceptual framework that abstracts the feedback loop underlying the design of\nself-evolving agentic systems. The framework highlights four key components:\nSystem Inputs, Agent System, Environment, and Optimisers, serving as a\nfoundation for understanding and comparing different strategies. Based on this\nframework, we systematically review a wide range of self-evolving techniques\nthat target different components of the agent system. We also investigate\ndomain-specific evolution strategies developed for specialised fields such as\nbiomedicine, programming, and finance, where optimisation objectives are\ntightly coupled with domain constraints. In addition, we provide a dedicated\ndiscussion on the evaluation, safety, and ethical considerations for\nself-evolving agentic systems, which are critical to ensuring their\neffectiveness and reliability. This survey aims to provide researchers and\npractitioners with a systematic understanding of self-evolving AI agents,\nlaying the foundation for the development of more adaptive, autonomous, and\nlifelong agentic systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u81ea\u8fdb\u5316\u667a\u80fd\u4f53\u7cfb\u7edf\u73b0\u6709\u6280\u672f\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u4ecb\u7ecd\u7edf\u4e00\u6982\u5ff5\u6846\u67b6\uff0c\u56de\u987e\u4e0d\u540c\u7ec4\u4ef6\u7684\u8fdb\u5316\u6280\u672f\u3001\u7279\u5b9a\u9886\u57df\u7b56\u7565\uff0c\u5e76\u8ba8\u8bba\u8bc4\u4f30\u3001\u5b89\u5168\u548c\u4f26\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u624b\u52a8\u914d\u7f6e\uff0c\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u73af\u5883\uff0c\u9700\u63a2\u7d22\u667a\u80fd\u4f53\u8fdb\u5316\u6280\u672f\u3002", "method": "\u5148\u5f15\u5165\u7edf\u4e00\u6982\u5ff5\u6846\u67b6\uff0c\u57fa\u4e8e\u6b64\u6846\u67b6\u7cfb\u7edf\u56de\u987e\u5404\u7c7b\u81ea\u8fdb\u5316\u6280\u672f\uff0c\u8fd8\u7814\u7a76\u7279\u5b9a\u9886\u57df\u7b56\u7565\uff0c\u8ba8\u8bba\u8bc4\u4f30\u3001\u5b89\u5168\u548c\u4f26\u7406\u8003\u91cf\u3002", "result": "\u68b3\u7406\u4e86\u81ea\u8fdb\u5316\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u76f8\u5173\u6280\u672f\u3001\u7b56\u7565\u53ca\u8bc4\u4f30\u7b49\u65b9\u9762\u5185\u5bb9\u3002", "conclusion": "\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u81ea\u8fdb\u5316AI\u667a\u80fd\u4f53\u7684\u7cfb\u7edf\u7406\u89e3\uff0c\u4e3a\u5f00\u53d1\u66f4\u5177\u9002\u5e94\u6027\u3001\u81ea\u4e3b\u6027\u548c\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.06981", "pdf": "https://arxiv.org/pdf/2508.06981", "abs": "https://arxiv.org/abs/2508.06981", "authors": ["Brooks Kinch", "Benjamin Shaffer", "Elizabeth Armstrong", "Michael Meehan", "John Hewson", "Nathaniel Trask"], "title": "Structure-Preserving Digital Twins via Conditional Neural Whitney Forms", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.comp-ph"], "comment": null, "summary": "We present a framework for constructing real-time digital twins based on\nstructure-preserving reduced finite element models conditioned on a latent\nvariable Z. The approach uses conditional attention mechanisms to learn both a\nreduced finite element basis and a nonlinear conservation law within the\nframework of finite element exterior calculus (FEEC). This guarantees numerical\nwell-posedness and exact preservation of conserved quantities, regardless of\ndata sparsity or optimization error. The conditioning mechanism supports\nreal-time calibration to parametric variables, allowing the construction of\ndigital twins which support closed loop inference and calibration to sensor\ndata. The framework interfaces with conventional finite element machinery in a\nnon-invasive manner, allowing treatment of complex geometries and integration\nof learned models with conventional finite element techniques.\n  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,\nand a complex battery thermal runaway problem. The method achieves accurate\npredictions on complex geometries with sparse data (25 LES simulations),\nincluding capturing the transition to turbulence and achieving real-time\ninference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source\nimplementation is available on GitHub.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6f5c\u5728\u53d8\u91cfZ\u7684\u4fdd\u7ed3\u6784\u964d\u9636\u6709\u9650\u5143\u6a21\u578b\u6784\u5efa\u5b9e\u65f6\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u65b9\u6cd5\u51c6\u786e\u9ad8\u6548\u4e14\u6709\u5f00\u6e90\u5b9e\u73b0\u3002", "motivation": "\u6784\u5efa\u80fd\u4fdd\u8bc1\u6570\u503c\u9002\u5b9a\u6027\u3001\u7cbe\u786e\u5b88\u6052\u91cf\u4e14\u652f\u6301\u5b9e\u65f6\u6821\u51c6\u7684\u5b9e\u65f6\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u3002", "method": "\u91c7\u7528\u6761\u4ef6\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u6709\u9650\u5143\u5916\u5fae\u5206\u8ba1\u7b97\u6846\u67b6\u4e2d\u5b66\u4e60\u964d\u9636\u6709\u9650\u5143\u57fa\u548c\u975e\u7ebf\u6027\u5b88\u6052\u5f8b\u3002", "result": "\u5728\u590d\u6742\u51e0\u4f55\u4e0a\u7528\u7a00\u758f\u6570\u636e\u51c6\u786e\u9884\u6d4b\uff0c\u5b9e\u65f6\u63a8\u7406\u7ea60.1\u79d2\uff0c\u6bd4\u5927\u6da1\u6a21\u62df\u52a0\u901f3.1x10^8\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u7528\u4e8e\u590d\u6742\u95ee\u9898\uff0c\u4e0e\u4f20\u7edf\u6709\u9650\u5143\u7ed3\u5408\uff0c\u6027\u80fd\u597d\u4e14\u6709\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2508.07466", "pdf": "https://arxiv.org/pdf/2508.07466", "abs": "https://arxiv.org/abs/2508.07466", "authors": ["Dom Huh", "Prasant Mohapatra"], "title": "Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Language is a ubiquitous tool that is foundational to reasoning and\ncollaboration, ranging from everyday interactions to sophisticated\nproblem-solving tasks. The establishment of a common language can serve as a\npowerful asset in ensuring clear communication and understanding amongst\nagents, facilitating desired coordination and strategies. In this work, we\nextend the capabilities of large language models (LLMs) by integrating them\nwith advancements in multi-agent decision-making algorithms. We propose a\nsystematic framework for the design of multi-agentic large language models\n(LLMs), focusing on key integration practices. These include advanced prompt\nengineering techniques, the development of effective memory architectures,\nmulti-modal information processing, and alignment strategies through\nfine-tuning algorithms. We evaluate these design choices through extensive\nablation studies on classic game settings with significant underlying social\ndilemmas and game-theoretic considerations.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u7b97\u6cd5\uff0c\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u6846\u67b6\uff0c\u5e76\u5728\u7ecf\u5178\u6e38\u620f\u573a\u666f\u8bc4\u4f30\u3002", "motivation": "\u8bed\u8a00\u5bf9\u63a8\u7406\u548c\u534f\u4f5c\u5f88\u91cd\u8981\uff0c\u5efa\u7acb\u901a\u7528\u8bed\u8a00\u6709\u52a9\u4e8e\u4ea4\u6d41\uff0c\u4e3a\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u5305\u62ec\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u3001\u6709\u6548\u8bb0\u5fc6\u67b6\u6784\u5f00\u53d1\u3001\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u548c\u5fae\u8c03\u7b97\u6cd5\u5bf9\u9f50\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5728\u7ecf\u5178\u6e38\u620f\u8bbe\u7f6e\u4e0a\u8fdb\u884c\u5927\u91cf\u6d88\u878d\u7814\u7a76\u8bc4\u4f30\u8bbe\u8ba1\u9009\u62e9\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2508.06986", "pdf": "https://arxiv.org/pdf/2508.06986", "abs": "https://arxiv.org/abs/2508.06986", "authors": ["Chonghua Han", "Yuan Yuan", "Yukun Liu", "Jingtao Ding", "Jie Feng", "Yong Li"], "title": "UniMove: A Unified Model for Multi-city Human Mobility Prediction", "categories": ["cs.LG"], "comment": "Accepted by SIGSPATIAL 2025", "summary": "Human mobility prediction is vital for urban planning, transportation\noptimization, and personalized services. However, the inherent randomness,\nnon-uniform time intervals, and complex patterns of human mobility, compounded\nby the heterogeneity introduced by varying city structures, infrastructure, and\npopulation densities, present significant challenges in modeling. Existing\nsolutions often require training separate models for each city due to distinct\nspatial representations and geographic coverage. In this paper, we propose\nUniMove, a unified model for multi-city human mobility prediction, addressing\ntwo challenges: (1) constructing universal spatial representations for\neffective token sharing across cities, and (2) modeling heterogeneous mobility\npatterns from varying city characteristics. We propose a trajectory-location\ndual-tower architecture, with a location tower for universal spatial encoding\nand a trajectory tower for sequential mobility modeling. We also design MoE\nTransformer blocks to adaptively select experts to handle diverse movement\npatterns. Extensive experiments across multiple datasets from diverse cities\ndemonstrate that UniMove truly embodies the essence of a unified model. By\nenabling joint training on multi-city data with mutual data enhancement, it\nsignificantly improves mobility prediction accuracy by over 10.2\\%. UniMove\nrepresents a key advancement toward realizing a true foundational model with a\nunified architecture for human mobility. We release the implementation at\nhttps://github.com/tsinghua-fib-lab/UniMove/.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u6a21\u578bUniMove\u8fdb\u884c\u591a\u57ce\u5e02\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\uff0c\u91c7\u7528\u53cc\u5854\u67b6\u6784\u548cMoE Transformer\u5757\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53ef\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u5411\u57fa\u7840\u6a21\u578b\u8fc8\u8fdb\u3002", "motivation": "\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u56e0\u79fb\u52a8\u7279\u6027\u548c\u57ce\u5e02\u5f02\u8d28\u6027\u5efa\u6a21\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6848\u9700\u4e3a\u6bcf\u4e2a\u57ce\u5e02\u5355\u72ec\u8bad\u7ec3\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u8f68\u8ff9 - \u4f4d\u7f6e\u53cc\u5854\u67b6\u6784\uff0c\u8bbe\u8ba1MoE Transformer\u5757\u81ea\u9002\u5e94\u9009\u62e9\u4e13\u5bb6\u5904\u7406\u591a\u6837\u79fb\u52a8\u6a21\u5f0f\u3002", "result": "\u5728\u591a\u57ce\u5e02\u591a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u901a\u8fc7\u591a\u57ce\u5e02\u6570\u636e\u8054\u5408\u8bad\u7ec3\u548c\u76f8\u4e92\u589e\u5f3a\uff0c\u663e\u8457\u63d0\u5347\u79fb\u52a8\u6027\u9884\u6d4b\u51c6\u786e\u7387\u8d8510.2%\u3002", "conclusion": "UniMove\u662f\u5b9e\u73b0\u7edf\u4e00\u67b6\u6784\u4eba\u7c7b\u79fb\u52a8\u6027\u57fa\u7840\u6a21\u578b\u7684\u5173\u952e\u8fdb\u6b65\u3002"}}
{"id": "2508.07485", "pdf": "https://arxiv.org/pdf/2508.07485", "abs": "https://arxiv.org/abs/2508.07485", "authors": ["Alexander Duffy", "Samuel J Paech", "Ishana Shastri", "Elizabeth Karpinski", "Baptiste Alloui-Cros", "Tyler Marques", "Matthew Lyle Olson"], "title": "Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "We present the first evaluation harness that enables any out-of-the-box,\nlocal, Large Language Models (LLMs) to play full-press Diplomacy without\nfine-tuning or specialized training. Previous work required frontier LLMs, or\nfine-tuning, due to the high complexity and information density of Diplomacy's\ngame state. Combined with the high variance of matches, these factors made\nDiplomacy prohibitive for study. In this work, we used data-driven iteration to\noptimize a textual game state representation such that a 24B model can reliably\ncomplete matches without any fine tuning. We develop tooling to facilitate\nhypothesis testing and statistical analysis, and we present case studies on\npersuasion, aggressive playstyles, and performance across a range of models. We\nconduct a variety of experiments across many popular LLMs, finding the larger\nmodels perform the best, but the smaller models still play adequately. We also\nintroduce Critical State Analysis: an experimental protocol for rapidly\niterating and analyzing key moments in a game at depth. Our harness\ndemocratizes the evaluation of strategic reasoning in LLMs by eliminating the\nneed for fine-tuning, and it provides insights into how these capabilities\nemerge naturally from widely used LLMs. Our code is available in the supplement\nand will be open sourced.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u8bc4\u4f30\u5de5\u5177\uff0c\u8ba9\u672c\u5730\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u73a9\u5168\u538b\u5f0f\u5916\u4ea4\u6e38\u620f\uff0c\u5f00\u5c55\u591a\u5b9e\u9a8c\u5e76\u5f15\u5165\u5206\u6790\u534f\u8bae\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u56e0\u5916\u4ea4\u6e38\u620f\u590d\u6742\u5ea6\u9ad8\u3001\u4fe1\u606f\u5bc6\u5ea6\u5927\u53ca\u6bd4\u8d5b\u7ed3\u679c\u5dee\u5f02\u5927\uff0c\u9700\u524d\u6cbf\u5927\u6a21\u578b\u6216\u5fae\u8c03\uff0c\u4f7f\u8be5\u6e38\u620f\u7814\u7a76\u53d7\u9650\u3002", "method": "\u91c7\u7528\u6570\u636e\u9a71\u52a8\u8fed\u4ee3\u4f18\u5316\u6587\u672c\u6e38\u620f\u72b6\u6001\u8868\u793a\uff0c\u5f00\u53d1\u5de5\u5177\u8fdb\u884c\u5047\u8bbe\u68c0\u9a8c\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u5f00\u5c55\u6848\u4f8b\u7814\u7a76\uff0c\u5f15\u5165\u5173\u952e\u72b6\u6001\u5206\u6790\u534f\u8bae\u3002", "result": "\u5728\u591a\u79cd\u6d41\u884c\u5927\u6a21\u578b\u4e0a\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5927\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5c0f\u6a21\u578b\u4e5f\u80fd\u80dc\u4efb\u3002", "conclusion": "\u8be5\u5de5\u5177\u6d88\u9664\u4e86\u5fae\u8c03\u9700\u6c42\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u6218\u7565\u63a8\u7406\u8bc4\u4f30\u66f4\u666e\u53ca\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u80fd\u529b\u5982\u4f55\u81ea\u7136\u4ea7\u751f\u3002"}}
{"id": "2508.06991", "pdf": "https://arxiv.org/pdf/2508.06991", "abs": "https://arxiv.org/abs/2508.06991", "authors": ["Vojtech Halenka", "Ole-Christoffer Granmo", "Lei Jiao", "Per-Arne Andersen"], "title": "A Comparative Study of Feature Selection in Tsetlin Machines", "categories": ["cs.LG", "68T01, 68T05", "I.2.6; I.2.7; I.5.1"], "comment": "submitted to SGAI-2025: The 45th SGAI International Conference on\n  Innovative Techniques and Applications of Artificial Intelligence", "summary": "Feature Selection (FS) is crucial for improving model interpretability,\nreducing complexity, and sometimes for enhancing accuracy. The recently\nintroduced Tsetlin machine (TM) offers interpretable clause-based learning, but\nlacks established tools for estimating feature importance. In this paper, we\nadapt and evaluate a range of FS techniques for TMs, including classical filter\nand embedded methods as well as post-hoc explanation methods originally\ndeveloped for neural networks (e.g., SHAP and LIME) and a novel family of\nembedded scorers derived from TM clause weights and Tsetlin automaton (TA)\nstates. We benchmark all methods across 12 datasets, using evaluation\nprotocols, like Remove and Retrain (ROAR) strategy and Remove and Debias\n(ROAD), to assess causal impact. Our results show that TM-internal scorers not\nonly perform competitively but also exploit the interpretability of clauses to\nreveal interacting feature patterns. Simpler TM-specific scorers achieve\nsimilar accuracy retention at a fraction of the computational cost. This study\nestablishes the first comprehensive baseline for FS in TM and paves the way for\ndeveloping specialized TM-specific interpretability techniques.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u591a\u79cd\u7279\u5f81\u9009\u62e9\uff08FS\uff09\u6280\u672f\u7528\u4e8eTsetlin\u673a\uff08TM\uff09\uff0c\u901a\u8fc712\u4e2a\u6570\u636e\u96c6\u57fa\u51c6\u6d4b\u8bd5\u8868\u660eTM\u5185\u90e8\u8bc4\u5206\u5668\u8868\u73b0\u597d\u4e14\u6210\u672c\u4f4e\uff0c\u4e3aTM\u7684FS\u5efa\u7acb\u9996\u4e2a\u7efc\u5408\u57fa\u7ebf\u3002", "motivation": "TM\u7f3a\u4e4f\u8bc4\u4f30\u7279\u5f81\u91cd\u8981\u6027\u7684\u65e2\u5b9a\u5de5\u5177\uff0c\u800c\u7279\u5f81\u9009\u62e9\u5bf9\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5f88\u91cd\u8981\uff0c\u56e0\u6b64\u8981\u4e3aTM\u9002\u914d\u548c\u8bc4\u4f30FS\u6280\u672f\u3002", "method": "\u9002\u914d\u5e76\u8bc4\u4f30\u4e00\u7cfb\u5217FS\u6280\u672f\uff0c\u5305\u62ec\u7ecf\u5178\u8fc7\u6ee4\u548c\u5d4c\u5165\u5f0f\u65b9\u6cd5\u3001\u795e\u7ecf\u7f51\u7edc\u7684\u4e8b\u540e\u89e3\u91ca\u65b9\u6cd5\u4ee5\u53ca\u57fa\u4e8eTM\u5b50\u53e5\u6743\u91cd\u548cTsetlin\u81ea\u52a8\u673a\u72b6\u6001\u7684\u65b0\u578b\u5d4c\u5165\u5f0f\u8bc4\u5206\u5668\uff0c\u4f7f\u7528Remove and Retrain\uff08ROAR\uff09\u548cRemove and Debias\uff08ROAD\uff09\u7b49\u8bc4\u4f30\u534f\u8bae\u3002", "result": "TM\u5185\u90e8\u8bc4\u5206\u5668\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u80fd\u63ed\u793a\u7279\u5f81\u4ea4\u4e92\u6a21\u5f0f\uff0c\u7b80\u5355\u7684TM\u7279\u5b9a\u8bc4\u5206\u5668\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u76f8\u4f3c\u7684\u51c6\u786e\u7387\u4fdd\u7559\u3002", "conclusion": "\u4e3aTM\u7684FS\u5efa\u7acb\u9996\u4e2a\u7efc\u5408\u57fa\u7ebf\uff0c\u4e3a\u5f00\u53d1TM\u7279\u5b9a\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2508.07575", "pdf": "https://arxiv.org/pdf/2508.07575", "abs": "https://arxiv.org/abs/2508.07575", "authors": ["Shiqing Fan", "Xichen Ding", "Liang Zhang", "Linjian Mo"], "title": "MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark", "categories": ["cs.AI"], "comment": "Benchmarks and Source Code Released", "summary": "LLMs' capabilities are enhanced by using function calls to integrate various\ndata sources or API results into the context window. Typical tools include\nsearch, web crawlers, maps, financial data, file systems, and browser usage,\netc. Integrating these data sources or functions requires a standardized\nmethod. The Model Context Protocol (MCP) provides a standardized way to supply\ncontext to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use\nabilities suffer from several issues. First, there's a lack of comprehensive\ndatasets or benchmarks to evaluate various MCP tools. Second, the diverse\nformats of response from MCP tool call execution further increase the\ndifficulty of evaluation. Additionally, unlike existing tool-use benchmarks\nwith high success rates in functions like programming and math functions, the\nsuccess rate of real-world MCP tool is not guaranteed and varies across\ndifferent MCP servers. Furthermore, the LLMs' context window also limits the\nnumber of available tools that can be called in a single run, because the\ntextual descriptions of tool and the parameters have long token length for an\nLLM to process all at once. To help address the challenges of evaluating LLMs'\nperformance on calling MCP tools, we propose MCPToolBench++, a large-scale,\nmulti-domain AI Agent tool use benchmark. As of July 2025, this benchmark is\nbuild upon marketplace of over 4k MCP servers from more than 40 categories,\ncollected from the MCP marketplaces and GitHub communities. The datasets\nconsist of both single-step and multi-step tool calls across different\ncategories. We evaluated SOTA LLMs with agentic abilities on this benchmark and\nreported the results.", "AI": {"tldr": "\u73b0\u6709LLMs\u8bc4\u4f30MCP\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u5b58\u5728\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faMCPToolBench++\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u5e76\u62a5\u544a\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30LLMs\u548cAI Agents\u7684MCP\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u5b58\u5728\u7f3a\u4e4f\u7efc\u5408\u6570\u636e\u96c6\u6216\u57fa\u51c6\u3001\u54cd\u5e94\u683c\u5f0f\u591a\u6837\u3001\u6210\u529f\u7387\u65e0\u4fdd\u8bc1\u3001\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u7b49\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u8bc4\u4f30\u6311\u6218\u3002", "method": "\u6784\u5efa\u5927\u89c4\u6a21\u3001\u591a\u9886\u57df\u7684AI Agent\u5de5\u5177\u4f7f\u7528\u57fa\u51c6MCPToolBench++\uff0c\u57fa\u4e8e\u8d854k\u4e2a\u6765\u81ea40\u591a\u4e2a\u7c7b\u522b\u7684MCP\u670d\u52a1\u5668\u6784\u5efa\uff0c\u5305\u542b\u5355\u6b65\u548c\u591a\u6b65\u5de5\u5177\u8c03\u7528\u6570\u636e\u96c6\u3002", "result": "\u5728\u8be5\u57fa\u51c6\u4e0a\u5bf9\u5177\u6709\u667a\u80fd\u4f53\u80fd\u529b\u7684SOTA LLMs\u8fdb\u884c\u8bc4\u4f30\u5e76\u62a5\u544a\u7ed3\u679c\u3002", "conclusion": "MCPToolBench++\u6709\u52a9\u4e8e\u89e3\u51b3\u8bc4\u4f30LLMs\u8c03\u7528MCP\u5de5\u5177\u6027\u80fd\u7684\u6311\u6218\u3002"}}
{"id": "2508.06997", "pdf": "https://arxiv.org/pdf/2508.06997", "abs": "https://arxiv.org/abs/2508.06997", "authors": ["Helbert Paat", "Guohao Shen"], "title": "Conformal Set-based Human-AI Complementarity with Multiple Experts", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "comment": "Accepted at AAMAS 2025. Code available at:\n  https://github.com/paathelb/conformal_hai_multiple", "summary": "Decision support systems are designed to assist human experts in\nclassification tasks by providing conformal prediction sets derived from a\npre-trained model. This human-AI collaboration has demonstrated enhanced\nclassification performance compared to using either the model or the expert\nindependently. In this study, we focus on the selection of instance-specific\nexperts from a pool of multiple human experts, contrasting it with existing\nresearch that typically focuses on single-expert scenarios. We characterize the\nconditions under which multiple experts can benefit from the conformal sets.\nWith the insight that only certain experts may be relevant for each instance,\nwe explore the problem of subset selection and introduce a greedy algorithm\nthat utilizes conformal sets to identify the subset of expert predictions that\nwill be used in classifying an instance. This approach is shown to yield better\nperformance compared to naive methods for human subset selection. Based on real\nexpert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation\nstudy indicates that our proposed greedy algorithm achieves near-optimal\nsubsets, resulting in improved classification performance among multiple\nexperts.", "AI": {"tldr": "\u7814\u7a76\u805a\u7126\u4ece\u591a\u4f4d\u4e13\u5bb6\u4e2d\u9009\u62e9\u7279\u5b9a\u5b9e\u4f8b\u7684\u4e13\u5bb6\uff0c\u5f15\u5165\u8d2a\u5fc3\u7b97\u6cd5\u5229\u7528\u5171\u5f62\u96c6\u9009\u4e13\u5bb6\u5b50\u96c6\uff0c\u5728\u591a\u4e13\u5bb6\u5206\u7c7b\u4e0a\u8868\u73b0\u4f18\u4e8e\u6734\u7d20\u65b9\u6cd5\uff0c\u6a21\u62df\u663e\u793a\u7b97\u6cd5\u63a5\u8fd1\u6700\u4f18\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u5355\u4e13\u5bb6\u573a\u666f\uff0c\u672c\u6587\u8981\u63a2\u7d22\u591a\u4e13\u5bb6\u5982\u4f55\u4ece\u5171\u5f62\u96c6\u4e2d\u83b7\u76ca\u53ca\u5b9e\u4f8b\u7279\u5b9a\u4e13\u5bb6\u7684\u9009\u62e9\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u5229\u7528\u5171\u5f62\u96c6\u8bc6\u522b\u7528\u4e8e\u5b9e\u4f8b\u5206\u7c7b\u7684\u4e13\u5bb6\u9884\u6d4b\u5b50\u96c6\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u4e13\u5bb6\u9884\u6d4b\u7684\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u63d0\u51fa\u7684\u8d2a\u5fc3\u7b97\u6cd5\u80fd\u5f97\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u5b50\u96c6\u3002", "conclusion": "\u8be5\u8d2a\u5fc3\u7b97\u6cd5\u53ef\u63d0\u5347\u591a\u4e13\u5bb6\u5206\u7c7b\u6027\u80fd\uff0c\u4f18\u4e8e\u6734\u7d20\u7684\u4eba\u7c7b\u5b50\u96c6\u9009\u62e9\u65b9\u6cd5\u3002"}}
{"id": "2508.07586", "pdf": "https://arxiv.org/pdf/2508.07586", "abs": "https://arxiv.org/abs/2508.07586", "authors": ["Wenjing Zhang", "Ye Hu", "Tao Luo", "Zhilong Zhang", "Mingzhe Chen"], "title": "Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method", "categories": ["cs.AI", "cs.NI"], "comment": null, "summary": "In this paper, a novel covert semantic communication framework is\ninvestigated. Within this framework, a server extracts and transmits the\nsemantic information, i.e., the meaning of image data, to a user over several\ntime slots. An attacker seeks to detect and eavesdrop the semantic transmission\nto acquire details of the original image. To avoid data meaning being\neavesdropped by an attacker, a friendly jammer is deployed to transmit jamming\nsignals to interfere the attacker so as to hide the transmitted semantic\ninformation. Meanwhile, the server will strategically select time slots for\nsemantic information transmission. Due to limited energy, the jammer will not\ncommunicate with the server and hence the server does not know the transmit\npower of the jammer. Therefore, the server must jointly optimize the semantic\ninformation transmitted at each time slot and the corresponding transmit power\nto maximize the privacy and the semantic information transmission quality of\nthe user. To solve this problem, we propose a prioritised sampling assisted\ntwin delayed deep deterministic policy gradient algorithm to jointly determine\nthe transmitted semantic information and the transmit power per time slot\nwithout the communications between the server and the jammer. Compared to\nstandard reinforcement learning methods, the propose method uses an additional\nQ network to estimate Q values such that the agent can select the action with a\nlower Q value from the two Q networks thus avoiding local optimal action\nselection and estimation bias of Q values. Simulation results show that the\nproposed algorithm can improve the privacy and the semantic information\ntransmission quality by up to 77.8% and 14.3% compared to the traditional\nreinforcement learning methods.", "AI": {"tldr": "\u7814\u7a76\u65b0\u578b\u9690\u853d\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u63d0\u51fa\u4f18\u5148\u91c7\u6837\u8f85\u52a9\u53cc\u5ef6\u8fdf\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff0c\u63d0\u5347\u9690\u79c1\u548c\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\u8d28\u91cf\u3002", "motivation": "\u907f\u514d\u653b\u51fb\u8005\u7a83\u542c\u8bed\u4e49\u4fe1\u606f\uff0c\u5728\u670d\u52a1\u5668\u4e0e\u5e72\u6270\u5668\u65e0\u901a\u4fe1\u60c5\u51b5\u4e0b\uff0c\u6700\u5927\u5316\u7528\u6237\u9690\u79c1\u548c\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4f18\u5148\u91c7\u6837\u8f85\u52a9\u53cc\u5ef6\u8fdf\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff0c\u7528\u989d\u5916Q\u7f51\u7edc\u4f30\u8ba1Q\u503c\uff0c\u907f\u514d\u5c40\u90e8\u6700\u4f18\u548c\u4f30\u8ba1\u504f\u5dee\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6240\u63d0\u7b97\u6cd5\u53ef\u5c06\u9690\u79c1\u548c\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\u8d28\u91cf\u5206\u522b\u63d0\u534777.8%\u548c14.3%\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u5728\u63d0\u5347\u9690\u79c1\u548c\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2508.07602", "pdf": "https://arxiv.org/pdf/2508.07602", "abs": "https://arxiv.org/abs/2508.07602", "authors": ["Wenpeng Xing", "Zhipeng Chen", "Changting Lin", "Meng Han"], "title": "HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol", "categories": ["cs.AI"], "comment": null, "summary": "Invoking external tools enables Large Language Models (LLMs) to perform\ncomplex, real-world tasks, yet selecting the correct tool from large,\nhierarchically-structured libraries remains a significant challenge. The\nlimited context windows of LLMs and noise from irrelevant options often lead to\nlow selection accuracy and high computational costs. To address this, we\npropose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic\npruning method for scalable tool invocation. HGMF first maps the user query and\nall tool descriptions into a unified semantic space. The framework then\noperates in two stages: it clusters servers using a Gaussian Mixture Model\n(GMM) and filters them based on the query's likelihood. Subsequently, it\napplies the same GMM-based clustering and filtering to the tools associated\nwith the selected servers. This hierarchical process produces a compact,\nhigh-relevance candidate set, simplifying the final selection task for the LLM.\nExperiments on a public dataset show that HGMF significantly improves tool\nselection accuracy while reducing inference latency, confirming the framework's\nscalability and effectiveness for large-scale tool libraries.", "AI": {"tldr": "\u63d0\u51faHierarchical Gaussian Mixture Framework (HGMF)\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u5927\u578b\u5206\u5c42\u5de5\u5177\u5e93\u9009\u5de5\u5177\u7684\u96be\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u5927\u578b\u5206\u5c42\u5de5\u5177\u5e93\u9009\u5de5\u5177\u5b58\u5728\u6311\u6218\uff0c\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u65e0\u5173\u9009\u9879\u566a\u58f0\u5bfc\u81f4\u51c6\u786e\u7387\u4f4e\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faHGMF\uff0c\u5148\u5c06\u7528\u6237\u67e5\u8be2\u548c\u5de5\u5177\u63cf\u8ff0\u6620\u5c04\u5230\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\uff0c\u5206\u4e24\u9636\u6bb5\u64cd\u4f5c\uff0c\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u805a\u7c7b\u548c\u8fc7\u6ee4\u670d\u52a1\u5668\u53ca\u76f8\u5173\u5de5\u5177\u3002", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u5b9e\u9a8c\u8868\u660e\uff0cHGMF\u663e\u8457\u63d0\u9ad8\u5de5\u5177\u9009\u62e9\u51c6\u786e\u7387\uff0c\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "HGMF\u5bf9\u5927\u89c4\u6a21\u5de5\u5177\u5e93\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2508.07029", "pdf": "https://arxiv.org/pdf/2508.07029", "abs": "https://arxiv.org/abs/2508.07029", "authors": ["Antonio Guillen-Perez"], "title": "From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving", "categories": ["cs.LG", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Learning robust driving policies from large-scale, real-world datasets is a\ncentral challenge in autonomous driving, as online data collection is often\nunsafe and impractical. While Behavioral Cloning (BC) offers a straightforward\napproach to imitation learning, policies trained with BC are notoriously\nbrittle and suffer from compounding errors in closed-loop execution. This work\npresents a comprehensive pipeline and a comparative study to address this\nlimitation. We first develop a series of increasingly sophisticated BC\nbaselines, culminating in a Transformer-based model that operates on a\nstructured, entity-centric state representation. While this model achieves low\nimitation loss, we show that it still fails in long-horizon simulations. We\nthen demonstrate that by applying a state-of-the-art Offline Reinforcement\nLearning algorithm, Conservative Q-Learning (CQL), to the same data and\narchitecture, we can learn a significantly more robust policy. Using a\ncarefully engineered reward function, the CQL agent learns a conservative value\nfunction that enables it to recover from minor errors and avoid\nout-of-distribution states. In a large-scale evaluation on 1,000 unseen\nscenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a\n3.2x higher success rate and a 7.4x lower collision rate than the strongest BC\nbaseline, proving that an offline RL approach is critical for learning robust,\nlong-horizon driving policies from static expert data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7efc\u5408\u6d41\u7a0b\u548c\u5bf9\u6bd4\u7814\u7a76\uff0c\u5bf9\u6bd4\u57fa\u4e8e\u884c\u4e3a\u514b\u9686\uff08BC\uff09\u548c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08CQL\uff09\u7684\u81ea\u52a8\u9a7e\u9a76\u7b56\u7565\uff0c\u7ed3\u679c\u663e\u793aCQL\u7b56\u7565\u66f4\u7a33\u5065\u3002", "motivation": "\u4ece\u5927\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u7a33\u5065\u9a7e\u9a76\u7b56\u7565\u662f\u81ea\u52a8\u9a7e\u9a76\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4f20\u7edfBC\u65b9\u6cd5\u8bad\u7ec3\u7684\u7b56\u7565\u8106\u5f31\u4e14\u5b58\u5728\u95ed\u73af\u6267\u884c\u8bef\u5dee\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5148\u5f00\u53d1\u4e00\u7cfb\u5217BC\u57fa\u7ebf\u6a21\u578b\uff0c\u6700\u7ec8\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff1b\u518d\u5bf9\u76f8\u540c\u6570\u636e\u548c\u67b6\u6784\u5e94\u7528\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5CQL\uff0c\u5e76\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5728Waymo\u5f00\u653e\u8fd0\u52a8\u6570\u636e\u96c6\u76841000\u4e2a\u672a\u89c1\u573a\u666f\u8bc4\u4f30\u4e2d\uff0cCQL\u667a\u80fd\u4f53\u6210\u529f\u7387\u6bd4\u6700\u5f3aBC\u57fa\u7ebf\u9ad83.2\u500d\uff0c\u78b0\u649e\u7387\u4f4e7.4\u500d\u3002", "conclusion": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5bf9\u4e8e\u4ece\u9759\u6001\u4e13\u5bb6\u6570\u636e\u4e2d\u5b66\u4e60\u7a33\u5065\u3001\u957f\u89c6\u91ce\u9a7e\u9a76\u7b56\u7565\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.07616", "pdf": "https://arxiv.org/pdf/2508.07616", "abs": "https://arxiv.org/abs/2508.07616", "authors": ["Aswin RRV", "Jacob Dineen", "Divij Handa", "Md Nayem Uddin", "Mihir Parmar", "Chitta Baral", "Ben Zhou"], "title": "ThinkTuning: Instilling Cognitive Reflections without Distillation", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "15 pages", "summary": "Recent advances in test-time scaling have led to the emergence of thinking\nLLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL\ndrives this self-improvement paradigm, a recent study (Gandhi et al., 2025)\nshows that RL alone does not truly instill these new reasoning abilities - it\nmerely draws out behaviors already present in the base models. This raises a\nquestion: How can we train the models that don't exhibit such thinking behavior\nto develop it in the first place? To this end, we propose ThinkTuning, a\nGRPO-based interactive training approach where we augment the rollouts of a\nstudent model with the guidance from a teacher model. A simple idea from\nclassroom practice inspires our method: a teacher poses a problem, lets the\nstudent try an answer, then gives corrective feedback -- enough to point the\nmind in the right direction and then show the solution. Each piece of feedback\nreshapes the student's thoughts, leading them to arrive at the correct\nsolution. Similarly, we find that this type of implicit supervision through\nfeedback from a teacher model of the same size improves the reasoning\ncapabilities of the student model. In particular, on average, our method shows\na 3.85% improvement over zero-shot baselines across benchmarks, and on\nMATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements\nover the vanilla-GRPO baseline. Source code is available at\nhttps://github.com/3rdAT/ThinkTuning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faThinkTuning\u65b9\u6cd5\uff0c\u501f\u52a9\u6559\u5e08\u6a21\u578b\u53cd\u9988\u63d0\u5347\u5b66\u751f\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u5f3a\u5316\u5b66\u4e60\u65e0\u6cd5\u771f\u6b63\u8d4b\u4e88\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u9700\u63a2\u7d22\u5982\u4f55\u8ba9\u65e0\u601d\u8003\u884c\u4e3a\u7684\u6a21\u578b\u53d1\u5c55\u8be5\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eGRPO\u7684\u4ea4\u4e92\u5f0f\u8bad\u7ec3\u65b9\u6cd5ThinkTuning\uff0c\u7528\u6559\u5e08\u6a21\u578b\u6307\u5bfc\u5b66\u751f\u6a21\u578b\u7684\u6eda\u52a8\u66f4\u65b0\uff0c\u901a\u8fc7\u53cd\u9988\u8fdb\u884c\u9690\u5f0f\u76d1\u7763\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u63d0\u53473.85%\uff0c\u5728MATH - 500\u3001AIME\u548cGPQA - Diamond\u4e0a\u6bd4vanilla - GRPO\u57fa\u7ebf\u5206\u522b\u63d0\u53472.08%\u30012.23%\u548c3.99%\u3002", "conclusion": "\u6559\u5e08\u6a21\u578b\u53cd\u9988\u7684\u9690\u5f0f\u76d1\u7763\u80fd\u6709\u6548\u63d0\u5347\u5b66\u751f\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0cThinkTuning\u65b9\u6cd5\u6709\u4e00\u5b9a\u6548\u679c\u3002"}}
{"id": "2508.07032", "pdf": "https://arxiv.org/pdf/2508.07032", "abs": "https://arxiv.org/abs/2508.07032", "authors": ["Tiantian He", "Keyue Jiang", "An Zhao", "Anna Schroder", "Elinor Thompson", "Sonja Soskic", "Frederik Barkhof", "Daniel C. Alexander"], "title": "A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "The long-term progression of neurodegenerative diseases is commonly\nconceptualized as a spatiotemporal diffusion process that consists of a graph\ndiffusion process across the structural brain connectome and a localized\nreaction process within brain regions. However, modeling this progression\nremains challenging due to 1) the scarcity of longitudinal data obtained\nthrough irregular and infrequent subject visits and 2) the complex interplay of\npathological mechanisms across brain regions and disease stages, where\ntraditional models assume fixed mechanisms throughout disease progression. To\naddress these limitations, we propose a novel stage-aware Mixture of Experts\n(MoE) framework that explicitly models how different contributing mechanisms\ndominate at different disease stages through time-dependent expert\nweighting.Data-wise, we utilize an iterative dual optimization method to\nproperly estimate the temporal position of individual observations,\nconstructing a co hort-level progression trajectory from irregular snapshots.\nModel-wise, we enhance the spatial component with an inhomogeneous graph neural\ndiffusion model (IGND) that allows diffusivity to vary based on node states and\ntime, providing more flexible representations of brain networks. We also\nintroduce a localized neural reaction module to capture complex dynamics beyond\nstandard processes.The resulting IGND-MoE model dynamically integrates these\ncomponents across temporal states, offering a principled way to understand how\nstage-specific pathological mechanisms contribute to progression. The\nstage-wise weights yield novel clinical insights that align with literature,\nsuggesting that graph-related processes are more influential at early stages,\nwhile other unknown physical processes become dominant later on.", "AI": {"tldr": "\u63d0\u51fa\u9636\u6bb5\u611f\u77e5\u7684IGND - MoE\u6a21\u578b\u89e3\u51b3\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u96be\u9898\uff0c\u6a21\u578b\u52a8\u6001\u6574\u5408\u7ec4\u4ef6\uff0c\u9636\u6bb5\u6743\u91cd\u7ed9\u51fa\u65b0\u4e34\u5e8a\u89c1\u89e3\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u5728\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u4e2d\uff0c\u56e0\u7eb5\u5411\u6570\u636e\u7a00\u7f3a\u548c\u75c5\u7406\u673a\u5236\u590d\u6742\u800c\u5b58\u5728\u5c40\u9650\uff0c\u9700\u65b0\u6a21\u578b\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u9636\u6bb5\u611f\u77e5\u7684MoE\u6846\u67b6\uff0c\u6570\u636e\u4e0a\u7528\u8fed\u4ee3\u53cc\u4f18\u5316\u6cd5\u4f30\u8ba1\u89c2\u6d4b\u65f6\u95f4\u4f4d\u7f6e\uff1b\u6a21\u578b\u4e0a\u7528IGND\u589e\u5f3a\u7a7a\u95f4\u7ec4\u4ef6\uff0c\u5f15\u5165\u5c40\u90e8\u795e\u7ecf\u53cd\u5e94\u6a21\u5757\u3002", "result": "IGND - MoE\u6a21\u578b\u52a8\u6001\u6574\u5408\u7ec4\u4ef6\uff0c\u9636\u6bb5\u6743\u91cd\u663e\u793a\u65e9\u671f\u56fe\u76f8\u5173\u8fc7\u7a0b\u5f71\u54cd\u5927\uff0c\u540e\u671f\u5176\u4ed6\u672a\u77e5\u7269\u7406\u8fc7\u7a0b\u5360\u4e3b\u5bfc\u3002", "conclusion": "IGND - MoE\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u89e3\u9636\u6bb5\u7279\u5b9a\u75c5\u7406\u673a\u5236\u5bf9\u75be\u75c5\u8fdb\u5c55\u8d21\u732e\u7684\u65b9\u6cd5\uff0c\u9636\u6bb5\u6743\u91cd\u4e34\u5e8a\u89c1\u89e3\u4e0e\u6587\u732e\u76f8\u7b26\u3002"}}
{"id": "2508.07628", "pdf": "https://arxiv.org/pdf/2508.07628", "abs": "https://arxiv.org/abs/2508.07628", "authors": ["Daniel Essien", "Suresh Neethirajan"], "title": "Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization", "categories": ["cs.AI"], "comment": "66 pages, 7 figures, 11 tables", "summary": "The future of poultry production depends on a paradigm shift replacing\nsubjective, labor-intensive welfare checks with data-driven, intelligent\nmonitoring ecosystems. Traditional welfare assessments-limited by human\nobservation and single-sensor data-cannot fully capture the complex,\nmultidimensional nature of laying hen welfare in modern farms. Multimodal\nArtificial Intelligence (AI) offers a breakthrough, integrating visual,\nacoustic, environmental, and physiological data streams to reveal deeper\ninsights into avian welfare dynamics. This investigation highlights multimodal\nAs transformative potential, showing that intermediate (feature-level) fusion\nstrategies achieve the best balance between robustness and performance under\nreal-world poultry conditions, and offer greater scalability than early or late\nfusion approaches. Key adoption barriers include sensor fragility in harsh farm\nenvironments, high deployment costs, inconsistent behavioral definitions, and\nlimited cross-farm generalizability. To address these, we introduce two novel\nevaluation tools - the Domain Transfer Score (DTS) to measure model\nadaptability across diverse farm settings, and the Data Reliability Index (DRI)\nto assess sensor data quality under operational constraints. We also propose a\nmodular, context-aware deployment framework designed for laying hen\nenvironments, enabling scalable and practical integration of multimodal\nsensing. This work lays the foundation for a transition from reactive, unimodal\nmonitoring to proactive, precision-driven welfare systems that unite\nproductivity with ethical, science based animal care.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u7528\u591a\u6a21\u6001AI\u76d1\u6d4b\u86cb\u9e21\u798f\u5229\uff0c\u6307\u51fa\u4e2d\u95f4\u878d\u5408\u7b56\u7565\u6700\u4f73\uff0c\u5206\u6790\u4e86\u91c7\u7528\u969c\u788d\uff0c\u4ecb\u7ecd\u8bc4\u4f30\u5de5\u5177\u548c\u90e8\u7f72\u6846\u67b6\uff0c\u63a8\u52a8\u5411\u4e3b\u52a8\u798f\u5229\u7cfb\u7edf\u8f6c\u53d8\u3002", "motivation": "\u4f20\u7edf\u798f\u5229\u8bc4\u4f30\u65b9\u6cd5\u53d7\u9650\uff0c\u9700\u7528\u6570\u636e\u9a71\u52a8\u7684\u667a\u80fd\u76d1\u6d4b\u751f\u6001\u7cfb\u7edf\u53d6\u4ee3\u4e3b\u89c2\u3001\u52b3\u52a8\u5bc6\u96c6\u7684\u798f\u5229\u68c0\u67e5\u3002", "method": "\u7814\u7a76\u591a\u6a21\u6001AI\u5728\u86cb\u9e21\u798f\u5229\u76d1\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u5bf9\u6bd4\u4e0d\u540c\u878d\u5408\u7b56\u7565\uff1b\u5f15\u5165Domain Transfer Score\u548cData Reliability Index\u8bc4\u4f30\u5de5\u5177\uff0c\u63d0\u51fa\u6a21\u5757\u5316\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u90e8\u7f72\u6846\u67b6\u3002", "result": "\u4e2d\u95f4\u878d\u5408\u7b56\u7565\u5728\u73b0\u5b9e\u5bb6\u79bd\u517b\u6b96\u6761\u4ef6\u4e0b\u80fd\u5b9e\u73b0\u7a33\u5065\u6027\u548c\u6027\u80fd\u7684\u6700\u4f73\u5e73\u8861\uff0c\u4e14\u6269\u5c55\u6027\u66f4\u597d\uff1b\u6307\u51fa\u4e86\u91c7\u7528\u591a\u6a21\u6001AI\u7684\u5173\u952e\u969c\u788d\u3002", "conclusion": "\u4e3a\u4ece\u88ab\u52a8\u5355\u6a21\u6001\u76d1\u6d4b\u5411\u4e3b\u52a8\u3001\u7cbe\u51c6\u9a71\u52a8\u7684\u798f\u5229\u7cfb\u7edf\u8f6c\u53d8\u5960\u5b9a\u57fa\u7840\uff0c\u5b9e\u73b0\u751f\u4ea7\u4e0e\u57fa\u4e8e\u79d1\u5b66\u7684\u52a8\u7269\u798f\u5229\u7edf\u4e00\u3002"}}
{"id": "2508.07037", "pdf": "https://arxiv.org/pdf/2508.07037", "abs": "https://arxiv.org/abs/2508.07037", "authors": ["Yangguang He", "Wenhao Li", "Minzhe Li", "Juan Zhang", "Xiangfeng Wang", "Bo Jin"], "title": "Differentiable Adaptive Kalman Filtering via Optimal Transport", "categories": ["cs.LG", "eess.SP"], "comment": "20 pages", "summary": "Learning-based filtering has demonstrated strong performance in non-linear\ndynamical systems, particularly when the statistics of noise are unknown.\nHowever, in real-world deployments, environmental factors, such as changing\nwind conditions or electromagnetic interference, can induce unobserved\nnoise-statistics drift, leading to substantial degradation of learning-based\nmethods. To address this challenge, we propose OTAKNet, the first online\nsolution to noise-statistics drift within learning-based adaptive Kalman\nfiltering. Unlike existing learning-based methods that perform offline\nfine-tuning using batch pointwise matching over entire trajectories, OTAKNet\nestablishes a connection between the state estimate and the drift via one-step\npredictive measurement likelihood, and addresses it using optimal transport.\nThis leverages OT's geometry - aware cost and stable gradients to enable fully\nonline adaptation without ground truth labels or retraining. We compare OTAKNet\nagainst classical model-based adaptive Kalman filtering and offline\nlearning-based filtering. The performance is demonstrated on both synthetic and\nreal-world NCLT datasets, particularly under limited training data.", "AI": {"tldr": "\u63d0\u51faOTAKNet\u89e3\u51b3\u5b66\u4e60\u578b\u81ea\u9002\u5e94\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e2d\u566a\u58f0\u7edf\u8ba1\u6f02\u79fb\u95ee\u9898\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u73af\u5883\u56e0\u7d20\u4f1a\u5bfc\u81f4\u5b66\u4e60\u578b\u65b9\u6cd5\u5728\u5904\u7406\u975e\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u65f6\u56e0\u566a\u58f0\u7edf\u8ba1\u6f02\u79fb\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u901a\u8fc7\u4e00\u6b65\u9884\u6d4b\u6d4b\u91cf\u4f3c\u7136\u5efa\u7acb\u72b6\u6001\u4f30\u8ba1\u4e0e\u6f02\u79fb\u7684\u8054\u7cfb\uff0c\u7528\u6700\u4f18\u4f20\u8f93\u89e3\u51b3\uff0c\u5b9e\u73b0\u65e0\u771f\u5b9e\u6807\u7b7e\u6216\u518d\u8bad\u7ec3\u7684\u5168\u5728\u7ebf\u81ea\u9002\u5e94\u3002", "result": "\u5c06OTAKNet\u4e0e\u7ecf\u5178\u57fa\u4e8e\u6a21\u578b\u7684\u81ea\u9002\u5e94\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u79bb\u7ebf\u5b66\u4e60\u578b\u6ee4\u6ce2\u6bd4\u8f83\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u7684NCLT\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u3002", "conclusion": "OTAKNet\u662f\u5b66\u4e60\u578b\u81ea\u9002\u5e94\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e2d\u5904\u7406\u566a\u58f0\u7edf\u8ba1\u6f02\u79fb\u7684\u6709\u6548\u5728\u7ebf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07642", "pdf": "https://arxiv.org/pdf/2508.07642", "abs": "https://arxiv.org/abs/2508.07642", "authors": ["Tianyi Ma", "Yue Zhang", "Zehao Wang", "Parisa Kordjamshidi"], "title": "Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "18 pages, 5 Figures,", "summary": "Vision-and-Language Navigation (VLN) poses significant challenges in enabling\nagents to interpret natural language instructions and navigate complex 3D\nenvironments. While recent progress has been driven by large-scale pre-training\nand data augmentation, current methods still struggle to generalize to unseen\nscenarios, particularly when complex spatial and temporal reasoning is\nrequired. In this work, we propose SkillNav, a modular framework that\nintroduces structured, skill-based reasoning into Transformer-based VLN agents.\nOur method decomposes navigation into a set of interpretable atomic skills\n(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each\nhandled by a specialized agent. We then introduce a novel zero-shot\nVision-Language Model (VLM)-based router, which dynamically selects the most\nsuitable agent at each time step by aligning sub-goals with visual observations\nand historical actions. SkillNav achieves a new state-of-the-art performance on\nthe R2R benchmark and demonstrates strong generalization to the GSA-R2R\nbenchmark that includes novel instruction styles and unseen environments.", "AI": {"tldr": "\u63d0\u51faSkillNav\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u6280\u80fd\u7684\u63a8\u7406\u5f15\u5165\u57fa\u4e8eTransformer\u7684VLN\u4ee3\u7406\uff0c\u5728R2R\u57fa\u51c6\u4e0a\u8fbe\u5230\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0c\u5bf9GSA - R2R\u57fa\u51c6\u6709\u5f3a\u6cdb\u5316\u6027\u3002", "motivation": "\u5f53\u524dVLN\u65b9\u6cd5\u5728\u672a\u89c1\u8fc7\u7684\u573a\u666f\uff0c\u7279\u522b\u662f\u9700\u8981\u590d\u6742\u65f6\u7a7a\u63a8\u7406\u65f6\u96be\u4ee5\u6cdb\u5316\u3002", "method": "\u63d0\u51faSkillNav\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5c06\u5bfc\u822a\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u7684\u539f\u5b50\u6280\u80fd\uff0c\u7531\u4e13\u95e8\u4ee3\u7406\u5904\u7406\uff0c\u5f15\u5165\u57fa\u4e8e\u96f6\u6837\u672cVLM\u7684\u8def\u7531\u6a21\u5757\u52a8\u6001\u9009\u62e9\u5408\u9002\u4ee3\u7406\u3002", "result": "\u5728R2R\u57fa\u51c6\u4e0a\u8fbe\u5230\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0c\u5bf9\u5305\u542b\u65b0\u6307\u4ee4\u98ce\u683c\u548c\u672a\u89c1\u73af\u5883\u7684GSA - R2R\u57fa\u51c6\u6709\u5f3a\u6cdb\u5316\u6027\u3002", "conclusion": "SkillNav\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86VLN\u4ee3\u7406\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.07054", "pdf": "https://arxiv.org/pdf/2508.07054", "abs": "https://arxiv.org/abs/2508.07054", "authors": ["Ziqi Zhang", "Ali Shahin Shamsabadi", "Hanxiao Lu", "Yifeng Cai", "Hamed Haddadi"], "title": "Membership and Memorization in LLM Knowledge Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in Knowledge Distillation (KD) aim to mitigate the high\ncomputational demands of Large Language Models (LLMs) by transferring knowledge\nfrom a large ''teacher'' to a smaller ''student'' model. However, students may\ninherit the teacher's privacy when the teacher is trained on private data. In\nthis work, we systematically characterize and investigate membership and\nmemorization privacy risks inherent in six LLM KD techniques. Using\ninstruction-tuning settings that span seven NLP tasks, together with three\nteacher model families (GPT-2, LLAMA-2, and OPT), and various size student\nmodels, we demonstrate that all existing LLM KD approaches carry membership and\nmemorization privacy risks from the teacher to its students. However, the\nextent of privacy risks varies across different KD techniques. We\nsystematically analyse how key LLM KD components (KD objective functions,\nstudent training data and NLP tasks) impact such privacy risks. We also\ndemonstrate a significant disagreement between memorization and membership\nprivacy risks of LLM KD techniques. Finally, we characterize per-block privacy\nrisk and demonstrate that the privacy risk varies across different blocks by a\nlarge margin.", "AI": {"tldr": "\u7814\u7a76\u7cfb\u7edf\u5206\u6790\u516d\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u7684\u9690\u79c1\u98ce\u9669\uff0c\u53d1\u73b0\u5747\u5b58\u5728\u98ce\u9669\u4e14\u7a0b\u5ea6\u4e0d\u540c\uff0c\u8fd8\u5206\u6790\u4e86\u5173\u952e\u7ec4\u4ef6\u5f71\u54cd\u53ca\u5757\u7ea7\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u5b66\u751f\u6a21\u578b\u53ef\u80fd\u7ee7\u627f\u6559\u5e08\u6a21\u578b\u9690\u79c1\u95ee\u9898\uff0c\u9700\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u7684\u9690\u79c1\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u6db5\u76d6\u4e03\u4e2aNLP\u4efb\u52a1\u7684\u6307\u4ee4\u8c03\u4f18\u8bbe\u7f6e\uff0c\u7ed3\u5408\u4e09\u79cd\u6559\u5e08\u6a21\u578b\u5bb6\u65cf\u548c\u4e0d\u540c\u5927\u5c0f\u7684\u5b66\u751f\u6a21\u578b\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u6240\u6709\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u90fd\u5b58\u5728\u4ece\u6559\u5e08\u5230\u5b66\u751f\u7684\u6210\u5458\u8d44\u683c\u548c\u8bb0\u5fc6\u9690\u79c1\u98ce\u9669\uff0c\u98ce\u9669\u7a0b\u5ea6\u56e0\u6280\u672f\u800c\u5f02\uff0c\u8bb0\u5fc6\u548c\u6210\u5458\u8d44\u683c\u9690\u79c1\u98ce\u9669\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e0d\u540c\u5757\u7684\u9690\u79c1\u98ce\u9669\u5dee\u5f02\u5927\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u5173\u952e\u7ec4\u4ef6\u4f1a\u5f71\u54cd\u98ce\u9669\u7a0b\u5ea6\uff0c\u4e0d\u540c\u5757\u7684\u9690\u79c1\u98ce\u9669\u4e0d\u540c\u3002"}}
{"id": "2508.07649", "pdf": "https://arxiv.org/pdf/2508.07649", "abs": "https://arxiv.org/abs/2508.07649", "authors": ["Jie Li", "Haoye Dong", "Zhengyang Wu", "Zetao Zheng", "Mingrong Lin"], "title": "Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Next Point-of-Interest (POI) recommendation is a research hotspot in business\nintelligence, where users' spatial-temporal transitions and social\nrelationships play key roles. However, most existing works model spatial and\ntemporal transitions separately, leading to misaligned representations of the\nsame spatial-temporal key nodes. This misalignment introduces redundant\ninformation during fusion, increasing model uncertainty and reducing\ninterpretability. To address this issue, we propose DiMuST, a socially enhanced\nPOI recommendation model based on disentangled representation learning over\nmultiplex spatial-temporal transition graphs. The model employs a novel\nDisentangled variational multiplex graph Auto-Encoder (DAE), which first\ndisentangles shared and private distributions using a multiplex\nspatial-temporal graph strategy. It then fuses the shared features via a\nProduct of Experts (PoE) mechanism and denoises the private features through\ncontrastive constraints. The model effectively captures the spatial-temporal\ntransition representations of POIs while preserving the intrinsic correlation\nof their spatial-temporal relationships. Experiments on two challenging\ndatasets demonstrate that our DiMuST significantly outperforms existing methods\nacross multiple metrics.", "AI": {"tldr": "\u63d0\u51faDiMuST\u6a21\u578b\u89e3\u51b3\u73b0\u6709POI\u63a8\u8350\u4e2d\u65f6\u7a7a\u8fc7\u6e21\u8868\u793a\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5206\u522b\u5efa\u6a21\u65f6\u7a7a\u8fc7\u6e21\uff0c\u5bfc\u81f4\u540c\u4e00\u65f6\u7a7a\u5173\u952e\u8282\u70b9\u8868\u793a\u4e0d\u5bf9\u9f50\uff0c\u589e\u52a0\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u964d\u4f4e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u89e3\u7ea0\u7f20\u8868\u793a\u5b66\u4e60\u7684\u793e\u4f1a\u589e\u5f3aPOI\u63a8\u8350\u6a21\u578bDiMuST\uff0c\u91c7\u7528\u89e3\u7ea0\u7f20\u53d8\u5206\u591a\u8def\u56fe\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5148\u5206\u79bb\u5206\u5e03\uff0c\u518d\u878d\u5408\u5171\u4eab\u7279\u5f81\u548c\u53bb\u566a\u79c1\u6709\u7279\u5f81\u3002", "result": "\u5728\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cDiMuST\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DiMuST\u80fd\u6709\u6548\u6355\u6349POI\u7684\u65f6\u7a7a\u8fc7\u6e21\u8868\u793a\uff0c\u4fdd\u7559\u5176\u65f6\u7a7a\u5173\u7cfb\u7684\u5185\u5728\u76f8\u5173\u6027\u3002"}}
{"id": "2508.07075", "pdf": "https://arxiv.org/pdf/2508.07075", "abs": "https://arxiv.org/abs/2508.07075", "authors": ["Stanley Ngugi"], "title": "Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 2 visual aids", "summary": "Large Language Models (LLMs) struggle with dynamic knowledge updates,\nespecially when new information conflicts with deeply embedded facts. Such\nconflicting factual edits often lead to two critical issues: resistance to\nadopting the new fact and severe catastrophic forgetting of unrelated\nknowledge. This paper introduces and evaluates a novel \"unlearn-then-learn\"\nstrategy for precise knowledge editing in LLMs, leveraging the\nparameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting\nand Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach\nis powered by an initial circuit localization phase that identifies and targets\nthe specific internal components responsible for encoding the conflicting fact.\nThrough a rigorous experimental methodology on\nmicrosoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically\ninformed two-stage approach achieves near-perfect accuracy (98.50%) for the\nnew, modulated fact while simultaneously effectively suppressing the original\nconflicting fact (96.00% forget rate). Critically, our strategy exhibits\nunprecedented localization (72.00% F_control accuracy), dramatically mitigating\ncatastrophic forgetting observed in direct fine-tuning approaches (which showed\nas low as ~20% F_control accuracy), a direct benefit of our targeted\ninterpretability-guided intervention. Furthermore, qualitative analysis reveals\na nuanced mechanism of \"soft forgetting,\" where original knowledge is\nsuppressed from default retrieval but remains latent and conditionally\naccessible, enhancing model safety and control. These findings represent a\nsignificant advancement towards precise, localized, and safe knowledge\nmanagement in compact LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201c\u5148\u9057\u5fd8\u540e\u5b66\u4e60\u201d\u7b56\u7565\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u7f16\u8f91\uff0c\u5728microsoft/Phi - 3 - mini - 4k - instruct\u4e0a\u5b9e\u9a8c\u6548\u679c\u597d\uff0c\u63d0\u5347\u6a21\u578b\u77e5\u8bc6\u7ba1\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u77e5\u8bc6\u66f4\u65b0\u65f6\u5b58\u5728\u91c7\u7528\u65b0\u4e8b\u5b9e\u56f0\u96be\u548c\u4e25\u91cd\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u201c\u5148\u9057\u5fd8\u540e\u5b66\u4e60\u201d\u7b56\u7565\uff0c\u5229\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f$IA^3$\uff0c\u901a\u8fc7\u521d\u59cb\u7535\u8def\u5b9a\u4f4d\u9636\u6bb5\u8bc6\u522b\u7f16\u7801\u51b2\u7a81\u4e8b\u5b9e\u7684\u5185\u90e8\u7ec4\u4ef6\u3002", "result": "\u5728\u65b0\u8c03\u5236\u4e8b\u5b9e\u51c6\u786e\u6027\u8fbe98.50%\uff0c\u9057\u5fd8\u539f\u51b2\u7a81\u4e8b\u5b9e\u738796.00%\uff0cF_control\u51c6\u786e\u738772.00%\uff0c\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u3002\u6709\u201c\u8f6f\u9057\u5fd8\u201d\u673a\u5236\u3002", "conclusion": "\u8be5\u7b56\u7565\u662f\u7d27\u51d1\u578b\u5927\u8bed\u8a00\u6a21\u578b\u7cbe\u786e\u3001\u5c40\u90e8\u548c\u5b89\u5168\u77e5\u8bc6\u7ba1\u7406\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2508.07667", "pdf": "https://arxiv.org/pdf/2508.07667", "abs": "https://arxiv.org/abs/2508.07667", "authors": ["Wenkai Li", "Liwen Sun", "Zhenxiang Guan", "Xuhui Zhou", "Maarten Sap"], "title": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Addressing contextual privacy concerns remains challenging in interactive\nsettings where large language models (LLMs) process information from multiple\nsources (e.g., summarizing meetings with private and public information). We\nintroduce a multi-agent framework that decomposes privacy reasoning into\nspecialized subtasks (extraction, classification), reducing the information\nload on any single agent while enabling iterative validation and more reliable\nadherence to contextual privacy norms. To understand how privacy errors emerge\nand propagate, we conduct a systematic ablation over information-flow\ntopologies, revealing when and why upstream detection mistakes cascade into\ndownstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with\nseveral open-source and closed-sourced LLMs demonstrate that our best\nmulti-agent configuration substantially reduces private information leakage\n(\\textbf{18\\%} on ConfAIde and \\textbf{19\\%} on PrivacyLens with GPT-4o) while\npreserving the fidelity of public content, outperforming single-agent\nbaselines. These results highlight the promise of principled information-flow\ndesign in multi-agent systems for contextual privacy with LLMs.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5904\u7406\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u9690\u79c1\u95ee\u9898\uff0c\u51cf\u5c11\u4fe1\u606f\u6cc4\u9732\uff0c\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002", "motivation": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u591a\u6e90\u4fe1\u606f\u7684\u4ea4\u4e92\u573a\u666f\u4e2d\uff0c\u89e3\u51b3\u4e0a\u4e0b\u6587\u9690\u79c1\u95ee\u9898\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u9690\u79c1\u63a8\u7406\u5206\u89e3\u4e3a\u63d0\u53d6\u3001\u5206\u7c7b\u7b49\u5b50\u4efb\u52a1\uff0c\u5bf9\u4fe1\u606f\u6d41\u62d3\u6251\u8fdb\u884c\u7cfb\u7edf\u6d88\u878d\u5b9e\u9a8c\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6700\u4f73\u591a\u667a\u80fd\u4f53\u914d\u7f6e\u663e\u8457\u51cf\u5c11\u79c1\u4eba\u4fe1\u606f\u6cc4\u9732\uff08ConfAIde \u51cf\u5c11 18%\uff0cPrivacyLens \u7528 GPT - 4o \u51cf\u5c11 19%\uff09\uff0c\u540c\u65f6\u4fdd\u7559\u516c\u5171\u5185\u5bb9\u4fdd\u771f\u5ea6\uff0c\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u539f\u5219\u7684\u4fe1\u606f\u6d41\u8bbe\u8ba1\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u6709\u524d\u666f\u3002"}}
{"id": "2508.07085", "pdf": "https://arxiv.org/pdf/2508.07085", "abs": "https://arxiv.org/abs/2508.07085", "authors": ["N Harshit", "K Mounvik"], "title": "Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework", "categories": ["cs.LG"], "comment": null, "summary": "In applied machine learning, concept drift, which is either gradual or abrupt\nchanges in data distribution, can significantly reduce model performance.\nTypical detection methods,such as statistical tests or reconstruction-based\nmodels,are generally reactive and not very sensitive to early detection. Our\nstudy proposes a hybrid framework consisting of Transformers and Autoencoders\nto model complex temporal dynamics and provide online drift detection. We\ncreate a distinct Trust Score methodology, which includes signals on (1)\nstatistical and reconstruction-based drift metrics, more specifically, PSI,\nJSD, Transformer-AE error, (2) prediction uncertainty, (3) rules violations,\nand (4) trend of classifier error aligned with the combined metrics defined by\nthe Trust Score. Using a time sequenced airline passenger data set with\nsynthetic drift, our proposed model allows for a better detection of drift\nusing as a whole and at different detection thresholds for both sensitivity and\ninterpretability compared to baseline methods and provides a strong pipeline\nfor drift detection in real time for applied machine learning. We evaluated\nperformance using a time-sequenced airline passenger dataset having the\ngradually injected stimulus of drift in expectations,e.g. permuted ticket\nprices in later batches, broken into 10 time segments [1].In the data, our\nresults support that the Transformation-Autoencoder detected drift earlier and\nwith more sensitivity than the autoencoders commonly used in the literature,\nand provided improved modeling over more error rates and logical violations.\nTherefore, a robust framework was developed to reliably monitor concept drift.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7531Transformers\u548cAutoencoders\u7ec4\u6210\u7684\u6df7\u5408\u6846\u67b6\u7528\u4e8e\u5728\u7ebf\u6f02\u79fb\u68c0\u6d4b\uff0c\u521b\u5efaTrust Score\u65b9\u6cd5\uff0c\u5728\u542b\u5408\u6210\u6f02\u79fb\u7684\u822a\u7a7a\u4e58\u5ba2\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5f00\u53d1\u51fa\u53ef\u9760\u76d1\u6d4b\u6982\u5ff5\u6f02\u79fb\u7684\u6846\u67b6\u3002", "motivation": "\u5e94\u7528\u673a\u5668\u5b66\u4e60\u4e2d\u6982\u5ff5\u6f02\u79fb\u4f1a\u964d\u4f4e\u6a21\u578b\u6027\u80fd\uff0c\u5178\u578b\u68c0\u6d4b\u65b9\u6cd5\u53cd\u5e94\u5f0f\u4e14\u5bf9\u65e9\u671f\u68c0\u6d4b\u4e0d\u654f\u611f\u3002", "method": "\u63d0\u51fa\u7531Transformers\u548cAutoencoders\u7ec4\u6210\u7684\u6df7\u5408\u6846\u67b6\uff0c\u521b\u5efaTrust Score\u65b9\u6cd5\uff0c\u5305\u542b\u7edf\u8ba1\u548c\u57fa\u4e8e\u91cd\u5efa\u7684\u6f02\u79fb\u6307\u6807\u3001\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3001\u89c4\u5219\u8fdd\u53cd\u548c\u5206\u7c7b\u5668\u8bef\u5dee\u8d8b\u52bf\u7b49\u4fe1\u53f7\u3002", "result": "\u5728\u542b\u5408\u6210\u6f02\u79fb\u7684\u822a\u7a7a\u4e58\u5ba2\u6570\u636e\u96c6\u4e0a\uff0cTransformation - Autoencoder\u6bd4\u6587\u732e\u4e2d\u5e38\u7528\u7684\u81ea\u7f16\u7801\u5668\u66f4\u65e9\u3001\u66f4\u7075\u654f\u5730\u68c0\u6d4b\u5230\u6f02\u79fb\uff0c\u5728\u66f4\u591a\u9519\u8bef\u7387\u548c\u903b\u8f91\u8fdd\u89c4\u65b9\u9762\u6709\u66f4\u597d\u7684\u5efa\u6a21\u3002", "conclusion": "\u5f00\u53d1\u51fa\u4e86\u53ef\u9760\u76d1\u6d4b\u6982\u5ff5\u6f02\u79fb\u7684\u5f3a\u5927\u6846\u67b6\u3002"}}
{"id": "2508.07671", "pdf": "https://arxiv.org/pdf/2508.07671", "abs": "https://arxiv.org/abs/2508.07671", "authors": ["Mohamed Rayan Barhdadi", "Mehmet Tuncel", "Erchin Serpedin", "Hasan Kurban"], "title": "EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MA", "stat.AP", "68T07, 68T42, 68T50, 91F20, 62P25", "I.2.11; I.2.1; H.1.2; J.4; K.4.2"], "comment": "19 pages, 3 figures (plus 6 figures in supplementary), 2 tables, 1\n  algorithm. Submitted to NeurIPS 2025 Creative AI Track: Humanity", "summary": "Current AI approaches to refugee integration optimize narrow objectives such\nas employment and fail to capture the cultural, emotional, and ethical\ndimensions critical for long-term success. We introduce EMPATHIA (Enriched\nMultimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),\na multi-agent framework addressing the central Creative AI question: how do we\npreserve human dignity when machines participate in life-altering decisions?\nGrounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes\nintegration into three modules: SEED (Socio-cultural Entry and Embedding\nDecision) for initial placement, RISE (Rapid Integration and Self-sufficiency\nEngine) for early independence, and THRIVE (Transcultural Harmony and\nResilience through Integrated Values and Engagement) for sustained outcomes.\nSEED employs a selector-validator architecture with three specialized agents -\nemotional, cultural, and ethical - that deliberate transparently to produce\ninterpretable recommendations. Experiments on the UN Kakuma dataset (15,026\nindividuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and\nimplementation on 6,359 working-age refugees (15+) with 150+ socioeconomic\nvariables achieved 87.4% validation convergence and explainable assessments\nacross five host countries. EMPATHIA's weighted integration of cultural,\nemotional, and ethical factors balances competing value systems while\nsupporting practitioner-AI collaboration. By augmenting rather than replacing\nhuman expertise, EMPATHIA provides a generalizable framework for AI-driven\nallocation tasks where multiple values must be reconciled.", "AI": {"tldr": "\u73b0\u6709AI\u96be\u6c11\u878d\u5408\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u5f15\u5165EMPATHIA\u6846\u67b6\uff0c\u7ecf\u5b9e\u9a8c\u53d6\u5f97\u8f83\u597d\u7ed3\u679c\u4e14\u53ef\u5e73\u8861\u591a\u4ef7\u503c\u7cfb\u7edf\uff0c\u63d0\u4f9b\u901a\u7528\u6846\u67b6\u3002", "motivation": "\u5f53\u524dAI\u96be\u6c11\u878d\u5408\u65b9\u6cd5\u4ec5\u4f18\u5316\u72ed\u7a84\u76ee\u6807\uff0c\u672a\u6db5\u76d6\u6587\u5316\u3001\u60c5\u611f\u548c\u9053\u5fb7\u7ef4\u5ea6\uff0c\u9700\u8981\u89e3\u51b3\u673a\u5668\u53c2\u4e0e\u91cd\u5927\u51b3\u7b56\u65f6\u5982\u4f55\u7ef4\u62a4\u4eba\u7c7b\u5c0a\u4e25\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8eKegan\u7684\u5efa\u6784\u53d1\u5c55\u7406\u8bba\uff0c\u5c06\u878d\u5408\u5206\u89e3\u4e3aSEED\u3001RISE\u548cTHRIVE\u4e09\u4e2a\u6a21\u5757\uff0cSEED\u91c7\u7528\u9009\u62e9\u5668 - \u9a8c\u8bc1\u5668\u67b6\u6784\u53ca\u4e09\u4e2a\u4e13\u4e1a\u4ee3\u7406\u8fdb\u884c\u900f\u660e\u5ba1\u8bae\u3002", "result": "\u5728UN Kakuma\u6570\u636e\u96c6\u548c6359\u540d\u9002\u9f84\u96be\u6c11\u4e0a\u5b9e\u9a8c\uff0c\u5b9e\u73b087.4%\u9a8c\u8bc1\u6536\u655b\u548c\u53ef\u89e3\u91ca\u8bc4\u4f30\u3002", "conclusion": "EMPATHIA\u52a0\u6743\u6574\u5408\u591a\u56e0\u7d20\u53ef\u5e73\u8861\u4ef7\u503c\u7cfb\u7edf\uff0c\u652f\u6301\u4eba\u673a\u534f\u4f5c\uff0c\u4e3a\u9700\u534f\u8c03\u591a\u4ef7\u503c\u7684AI\u5206\u914d\u4efb\u52a1\u63d0\u4f9b\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2508.07102", "pdf": "https://arxiv.org/pdf/2508.07102", "abs": "https://arxiv.org/abs/2508.07102", "authors": ["Yang Cao", "Yubin Chen", "Zhao Song", "Jiahao Zhang"], "title": "Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Generative modelling has seen significant advances through simulation-free\nparadigms such as Flow Matching, and in particular, the MeanFlow framework,\nwhich replaces instantaneous velocity fields with average velocities to enable\nefficient single-step sampling. In this work, we introduce a theoretical study\non Second-Order MeanFlow, a novel extension that incorporates average\nacceleration fields into the MeanFlow objective. We first establish the\nfeasibility of our approach by proving that the average acceleration satisfies\na generalized consistency condition analogous to first-order MeanFlow, thereby\nsupporting stable, one-step sampling and tractable loss functions. We then\ncharacterize its expressivity via circuit complexity analysis, showing that\nunder mild assumptions, the Second-Order MeanFlow sampling process can be\nimplemented by uniform threshold circuits within the $\\mathsf{TC}^0$ class.\nFinally, we derive provably efficient criteria for scalable implementation by\nleveraging fast approximate attention computations: we prove that attention\noperations within the Second-Order MeanFlow architecture can be approximated to\nwithin $1/\\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results\nlay the theoretical foundation for high-order flow matching models that combine\nrich dynamics with practical sampling efficiency.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e8c\u9636MeanFlow\u8fdb\u884c\u7406\u8bba\u7814\u7a76\uff0c\u8bc1\u660e\u5176\u53ef\u884c\u6027\u3001\u523b\u753b\u8868\u8fbe\u80fd\u529b\u5e76\u63a8\u5bfc\u9ad8\u6548\u5b9e\u73b0\u6807\u51c6\uff0c\u4e3a\u9ad8\u9636\u6d41\u5339\u914d\u6a21\u578b\u5960\u5b9a\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5efa\u6a21\u5728\u65e0\u6a21\u62df\u8303\u5f0f\u5982Flow Matching\u548cMeanFlow\u6846\u67b6\u53d6\u5f97\u8fdb\u5c55\uff0c\u5f15\u5165\u4e8c\u9636MeanFlow\u4ee5\u62d3\u5c55MeanFlow\u76ee\u6807\uff0c\u7ed3\u5408\u4e30\u5bcc\u52a8\u529b\u5b66\u548c\u9ad8\u6548\u91c7\u6837\u3002", "method": "\u8bc1\u660e\u5e73\u5747\u52a0\u901f\u5ea6\u6ee1\u8db3\u5e7f\u4e49\u4e00\u81f4\u6027\u6761\u4ef6\uff1b\u901a\u8fc7\u7535\u8def\u590d\u6742\u5ea6\u5206\u6790\u523b\u753b\u8868\u8fbe\u80fd\u529b\uff1b\u5229\u7528\u5feb\u901f\u8fd1\u4f3c\u6ce8\u610f\u529b\u8ba1\u7b97\u63a8\u5bfc\u53ef\u6269\u5c55\u5b9e\u73b0\u6807\u51c6\u3002", "result": "\u8bc1\u660e\u4e8c\u9636MeanFlow\u652f\u6301\u7a33\u5b9a\u5355\u6b65\u91c7\u6837\u548c\u6613\u5904\u7406\u635f\u5931\u51fd\u6570\uff1b\u8868\u660e\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u91c7\u6837\u8fc7\u7a0b\u53ef\u7531\u7279\u5b9a\u9608\u503c\u7535\u8def\u5b9e\u73b0\uff1b\u8bc1\u660e\u6ce8\u610f\u529b\u64cd\u4f5c\u53ef\u5728\u7279\u5b9a\u65f6\u95f4\u5185\u4ee5\u7279\u5b9a\u8bef\u5dee\u8fd1\u4f3c\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7ed3\u5408\u4e30\u5bcc\u52a8\u529b\u5b66\u548c\u5b9e\u9645\u91c7\u6837\u6548\u7387\u7684\u9ad8\u9636\u6d41\u5339\u914d\u6a21\u578b\u5960\u5b9a\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.07673", "pdf": "https://arxiv.org/pdf/2508.07673", "abs": "https://arxiv.org/abs/2508.07673", "authors": ["Gianluca Bontempi"], "title": "Ethics2vec: aligning automatic agents and human preferences", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Though intelligent agents are supposed to improve human experience (or make\nit more efficient), it is hard from a human perspective to grasp the ethical\nvalues which are explicitly or implicitly embedded in an agent behaviour. This\nis the well-known problem of alignment, which refers to the challenge of\ndesigning AI systems that align with human values, goals and preferences. This\nproblem is particularly challenging since most human ethical considerations\nrefer to \\emph{incommensurable} (i.e. non-measurable and/or incomparable)\nvalues and criteria. Consider, for instance, a medical agent prescribing a\ntreatment to a cancerous patient. How could it take into account (and/or weigh)\nincommensurable aspects like the value of a human life and the cost of the\ntreatment? Now, the alignment between human and artificial values is possible\nonly if we define a common space where a metric can be defined and used. This\npaper proposes to extend to ethics the conventional Anything2vec approach,\nwhich has been successful in plenty of similar and hard-to-quantify domains\n(ranging from natural language processing to recommendation systems and graph\nanalysis). This paper proposes a way to map an automatic agent decision-making\n(or control law) strategy to a multivariate vector representation, which can be\nused to compare and assess the alignment with human values. The Ethics2Vec\nmethod is first introduced in the case of an automatic agent performing binary\ndecision-making. Then, a vectorisation of an automatic control law (like in the\ncase of a self-driving car) is discussed to show how the approach can be\nextended to automatic control settings.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u4ef7\u503c\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u51fa\u7528Ethics2Vec\u65b9\u6cd5\u5c06\u81ea\u52a8\u51b3\u7b56\u7b56\u7565\u6620\u5c04\u4e3a\u5411\u91cf\u8868\u793a\u6765\u8bc4\u4f30\u4e0e\u4eba\u7c7b\u4ef7\u503c\u7684\u5bf9\u9f50\u60c5\u51b5\u3002", "motivation": "\u89e3\u51b3\u667a\u80fd\u4f53\u884c\u4e3a\u4e2d\u96be\u4ee5\u628a\u63e1\u4f26\u7406\u4ef7\u503c\uff0c\u5373\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u4ef7\u503c\u3001\u76ee\u6807\u548c\u504f\u597d\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u8003\u8651\u5230\u4eba\u7c7b\u4f26\u7406\u8003\u91cf\u4e2d\u5b58\u5728\u4e0d\u53ef\u901a\u7ea6\u7684\u4ef7\u503c\u548c\u6807\u51c6\u3002", "method": "\u5c06\u4f20\u7edf\u7684Anything2vec\u65b9\u6cd5\u6269\u5c55\u5230\u4f26\u7406\u5b66\u9886\u57df\uff0c\u628a\u81ea\u52a8\u667a\u80fd\u4f53\u51b3\u7b56\u7b56\u7565\u6620\u5c04\u4e3a\u591a\u5143\u5411\u91cf\u8868\u793a\u3002\u5148\u5728\u4e8c\u5143\u51b3\u7b56\u573a\u666f\u4ecb\u7ecdEthics2Vec\u65b9\u6cd5\uff0c\u518d\u8ba8\u8bba\u81ea\u52a8\u63a7\u5236\u5f8b\u7684\u5411\u91cf\u5316\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\uff0c\u4f46\u63d0\u51fa\u4e86\u8bc4\u4f30\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u4ef7\u503c\u5bf9\u9f50\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.07106", "pdf": "https://arxiv.org/pdf/2508.07106", "abs": "https://arxiv.org/abs/2508.07106", "authors": ["Yiran Huang", "Amirhossein Nouranizadeh", "Christine Ahrends", "Mengjia Xu"], "title": "BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation", "categories": ["cs.LG"], "comment": null, "summary": "Functional Magnetic Resonance Imaging (fMRI) is an imaging technique widely\nused to study human brain activity. fMRI signals in areas across the brain\ntransiently synchronise and desynchronise their activity in a highly structured\nmanner, even when an individual is at rest. These functional connectivity\ndynamics may be related to behaviour and neuropsychiatric disease. To model\nthese dynamics, temporal brain connectivity representations are essential, as\nthey reflect evolving interactions between brain regions and provide insight\ninto transient neural states and network reconfigurations. However,\nconventional graph neural networks (GNNs) often struggle to capture long-range\ntemporal dependencies in dynamic fMRI data. To address this challenge, we\npropose BrainATCL, an unsupervised, nonparametric framework for adaptive\ntemporal brain connectivity learning, enabling functional link prediction and\nage estimation. Our method dynamically adjusts the lookback window for each\nsnapshot based on the rate of newly added edges. Graph sequences are\nsubsequently encoded using a GINE-Mamba2 backbone to learn spatial-temporal\nrepresentations of dynamic functional connectivity in resting-state fMRI data\nof 1,000 participants from the Human Connectome Project. To further improve\nspatial modeling, we incorporate brain structure and function-informed edge\nattributes, i.e., the left/right hemispheric identity and subnetwork membership\nof brain regions, enabling the model to capture biologically meaningful\ntopological patterns. We evaluate our BrainATCL on two tasks: functional link\nprediction and age estimation. The experimental results demonstrate superior\nperformance and strong generalization, including in cross-session prediction\nscenarios.", "AI": {"tldr": "\u63d0\u51faBrainATCL\u6846\u67b6\u7528\u4e8e\u81ea\u9002\u5e94\u5b66\u4e60\u52a8\u6001\u8111\u8fde\u63a5\uff0c\u5728\u529f\u80fd\u94fe\u63a5\u9884\u6d4b\u548c\u5e74\u9f84\u4f30\u8ba1\u4efb\u52a1\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u56fe\u795e\u7ecf\u7f51\u7edc\u96be\u4ee5\u6355\u6349\u52a8\u6001fMRI\u6570\u636e\u7684\u957f\u65f6\u4f9d\u8d56\uff0c\u800c\u529f\u80fd\u6027\u8fde\u63a5\u52a8\u529b\u5b66\u4e0e\u884c\u4e3a\u548c\u795e\u7ecf\u7cbe\u795e\u75be\u75c5\u76f8\u5173\uff0c\u9700\u8981\u66f4\u597d\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51faBrainATCL\u6846\u67b6\uff0c\u6839\u636e\u65b0\u8fb9\u6dfb\u52a0\u7387\u52a8\u6001\u8c03\u6574\u56de\u6eaf\u7a97\u53e3\uff0c\u7528GINE - Mamba2\u9aa8\u5e72\u7f16\u7801\u56fe\u5e8f\u5217\uff0c\u7ed3\u5408\u8111\u7ed3\u6784\u548c\u529f\u80fd\u4fe1\u606f\u7684\u8fb9\u5c5e\u6027\u3002", "result": "\u5728\u529f\u80fd\u94fe\u63a5\u9884\u6d4b\u548c\u5e74\u9f84\u4f30\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u6709\u5f88\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5305\u62ec\u8de8\u4f1a\u8bdd\u9884\u6d4b\u573a\u666f\u3002", "conclusion": "BrainATCL\u6846\u67b6\u80fd\u6709\u6548\u5b66\u4e60\u52a8\u6001\u8111\u8fde\u63a5\uff0c\u5728\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.07743", "pdf": "https://arxiv.org/pdf/2508.07743", "abs": "https://arxiv.org/abs/2508.07743", "authors": ["Markus Fritzsche", "Elliot Gestrin", "Jendrik Seipp"], "title": "Symmetry-Aware Transformer Training for Automated Planning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "While transformers excel in many settings, their application in the field of\nautomated planning is limited. Prior work like PlanGPT, a state-of-the-art\ndecoder-only transformer, struggles with extrapolation from easy to hard\nplanning problems. This in turn stems from problem symmetries: planning tasks\ncan be represented with arbitrary variable names that carry no meaning beyond\nbeing identifiers. This causes a combinatorial explosion of equivalent\nrepresentations that pure transformers cannot efficiently learn from. We\npropose a novel contrastive learning objective to make transformers\nsymmetry-aware and thereby compensate for their lack of inductive bias.\nCombining this with architectural improvements, we show that transformers can\nbe efficiently trained for either plan-generation or heuristic-prediction. Our\nresults across multiple planning domains demonstrate that our symmetry-aware\ntraining effectively and efficiently addresses the limitations of PlanGPT.", "AI": {"tldr": "\u73b0\u6709transformer\u5728\u81ea\u52a8\u5316\u89c4\u5212\u9886\u57df\u5e94\u7528\u53d7\u9650\uff0c\u63d0\u51fa\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u4f7ftransformers\u5177\u6709\u5bf9\u79f0\u6027\u611f\u77e5\u80fd\u529b\uff0c\u7ed3\u5408\u67b6\u6784\u6539\u8fdb\uff0c\u6709\u6548\u89e3\u51b3\u4e86PlanGPT\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709transformer\u5728\u81ea\u52a8\u5316\u89c4\u5212\u9886\u57df\u5e94\u7528\u6709\u9650\uff0cPlanGPT\u96be\u4ee5\u4ece\u7b80\u5355\u89c4\u5212\u95ee\u9898\u63a8\u5e7f\u5230\u590d\u6742\u95ee\u9898\uff0c\u6839\u6e90\u5728\u4e8e\u95ee\u9898\u5bf9\u79f0\u6027\u5bfc\u81f4\u7684\u7ec4\u5408\u7206\u70b8\u3002", "method": "\u63d0\u51fa\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u4f7ftransformers\u5177\u6709\u5bf9\u79f0\u6027\u611f\u77e5\u80fd\u529b\uff0c\u7ed3\u5408\u67b6\u6784\u6539\u8fdb\u3002", "result": "\u5728\u591a\u4e2a\u89c4\u5212\u9886\u57df\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u79f0\u611f\u77e5\u8bad\u7ec3\u6709\u6548\u4e14\u9ad8\u6548\u5730\u89e3\u51b3\u4e86PlanGPT\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u67b6\u6784\u6539\u8fdb\uff0ctransformers\u53ef\u7528\u4e8e\u89c4\u5212\u751f\u6210\u6216\u542f\u53d1\u5f0f\u9884\u6d4b\uff0c\u5bf9\u79f0\u611f\u77e5\u8bad\u7ec3\u80fd\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.07114", "pdf": "https://arxiv.org/pdf/2508.07114", "abs": "https://arxiv.org/abs/2508.07114", "authors": ["Atakan Azakli", "Bernd Stelzer"], "title": "Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning", "categories": ["cs.LG", "hep-ex"], "comment": null, "summary": "In this work, we propose a new machine learning (ML) methodology to obtain\nmore precise predictions for some parameters of interest in a given hypotheses\ntesting problem. Our proposed method also allows ML models to have more\ndiscriminative power in cases where it is extremely challenging for\nstate-of-the-art classifiers to have any level of accurate predictions. This\nmethod can also allow us to systematically decrease the error from ML models in\ntheir predictions. In this paper, we provide a mathematical motivation why\nMultiple Instance Learning (MIL) would have more predictive power over their\nsingle-instance counterparts. We support our theoretical claims by analyzing\nthe behavior of the MIL models through their scaling behaviors with respect to\nthe number of instances on which the model makes predictions. As a concrete\napplication, we constrain Wilson coefficients of the Standard Model Effective\nField Theory (SMEFT) using kinematic information from subatomic particle\ncollision events at the Large Hadron Collider (LHC). We show that under certain\ncircumstances, it might be possible to extract the theoretical maximum Fisher\nInformation latent in a dataset.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u5047\u8bbe\u68c0\u9a8c\u95ee\u9898\u53c2\u6570\u9884\u6d4b\uff0c\u6709\u66f4\u5f3a\u5224\u522b\u529b\u548c\u964d\u8bef\u5dee\u80fd\u529b\uff0c\u4ee5MIL\u4e3a\u4f8b\u5e76\u5e94\u7528\u4e8eSMEFT\u7ea6\u675f\uff0c\u6216\u53ef\u63d0\u53d6\u7406\u8bba\u6700\u5927Fisher\u4fe1\u606f\u3002", "motivation": "\u83b7\u5f97\u7ed9\u5b9a\u5047\u8bbe\u68c0\u9a8c\u95ee\u9898\u4e2d\u611f\u5174\u8da3\u53c2\u6570\u66f4\u7cbe\u786e\u7684\u9884\u6d4b\uff0c\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5224\u522b\u529b\u548c\u964d\u4f4e\u9884\u6d4b\u8bef\u5dee\u3002", "method": "\u63d0\u51fa\u65b0\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5206\u6790MIL\u6a21\u578b\u5173\u4e8e\u5b9e\u4f8b\u6570\u91cf\u7684\u7f29\u653e\u884c\u4e3a\u6765\u652f\u6301\u7406\u8bba\u4e3b\u5f20\uff0c\u7528LHC\u5b50\u539f\u5b50\u7c92\u5b50\u78b0\u649e\u4e8b\u4ef6\u8fd0\u52a8\u5b66\u4fe1\u606f\u7ea6\u675fSMEFT\u7684Wilson\u7cfb\u6570\u3002", "result": "\u8868\u660e\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u63d0\u53d6\u6570\u636e\u96c6\u4e2d\u6f5c\u5728\u7684\u7406\u8bba\u6700\u5927Fisher\u4fe1\u606f\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u53c2\u6570\u9884\u6d4b\u7b49\u65b9\u9762\u6709\u6548\u679c\uff0cMIL\u6709\u6bd4\u5355\u5b9e\u4f8b\u6a21\u578b\u66f4\u5f3a\u7684\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2508.07790", "pdf": "https://arxiv.org/pdf/2508.07790", "abs": "https://arxiv.org/abs/2508.07790", "authors": ["Alessandro Abate", "Thom Badings", "Giuseppe De Giacomo", "Francesco Fabiano"], "title": "Best-Effort Policies for Robust Markov Decision Processes", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We study the common generalization of Markov decision processes (MDPs) with\nsets of transition probabilities, known as robust MDPs (RMDPs). A standard goal\nin RMDPs is to compute a policy that maximizes the expected return under an\nadversarial choice of the transition probabilities. If the uncertainty in the\nprobabilities is independent between the states, known as s-rectangularity,\nsuch optimal robust policies can be computed efficiently using robust value\niteration. However, there might still be multiple optimal robust policies,\nwhich, while equivalent with respect to the worst-case, reflect different\nexpected returns under non-adversarial choices of the transition probabilities.\nHence, we propose a refined policy selection criterion for RMDPs, drawing\ninspiration from the notions of dominance and best-effort in game theory.\nInstead of seeking a policy that only maximizes the worst-case expected return,\nwe additionally require the policy to achieve a maximal expected return under\ndifferent (i.e., not fully adversarial) transition probabilities. We call such\na policy an optimal robust best-effort (ORBE) policy. We prove that ORBE\npolicies always exist, characterize their structure, and present an algorithm\nto compute them with a small overhead compared to standard robust value\niteration. ORBE policies offer a principled tie-breaker among optimal robust\npolicies. Numerical experiments show the feasibility of our approach.", "AI": {"tldr": "\u7814\u7a76\u9c81\u68d2\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08RMDPs\uff09\uff0c\u63d0\u51fa\u6700\u4f18\u9c81\u68d2\u5c3d\u529b\u800c\u4e3a\uff08ORBE\uff09\u7b56\u7565\u9009\u62e9\u6807\u51c6\uff0c\u8bc1\u660e\u5176\u5b58\u5728\u6027\u3001\u523b\u753b\u7ed3\u6784\u5e76\u7ed9\u51fa\u8ba1\u7b97\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u53ef\u884c\u6027\u3002", "motivation": "RMDPs\u5b58\u5728\u591a\u4e2a\u6700\u4f18\u9c81\u68d2\u7b56\u7565\uff0c\u5728\u975e\u5bf9\u6297\u9009\u62e9\u4e0b\u671f\u671b\u56de\u62a5\u4e0d\u540c\uff0c\u9700\u66f4\u597d\u7684\u7b56\u7565\u9009\u62e9\u6807\u51c6\u3002", "method": "\u501f\u9274\u535a\u5f08\u8bba\u4e2d\u652f\u914d\u548c\u5c3d\u529b\u800c\u4e3a\u7684\u6982\u5ff5\uff0c\u63d0\u51faORBE\u7b56\u7565\u6807\u51c6\uff0c\u8bc1\u660e\u5b58\u5728\u6027\u3001\u523b\u753b\u7ed3\u6784\u5e76\u7ed9\u51fa\u8ba1\u7b97\u7b97\u6cd5\u3002", "result": "\u8bc1\u660eORBE\u7b56\u7565\u5b58\u5728\uff0c\u7ed9\u51fa\u8ba1\u7b97\u7b97\u6cd5\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u53ef\u884c\u3002", "conclusion": "ORBE\u7b56\u7565\u4e3a\u6700\u4f18\u9c81\u68d2\u7b56\u7565\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u9009\u62e9\u4f9d\u636e\u3002"}}
{"id": "2508.07117", "pdf": "https://arxiv.org/pdf/2508.07117", "abs": "https://arxiv.org/abs/2508.07117", "authors": ["Peyman Baghershahi", "Gregoire Fournier", "Pranav Nyati", "Sourav Medya"], "title": "From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context", "categories": ["cs.LG"], "comment": "18 pages, 3 figures, 8 tables", "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning over\nstructured data, including text-attributed graphs, which are common in domains\nsuch as citation networks, social platforms, and knowledge graphs. GNNs are not\ninherently interpretable and thus, many explanation methods have been proposed.\nHowever, existing explanation methods often struggle to generate interpretable,\nfine-grained rationales, especially when node attributes include rich natural\nlanguage. In this work, we introduce LOGIC, a lightweight, post-hoc framework\nthat uses large language models (LLMs) to generate faithful and interpretable\nexplanations for GNN predictions. LOGIC projects GNN node embeddings into the\nLLM embedding space and constructs hybrid prompts that interleave soft prompts\nwith textual inputs from the graph structure. This enables the LLM to reason\nabout GNN internal representations and produce natural language explanations\nalong with concise explanation subgraphs. Our experiments across four\nreal-world TAG datasets demonstrate that LOGIC achieves a favorable trade-off\nbetween fidelity and sparsity, while significantly improving human-centric\nmetrics such as insightfulness. LOGIC sets a new direction for LLM-based\nexplainability in graph learning by aligning GNN internals with human\nreasoning.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u4e8b\u540e\u6846\u67b6LOGIC\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3aGNN\u9884\u6d4b\u751f\u6210\u89e3\u91ca\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u56fe\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u6307\u660e\u65b0\u65b9\u5411\u3002", "motivation": "\u73b0\u6709GNN\u89e3\u91ca\u65b9\u6cd5\u96be\u751f\u6210\u7ec6\u7c92\u5ea6\u3001\u53ef\u89e3\u91ca\u7406\u7531\uff0c\u5c24\u5176\u662f\u8282\u70b9\u5c5e\u6027\u542b\u4e30\u5bcc\u81ea\u7136\u8bed\u8a00\u65f6\u3002", "method": "\u5c06GNN\u8282\u70b9\u5d4c\u5165\u6295\u5f71\u5230LLM\u5d4c\u5165\u7a7a\u95f4\uff0c\u6784\u5efa\u6df7\u5408\u63d0\u793a\uff0c\u4f7fLLM\u5bf9GNN\u5185\u90e8\u8868\u793a\u63a8\u7406\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754cTAG\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cLOGIC\u5728\u4fdd\u771f\u5ea6\u548c\u7a00\u758f\u6027\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u6307\u6807\u3002", "conclusion": "LOGIC\u901a\u8fc7\u5bf9\u9f50GNN\u5185\u90e8\u673a\u5236\u548c\u4eba\u7c7b\u63a8\u7406\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u56fe\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u8bbe\u5b9a\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.07834", "pdf": "https://arxiv.org/pdf/2508.07834", "abs": "https://arxiv.org/abs/2508.07834", "authors": ["Mubaris Nadeem", "Johannes Zenkert", "Lisa Bender", "Christian Weber", "Madjid Fathi"], "title": "KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations", "categories": ["cs.AI", "cs.ET"], "comment": "LWDA'23, KIRETT project, University of Siegen, Germany", "summary": "Over the years, the need for rescue operations throughout the world has\nincreased rapidly. Demographic changes and the resulting risk of injury or\nhealth disorders form the basis for emergency calls. In such scenarios, first\nresponders are in a rush to reach the patient in need, provide first aid, and\nsave lives. In these situations, they must be able to provide personalized and\noptimized healthcare in the shortest possible time and estimate the patients\ncondition with the help of freshly recorded vital data in an emergency\nsituation. However, in such a timedependent situation, first responders and\nmedical experts cannot fully grasp their knowledge and need assistance and\nrecommendation for further medical treatments. To achieve this, on the spot\ncalculated, evaluated, and processed knowledge must be made available to\nimprove treatments by first responders. The Knowledge Graph presented in this\narticle as a central knowledge representation provides first responders with an\ninnovative knowledge management that enables intelligent treatment\nrecommendations with an artificial intelligence-based pre-recognition of the\nsituation.", "AI": {"tldr": "\u5168\u7403\u6551\u63f4\u884c\u52a8\u9700\u6c42\u589e\u957f\uff0c\u6025\u6551\u4eba\u5458\u9700\u501f\u52a9\u65b0\u6280\u672f\u63d0\u4f9b\u533b\u7597\u5efa\u8bae\uff0c\u672c\u6587\u63d0\u51fa\u77e5\u8bc6\u56fe\u8c31\u5b9e\u73b0\u667a\u80fd\u6cbb\u7597\u63a8\u8350\u3002", "motivation": "\u6551\u63f4\u9700\u6c42\u589e\u52a0\uff0c\u6025\u6551\u4eba\u5458\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u9700\u501f\u52a9\u65b0\u77e5\u8bc6\u8f85\u52a9\u6cbb\u7597\u3002", "method": "\u63d0\u51fa\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u6838\u5fc3\u77e5\u8bc6\u8868\u793a\u3002", "result": "\u77e5\u8bc6\u56fe\u8c31\u4e3a\u6025\u6551\u4eba\u5458\u63d0\u4f9b\u521b\u65b0\u77e5\u8bc6\u7ba1\u7406\u3002", "conclusion": "\u77e5\u8bc6\u56fe\u8c31\u53ef\u5b9e\u73b0\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u60c5\u51b5\u9884\u8bc6\u522b\u548c\u667a\u80fd\u6cbb\u7597\u63a8\u8350\u3002"}}
{"id": "2508.07122", "pdf": "https://arxiv.org/pdf/2508.07122", "abs": "https://arxiv.org/abs/2508.07122", "authors": ["Zhihao Xue", "Yun Zi", "Nia Qi", "Ming Gong", "Yujun Zou"], "title": "Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "This paper proposes a spatiotemporal graph neural network-based performance\nprediction algorithm to address the challenge of forecasting performance\nfluctuations in distributed backend systems with multi-level service call\nstructures. The method abstracts system states at different time slices into a\nsequence of graph structures. It integrates the runtime features of service\nnodes with the invocation relationships among services to construct a unified\nspatiotemporal modeling framework. The model first applies a graph\nconvolutional network to extract high-order dependency information from the\nservice topology. Then it uses a gated recurrent network to capture the dynamic\nevolution of performance metrics over time. A time encoding mechanism is also\nintroduced to enhance the model's ability to represent non-stationary temporal\nsequences. The architecture is trained in an end-to-end manner, optimizing the\nmulti-layer nested structure to achieve high-precision regression of future\nservice performance metrics. To validate the effectiveness of the proposed\nmethod, a large-scale public cluster dataset is used. A series of\nmulti-dimensional experiments are designed, including variations in time\nwindows and concurrent load levels. These experiments comprehensively evaluate\nthe model's predictive performance and stability. The experimental results show\nthat the proposed model outperforms existing representative methods across key\nmetrics such as MAE, RMSE, and R2. It maintains strong robustness under varying\nload intensities and structural complexities. These results demonstrate the\nmodel's practical potential for backend service performance management tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6027\u80fd\u9884\u6d4b\u7b97\u6cd5\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u540e\u7aef\u7cfb\u7edf\u6027\u80fd\u6ce2\u52a8\u9884\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u5b9e\u7528\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u5177\u6709\u591a\u7ea7\u670d\u52a1\u8c03\u7528\u7ed3\u6784\u7684\u5206\u5e03\u5f0f\u540e\u7aef\u7cfb\u7edf\u6027\u80fd\u6ce2\u52a8\u9884\u6d4b\u7684\u6311\u6218\u3002", "method": "\u5c06\u4e0d\u540c\u65f6\u95f4\u7247\u7684\u7cfb\u7edf\u72b6\u6001\u62bd\u8c61\u4e3a\u56fe\u7ed3\u6784\u5e8f\u5217\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u65f6\u7a7a\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u56fe\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u62d3\u6251\u4fe1\u606f\uff0c\u95e8\u63a7\u5faa\u73af\u7f51\u7edc\u6355\u6349\u6027\u80fd\u6307\u6807\u52a8\u6001\u53d8\u5316\uff0c\u5f15\u5165\u65f6\u95f4\u7f16\u7801\u673a\u5236\uff0c\u7aef\u5230\u7aef\u8bad\u7ec3\u4f18\u5316\u591a\u5c42\u5d4c\u5957\u7ed3\u6784\u3002", "result": "\u4f7f\u7528\u5927\u89c4\u6a21\u516c\u5171\u96c6\u7fa4\u6570\u636e\u96c6\u5b9e\u9a8c\uff0c\u8be5\u6a21\u578b\u5728MAE\u3001RMSE\u548cR2\u7b49\u5173\u952e\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u4ee3\u8868\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u8d1f\u8f7d\u5f3a\u5ea6\u548c\u7ed3\u6784\u590d\u6742\u5ea6\u4e0b\u4fdd\u6301\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u540e\u7aef\u670d\u52a1\u6027\u80fd\u7ba1\u7406\u4efb\u52a1\u4e2d\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.07932", "pdf": "https://arxiv.org/pdf/2508.07932", "abs": "https://arxiv.org/abs/2508.07932", "authors": ["Yi Zhai", "Zhiqiang Wei", "Ruohan Li", "Keyu Pan", "Shuo Liu", "Lu Zhang", "Jianmin Ji", "Wuyang Zhang", "Yu Zhang", "Yanyong Zhang"], "title": "\\(X\\)-evolve: Solution space evolution powered by large language models", "categories": ["cs.AI"], "comment": null, "summary": "While combining large language models (LLMs) with evolutionary algorithms\n(EAs) shows promise for solving complex optimization problems, current\napproaches typically evolve individual solutions, often incurring high LLM call\ncosts. We introduce \\(X\\)-evolve, a paradigm-shifting method that instead\nevolves solution spaces \\(X\\) (sets of individual solutions) - subsets of the\noverall search space \\(S\\). In \\(X\\)-evolve, LLMs generate tunable programs\nwherein certain code snippets, designated as parameters, define a tunable\nsolution space. A score-based search algorithm then efficiently explores this\nparametrically defined space, guided by feedback from objective function\nscores. This strategy enables broader and more efficient exploration, which can\npotentially accelerate convergence at a much lower search cost, requiring up to\ntwo orders of magnitude fewer LLM calls than prior leading methods. We\ndemonstrate \\(X\\)-evolve's efficacy across three distinct hard optimization\nproblems. For the cap set problem, we discover a larger partial admissible set,\nestablishing a new tighter asymptotic lower bound for the cap set constant (\\(C\n\\ge 2.2203\\)). In information theory, we uncover a larger independent set for\nthe 15-vertex cycle graph (\\(\\mathcal{C}_{15}^{\\boxtimes 5}\\), size 19,946),\nthereby raising the known lower bound on its Shannon capacity. Furthermore, for\nthe NP-hard online bin packing problem, we generate heuristics that\nconsistently outperform standard strategies across established benchmarks. By\nevolving solution spaces, our method considerably improves search\neffectiveness, making it possible to tackle high-dimensional problems that were\npreviously computationally prohibitive.", "AI": {"tldr": "\u63d0\u51faX - evolve\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fdb\u5316\u89e3\u7a7a\u95f4\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\uff0c\u51cf\u5c11LLM\u8c03\u7528\u6210\u672c\uff0c\u5728\u4e09\u4e2a\u96be\u9898\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u8fdb\u5316\u7b97\u6cd5\u7ed3\u5408\u7684\u65b9\u6cd5\u8fdb\u5316\u5355\u4e2a\u89e3\uff0cLLM\u8c03\u7528\u6210\u672c\u9ad8\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5f15\u5165X - evolve\u65b9\u6cd5\uff0c\u8ba9LLM\u751f\u6210\u53ef\u8c03\u7a0b\u5e8f\u5b9a\u4e49\u89e3\u7a7a\u95f4\uff0c\u7528\u57fa\u4e8e\u5206\u6570\u7684\u641c\u7d22\u7b97\u6cd5\u63a2\u7d22\u3002", "result": "\u5728\u4e09\u4e2a\u96be\u9898\u4e0a\u9a8c\u8bc1\u6548\u679c\uff0c\u5982\u5728\u5e3d\u96c6\u95ee\u9898\u786e\u5b9a\u65b0\u4e0b\u754c\uff0c\u5728\u4fe1\u606f\u8bba\u63d0\u9ad8\u5df2\u77e5\u4e0b\u754c\uff0c\u5728\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u751f\u6210\u66f4\u4f18\u542f\u53d1\u5f0f\u7b56\u7565\u3002", "conclusion": "\u8fdb\u5316\u89e3\u7a7a\u95f4\u7684\u65b9\u6cd5\u63d0\u9ad8\u641c\u7d22\u6709\u6548\u6027\uff0c\u53ef\u89e3\u51b3\u9ad8\u7ef4\u96be\u9898\u3002"}}
{"id": "2508.07126", "pdf": "https://arxiv.org/pdf/2508.07126", "abs": "https://arxiv.org/abs/2508.07126", "authors": ["Zhengran Ji", "Boyuan Chen"], "title": "Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training reinforcement learning agents with human feedback is crucial when\ntask objectives are difficult to specify through dense reward functions. While\nprior methods rely on offline trajectory comparisons to elicit human\npreferences, such data is unavailable in online learning scenarios where agents\nmust adapt on the fly. Recent approaches address this by collecting real-time\nscalar feedback to guide agent behavior and train reward models for continued\nlearning after human feedback becomes unavailable. However, scalar feedback is\noften noisy and inconsistent, limiting the accuracy and generalization of\nlearned rewards. We propose Pref-GUIDE, a framework that transforms real-time\nscalar feedback into preference-based data to improve reward model learning for\ncontinual policy training. Pref-GUIDE Individual mitigates temporal\ninconsistency by comparing agent behaviors within short windows and filtering\nambiguous feedback. Pref-GUIDE Voting further enhances robustness by\naggregating reward models across a population of users to form consensus\npreferences. Across three challenging environments, Pref-GUIDE significantly\noutperforms scalar-feedback baselines, with the voting variant exceeding even\nexpert-designed dense rewards. By reframing scalar feedback as structured\npreferences with population feedback, Pref-GUIDE offers a scalable and\nprincipled approach for harnessing human input in online reinforcement\nlearning.", "AI": {"tldr": "\u63d0\u51faPref - GUIDE\u6846\u67b6\u5c06\u5b9e\u65f6\u6807\u91cf\u53cd\u9988\u8f6c\u5316\u4e3a\u57fa\u4e8e\u504f\u597d\u7684\u6570\u636e\uff0c\u7528\u4e8e\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u4e09\u4e2a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u6536\u96c6\u5b9e\u65f6\u6807\u91cf\u53cd\u9988\u6709\u566a\u58f0\u548c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u9650\u5236\u5956\u52b1\u6a21\u578b\u5b66\u4e60\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u6027\u3002", "method": "\u63d0\u51faPref - GUIDE\u6846\u67b6\uff0c\u5305\u62ecIndividual\u901a\u8fc7\u77ed\u7a97\u53e3\u6bd4\u8f83\u548c\u8fc7\u6ee4\u6a21\u7cca\u53cd\u9988\u51cf\u5c11\u65f6\u95f4\u4e0d\u4e00\u81f4\u6027\uff0cVoting\u901a\u8fc7\u805a\u5408\u7528\u6237\u5956\u52b1\u6a21\u578b\u5f62\u6210\u5171\u8bc6\u504f\u597d\u3002", "result": "\u5728\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u4e2d\uff0cPref - GUIDE\u663e\u8457\u4f18\u4e8e\u6807\u91cf\u53cd\u9988\u57fa\u7ebf\uff0c\u6295\u7968\u53d8\u4f53\u751a\u81f3\u8d85\u8fc7\u4e13\u5bb6\u8bbe\u8ba1\u7684\u5bc6\u96c6\u5956\u52b1\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6807\u91cf\u53cd\u9988\u91cd\u6784\u4e3a\u7ed3\u6784\u5316\u504f\u597d\u5e76\u7ed3\u5408\u7fa4\u4f53\u53cd\u9988\uff0cPref - GUIDE\u4e3a\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5229\u7528\u4eba\u7c7b\u8f93\u5165\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6709\u539f\u5219\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.07941", "pdf": "https://arxiv.org/pdf/2508.07941", "abs": "https://arxiv.org/abs/2508.07941", "authors": ["Olivier Poulet", "Fr\u00e9d\u00e9ric Guinand", "Fran\u00e7ois Gu\u00e9rin"], "title": "Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots", "categories": ["cs.AI"], "comment": null, "summary": "This article proposes a collision risk anticipation method based on\nshort-term prediction of the agents position. A Long Short-Term Memory (LSTM)\nmodel, trained on past trajectories, is used to estimate the next position of\neach robot. This prediction allows us to define an anticipated collision risk\nby dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent.\nThe approach is tested in a constrained environment, where two robots move\nwithout communication or identifiers. Despite a limited sampling frequency (1\nHz), the results show a significant decrease of the collisions number and a\nstability improvement. The proposed method, which is computationally\ninexpensive, appears particularly attractive for implementation on embedded\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u667a\u80fd\u4f53\u4f4d\u7f6e\u77ed\u671f\u9884\u6d4b\u7684\u78b0\u649e\u98ce\u9669\u9884\u4f30\u65b9\u6cd5\uff0c\u7528LSTM\u6a21\u578b\u9884\u6d4b\u4f4d\u7f6e\uff0c\u7ed3\u5408DQN\u52a8\u6001\u8c03\u6574\u5956\u52b1\uff0c\u6d4b\u8bd5\u6548\u679c\u597d\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5728\u53d7\u9650\u73af\u5883\u4e2d\u65e0\u901a\u4fe1\u548c\u6807\u8bc6\u65f6\u7684\u78b0\u649e\u95ee\u9898\u3002", "method": "\u7528\u8bad\u7ec3\u597d\u7684LSTM\u6a21\u578b\u9884\u6d4b\u673a\u5668\u4eba\u4e0b\u4e00\u4f4d\u7f6e\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574DQN\u667a\u80fd\u4f53\u5956\u52b1\u6765\u5b9a\u4e49\u9884\u671f\u78b0\u649e\u98ce\u9669\u3002", "result": "\u5728\u53d7\u9650\u73af\u5883\u6d4b\u8bd5\u4e2d\uff0c\u867d\u91c7\u6837\u9891\u7387\u4f4e\uff0c\u78b0\u649e\u6b21\u6570\u663e\u8457\u51cf\u5c11\uff0c\u7a33\u5b9a\u6027\u63d0\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u9002\u5408\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5b9e\u73b0\u3002"}}
{"id": "2508.07127", "pdf": "https://arxiv.org/pdf/2508.07127", "abs": "https://arxiv.org/abs/2508.07127", "authors": ["Niranjana Arun Menon", "Iqra Farooq", "Yulong Li", "Sara Ahmed", "Yutong Xie", "Muhammad Awais", "Imran Razzak"], "title": "How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Cardiovascular disease (CVD) prediction remains a tremendous challenge due to\nits multifactorial etiology and global burden of morbidity and mortality.\nDespite the growing availability of genomic and electrophysiological data,\nextracting biologically meaningful insights from such high-dimensional, noisy,\nand sparsely annotated datasets remains a non-trivial task. Recently, LLMs has\nbeen applied effectively to predict structural variations in biological\nsequences. In this work, we explore the potential of fine-tuned LLMs to predict\ncardiac diseases and SNPs potentially leading to CVD risk using genetic markers\nderived from high-throughput genomic profiling. We investigate the effect of\ngenetic patterns associated with cardiac conditions and evaluate how LLMs can\nlearn latent biological relationships from structured and semi-structured\ngenomic data obtained by mapping genetic aspects that are inherited from the\nfamily tree. By framing the problem as a Chain of Thought (CoT) reasoning task,\nthe models are prompted to generate disease labels and articulate informed\nclinical deductions across diverse patient profiles and phenotypes. The\nfindings highlight the promise of LLMs in contributing to early detection, risk\nassessment, and ultimately, the advancement of personalized medicine in cardiac\ncare.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5229\u7528\u9ad8\u901a\u91cf\u57fa\u56e0\u7ec4\u5206\u6790\u7684\u9057\u4f20\u6807\u8bb0\u9884\u6d4b\u5fc3\u810f\u75c5\u548c\u76f8\u5173\u5355\u6838\u82f7\u9178\u591a\u6001\u6027\uff08SNPs\uff09\u7684\u6f5c\u529b\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5728\u5fc3\u810f\u62a4\u7406\u4e2a\u6027\u5316\u533b\u7597\u65b9\u9762\u6709\u524d\u666f\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u9884\u6d4b\u56e0\u591a\u56e0\u7d20\u75c5\u56e0\u548c\u9ad8\u53d1\u75c5\u7387\u6b7b\u4ea1\u7387\u9762\u4e34\u6311\u6218\uff0c\u4ece\u9ad8\u7ef4\u3001\u5608\u6742\u4e14\u6ce8\u91ca\u7a00\u758f\u7684\u57fa\u56e0\u7ec4\u548c\u7535\u751f\u7406\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u4fe1\u606f\u662f\u96be\u9898\uff0c\u8fd1\u671fLLMs\u5728\u751f\u7269\u5e8f\u5217\u7ed3\u6784\u53d8\u5f02\u9884\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u56e0\u6b64\u63a2\u7d22\u5176\u5728\u5fc3\u810f\u75c5\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528\u9ad8\u901a\u91cf\u57fa\u56e0\u7ec4\u5206\u6790\u7684\u9057\u4f20\u6807\u8bb0\uff0c\u7814\u7a76\u4e0e\u5fc3\u810f\u72b6\u51b5\u76f8\u5173\u7684\u9057\u4f20\u6a21\u5f0f\uff0c\u5c06\u95ee\u9898\u6784\u5efa\u4e3a\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\u4efb\u52a1\uff0c\u8ba9\u6a21\u578b\u6839\u636e\u4e0d\u540c\u60a3\u8005\u7279\u5f81\u548c\u8868\u578b\u751f\u6210\u75be\u75c5\u6807\u7b7e\u5e76\u8fdb\u884c\u4e34\u5e8a\u63a8\u65ad\u3002", "result": "\u53d1\u73b0LLMs\u5728\u5fc3\u810f\u75c5\u65e9\u671f\u68c0\u6d4b\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u4e2a\u6027\u5316\u533b\u7597\u63a8\u8fdb\u65b9\u9762\u6709\u6f5c\u529b\u3002", "conclusion": "LLMs\u6709\u52a9\u4e8e\u5fc3\u810f\u62a4\u7406\u7684\u65e9\u671f\u68c0\u6d4b\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u4e2a\u6027\u5316\u533b\u7597\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.07950", "pdf": "https://arxiv.org/pdf/2508.07950", "abs": "https://arxiv.org/abs/2508.07950", "authors": ["Chen Shen", "Wanqing Zhang", "Kehan Li", "Erwen Huang", "Haitao Bi", "Aiying Fan", "Yiwen Shen", "Hongmei Dong", "Ji Zhang", "Yuming Shao", "Zengjia Liu", "Xinshe Liu", "Tao Li", "Chunxia Yan", "Shuanliang Fan", "Di Wu", "Jianhua Ma", "Bin Cong", "Zhenyuan Wang", "Chunfeng Lian"], "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA"], "comment": "18pages, 6 figures", "summary": "Forensic cause-of-death determination faces systemic challenges, including\nworkforce shortages and diagnostic variability, particularly in high-volume\nsystems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic\nAgenT), a multi-agent AI framework that automates and standardizes death\ninvestigations through a domain-adapted large language model. FEAT's\napplication-oriented architecture integrates: (i) a central Planner for task\ndecomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a\nMemory & Reflection module for iterative refinement, and (iv) a Global Solver\nfor conclusion synthesis. The system employs tool-augmented reasoning,\nhierarchical retrieval-augmented generation, forensic-tuned LLMs, and\nhuman-in-the-loop feedback to ensure legal and medical validity. In evaluations\nacross diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI\nsystems in both long-form autopsy analyses and concise cause-of-death\nconclusions. It demonstrated robust generalization across six geographic\nregions and achieved high expert concordance in blinded validations. Senior\npathologists validated FEAT's outputs as comparable to those of human experts,\nwith improved detection of subtle evidentiary nuances. To our knowledge, FEAT\nis the first LLM-based AI agent system dedicated to forensic medicine, offering\nscalable, consistent death certification while maintaining expert-level rigor.\nBy integrating AI efficiency with human oversight, this work could advance\nequitable access to reliable medicolegal services while addressing critical\ncapacity constraints in forensic systems.", "AI": {"tldr": "\u5f15\u5165\u591a\u667a\u80fd\u4f53AI\u6846\u67b6FEAT\u7528\u4e8e\u6cd5\u533b\u6b7b\u56e0\u9274\u5b9a\uff0c\u5728\u591a\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\uff0c\u517c\u5177\u6548\u7387\u4e0e\u4e25\u8c28\u6027\uff0c\u6709\u671b\u6539\u5584\u6cd5\u533b\u7cfb\u7edf\u670d\u52a1\u3002", "motivation": "\u6cd5\u533b\u6b7b\u56e0\u9274\u5b9a\u9762\u4e34\u4eba\u5458\u77ed\u7f3a\u548c\u8bca\u65ad\u5dee\u5f02\u7b49\u7cfb\u7edf\u6027\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u4e2d\u56fd\u8fd9\u6837\u7684\u9ad8\u6d41\u91cf\u6cd5\u533b\u7cfb\u7edf\u4e2d\u3002", "method": "\u5f15\u5165FEAT\u6846\u67b6\uff0c\u5176\u67b6\u6784\u96c6\u6210\u4e2d\u592e\u89c4\u5212\u5668\u3001\u4e13\u4e1a\u672c\u5730\u6c42\u89e3\u5668\u3001\u8bb0\u5fc6\u4e0e\u53cd\u601d\u6a21\u5757\u548c\u5168\u5c40\u6c42\u89e3\u5668\uff0c\u91c7\u7528\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u3001\u5206\u5c42\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u6cd5\u533b\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4eba\u5728\u73af\u53cd\u9988\u3002", "result": "\u5728\u4e0d\u540c\u4e2d\u56fd\u6848\u4f8b\u961f\u5217\u8bc4\u4f30\u4e2d\uff0cFEAT\u5728\u5c38\u68c0\u5206\u6790\u548c\u6b7b\u56e0\u7ed3\u8bba\u65b9\u9762\u4f18\u4e8e\u73b0\u6709AI\u7cfb\u7edf\uff0c\u5728\u516d\u4e2a\u5730\u7406\u533a\u57df\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u76f2\u6d4b\u4e2d\u4e0e\u4e13\u5bb6\u610f\u89c1\u9ad8\u5ea6\u4e00\u81f4\uff0c\u80fd\u68c0\u6d4b\u7ec6\u5fae\u8bc1\u636e\u5dee\u5f02\u3002", "conclusion": "FEAT\u662f\u9996\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cd5\u533bAI\u7cfb\u7edf\uff0c\u7ed3\u5408AI\u6548\u7387\u548c\u4eba\u5de5\u76d1\u7763\uff0c\u53ef\u4fc3\u8fdb\u516c\u5e73\u83b7\u5f97\u53ef\u9760\u6cd5\u533b\u670d\u52a1\uff0c\u89e3\u51b3\u6cd5\u533b\u7cfb\u7edf\u7684\u80fd\u529b\u9650\u5236\u95ee\u9898\u3002"}}
{"id": "2508.07134", "pdf": "https://arxiv.org/pdf/2508.07134", "abs": "https://arxiv.org/abs/2508.07134", "authors": ["Lu Chenggang"], "title": "A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs", "categories": ["cs.LG", "cs.DM", "15A23, 90C26, 62H25", "I.2.6; I.5.3"], "comment": "10 pages, 2 figures, under review in [SIAM Journal of Optimization]", "summary": "Semi-Nonnegative Matrix Factorization (semi-NMF) extends classical\nNonnegative Matrix Factorization (NMF) by allowing the basis matrix to contain\nboth positive and negative entries, making it suitable for decomposing data\nwith mixed signs. However, most existing semi-NMF algorithms are iterative,\nnon-convex, and prone to local minima. In this paper, we propose a novel method\nthat yields a globally optimal solution to the semi-NMF problem under the\nFrobenius norm, through an orthogonal decomposition derived from the scatter\nmatrix of the input data. We rigorously prove that our solution attains the\nglobal minimum of the reconstruction error. Furthermore, we demonstrate that\nwhen the input matrix is nonnegative, our method often achieves lower\nreconstruction error than standard NMF algorithms, although unfortunately the\nbasis matrix may not satisfy nonnegativity. In particular, in low-rank cases\nsuch as rank 1 or 2, our solution reduces exactly to a nonnegative\nfactorization, recovering the NMF structure. We validate our approach through\nexperiments on both synthetic data and the UCI Wine dataset, showing that our\nmethod consistently outperforms existing NMF and semi-NMF methods in terms of\nreconstruction accuracy. These results confirm that our globally optimal,\nnon-iterative formulation offers both theoretical guarantees and empirical\nadvantages, providing a new perspective on matrix factorization in optimization\nand data analysis.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u65b9\u6cd5\u89e3\u51b3\u534a\u975e\u8d1f\u77e9\u9635\u5206\u89e3\uff08semi - NMF\uff09\u95ee\u9898\uff0c\u6709\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709semi - NMF\u7b97\u6cd5\u591a\u4e3a\u8fed\u4ee3\u3001\u975e\u51f8\u4e14\u6613\u9677\u5165\u5c40\u90e8\u6781\u5c0f\u503c\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u901a\u8fc7\u8f93\u5165\u6570\u636e\u6563\u5ea6\u77e9\u9635\u7684\u6b63\u4ea4\u5206\u89e3\uff0c\u5f97\u5230Frobenius\u8303\u6570\u4e0bsemi - NMF\u95ee\u9898\u7684\u5168\u5c40\u6700\u4f18\u89e3\u3002", "result": "\u8bc1\u660e\u89e3\u80fd\u8fbe\u5230\u91cd\u6784\u8bef\u5dee\u5168\u5c40\u6700\u5c0f\uff1b\u8f93\u5165\u77e9\u9635\u975e\u8d1f\u65f6\uff0c\u5e38\u6bd4\u6807\u51c6NMF\u7b97\u6cd5\u91cd\u6784\u8bef\u5dee\u4f4e\uff1b\u4f4e\u79e9\u60c5\u51b5\u80fd\u5f97\u5230\u975e\u8d1f\u5206\u89e3\uff1b\u5b9e\u9a8c\u663e\u793a\u5728\u91cd\u6784\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709NMF\u548csemi - NMF\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5168\u5c40\u6700\u4f18\u3001\u975e\u8fed\u4ee3\u516c\u5f0f\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8bc1\u4f18\u52bf\uff0c\u4e3a\u77e9\u9635\u5206\u89e3\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.08001", "pdf": "https://arxiv.org/pdf/2508.08001", "abs": "https://arxiv.org/abs/2508.08001", "authors": ["Rui Yao", "Qi Chai", "Jinhai Yao", "Siyuan Li", "Junhao Chen", "Qi Zhang", "Hao Wang"], "title": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths", "categories": ["cs.AI"], "comment": "Rui Yao, Qi Chai, and Jinhai Yao contributed equally to this work.\n  Corresponding authors: Qi Zhang (zhang.qi@sjtu.edu.cn) and Hao Wang\n  (haowang@hkust-gz.edu.cn)", "summary": "\"Fedspeak\", the stylized and often nuanced language used by the U.S. Federal\nReserve, encodes implicit policy signals and strategic stances. The Federal\nOpen Market Committee strategically employs Fedspeak as a communication tool to\nshape market expectations and influence both domestic and global economic\nconditions. As such, automatically parsing and interpreting Fedspeak presents a\nhigh-impact challenge, with significant implications for financial forecasting,\nalgorithmic trading, and data-driven policy analysis. In this paper, we propose\nan LLM-based, uncertainty-aware framework for deciphering Fedspeak and\nclassifying its underlying monetary policy stance. Technically, to enrich the\nsemantic and contextual representation of Fedspeak texts, we incorporate\ndomain-specific reasoning grounded in the monetary policy transmission\nmechanism. We further introduce a dynamic uncertainty decoding module to assess\nthe confidence of model predictions, thereby enhancing both classification\naccuracy and model reliability. Experimental results demonstrate that our\nframework achieves state-of-the-art performance on the policy stance analysis\ntask. Moreover, statistical analysis reveals a significant positive correlation\nbetween perceptual uncertainty and model error rates, validating the\neffectiveness of perceptual uncertainty as a diagnostic signal.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u3001\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684\u6846\u67b6\u89e3\u8bfbFedspeak\u5e76\u5206\u7c7b\u8d27\u5e01\u653f\u7b56\u7acb\u573a\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f73\uff0c\u9a8c\u8bc1\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u6709\u6548\u6027\u3002", "motivation": "\u81ea\u52a8\u89e3\u6790\u548c\u89e3\u8bfbFedspeak\u5bf9\u91d1\u878d\u9884\u6d4b\u3001\u7b97\u6cd5\u4ea4\u6613\u548c\u653f\u7b56\u5206\u6790\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u5b58\u5728\u9ad8\u5f71\u54cd\u6311\u6218\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u3001\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u8d27\u5e01\u653f\u7b56\u4f20\u5bfc\u673a\u5236\u7684\u9886\u57df\u7279\u5b9a\u63a8\u7406\uff0c\u5f15\u5165\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u89e3\u7801\u6a21\u5757\u3002", "result": "\u6846\u67b6\u5728\u653f\u7b56\u7acb\u573a\u5206\u6790\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0e\u6a21\u578b\u9519\u8bef\u7387\u5448\u663e\u8457\u6b63\u76f8\u5173\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\uff0c\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u53ef\u4f5c\u4e3a\u8bca\u65ad\u4fe1\u53f7\u3002"}}
{"id": "2508.07137", "pdf": "https://arxiv.org/pdf/2508.07137", "abs": "https://arxiv.org/abs/2508.07137", "authors": ["Yuandong Tan"], "title": "A Stable and Principled Loss Function for Direct Language Model Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The alignment of large language models (LLMs) with human preferences is\ncommonly achieved through Reinforcement Learning from Human Feedback (RLHF).\nDirect Preference Optimization (DPO) simplified this paradigm by establishing a\ndirect mapping between the optimal policy and a reward function, eliminating\nthe need for an explicit reward model. However, we argue that the DPO loss\nfunction is theoretically misaligned with its own derivation, as it promotes\nthe indefinite maximization of a logits difference, which can lead to training\ninstability and reward hacking. In this paper, we propose a novel loss function\nderived directly from the RLHF optimality condition. Our proposed loss targets\na specific, finite value for the logits difference, which is dictated by the\nunderlying reward, rather than its maximization. We provide a theoretical\nanalysis, including a gradient-based comparison, to demonstrate that our method\navoids the large gradients that plague DPO when the probability of dispreferred\nresponses approaches zero. This inherent stability prevents reward hacking and\nleads to more effective alignment. We validate our approach by fine-tuning a\nQwen2.5-7B model, showing significant win-rate improvements over a standard DPO\nbaseline and achieving competitive performance against larger models like\nLlama-3.1-8B.", "AI": {"tldr": "\u672c\u6587\u6307\u51faDPO\u635f\u5931\u51fd\u6570\u7406\u8bba\u4e0a\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u7406\u8bba\u5206\u6790\u663e\u793a\u5176\u7a33\u5b9a\u6027\u66f4\u597d\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5728\u5fae\u8c03\u6a21\u578b\u65f6\u6bd4DPO\u57fa\u7ebf\u6709\u663e\u8457\u80dc\u7387\u63d0\u5347\u3002", "motivation": "DPO\u635f\u5931\u51fd\u6570\u7406\u8bba\u4e0a\u4e0e\u81ea\u8eab\u63a8\u5bfc\u4e0d\u4e00\u81f4\uff0c\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u5956\u52b1\u4f5c\u5f0a\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u4eceRLHF\u6700\u4f18\u6761\u4ef6\u76f4\u63a5\u63a8\u5bfc\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u76ee\u6807\u662f\u8ba9logits\u5dee\u5f02\u8fbe\u5230\u7279\u5b9a\u6709\u9650\u503c\uff0c\u8fdb\u884c\u57fa\u4e8e\u68af\u5ea6\u7684\u7406\u8bba\u5206\u6790\u3002", "result": "\u5bf9Qwen2.5 - 7B\u6a21\u578b\u5fae\u8c03\uff0c\u76f8\u6bd4\u6807\u51c6DPO\u57fa\u7ebf\u6709\u663e\u8457\u80dc\u7387\u63d0\u5347\uff0c\u4e0eLlama - 3.1 - 8B\u7b49\u66f4\u5927\u6a21\u578b\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u635f\u5931\u51fd\u6570\u907f\u514d\u4e86DPO\u7684\u95ee\u9898\uff0c\u5177\u6709\u7a33\u5b9a\u6027\uff0c\u80fd\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u5bf9\u9f50\u3002"}}
{"id": "2508.08007", "pdf": "https://arxiv.org/pdf/2508.08007", "abs": "https://arxiv.org/abs/2508.08007", "authors": ["Maurice Funk", "Marvin Grosser", "Carsten Lutz"], "title": "Fitting Description Logic Ontologies to ABox and Query Examples", "categories": ["cs.AI", "Computing methodologies~Description logics, Computing\n  methodologies~Ontology engineering"], "comment": "Submitted to the 22nd International Conference on Principles of\n  Knowledge Representation and Reasoning (KR2025), 23 pages", "summary": "We study a fitting problem inspired by ontology-mediated querying: given a\ncollection\n  of positive and negative examples of\n  the form $(\\mathcal{A},q)$ with\n  $\\mathcal{A}$ an ABox and $q$ a Boolean query, we seek\n  an ontology $\\mathcal{O}$ that satisfies $\\mathcal{A} \\cup \\mathcal{O} \\vDash\nq$ for all positive examples and $\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$ for\nall negative examples.\n  We consider the description logics $\\mathcal{ALC}$ and $\\mathcal{ALCI}$ as\nontology languages and\n  a range of query languages that\n  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof\n(UCQs).\n  For all of the resulting fitting problems,\n  we provide\n  effective characterizations and determine the computational complexity\n  of deciding whether a fitting ontology exists. This problem turns out to be\n${\\small CO}NP$ for AQs and full CQs\n  and $2E{\\small XP}T{\\small IME}$-complete for CQs and UCQs.\n  These results hold for both $\\mathcal{ALC}$ and $\\mathcal{ALCI}$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.08053", "pdf": "https://arxiv.org/pdf/2508.08053", "abs": "https://arxiv.org/abs/2508.08053", "authors": ["Runchuan Zhu", "Bowen Jiang", "Lingrui Mei", "Fangkai Yang", "Lu Wang", "Haoxiang Gao", "Fengshuo Bai", "Pu Zhao", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "AdaptFlow: Adaptive Workflow Optimization via Meta-Learning", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin agentic workflows, which are structured sequences of LLM invocations\nintended to solve complex tasks. However, existing approaches often rely on\nstatic templates or manually designed workflows, which limit adaptability to\ndiverse tasks and hinder scalability. We propose AdaptFlow, a natural\nlanguage-based meta-learning framework inspired by model-agnostic meta-learning\n(MAML). AdaptFlow learns a generalizable workflow initialization that enables\nrapid subtask-level adaptation. It employs a bi-level optimization scheme: the\ninner loop refines the workflow for a specific subtask using LLM-generated\nfeedback, while the outer loop updates the shared initialization to perform\nwell across tasks. This setup allows AdaptFlow to generalize effectively to\nunseen tasks by adapting the initialized workflow through language-guided\nmodifications. Evaluated across question answering, code generation, and\nmathematical reasoning benchmarks, AdaptFlow consistently outperforms both\nmanually crafted and automatically searched baselines, achieving\nstate-of-the-art results with strong generalization across tasks and models.\nThe source code and data are available at\nhttps://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.", "AI": {"tldr": "\u63d0\u51faAdaptFlow\u6846\u67b6\u89e3\u51b3LLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u6a21\u677f\u6216\u624b\u52a8\u8bbe\u8ba1\uff0c\u9650\u5236\u4e86\u5bf9\u4e0d\u540c\u4efb\u52a1\u7684\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u5143\u5b66\u4e60\u6846\u67b6AdaptFlow\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u65b9\u6848\uff0c\u5185\u5faa\u73af\u7528LLM\u53cd\u9988\u4f18\u5316\u7279\u5b9a\u5b50\u4efb\u52a1\u5de5\u4f5c\u6d41\uff0c\u5916\u5faa\u73af\u66f4\u65b0\u5171\u4eab\u521d\u59cb\u5316\u3002", "result": "\u5728\u95ee\u7b54\u3001\u4ee3\u7801\u751f\u6210\u548c\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAdaptFlow\u59cb\u7ec8\u4f18\u4e8e\u624b\u52a8\u548c\u81ea\u52a8\u641c\u7d22\u7684\u57fa\u7ebf\uff0c\u53d6\u5f97\u4e86\u8de8\u4efb\u52a1\u548c\u6a21\u578b\u7684\u6700\u4f73\u7ed3\u679c\u3002", "conclusion": "AdaptFlow\u80fd\u901a\u8fc7\u8bed\u8a00\u5f15\u5bfc\u4fee\u6539\u521d\u59cb\u5316\u5de5\u4f5c\u6d41\uff0c\u6709\u6548\u6cdb\u5316\u5230\u672a\u89c1\u4efb\u52a1\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.07142", "pdf": "https://arxiv.org/pdf/2508.07142", "abs": "https://arxiv.org/abs/2508.07142", "authors": ["Vincent-Daniel Yun"], "title": "SGD Convergence under Stepsize Shrinkage in Low-Precision Training", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NA", "math.IT", "math.NA"], "comment": null, "summary": "Low-precision training has become essential for reducing the computational\nand memory costs of large-scale deep learning. However, quantization of\ngradients introduces both magnitude shrinkage and additive noise, which can\nalter the convergence behavior of stochastic gradient descent (SGD). In this\nwork, we study the convergence of SGD under a gradient shrinkage model, where\neach stochastic gradient is scaled by a factor $q_k \\in (0,1]$ and perturbed by\nzero-mean quantization noise. We show that this shrinkage is equivalent to\nreplacing the nominal stepsize $\\mu_k$ with an effective stepsize $\\mu_k q_k$,\nwhich slows convergence when $q_{\\min} < 1$. Under standard smoothness and\nbounded-variance assumptions, we prove that low-precision SGD still converges,\nbut at a reduced rate determined by $q_{\\min}$, and with an increased\nasymptotic error floor due to quantization noise. We theoretically analyze how\nreduced numerical precision slows down training by modeling it as gradient\nshrinkage in the standard SGD convergence framework.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.08075", "pdf": "https://arxiv.org/pdf/2508.08075", "abs": "https://arxiv.org/abs/2508.08075", "authors": ["Meishen He", "Wenjun Ma", "Jiao Wang", "Huijun Yue", "Xiaoma Fan"], "title": "FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence", "categories": ["cs.AI"], "comment": null, "summary": "The Dempster-Shafer theory of evidence has been widely applied in the field\nof information fusion under uncertainty. Most existing research focuses on\ncombining evidence within the same frame of discernment. However, in real-world\nscenarios, trained algorithms or data often originate from different regions or\norganizations, where data silos are prevalent. As a result, using different\ndata sources or models to generate basic probability assignments may lead to\nheterogeneous frames, for which traditional fusion methods often yield\nunsatisfactory results. To address this challenge, this study proposes an\nopen-world information fusion method, termed Full Negation Belief\nTransformation (FNBT), based on the Dempster-Shafer theory. More specially, a\ncriterion is introduced to determine whether a given fusion task belongs to the\nopen-world setting. Then, by extending the frames, the method can accommodate\nelements from heterogeneous frames. Finally, a full negation mechanism is\nemployed to transform the mass functions, so that existing combination rules\ncan be applied to the transformed mass functions for such information fusion.\nTheoretically, the proposed method satisfies three desirable properties, which\nare formally proven: mass function invariance, heritability, and essential\nconflict elimination. Empirically, FNBT demonstrates superior performance in\npattern classification tasks on real-world datasets and successfully resolves\nZadeh's counterexample, thereby validating its practical effectiveness.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u57fa\u4e8eDempster - Shafer\u7406\u8bba\u7684\u5f00\u653e\u4e16\u754c\u4fe1\u606f\u878d\u5408\u65b9\u6cd5FNBT\uff0c\u7406\u8bba\u4e0a\u6ee1\u8db3\u4e09\u4e2a\u5c5e\u6027\uff0c\u5b9e\u8bc1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u540c\u4e00\u8bc6\u522b\u6846\u67b6\u5185\u7684\u8bc1\u636e\u7ec4\u5408\uff0c\u4f46\u73b0\u5b9e\u4e2d\u4e0d\u540c\u6570\u636e\u6e90\u6216\u6a21\u578b\u751f\u6210\u7684\u57fa\u672c\u6982\u7387\u5206\u914d\u53ef\u80fd\u5bfc\u81f4\u5f02\u6784\u6846\u67b6\uff0c\u4f20\u7edf\u878d\u5408\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u6807\u51c6\u5224\u65ad\u878d\u5408\u4efb\u52a1\u662f\u5426\u5c5e\u4e8e\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\uff0c\u6269\u5c55\u6846\u67b6\u4ee5\u5bb9\u7eb3\u5f02\u6784\u6846\u67b6\u5143\u7d20\uff0c\u91c7\u7528\u5168\u5426\u5b9a\u673a\u5236\u8f6c\u6362\u8d28\u91cf\u51fd\u6570\u3002", "result": "\u7406\u8bba\u4e0a\u6ee1\u8db3\u8d28\u91cf\u51fd\u6570\u4e0d\u53d8\u6027\u3001\u9057\u4f20\u6027\u548c\u57fa\u672c\u51b2\u7a81\u6d88\u9664\u4e09\u4e2a\u5c5e\u6027\uff1b\u5b9e\u8bc1\u4e2d\u5728\u6a21\u5f0f\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u89e3\u51b3\u4e86Zadeh\u53cd\u4f8b\u3002", "conclusion": "\u63d0\u51fa\u7684FNBT\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u90fd\u6709\u6548\uff0c\u80fd\u89e3\u51b3\u5f02\u6784\u6846\u67b6\u4e0b\u7684\u4fe1\u606f\u878d\u5408\u95ee\u9898\u3002"}}
{"id": "2508.07208", "pdf": "https://arxiv.org/pdf/2508.07208", "abs": "https://arxiv.org/abs/2508.07208", "authors": ["Chanakya Ekbote", "Marco Bondaschi", "Nived Rajaraman", "Jason D. Lee", "Michael Gastpar", "Ashok Vardhan Makkuva", "Paul Pu Liang"], "title": "What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In-context learning (ICL) is a hallmark capability of transformers, through\nwhich trained models learn to adapt to new tasks by leveraging information from\nthe input context. Prior work has shown that ICL emerges in transformers due to\nthe presence of special circuits called induction heads. Given the equivalence\nbetween induction heads and conditional k-grams, a recent line of work modeling\nsequential inputs as Markov processes has revealed the fundamental impact of\nmodel depth on its ICL capabilities: while a two-layer transformer can\nefficiently represent a conditional 1-gram model, its single-layer counterpart\ncannot solve the task unless it is exponentially large. However, for higher\norder Markov sources, the best known constructions require at least three\nlayers (each with a single attention head) - leaving open the question: can a\ntwo-layer single-head transformer represent any kth-order Markov process? In\nthis paper, we precisely address this and theoretically show that a two-layer\ntransformer with one head per layer can indeed represent any conditional\nk-gram. Thus, our result provides the tightest known characterization of the\ninterplay between transformer depth and Markov order for ICL. Building on this,\nwe further analyze the learning dynamics of our two-layer construction,\nfocusing on a simplified variant for first-order Markov chains, illustrating\nhow effective in-context representations emerge during training. Together,\nthese results deepen our current understanding of transformer-based ICL and\nillustrate how even shallow architectures can surprisingly exhibit strong ICL\ncapabilities on structured sequence modeling tasks.", "AI": {"tldr": "\u672c\u6587\u7406\u8bba\u8bc1\u660e\u4e24\u5c42\u6bcf\u5c42\u5355\u5934\u7684Transformer\u53ef\u8868\u793a\u4efb\u4f55\u6761\u4ef6k\u5143\u8bed\u6cd5\uff0c\u5206\u6790\u5176\u5b66\u4e60\u52a8\u6001\uff0c\u52a0\u6df1\u5bf9\u57fa\u4e8eTransformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u7406\u89e3\u3002", "motivation": "\u6b64\u524d\u5de5\u4f5c\u63ed\u793a\u6a21\u578b\u6df1\u5ea6\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u6709\u5f71\u54cd\uff0c\u4f46\u5bf9\u4e8e\u9ad8\u9636\u9a6c\u5c14\u53ef\u592b\u6e90\uff0c\u6700\u4f73\u6784\u9020\u81f3\u5c11\u9700\u4e09\u5c42\uff0c\u56e0\u6b64\u63a2\u7a76\u4e24\u5c42\u5355\u5934Transformer\u80fd\u5426\u8868\u793a\u4efb\u610fk\u9636\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u3002", "method": "\u8fdb\u884c\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e24\u5c42\u6bcf\u5c42\u5355\u5934\u7684Transformer\u53ef\u8868\u793a\u4efb\u4f55\u6761\u4ef6k\u5143\u8bed\u6cd5\uff0c\u805a\u7126\u4e00\u9636\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u7b80\u5316\u53d8\u4f53\u5206\u6790\u5b66\u4e60\u52a8\u6001\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e24\u5c42\u6bcf\u5c42\u5355\u5934\u7684Transformer\u53ef\u8868\u793a\u4efb\u4f55\u6761\u4ef6k\u5143\u8bed\u6cd5\uff0c\u5206\u6790\u4e86\u5176\u5b66\u4e60\u52a8\u6001\u3002", "conclusion": "\u7814\u7a76\u52a0\u6df1\u4e86\u5bf9\u57fa\u4e8eTransformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u7406\u89e3\uff0c\u8868\u660e\u6d45\u5c42\u67b6\u6784\u5728\u7ed3\u6784\u5316\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u4e2d\u4e5f\u80fd\u6709\u5f3a\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002"}}
{"id": "2508.08115", "pdf": "https://arxiv.org/pdf/2508.08115", "abs": "https://arxiv.org/abs/2508.08115", "authors": ["Pranav Pushkar Mishra", "Mohammad Arvan", "Mohan Zalake"], "title": "TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork", "categories": ["cs.AI"], "comment": "10 pages, 1 figure, 6 tables(2 in main, 4 in appendix)", "summary": "We present TeamMedAgents, a novel multi-agent approach that systematically\nintegrates evidence-based teamwork components from human-human collaboration\ninto medical decision-making with large language models (LLMs). Our approach\nvalidates an organizational psychology teamwork model from human collaboration\nto computational multi-agent medical systems by operationalizing six core\nteamwork components derived from Salas et al.'s \"Big Five\" model: team\nleadership, mutual performance monitoring, team orientation, shared mental\nmodels, closed-loop communication, and mutual trust. We implement and evaluate\nthese components as modular, configurable mechanisms within an adaptive\ncollaboration architecture while assessing the effect of the number of agents\ninvolved based on the task's requirements and domain. Systematic evaluation of\ncomputational implementations of teamwork behaviors across eight medical\nbenchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets,\nPath-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8\nevaluated datasets. Controlled ablation studies conducted on 50 questions per\nconfiguration across 3 independent runs provide mechanistic insights into\nindividual component contributions, revealing optimal teamwork configurations\nthat vary by reasoning task complexity and domain-specific requirements. Our\nablation analyses reveal dataset-specific optimal teamwork configurations,\nindicating that different medical reasoning modalities benefit from distinct\ncollaborative patterns. TeamMedAgents represents an advancement in\ncollaborative AI by providing a systematic translation of established teamwork\ntheories from human collaboration into agentic collaboration, establishing a\nfoundation for evidence-based multi-agent system design in critical\ndecision-making domains.", "AI": {"tldr": "\u63d0\u51faTeamMedAgents\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u5c06\u4eba\u7c7b\u534f\u4f5c\u56e2\u961f\u7ec4\u4ef6\u96c6\u6210\u5230\u533b\u5b66\u51b3\u7b56\uff0c\u5728\u591a\u4e2a\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u63ed\u793a\u4e0d\u540c\u6570\u636e\u96c6\u7684\u6700\u4f18\u56e2\u961f\u914d\u7f6e\u3002", "motivation": "\u5c06\u4eba\u7c7b\u534f\u4f5c\u4e2d\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u56e2\u961f\u5408\u4f5c\u7ec4\u4ef6\u7cfb\u7edf\u5730\u96c6\u6210\u5230\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u533b\u5b66\u51b3\u7b56\u4e2d\uff0c\u9a8c\u8bc1\u56e2\u961f\u5408\u4f5c\u6a21\u578b\u5728\u8ba1\u7b97\u591a\u667a\u80fd\u4f53\u533b\u7597\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u57fa\u4e8eSalas\u7b49\u4eba\u7684\u201cBig Five\u201d\u6a21\u578b\u7684\u516d\u4e2a\u6838\u5fc3\u56e2\u961f\u5408\u4f5c\u7ec4\u4ef6\uff0c\u5728\u81ea\u9002\u5e94\u534f\u4f5c\u67b6\u6784\u4e2d\u5b9e\u73b0\u5e76\u8bc4\u4f30\u8fd9\u4e9b\u7ec4\u4ef6\uff0c\u8bc4\u4f30\u4e0d\u540c\u6570\u91cf\u667a\u80fd\u4f53\u7684\u5f71\u54cd\u3002", "result": "\u57288\u4e2a\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76847\u4e2a\u6570\u636e\u96c6\u4e0a\u6709\u4e00\u81f4\u6539\u8fdb\uff0c\u6d88\u878d\u7814\u7a76\u63ed\u793a\u4e86\u4e0d\u540c\u63a8\u7406\u4efb\u52a1\u590d\u6742\u6027\u548c\u7279\u5b9a\u9886\u57df\u8981\u6c42\u4e0b\u7684\u6700\u4f18\u56e2\u961f\u914d\u7f6e\u3002", "conclusion": "TeamMedAgents\u662f\u534f\u4f5cAI\u7684\u8fdb\u6b65\uff0c\u4e3a\u5173\u952e\u51b3\u7b56\u9886\u57df\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.07220", "pdf": "https://arxiv.org/pdf/2508.07220", "abs": "https://arxiv.org/abs/2508.07220", "authors": ["Jian Xu", "Yican Liu", "Qibin Zhao", "John Paisley", "Delu Zeng"], "title": "Neural Bridge Processes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning stochastic functions from partially observed context-target pairs is\na fundamental problem in probabilistic modeling. Traditional models like\nGaussian Processes (GPs) face scalability issues with large datasets and assume\nGaussianity, limiting their applicability. While Neural Processes (NPs) offer\nmore flexibility, they struggle with capturing complex, multi-modal target\ndistributions. Neural Diffusion Processes (NDPs) enhance expressivity through a\nlearned diffusion process but rely solely on conditional signals in the\ndenoising network, resulting in weak input coupling from an unconditional\nforward process and semantic mismatch at the diffusion endpoint. In this work,\nwe propose Neural Bridge Processes (NBPs), a novel method for modeling\nstochastic functions where inputs x act as dynamic anchors for the entire\ndiffusion trajectory. By reformulating the forward kernel to explicitly depend\non x, NBP enforces a constrained path that strictly terminates at the\nsupervised target. This approach not only provides stronger gradient signals\nbut also guarantees endpoint coherence. We validate NBPs on synthetic data, EEG\nsignal regression and image regression tasks, achieving substantial\nimprovements over baselines. These results underscore the effectiveness of\nDDPM-style bridge sampling in enhancing both performance and theoretical\nconsistency for structured prediction tasks.", "AI": {"tldr": "\u63d0\u51fa\u795e\u7ecf\u6865\u8fc7\u7a0b\uff08NBPs\uff09\u7528\u4e8e\u5efa\u6a21\u968f\u673a\u51fd\u6570\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u5982GPs\u6709\u6269\u5c55\u6027\u548c\u9ad8\u65af\u5047\u8bbe\u95ee\u9898\uff0cNPs\u96be\u6355\u6349\u590d\u6742\u5206\u5e03\uff0cNDPs\u5b58\u5728\u8f93\u5165\u8026\u5408\u5f31\u548c\u8bed\u4e49\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51faNBPs\uff0c\u5c06\u8f93\u5165x\u4f5c\u4e3a\u6574\u4e2a\u6269\u6563\u8f68\u8ff9\u7684\u52a8\u6001\u951a\u70b9\uff0c\u91cd\u65b0\u6784\u5efa\u524d\u5411\u6838\u4f7f\u5176\u660e\u786e\u4f9d\u8d56x\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u3001EEG\u4fe1\u53f7\u56de\u5f52\u548c\u56fe\u50cf\u56de\u5f52\u4efb\u52a1\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "DDPM\u98ce\u683c\u7684\u6865\u91c7\u6837\u5728\u63d0\u5347\u7ed3\u6784\u5316\u9884\u6d4b\u4efb\u52a1\u7684\u6027\u80fd\u548c\u7406\u8bba\u4e00\u81f4\u6027\u4e0a\u6709\u6548\u3002"}}
{"id": "2508.08127", "pdf": "https://arxiv.org/pdf/2508.08127", "abs": "https://arxiv.org/abs/2508.08127", "authors": ["Rui Miao", "Yixin Liu", "Yili Wang", "Xu Shen", "Yue Tan", "Yiwei Dai", "Shirui Pan", "Xin Wang"], "title": "BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks", "categories": ["cs.AI"], "comment": null, "summary": "The security of LLM-based multi-agent systems (MAS) is critically threatened\nby propagation vulnerability, where malicious agents can distort collective\ndecision-making through inter-agent message interactions. While existing\nsupervised defense methods demonstrate promising performance, they may be\nimpractical in real-world scenarios due to their heavy reliance on labeled\nmalicious agents to train a supervised malicious detection model. To enable\npractical and generalizable MAS defenses, in this paper, we propose BlindGuard,\nan unsupervised defense method that learns without requiring any\nattack-specific labels or prior knowledge of malicious behaviors. To this end,\nwe establish a hierarchical agent encoder to capture individual, neighborhood,\nand global interaction patterns of each agent, providing a comprehensive\nunderstanding for malicious agent detection. Meanwhile, we design a\ncorruption-guided detector that consists of directional noise injection and\ncontrastive learning, allowing effective detection model training solely on\nnormal agent behaviors. Extensive experiments show that BlindGuard effectively\ndetects diverse attack types (i.e., prompt injection, memory poisoning, and\ntool attack) across MAS with various communication patterns while maintaining\nsuperior generalizability compared to supervised baselines. The code is\navailable at: https://github.com/MR9812/BlindGuard.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u76d1\u7763\u9632\u5fa1\u65b9\u6cd5BlindGuard\u4fdd\u62a4LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b89\u5168\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u4e14\u6cdb\u5316\u6027\u5f3a\u3002", "motivation": "\u73b0\u6709\u76d1\u7763\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u6807\u8bb0\u6076\u610f\u667a\u80fd\u4f53\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e0d\u5b9e\u7528\uff0c\u9700\u5b9e\u7528\u4e14\u53ef\u6cdb\u5316\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u5efa\u7acb\u5206\u5c42\u667a\u80fd\u4f53\u7f16\u7801\u5668\u6355\u6349\u4ea4\u4e92\u6a21\u5f0f\uff0c\u8bbe\u8ba1\u8150\u8d25\u5f15\u5bfc\u68c0\u6d4b\u5668\uff0c\u542b\u5b9a\u5411\u566a\u58f0\u6ce8\u5165\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ec5\u57fa\u4e8e\u6b63\u5e38\u667a\u80fd\u4f53\u884c\u4e3a\u8bad\u7ec3\u68c0\u6d4b\u6a21\u578b\u3002", "result": "BlindGuard\u80fd\u6709\u6548\u68c0\u6d4b\u591a\u79cd\u653b\u51fb\u7c7b\u578b\uff0c\u5728\u4e0d\u540c\u901a\u4fe1\u6a21\u5f0f\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4fdd\u6301\u4f18\u4e8e\u76d1\u7763\u57fa\u7ebf\u7684\u6cdb\u5316\u6027\u3002", "conclusion": "BlindGuard\u662f\u5b9e\u7528\u4e14\u53ef\u6cdb\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9632\u5fa1\u65b9\u6cd5\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2508.07221", "pdf": "https://arxiv.org/pdf/2508.07221", "abs": "https://arxiv.org/abs/2508.07221", "authors": ["Po-Han Lee", "Yu-Cheng Lin", "Chan-Tung Ku", "Chan Hsu", "Pei-Cing Huang", "Ping-Hsun Wu", "Yihuang Kang"], "title": "LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference", "categories": ["cs.LG", "cs.AI", "cs.MA", "stat.AP", "stat.ME"], "comment": null, "summary": "Estimating individualized treatment effects from observational data presents\na persistent challenge due to unmeasured confounding and structural bias.\nCausal Machine Learning (causal ML) methods, such as causal trees and doubly\nrobust estimators, provide tools for estimating conditional average treatment\neffects. These methods have limited effectiveness in complex real-world\nenvironments due to the presence of latent confounders or those described in\nunstructured formats. Moreover, reliance on domain experts for confounder\nidentification and rule interpretation introduces high annotation cost and\nscalability concerns. In this work, we proposed Large Language Model-based\nagents for automated confounder discovery and subgroup analysis that integrate\nagents into the causal ML pipeline to simulate domain expertise. Our framework\nsystematically performs subgroup identification and confounding structure\ndiscovery by leveraging the reasoning capabilities of LLM-based agents, which\nreduces human dependency while preserving interpretability. Experiments on\nreal-world medical datasets show that our proposed approach enhances treatment\neffect estimation robustness by narrowing confidence intervals and uncovering\nunrecognized confounding biases. Our findings suggest that LLM-based agents\noffer a promising path toward scalable, trustworthy, and semantically aware\ncausal inference.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u7528\u4e8e\u81ea\u52a8\u6df7\u6742\u56e0\u7d20\u53d1\u73b0\u548c\u4e9a\u7ec4\u5206\u6790\uff0c\u51cf\u5c11\u4eba\u5de5\u4f9d\u8d56\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u589e\u5f3a\u6cbb\u7597\u6548\u679c\u4f30\u8ba1\u7684\u7a33\u5065\u6027\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u56e0\u6f5c\u5728\u6df7\u6742\u56e0\u7d20\u548c\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u800c\u6548\u679c\u53d7\u9650\u3002", "method": "\u5c06\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u96c6\u6210\u5230\u56e0\u679c\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u4e2d\uff0c\u5229\u7528\u5176\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u4e9a\u7ec4\u8bc6\u522b\u548c\u6df7\u6742\u7ed3\u6784\u53d1\u73b0\u3002", "result": "\u5728\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u7f29\u5c0f\u7f6e\u4fe1\u533a\u95f4\u548c\u53d1\u73b0\u672a\u8bc6\u522b\u7684\u6df7\u6742\u504f\u5dee\uff0c\u589e\u5f3a\u4e86\u6cbb\u7597\u6548\u679c\u4f30\u8ba1\u7684\u7a33\u5065\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u4fe1\u548c\u8bed\u4e49\u611f\u77e5\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2508.08147", "pdf": "https://arxiv.org/pdf/2508.08147", "abs": "https://arxiv.org/abs/2508.08147", "authors": ["Yunkai Hu", "Tianqiao Zhao", "Meng Yue"], "title": "From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces a novel Large Language Models (LLMs)-assisted agent\nthat automatically converts natural-language descriptions of power system\noptimization scenarios into compact, solver-ready formulations and generates\ncorresponding solutions. In contrast to approaches that rely solely on LLM to\nproduce solutions directly, the proposed method focuses on discovering a\nmathematically compatible formulation that can be efficiently solved by\noff-the-shelf optimization solvers. Directly using LLMs to produce solutions\noften leads to infeasible or suboptimal results, as these models lack the\nnumerical precision and constraint-handling capabilities of established\noptimization solvers. The pipeline integrates a domain-aware prompt and schema\nwith an LLM, enforces feasibility through systematic validation and iterative\nrepair, and returns both solver-ready models and user-facing results. Using the\nunit commitment problem as a representative case study, the agent produces\noptimal or near-optimal schedules along with the associated objective costs.\nResults demonstrate that coupling the solver with task-specific validation\nsignificantly enhances solution reliability. This work shows that combining AI\nwith established optimization frameworks bridges high-level problem\ndescriptions and executable mathematical models, enabling more efficient\ndecision-making in energy systems", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u667a\u80fd\u4f53\uff0c\u5c06\u7535\u529b\u7cfb\u7edf\u4f18\u5316\u573a\u666f\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u5316\u4e3a\u53ef\u6c42\u89e3\u7684\u516c\u5f0f\u5e76\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5355\u4f4d\u627f\u8bfa\u95ee\u9898\u4e3a\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u76f4\u63a5\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u89e3\u51b3\u65b9\u6848\u5e38\u5bfc\u81f4\u4e0d\u53ef\u884c\u6216\u6b21\u4f18\u7ed3\u679c\uff0c\u56e0\u5176\u7f3a\u4e4f\u6570\u503c\u7cbe\u5ea6\u548c\u7ea6\u675f\u5904\u7406\u80fd\u529b\uff0c\u9700\u7ed3\u5408\u73b0\u6709\u4f18\u5316\u6846\u67b6\u3002", "method": "\u5c06\u9886\u57df\u611f\u77e5\u63d0\u793a\u548c\u6a21\u5f0f\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u901a\u8fc7\u7cfb\u7edf\u9a8c\u8bc1\u548c\u8fed\u4ee3\u4fee\u590d\u786e\u4fdd\u53ef\u884c\u6027\uff0c\u8fd4\u56de\u53ef\u6c42\u89e3\u6a21\u578b\u548c\u7528\u6237\u7ed3\u679c\u3002", "result": "\u4ee5\u5355\u4f4d\u627f\u8bfa\u95ee\u9898\u4e3a\u4f8b\uff0c\u667a\u80fd\u4f53\u4ea7\u751f\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684\u8c03\u5ea6\u548c\u76ee\u6807\u6210\u672c\uff0c\u6c42\u89e3\u5668\u4e0e\u7279\u5b9a\u4efb\u52a1\u9a8c\u8bc1\u7ed3\u5408\u663e\u8457\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u53ef\u9760\u6027\u3002", "conclusion": "\u5c06\u4eba\u5de5\u667a\u80fd\u4e0e\u73b0\u6709\u4f18\u5316\u6846\u67b6\u7ed3\u5408\uff0c\u80fd\u8fde\u63a5\u9ad8\u5c42\u95ee\u9898\u63cf\u8ff0\u548c\u53ef\u6267\u884c\u6570\u5b66\u6a21\u578b\uff0c\u5b9e\u73b0\u80fd\u6e90\u7cfb\u7edf\u66f4\u9ad8\u6548\u51b3\u7b56\u3002"}}
{"id": "2508.07224", "pdf": "https://arxiv.org/pdf/2508.07224", "abs": "https://arxiv.org/abs/2508.07224", "authors": ["Ananda Prakash Verma"], "title": "EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present EDGE, a general-purpose, misconception-aware adaptive learning\nframework composed of four stages: Evaluate (ability and state estimation),\nDiagnose (posterior infer-ence of misconceptions), Generate (counterfactual\nitem synthesis), and Exercise (index-based retrieval scheduling). EDGE unifies\npsychometrics (IRT/Bayesian state space models), cog-nitive diagnostics\n(misconception discovery from distractor patterns and response latencies),\ncontrastive item generation (minimal perturbations that invalidate learner\nshortcuts while pre-serving psychometric validity), and principled scheduling\n(a restless bandit approximation to spaced retrieval). We formalize a composite\nreadiness metric, EdgeScore, prove its monotonicity and Lipschitz continuity,\nand derive an index policy that is near-optimal under mild assumptions on\nforgetting and learning gains. We further establish conditions under which\ncounterfactual items provably reduce the posterior probability of a targeted\nmisconception faster than standard practice. The paper focuses on theory and\nimplementable pseudocode; empirical study is left to future work.", "AI": {"tldr": "\u63d0\u51fa\u901a\u7528\u3001\u8bef\u89e3\u611f\u77e5\u81ea\u9002\u5e94\u5b66\u4e60\u6846\u67b6EDGE\uff0c\u542b\u56db\u9636\u6bb5\uff0c\u7edf\u4e00\u591a\u65b9\u6cd5\uff0c\u5b9a\u4e49EdgeScore\u5e76\u8bc1\u660e\u6027\u8d28\uff0c\u63a8\u5bfc\u8fd1\u6700\u4f18\u7d22\u5f15\u7b56\u7565\uff0c\u8fd8\u660e\u786e\u53cd\u4e8b\u5b9e\u9879\u76ee\u4f18\u52bf\uff0c\u4fa7\u91cd\u7406\u8bba\u548c\u4f2a\u4ee3\u7801\u3002", "motivation": "\u6784\u5efa\u901a\u7528\u3001\u80fd\u611f\u77e5\u5b66\u4e60\u8005\u8bef\u89e3\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u5c06\u5fc3\u7406\u6d4b\u91cf\u5b66\u3001\u8ba4\u77e5\u8bca\u65ad\u3001\u5bf9\u6bd4\u9879\u76ee\u751f\u6210\u548c\u539f\u5219\u6027\u8c03\u5ea6\u7b49\u65b9\u6cd5\u7ed3\u5408\uff0c\u5b9a\u4e49EdgeScore\uff0c\u63a8\u5bfc\u7d22\u5f15\u7b56\u7565\u3002", "result": "\u8bc1\u660eEdgeScore\u7684\u5355\u8c03\u6027\u548cLipschitz\u8fde\u7eed\u6027\uff0c\u63a8\u5bfc\u8fd1\u6700\u4f18\u7d22\u5f15\u7b56\u7565\uff0c\u660e\u786e\u53cd\u4e8b\u5b9e\u9879\u76ee\u6bd4\u6807\u51c6\u505a\u6cd5\u66f4\u5feb\u964d\u4f4e\u76ee\u6807\u8bef\u89e3\u540e\u9a8c\u6982\u7387\u3002", "conclusion": "\u8bba\u6587\u4fa7\u91cd\u7406\u8bba\u548c\u53ef\u5b9e\u73b0\u7684\u4f2a\u4ee3\u7801\uff0c\u5b9e\u8bc1\u7814\u7a76\u7559\u5f85\u672a\u6765\u3002"}}
{"id": "2505.23197", "pdf": "https://arxiv.org/pdf/2505.23197", "abs": "https://arxiv.org/abs/2505.23197", "authors": ["Jatin Kumar Arora", "Shubhendu Bhasin"], "title": "UPP: Unified Path Planner with Adaptive Safety and Optimality", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages,11 figures", "summary": "We are surrounded by robots helping us perform complex tasks. Robots have a\nwide range of applications, from industrial automation to personalized\nassistance. However, with great technological innovation come significant\nchallenges. One of the major challenges in robotics is path planning. Despite\nadvancements such as graph search, sampling, and potential field methods, most\npath planning algorithms focus either on optimality or on safety. Very little\nresearch addresses both simultaneously. We propose a Unified Path Planner (UPP)\nthat uses modified heuristics and a dynamic safety cost function to balance\nsafety and optimality. The level of safety can be adjusted via tunable\nparameters, trading off against computational complexity. We demonstrate the\nplanner's performance in simulations, showing how parameter variation affects\nresults. UPP is compared with various traditional and safe-optimal planning\nalgorithms across different scenarios. We also validate it on a TurtleBot,\nwhere the robot successfully finds safe and sub-optimal paths.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u8def\u5f84\u89c4\u5212\u5668UPP\u5e73\u8861\u8def\u5f84\u89c4\u5212\u7684\u5b89\u5168\u6027\u4e0e\u6700\u4f18\u6027\uff0c\u5728\u6a21\u62df\u548c\u5b9e\u9645\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u5927\u591a\u53ea\u5173\u6ce8\u6700\u4f18\u6027\u6216\u5b89\u5168\u6027\uff0c\u5f88\u5c11\u540c\u65f6\u517c\u987e\u4e24\u8005\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7b97\u6cd5\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faUPP\uff0c\u4f7f\u7528\u4fee\u6539\u540e\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u52a8\u6001\u5b89\u5168\u6210\u672c\u51fd\u6570\uff0c\u53ef\u901a\u8fc7\u53ef\u8c03\u53c2\u6570\u8c03\u6574\u5b89\u5168\u7ea7\u522b\u5e76\u6743\u8861\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728\u6a21\u62df\u4e2d\u5c55\u793a\u4e86\u53c2\u6570\u53d8\u5316\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u4e0e\u591a\u79cd\u4f20\u7edf\u548c\u5b89\u5168\u6700\u4f18\u89c4\u5212\u7b97\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u5728TurtleBot\u4e0a\u9a8c\u8bc1\u673a\u5668\u4eba\u80fd\u627e\u5230\u5b89\u5168\u4e14\u6b21\u4f18\u7684\u8def\u5f84\u3002", "conclusion": "UPP\u80fd\u591f\u5728\u8def\u5f84\u89c4\u5212\u4e2d\u5e73\u8861\u5b89\u5168\u6027\u548c\u6700\u4f18\u6027\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2508.07243", "pdf": "https://arxiv.org/pdf/2508.07243", "abs": "https://arxiv.org/abs/2508.07243", "authors": ["Chu Zhao", "Eneng Yang", "Yizhou Dang", "Jianzhe Zhao", "Guibing Guo", "Xingwei Wang"], "title": "Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 6 figures, Under-review", "summary": "Heuristic negative sampling enhances recommendation performance by selecting\nnegative samples of varying hardness levels from predefined candidate pools to\nguide the model toward learning more accurate decision boundaries. However, our\nempirical and theoretical analyses reveal that unobserved environmental\nconfounders (e.g., exposure or popularity biases) in candidate pools may cause\nheuristic sampling methods to introduce false hard negatives (FHNS). These\nmisleading samples can encourage the model to learn spurious correlations\ninduced by such confounders, ultimately compromising its generalization ability\nunder distribution shifts. To address this issue, we propose a novel method\nnamed Causal Negative Sampling via Diffusion (CNSDiff). By synthesizing\nnegative samples in the latent space via a conditional diffusion process,\nCNSDiff avoids the bias introduced by predefined candidate pools and thus\nreduces the likelihood of generating FHNS. Moreover, it incorporates a causal\nregularization term to explicitly mitigate the influence of environmental\nconfounders during the negative sampling process, leading to robust negatives\nthat promote out-of-distribution (OOD) generalization. Comprehensive\nexperiments under four representative distribution shift scenarios demonstrate\nthat CNSDiff achieves an average improvement of 13.96% across all evaluation\nmetrics compared to state-of-the-art baselines, verifying its effectiveness and\nrobustness in OOD recommendation tasks.", "AI": {"tldr": "\u542f\u53d1\u5f0f\u8d1f\u91c7\u6837\u6709\u95ee\u9898\uff0c\u63d0\u51faCNSDiff\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728OOD\u63a8\u8350\u4efb\u52a1\u6709\u6548\u4e14\u7a33\u5065\u3002", "motivation": "\u542f\u53d1\u5f0f\u8d1f\u91c7\u6837\u56e0\u5019\u9009\u6c60\u4e2d\u7684\u73af\u5883\u6df7\u6742\u56e0\u7d20\u4f1a\u5f15\u5165\u865a\u5047\u786c\u8d1f\u6837\u672c\uff0c\u5f71\u54cd\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faCausal Negative Sampling via Diffusion (CNSDiff)\u65b9\u6cd5\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u901a\u8fc7\u6761\u4ef6\u6269\u6563\u8fc7\u7a0b\u5408\u6210\u8d1f\u6837\u672c\uff0c\u907f\u514d\u5019\u9009\u6c60\u504f\u5dee\uff0c\u5e76\u5f15\u5165\u56e0\u679c\u6b63\u5219\u5316\u9879\u51cf\u8f7b\u73af\u5883\u6df7\u6742\u56e0\u7d20\u5f71\u54cd\u3002", "result": "\u5728\u56db\u79cd\u4ee3\u8868\u6027\u5206\u5e03\u504f\u79fb\u573a\u666f\u7684\u7efc\u5408\u5b9e\u9a8c\u4e2d\uff0cCNSDiff\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u5e73\u5747\u63d0\u9ad813.96%\u3002", "conclusion": "CNSDiff\u5728OOD\u63a8\u8350\u4efb\u52a1\u4e2d\u6709\u6548\u4e14\u7a33\u5065\u3002"}}
{"id": "2508.05691", "pdf": "https://arxiv.org/pdf/2508.05691", "abs": "https://arxiv.org/abs/2508.05691", "authors": ["Kai Yao", "Marc Juarez"], "title": "AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Generative models are increasingly adopted in high-stakes domains, yet\ncurrent deployments offer no mechanisms to verify the origin of model outputs.\nWe address this gap by extending model fingerprinting techniques beyond the\ntraditional collaborative setting to one where the model provider may act\nadversarially. To our knowledge, this is the first work to evaluate\nfingerprinting for provenance attribution under such a threat model. The\nmethods rely on a trusted verifier that extracts secret fingerprints from the\nmodel's output space, unknown to the provider, and trains a model to predict\nand verify them. Our empirical evaluation shows that our methods achieve\nnear-zero FPR@95%TPR for instances of GAN and diffusion models, even when\ntested on small modifications to the original architecture and training data.\nMoreover, the methods remain robust against adversarial attacks that actively\nmodify the outputs to bypass detection. Source codes are available at\nhttps://github.com/PSMLab/authprint.", "AI": {"tldr": "\u6587\u7ae0\u5c06\u6a21\u578b\u6307\u7eb9\u6280\u672f\u6269\u5c55\u5230\u6a21\u578b\u63d0\u4f9b\u8005\u53ef\u80fd\u6709\u6076\u610f\u884c\u4e3a\u7684\u573a\u666f\uff0c\u7528\u4e8e\u9a8c\u8bc1\u751f\u6210\u6a21\u578b\u8f93\u51fa\u7684\u6765\u6e90\uff0c\u65b9\u6cd5\u6548\u679c\u597d\u4e14\u6297\u653b\u51fb\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\u65f6\u7f3a\u4e4f\u9a8c\u8bc1\u6a21\u578b\u8f93\u51fa\u6765\u6e90\u7684\u673a\u5236\u3002", "method": "\u4f9d\u9760\u53ef\u4fe1\u9a8c\u8bc1\u8005\u4ece\u6a21\u578b\u8f93\u51fa\u7a7a\u95f4\u63d0\u53d6\u63d0\u4f9b\u8005\u672a\u77e5\u7684\u79d8\u5bc6\u6307\u7eb9\uff0c\u5e76\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u548c\u9a8c\u8bc1\u3002", "result": "\u65b9\u6cd5\u5728GAN\u548c\u6269\u6563\u6a21\u578b\u5b9e\u4f8b\u4e0a\u8fbe\u5230\u8fd1\u96f6FPR@95%TPR\uff0c\u5bf9\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u6570\u636e\u5c0f\u4fee\u6539\u53ca\u5bf9\u6297\u653b\u51fb\u90fd\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u6709\u6548\u9a8c\u8bc1\u751f\u6210\u6a21\u578b\u8f93\u51fa\u7684\u6765\u6e90\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2508.07249", "pdf": "https://arxiv.org/pdf/2508.07249", "abs": "https://arxiv.org/abs/2508.07249", "authors": ["Soumen Pachal", "Mizhaan Prajit Maniyar", "Prashanth L. A"], "title": "Policy Newton methods for Distortion Riskmetrics", "categories": ["cs.LG"], "comment": null, "summary": "We consider the problem of risk-sensitive control in a reinforcement learning\n(RL) framework. In particular, we aim to find a risk-optimal policy by\nmaximizing the distortion riskmetric (DRM) of the discounted reward in a finite\nhorizon Markov decision process (MDP). DRMs are a rich class of risk measures\nthat include several well-known risk measures as special cases. We derive a\npolicy Hessian theorem for the DRM objective using the likelihood ratio method.\nUsing this result, we propose a natural DRM Hessian estimator from sample\ntrajectories of the underlying MDP. Next, we present a cubic-regularized policy\nNewton algorithm for solving this problem in an on-policy RL setting using\nestimates of the DRM gradient and Hessian. Our proposed algorithm is shown to\nconverge to an $\\epsilon$-second-order stationary point ($\\epsilon$-SOSP) of\nthe DRM objective, and this guarantee ensures the escaping of saddle points.\nThe sample complexity of our algorithms to find an $ \\epsilon$-SOSP is\n$\\mathcal{O}(\\epsilon^{-3.5})$. Our experiments validate the theoretical\nfindings. To the best of our knowledge, our is the first work to present\nconvergence to an $\\epsilon$-SOSP of a risk-sensitive objective, while existing\nworks in the literature have either shown convergence to a first-order\nstationary point of a risk-sensitive objective, or a SOSP of a risk-neutral\none.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.07253", "pdf": "https://arxiv.org/pdf/2508.07253", "abs": "https://arxiv.org/abs/2508.07253", "authors": ["Bartlomiej Chybowski", "Shima Abdullateef", "Hollan Haule", "Alfredo Gonzalez-Sulser", "Javier Escudero"], "title": "PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets", "categories": ["cs.LG", "eess.SP", "q-bio.NC"], "comment": null, "summary": "Reliable seizure detection is critical for diagnosing and managing epilepsy,\nyet clinical workflows remain dependent on time-consuming manual EEG\ninterpretation. While machine learning has shown promise, existing approaches\noften rely on dataset-specific optimisations, limiting their real-world\napplicability and reproducibility. Here, we introduce an innovative,\nopen-source machine-learning framework that enables robust and generalisable\nseizure detection across varied clinical datasets. We evaluate our approach on\ntwo publicly available EEG datasets that differ in patient populations and\nelectrode configurations. To enhance robustness, the framework incorporates an\nautomated pre-processing pipeline to standardise data and a majority voting\nmechanism, in which multiple models independently assess each second of EEG\nbefore reaching a final decision. We train, tune, and evaluate models within\neach dataset, assessing their cross-dataset transferability. Our models achieve\nhigh within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and\n0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets\ndespite differences in EEG setups and populations (AUC 0.615+/-0.039 for models\ntrained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case)\nwithout any post-processing. Furthermore, a mild post-processing improved the\nwithin-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset\nresults to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the\npotential of, and essential considerations for, deploying our framework in\ndiverse clinical settings. By making our methodology fully reproducible, we\nprovide a foundation for advancing clinically viable, dataset-agnostic seizure\ndetection systems. This approach has the potential for widespread adoption,\ncomplementing rather than replacing expert interpretation, and accelerating\nclinical integration.", "AI": {"tldr": "\u63d0\u51fa\u5f00\u6e90\u673a\u5668\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6027\u80fd\u826f\u597d\u4e14\u6709\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u4e34\u5e8a\u53ef\u7528\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u53ef\u9760\u7684\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\u5bf9\u766b\u75eb\u8bca\u65ad\u548c\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4e34\u5e8a\u4f9d\u8d56\u8017\u65f6\u7684\u624b\u52a8\u8111\u7535\u56fe\u89e3\u8bfb\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u7279\u5b9a\u6570\u636e\u96c6\u4f18\u5316\uff0c\u7f3a\u4e4f\u5b9e\u7528\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u5f15\u5165\u5f00\u6e90\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u81ea\u52a8\u9884\u5904\u7406\u6d41\u7a0b\u548c\u591a\u6570\u6295\u7968\u673a\u5236\uff0c\u5728\u4e24\u4e2a\u516c\u5f00\u8111\u7535\u56fe\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u3001\u8c03\u4f18\u548c\u8bc4\u4f30\u6a21\u578b\uff0c\u8bc4\u4f30\u8de8\u6570\u636e\u96c6\u8fc1\u79fb\u80fd\u529b\u3002", "result": "\u6a21\u578b\u5728\u6570\u636e\u96c6\u5185\u8868\u73b0\u826f\u597d\uff08CHB - MIT\u7684AUC\u4e3a0.904\u00b10.059\uff0cTUSZ\u4e3a0.864\u00b10.060\uff09\uff0c\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u8f7b\u5ea6\u540e\u5904\u7406\u53ef\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u5728\u4e0d\u540c\u4e34\u5e8a\u73af\u5883\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u4e3a\u63a8\u8fdb\u4e34\u5e8a\u53ef\u884c\u3001\u4e0e\u6570\u636e\u96c6\u65e0\u5173\u7684\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u5e76\u52a0\u901f\u4e34\u5e8a\u6574\u5408\u3002"}}
{"id": "2508.07297", "pdf": "https://arxiv.org/pdf/2508.07297", "abs": "https://arxiv.org/abs/2508.07297", "authors": ["Hongbo Zhu", "Angelo Cangelosi"], "title": "Revisiting Data Attribution for Influence Functions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The goal of data attribution is to trace the model's predictions through the\nlearning algorithm and back to its training data. thereby identifying the most\ninfluential training samples and understanding how the model's behavior leads\nto particular predictions. Understanding how individual training examples\ninfluence a model's predictions is fundamental for machine learning\ninterpretability, data debugging, and model accountability. Influence\nfunctions, originating from robust statistics, offer an efficient, first-order\napproximation to estimate the impact of marginally upweighting or removing a\ndata point on a model's learned parameters and its subsequent predictions,\nwithout the need for expensive retraining. This paper comprehensively reviews\nthe data attribution capability of influence functions in deep learning. We\ndiscuss their theoretical foundations, recent algorithmic advances for\nefficient inverse-Hessian-vector product estimation, and evaluate their\neffectiveness for data attribution and mislabel detection. Finally,\nhighlighting current challenges and promising directions for unleashing the\nhuge potential of influence functions in large-scale, real-world deep learning\nscenarios.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u56de\u987e\u5f71\u54cd\u51fd\u6570\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u5f52\u56e0\u80fd\u529b\uff0c\u63a2\u8ba8\u5176\u7406\u8bba\u57fa\u7840\u3001\u7b97\u6cd5\u8fdb\u5c55\uff0c\u8bc4\u4f30\u5176\u6548\u679c\uff0c\u6307\u51fa\u6311\u6218\u4e0e\u65b9\u5411\u3002", "motivation": "\u7406\u89e3\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u5bf9\u6a21\u578b\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u5bf9\u673a\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u3001\u6570\u636e\u8c03\u8bd5\u548c\u6a21\u578b\u95ee\u8d23\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5f71\u54cd\u51fd\u6570\u53ef\u7528\u4e8e\u6570\u636e\u5f52\u56e0\u3002", "method": "\u5bf9\u5f71\u54cd\u51fd\u6570\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u5f52\u56e0\u80fd\u529b\u8fdb\u884c\u5168\u9762\u56de\u987e\uff0c\u8ba8\u8bba\u7406\u8bba\u57fa\u7840\u3001\u7b97\u6cd5\u8fdb\u5c55\uff0c\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "\u8bc4\u4f30\u4e86\u5f71\u54cd\u51fd\u6570\u5728\u6570\u636e\u5f52\u56e0\u548c\u8bef\u6807\u7b7e\u68c0\u6d4b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6307\u51fa\u5f53\u524d\u6311\u6218\u548c\u5728\u5927\u89c4\u6a21\u3001\u73b0\u5b9e\u6df1\u5ea6\u5b66\u4e60\u573a\u666f\u4e2d\u91ca\u653e\u5f71\u54cd\u51fd\u6570\u6f5c\u529b\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2508.06499", "pdf": "https://arxiv.org/pdf/2508.06499", "abs": "https://arxiv.org/abs/2508.06499", "authors": ["Andrea Corsico", "Giorgia Rigamonti", "Simone Zini", "Luigi Celona", "Paolo Napoletano"], "title": "Network-Specific Models for Multimodal Brain Response Prediction", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "In this work, we present a network-specific approach for predicting brain\nresponses to complex multimodal movies, leveraging the Yeo 7-network\nparcellation of the Schaefer atlas. Rather than treating the brain as a\nhomogeneous system, we grouped the seven functional networks into four clusters\nand trained separate multi-subject, multi-layer perceptron (MLP) models for\neach. This architecture supports cluster-specific optimization and adaptive\nmemory modeling, allowing each model to adjust temporal dynamics and modality\nweighting based on the functional role of its target network. Our results\ndemonstrate that this clustered strategy significantly enhances prediction\naccuracy across the 1,000 cortical regions of the Schaefer atlas. The final\nmodel achieved an eighth-place ranking in the Algonauts Project 2025 Challenge,\nwith out-of-distribution (OOD) correlation scores nearly double those of the\nbaseline model used in the selection phase. Code is available at\nhttps://github.com/Corsi01/algo2025.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eYeo 7 - \u7f51\u7edc\u5206\u533a\u7684\u7279\u5b9a\u7f51\u7edc\u65b9\u6cd5\u9884\u6d4b\u5927\u8111\u5bf9\u590d\u6742\u591a\u6a21\u6001\u7535\u5f71\u7684\u53cd\u5e94\uff0c\u5206\u7ec4\u8bad\u7ec3\u6a21\u578b\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5728\u6311\u6218\u8d5b\u83b7\u7b2c\u516b\u540d\u3002", "motivation": "\u6539\u8fdb\u5927\u8111\u5bf9\u590d\u6742\u591a\u6a21\u6001\u7535\u5f71\u53cd\u5e94\u7684\u9884\u6d4b\u65b9\u6cd5\uff0c\u4e0d\u5c06\u5927\u8111\u89c6\u4e3a\u5747\u5300\u7cfb\u7edf\u3002", "method": "\u5c06\u4e03\u4e2a\u529f\u80fd\u7f51\u7edc\u5206\u4e3a\u56db\u4e2a\u96c6\u7fa4\uff0c\u4e3a\u6bcf\u4e2a\u96c6\u7fa4\u8bad\u7ec3\u591a\u4e3b\u4f53\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u6a21\u578b\uff0c\u652f\u6301\u7279\u5b9a\u96c6\u7fa4\u4f18\u5316\u548c\u81ea\u9002\u5e94\u8bb0\u5fc6\u5efa\u6a21\u3002", "result": "\u805a\u7c7b\u7b56\u7565\u663e\u8457\u63d0\u9ad8Schaefer\u56fe\u8c311000\u4e2a\u76ae\u8d28\u533a\u57df\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u6700\u7ec8\u6a21\u578b\u5728\u6311\u6218\u8d5b\u83b7\u7b2c\u516b\u540d\uff0c\u5206\u5e03\u5916\uff08OOD\uff09\u76f8\u5173\u5206\u6570\u63a5\u8fd1\u57fa\u7ebf\u6a21\u578b\u4e24\u500d\u3002", "conclusion": "\u57fa\u4e8e\u7f51\u7edc\u805a\u7c7b\u7684\u9884\u6d4b\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5927\u8111\u53cd\u5e94\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.07299", "pdf": "https://arxiv.org/pdf/2508.07299", "abs": "https://arxiv.org/abs/2508.07299", "authors": ["Lin-Han Jia", "Si-Yu Han", "Wen-Chao Hu", "Jie-Jing Shao", "Wen-Da Wei", "Zhi Zhou", "Lan-Zhe Guo", "Yu-Feng Li"], "title": "When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neuro-symbolic (Nesy) learning improves the target task performance of models\nby enabling them to satisfy knowledge, while semi/self-supervised learning\n(SSL) improves the target task performance by designing unsupervised pretext\ntasks for unlabeled data to make models satisfy corresponding assumptions. We\nextend the Nesy theory based on reliable knowledge to the scenario of\nunreliable knowledge (i.e., assumptions), thereby unifying the theoretical\nframeworks of SSL and Nesy. Through rigorous theoretical analysis, we\ndemonstrate that, in theory, the impact of pretext tasks on target performance\nhinges on three factors: knowledge learnability with respect to the model,\nknowledge reliability with respect to the data, and knowledge completeness with\nrespect to the target. We further propose schemes to operationalize these\ntheoretical metrics, and thereby develop a method that can predict the\neffectiveness of pretext tasks in advance. This will change the current status\nquo in practical applications, where the selections of unsupervised tasks are\nheuristic-based rather than theory-based, and it is difficult to evaluate the\nrationality of unsupervised pretext task selection before testing the model on\nthe target task. In experiments, we verify a high correlation between the\npredicted performance-estimated using minimal data-and the actual performance\nachieved after large-scale semi-supervised or self-supervised learning, thus\nconfirming the validity of the theory and the effectiveness of the evaluation\nmethod.", "AI": {"tldr": "\u6587\u7ae0\u7edf\u4e00\u534a/\u81ea\u76d1\u7763\u5b66\u4e60\u4e0e\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u9884\u8bad\u7ec3\u4efb\u52a1\u5bf9\u76ee\u6807\u6027\u80fd\u5f71\u54cd\u56e0\u7d20\uff0c\u63d0\u51fa\u8bc4\u4f30\u65b9\u6cd5\u5e76\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\u4efb\u52a1\u9009\u62e9\u57fa\u4e8e\u542f\u53d1\u5f0f\u800c\u975e\u7406\u8bba\uff0c\u96be\u4ee5\u5728\u76ee\u6807\u4efb\u52a1\u6d4b\u8bd5\u524d\u8bc4\u4f30\u5176\u5408\u7406\u6027\uff0c\u9700\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u5e76\u63d0\u51fa\u6709\u6548\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5c06\u53ef\u9760\u77e5\u8bc6\u7684\u795e\u7ecf\u7b26\u53f7\u7406\u8bba\u6269\u5c55\u5230\u4e0d\u53ef\u9760\u77e5\u8bc6\u573a\u666f\uff0c\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff1b\u5206\u6790\u9884\u8bad\u7ec3\u4efb\u52a1\u5f71\u54cd\u76ee\u6807\u6027\u80fd\u7684\u56e0\u7d20\uff0c\u63d0\u51fa\u64cd\u4f5c\u7406\u8bba\u6307\u6807\u7684\u65b9\u6848\u548c\u9884\u6d4b\u9884\u8bad\u7ec3\u4efb\u52a1\u6709\u6548\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4f7f\u7528\u5c11\u91cf\u6570\u636e\u9884\u6d4b\u7684\u6027\u80fd\u4e0e\u5927\u89c4\u6a21\u534a/\u81ea\u76d1\u7763\u5b66\u4e60\u540e\u7684\u5b9e\u9645\u6027\u80fd\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u7406\u8bba\u6709\u6548\uff0c\u8bc4\u4f30\u65b9\u6cd5\u53ef\u884c\uff0c\u53ef\u6539\u53d8\u65e0\u76d1\u7763\u4efb\u52a1\u9009\u62e9\u73b0\u72b6\u3002"}}
{"id": "2508.07329", "pdf": "https://arxiv.org/pdf/2508.07329", "abs": "https://arxiv.org/abs/2508.07329", "authors": ["Tuo Zhang", "Ning Li", "Xin Yuan", "Wenchao Xu", "Quan Chen", "Song Guo", "Haijun Zhang"], "title": "Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the breakthrough progress of large language models (LLMs) in natural\nlanguage processing and multimodal tasks, efficiently deploying them on\nresource-constrained edge devices has become a critical challenge. The Mixture\nof Experts (MoE) architecture enhances model capacity through sparse\nactivation, but faces two major difficulties in practical deployment: (1) The\npresence of numerous outliers in activation distributions leads to severe\ndegradation in quantization accuracy for both activations and weights,\nsignificantly impairing inference performance; (2) Under limited memory,\nefficient offloading and collaborative inference of expert modules struggle to\nbalance latency and throughput. To address these issues, this paper proposes an\nefficient MoE edge deployment scheme based on Hessian-Aware Quantization (HAQ)\nand CPU-GPU collaborative inference. First, by introducing smoothed Hessian\nmatrix quantization, we achieve joint 8-bit quantization of activations and\nweights, which significantly alleviates the accuracy loss caused by outliers\nwhile ensuring efficient implementation on mainstream hardware. Second, we\ndesign an expert-level collaborative offloading and inference mechanism, which,\ncombined with expert activation path statistics, enables efficient deployment\nand scheduling of expert modules between CPU and GPU, greatly reducing memory\nfootprint and inference latency. Extensive experiments validate the\neffectiveness of our method on mainstream large models such as the OPT series\nand Mixtral 8*7B: on datasets like Wikitext2 and C4, the inference accuracy of\nthe low-bit quantized model approaches that of the full-precision model, while\nGPU memory usage is reduced by about 60%, and inference latency is\nsignificantly improved.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u96be\u9898\uff0c\u63d0\u51fa\u57fa\u4e8eHAQ\u548cCPU - GPU\u534f\u4f5c\u63a8\u7406\u7684MoE\u8fb9\u7f18\u90e8\u7f72\u65b9\u6848\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u9ad8\u6548\u90e8\u7f72\u6210\u5173\u952e\u6311\u6218\uff0cMoE\u67b6\u6784\u90e8\u7f72\u5b58\u5728\u91cf\u5316\u7cbe\u5ea6\u4e0b\u964d\u548c\u5185\u5b58\u53d7\u9650\u4e0b\u96be\u4ee5\u5e73\u8861\u5ef6\u8fdf\u4e0e\u541e\u5410\u91cf\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u5e73\u6ed1Hessian\u77e9\u9635\u91cf\u5316\u5b9e\u73b0\u6fc0\u6d3b\u548c\u6743\u91cd\u76848\u4f4d\u8054\u5408\u91cf\u5316\uff1b\u8bbe\u8ba1\u4e13\u5bb6\u7ea7\u534f\u4f5c\u5378\u8f7d\u548c\u63a8\u7406\u673a\u5236\uff0c\u7ed3\u5408\u4e13\u5bb6\u6fc0\u6d3b\u8def\u5f84\u7edf\u8ba1\u5728CPU\u548cGPU\u95f4\u90e8\u7f72\u548c\u8c03\u5ea6\u4e13\u5bb6\u6a21\u5757\u3002", "result": "\u5728OPT\u7cfb\u5217\u548cMixtral 8*7B\u7b49\u4e3b\u6d41\u5927\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0c\u4f4e\u6bd4\u7279\u91cf\u5316\u6a21\u578b\u63a8\u7406\u7cbe\u5ea6\u63a5\u8fd1\u5168\u7cbe\u5ea6\u6a21\u578b\uff0cGPU\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u7ea660%\uff0c\u63a8\u7406\u5ef6\u8fdf\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eHAQ\u548cCPU - GPU\u534f\u4f5c\u63a8\u7406\u7684MoE\u8fb9\u7f18\u90e8\u7f72\u65b9\u6848\u6709\u6548\uff0c\u80fd\u89e3\u51b3\u5f53\u524dMoE\u67b6\u6784\u90e8\u7f72\u96be\u9898\u3002"}}
{"id": "2508.06503", "pdf": "https://arxiv.org/pdf/2508.06503", "abs": "https://arxiv.org/abs/2508.06503", "authors": ["Logan Cross", "Erik Brockbank", "Tobias Gerstenberg", "Judith E. Fan", "Daniel L. K. Yamins", "Nick Haber"], "title": "Understanding Human Limits in Pattern Recognition: A Computational Model of Sequential Reasoning in Rock, Paper, Scissors", "categories": ["q-bio.NC", "cs.AI"], "comment": "To be published in Proceedings of the 8th Annual Conference on\n  Cognitive Computational Neuroscience (2025)", "summary": "How do we predict others from patterns in their behavior and what are the\ncomputational constraints that limit this ability? We investigate these\nquestions by modeling human behavior over repeated games of rock, paper,\nscissors from Brockbank & Vul (2024). Against algorithmic opponents that varied\nin strategic sophistication, people readily exploit simple transition patterns\n(e.g., consistently playing rock after paper) but struggle to detect more\ncomplex sequential dependencies. To understand the cognitive mechanisms\nunderlying these abilities and their limitations, we deploy Hypothetical Minds\n(HM), a large language model-based agent that generates and tests hypotheses\nabout opponent strategies, as a cognitive model of this behavior (Cross et al.,\n2024). We show that when applied to the same experimental conditions, HM\nclosely mirrors human performance patterns, succeeding and failing in similar\nways. To better understand the source of HM's failures and whether people might\nface similar cognitive bottlenecks in this context, we performed a series of\nablations and augmentations targeting different components of the system. When\nprovided with natural language descriptions of the opponents' strategies, HM\nsuccessfully exploited 6/7 bot opponents with win rates >80% suggesting that\naccurate hypothesis generation is the primary cognitive bottleneck in this\ntask. Further, by systematically manipulating the model's hypotheses through\npedagogically-inspired interventions, we find that the model substantially\nupdates its causal understanding of opponent behavior, revealing how\nmodel-based analyses can produce testable hypotheses about human cognition.", "AI": {"tldr": "\u7814\u7a76\u4eba\u7c7b\u5728\u77f3\u5934\u526a\u5200\u5e03\u91cd\u590d\u6e38\u620f\u4e2d\u9884\u6d4b\u5bf9\u624b\u884c\u4e3a\u7684\u80fd\u529b\u53ca\u8ba1\u7b97\u9650\u5236\uff0c\u7528HM\u6a21\u578b\u6a21\u62df\u4eba\u7c7b\u8868\u73b0\uff0c\u63ed\u793a\u51c6\u786e\u5047\u8bbe\u751f\u6210\u662f\u4e3b\u8981\u8ba4\u77e5\u74f6\u9888\u3002", "motivation": "\u63a2\u7a76\u4eba\u7c7b\u5982\u4f55\u4ece\u884c\u4e3a\u6a21\u5f0f\u9884\u6d4b\u4ed6\u4eba\u4ee5\u53ca\u9650\u5236\u8be5\u80fd\u529b\u7684\u8ba1\u7b97\u7ea6\u675f\u3002", "method": "\u5bf9Brockbank & Vul (2024)\u7684\u77f3\u5934\u526a\u5200\u5e03\u91cd\u590d\u6e38\u620f\u6570\u636e\u5efa\u6a21\uff0c\u7528HM\u6a21\u578b\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\uff0c\u8fdb\u884c\u6d88\u878d\u548c\u589e\u5f3a\u5b9e\u9a8c\uff0c\u901a\u8fc7\u6559\u5b66\u5e72\u9884\u64cd\u7eb5\u6a21\u578b\u5047\u8bbe\u3002", "result": "HM\u6a21\u578b\u8868\u73b0\u4e0e\u4eba\u7c7b\u76f8\u4f3c\uff0c\u63d0\u4f9b\u5bf9\u624b\u7b56\u7565\u63cf\u8ff0\u65f6\u80fd\u6210\u529f\u51fb\u8d25\u591a\u6570\u5bf9\u624b\uff0c\u6559\u5b66\u5e72\u9884\u53ef\u4f7f\u6a21\u578b\u66f4\u65b0\u5bf9\u5bf9\u624b\u884c\u4e3a\u7684\u56e0\u679c\u7406\u89e3\u3002", "conclusion": "\u51c6\u786e\u5047\u8bbe\u751f\u6210\u662f\u8be5\u4efb\u52a1\u7684\u4e3b\u8981\u8ba4\u77e5\u74f6\u9888\uff0c\u57fa\u4e8e\u6a21\u578b\u7684\u5206\u6790\u53ef\u4ea7\u751f\u5173\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u7684\u53ef\u68c0\u9a8c\u5047\u8bbe\u3002"}}
{"id": "2508.07333", "pdf": "https://arxiv.org/pdf/2508.07333", "abs": "https://arxiv.org/abs/2508.07333", "authors": ["Yuhao Liu", "Rui Hu", "Yu Chen", "Longbo Huang"], "title": "Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants", "categories": ["cs.LG"], "comment": null, "summary": "Stochastic interpolants offer a robust framework for continuously\ntransforming samples between arbitrary data distributions, holding significant\npromise for generative modeling. Despite their potential, rigorous finite-time\nconvergence guarantees for practical numerical schemes remain largely\nunexplored. In this work, we address the finite-time convergence analysis of\nnumerical implementations for ordinary differential equations (ODEs) derived\nfrom stochastic interpolants. Specifically, we establish novel finite-time\nerror bounds in total variation distance for two widely used numerical\nintegrators: the first-order forward Euler method and the second-order Heun's\nmethod. Furthermore, our analysis on the iteration complexity of specific\nstochastic interpolant constructions provides optimized schedules to enhance\ncomputational efficiency. Our theoretical findings are corroborated by\nnumerical experiments, which validate the derived error bounds and complexity\nanalyses.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u968f\u673a\u63d2\u503c\u5668ODE\u6570\u503c\u5b9e\u73b0\u7684\u6709\u9650\u65f6\u95f4\u6536\u655b\u5206\u6790\uff0c\u7ed9\u51fa\u4e24\u79cd\u6570\u503c\u79ef\u5206\u5668\u8bef\u5dee\u754c\uff0c\u5206\u6790\u8fed\u4ee3\u590d\u6742\u5ea6\u5e76\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u968f\u673a\u63d2\u503c\u5668\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u5b9e\u8df5\u6570\u503c\u65b9\u6848\u7684\u6709\u9650\u65f6\u95f4\u6536\u655b\u4fdd\u8bc1\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u5bf9\u5176ODE\u6570\u503c\u5b9e\u73b0\u8fdb\u884c\u6709\u9650\u65f6\u95f4\u6536\u655b\u5206\u6790\u3002", "method": "\u4e3a\u4e00\u9636\u524d\u5411\u6b27\u62c9\u6cd5\u548c\u4e8c\u9636Heun\u6cd5\u5efa\u7acb\u603b\u53d8\u5dee\u8ddd\u79bb\u7684\u6709\u9650\u65f6\u95f4\u8bef\u5dee\u754c\uff0c\u5206\u6790\u7279\u5b9a\u968f\u673a\u63d2\u503c\u5668\u6784\u9020\u7684\u8fed\u4ee3\u590d\u6742\u5ea6\u3002", "result": "\u5f97\u51fa\u4e24\u79cd\u6570\u503c\u79ef\u5206\u5668\u7684\u6709\u9650\u65f6\u95f4\u8bef\u5dee\u754c\u548c\u7279\u5b9a\u968f\u673a\u63d2\u503c\u5668\u6784\u9020\u7684\u8fed\u4ee3\u590d\u6742\u5ea6\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "\u7406\u8bba\u5206\u6790\u6709\u6548\uff0c\u5f97\u51fa\u7684\u8bef\u5dee\u754c\u548c\u590d\u6742\u5ea6\u5206\u6790\u53ef\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2508.06504", "pdf": "https://arxiv.org/pdf/2508.06504", "abs": "https://arxiv.org/abs/2508.06504", "authors": ["Yao Ge", "Sudeshna Das", "Yuting Guo", "Abeed Sarker"], "title": "Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models", "categories": ["cs.CL", "cs.AI"], "comment": "31 pages, 4 figures, 15 tables", "summary": "Biomedical named entity recognition (NER) is a high-utility natural language\nprocessing (NLP) task, and large language models (LLMs) show promise\nparticularly in few-shot settings (i.e., limited training data). In this\narticle, we address the performance challenges of LLMs for few-shot biomedical\nNER by investigating a dynamic prompting strategy involving retrieval-augmented\ngeneration (RAG). In our approach, the annotated in-context learning examples\nare selected based on their similarities with the input texts, and the prompt\nis dynamically updated for each instance during inference. We implemented and\noptimized static and dynamic prompt engineering techniques and evaluated them\non five biomedical NER datasets. Static prompting with structured components\nincreased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA\n3-70B, relative to basic static prompting. Dynamic prompting further improved\nperformance, with TF-IDF and SBERT retrieval methods yielding the best results,\nimproving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,\nrespectively. These findings highlight the utility of contextually adaptive\nprompts via RAG for biomedical NER.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u52a8\u6001\u63d0\u793a\u7b56\u7565\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u751f\u7269\u533b\u5b66\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u52a8\u6001\u63d0\u793a\u6548\u679c\u66f4\u4f73\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u751f\u7269\u533b\u5b66\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e2d\u7684\u6027\u80fd\u6311\u6218\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u52a8\u6001\u63d0\u793a\u7b56\u7565\uff0c\u6839\u636e\u8f93\u5165\u6587\u672c\u76f8\u4f3c\u5ea6\u9009\u62e9\u4e0a\u4e0b\u6587\u5b66\u4e60\u793a\u4f8b\u5e76\u52a8\u6001\u66f4\u65b0\u63d0\u793a\uff0c\u5b9e\u73b0\u5e76\u4f18\u5316\u9759\u6001\u548c\u52a8\u6001\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u3002", "result": "\u7ed3\u6784\u5316\u7ec4\u4ef6\u7684\u9759\u6001\u63d0\u793a\u4f7fGPT - 4\u3001GPT - 3.5\u548cLLaMA 3 - 70B\u7684\u5e73\u5747F1\u5206\u6570\u63d0\u5347\uff0c\u52a8\u6001\u63d0\u793a\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\uff0cTF - IDF\u548cSBERT\u68c0\u7d22\u65b9\u6cd5\u6548\u679c\u6700\u4f73\u3002", "conclusion": "\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u63d0\u793a\u5bf9\u751f\u7269\u533b\u5b66\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6709\u7528\u3002"}}
{"id": "2508.07345", "pdf": "https://arxiv.org/pdf/2508.07345", "abs": "https://arxiv.org/abs/2508.07345", "authors": ["Samiha Afaf Neha", "Abir Ahammed Bhuiyan", "Md. Ishrak Khan"], "title": "ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "\\textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is\nessential for genomic studies due to their crucial role as structural elements\nin bacteriophages. Computational tools, particularly machine learning, have\nemerged for annotating phage protein sequences from high-throughput sequencing.\nHowever, effective annotation requires specialized sequence encodings. Our\npaper introduces ProteoKnight, a new image-based encoding method that addresses\nspatial constraints in existing techniques, yielding competitive performance in\nPVP classification using pre-trained convolutional neural networks.\nAdditionally, our study evaluates prediction uncertainty in binary PVP\nclassification through Monte Carlo Dropout (MCD). \\textbf{Methods:}\nProteoKnight adapts the classical DNA-Walk algorithm for protein sequences,\nincorporating pixel colors and adjusting walk distances to capture intricate\nprotein features. Encoded sequences were classified using multiple pre-trained\nCNNs. Variance and entropy measures assessed prediction uncertainty across\nproteins of various classes and lengths. \\textbf{Results:} Our experiments\nachieved 90.8% accuracy in binary classification, comparable to\nstate-of-the-art methods. Multi-class classification accuracy remains\nsuboptimal. Our uncertainty analysis unveils variability in prediction\nconfidence influenced by protein class and sequence length.\n\\textbf{Conclusions:} Our study surpasses frequency chaos game representation\n(FCGR) by introducing novel image encoding that mitigates spatial information\nloss limitations. Our classification technique yields accurate and robust PVP\npredictions while identifying low-confidence predictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faProteoKnight\u56fe\u50cf\u7f16\u7801\u65b9\u6cd5\u7528\u4e8e\u566c\u83cc\u4f53\u75c5\u6bd2\u7c92\u5b50\u86cb\u767d\uff08PVP\uff09\u5206\u7c7b\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3CNN\u5b9e\u73b0\u8f83\u597d\u4e8c\u5206\u7c7b\u6548\u679c\uff0c\u5e76\u8bc4\u4f30\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u51c6\u786e\u9884\u6d4bPVP\u5bf9\u57fa\u56e0\u7ec4\u7814\u7a76\u5f88\u91cd\u8981\uff0c\u73b0\u6709\u8ba1\u7b97\u5de5\u5177\u9700\u4e13\u4e1a\u5e8f\u5217\u7f16\u7801\uff0c\u89e3\u51b3\u73b0\u6709\u6280\u672f\u7a7a\u95f4\u7ea6\u675f\u95ee\u9898\u3002", "method": "ProteoKnight\u6539\u7f16DNA - Walk\u7b97\u6cd5\u7528\u4e8e\u86cb\u767d\u8d28\u5e8f\u5217\uff0c\u7ed3\u5408\u50cf\u7d20\u989c\u8272\u548c\u8c03\u6574\u6b65\u957f\uff0c\u7528\u9884\u8bad\u7ec3CNN\u5206\u7c7b\uff0c\u7528\u65b9\u5dee\u548c\u71b5\u8bc4\u4f30\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u4e8c\u5206\u7c7b\u51c6\u786e\u7387\u8fbe90.8%\uff0c\u591a\u5206\u7c7b\u6548\u679c\u6b20\u4f73\uff0c\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u63ed\u793a\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u53d7\u86cb\u767d\u7c7b\u522b\u548c\u5e8f\u5217\u957f\u5ea6\u5f71\u54cd\u3002", "conclusion": "\u65b0\u56fe\u50cf\u7f16\u7801\u8d85\u8d8aFCGR\uff0c\u5206\u7c7b\u6280\u672f\u80fd\u51c6\u786e\u9c81\u68d2\u9884\u6d4bPVP\u5e76\u8bc6\u522b\u4f4e\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u3002"}}
{"id": "2508.07370", "pdf": "https://arxiv.org/pdf/2508.07370", "abs": "https://arxiv.org/abs/2508.07370", "authors": ["Sibylle Marcotte", "Gabriel Peyr\u00e9", "R\u00e9mi Gribonval"], "title": "Intrinsic training dynamics of deep neural networks", "categories": ["cs.LG"], "comment": null, "summary": "A fundamental challenge in the theory of deep learning is to understand\nwhether gradient-based training in high-dimensional parameter spaces can be\ncaptured by simpler, lower-dimensional structures, leading to so-called\nimplicit bias. As a stepping stone, we study when a gradient flow on a\nhigh-dimensional variable $\\theta$ implies an intrinsic gradient flow on a\nlower-dimensional variable $z = \\phi(\\theta)$, for an architecture-related\nfunction $\\phi$. We express a so-called intrinsic dynamic property and show how\nit is related to the study of conservation laws associated with the\nfactorization $\\phi$. This leads to a simple criterion based on the inclusion\nof kernels of linear maps which yields a necessary condition for this property\nto hold. We then apply our theory to general ReLU networks of arbitrary depth\nand show that, for any initialization, it is possible to rewrite the flow as an\nintrinsic dynamic in a lower dimension that depends only on $z$ and the\ninitialization, when $\\phi$ is the so-called path-lifting. In the case of\nlinear networks with $\\phi$ the product of weight matrices, so-called balanced\ninitializations are also known to enable such a dimensionality reduction; we\ngeneralize this result to a broader class of {\\em relaxed balanced}\ninitializations, showing that, in certain configurations, these are the\n\\emph{only} initializations that ensure the intrinsic dynamic property.\nFinally, for the linear neural ODE associated with the limit of infinitely deep\nlinear networks, with relaxed balanced initialization, we explicitly express\nthe corresponding intrinsic dynamics.", "AI": {"tldr": "\u7814\u7a76\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u68af\u5ea6\u6d41\u80fd\u5426\u6620\u5c04\u5230\u4f4e\u7ef4\u53d8\u91cf\u7684\u5185\u5728\u68af\u5ea6\u6d41\uff0c\u7ed9\u51fa\u51c6\u5219\u5e76\u5e94\u7528\u4e8eReLU\u7f51\u7edc\u3001\u7ebf\u6027\u7f51\u7edc\u548c\u7ebf\u6027\u795e\u7ecfODE\u3002", "motivation": "\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\u4e2d\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u80fd\u5426\u7531\u4f4e\u7ef4\u7ed3\u6784\u6355\u83b7\uff0c\u5373\u9690\u5f0f\u504f\u5dee\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5185\u5728\u52a8\u6001\u5c5e\u6027\uff0c\u901a\u8fc7\u7ebf\u6027\u6620\u5c04\u6838\u7684\u5305\u542b\u5173\u7cfb\u7ed9\u51fa\u5fc5\u8981\u6761\u4ef6\uff0c\u5c06\u7406\u8bba\u5e94\u7528\u4e8e\u4e0d\u540c\u7f51\u7edc\u3002", "result": "\u5728ReLU\u7f51\u7edc\u4e2d\u53ef\u5c06\u6d41\u91cd\u5199\u4e3a\u4f4e\u7ef4\u5185\u5728\u52a8\u6001\uff1b\u63a8\u5e7f\u7ebf\u6027\u7f51\u7edc\u7684\u964d\u7ef4\u7ed3\u679c\u5230\u66f4\u5e7f\u6cdb\u521d\u59cb\u5316\uff1b\u660e\u786e\u7ebf\u6027\u795e\u7ecfODE\u7684\u5185\u5728\u52a8\u6001\u3002", "conclusion": "\u7ed9\u51fa\u9ad8\u7ef4\u68af\u5ea6\u6d41\u5230\u4f4e\u7ef4\u5185\u5728\u68af\u5ea6\u6d41\u7684\u6761\u4ef6\uff0c\u63a8\u5e7f\u7ebf\u6027\u7f51\u7edc\u964d\u7ef4\u521d\u59cb\u5316\u8303\u56f4\u3002"}}
{"id": "2508.06528", "pdf": "https://arxiv.org/pdf/2508.06528", "abs": "https://arxiv.org/abs/2508.06528", "authors": ["Xiuliang Zhang", "Tadiwa Elisha Nyamasvisva", "Chuntao Liu"], "title": "A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages,6 figures", "summary": "Video-based behavior recognition is essential in fields such as public\nsafety, intelligent surveillance, and human-computer interaction. Traditional\n3D Convolutional Neural Network (3D CNN) effectively capture local\nspatiotemporal features but struggle with modeling long-range dependencies.\nConversely, Transformers excel at learning global contextual information but\nface challenges with high computational costs. To address these limitations, we\npropose a hybrid framework combining 3D CNN and Transformer architectures. The\n3D CNN module extracts low-level spatiotemporal features, while the Transformer\nmodule captures long-range temporal dependencies, with a fusion mechanism\nintegrating both representations. Evaluated on benchmark datasets, the proposed\nmodel outperforms traditional 3D CNN and standalone Transformers, achieving\nhigher recognition accuracy with manageable complexity. Ablation studies\nfurther validate the complementary strengths of the two modules. This hybrid\nframework offers an effective and scalable solution for video-based behavior\nrecognition.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u54083D CNN\u548cTransformer\u7684\u6df7\u5408\u6846\u67b6\u7528\u4e8e\u89c6\u9891\u884c\u4e3a\u8bc6\u522b\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf3D CNN\u96be\u4ee5\u5efa\u6a21\u957f\u8ddd\u79bb\u4f9d\u8d56\uff0cTransformer\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u7ed3\u54083D CNN\u548cTransformer\u67b6\u6784\u7684\u6df7\u5408\u6846\u67b6\uff0c3D CNN\u63d0\u53d6\u4f4e\u7ea7\u65f6\u7a7a\u7279\u5f81\uff0cTransformer\u6355\u83b7\u957f\u8ddd\u79bb\u65f6\u95f4\u4f9d\u8d56\uff0c\u7528\u878d\u5408\u673a\u5236\u6574\u5408\u4e24\u8005\u8868\u793a\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf3D CNN\u548c\u72ec\u7acb\u7684Transformer\uff0c\u4ee5\u53ef\u7ba1\u7406\u7684\u590d\u6742\u5ea6\u5b9e\u73b0\u66f4\u9ad8\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e24\u6a21\u5757\u4e92\u8865\u4f18\u52bf\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u4e3a\u89c6\u9891\u884c\u4e3a\u8bc6\u522b\u63d0\u4f9b\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07395", "pdf": "https://arxiv.org/pdf/2508.07395", "abs": "https://arxiv.org/abs/2508.07395", "authors": ["Behnoush Khavari", "Mehran Shakerinava", "Jayesh Khullar", "Jerry Huang", "Fran\u00e7ois Rivest", "Siamak Ravanbakhsh", "Sarath Chandar"], "title": "Parity Requires Unified Input Dependence and Negative Eigenvalues in SSMs", "categories": ["cs.LG", "68Q32"], "comment": "5 pages. Accepted at ICML 2025 Workshop on Methods and Opportunities\n  at Small Scale", "summary": "Recent work has shown that LRNN models such as S4D, Mamba, and DeltaNet lack\nstate-tracking capability due to either time-invariant transition matrices or\nrestricted eigenvalue ranges. To address this, input-dependent transition\nmatrices, particularly those that are complex or non-triangular, have been\nproposed to enhance SSM performance on such tasks. While existing theorems\ndemonstrate that both input-independent and non-negative SSMs are incapable of\nsolving simple state-tracking tasks, such as parity, regardless of depth, they\ndo not explore whether combining these two types in a multilayer SSM could\nhelp. We investigate this question for efficient SSMs with diagonal transition\nmatrices and show that such combinations still fail to solve parity. This\nimplies that a recurrence layer must both be input-dependent and include\nnegative eigenvalues. Our experiments support this conclusion by analyzing an\nSSM model that combines S4D and Mamba layers.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u73b0\u6709LRNN\u6a21\u578b\u7f3a\u72b6\u6001\u8ddf\u8e2a\u80fd\u529b\uff0c\u7814\u7a76\u591a\u5c42SSM\u7ed3\u5408\u4e24\u79cd\u7c7b\u578b\u80fd\u5426\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u7ed3\u679c\u663e\u793a\u4ecd\u5931\u8d25\uff0c\u610f\u5473\u7740\u9012\u5f52\u5c42\u9700\u8f93\u5165\u4f9d\u8d56\u4e14\u542b\u8d1f\u7279\u5f81\u503c\u3002", "motivation": "\u73b0\u6709LRNN\u6a21\u578b\u5982S4D\u3001Mamba\u7b49\u56e0\u65f6\u4e0d\u53d8\u8f6c\u79fb\u77e9\u9635\u6216\u53d7\u9650\u7279\u5f81\u503c\u8303\u56f4\u7f3a\u4e4f\u72b6\u6001\u8ddf\u8e2a\u80fd\u529b\uff0c\u73b0\u6709\u5b9a\u7406\u672a\u63a2\u8ba8\u591a\u5c42SSM\u7ed3\u5408\u4e24\u79cd\u7c7b\u578b\u80fd\u5426\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u9488\u5bf9\u5177\u6709\u5bf9\u89d2\u8f6c\u79fb\u77e9\u9635\u7684\u9ad8\u6548SSM\u8fdb\u884c\u7814\u7a76\uff0c\u5e76\u5206\u6790\u7ed3\u5408S4D\u548cMamba\u5c42\u7684SSM\u6a21\u578b\u3002", "result": "\u591a\u5c42SSM\u7ed3\u5408\u4e24\u79cd\u7c7b\u578b\u4ecd\u65e0\u6cd5\u89e3\u51b3\u5947\u5076\u6027\u95ee\u9898\u3002", "conclusion": "\u9012\u5f52\u5c42\u5fc5\u987b\u540c\u65f6\u5177\u5907\u8f93\u5165\u4f9d\u8d56\u6027\u548c\u5305\u542b\u8d1f\u7279\u5f81\u503c\u3002"}}
{"id": "2508.06533", "pdf": "https://arxiv.org/pdf/2508.06533", "abs": "https://arxiv.org/abs/2508.06533", "authors": ["Aamod Thakur", "Ajay Nagpal", "Atharva Savarkar", "Kundeshwar Pundalik", "Siddhesh Dosi", "Piyush Sawarkar", "Viraj Thakur", "Rohit Saluja", "Maunendra Sankar Desarkar", "Ganesh Ramakrishnan"], "title": "The Art of Breaking Words: Rethinking Multilingual Tokenizer Design", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While model architecture and training objectives are well-studied,\ntokenization, particularly in multilingual contexts, remains a relatively\nneglected aspect of Large Language Model (LLM) development. Existing tokenizers\noften exhibit high token-to-word ratios, inefficient use of context length, and\nslower inference. We present a systematic study that links vocabulary size,\npre-tokenization rules, and training-corpus composition to both token-to-word\nefficiency and model quality. To ground our analysis in a linguistically\ndiverse context, we conduct extensive experiments on Indic scripts, which\npresent unique challenges due to their high script diversity and orthographic\ncomplexity. Drawing on the insights from these analyses, we propose a novel\nalgorithm for data composition that balances multilingual data for tokenizer\ntraining. Our observations on pretokenization strategies significantly improve\nmodel performance, and our data composition algorithm reduces the average\ntoken-to-word ratio by approximately 6% with respect to the conventional data\nrandomization approach. Our tokenizer achieves more than 40% improvement on\naverage token-to-word ratio against stateof-the-art multilingual Indic models.\nThis improvement yields measurable gains in both model performance and\ninference speed. This highlights tokenization alongside architecture and\ntraining objectives as a critical lever for building efficient, scalable\nmultilingual LLMs", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5206\u8bcd\uff0c\u5bf9\u5370\u5730\u8bed\u811a\u672c\u5b9e\u9a8c\uff0c\u63d0\u51fa\u6570\u636e\u7ec4\u5408\u7b97\u6cd5\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u5206\u8bcd\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u4e2d\u88ab\u76f8\u5bf9\u5ffd\u89c6\uff0c\u73b0\u6709\u5206\u8bcd\u5668\u5b58\u5728\u9ad8\u8bcd\u7b26\u6bd4\u3001\u4e0a\u4e0b\u6587\u957f\u5ea6\u5229\u7528\u4f4e\u6548\u548c\u63a8\u7406\u6162\u7b49\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u8bcd\u6c47\u5927\u5c0f\u3001\u9884\u5206\u8bcd\u89c4\u5219\u548c\u8bad\u7ec3\u8bed\u6599\u7ec4\u6210\u4e0e\u8bcd\u7b26\u6548\u7387\u53ca\u6a21\u578b\u8d28\u91cf\u7684\u5173\u7cfb\uff0c\u5bf9\u5370\u5730\u8bed\u811a\u672c\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u63d0\u51fa\u65b0\u578b\u6570\u636e\u7ec4\u5408\u7b97\u6cd5\u3002", "result": "\u9884\u5206\u8bcd\u7b56\u7565\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u6570\u636e\u7ec4\u5408\u7b97\u6cd5\u4f7f\u5e73\u5747\u8bcd\u7b26\u6bd4\u76f8\u5bf9\u4e8e\u4f20\u7edf\u65b9\u6cd5\u964d\u4f4e\u7ea66%\uff0c\u6bd4\u73b0\u6709\u591a\u8bed\u8a00\u5370\u5730\u8bed\u6a21\u578b\u5e73\u5747\u8bcd\u7b26\u6bd4\u63d0\u9ad8\u8d8540%\u3002", "conclusion": "\u5206\u8bcd\u4e0e\u67b6\u6784\u548c\u8bad\u7ec3\u76ee\u6807\u4e00\u6837\uff0c\u662f\u6784\u5efa\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2508.07400", "pdf": "https://arxiv.org/pdf/2508.07400", "abs": "https://arxiv.org/abs/2508.07400", "authors": ["Mohamad Louai Shehab", "Alperen Tercan", "Necmiye Ozay"], "title": "Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we consider the problem of recovering time-varying reward\nfunctions from either optimal policies or demonstrations coming from a max\nentropy reinforcement learning problem. This problem is highly ill-posed\nwithout additional assumptions on the underlying rewards. However, in many\napplications, the rewards are indeed parsimonious, and some prior information\nis available. We consider two such priors on the rewards: 1) rewards are mostly\nconstant and they change infrequently, 2) rewards can be represented by a\nlinear combination of a small number of feature functions. We first show that\nthe reward identification problem with the former prior can be recast as a\nsparsification problem subject to linear constraints. Moreover, we give a\npolynomial-time algorithm that solves this sparsification problem exactly.\nThen, we show that identifying rewards representable with the minimum number of\nfeatures can be recast as a rank minimization problem subject to linear\nconstraints, for which convex relaxations of rank can be invoked. In both\ncases, these observations lead to efficient optimization-based reward\nidentification algorithms. Several examples are given to demonstrate the\naccuracy of the recovered rewards as well as their generalizability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4ece\u6700\u4f18\u7b56\u7565\u6216\u6700\u5927\u71b5\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u7684\u6f14\u793a\u4e2d\u6062\u590d\u65f6\u53d8\u5956\u52b1\u51fd\u6570\uff0c\u5229\u7528\u5956\u52b1\u7684\u4e24\u79cd\u5148\u9a8c\u4fe1\u606f\u63d0\u51fa\u9ad8\u6548\u4f18\u5316\u7b97\u6cd5\u5e76\u4e3e\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u6062\u590d\u65f6\u53d8\u5956\u52b1\u51fd\u6570\u95ee\u9898\u5728\u65e0\u989d\u5916\u5047\u8bbe\u65f6\u662f\u75c5\u6001\u7684\uff0c\u800c\u5b9e\u9645\u4e2d\u5956\u52b1\u5177\u6709\u7b80\u7ea6\u6027\u4e14\u6709\u5148\u9a8c\u4fe1\u606f\uff0c\u9700\u5229\u7528\u5148\u9a8c\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u8003\u8651\u5956\u52b1\u7684\u4e24\u79cd\u5148\u9a8c\uff0c\u5c06\u5956\u52b1\u8bc6\u522b\u95ee\u9898\u5206\u522b\u8f6c\u5316\u4e3a\u7ebf\u6027\u7ea6\u675f\u4e0b\u7684\u7a00\u758f\u5316\u95ee\u9898\u548c\u79e9\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5206\u522b\u7528\u7cbe\u786e\u6c42\u89e3\u548c\u51f8\u677e\u5f1b\u65b9\u6cd5\u89e3\u51b3\u3002", "result": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u4f18\u5316\u7684\u5956\u52b1\u8bc6\u522b\u9ad8\u6548\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f8b\u5b50\u8bc1\u660e\u4e86\u6062\u590d\u5956\u52b1\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u6027\u3002", "conclusion": "\u5229\u7528\u5956\u52b1\u7684\u5148\u9a8c\u4fe1\u606f\u53ef\u5c06\u5956\u52b1\u8bc6\u522b\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u6c42\u89e3\u7684\u4f18\u5316\u95ee\u9898\uff0c\u6240\u63d0\u7b97\u6cd5\u6709\u6548\u3002"}}
{"id": "2508.06534", "pdf": "https://arxiv.org/pdf/2508.06534", "abs": "https://arxiv.org/abs/2508.06534", "authors": ["Aishan Liu", "Jiakai Wang", "Tianyuan Zhang", "Hainan Li", "Jiangfan Liu", "Siyuan Liang", "Yilong Ren", "Xianglong Liu", "Dacheng Tao"], "title": "MetAdv: A Unified and Interactive Adversarial Testing Platform for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted by ACM MM 2025 Demo/Videos track", "summary": "Evaluating and ensuring the adversarial robustness of autonomous driving (AD)\nsystems is a critical and unresolved challenge. This paper introduces MetAdv, a\nnovel adversarial testing platform that enables realistic, dynamic, and\ninteractive evaluation by tightly integrating virtual simulation with physical\nvehicle feedback. At its core, MetAdv establishes a hybrid virtual-physical\nsandbox, within which we design a three-layer closed-loop testing environment\nwith dynamic adversarial test evolution. This architecture facilitates\nend-to-end adversarial evaluation, ranging from high-level unified adversarial\ngeneration, through mid-level simulation-based interaction, to low-level\nexecution on physical vehicles. Additionally, MetAdv supports a broad spectrum\nof AD tasks, algorithmic paradigms (e.g., modular deep learning pipelines,\nend-to-end learning, vision-language models). It supports flexible 3D vehicle\nmodeling and seamless transitions between simulated and physical environments,\nwith built-in compatibility for commercial platforms such as Apollo and Tesla.\nA key feature of MetAdv is its human-in-the-loop capability: besides flexible\nenvironmental configuration for more customized evaluation, it enables\nreal-time capture of physiological signals and behavioral feedback from\ndrivers, offering new insights into human-machine trust under adversarial\nconditions. We believe MetAdv can offer a scalable and unified framework for\nadversarial assessment, paving the way for safer AD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u578b\u5bf9\u6297\u6d4b\u8bd5\u5e73\u53f0MetAdv\uff0c\u53ef\u7ed3\u5408\u865a\u62df\u4eff\u771f\u4e0e\u7269\u7406\u8f66\u8f86\u53cd\u9988\u8fdb\u884c\u5bf9\u6297\u6027\u8bc4\u4f30\uff0c\u652f\u6301\u591a\u79cdAD\u4efb\u52a1\u548c\u7b97\u6cd5\u8303\u5f0f\uff0c\u6709\u4eba\u5728\u73af\u80fd\u529b\uff0c\u4e3a\u5b89\u5168AD\u63d0\u4f9b\u6846\u67b6\u3002", "motivation": "\u8bc4\u4f30\u548c\u786e\u4fdd\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u662f\u5173\u952e\u4e14\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002", "method": "\u5efa\u7acb\u6df7\u5408\u865a\u62df - \u7269\u7406\u6c99\u76d2\uff0c\u8bbe\u8ba1\u4e09\u5c42\u95ed\u73af\u6d4b\u8bd5\u73af\u5883\uff0c\u652f\u6301\u591a\u79cdAD\u4efb\u52a1\u548c\u7b97\u6cd5\u8303\u5f0f\uff0c\u5177\u5907\u4eba\u5728\u73af\u80fd\u529b\u3002", "result": "MetAdv\u80fd\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u5bf9\u6297\u8bc4\u4f30\uff0c\u652f\u6301\u7075\u6d3b3D\u8f66\u8f86\u5efa\u6a21\u548c\u73af\u5883\u5207\u6362\uff0c\u53ef\u5b9e\u65f6\u6355\u83b7\u9a7e\u9a76\u5458\u4fe1\u53f7\u548c\u53cd\u9988\u3002", "conclusion": "MetAdv\u53ef\u4e3a\u5bf9\u6297\u6027\u8bc4\u4f30\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u4e3a\u66f4\u5b89\u5168\u7684\u81ea\u52a8\u9a7e\u9a76\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2508.07428", "pdf": "https://arxiv.org/pdf/2508.07428", "abs": "https://arxiv.org/abs/2508.07428", "authors": ["Md Sultanul Arifin", "Abu Nowshed Sakib", "Yeasir Rayhan", "Tanzima Hashem"], "title": "Lightning Prediction under Uncertainty: DeepLight with Hazy Loss", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Lightning, a common feature of severe meteorological conditions, poses\nsignificant risks, from direct human injuries to substantial economic losses.\nThese risks are further exacerbated by climate change. Early and accurate\nprediction of lightning would enable preventive measures to safeguard people,\nprotect property, and minimize economic losses. In this paper, we present\nDeepLight, a novel deep learning architecture for predicting lightning\noccurrences. Existing prediction models face several critical limitations: they\noften struggle to capture the dynamic spatial context and inherent uncertainty\nof lightning events, underutilize key observational data, such as radar\nreflectivity and cloud properties, and rely heavily on Numerical Weather\nPrediction (NWP) systems, which are both computationally expensive and highly\nsensitive to parameter settings. To overcome these challenges, DeepLight\nleverages multi-source meteorological data, including radar reflectivity, cloud\nproperties, and historical lightning occurrences through a dual-encoder\narchitecture. By employing multi-branch convolution techniques, it dynamically\ncaptures spatial correlations across varying extents. Furthermore, its novel\nHazy Loss function explicitly addresses the spatio-temporal uncertainty of\nlightning by penalizing deviations based on proximity to true events, enabling\nthe model to better learn patterns amidst randomness. Extensive experiments\nshow that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over\nstate-of-the-art methods, establishing it as a robust solution for lightning\nprediction.", "AI": {"tldr": "\u63d0\u51faDeepLight\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u7528\u4e8e\u95ea\u7535\u9884\u6d4b\uff0c\u514b\u670d\u73b0\u6709\u6a21\u578b\u5c40\u9650\uff0c\u5b9e\u9a8c\u663e\u793a\u5176ETS\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534718%-30%\u3002", "motivation": "\u95ea\u7535\u5e26\u6765\u91cd\u5927\u98ce\u9669\u4e14\u53d7\u6c14\u5019\u53d8\u5316\u52a0\u5267\uff0c\u73b0\u6709\u9884\u6d4b\u6a21\u578b\u5b58\u5728\u8bf8\u591a\u5c40\u9650\uff0c\u9700\u8981\u65e9\u671f\u51c6\u786e\u7684\u95ea\u7535\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5229\u7528\u591a\u6e90\u6c14\u8c61\u6570\u636e\uff0c\u8fd0\u7528\u591a\u5206\u652f\u5377\u79ef\u6280\u672f\u6355\u6349\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u4f7f\u7528\u65b0\u578bHazy Loss\u51fd\u6570\u5904\u7406\u65f6\u7a7a\u4e0d\u786e\u5b9a\u6027\u3002", "result": "DeepLight\u4f7f\u516c\u5e73\u5a01\u80c1\u8bc4\u5206\uff08ETS\uff09\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad818%-30%\u3002", "conclusion": "DeepLight\u662f\u4e00\u79cd\u7528\u4e8e\u95ea\u7535\u9884\u6d4b\u7684\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06538", "pdf": "https://arxiv.org/pdf/2508.06538", "abs": "https://arxiv.org/abs/2508.06538", "authors": ["Gioele Buriani", "Jingyue Liu", "Maximilian St\u00f6lzle", "Cosimo Della Santina", "Jiatao Ding"], "title": "Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "8 pages, under review", "summary": "Reduced-order models are essential for motion planning and control of\nquadruped robots, as they simplify complex dynamics while preserving critical\nbehaviors. This paper introduces a novel methodology for deriving such\ninterpretable dynamic models, specifically for jumping. We capture the\nhigh-dimensional, nonlinear jumping dynamics in a low-dimensional latent space\nby proposing a learning architecture combining Sparse Identification of\nNonlinear Dynamics (SINDy) with physical structural priors on the jump\ndynamics. Our approach demonstrates superior accuracy to the traditional\nactuated Spring-loaded Inverted Pendulum (aSLIP) model and is validated through\nsimulation and hardware experiments across different jumping strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u63a8\u5bfc\u56db\u8db3\u673a\u5668\u4eba\u8df3\u8dc3\u53ef\u89e3\u91ca\u52a8\u529b\u5b66\u964d\u9636\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u964d\u9636\u6a21\u578b\u5bf9\u56db\u8db3\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u548c\u63a7\u5236\u81f3\u5173\u91cd\u8981\uff0c\u9700\u4e00\u79cd\u63a8\u5bfc\u8df3\u8dc3\u53ef\u89e3\u91ca\u52a8\u529b\u5b66\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7ed3\u5408Sparse Identification of Nonlinear Dynamics (SINDy)\u548c\u8df3\u8dc3\u52a8\u529b\u5b66\u7269\u7406\u7ed3\u6784\u5148\u9a8c\u7684\u5b66\u4e60\u67b6\u6784\uff0c\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u6355\u83b7\u9ad8\u7ef4\u975e\u7ebf\u6027\u8df3\u8dc3\u52a8\u529b\u5b66\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u7684\u9a71\u52a8\u5f39\u7c27\u5012\u7acb\u6446(aSLIP)\u6a21\u578b\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u901a\u8fc7\u4e0d\u540c\u8df3\u8dc3\u7b56\u7565\u7684\u4eff\u771f\u548c\u786c\u4ef6\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u56db\u8db3\u673a\u5668\u4eba\u8df3\u8dc3\u7684\u53ef\u89e3\u91ca\u52a8\u529b\u5b66\u964d\u9636\u6a21\u578b\u63a8\u5bfc\u3002"}}
{"id": "2508.07440", "pdf": "https://arxiv.org/pdf/2508.07440", "abs": "https://arxiv.org/abs/2508.07440", "authors": ["Zhipeng Chang", "Zhenye Wen", "Xiaofei Zhao"], "title": "Unsupervised operator learning approach for dissipative equations via Onsager principle", "categories": ["cs.LG"], "comment": null, "summary": "Existing operator learning methods rely on supervised training with\nhigh-fidelity simulation data, introducing significant computational cost. In\nthis work, we propose the deep Onsager operator learning (DOOL) method, a novel\nunsupervised framework for solving dissipative equations. Rooted in the Onsager\nvariational principle (OVP), DOOL trains a deep operator network by directly\nminimizing the OVP-defined Rayleighian functional, requiring no labeled data,\nand then proceeds in time explicitly through conservation/change laws for the\nsolution. Another key innovation here lies in the spatiotemporal decoupling\nstrategy: the operator's trunk network processes spatial coordinates\nexclusively, thereby enhancing training efficiency, while integrated external\ntime stepping enables temporal extrapolation. Numerical experiments on typical\ndissipative equations validate the effectiveness of the DOOL method, and\nsystematic comparisons with supervised DeepONet and MIONet demonstrate its\nenhanced performance. Extensions are made to cover the second-order wave models\nwith dissipation that do not directly follow OVP.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u76d1\u7763\u7684\u6df1\u5ea6Onsager\u7b97\u5b50\u5b66\u4e60\uff08DOOL\uff09\u65b9\u6cd5\u89e3\u8017\u6563\u65b9\u7a0b\uff0c\u9a8c\u8bc1\u6709\u6548\u6027\u5e76\u5c55\u793a\u6027\u80fd\u4f18\u52bf\uff0c\u8fd8\u8fdb\u884c\u4e86\u6269\u5c55\u3002", "motivation": "\u73b0\u6709\u7b97\u5b50\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u4fdd\u771f\u6a21\u62df\u6570\u636e\u7684\u76d1\u7763\u8bad\u7ec3\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u57fa\u4e8eOnsager\u53d8\u5206\u539f\u7406\uff0c\u76f4\u63a5\u6700\u5c0f\u5316Rayleighian\u6cdb\u51fd\u8bad\u7ec3\u6df1\u5ea6\u7b97\u5b50\u7f51\u7edc\uff0c\u91c7\u7528\u65f6\u7a7a\u89e3\u8026\u7b56\u7565\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86DOOL\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e0e\u76d1\u7763\u7684DeepONet\u548cMIONet\u76f8\u6bd4\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "DOOL\u65b9\u6cd5\u662f\u89e3\u51b3\u8017\u6563\u65b9\u7a0b\u7684\u6709\u6548\u65e0\u76d1\u7763\u6846\u67b6\uff0c\u8fd8\u53ef\u6269\u5c55\u5230\u4e8c\u9636\u8017\u6563\u6ce2\u6a21\u578b\u3002"}}
{"id": "2508.07452", "pdf": "https://arxiv.org/pdf/2508.07452", "abs": "https://arxiv.org/abs/2508.07452", "authors": ["Fernando Martinez", "Tao Li", "Yingdong Lu", "Juntao Chen"], "title": "Stackelberg Coupling of Online Representation Learning and Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Integrated, end-to-end learning of representations and policies remains a\ncornerstone of deep reinforcement learning (RL). However, to address the\nchallenge of learning effective features from a sparse reward signal, recent\ntrends have shifted towards adding complex auxiliary objectives or fully\ndecoupling the two processes, often at the cost of increased design complexity.\nThis work proposes an alternative to both decoupling and naive end-to-end\nlearning, arguing that performance can be significantly improved by structuring\nthe interaction between distinct perception and control networks with a\nprincipled, game-theoretic dynamic. We formalize this dynamic by introducing\nthe Stackelberg Coupled Representation and Reinforcement Learning (SCORER)\nframework, which models the interaction between perception and control as a\nStackelberg game. The perception network (leader) strategically learns features\nto benefit the control network (follower), whose own objective is to minimize\nits Bellman error. We approximate the game's equilibrium with a practical\ntwo-timescale algorithm. Applied to standard DQN variants on benchmark tasks,\nSCORER improves sample efficiency and final performance. Our results show that\nperformance gains can be achieved through principled algorithmic design of the\nperception-control dynamic, without requiring complex auxiliary objectives or\narchitectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCORER\u6846\u67b6\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u52a8\u6001\u6784\u5efa\u611f\u77e5\u4e0e\u63a7\u5236\u7f51\u7edc\u4ea4\u4e92\uff0c\u63d0\u5347\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u65e0\u9700\u590d\u6742\u8f85\u52a9\u76ee\u6807\u6216\u67b6\u6784\u3002", "motivation": "\u89e3\u51b3\u4ece\u7a00\u758f\u5956\u52b1\u4fe1\u53f7\u5b66\u4e60\u6709\u6548\u7279\u5f81\u7684\u6311\u6218\uff0c\u907f\u514d\u73b0\u6709\u65b9\u6cd5\u589e\u52a0\u8bbe\u8ba1\u590d\u6742\u5ea6\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165Stackelberg Coupled Representation and Reinforcement Learning (SCORER)\u6846\u67b6\uff0c\u5c06\u611f\u77e5\u4e0e\u63a7\u5236\u7684\u4ea4\u4e92\u5efa\u6a21\u4e3aStackelberg\u535a\u5f08\uff0c\u7528\u53cc\u65f6\u95f4\u5c3a\u5ea6\u7b97\u6cd5\u8fd1\u4f3c\u535a\u5f08\u5747\u8861\u3002", "result": "\u5e94\u7528\u4e8e\u6807\u51c6DQN\u53d8\u4f53\u5728\u57fa\u51c6\u4efb\u52a1\u4e0a\uff0c\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u6700\u7ec8\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u611f\u77e5 - \u63a7\u5236\u52a8\u6001\u8fdb\u884c\u6709\u539f\u5219\u7684\u7b97\u6cd5\u8bbe\u8ba1\u53ef\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\uff0c\u65e0\u9700\u590d\u6742\u8f85\u52a9\u76ee\u6807\u6216\u67b6\u6784\u3002"}}
{"id": "2508.06566", "pdf": "https://arxiv.org/pdf/2508.06566", "abs": "https://arxiv.org/abs/2508.06566", "authors": ["Manish Kansana", "Elias Hossain", "Shahram Rahimi", "Noorbakhsh Amiri Golilarz"], "title": "Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Surface material recognition is a key component in robotic perception and\nphysical interaction, particularly when leveraging both tactile and visual\nsensory inputs. In this work, we propose Surformer v1, a transformer-based\narchitecture designed for surface classification using structured tactile\nfeatures and PCA-reduced visual embeddings extracted via ResNet-50. The model\nintegrates modality-specific encoders with cross-modal attention layers,\nenabling rich interactions between vision and touch. Currently,\nstate-of-the-art deep learning models for vision tasks have achieved remarkable\nperformance. With this in mind, our first set of experiments focused\nexclusively on tactile-only surface classification. Using feature engineering,\nwe trained and evaluated multiple machine learning models, assessing their\naccuracy and inference time. We then implemented an encoder-only Transformer\nmodel tailored for tactile features. This model not only achieved the highest\naccuracy but also demonstrated significantly faster inference time compared to\nother evaluated models, highlighting its potential for real-time applications.\nTo extend this investigation, we introduced a multimodal fusion setup by\ncombining vision and tactile inputs. We trained both Surformer v1 (using\nstructured features) and Multimodal CNN (using raw images) to examine the\nimpact of feature-based versus image-based multimodal learning on\nclassification accuracy and computational efficiency. The results showed that\nSurformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while\nthe Multimodal CNN achieved slightly higher accuracy but required significantly\nmore inference time. These findings suggest Surformer v1 offers a compelling\nbalance between accuracy, efficiency, and computational cost for surface\nmaterial recognition.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSurformer v1\u7528\u4e8e\u8868\u9762\u6750\u6599\u8bc6\u522b\uff0c\u5148\u8fdb\u884c\u4ec5\u89e6\u89c9\u5206\u7c7b\u5b9e\u9a8c\uff0c\u540e\u5f15\u5165\u591a\u6a21\u6001\u878d\u5408\uff0c\u7ed3\u679c\u663e\u793aSurformer v1\u5728\u51c6\u786e\u7387\u3001\u6548\u7387\u548c\u8ba1\u7b97\u6210\u672c\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u611f\u77e5\u548c\u7269\u7406\u4ea4\u4e92\u4e2d\u8868\u9762\u6750\u6599\u8bc6\u522b\u95ee\u9898\uff0c\u5229\u7528\u89e6\u89c9\u548c\u89c6\u89c9\u8f93\u5165\u8fdb\u884c\u8868\u9762\u5206\u7c7b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684Surformer v1\u67b6\u6784\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u89e6\u89c9\u7279\u5f81\u548cPCA\u964d\u7ef4\u7684\u89c6\u89c9\u5d4c\u5165\uff1b\u5148\u8fdb\u884c\u4ec5\u89e6\u89c9\u5206\u7c7b\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548cTransformer\u6a21\u578b\uff1b\u518d\u5f15\u5165\u591a\u6a21\u6001\u878d\u5408\uff0c\u8bad\u7ec3Surformer v1\u548cMultimodal CNN\u3002", "result": "\u4ec5\u89e6\u89c9\u5206\u7c7b\u4e2dTransformer\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u3001\u63a8\u7406\u65f6\u95f4\u5feb\uff1b\u591a\u6a21\u6001\u878d\u5408\u4e2dSurformer v1\u51c6\u786e\u7387\u8fbe99.4%\uff0c\u63a8\u7406\u65f6\u95f40.77 ms\uff0cMultimodal CNN\u51c6\u786e\u7387\u7a0d\u9ad8\u4f46\u63a8\u7406\u65f6\u95f4\u957f\u3002", "conclusion": "Surformer v1\u5728\u8868\u9762\u6750\u6599\u8bc6\u522b\u4e2d\u80fd\u5728\u51c6\u786e\u7387\u3001\u6548\u7387\u548c\u8ba1\u7b97\u6210\u672c\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2508.07458", "pdf": "https://arxiv.org/pdf/2508.07458", "abs": "https://arxiv.org/abs/2508.07458", "authors": ["Wei Qian", "Chenxu Zhao", "Yangyi Li", "Wenqian Ye", "Mengdi Huai"], "title": "Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten", "categories": ["cs.LG"], "comment": null, "summary": "Currently, various uncertainty quantification methods have been proposed to\nprovide certainty and probability estimates for deep learning models' label\npredictions. Meanwhile, with the growing demand for the right to be forgotten,\nmachine unlearning has been extensively studied as a means to remove the impact\nof requested sensitive data from a pre-trained model without retraining the\nmodel from scratch. However, the vulnerabilities of such generated predictive\nuncertainties with regard to dedicated malicious unlearning attacks remain\nunexplored. To bridge this gap, for the first time, we propose a new class of\nmalicious unlearning attacks against predictive uncertainties, where the\nadversary aims to cause the desired manipulations of specific predictive\nuncertainty results. We also design novel optimization frameworks for our\nattacks and conduct extensive experiments, including black-box scenarios.\nNotably, our extensive experiments show that our attacks are more effective in\nmanipulating predictive uncertainties than traditional attacks that focus on\nlabel misclassifications, and existing defenses against conventional attacks\nare ineffective against our attacks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u9488\u5bf9\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u6076\u610f\u9057\u5fd8\u653b\u51fb\uff0c\u8bbe\u8ba1\u4f18\u5316\u6846\u67b6\u5e76\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u653b\u51fb\u6bd4\u4f20\u7edf\u653b\u51fb\u66f4\u6709\u6548\u4e14\u73b0\u6709\u9632\u5fa1\u65e0\u6548\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u63a2\u7d22\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u5728\u6076\u610f\u9057\u5fd8\u653b\u51fb\u4e0b\u7684\u6f0f\u6d1e\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u9488\u5bf9\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u65b0\u578b\u6076\u610f\u9057\u5fd8\u653b\u51fb\uff0c\u8bbe\u8ba1\u653b\u51fb\u7684\u4f18\u5316\u6846\u67b6\uff0c\u5e76\u8fdb\u884c\u5305\u62ec\u9ed1\u76d2\u573a\u666f\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "\u653b\u51fb\u5728\u64cd\u7eb5\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u6bd4\u4e13\u6ce8\u6807\u7b7e\u9519\u8bef\u5206\u7c7b\u7684\u4f20\u7edf\u653b\u51fb\u66f4\u6709\u6548\uff0c\u73b0\u6709\u9488\u5bf9\u4f20\u7edf\u653b\u51fb\u7684\u9632\u5fa1\u5bf9\u8be5\u653b\u51fb\u65e0\u6548\u3002", "conclusion": "\u65b0\u578b\u6076\u610f\u9057\u5fd8\u653b\u51fb\u5bf9\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6709\u66f4\u6709\u6548\u7684\u64cd\u7eb5\u80fd\u529b\uff0c\u73b0\u6709\u9632\u5fa1\u624b\u6bb5\u4e0d\u8db3\u3002"}}
{"id": "2508.06572", "pdf": "https://arxiv.org/pdf/2508.06572", "abs": "https://arxiv.org/abs/2508.06572", "authors": ["Nikolaos Avouris", "Kyriakos Sgarbas", "George Caridakis", "Christos Sintoris"], "title": "Teaching Introduction to Programming in the times of AI: A case study of a course re-design", "categories": ["cs.CY", "cs.AI"], "comment": "To be cited as: Avouris, N., Sgarbas, K., Caridakis, G., Sintoris,\n  C., (2025). Teaching Introduction to Programming in the times of AI: A case\n  study of a course re-design, Proceedings 12th Penhellenic Conference of\n  Computer Science Education, PCCSE 2025, Rhodes, October 2025", "summary": "The integration of AI tools into programming education has become\nincreasingly prevalent in recent years, transforming the way programming is\ntaught and learned. This paper provides a review of the state-of-the-art AI\ntools available for teaching and learning programming, particularly in the\ncontext of introductory courses. It highlights the challenges on course design,\nlearning objectives, course delivery and formative and summative assessment, as\nwell as the misuse of such tools by the students. We discuss ways of\nre-designing an existing course, re-shaping assignments and pedagogy to address\nthe current AI technologies challenges. This example can serve as a guideline\nfor policies for institutions and teachers involved in teaching programming,\naiming to maximize the benefits of AI tools while addressing the associated\nchallenges and concerns.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u7f16\u7a0b\u6559\u80b2\u4e2dAI\u5de5\u5177\uff0c\u6307\u51fa\u6311\u6218\u5e76\u8ba8\u8bba\u5e94\u5bf9\u65b9\u6cd5\uff0c\u4e3a\u6559\u5b66\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "AI\u5de5\u5177\u878d\u5165\u7f16\u7a0b\u6559\u80b2\u65e5\u76ca\u666e\u904d\uff0c\u9700\u63a2\u8ba8\u5176\u5728\u6559\u5b66\u4e2d\u7684\u5e94\u7528\u53ca\u5e94\u5bf9\u6311\u6218\u3002", "method": "\u5bf9\u7f16\u7a0b\u6559\u80b2\u4e2dAI\u5de5\u5177\u8fdb\u884c\u7efc\u8ff0\uff0c\u5206\u6790\u8bfe\u7a0b\u8bbe\u8ba1\u7b49\u65b9\u9762\u6311\u6218\u5e76\u8ba8\u8bba\u5e94\u5bf9\u65b9\u6cd5\u3002", "result": "\u660e\u786e\u4e86AI\u5de5\u5177\u5728\u7f16\u7a0b\u6559\u5b66\u4e2d\u7684\u6311\u6218\uff0c\u5982\u8bfe\u7a0b\u8bbe\u8ba1\u3001\u5b66\u751f\u6ee5\u7528\u7b49\u95ee\u9898\u3002", "conclusion": "\u8ba8\u8bba\u7684\u5e94\u5bf9\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u673a\u6784\u548c\u6559\u5e08\u6559\u5b66\u653f\u7b56\u7684\u6307\u5bfc\uff0c\u4ee5\u6700\u5927\u5316AI\u5de5\u5177\u6548\u76ca\u5e76\u89e3\u51b3\u76f8\u5173\u95ee\u9898\u3002"}}
{"id": "2508.06575", "pdf": "https://arxiv.org/pdf/2508.06575", "abs": "https://arxiv.org/abs/2508.06575", "authors": ["Rui Zhou"], "title": "Efficient Safety Testing of Autonomous Vehicles via Adaptive Search over Crash-Derived Scenarios", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Ensuring the safety of autonomous vehicles (AVs) is paramount in their\ndevelopment and deployment. Safety-critical scenarios pose more severe\nchallenges, necessitating efficient testing methods to validate AVs safety.\nThis study focuses on designing an accelerated testing algorithm for AVs in\nsafety-critical scenarios, enabling swift recognition of their driving\ncapabilities. First, typical logical scenarios were extracted from real-world\ncrashes in the China In-depth Mobility Safety Study-Traffic Accident (CIMSS-TA)\ndatabase, obtaining pre-crash features through reconstruction. Second, Baidu\nApollo, an advanced black-box automated driving system (ADS) is integrated to\ncontrol the behavior of the ego vehicle. Third, we proposed an adaptive\nlarge-variable neighborhood-simulated annealing algorithm (ALVNS-SA) to\nexpedite the testing process. Experimental results demonstrate a significant\nenhancement in testing efficiency when utilizing ALVNS-SA. It achieves an\n84.00% coverage of safety-critical scenarios, with crash scenario coverage of\n96.83% and near-crash scenario coverage of 92.07%. Compared to genetic\nalgorithm (GA), adaptive large neighborhood-simulated annealing algorithm\n(ALNS-SA), and random testing, ALVNS-SA exhibits substantially higher coverage\nin safety-critical scenarios.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u8bbe\u8ba1\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u52a0\u901f\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u63d0\u51faALVNS - SA\u7b97\u6cd5\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u3002", "motivation": "\u786e\u4fdd\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u5b89\u5168\u5173\u952e\u573a\u666f\u5bf9\u6d4b\u8bd5\u65b9\u6cd5\u63d0\u51fa\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u6d4b\u8bd5\u65b9\u6cd5\u9a8c\u8bc1\u5176\u5b89\u5168\u6027\u3002", "method": "\u4eceCIMSS - TA\u6570\u636e\u5e93\u63d0\u53d6\u5178\u578b\u903b\u8f91\u573a\u666f\u5e76\u91cd\u6784\u83b7\u53d6\u9884\u78b0\u649e\u7279\u5f81\uff1b\u96c6\u6210\u767e\u5ea6Apollo\u63a7\u5236\u81ea\u8f66\u884c\u4e3a\uff1b\u63d0\u51fa\u81ea\u9002\u5e94\u5927\u53d8\u91cf\u90bb\u57df\u6a21\u62df\u9000\u706b\u7b97\u6cd5\uff08ALVNS - SA\uff09\u52a0\u901f\u6d4b\u8bd5\u3002", "result": "\u4f7f\u7528ALVNS - SA\u7b97\u6cd5\u6d4b\u8bd5\u6548\u7387\u663e\u8457\u63d0\u5347\uff0c\u5b89\u5168\u5173\u952e\u573a\u666f\u8986\u76d6\u7387\u8fbe84.00%\uff0c\u78b0\u649e\u573a\u666f\u8986\u76d6\u738796.83%\uff0c\u8fd1\u78b0\u649e\u573a\u666f\u8986\u76d6\u738792.07%\uff0c\u6bd4\u9057\u4f20\u7b97\u6cd5\u7b49\u8986\u76d6\u7387\u66f4\u9ad8\u3002", "conclusion": "ALVNS - SA\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u6d4b\u8bd5\u6548\u7387\u548c\u8986\u76d6\u7387\u3002"}}
{"id": "2508.06577", "pdf": "https://arxiv.org/pdf/2508.06577", "abs": "https://arxiv.org/abs/2508.06577", "authors": ["Juan Zambrano", "Cl\u00e9ment Contet", "Jairo Gudi\u00f1o", "Felipe Garrido-Lucero", "Umberto Grandi", "Cesar A Hidalgo"], "title": "Leveraging LLMs for Privacy-Aware Predictions in Participatory Budgeting", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Participatory Budgeting (PB) empowers citizens to propose and vote on public\ninvestment projects. Yet, despite its democratic potential, PB initiatives\noften suffer from low participation rates, limiting their visibility and\nperceived legitimacy. In this work, we aim to strengthen PB elections in two\nkey ways: by supporting project proposers in crafting better proposals, and by\nhelping PB organizers manage large volumes of submissions in a transparent\nmanner. We propose a privacy-preserving approach to predict which PB proposals\nare likely to be funded, using only their textual descriptions and anonymous\nhistorical voting records -- without relying on voter demographics or\npersonally identifiable information. We evaluate the performance of GPT 4 Turbo\nin forecasting proposal outcomes across varying contextual scenarios, observing\nthat the LLM's prior knowledge needs to be complemented by past voting data to\nobtain predictions reflecting real-world PB voting behavior. Our findings\nhighlight the potential of AI-driven tools to support PB processes by improving\ntransparency, planning efficiency, and civic engagement.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u7528\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u9884\u6d4b\u53c2\u4e0e\u5f0f\u9884\u7b97\uff08PB\uff09\u63d0\u6848\u662f\u5426\u4f1a\u83b7\u6279\uff0c\u8bc4\u4f30GPT 4 Turbo\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u9884\u6d4b\u63d0\u6848\u7ed3\u679c\u7684\u8868\u73b0\uff0c\u5f3a\u8c03AI\u5de5\u5177\u5bf9PB\u6d41\u7a0b\u7684\u652f\u6301\u6f5c\u529b\u3002", "motivation": "PB\u5021\u8bae\u5e38\u56e0\u53c2\u4e0e\u7387\u4f4e\u9650\u5236\u5176\u53ef\u89c1\u6027\u548c\u5408\u6cd5\u6027\uff0c\u65e8\u5728\u901a\u8fc7\u652f\u6301\u63d0\u6848\u8005\u548c\u5e2e\u52a9\u7ec4\u7ec7\u8005\u900f\u660e\u7ba1\u7406\u63d0\u4ea4\u5185\u5bb9\u6765\u52a0\u5f3aPB\u9009\u4e3e\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u4ec5\u5229\u7528\u63d0\u6848\u6587\u672c\u63cf\u8ff0\u548c\u533f\u540d\u5386\u53f2\u6295\u7968\u8bb0\u5f55\u9884\u6d4bPB\u63d0\u6848\u83b7\u6279\u53ef\u80fd\u6027\uff0c\u8bc4\u4f30GPT 4 Turbo\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u9884\u6d4b\u8868\u73b0\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5148\u9a8c\u77e5\u8bc6\u9700\u7ed3\u5408\u8fc7\u53bb\u6295\u7968\u6570\u636e\uff0c\u624d\u80fd\u83b7\u5f97\u53cd\u6620\u73b0\u5b9ePB\u6295\u7968\u884c\u4e3a\u7684\u9884\u6d4b\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u5de5\u5177\u53ef\u901a\u8fc7\u63d0\u9ad8\u900f\u660e\u5ea6\u3001\u89c4\u5212\u6548\u7387\u548c\u516c\u6c11\u53c2\u4e0e\u5ea6\u6765\u652f\u6301PB\u6d41\u7a0b\u3002"}}
{"id": "2508.06583", "pdf": "https://arxiv.org/pdf/2508.06583", "abs": "https://arxiv.org/abs/2508.06583", "authors": ["Ying Liu", "Can Li", "Ting Zhang", "Mei Wang", "Qiannan Zhu", "Jian Li", "Hua Huang"], "title": "Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The conversational capabilities of large language models hold significant\npromise for enabling scalable and interactive tutoring. While prior research\nhas primarily examined their capacity for Socratic questioning, it often\noverlooks a critical dimension: adaptively guiding learners based on their\ncognitive states. This study shifts focus from mere question generation to the\nbroader instructional guidance capability. We ask: Can LLMs emulate expert\ntutors who dynamically adjust strategies in response to learners'\nunderstanding? To investigate this, we propose GuideEval, a benchmark grounded\nin authentic educational dialogues that evaluates pedagogical guidance through\na three-phase behavioral framework: (1) Perception, inferring learner states;\n(2) Orchestration, adapting instructional strategies; and (3) Elicitation,\nstimulating proper reflections. Empirical findings reveal that existing LLMs\nfrequently fail to provide effective adaptive scaffolding when learners exhibit\nconfusion or require redirection. Furthermore, we introduce a behavior-guided\nfinetuning strategy that leverages behavior-prompted instructional dialogues,\nsignificantly enhancing guidance performance. By shifting the focus from\nisolated content evaluation to learner-centered interaction, our work advocates\na more dialogic paradigm for evaluating Socratic LLMs.", "AI": {"tldr": "\u7814\u7a76\u4ece\u5355\u7eaf\u95ee\u9898\u751f\u6210\u8f6c\u5411\u6559\u5b66\u6307\u5bfc\u80fd\u529b\u8bc4\u4f30\uff0c\u63d0\u51faGuideEval\u57fa\u51c6\uff0c\u53d1\u73b0\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u9002\u5e94\u652f\u6301\u4e0a\u4e0d\u8db3\uff0c\u5f15\u5165\u5fae\u8c03\u7b56\u7565\u63d0\u5347\u6027\u80fd\uff0c\u5021\u5bfc\u4ee5\u5b66\u4e60\u8005\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u8303\u5f0f\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u591a\u5173\u6ce8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u82cf\u683c\u62c9\u5e95\u5f0f\u63d0\u95ee\u80fd\u529b\uff0c\u5ffd\u7565\u57fa\u4e8e\u5b66\u4e60\u8005\u8ba4\u77e5\u72b6\u6001\u7684\u81ea\u9002\u5e94\u6307\u5bfc\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5176\u80fd\u5426\u50cf\u4e13\u5bb6\u5bfc\u5e08\u4e00\u6837\u52a8\u6001\u8c03\u6574\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u771f\u5b9e\u6559\u80b2\u5bf9\u8bdd\u7684GuideEval\u57fa\u51c6\uff0c\u901a\u8fc7\u611f\u77e5\u3001\u7f16\u6392\u3001\u542f\u53d1\u4e09\u4e2a\u9636\u6bb5\u7684\u884c\u4e3a\u6846\u67b6\u8bc4\u4f30\u6559\u5b66\u6307\u5bfc\uff0c\u8fd8\u5f15\u5165\u884c\u4e3a\u5f15\u5bfc\u7684\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b66\u4e60\u8005\u56f0\u60d1\u6216\u9700\u5f15\u5bfc\u65f6\uff0c\u5e38\u65e0\u6cd5\u63d0\u4f9b\u6709\u6548\u81ea\u9002\u5e94\u652f\u6301\uff1b\u884c\u4e3a\u5f15\u5bfc\u7684\u5fae\u8c03\u7b56\u7565\u663e\u8457\u63d0\u5347\u6307\u5bfc\u6027\u80fd\u3002", "conclusion": "\u5e94\u4ece\u5b64\u7acb\u5185\u5bb9\u8bc4\u4f30\u8f6c\u5411\u4ee5\u5b66\u4e60\u8005\u4e3a\u4e2d\u5fc3\u7684\u4ea4\u4e92\u8bc4\u4f30\uff0c\u5021\u5bfc\u66f4\u5bf9\u8bdd\u5f0f\u7684\u8bc4\u4f30\u8303\u5f0f\u3002"}}
{"id": "2508.07536", "pdf": "https://arxiv.org/pdf/2508.07536", "abs": "https://arxiv.org/abs/2508.07536", "authors": ["Tasfiq E. Alam", "Md Manjurul Ahsan", "Shivakumar Raman"], "title": "Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning", "categories": ["cs.LG"], "comment": null, "summary": "Accurate and interpretable bearing fault classification is critical for\nensuring the reliability of rotating machinery, particularly under variable\noperating conditions where domain shifts can significantly degrade model\nperformance. This study proposes a physics-informed multimodal convolutional\nneural network (CNN) with a late fusion architecture, integrating vibration and\nmotor current signals alongside a dedicated physics-based feature extraction\nbranch. The model incorporates a novel physics-informed loss function that\npenalizes physically implausible predictions based on characteristic bearing\nfault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency\nInner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive\nexperiments on the Paderborn University dataset demonstrate that the proposed\nphysics-informed approach consistently outperforms a non-physics-informed\nbaseline, achieving higher accuracy, reduced false classifications, and\nimproved robustness across multiple data splits. To address performance\ndegradation under unseen operating conditions, three transfer learning (TL)\nstrategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy\n(LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS\nyields the best generalization, with additional performance gains when combined\nwith physics-informed modeling. Validation on the KAIST bearing dataset\nconfirms the framework's cross-dataset applicability, achieving up to 98\npercent accuracy. Statistical hypothesis testing further verifies significant\nimprovements (p < 0.01) in classification performance. The proposed framework\ndemonstrates the potential of integrating domain knowledge with data-driven\nlearning to achieve robust, interpretable, and generalizable fault diagnosis\nfor real-world industrial applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u591a\u6a21\u6001CNN\u7528\u4e8e\u8f74\u627f\u6545\u969c\u5206\u7c7b\uff0c\u7ed3\u5408\u632f\u52a8\u548c\u7535\u6d41\u4fe1\u53f7\u53ca\u7269\u7406\u7279\u5f81\u63d0\u53d6\u5206\u652f\uff0c\u7528\u65b0\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u65e0\u7269\u7406\u4fe1\u606f\u57fa\u7ebf\uff0c\u8bc4\u4f30\u4e09\u79cd\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\uff0cLAS\u6cdb\u5316\u6027\u6700\u4f73\uff0c\u9a8c\u8bc1\u4e86\u8de8\u6570\u636e\u96c6\u9002\u7528\u6027\u548c\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5728\u53ef\u53d8\u5de5\u51b5\u4e0b\uff0c\u9886\u57df\u504f\u79fb\u4f1a\u964d\u4f4e\u6a21\u578b\u6027\u80fd\uff0c\u9700\u8981\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u8f74\u627f\u6545\u969c\u5206\u7c7b\u65b9\u6cd5\u786e\u4fdd\u65cb\u8f6c\u673a\u68b0\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u5e26\u540e\u671f\u878d\u5408\u67b6\u6784\u7684\u7269\u7406\u4fe1\u606f\u591a\u6a21\u6001CNN\uff0c\u7ed3\u5408\u632f\u52a8\u548c\u7535\u6d41\u4fe1\u53f7\u53ca\u7269\u7406\u7279\u5f81\u63d0\u53d6\u5206\u652f\uff0c\u4f7f\u7528\u57fa\u4e8e\u7279\u5f81\u9891\u7387\u7684\u7269\u7406\u4fe1\u606f\u635f\u5931\u51fd\u6570\uff0c\u8bc4\u4f30\u4e09\u79cd\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u7269\u7406\u4fe1\u606f\u65b9\u6cd5\u4f18\u4e8e\u65e0\u7269\u7406\u4fe1\u606f\u57fa\u7ebf\uff0cLAS\u6cdb\u5316\u6027\u6700\u4f73\uff0c\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u5efa\u6a21\u6709\u989d\u5916\u6027\u80fd\u63d0\u5347\uff0c\u8de8\u6570\u636e\u96c6\u9a8c\u8bc1\u53ef\u8fbe98%\u51c6\u786e\u7387\uff0c\u7edf\u8ba1\u68c0\u9a8c\u663e\u793a\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u5c55\u793a\u4e86\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u548c\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7528\u4e8e\u73b0\u5b9e\u5de5\u4e1a\u5e94\u7528\u4e2d\u5b9e\u73b0\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6cdb\u5316\u6545\u969c\u8bca\u65ad\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.07555", "pdf": "https://arxiv.org/pdf/2508.07555", "abs": "https://arxiv.org/abs/2508.07555", "authors": ["Keyuan Zhang", "Yin Sun", "Bo Ji"], "title": "Multimodal Remote Inference", "categories": ["cs.LG", "cs.IT", "cs.NI", "math.IT"], "comment": "Accepted by The 22nd IEEE International Conference on Mobile Ad-Hoc\n  and Smart Systems (MASS 2025)", "summary": "We consider a remote inference system with multiple modalities, where a\nmultimodal machine learning (ML) model performs real-time inference using\nfeatures collected from remote sensors. As sensor observations may change\ndynamically over time, fresh features are critical for inference tasks.\nHowever, timely delivering features from all modalities is often infeasible due\nto limited network resources. To this end, we study a two-modality scheduling\nproblem to minimize the ML model's inference error, which is expressed as a\npenalty function of AoI for both modalities. We develop an index-based\nthreshold policy and prove its optimality. Specifically, the scheduler switches\nmodalities when the current modality's index function exceeds a threshold. We\nshow that the two modalities share the same threshold, and both the index\nfunctions and the threshold can be computed efficiently. The optimality of our\npolicy holds for (i) general AoI functions that are \\emph{non-monotonic} and\n\\emph{non-additive} and (ii) \\emph{heterogeneous} transmission times. Numerical\nresults show that our policy reduces inference error by up to 55% compared to\nround-robin and uniform random policies, which are oblivious to the AoI-based\ninference error function. Our results shed light on how to improve remote\ninference accuracy by optimizing task-oriented AoI functions.", "AI": {"tldr": "\u7814\u7a76\u591a\u6a21\u6001\u8fdc\u7a0b\u63a8\u7406\u7cfb\u7edf\u4e2d\u4e24\u6a21\u6001\u8c03\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u7d22\u5f15\u7684\u9608\u503c\u7b56\u7565\u5e76\u8bc1\u660e\u5176\u6700\u4f18\u6027\uff0c\u6570\u503c\u7ed3\u679c\u663e\u793a\u8be5\u7b56\u7565\u53ef\u5927\u5e45\u964d\u4f4e\u63a8\u7406\u8bef\u5dee\u3002", "motivation": "\u5728\u591a\u6a21\u6001\u8fdc\u7a0b\u63a8\u7406\u7cfb\u7edf\u4e2d\uff0c\u56e0\u7f51\u7edc\u8d44\u6e90\u6709\u9650\u96be\u4ee5\u53ca\u65f6\u4f20\u8f93\u5404\u6a21\u6001\u7279\u5f81\uff0c\u4e3a\u51cf\u5c11\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63a8\u7406\u8bef\u5dee\u800c\u7814\u7a76\u4e24\u6a21\u6001\u8c03\u5ea6\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7d22\u5f15\u7684\u9608\u503c\u7b56\u7565\uff0c\u5f53\u5f53\u524d\u6a21\u6001\u7684\u7d22\u5f15\u51fd\u6570\u8d85\u8fc7\u9608\u503c\u65f6\u5207\u6362\u6a21\u6001\uff0c\u8bc1\u660e\u8be5\u7b56\u7565\u5728\u4e00\u822c\u975e\u5355\u8c03\u975e\u52a0\u6027\u7684AoI\u51fd\u6570\u548c\u5f02\u6784\u4f20\u8f93\u65f6\u95f4\u4e0b\u7684\u6700\u4f18\u6027\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b56\u7565\u76f8\u6bd4\u8f6e\u8be2\u548c\u5747\u5300\u968f\u673a\u7b56\u7565\uff0c\u63a8\u7406\u8bef\u5dee\u6700\u591a\u964d\u4f4e55%\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u9762\u5411\u4efb\u52a1\u7684AoI\u51fd\u6570\u53ef\u63d0\u9ad8\u8fdc\u7a0b\u63a8\u7406\u51c6\u786e\u6027\u3002"}}
{"id": "2508.06592", "pdf": "https://arxiv.org/pdf/2508.06592", "abs": "https://arxiv.org/abs/2508.06592", "authors": ["Ben Y. Reis", "William La Cava"], "title": "Towards Integrated Alignment", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As AI adoption expands across human society, the problem of aligning AI\nmodels to match human preferences remains a grand challenge. Currently, the AI\nalignment field is deeply divided between behavioral and representational\napproaches, resulting in narrowly aligned models that are more vulnerable to\nincreasingly deceptive misalignment threats. In the face of this fragmentation,\nwe propose an integrated vision for the future of the field. Drawing on related\nlessons from immunology and cybersecurity, we lay out a set of design\nprinciples for the development of Integrated Alignment frameworks that combine\nthe complementary strengths of diverse alignment approaches through deep\nintegration and adaptive coevolution. We highlight the importance of strategic\ndiversity - deploying orthogonal alignment and misalignment detection\napproaches to avoid homogeneous pipelines that may be \"doomed to success\". We\nalso recommend steps for greater unification of the AI alignment research field\nitself, through cross-collaboration, open model weights and shared community\nresources.", "AI": {"tldr": "\u968f\u7740AI\u666e\u53ca\uff0cAI\u5bf9\u9f50\u95ee\u9898\u4e25\u5cfb\uff0c\u63d0\u51fa\u6574\u5408\u613f\u666f\u3001\u8bbe\u8ba1\u539f\u5219\u53ca\u7edf\u4e00\u7814\u7a76\u9886\u57df\u7684\u5efa\u8bae\u3002", "motivation": "AI\u5bf9\u9f50\u9886\u57df\u5728\u884c\u4e3a\u548c\u8868\u5f81\u65b9\u6cd5\u4e0a\u5b58\u5728\u5206\u6b67\uff0c\u6a21\u578b\u6613\u53d7\u6b3a\u9a97\u6027\u5bf9\u9f50\u5a01\u80c1\u3002", "method": "\u501f\u9274\u514d\u75ab\u5b66\u548c\u7f51\u7edc\u5b89\u5168\u7684\u7ecf\u9a8c\uff0c\u63d0\u51fa\u7efc\u5408\u5bf9\u9f50\u6846\u67b6\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u5f3a\u8c03\u6218\u7565\u591a\u6837\u6027\uff0c\u5efa\u8bae\u8de8\u5408\u4f5c\u7b49\u7edf\u4e00\u7814\u7a76\u9886\u57df\u3002", "result": "\u63d0\u51fa\u7efc\u5408\u5bf9\u9f50\u6846\u67b6\u7684\u8bbe\u8ba1\u539f\u5219\u548c\u7edf\u4e00\u7814\u7a76\u9886\u57df\u7684\u6b65\u9aa4\u3002", "conclusion": "\u4e3aAI\u5bf9\u9f50\u9886\u57df\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u6574\u5408\u6027\u7684\u65b9\u5411\u548c\u5efa\u8bae\u3002"}}
{"id": "2508.07571", "pdf": "https://arxiv.org/pdf/2508.07571", "abs": "https://arxiv.org/abs/2508.07571", "authors": ["Xingwu Chen", "Miao Lu", "Beining Wu", "Difan Zou"], "title": "Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Using more test-time computation during language model inference, such as\ngenerating more intermediate thoughts or sampling multiple candidate answers,\nhas proven effective in significantly improving model performance. This paper\ntakes an initial step toward bridging the gap between practical language model\ninference and theoretical transformer analysis by incorporating randomness and\nsampling. We focus on in-context linear regression with continuous/binary\ncoefficients, where our framework simulates language model decoding through\nnoise injection and binary coefficient sampling. Through this framework, we\nprovide detailed analyses of widely adopted inference techniques. Supported by\nempirical results, our theoretical framework and analysis demonstrate the\npotential for offering new insights into understanding inference behaviors in\nreal-world language models.", "AI": {"tldr": "\u6587\u7ae0\u901a\u8fc7\u5f15\u5165\u968f\u673a\u6027\u548c\u91c7\u6837\uff0c\u5728\u4e0a\u4e0b\u6587\u7ebf\u6027\u56de\u5f52\u6846\u67b6\u4e0b\u5206\u6790\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6280\u672f\uff0c\u7406\u8bba\u4e0e\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u80fd\u4e3a\u7406\u89e3\u63a8\u7406\u884c\u4e3a\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002", "motivation": "\u7f29\u5c0f\u5b9e\u9645\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u7406\u8bba\u53d8\u538b\u5668\u5206\u6790\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5728\u4e0a\u4e0b\u6587\u7ebf\u6027\u56de\u5f52\u4e2d\uff0c\u901a\u8fc7\u566a\u58f0\u6ce8\u5165\u548c\u4e8c\u5143\u7cfb\u6570\u91c7\u6837\u6a21\u62df\u8bed\u8a00\u6a21\u578b\u89e3\u7801\uff0c\u5e76\u5206\u6790\u5e38\u7528\u63a8\u7406\u6280\u672f\u3002", "result": "\u7406\u8bba\u6846\u67b6\u548c\u5206\u6790\u5f97\u5230\u4e86\u5b9e\u8bc1\u7ed3\u679c\u7684\u652f\u6301\u3002", "conclusion": "\u7406\u8bba\u6846\u67b6\u548c\u5206\u6790\u6709\u6f5c\u529b\u4e3a\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u884c\u4e3a\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2508.06595", "pdf": "https://arxiv.org/pdf/2508.06595", "abs": "https://arxiv.org/abs/2508.06595", "authors": ["Xiaoyuan Zhu", "Muru Zhang", "Ollie Liu", "Robin Jia", "Willie Neiswanger"], "title": "LLM Unlearning Without an Expert Curated Dataset", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Modern large language models often encode sensitive, harmful, or copyrighted\nknowledge, raising the need for post-hoc unlearning-the ability to remove\nspecific domains of knowledge from a model without full retraining. A major\nbottleneck in current unlearning pipelines is constructing effective forget\nsets-datasets that approximate the target domain and guide the model to forget\nit. In this work, we introduce a scalable, automated approach to generate\nhigh-quality forget sets using language models themselves. Our method\nsynthesizes textbook-style data through a structured prompting pipeline,\nrequiring only a domain name as input. Through experiments on unlearning\nbiosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic\ndatasets consistently outperform the baseline synthetic alternatives and are\ncomparable to the expert-curated ones. Additionally, ablation studies reveal\nthat the multi-step generation pipeline significantly boosts data diversity,\nwhich in turn improves unlearning utility. Overall, our findings suggest that\nsynthetic datasets offer a promising path toward practical, scalable unlearning\nfor a wide range of emerging domains without the need for manual intervention.\nWe release our code and dataset at\nhttps://github.com/xyzhu123/Synthetic_Textbook.", "AI": {"tldr": "\u63d0\u51fa\u7528\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u9057\u5fd8\u96c6\u7684\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5408\u6210\u6570\u636e\u96c6\u8868\u73b0\u4f73\uff0c\u4e3a\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u5b9e\u7528\u53ef\u6269\u5c55\u9057\u5fd8\u5b66\u4e60\u63d0\u4f9b\u8def\u5f84\u3002", "motivation": "\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u9700\u4e8b\u540e\u9057\u5fd8\u7279\u5b9a\u77e5\u8bc6\uff0c\u4f46\u5f53\u524d\u9057\u5fd8\u5b66\u4e60\u6d41\u7a0b\u6784\u5efa\u6709\u6548\u9057\u5fd8\u96c6\u5b58\u5728\u74f6\u9888\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u7ba1\u9053\u5408\u6210\u6559\u79d1\u4e66\u5f0f\u6570\u636e\uff0c\u4ec5\u9700\u9886\u57df\u540d\u79f0\u4f5c\u4e3a\u8f93\u5165\u3002", "result": "\u5408\u6210\u6570\u636e\u96c6\u5728\u751f\u7269\u5b89\u5168\u3001\u7f51\u7edc\u5b89\u5168\u548c\u300a\u54c8\u5229\u00b7\u6ce2\u7279\u300b\u5c0f\u8bf4\u9057\u5fd8\u5b66\u4e60\u5b9e\u9a8c\u4e2d\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u5408\u6210\u66ff\u4ee3\u65b9\u6848\uff0c\u4e0e\u4e13\u5bb6\u7b56\u5212\u7684\u6570\u636e\u96c6\u76f8\u5f53\uff1b\u591a\u6b65\u751f\u6210\u7ba1\u9053\u53ef\u63d0\u5347\u6570\u636e\u591a\u6837\u6027\u548c\u9057\u5fd8\u5b66\u4e60\u6548\u7528\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u96c6\u4e3a\u5e7f\u6cdb\u65b0\u5174\u9886\u57df\u7684\u5b9e\u7528\u53ef\u6269\u5c55\u9057\u5fd8\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002"}}
{"id": "2508.07581", "pdf": "https://arxiv.org/pdf/2508.07581", "abs": "https://arxiv.org/abs/2508.07581", "authors": ["Nisha Chandramoorthy", "Adriaan de Clercq"], "title": "When and how can inexact generative models still sample from the data manifold?", "categories": ["cs.LG", "math.DS", "math.PR"], "comment": null, "summary": "A curious phenomenon observed in some dynamical generative models is the\nfollowing: despite learning errors in the score function or the drift vector\nfield, the generated samples appear to shift \\emph{along} the support of the\ndata distribution but not \\emph{away} from it. In this work, we investigate\nthis phenomenon of \\emph{robustness of the support} by taking a dynamical\nsystems approach on the generating stochastic/deterministic process. Our\nperturbation analysis of the probability flow reveals that infinitesimal\nlearning errors cause the predicted density to be different from the target\ndensity only on the data manifold for a wide class of generative models.\nFurther, what is the dynamical mechanism that leads to the robustness of the\nsupport? We show that the alignment of the top Lyapunov vectors (most sensitive\ninfinitesimal perturbation directions) with the tangent spaces along the\nboundary of the data manifold leads to robustness and prove a sufficient\ncondition on the dynamics of the generating process to achieve this alignment.\nMoreover, the alignment condition is efficient to compute and, in practice, for\nrobust generative models, automatically leads to accurate estimates of the\ntangent bundle of the data manifold. Using a finite-time linear perturbation\nanalysis on samples paths as well as probability flows, our work complements\nand extends existing works on obtaining theoretical guarantees for generative\nmodels from a stochastic analysis, statistical learning and uncertainty\nquantification points of view. Our results apply across different dynamical\ngenerative models, such as conditional flow-matching and score-based generative\nmodels, and for different target distributions that may or may not satisfy the\nmanifold hypothesis.", "AI": {"tldr": "\u672c\u6587\u91c7\u7528\u52a8\u529b\u7cfb\u7edf\u65b9\u6cd5\u7814\u7a76\u751f\u6210\u6a21\u578b\u4e2d\u652f\u6301\u9c81\u68d2\u6027\u73b0\u8c61\uff0c\u5206\u6790\u6982\u7387\u6d41\u6270\u52a8\uff0c\u63ed\u793a\u52a8\u529b\u673a\u5236\uff0c\u7ed9\u51fa\u5bf9\u9f50\u6761\u4ef6\uff0c\u7ed3\u679c\u9002\u7528\u4e8e\u4e0d\u540c\u6a21\u578b\u548c\u5206\u5e03\u3002", "motivation": "\u63a2\u7a76\u4e00\u4e9b\u52a8\u6001\u751f\u6210\u6a21\u578b\u4e2d\u5c3d\u7ba1\u5206\u6570\u51fd\u6570\u6216\u6f02\u79fb\u5411\u91cf\u573a\u5b58\u5728\u5b66\u4e60\u8bef\u5dee\uff0c\u4f46\u751f\u6210\u6837\u672c\u4ecd\u6cbf\u6570\u636e\u5206\u5e03\u652f\u6301\u79fb\u52a8\u800c\u975e\u504f\u79bb\u7684\u652f\u6301\u9c81\u68d2\u6027\u73b0\u8c61\u3002", "method": "\u5bf9\u751f\u6210\u7684\u968f\u673a/\u786e\u5b9a\u6027\u8fc7\u7a0b\u91c7\u7528\u52a8\u529b\u7cfb\u7edf\u65b9\u6cd5\uff0c\u8fdb\u884c\u6982\u7387\u6d41\u7684\u6270\u52a8\u5206\u6790\uff0c\u5bf9\u6837\u672c\u8def\u5f84\u548c\u6982\u7387\u6d41\u8fdb\u884c\u6709\u9650\u65f6\u95f4\u7ebf\u6027\u6270\u52a8\u5206\u6790\u3002", "result": "\u65e0\u7a77\u5c0f\u5b66\u4e60\u8bef\u5dee\u4ec5\u4f7f\u9884\u6d4b\u5bc6\u5ea6\u5728\u6570\u636e\u6d41\u5f62\u4e0a\u4e0e\u76ee\u6807\u5bc6\u5ea6\u4e0d\u540c\uff1b\u6570\u636e\u6d41\u5f62\u8fb9\u754c\u5207\u7a7a\u95f4\u4e0e\u9876\u7ea7\u674e\u96c5\u666e\u8bfa\u592b\u5411\u91cf\u5bf9\u9f50\u5bfc\u81f4\u652f\u6301\u9c81\u68d2\u6027\uff1b\u5bf9\u9f50\u6761\u4ef6\u8ba1\u7b97\u9ad8\u6548\u4e14\u80fd\u81ea\u52a8\u51c6\u786e\u4f30\u8ba1\u6570\u636e\u6d41\u5f62\u5207\u4e1b\u3002", "conclusion": "\u4ece\u968f\u673a\u5206\u6790\u3001\u7edf\u8ba1\u5b66\u4e60\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u89d2\u5ea6\u8865\u5145\u548c\u6269\u5c55\u4e86\u751f\u6210\u6a21\u578b\u7406\u8bba\u4fdd\u8bc1\u7684\u73b0\u6709\u5de5\u4f5c\uff0c\u7ed3\u679c\u9002\u7528\u4e8e\u4e0d\u540c\u52a8\u6001\u751f\u6210\u6a21\u578b\u548c\u76ee\u6807\u5206\u5e03\u3002"}}
{"id": "2508.07629", "pdf": "https://arxiv.org/pdf/2508.07629", "abs": "https://arxiv.org/abs/2508.07629", "authors": ["Zhenpeng Su", "Leiyu Pan", "Xue Bai", "Dening Liu", "Guanting Dong", "Jiaming Huang", "Wenping Hu", "Guorui Zhou"], "title": "Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We present Klear-Reasoner, a model with long reasoning capabilities that\ndemonstrates careful deliberation during problem solving, achieving outstanding\nperformance across multiple benchmarks. Although there are already many\nexcellent works related to inference models in the current community, there are\nstill many problems with reproducing high-performance inference models due to\nincomplete disclosure of training details. This report provides an in-depth\nanalysis of the reasoning model, covering the entire post-training workflow\nfrom data preparation and long Chain-of-Thought supervised fine-tuning (long\nCoT SFT) to reinforcement learning (RL), along with detailed ablation studies\nfor each experimental component. For SFT data, our experiments show that a\nsmall number of high-quality data sources are more effective than a large\nnumber of diverse data sources, and that difficult samples can achieve better\nresults without accuracy filtering. In addition, we investigate two key issues\nwith current clipping mechanisms in RL: Clipping suppresses critical\nexploration signals and ignores suboptimal trajectories. To address these\nchallenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)\nthat gently backpropagates gradients from clipped tokens. GPPO not only\nenhances the model's exploration capacity but also improves its efficiency in\nlearning from negative samples. Klear-Reasoner exhibits exceptional reasoning\nabilities in mathematics and programming, scoring 90.5\\% on AIME 2024, 83.2\\%\non AIME 2025, 66.0\\% on LiveCodeBench V5 and 58.1\\% on LiveCodeBench V6.", "AI": {"tldr": "\u63d0\u51faKlear - Reasoner\u6a21\u578b\uff0c\u5206\u6790\u63a8\u7406\u6a21\u578b\u8bad\u7ec3\u6d41\u7a0b\uff0c\u6307\u51faSFT\u6570\u636e\u7279\u70b9\uff0c\u63d0\u51faGPPO\u89e3\u51b3RL\u88c1\u526a\u673a\u5236\u95ee\u9898\uff0c\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u793e\u533a\u63a8\u7406\u6a21\u578b\u8bad\u7ec3\u7ec6\u8282\u62ab\u9732\u4e0d\u5b8c\u6574\uff0c\u96be\u4ee5\u590d\u73b0\u9ad8\u6027\u80fd\u63a8\u7406\u6a21\u578b\u3002", "method": "\u6df1\u5165\u5206\u6790\u63a8\u7406\u6a21\u578b\u4ece\u6570\u636e\u51c6\u5907\u5230\u957f\u601d\u7ef4\u94fe\u76d1\u7763\u5fae\u8c03\u518d\u5230\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u6d41\u7a0b\uff0c\u63d0\u51faGradient - Preserving clipping Policy Optimization (GPPO)\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5c11\u91cf\u9ad8\u8d28\u91cfSFT\u6570\u636e\u6e90\u66f4\u6709\u6548\uff0c\u56f0\u96be\u6837\u672c\u4e0d\u505a\u7cbe\u5ea6\u8fc7\u6ee4\u6548\u679c\u66f4\u597d\uff1bKlear - Reasoner\u5728AIME 2024\u3001AIME 2025\u3001LiveCodeBench V5\u548cV6\u7b49\u57fa\u51c6\u6d4b\u8bd5\u53d6\u5f97\u9ad8\u5206\u6570\u3002", "conclusion": "Klear - Reasoner\u5177\u6709\u51fa\u8272\u7684\u63a8\u7406\u80fd\u529b\uff0cGPPO\u80fd\u589e\u5f3a\u6a21\u578b\u63a2\u7d22\u80fd\u529b\u548c\u4ece\u8d1f\u6837\u672c\u5b66\u4e60\u7684\u6548\u7387\u3002"}}
{"id": "2508.06616", "pdf": "https://arxiv.org/pdf/2508.06616", "abs": "https://arxiv.org/abs/2508.06616", "authors": ["Md Arafat Habib", "Medhat Elsayed", "Yigit Ozcan", "Pedro Enrique Iturria-Rivera", "Majid Bavand", "Melike Erol-Kantarci"], "title": "Generative AI for Intent-Driven Network Management in 6G: A Case Study on Hierarchical Learning Approach", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "With the emergence of 6G, mobile networks are becoming increasingly\nheterogeneous and dynamic, necessitating advanced automation for efficient\nmanagement. Intent-Driven Networks (IDNs) address this by translating\nhigh-level intents into optimization policies. Large Language Models (LLMs) can\nenhance this process by understanding complex human instructions to enable\nadaptive, intelligent automation. Given the rapid advancements in Generative AI\n(GenAI), a comprehensive survey of LLM-based IDN architectures in disaggregated\nRadio Access Network (RAN) environments is both timely and critical. This\narticle provides such a survey, along with a case study on a hierarchical\nlearning-enabled IDN architecture that integrates GenAI across three key\nstages: intent processing, intent validation, and intent execution. Unlike most\nexisting approaches that apply GenAI in the form of LLMs for intent processing\nonly, we propose a hierarchical framework that introduces GenAI across all\nthree stages of IDN. To demonstrate the effectiveness of the proposed IDN\nmanagement architecture, we present a case study based on the latest GenAI\narchitecture named Mamba. The case study shows how the proposed GenAI-driven\narchitecture enhances network performance through intelligent automation,\nsurpassing the performance of the conventional IDN architectures.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u8026\u5f0f\u65e0\u7ebf\u63a5\u5165\u7f51\u73af\u5883\u4e0b\u7684\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\u67b6\u6784\u8fdb\u884c\u4e86\u5168\u9762\u8c03\u7814\uff0c\u63d0\u51fa\u8de8\u4e09\u4e2a\u9636\u6bb5\u5f15\u5165\u751f\u6210\u5f0fAI\u7684\u5206\u5c42\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8eMamba\u7684\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u67b6\u6784\u3002", "motivation": "\u968f\u77406G\u51fa\u73b0\uff0c\u79fb\u52a8\u7f51\u7edc\u53d8\u5f97\u66f4\u52a0\u5f02\u6784\u548c\u52a8\u6001\uff0c\u9700\u8981\u5148\u8fdb\u81ea\u52a8\u5316\u7ba1\u7406\uff0c\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\u53ef\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u589e\u5f3a\u6b64\u8fc7\u7a0b\uff0c\u56e0\u6b64\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u8026\u5f0f\u65e0\u7ebf\u63a5\u5165\u7f51\u73af\u5883\u4e0b\u7684\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\u67b6\u6784\u8fdb\u884c\u5168\u9762\u8c03\u7814\u5f88\u6709\u5fc5\u8981\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8de8\u610f\u56fe\u5904\u7406\u3001\u9a8c\u8bc1\u548c\u6267\u884c\u4e09\u4e2a\u5173\u952e\u9636\u6bb5\u5f15\u5165\u751f\u6210\u5f0fAI\u7684\u5206\u5c42\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u6700\u65b0\u751f\u6210\u5f0fAI\u67b6\u6784Mamba\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u751f\u6210\u5f0fAI\u9a71\u52a8\u7684\u67b6\u6784\u901a\u8fc7\u667a\u80fd\u81ea\u52a8\u5316\u63d0\u9ad8\u4e86\u7f51\u7edc\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\u67b6\u6784\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5c42\u6846\u67b6\u6709\u6548\uff0c\u80fd\u901a\u8fc7\u667a\u80fd\u81ea\u52a8\u5316\u63d0\u5347\u7f51\u7edc\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u67b6\u6784\u3002"}}
{"id": "2508.07631", "pdf": "https://arxiv.org/pdf/2508.07631", "abs": "https://arxiv.org/abs/2508.07631", "authors": ["Advait Parulekar", "Litu Rout", "Karthikeyan Shanmugam", "Sanjay Shakkottai"], "title": "Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We study the problem of posterior sampling in the context of score based\ngenerative models. We have a trained score network for a prior $p(x)$, a\nmeasurement model $p(y|x)$, and are tasked with sampling from the posterior\n$p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case)\nunder well-accepted computational hardness assumptions. Despite this, popular\nalgorithms for tasks such as image super-resolution, stylization, and\nreconstruction enjoy empirical success. Rather than establishing distributional\nassumptions or restricted settings under which exact posterior sampling is\ntractable, we view this as a more general \"tilting\" problem of biasing a\ndistribution towards a measurement. Under minimal assumptions, we show that one\ncan tractably sample from a distribution that is simultaneously close to the\nposterior of a noised prior in KL divergence and the true posterior in Fisher\ndivergence. Intuitively, this combination ensures that the resulting sample is\nconsistent with both the measurement and the prior. To the best of our\nknowledge these are the first formal results for (approximate) posterior\nsampling in polynomial time.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u5206\u6570\u7684\u751f\u6210\u6a21\u578b\u4e2d\u540e\u9a8c\u91c7\u6837\u95ee\u9898\uff0c\u63d0\u51fa\u5c06\u5176\u89c6\u4e3a\u5206\u5e03\u503e\u659c\u95ee\u9898\uff0c\u5728\u6700\u5c0f\u5047\u8bbe\u4e0b\u53ef\u8fdb\u884c\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u540e\u9a8c\u91c7\u6837\u3002", "motivation": "\u5df2\u6709\u5de5\u4f5c\u8868\u660e\u5728KL\u6563\u5ea6\u4e0b\u7cbe\u786e\u540e\u9a8c\u91c7\u6837\u96be\u5904\u7406\uff0c\u4f46\u76f8\u5173\u7b97\u6cd5\u6709\u5b9e\u8bc1\u6210\u529f\uff0c\u8981\u89e3\u51b3\u540e\u9a8c\u91c7\u6837\u95ee\u9898\u3002", "method": "\u5c06\u540e\u9a8c\u91c7\u6837\u89c6\u4e3a\u66f4\u4e00\u822c\u7684\u5206\u5e03\u201c\u503e\u659c\u201d\u95ee\u9898\u3002", "result": "\u5728\u6700\u5c0f\u5047\u8bbe\u4e0b\uff0c\u53ef\u4ece\u4e00\u4e2a\u5206\u5e03\u4e2d\u8fdb\u884c\u91c7\u6837\uff0c\u8be5\u5206\u5e03\u4e0e\u52a0\u566a\u5148\u9a8c\u7684\u540e\u9a8c\u5728KL\u6563\u5ea6\u4e0a\u63a5\u8fd1\uff0c\u4e0e\u771f\u5b9e\u540e\u9a8c\u5728Fisher\u6563\u5ea6\u4e0a\u63a5\u8fd1\u3002", "conclusion": "\u5f97\u5230\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\uff08\u8fd1\u4f3c\uff09\u540e\u9a8c\u91c7\u6837\u7684\u9996\u4e2a\u6b63\u5f0f\u7ed3\u679c\u3002"}}
{"id": "2508.07636", "pdf": "https://arxiv.org/pdf/2508.07636", "abs": "https://arxiv.org/abs/2508.07636", "authors": ["Huiqi Deng", "Hongbin Pei", "Quanshi Zhang", "Mengnan Du"], "title": "Attribution Explanations for Deep Neural Networks: A Theoretical Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Attribution explanation is a typical approach for explaining deep neural\nnetworks (DNNs), inferring an importance or contribution score for each input\nvariable to the final output. In recent years, numerous attribution methods\nhave been developed to explain DNNs. However, a persistent concern remains\nunresolved, i.e., whether and which attribution methods faithfully reflect the\nactual contribution of input variables to the decision-making process. The\nfaithfulness issue undermines the reliability and practical utility of\nattribution explanations. We argue that these concerns stem from three core\nchallenges. First, difficulties arise in comparing attribution methods due to\ntheir unstructured heterogeneity, differences in heuristics, formulations, and\nimplementations that lack a unified organization. Second, most methods lack\nsolid theoretical underpinnings, with their rationales remaining absent,\nambiguous, or unverified. Third, empirically evaluating faithfulness is\nchallenging without ground truth. Recent theoretical advances provide a\npromising way to tackle these challenges, attracting increasing attention. We\nsummarize these developments, with emphasis on three key directions: (i)\nTheoretical unification, which uncovers commonalities and differences among\nmethods, enabling systematic comparisons; (ii) Theoretical rationale,\nclarifying the foundations of existing methods; (iii) Theoretical evaluation,\nrigorously proving whether methods satisfy faithfulness principles. Beyond a\ncomprehensive review, we provide insights into how these studies help deepen\ntheoretical understanding, inform method selection, and inspire new attribution\nmethods. We conclude with a discussion of promising open problems for further\nwork.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5f52\u56e0\u89e3\u91caDNNs\u7684\u65b9\u6cd5\u5b58\u5728\u5fe0\u5b9e\u6027\u95ee\u9898\uff0c\u6e90\u4e8e\u4e09\u4e2a\u6838\u5fc3\u6311\u6218\uff0c\u603b\u7ed3\u8fd1\u671f\u7406\u8bba\u8fdb\u5c55\u4e09\u4e2a\u65b9\u5411\u5e76\u7ed9\u51fa\u89c1\u89e3\uff0c\u6700\u540e\u8ba8\u8bba\u5f85\u7814\u7a76\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5f52\u56e0\u65b9\u6cd5\u662f\u5426\u53ca\u54ea\u4e9b\u80fd\u5fe0\u5b9e\u53cd\u6620\u8f93\u5165\u53d8\u91cf\u5bf9\u51b3\u7b56\u8fc7\u7a0b\u5b9e\u9645\u8d21\u732e\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u5f52\u56e0\u89e3\u91ca\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u603b\u7ed3\u8fd1\u671f\u7406\u8bba\u8fdb\u5c55\uff0c\u4ece\u7406\u8bba\u7edf\u4e00\u3001\u7406\u8bba\u57fa\u7840\u3001\u7406\u8bba\u8bc4\u4f30\u4e09\u4e2a\u5173\u952e\u65b9\u5411\u8fdb\u884c\u68b3\u7406\u3002", "result": "\u7406\u6e05\u4e86\u5f52\u56e0\u65b9\u6cd5\u7684\u76f8\u5173\u7406\u8bba\u8fdb\u5c55\uff0c\u80fd\u5e2e\u52a9\u52a0\u6df1\u7406\u8bba\u7406\u89e3\u3001\u6307\u5bfc\u65b9\u6cd5\u9009\u62e9\u548c\u542f\u53d1\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6709\u524d\u666f\u7684\u5f85\u7814\u7a76\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2508.07637", "pdf": "https://arxiv.org/pdf/2508.07637", "abs": "https://arxiv.org/abs/2508.07637", "authors": ["Guanqun Ma", "David Lenz", "Hanqi Guo", "Tom Peterka", "Bei Wang"], "title": "Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs", "categories": ["cs.LG", "cs.CG"], "comment": "The paper is to be published at the 15th IEEE Workshop on Large Data\n  Analysis and Visualization (LDAV)", "summary": "Implicit continuous models, such as functional models and implicit neural\nnetworks, are an increasingly popular method for replacing discrete data\nrepresentations with continuous, high-order, and differentiable surrogates.\nThese models offer new perspectives on the storage, transfer, and analysis of\nscientific data. In this paper, we introduce the first framework to directly\nextract complex topological features -- contours, Jacobi sets, and ridge-valley\ngraphs -- from a type of continuous implicit model known as multivariate\nfunctional approximation (MFA). MFA replaces discrete data with continuous\npiecewise smooth functions. Given an MFA model as the input, our approach\nenables direct extraction of complex topological features from the model,\nwithout reverting to a discrete representation of the model. Our work is easily\ngeneralizable to any continuous implicit model that supports the queries of\nfunction values and high-order derivatives. Our work establishes the building\nblocks for performing topological data analysis and visualization on implicit\ncontinuous models.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u9996\u4e2a\u4ece\u591a\u5143\u51fd\u6570\u903c\u8fd1\uff08MFA\uff09\u8fd9\u79cd\u8fde\u7eed\u9690\u5f0f\u6a21\u578b\u4e2d\u76f4\u63a5\u63d0\u53d6\u590d\u6742\u62d3\u6251\u7279\u5f81\u7684\u6846\u67b6\uff0c\u8be5\u5de5\u4f5c\u53ef\u63a8\u5e7f\uff0c\u4e3a\u9690\u5f0f\u8fde\u7eed\u6a21\u578b\u7684\u62d3\u6251\u6570\u636e\u5206\u6790\u548c\u53ef\u89c6\u5316\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u9690\u5f0f\u8fde\u7eed\u6a21\u578b\u4e3a\u79d1\u5b66\u6570\u636e\u7684\u5b58\u50a8\u3001\u4f20\u8f93\u548c\u5206\u6790\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u9700\u8981\u4e00\u79cd\u4ece\u8fde\u7eed\u9690\u5f0f\u6a21\u578b\u4e2d\u76f4\u63a5\u63d0\u53d6\u590d\u6742\u62d3\u6251\u7279\u5f81\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u6846\u67b6\uff0c\u4ee5MFA\u6a21\u578b\u4e3a\u8f93\u5165\uff0c\u76f4\u63a5\u4ece\u6a21\u578b\u4e2d\u63d0\u53d6\u590d\u6742\u62d3\u6251\u7279\u5f81\uff0c\u4e0d\u8f6c\u6362\u4e3a\u79bb\u6563\u8868\u793a\u3002", "result": "\u5b9e\u73b0\u4e86\u4eceMFA\u6a21\u578b\u4e2d\u76f4\u63a5\u63d0\u53d6\u590d\u6742\u62d3\u6251\u7279\u5f81\uff0c\u4e14\u8be5\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u652f\u6301\u51fd\u6570\u503c\u548c\u9ad8\u9636\u5bfc\u6570\u67e5\u8be2\u7684\u4efb\u4f55\u8fde\u7eed\u9690\u5f0f\u6a21\u578b\u3002", "conclusion": "\u4e3a\u9690\u5f0f\u8fde\u7eed\u6a21\u578b\u7684\u62d3\u6251\u6570\u636e\u5206\u6790\u548c\u53ef\u89c6\u5316\u5efa\u7acb\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.06632", "pdf": "https://arxiv.org/pdf/2508.06632", "abs": "https://arxiv.org/abs/2508.06632", "authors": ["Wenpeng Xing", "Jie Chen", "Zaifeng Yang", "Tiancheng Zhao", "Gaolei Li", "Changting Lin", "Yike Guo", "Meng Han"], "title": "CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Neural Radiance Fields (NeRF) have shown impressive performance in novel view\nsynthesis, but challenges remain in rendering scenes with complex specular\nreflections and highlights. Existing approaches may produce blurry reflections\ndue to entanglement between lighting and material properties, or encounter\noptimization instability when relying on physically-based inverse rendering. In\nthis work, we present a neural rendering framework based on dynamic coefficient\ndecomposition, aiming to improve the modeling of view-dependent appearance. Our\napproach decomposes complex appearance into a shared, static neural basis that\nencodes intrinsic material properties, and a set of dynamic coefficients\ngenerated by a Coefficient Network conditioned on view and illumination. A\nDynamic Radiance Integrator then combines these components to synthesize the\nfinal radiance. Experimental results on several challenging benchmarks suggest\nthat our method can produce sharper and more realistic specular highlights\ncompared to existing techniques. We hope that this decomposition paradigm can\nprovide a flexible and effective direction for modeling complex appearance in\nneural scene representations.", "AI": {"tldr": "\u73b0\u6709NeRF\u65b9\u6cd5\u5728\u6e32\u67d3\u590d\u6742\u955c\u9762\u53cd\u5c04\u573a\u666f\u65f6\u6709\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u52a8\u6001\u7cfb\u6570\u5206\u89e3\u7684\u795e\u7ecf\u6e32\u67d3\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u73b0\u6709NeRF\u65b9\u6cd5\u5728\u6e32\u67d3\u590d\u6742\u955c\u9762\u53cd\u5c04\u548c\u9ad8\u5149\u573a\u666f\u65f6\u5b58\u5728\u751f\u6210\u6a21\u7cca\u53cd\u5c04\u3001\u4f18\u5316\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u89c6\u56fe\u76f8\u5173\u5916\u89c2\u7684\u5efa\u6a21\u3002", "method": "\u5c06\u590d\u6742\u5916\u89c2\u5206\u89e3\u4e3a\u7f16\u7801\u56fa\u6709\u6750\u6599\u5c5e\u6027\u7684\u5171\u4eab\u9759\u6001\u795e\u7ecf\u57fa\u548c\u7531\u7cfb\u6570\u7f51\u7edc\u6839\u636e\u89c6\u56fe\u548c\u5149\u7167\u751f\u6210\u7684\u4e00\u7ec4\u52a8\u6001\u7cfb\u6570\uff0c\u518d\u7531\u52a8\u6001\u8f90\u5c04\u79ef\u5206\u5668\u5408\u6210\u6700\u7ec8\u8f90\u5c04\u3002", "result": "\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u80fd\u4ea7\u751f\u66f4\u6e05\u6670\u3001\u66f4\u903c\u771f\u7684\u955c\u9762\u9ad8\u5149\u3002", "conclusion": "\u8fd9\u79cd\u5206\u89e3\u8303\u5f0f\u53ef\u4e3a\u795e\u7ecf\u573a\u666f\u8868\u793a\u4e2d\u590d\u6742\u5916\u89c2\u7684\u5efa\u6a21\u63d0\u4f9b\u7075\u6d3b\u6709\u6548\u7684\u65b9\u5411\u3002"}}
{"id": "2508.07638", "pdf": "https://arxiv.org/pdf/2508.07638", "abs": "https://arxiv.org/abs/2508.07638", "authors": ["Jia Zhang", "Yao Liu", "Chen-Xi Zhang", "Yi Liu", "Yi-Xuan Jin", "Lan-Zhe Guo", "Yu-Feng Li"], "title": "Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals", "categories": ["cs.LG"], "comment": "Under review", "summary": "Aligning Large Language Models (LLMs) with diverse human values requires\nmoving beyond a single holistic \"better-than\" preference criterion. While\ncollecting fine-grained, aspect-specific preference data is more reliable and\nscalable, existing methods like Direct Preference Optimization (DPO) struggle\nwith the severe noise and conflicts inherent in such aggregated datasets. In\nthis paper, we tackle this challenge from a data-centric perspective. We first\nderive the Direct Multi-Preference Optimization (DMPO) objective, and uncover a\nkey Preference Divergence (PD) term that quantifies inter-aspect preference\nconflicts. Instead of using this term for direct optimization, we leverage it\nto formulate a novel, theoretically-grounded data selection principle. Our\nprinciple advocates for selecting a subset of high-consensus data-identified by\nthe most negative PD values-for efficient DPO training. We prove the optimality\nof this strategy by analyzing the loss bounds of the DMPO objective in the\nselection problem. To operationalize our approach, we introduce practical\nmethods of PD term estimation and length bias mitigation, thereby proposing our\nPD selection method. Evaluation on the UltraFeedback dataset with three varying\nconflict levels shows that our simple yet effective strategy achieves over 10%\nrelative improvement against both the standard holistic preference and a\nstronger oracle using aggregated preference signals, all while boosting\ntraining efficiency and obviating the need for intractable holistic preference\nannotating, unlocking the potential of robust LLM alignment via fine-grained\npreference signals.", "AI": {"tldr": "\u8bba\u6587\u4ece\u6570\u636e\u89d2\u5ea6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4ef7\u503c\u5bf9\u9f50\u4e2d\u591a\u504f\u597d\u6570\u636e\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51faPD\u9009\u62e9\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u8d8510%\u76f8\u5bf9\u63d0\u5347\u5e76\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4ef7\u503c\u5bf9\u9f50\u65b9\u6cd5\u5728\u5904\u7406\u7ec6\u7c92\u5ea6\u3001\u7279\u5b9a\u65b9\u9762\u504f\u597d\u6570\u636e\u65f6\u5b58\u5728\u566a\u58f0\u548c\u51b2\u7a81\u95ee\u9898\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63a8\u5bfcDirect Multi - Preference Optimization (DMPO)\u76ee\u6807\uff0c\u53d1\u73b0Preference Divergence (PD)\u9879\uff0c\u57fa\u4e8e\u6b64\u63d0\u51fa\u6570\u636e\u9009\u62e9\u539f\u5219\uff0c\u8fd8\u4ecb\u7ecdPD\u9879\u4f30\u8ba1\u548c\u957f\u5ea6\u504f\u5dee\u7f13\u89e3\u65b9\u6cd5\u3002", "result": "\u5728UltraFeedback\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u5bf9\u6807\u51c6\u6574\u4f53\u504f\u597d\u548c\u4f7f\u7528\u805a\u5408\u504f\u597d\u4fe1\u53f7\u7684\u66f4\u5f3a\u57fa\u51c6\u6709\u8d8510%\u76f8\u5bf9\u63d0\u5347\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\uff0c\u65e0\u9700\u6574\u4f53\u504f\u597d\u6807\u6ce8\u3002", "conclusion": "\u63d0\u51fa\u7684PD\u9009\u62e9\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u80fd\u901a\u8fc7\u7ec6\u7c92\u5ea6\u504f\u597d\u4fe1\u53f7\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u5bf9\u9f50\u3002"}}
{"id": "2508.07646", "pdf": "https://arxiv.org/pdf/2508.07646", "abs": "https://arxiv.org/abs/2508.07646", "authors": ["Xiaoxue Yang", "Jaeha Lee", "Anna-Katharina Dick", "Jasper Timm", "Fei Xie", "Diogo Cruz"], "title": "Multi-Turn Jailbreaks Are Simpler Than They Seem", "categories": ["cs.LG"], "comment": "25 pages, 15 figures. Accepted at COLM 2025 SoLaR Workshop", "summary": "While defenses against single-turn jailbreak attacks on Large Language Models\n(LLMs) have improved significantly, multi-turn jailbreaks remain a persistent\nvulnerability, often achieving success rates exceeding 70% against models\noptimized for single-turn protection. This work presents an empirical analysis\nof automated multi-turn jailbreak attacks across state-of-the-art models\nincluding GPT-4, Claude, and Gemini variants, using the StrongREJECT benchmark.\nOur findings challenge the perceived sophistication of multi-turn attacks: when\naccounting for the attacker's ability to learn from how models refuse harmful\nrequests, multi-turn jailbreaking approaches are approximately equivalent to\nsimply resampling single-turn attacks multiple times. Moreover, attack success\nis correlated among similar models, making it easier to jailbreak newly\nreleased ones. Additionally, for reasoning models, we find surprisingly that\nhigher reasoning effort often leads to higher attack success rates. Our results\nhave important implications for AI safety evaluation and the design of\njailbreak-resistant systems. We release the source code at\nhttps://github.com/diogo-cruz/multi_turn_simpler", "AI": {"tldr": "\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0\u591a\u8f6e\u653b\u51fb\u8fd1\u4f3c\u591a\u6b21\u91cd\u91c7\u6837\u5355\u8f6e\u653b\u51fb\uff0c\u76f8\u4f3c\u6a21\u578b\u653b\u51fb\u6210\u529f\u7387\u76f8\u5173\uff0c\u63a8\u7406\u6a21\u578b\u63a8\u7406\u52aa\u529b\u4e0e\u653b\u51fb\u6210\u529f\u7387\u6b63\u76f8\u5173\u3002", "motivation": "\u5c3d\u7ba1\u5355\u8f6e\u8d8a\u72f1\u653b\u51fb\u9632\u5fa1\u6709\u63d0\u5347\uff0c\u4f46\u591a\u8f6e\u8d8a\u72f1\u4ecd\u662f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6301\u4e45\u6f0f\u6d1e\uff0c\u9700\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u4f7f\u7528StrongREJECT\u57fa\u51c6\u5bf9GPT - 4\u3001Claude\u548cGemini\u7b49\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u5316\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u7ea6\u7b49\u4e8e\u591a\u6b21\u91cd\u91c7\u6837\u5355\u8f6e\u653b\u51fb\uff1b\u76f8\u4f3c\u6a21\u578b\u653b\u51fb\u6210\u529f\u7387\u76f8\u5173\uff1b\u63a8\u7406\u6a21\u578b\u63a8\u7406\u52aa\u529b\u8d8a\u9ad8\u653b\u51fb\u6210\u529f\u7387\u8d8a\u9ad8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9AI\u5b89\u5168\u8bc4\u4f30\u548c\u6297\u8d8a\u72f1\u7cfb\u7edf\u8bbe\u8ba1\u6709\u91cd\u8981\u610f\u4e49\uff0c\u5df2\u53d1\u5e03\u6e90\u4ee3\u7801\u3002"}}
{"id": "2508.07659", "pdf": "https://arxiv.org/pdf/2508.07659", "abs": "https://arxiv.org/abs/2508.07659", "authors": ["Hyeon-Ju Jeon", "Jeon-Ho Kang", "In-Hyuk Kwon", "O-Joun Lee"], "title": "Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages", "summary": "This study aims to discover spatial correlations between Earth observations\nand atmospheric states to improve the forecasting accuracy of global\natmospheric state estimation, which are usually conducted using conventional\nnumerical weather prediction (NWP) systems and is the beginning of weather\nforecasting. NWP systems predict future atmospheric states at fixed locations,\nwhich are called NWP grid points, by analyzing previous atmospheric states and\nnewly acquired Earth observations without fixed locations. Thus, surrounding\nmeteorological context and the changing locations of the observations make\nspatial correlations between atmospheric states and observations over time. To\nhandle complicated spatial correlations, which change dynamically, we employ\nspatiotemporal graph neural networks (STGNNs) with structure learning. However,\nstructure learning has an inherent limitation that this can cause structural\ninformation loss and over-smoothing problem by generating excessive edges. To\nsolve this problem, we regulate edge sampling by adaptively determining node\ndegrees and considering the spatial distances between NWP grid points and\nobservations. We validated the effectiveness of the proposed method by using\nreal-world atmospheric state and observation data from East Asia. Even in areas\nwith high atmospheric variability, the proposed method outperformed existing\nSTGNN models with and without structure learning.", "AI": {"tldr": "\u4e3a\u63d0\u9ad8\u5168\u7403\u5927\u6c14\u72b6\u6001\u4f30\u8ba1\u9884\u6d4b\u7cbe\u5ea6\uff0c\u91c7\u7528\u5e26\u7ed3\u6784\u5b66\u4e60\u7684\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u590d\u6742\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u901a\u8fc7\u8c03\u8282\u8fb9\u91c7\u6837\u89e3\u51b3\u95ee\u9898\uff0c\u7528\u4e1c\u4e9a\u6570\u636e\u9a8c\u8bc1\u6548\u679c\u4f73\u3002", "motivation": "\u53d1\u73b0\u5730\u7403\u89c2\u6d4b\u4e0e\u5927\u6c14\u72b6\u6001\u7684\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u63d0\u9ad8\u5168\u7403\u5927\u6c14\u72b6\u6001\u4f30\u8ba1\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "method": "\u91c7\u7528\u5e26\u7ed3\u6784\u5b66\u4e60\u7684\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\uff08STGNNs\uff09\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u786e\u5b9a\u8282\u70b9\u5ea6\u548c\u8003\u8651\u7f51\u683c\u70b9\u4e0e\u89c2\u6d4b\u70b9\u7684\u7a7a\u95f4\u8ddd\u79bb\u6765\u8c03\u8282\u8fb9\u91c7\u6837\u3002", "result": "\u4f7f\u7528\u4e1c\u4e9a\u771f\u5b9e\u5927\u6c14\u72b6\u6001\u548c\u89c2\u6d4b\u6570\u636e\u9a8c\u8bc1\uff0c\u5728\u5927\u6c14\u53d8\u5316\u5927\u7684\u533a\u57df\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u5e26\u6216\u4e0d\u5e26\u7ed3\u6784\u5b66\u4e60\u7684STGNN\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u5927\u6c14\u72b6\u6001\u548c\u89c2\u6d4b\u4e4b\u95f4\u590d\u6742\u7684\u52a8\u6001\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2508.07662", "pdf": "https://arxiv.org/pdf/2508.07662", "abs": "https://arxiv.org/abs/2508.07662", "authors": ["Ihor Stepanov", "Mykhailo Shtopko", "Dmytro Vodianytskyi", "Oleksandr Lukashov", "Alexander Yavorskyi", "Mykyta Yaroshenko"], "title": "GLiClass: Generalist Lightweight Model for Sequence Classification Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "14 pages, 7 tables, 2 figures", "summary": "Classification is one of the most widespread tasks in AI applications,\nserving often as the first step in filtering, sorting, and categorizing data.\nSince modern AI systems must handle large volumes of input data and early\npipeline stages can propagate errors downstream, achieving high efficiency and\naccuracy is critical. Moreover, classification requirements can change\ndynamically based on user needs, necessitating models with strong zero-shot\ncapabilities. While generative LLMs have become mainstream for zero-shot\nclassification due to their versatility, they suffer from inconsistent\ninstruction following and computational inefficiency. Cross-encoders, commonly\nused as rerankers in RAG pipelines, face a different bottleneck: they must\nprocess text-label pairs sequentially, significantly reducing efficiency with\nlarge label sets. Embedding-based approaches offer good efficiency but struggle\nwith complex scenarios involving logical and semantic constraints. We propose\nGLiClass, a novel method that adapts the GLiNER architecture for sequence\nclassification tasks. Our approach achieves strong accuracy and efficiency\ncomparable to embedding-based methods, while maintaining the flexibility needed\nfor zero-shot and few-shot learning scenarios. Additionally, we adapted\nproximal policy optimization (PPO) for multi-label text classification,\nenabling training classifiers in data-sparse conditions or from human feedback.", "AI": {"tldr": "\u63d0\u51faGLiClass\u7528\u4e8e\u5e8f\u5217\u5206\u7c7b\uff0c\u7ed3\u5408PPO\u7528\u4e8e\u591a\u6807\u7b7e\u6587\u672c\u5206\u7c7b\uff0c\u517c\u987e\u6548\u7387\u3001\u51c6\u786e\u6027\u4e0e\u7075\u6d3b\u6027\u3002", "motivation": "\u5f53\u524dAI\u5206\u7c7b\u4efb\u52a1\u9700\u9ad8\u6548\u51c6\u786e\u4e14\u6709\u96f6\u6837\u672c\u80fd\u529b\uff0c\u73b0\u6709\u65b9\u6cd5\u5982\u751f\u6210\u5f0fLLMs\u3001\u4ea4\u53c9\u7f16\u7801\u5668\u3001\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5c06GLiNER\u67b6\u6784\u7528\u4e8e\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\uff0c\u91c7\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7528\u4e8e\u591a\u6807\u7b7e\u6587\u672c\u5206\u7c7b\u3002", "result": "GLiClass\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u4e0e\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u76f8\u5f53\uff0c\u80fd\u9002\u5e94\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u573a\u666f\u3002", "conclusion": "GLiClass\u65b9\u6cd5\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5177\u6709\u826f\u597d\u8868\u73b0\uff0cPPO\u53ef\u5728\u6570\u636e\u7a00\u758f\u6216\u6709\u4eba\u5de5\u53cd\u9988\u60c5\u51b5\u4e0b\u8bad\u7ec3\u5206\u7c7b\u5668\u3002"}}
{"id": "2508.07668", "pdf": "https://arxiv.org/pdf/2508.07668", "abs": "https://arxiv.org/abs/2508.07668", "authors": ["Hyobin Park", "Jinwook Jung", "Minseok Seo", "Hyunsoo Choi", "Deukjae Cho", "Sekil Park", "Dong-Geol Choi"], "title": "AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the increase in maritime traffic and the mandatory implementation of the\nAutomatic Identification System (AIS), the importance and diversity of maritime\ntraffic analysis tasks based on AIS data, such as vessel trajectory prediction,\nanomaly detection, and collision risk assessment, is rapidly growing. However,\nexisting approaches tend to address these tasks individually, making it\ndifficult to holistically consider complex maritime situations. To address this\nlimitation, we propose a novel framework, AIS-LLM, which integrates time-series\nAIS data with a large language model (LLM). AIS-LLM consists of a Time-Series\nEncoder for processing AIS sequences, an LLM-based Prompt Encoder, a\nCross-Modality Alignment Module for semantic alignment between time-series data\nand textual prompts, and an LLM-based Multi-Task Decoder. This architecture\nenables the simultaneous execution of three key tasks: trajectory prediction,\nanomaly detection, and risk assessment of vessel collisions within a single\nend-to-end system. Experimental results demonstrate that AIS-LLM outperforms\nexisting methods across individual tasks, validating its effectiveness.\nFurthermore, by integratively analyzing task outputs to generate situation\nsummaries and briefings, AIS-LLM presents the potential for more intelligent\nand efficient maritime traffic management.", "AI": {"tldr": "\u63d0\u51faAIS-LLM\u6846\u67b6\u6574\u5408AIS\u6570\u636e\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u540c\u65f6\u6267\u884c\u4e09\u9879\u5173\u952e\u4efb\u52a1\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\uff0c\u6709\u667a\u80fd\u9ad8\u6548\u7ba1\u7406\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5355\u72ec\u5904\u7406\u6d77\u4e8b\u4ea4\u901a\u5206\u6790\u4efb\u52a1\uff0c\u96be\u4ee5\u5168\u9762\u8003\u8651\u590d\u6742\u6d77\u4e8b\u60c5\u51b5\u3002", "method": "\u63d0\u51faAIS - LLM\u6846\u67b6\uff0c\u5305\u542b\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u5668\u3001\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63d0\u793a\u7f16\u7801\u5668\u3001\u8de8\u6a21\u6001\u5bf9\u9f50\u6a21\u5757\u548c\u591a\u4efb\u52a1\u89e3\u7801\u5668\u3002", "result": "AIS - LLM\u5728\u5404\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "AIS - LLM\u6709\u6548\uff0c\u5728\u6d77\u4e8b\u4ea4\u901a\u7ba1\u7406\u4e0a\u6709\u667a\u80fd\u9ad8\u6548\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.06671", "pdf": "https://arxiv.org/pdf/2508.06671", "abs": "https://arxiv.org/abs/2508.06671", "authors": ["Swati Rajwal", "Shivank Garg", "Reem Abdel-Salam", "Abdelrahman Zayed"], "title": "Do Biased Models Have Biased Thoughts?", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "Accepted at main track of the Second Conference on Language Modeling\n  (COLM 2025)", "summary": "The impressive performance of language models is undeniable. However, the\npresence of biases based on gender, race, socio-economic status, physical\nappearance, and sexual orientation makes the deployment of language models\nchallenging. This paper studies the effect of chain-of-thought prompting, a\nrecent approach that studies the steps followed by the model before it\nresponds, on fairness. More specifically, we ask the following question:\n\\textit{Do biased models have biased thoughts}? To answer our question, we\nconduct experiments on $5$ popular large language models using fairness metrics\nto quantify $11$ different biases in the model's thoughts and output. Our\nresults show that the bias in the thinking steps is not highly correlated with\nthe output bias (less than $0.6$ correlation with a $p$-value smaller than\n$0.001$ in most cases). In other words, unlike human beings, the tested models\nwith biased decisions do not always possess biased thoughts.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u601d\u7ef4\u94fe\u63d0\u793a\u5bf9\u8bed\u8a00\u6a21\u578b\u516c\u5e73\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6a21\u578b\u601d\u7ef4\u6b65\u9aa4\u4e2d\u7684\u504f\u5dee\u4e0e\u8f93\u51fa\u504f\u5dee\u76f8\u5173\u6027\u4f4e\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u57fa\u4e8e\u6027\u522b\u3001\u79cd\u65cf\u7b49\u65b9\u9762\u7684\u504f\u5dee\uff0c\u5f71\u54cd\u5176\u90e8\u7f72\uff0c\u56e0\u6b64\u7814\u7a76\u601d\u7ef4\u94fe\u63d0\u793a\u5bf9\u516c\u5e73\u6027\u7684\u5f71\u54cd\u3002", "method": "\u5bf95\u4e2a\u6d41\u884c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528\u516c\u5e73\u6027\u6307\u6807\u91cf\u5316\u6a21\u578b\u601d\u7ef4\u548c\u8f93\u51fa\u4e2d\u768411\u79cd\u4e0d\u540c\u504f\u5dee\u3002", "result": "\u601d\u7ef4\u6b65\u9aa4\u4e2d\u7684\u504f\u5dee\u4e0e\u8f93\u51fa\u504f\u5dee\u76f8\u5173\u6027\u4e0d\u9ad8\uff08\u591a\u6570\u60c5\u51b5\u4e0b\u76f8\u5173\u6027\u5c0f\u4e8e0.6\uff0cp\u503c\u5c0f\u4e8e0.001\uff09\u3002", "conclusion": "\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u6709\u504f\u5dee\u51b3\u7b56\u7684\u6d4b\u8bd5\u6a21\u578b\u5e76\u4e0d\u603b\u662f\u6709\u504f\u5dee\u7684\u601d\u7ef4\u3002"}}
{"id": "2508.07675", "pdf": "https://arxiv.org/pdf/2508.07675", "abs": "https://arxiv.org/abs/2508.07675", "authors": ["Xutong Liu", "Baran Atalar", "Xiangxiang Dai", "Jinhang Zuo", "Siwei Wang", "John C. S. Lui", "Wei Chen", "Carlee Joe-Wong"], "title": "Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are revolutionizing how users interact with\ninformation systems, yet their high inference cost poses serious scalability\nand sustainability challenges. Caching inference responses, allowing them to be\nretrieved without another forward pass through the LLM, has emerged as one\npossible solution. Traditional exact-match caching, however, overlooks the\nsemantic similarity between queries, leading to unnecessary recomputation.\nSemantic caching addresses this by retrieving responses based on semantic\nsimilarity, but introduces a fundamentally different cache eviction problem:\none must account for mismatch costs between incoming queries and cached\nresponses. Moreover, key system parameters, such as query arrival probabilities\nand serving costs, are often unknown and must be learned over time. Existing\nsemantic caching methods are largely ad-hoc, lacking theoretical foundations\nand unable to adapt to real-world uncertainty. In this paper, we present a\nprincipled, learning-based framework for semantic cache eviction under unknown\nquery and cost distributions. We formulate both offline optimization and online\nlearning variants of the problem, and develop provably efficient algorithms\nwith state-of-the-art guarantees. We also evaluate our framework on a synthetic\ndataset, showing that our proposed algorithms perform matching or superior\nperformance compared with baselines.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6210\u672c\u9ad8\uff0c\u7f13\u5b58\u662f\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4f20\u7edf\u7cbe\u786e\u5339\u914d\u7f13\u5b58\u6709\u95ee\u9898\uff0c\u8bed\u4e49\u7f13\u5b58\u6709\u65b0\u95ee\u9898\u4e14\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u3002\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u8bed\u4e49\u7f13\u5b58\u6dd8\u6c70\u6846\u67b6\uff0c\u6709\u79bb\u7ebf\u4f18\u5316\u548c\u5728\u7ebf\u5b66\u4e60\u53d8\u4f53\uff0c\u7b97\u6cd5\u9ad8\u6548\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u597d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6210\u672c\u9ad8\uff0c\u4f20\u7edf\u7cbe\u786e\u5339\u914d\u7f13\u5b58\u5ffd\u89c6\u67e5\u8be2\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u8bed\u4e49\u7f13\u5b58\u6709\u65b0\u7684\u7f13\u5b58\u6dd8\u6c70\u95ee\u9898\uff0c\u73b0\u6709\u8bed\u4e49\u7f13\u5b58\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u4e14\u65e0\u6cd5\u9002\u5e94\u73b0\u5b9e\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u8bed\u4e49\u7f13\u5b58\u6dd8\u6c70\u6846\u67b6\uff0c\u5236\u5b9a\u95ee\u9898\u7684\u79bb\u7ebf\u4f18\u5316\u548c\u5728\u7ebf\u5b66\u4e60\u53d8\u4f53\uff0c\u5f00\u53d1\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u8868\u73b0\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u8bed\u4e49\u7f13\u5b58\u6dd8\u6c70\u6846\u67b6\u6709\u6548\uff0c\u5176\u7b97\u6cd5\u5728\u672a\u77e5\u67e5\u8be2\u548c\u6210\u672c\u5206\u5e03\u4e0b\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2508.06701", "pdf": "https://arxiv.org/pdf/2508.06701", "abs": "https://arxiv.org/abs/2508.06701", "authors": ["Md Rezwanul Haque", "Md. Milon Islam", "S M Taslim Uddin Raju", "Hamdi Altaheri", "Lobna Nassar", "Fakhri Karray"], "title": "MMFformer: Multimodal Fusion Transformer Network for Depression Detection", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.SD", "eess.AS"], "comment": "Accepted for the 2025 IEEE International Conference on Systems, Man,\n  and Cybernetics (SMC), Vienna, Austria", "summary": "Depression is a serious mental health illness that significantly affects an\nindividual's well-being and quality of life, making early detection crucial for\nadequate care and treatment. Detecting depression is often difficult, as it is\nbased primarily on subjective evaluations during clinical interviews. Hence,\nthe early diagnosis of depression, thanks to the content of social networks,\nhas become a prominent research area. The extensive and diverse nature of\nuser-generated information poses a significant challenge, limiting the accurate\nextraction of relevant temporal information and the effective fusion of data\nacross multiple modalities. This paper introduces MMFformer, a multimodal\ndepression detection network designed to retrieve depressive spatio-temporal\nhigh-level patterns from multimodal social media information. The transformer\nnetwork with residual connections captures spatial features from videos, and a\ntransformer encoder is exploited to design important temporal dynamics in\naudio. Moreover, the fusion architecture fused the extracted features through\nlate and intermediate fusion strategies to find out the most relevant\nintermodal correlations among them. Finally, the proposed network is assessed\non two large-scale depression detection datasets, and the results clearly\nreveal that it surpasses existing state-of-the-art approaches, improving the\nF1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is\nmade available publicly at\nhttps://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faMMFformer\u591a\u6a21\u6001\u6291\u90c1\u68c0\u6d4b\u7f51\u7edc\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6291\u90c1\u75c7\u65e9\u671f\u68c0\u6d4b\u91cd\u8981\u4f46\u57fa\u4e8e\u4e34\u5e8a\u8bbf\u8c08\u4e3b\u89c2\u8bc4\u4f30\u56f0\u96be\uff0c\u5229\u7528\u793e\u4ea4\u7f51\u7edc\u5185\u5bb9\u8fdb\u884c\u65e9\u671f\u8bca\u65ad\u6210\u7814\u7a76\u70ed\u70b9\uff0c\u4f46\u9762\u4e34\u4fe1\u606f\u63d0\u53d6\u548c\u878d\u5408\u6311\u6218\u3002", "method": "\u5f15\u5165MMFformer\u7f51\u7edc\uff0c\u7528\u5e26\u6b8b\u5dee\u8fde\u63a5\u7684transformer\u7f51\u7edc\u63d0\u53d6\u89c6\u9891\u7a7a\u95f4\u7279\u5f81\uff0c\u7528transformer\u7f16\u7801\u5668\u8bbe\u8ba1\u97f3\u9891\u65f6\u95f4\u52a8\u6001\uff0c\u901a\u8fc7\u540e\u671f\u548c\u4e2d\u95f4\u878d\u5408\u7b56\u7565\u878d\u5408\u7279\u5f81\u3002", "result": "\u5728\u4e24\u4e2a\u5927\u89c4\u6a21\u6291\u90c1\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cF1\u5206\u6570\u5728D - Vlog\u6570\u636e\u96c6\u63d0\u9ad813.92%\uff0c\u5728LMVD\u6570\u636e\u96c6\u63d0\u9ad87.74%\u3002", "conclusion": "MMFformer\u7f51\u7edc\u5728\u6291\u90c1\u68c0\u6d4b\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.06709", "pdf": "https://arxiv.org/pdf/2508.06709", "abs": "https://arxiv.org/abs/2508.06709", "authors": ["Evangelia Spiliopoulou", "Riccardo Fogliato", "Hanna Burnsky", "Tamer Soliman", "Jie Ma", "Graham Horwood", "Miguel Ballesteros"], "title": "Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) can serve as judges that offer rapid and\nreliable assessments of other LLM outputs. However, models may systematically\nassign overly favorable ratings to their own outputs, a phenomenon known as\nself-bias, which can distort evaluations of true model performance. Previous\nstudies often conflate genuine differences in model quality with bias or\nincorrectly assume that evaluations from LLMs and humans follow the same rating\ndistributions. In this work, we present a statistical framework that explicitly\nformalizes assumptions under which self-bias can be identified and estimated.\nOur method models the difference in the scoring distribution that\nLLM-as-a-judge assigns to its own completions compared to other models, while\naccounting for the underlying quality of the completions provided by an\nindependent, third-party judge (e.g., humans). Our method reliably isolates and\nquantifies self-bias, even when models vary in ability, ensuring that genuine\nperformance differences are not mistaken for self-bias. We conduct an empirical\nanalysis of self-bias on a large dataset (>5000 prompt-completion pairs)\nconsisting of expert human annotations and judgments from nine different LLM\njudges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,\nsystematically assign higher scores to their own outputs. These models also\ndisplay family-bias; systematically assigning higher ratings to outputs\nproduced by other models of the same family. Our findings highlight potential\npitfalls of using LLM judges and offer practical guidance to mitigate biases\nwhen interpreting automated evaluations.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u8ba1\u6846\u67b6\u8bc6\u522b\u548c\u4f30\u8ba1\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u8bc4\u504f\u5dee\uff0c\u5206\u6790\u6570\u636e\u96c6\u53d1\u73b0\u90e8\u5206\u6a21\u578b\u5b58\u5728\u81ea\u8bc4\u548c\u5bb6\u65cf\u504f\u5dee\uff0c\u7ed9\u51fa\u51cf\u8f7b\u504f\u5dee\u5efa\u8bae\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u5e38\u6df7\u6dc6\u6a21\u578b\u8d28\u91cf\u5dee\u5f02\u4e0e\u504f\u5dee\uff0c\u4e14\u9519\u8bef\u5047\u8bbe\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4eba\u7c7b\u8bc4\u4f30\u8bc4\u5206\u5206\u5e03\u76f8\u540c\uff0c\u9700\u89e3\u51b3\u6a21\u578b\u81ea\u8bc4\u504f\u5dee\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7edf\u8ba1\u6846\u67b6\uff0c\u5efa\u6a21\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\u5bf9\u81ea\u8eab\u548c\u5176\u4ed6\u6a21\u578b\u8f93\u51fa\u8bc4\u5206\u5206\u5e03\u5dee\u5f02\uff0c\u7ed3\u5408\u7b2c\u4e09\u65b9\u8bc4\u5224\u8005\u8003\u91cf\u8f93\u51fa\u8d28\u91cf\u3002", "result": "\u5bf9\u8d855000\u4e2a\u63d0\u793a - \u5b8c\u6210\u5bf9\u6570\u636e\u96c6\u5206\u6790\uff0c\u53d1\u73b0GPT - 4o\u548cClaude 3.5 Sonnet\u7b49\u6a21\u578b\u6709\u81ea\u8bc4\u548c\u5bb6\u65cf\u504f\u5dee\u3002", "conclusion": "\u6307\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u7684\u6f5c\u5728\u9677\u9631\uff0c\u63d0\u4f9b\u51cf\u8f7b\u504f\u5dee\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2508.07681", "pdf": "https://arxiv.org/pdf/2508.07681", "abs": "https://arxiv.org/abs/2508.07681", "authors": ["Yooseok Lim", "ByoungJun Jeon", "Seong-A Park", "Jisoo Lee", "Sae Won Choi", "Chang Wook Jeong", "Ho-Geol Ryu", "Hongyeol Lee", "Hyun-Lim Yang"], "title": "MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 5 figures", "summary": "Sepsis, a life-threatening inflammatory response to infection, causes organ\ndysfunction, making early detection and optimal management critical. Previous\nreinforcement learning (RL) approaches to sepsis management rely primarily on\nstructured data, such as lab results or vital signs, and on a dearth of a\ncomprehensive understanding of the patient's condition. In this work, we\npropose a Multimodal Offline REinforcement learning for Clinical notes\nLeveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis\ncontrol in intensive care units. MORE-CLEAR employs pre-trained large-scale\nlanguage models (LLMs) to facilitate the extraction of rich semantic\nrepresentations from clinical notes, preserving clinical context and improving\npatient state representation. Gated fusion and cross-modal attention allow\ndynamic weight adjustment in the context of time and the effective integration\nof multimodal data. Extensive cross-validation using two public (MIMIC-III and\nMIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly\nimproves estimated survival rate and policy performance compared to\nsingle-modal RL approaches. To our knowledge, this is the first to leverage LLM\ncapabilities within a multimodal offline RL for better state representation in\nmedical applications. This approach can potentially expedite the treatment and\nmanagement of sepsis by enabling reinforcement learning models to propose\nenhanced actions based on a more comprehensive understanding of patient\nconditions.", "AI": {"tldr": "\u63d0\u51faMORE - CLEAR\u6846\u67b6\u7528\u4e8e\u91cd\u75c7\u76d1\u62a4\u5ba4\u8113\u6bd2\u75c7\u63a7\u5236\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u4e34\u5e8a\u7b14\u8bb0\u8bed\u4e49\u4fe1\u606f\uff0c\u878d\u5408\u591a\u6a21\u6001\u6570\u636e\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u4f18\u4e8e\u5355\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6216\u53ef\u52a0\u901f\u8113\u6bd2\u75c7\u6cbb\u7597\u7ba1\u7406\u3002", "motivation": "\u4ee5\u5f80\u8113\u6bd2\u75c7\u7ba1\u7406\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u7ed3\u6784\u5316\u6570\u636e\uff0c\u7f3a\u4e4f\u5bf9\u60a3\u8005\u72b6\u51b5\u7684\u5168\u9762\u7406\u89e3\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u8fdb\u884c\u65e9\u671f\u68c0\u6d4b\u548c\u4f18\u5316\u7ba1\u7406\u3002", "method": "\u63d0\u51faMORE - CLEAR\u6846\u67b6\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u4e34\u5e8a\u7b14\u8bb0\u8bed\u4e49\u8868\u793a\uff0c\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u548c\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u52a8\u6001\u8c03\u6574\u6743\u91cd\uff0c\u6709\u6548\u96c6\u6210\u591a\u6a21\u6001\u6570\u636e\u3002", "result": "\u4f7f\u7528\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u79c1\u6709\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u4ea4\u53c9\u9a8c\u8bc1\u8868\u660e\uff0cMORE - CLEAR\u663e\u8457\u63d0\u9ad8\u4e86\u4f30\u8ba1\u751f\u5b58\u7387\u548c\u7b56\u7565\u6027\u80fd\uff0c\u4f18\u4e8e\u5355\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5728\u591a\u6a21\u6001\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u533b\u7597\u5e94\u7528\u72b6\u6001\u8868\u793a\uff0c\u8be5\u65b9\u6cd5\u53ef\u57fa\u4e8e\u5bf9\u60a3\u8005\u72b6\u51b5\u7684\u66f4\u5168\u9762\u7406\u89e3\uff0c\u4f7f\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u63d0\u51fa\u66f4\u4f18\u884c\u52a8\uff0c\u6709\u671b\u52a0\u901f\u8113\u6bd2\u75c7\u7684\u6cbb\u7597\u548c\u7ba1\u7406\u3002"}}
{"id": "2508.06729", "pdf": "https://arxiv.org/pdf/2508.06729", "abs": "https://arxiv.org/abs/2508.06729", "authors": ["Komala Subramanyam Cherukuri", "Pranav Abishai Moses", "Aisa Sakata", "Jiangping Chen", "Haihua Chen"], "title": "Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Oral histories are vital records of lived experience, particularly within\ncommunities affected by systemic injustice and historical erasure. Effective\nand efficient analysis of their oral history archives can promote access and\nunderstanding of the oral histories. However, Large-scale analysis of these\narchives remains limited due to their unstructured format, emotional\ncomplexity, and high annotation costs. This paper presents a scalable framework\nto automate semantic and sentiment annotation for Japanese American\nIncarceration Oral History. Using LLMs, we construct a high-quality dataset,\nevaluate multiple models, and test prompt engineering strategies in\nhistorically sensitive contexts. Our multiphase approach combines expert\nannotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We\nlabeled 558 sentences from 15 narrators for sentiment and semantic\nclassification, then evaluated zero-shot, few-shot, and RAG strategies. For\nsemantic classification, ChatGPT achieved the highest F1 score (88.71%),\nfollowed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama\nslightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models\nshowing comparable results. The best prompt configurations were used to\nannotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our\nfindings show that LLMs can effectively perform semantic and sentiment\nannotation across large oral history collections when guided by well-designed\nprompts. This study provides a reusable annotation pipeline and practical\nguidance for applying LLMs in culturally sensitive archival analysis. By\nbridging archival ethics with scalable NLP techniques, this work lays the\ngroundwork for responsible use of artificial intelligence in digital humanities\nand preservation of collective memory. GitHub:\nhttps://github.com/kc6699c/LLM4OralHistoryAnalysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53ef\u6269\u5c55\u6846\u67b6\u4e3a\u65e5\u88d4\u7f8e\u56fd\u4eba\u76d1\u7981\u53e3\u8ff0\u5386\u53f2\u81ea\u52a8\u8fdb\u884c\u8bed\u4e49\u548c\u60c5\u611f\u6807\u6ce8\uff0c\u7528LLM\u6784\u5efa\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u6a21\u578b\u548c\u6d4b\u8bd5\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u7ed3\u679c\u663e\u793aLLM\u5728\u8bbe\u8ba1\u826f\u597d\u7684\u63d0\u793a\u4e0b\u80fd\u6709\u6548\u6807\u6ce8\uff0c\u8fd8\u63d0\u4f9b\u4e86\u53ef\u590d\u7528\u6d41\u7a0b\u548c\u5e94\u7528\u6307\u5bfc\u3002", "motivation": "\u5927\u89c4\u6a21\u5206\u6790\u53e3\u8ff0\u5386\u53f2\u6863\u6848\u56e0\u975e\u7ed3\u6784\u5316\u683c\u5f0f\u3001\u60c5\u611f\u590d\u6742\u6027\u548c\u9ad8\u6807\u6ce8\u6210\u672c\u53d7\u9650\uff0c\u9700\u6709\u6548\u65b9\u6cd5\u4fc3\u8fdb\u5bf9\u53e3\u8ff0\u5386\u53f2\u7684\u8bbf\u95ee\u548c\u7406\u89e3\u3002", "method": "\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u591a\u4e2a\u6a21\u578b\uff0c\u6d4b\u8bd5\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u65b9\u6cd5\u7ed3\u5408\u4e13\u5bb6\u6807\u6ce8\u3001\u63d0\u793a\u8bbe\u8ba1\u548c\u7528ChatGPT\u3001Llama\u3001Qwen\u8fdb\u884cLLM\u8bc4\u4f30\uff0c\u5bf9\u53e5\u5b50\u8fdb\u884c\u60c5\u611f\u548c\u8bed\u4e49\u5206\u7c7b\u6807\u6ce8\uff0c\u8bc4\u4f30\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548cRAG\u7b56\u7565\u3002", "result": "\u8bed\u4e49\u5206\u7c7b\u4e2dChatGPT\u7684F1\u5206\u6570\u6700\u9ad8\uff0c\u60c5\u611f\u5206\u6790\u4e2dLlama\u7a0d\u80dc\u4e00\u7b79\uff0c\u5404\u6a21\u578b\u7ed3\u679c\u76f8\u8fd1\uff0c\u7528\u6700\u4f73\u63d0\u793a\u914d\u7f6e\u6807\u6ce8JAIOH\u96c6\u5408\u4e2d\u7684\u53e5\u5b50\u3002", "conclusion": "LLM\u5728\u8bbe\u8ba1\u826f\u597d\u7684\u63d0\u793a\u4e0b\u80fd\u5bf9\u5927\u578b\u53e3\u8ff0\u5386\u53f2\u96c6\u5408\u8fdb\u884c\u6709\u6548\u8bed\u4e49\u548c\u60c5\u611f\u6807\u6ce8\uff0c\u63d0\u4f9b\u4e86\u53ef\u590d\u7528\u6807\u6ce8\u6d41\u7a0b\u548c\u5728\u6587\u5316\u654f\u611f\u6863\u6848\u5206\u6790\u4e2d\u5e94\u7528LLM\u7684\u5b9e\u7528\u6307\u5bfc\uff0c\u4e3a\u6570\u5b57\u4eba\u6587\u4e2d\u8d1f\u8d23\u4efb\u4f7f\u7528\u4eba\u5de5\u667a\u80fd\u548c\u96c6\u4f53\u8bb0\u5fc6\u4fdd\u5b58\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.06742", "pdf": "https://arxiv.org/pdf/2508.06742", "abs": "https://arxiv.org/abs/2508.06742", "authors": ["Alejandro Murillo-Gonzalez", "Junhong Xu", "Lantao Liu"], "title": "Learning Causal Structure Distributions for Robust Planning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Structural causal models describe how the components of a robotic system\ninteract. They provide both structural and functional information about the\nrelationships that are present in the system. The structural information\noutlines the variables among which there is interaction. The functional\ninformation describes how such interactions work, via equations or learned\nmodels. In this paper we find that learning the functional relationships while\naccounting for the uncertainty about the structural information leads to more\nrobust dynamics models which improves downstream planning, while using\nsignificantly lower computational resources. This in contrast with common\nmodel-learning methods that ignore the causal structure and fail to leverage\nthe sparsity of interactions in robotic systems. We achieve this by estimating\na causal structure distribution that is used to sample causal graphs that\ninform the latent-space representations in an encoder-multidecoder\nprobabilistic model. We show that our model can be used to learn the dynamics\nof a robot, which together with a sampling-based planner can be used to perform\nnew tasks in novel environments, provided an objective function for the new\nrequirement is available. We validate our method using manipulators and mobile\nrobots in both simulation and the real-world. Additionally, we validate the\nlearned dynamics' adaptability and increased robustness to corrupted inputs and\nchanges in the environment, which is highly desirable in challenging real-world\nrobotics scenarios. Video: https://youtu.be/X6k5t7OOnNc.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8003\u8651\u7ed3\u6784\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\u5b66\u4e60\u529f\u80fd\u5173\u7cfb\uff0c\u80fd\u5f97\u5230\u66f4\u9c81\u68d2\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u7528\u66f4\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6539\u8fdb\u4e0b\u6e38\u89c4\u5212\uff0c\u901a\u8fc7\u4f30\u8ba1\u56e0\u679c\u7ed3\u6784\u5206\u5e03\u5b9e\u73b0\uff0c\u7ecf\u591a\u79cd\u673a\u5668\u4eba\u9a8c\u8bc1\u3002", "motivation": "\u5e38\u89c1\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\u5ffd\u7565\u56e0\u679c\u7ed3\u6784\uff0c\u672a\u5229\u7528\u673a\u5668\u4eba\u7cfb\u7edf\u4ea4\u4e92\u7a00\u758f\u6027\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u5f97\u5230\u66f4\u4f18\u6a21\u578b\u3002", "method": "\u4f30\u8ba1\u56e0\u679c\u7ed3\u6784\u5206\u5e03\uff0c\u91c7\u6837\u56e0\u679c\u56fe\u4e3a\u7f16\u7801\u5668 - \u591a\u89e3\u7801\u5668\u6982\u7387\u6a21\u578b\u7684\u9690\u7a7a\u95f4\u8868\u793a\u63d0\u4f9b\u4fe1\u606f\u3002", "result": "\u6a21\u578b\u53ef\u5b66\u4e60\u673a\u5668\u4eba\u52a8\u529b\u5b66\uff0c\u7ed3\u5408\u91c7\u6837\u89c4\u5212\u5668\u80fd\u5728\u65b0\u73af\u5883\u6267\u884c\u65b0\u4efb\u52a1\uff0c\u9a8c\u8bc1\u4e86\u5b66\u4e60\u52a8\u529b\u5b66\u7684\u9002\u5e94\u6027\u3001\u5bf9\u8f93\u5165\u635f\u574f\u548c\u73af\u5883\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8003\u8651\u7ed3\u6784\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\u5b66\u4e60\u529f\u80fd\u5173\u7cfb\u80fd\u5f97\u5230\u66f4\u9c81\u68d2\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u5728\u673a\u5668\u4eba\u9886\u57df\u6709\u826f\u597d\u5e94\u7528\u6548\u679c\u3002"}}
{"id": "2508.07706", "pdf": "https://arxiv.org/pdf/2508.07706", "abs": "https://arxiv.org/abs/2508.07706", "authors": ["Philipp Huber", "David Li", "Juan Pedro Guti\u00e9rrez Hermosillo Muriedas", "Deifilia Kieckhefen", "Markus G\u00f6tz", "Achim Streit", "Charlotte Debus"], "title": "Energy Consumption in Parallel Neural Network Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The increasing demand for computational resources of training neural networks\nleads to a concerning growth in energy consumption. While parallelization has\nenabled upscaling model and dataset sizes and accelerated training, its impact\non energy consumption is often overlooked. To close this research gap, we\nconducted scaling experiments for data-parallel training of two models,\nResNet50 and FourCastNet, and evaluated the impact of parallelization\nparameters, i.e., GPU count, global batch size, and local batch size, on\npredictive performance, training time, and energy consumption. We show that\nenergy consumption scales approximately linearly with the consumed resources,\ni.e., GPU hours; however, the respective scaling factor differs substantially\nbetween distinct model trainings and hardware, and is systematically influenced\nby the number of samples and gradient updates per GPU hour. Our results shed\nlight on the complex interplay of scaling up neural network training and can\ninform future developments towards more sustainable AI research.", "AI": {"tldr": "\u7814\u7a76\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u4e2d\u5e76\u884c\u5316\u53c2\u6570\u5bf9\u9884\u6d4b\u6027\u80fd\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u80fd\u8017\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u80fd\u8017\u4e0e\u8d44\u6e90\u6d88\u8017\u5173\u7cfb\u53ca\u5f71\u54cd\u56e0\u7d20\u3002", "motivation": "\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u589e\u52a0\u81f4\u80fd\u8017\u589e\u957f\uff0c\u5e76\u884c\u5316\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\u5e38\u88ab\u5ffd\u89c6\uff0c\u586b\u8865\u6b64\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5bf9ResNet50\u548cFourCastNet\u8fdb\u884c\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u7684\u7f29\u653e\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5e76\u884c\u5316\u53c2\u6570\u5f71\u54cd\u3002", "result": "\u80fd\u8017\u4e0e\u6d88\u8017\u8d44\u6e90\uff08GPU\u5c0f\u65f6\uff09\u8fd1\u4f3c\u7ebf\u6027\u76f8\u5173\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u8bad\u7ec3\u548c\u786c\u4ef6\u7684\u7f29\u653e\u56e0\u5b50\u4e0d\u540c\uff0c\u53d7\u6bcfGPU\u5c0f\u65f6\u6837\u672c\u6570\u548c\u68af\u5ea6\u66f4\u65b0\u6570\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6269\u5c55\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\uff0c\u4e3a\u53ef\u6301\u7eedAI\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2508.07710", "pdf": "https://arxiv.org/pdf/2508.07710", "abs": "https://arxiv.org/abs/2508.07710", "authors": ["Jingya Wang", "Xin Deng", "Wenjie Wei", "Dehao Zhang", "Shuai Wang", "Qian Sun", "Jieyuan Zhang", "Hanwen Liu", "Ning Xie", "Malu Zhang"], "title": "Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a\npromising approach for constructing energy-efficient Transformer architectures.\nCompared to directly trained Spiking Transformers, ANN-to-SNN conversion\nmethods bypass the high training costs. However, existing methods still suffer\nfrom notable limitations, failing to effectively handle nonlinear operations in\nTransformer architectures and requiring additional fine-tuning processes for\npre-trained ANNs. To address these issues, we propose a high-performance and\ntraining-free ANN-to-SNN conversion framework tailored for Transformer\narchitectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE)\nneuron, which employs an exponential decay strategy and multi-basis encoding\nmethod to efficiently approximate various nonlinear operations. It removes the\nrequirement for weight modifications in pre-trained ANNs. Extensive experiments\nacross diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures\n(ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless\nconversion accuracy with significantly lower latency. This provides a promising\npathway for the efficient and scalable deployment of Spiking Transformers in\nreal-world applications.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8eTransformer\u67b6\u6784\u7684\u65e0\u8bad\u7ec3ANN - SNN\u8f6c\u6362\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u8f6c\u6362\u7cbe\u5ea6\u9ad8\u3001\u5ef6\u8fdf\u4f4e\u3002", "motivation": "\u73b0\u6709ANN - SNN\u8f6c\u6362\u65b9\u6cd5\u5728\u5904\u7406Transformer\u67b6\u6784\u975e\u7ebf\u6027\u64cd\u4f5c\u6709\u5c40\u9650\uff0c\u4e14\u9700\u9884\u8bad\u7ec3ANN\u5fae\u8c03\u3002", "method": "\u63d0\u51faMulti - basis Exponential Decay (MBE)\u795e\u7ecf\u5143\uff0c\u7528\u6307\u6570\u8870\u51cf\u7b56\u7565\u548c\u591a\u57fa\u7f16\u7801\u65b9\u6cd5\u8fd1\u4f3c\u975e\u7ebf\u6027\u64cd\u4f5c\uff0c\u65e0\u9700\u4fee\u6539\u9884\u8bad\u7ec3ANN\u6743\u91cd\u3002", "result": "\u5728\u591a\u79cd\u4efb\u52a1\u548c\u4e3b\u6d41Transformer\u67b6\u6784\u5b9e\u9a8c\u4e2d\uff0c\u5b9e\u73b0\u8fd1\u65e0\u635f\u8f6c\u6362\u7cbe\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u3002", "conclusion": "\u4e3a\u8109\u51b2Transformer\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u9ad8\u6548\u53ef\u6269\u5c55\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2508.06755", "pdf": "https://arxiv.org/pdf/2508.06755", "abs": "https://arxiv.org/abs/2508.06755", "authors": ["Xianjun Yang", "Liqiang Xiao", "Shiyang Li", "Faisal Ladhak", "Hyokun Yun", "Linda Ruth Petzold", "Yi Xu", "William Yang Wang"], "title": "Many-Turn Jailbreaking", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Current jailbreaking work on large language models (LLMs) aims to elicit\nunsafe outputs from given prompts. However, it only focuses on single-turn\njailbreaking targeting one specific query. On the contrary, the advanced LLMs\nare designed to handle extremely long contexts and can thus conduct multi-turn\nconversations. So, we propose exploring multi-turn jailbreaking, in which the\njailbroken LLMs are continuously tested on more than the first-turn\nconversation or a single target query. This is an even more serious threat\nbecause 1) it is common for users to continue asking relevant follow-up\nquestions to clarify certain jailbroken details, and 2) it is also possible\nthat the initial round of jailbreaking causes the LLMs to respond to additional\nirrelevant questions consistently. As the first step (First draft done at June\n2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak\nBenchmark (MTJ-Bench) for benchmarking this setting on a series of open- and\nclosed-source models and provide novel insights into this new safety threat. By\nrevealing this new vulnerability, we aim to call for community efforts to build\nsafer LLMs and pave the way for a more in-depth understanding of jailbreaking\nLLMs.", "AI": {"tldr": "\u63d0\u51fa\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\uff0c\u6784\u5efaMTJ - Bench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u5e76\u63ed\u793a\u65b0\u6f0f\u6d1e\uff0c\u547c\u5401\u6784\u5efa\u66f4\u5b89\u5168\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u5de5\u4f5c\u591a\u4e3a\u5355\u8f6e\uff0c\u800c\u5148\u8fdb\u6a21\u578b\u53ef\u8fdb\u884c\u591a\u8f6e\u5bf9\u8bdd\uff0c\u591a\u8f6e\u8d8a\u72f1\u5a01\u80c1\u66f4\u4e25\u91cd\uff0c\u9700\u63a2\u7d22\u3002", "method": "\u6784\u5efaMulti - Turn Jailbreak Benchmark\uff08MTJ - Bench\uff09\u5728\u4e00\u7cfb\u5217\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8f6e\u8d8a\u72f1\u8fd9\u4e00\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "conclusion": "\u547c\u5401\u793e\u533a\u5171\u540c\u52aa\u529b\u6784\u5efa\u66f4\u5b89\u5168\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e3a\u6df1\u5165\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2508.06756", "pdf": "https://arxiv.org/pdf/2508.06756", "abs": "https://arxiv.org/abs/2508.06756", "authors": ["Somayeh Farahani", "Marjaneh Hejazi", "Antonio Di Ieva", "Sidong Liu"], "title": "FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted for oral and poster presentation at MICCAI 2025", "summary": "Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is\nessential for effective glioma management. Traditional methods rely on invasive\ntissue sampling, which may fail to capture a tumor's spatial heterogeneity.\nWhile deep learning models have shown promise in molecular profiling, their\nperformance is often limited by scarce annotated data. In contrast, foundation\ndeep learning models offer a more generalizable approach for glioma imaging\nbiomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that\nutilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation\nstatus from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware\nFeature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and\nCross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch\nsignals associated with IDH mutation. The model was trained and validated on a\ndiverse, multi-center cohort of 1705 glioma patients from six public datasets.\nOur model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent\ntest sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming\nbaseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE\nand CMD modules are essential for improving predictive accuracy. By integrating\nlarge-scale pretraining and task-specific fine-tuning, FoundBioNet enables\ngeneralizable glioma characterization. This approach enhances diagnostic\naccuracy and interpretability, with the potential to enable more personalized\npatient care.", "AI": {"tldr": "\u63d0\u51faFoundBioNet\u6a21\u578b\u975e\u4fb5\u5165\u6027\u9884\u6d4b\u8111\u80f6\u8d28\u7624IDH\u7a81\u53d8\u72b6\u6001\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u589e\u5f3a\u8bca\u65ad\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4fb5\u5165\u6027\u7ec4\u7ec7\u91c7\u6837\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53d7\u9650\u4e8e\u6807\u6ce8\u6570\u636e\uff0c\u9700\u66f4\u901a\u7528\u65b9\u6cd5\u68c0\u6d4b\u8111\u80f6\u8d28\u7624IDH\u7a81\u53d8\u3002", "method": "\u63d0\u51faFoundBioNet\u6a21\u578b\uff0c\u91c7\u7528SWIN - UNETR\u67b6\u6784\uff0c\u542bTAFE\u548cCMD\u6a21\u5757\uff0c\u5728\u516d\u4e2a\u516c\u5171\u6570\u636e\u96c6\u76841705\u4f8b\u60a3\u8005\u4e2d\u8bad\u7ec3\u9a8c\u8bc1\u3002", "result": "\u6a21\u578b\u5728\u591a\u4e2a\u72ec\u7acb\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f97\u9ad8AUC\u503c\uff0c\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e24\u6a21\u5757\u5bf9\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "FoundBioNet\u7ed3\u5408\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u548c\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\uff0c\u53ef\u5b9e\u73b0\u53ef\u63a8\u5e7f\u7684\u8111\u80f6\u8d28\u7624\u7279\u5f81\u63cf\u8ff0\uff0c\u6709\u671b\u5b9e\u73b0\u66f4\u4e2a\u6027\u5316\u7684\u60a3\u8005\u62a4\u7406\u3002"}}
{"id": "2508.07722", "pdf": "https://arxiv.org/pdf/2508.07722", "abs": "https://arxiv.org/abs/2508.07722", "authors": ["Pietro Talli", "Federico Mason", "Federico Chiariotti", "Andrea Zanella"], "title": "Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations", "categories": ["cs.LG", "cs.IT", "cs.MA", "math.IT"], "comment": "This manuscript is currently under revision", "summary": "In this work, we address the problem of training Reinforcement Learning (RL)\nagents over communication networks. The RL paradigm requires the agent to\ninstantaneously perceive the state evolution to infer the effects of its\nactions on the environment. This is impossible if the agent receives state\nupdates over lossy or delayed wireless systems and thus operates with partial\nand intermittent information. In recent years, numerous frameworks have been\nproposed to manage RL with imperfect feedback; however, they often offer\nspecific solutions with a substantial computational burden. To address these\nlimits, we propose a novel architecture, named Homomorphic Robust Remote\nReinforcement Learning (HR3L), that enables the training of remote RL agents\nexchanging observations across a non-ideal wireless channel. HR3L considers two\nunits: the transmitter, which encodes meaningful representations of the\nenvironment, and the receiver, which decodes these messages and performs\nactions to maximize a reward signal. Importantly, HR3L does not require the\nexchange of gradient information across the wireless channel, allowing for\nquicker training and a lower communication overhead than state-of-the-art\nsolutions. Experimental results demonstrate that HR3L significantly outperforms\nbaseline methods in terms of sample efficiency and adapts to different\ncommunication scenarios, including packet losses, delayed transmissions, and\ncapacity limitations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHR3L\u67b6\u6784\u89e3\u51b3\u901a\u4fe1\u7f51\u7edc\u4e2d\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u8bad\u7ec3\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5728\u6709\u635f\u8017\u6216\u5ef6\u8fdf\u7684\u65e0\u7ebf\u7cfb\u7edf\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u56e0\u63a5\u6536\u72b6\u6001\u66f4\u65b0\u4e0d\u5b8c\u6574\u800c\u65e0\u6cd5\u5373\u65f6\u611f\u77e5\u72b6\u6001\u6f14\u53d8\uff0c\u4ee5\u53ca\u73b0\u6709\u5904\u7406\u4e0d\u5b8c\u7f8e\u53cd\u9988\u7684\u6846\u67b6\u8ba1\u7b97\u8d1f\u62c5\u5927\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faHomomorphic Robust Remote Reinforcement Learning (HR3L) \u67b6\u6784\uff0c\u5305\u542b\u7f16\u7801\u73af\u5883\u4fe1\u606f\u7684\u53d1\u5c04\u673a\u548c\u89e3\u7801\u4fe1\u606f\u5e76\u6267\u884c\u52a8\u4f5c\u7684\u63a5\u6536\u673a\uff0c\u4e14\u65e0\u9700\u5728\u65e0\u7ebf\u4fe1\u9053\u4ea4\u6362\u68af\u5ea6\u4fe1\u606f\u3002", "result": "HR3L\u5728\u6837\u672c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u9002\u5e94\u4e0d\u540c\u901a\u4fe1\u573a\u666f\u3002", "conclusion": "HR3L\u67b6\u6784\u80fd\u6709\u6548\u89e3\u51b3\u901a\u4fe1\u7f51\u7edc\u4e2d\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u8bad\u7ec3\u95ee\u9898\uff0c\u5177\u6709\u66f4\u5feb\u7684\u8bad\u7ec3\u901f\u5ea6\u548c\u66f4\u4f4e\u7684\u901a\u4fe1\u5f00\u9500\u3002"}}
{"id": "2508.06763", "pdf": "https://arxiv.org/pdf/2508.06763", "abs": "https://arxiv.org/abs/2508.06763", "authors": ["Zihao Sheng", "Zilin Huang", "Yen-Jung Chen", "Yansong Qu", "Yuhao Luo", "Yue Leng", "Sikai Chen"], "title": "SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding", "categories": ["cs.CV", "cs.AI"], "comment": "The code, dataset, and model checkpoints will be made publicly\n  available at: https://zihaosheng.github.io/SafePLUG", "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress\nacross a range of vision-language tasks and demonstrate strong potential for\ntraffic accident understanding. However, existing MLLMs in this domain\nprimarily focus on coarse-grained image-level or video-level comprehension and\noften struggle to handle fine-grained visual details or localized scene\ncomponents, limiting their applicability in complex accident scenarios. To\naddress these limitations, we propose SafePLUG, a novel framework that empowers\nMLLMs with both Pixel-Level Understanding and temporal Grounding for\ncomprehensive traffic accident analysis. SafePLUG supports both\narbitrary-shaped visual prompts for region-aware question answering and\npixel-level segmentation based on language instructions, while also enabling\nthe recognition of temporally anchored events in traffic accident scenarios. To\nadvance the development of MLLMs for traffic accident understanding, we curate\na new dataset containing multimodal question-answer pairs centered on diverse\naccident scenarios, with detailed pixel-level annotations and temporal event\nboundaries. Experimental results show that SafePLUG achieves strong performance\non multiple tasks, including region-based question answering, pixel-level\nsegmentation, temporal event localization, and accident event understanding.\nThese capabilities lay a foundation for fine-grained understanding of complex\ntraffic scenes, with the potential to improve driving safety and enhance\nsituational awareness in smart transportation systems. The code, dataset, and\nmodel checkpoints will be made publicly available at:\nhttps://zihaosheng.github.io/SafePLUG", "AI": {"tldr": "\u63d0\u51faSafePLUG\u6846\u67b6\u7528\u4e8e\u4ea4\u901a\u610f\u5916\u5206\u6790\uff0c\u6574\u7406\u65b0\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u5728\u591a\u4efb\u52a1\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u901a\u610f\u5916\u7406\u89e3\u9886\u57df\u4e3b\u8981\u5173\u6ce8\u7c97\u7c92\u5ea6\u7406\u89e3\uff0c\u96be\u4ee5\u5904\u7406\u7ec6\u7c92\u5ea6\u89c6\u89c9\u7ec6\u8282\u6216\u5c40\u90e8\u573a\u666f\u7ec4\u4ef6\uff0c\u9650\u5236\u5176\u5728\u590d\u6742\u4e8b\u6545\u573a\u666f\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faSafePLUG\u6846\u67b6\uff0c\u652f\u6301\u4efb\u610f\u5f62\u72b6\u89c6\u89c9\u63d0\u793a\u3001\u57fa\u4e8e\u8bed\u8a00\u6307\u4ee4\u7684\u50cf\u7d20\u7ea7\u5206\u5272\u548c\u65f6\u95f4\u951a\u5b9a\u4e8b\u4ef6\u8bc6\u522b\uff1b\u6574\u7406\u5305\u542b\u591a\u6a21\u6001\u95ee\u7b54\u5bf9\u3001\u8be6\u7ec6\u50cf\u7d20\u7ea7\u6ce8\u91ca\u548c\u65f6\u95f4\u4e8b\u4ef6\u8fb9\u754c\u7684\u65b0\u6570\u636e\u96c6\u3002", "result": "SafePLUG\u5728\u57fa\u4e8e\u533a\u57df\u7684\u95ee\u7b54\u3001\u50cf\u7d20\u7ea7\u5206\u5272\u3001\u65f6\u95f4\u4e8b\u4ef6\u5b9a\u4f4d\u548c\u4e8b\u6545\u4e8b\u4ef6\u7406\u89e3\u7b49\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "SafePLUG\u4e3a\u590d\u6742\u4ea4\u901a\u573a\u666f\u7684\u7ec6\u7c92\u5ea6\u7406\u89e3\u5960\u5b9a\u57fa\u7840\uff0c\u6709\u6f5c\u529b\u63d0\u9ad8\u9a7e\u9a76\u5b89\u5168\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u6001\u52bf\u611f\u77e5\u80fd\u529b\u3002"}}
{"id": "2508.07738", "pdf": "https://arxiv.org/pdf/2508.07738", "abs": "https://arxiv.org/abs/2508.07738", "authors": ["Jialu Zhou", "Dianxi Shi", "Shaowu Yang", "Xinyu Wei", "Mingyue Yang", "Leqian Li", "Mengzhu Wang", "Chunping Qiu"], "title": "Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Multi-Domain Continual Learning (MDCL) acquires knowledge from sequential\ntasks with shifting class sets and distribution. Despite the\nParameter-Efficient Fine-Tuning (PEFT) methods can adapt for this dual\nheterogeneity, they still suffer from catastrophic forgetting and forward\nforgetting. To address these challenges, we propose a Two-Level Routing Grouped\nMixture-of-Experts (TRGE) method. Firstly, TRGE dynamically expands the\npre-trained CLIP model, assigning specific expert group for each task to\nmitigate catastrophic forgetting. With the number of experts continually grows\nin this process, TRGE maintains the static experts count within the group and\nintroduces the intra-group router to alleviate routing overfitting caused by\nthe increasing routing complexity. Meanwhile, we design an inter-group routing\npolicy based on task identifiers and task prototype distance, which dynamically\nselects relevant expert groups and combines their outputs to enhance inter-task\ncollaboration. Secondly, to get the correct task identifiers, we leverage\nMultimodal Large Language Models (MLLMs) which own powerful multimodal\ncomprehension capabilities to generate semantic task descriptions and recognize\nthe correct task identifier. Finally, to mitigate forward forgetting, we\ndynamically fuse outputs for unseen samples from the frozen CLIP model and TRGE\nadapter based on training progress, leveraging both pre-trained and learned\nknowledge. Through extensive experiments across various settings, our method\noutperforms other advanced methods with fewer trainable parameters.", "AI": {"tldr": "\u63d0\u51faTRGE\u65b9\u6cd5\u89e3\u51b3MDCL\u4e2d\u9057\u5fd8\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u679c\u4f73\u4e14\u53ef\u8bad\u7ec3\u53c2\u6570\u5c11\u3002", "motivation": "\u73b0\u6709PEFT\u65b9\u6cd5\u7528\u4e8eMDCL\u65f6\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u524d\u5411\u9057\u5fd8\u95ee\u9898\u3002", "method": "\u63d0\u51faTRGE\u65b9\u6cd5\uff0c\u52a8\u6001\u6269\u5c55\u9884\u8bad\u7ec3CLIP\u6a21\u578b\uff0c\u8bbe\u8ba1\u7ec4\u5185\u548c\u7ec4\u95f4\u8def\u7531\u7b56\u7565\uff1b\u7528MLLMs\u751f\u6210\u8bed\u4e49\u4efb\u52a1\u63cf\u8ff0\u83b7\u53d6\u4efb\u52a1\u6807\u8bc6\u7b26\uff1b\u52a8\u6001\u878d\u5408\u51bb\u7ed3CLIP\u6a21\u578b\u548cTRGE\u9002\u914d\u5668\u8f93\u51fa\u3002", "result": "\u5728\u4e0d\u540c\u8bbe\u7f6e\u7684\u5927\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4ee5\u8f83\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u8d85\u8d8a\u5176\u4ed6\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684TRGE\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3MDCL\u4e2d\u7684\u9057\u5fd8\u95ee\u9898\u3002"}}
{"id": "2508.07750", "pdf": "https://arxiv.org/pdf/2508.07750", "abs": "https://arxiv.org/abs/2508.07750", "authors": ["Haowen Wang", "Yun Yue", "Zhiling Ye", "Shuowen Zhang", "Lei Fan", "Jiaxin Liang", "Jiadi Jiang", "Cheng Wei", "Jingyuan Deng", "Xudong Han", "Ji Li", "Chunxiao Guo", "Peng Wei", "Jian Wang", "Jinjie Gu"], "title": "Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "12 pages, 5 figures, 7 tables", "summary": "Alignment methodologies have emerged as a critical pathway for enhancing\nlanguage model alignment capabilities. While SFT (supervised fine-tuning)\naccelerates convergence through direct token-level loss intervention, its\nefficacy is constrained by offline policy trajectory. In contrast,\nRL(reinforcement learning) facilitates exploratory policy optimization, but\nsuffers from low sample efficiency and stringent dependency on high-quality\nbase models. To address these dual challenges, we propose GRAO (Group Relative\nAlignment Optimization), a unified framework that synergizes the respective\nstrengths of SFT and RL through three key innovations: 1) A multi-sample\ngeneration strategy enabling comparative quality assessment via reward\nfeedback; 2) A novel Group Direct Alignment Loss formulation leveraging\nintra-group relative advantage weighting; 3) Reference-aware parameter updates\nguided by pairwise preference dynamics. Our theoretical analysis establishes\nGRAO's convergence guarantees and sample efficiency advantages over\nconventional approaches. Comprehensive evaluations across complex human\nalignment tasks demonstrate GRAO's superior performance, achieving\n57.70\\%,17.65\\% 7.95\\% and 5.18\\% relative improvements over SFT, DPO, PPO and\nGRPO baselines respectively. This work provides both a theoretically grounded\nalignment framework and empirical evidence for efficient capability evolution\nin language models.", "AI": {"tldr": "\u63d0\u51faGRAO\u6846\u67b6\u7ed3\u5408SFT\u548cRL\u4f18\u52bf\uff0c\u6709\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\uff0c\u5728\u4eba\u7c7b\u5bf9\u9f50\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u3002", "motivation": "SFT\u53d7\u79bb\u7ebf\u7b56\u7565\u8f68\u8ff9\u9650\u5236\uff0cRL\u6837\u672c\u6548\u7387\u4f4e\u4e14\u4f9d\u8d56\u9ad8\u8d28\u91cf\u57fa\u7840\u6a21\u578b\uff0c\u9700\u89e3\u51b3\u4e24\u8005\u95ee\u9898\u3002", "method": "\u63d0\u51faGRAO\u6846\u67b6\uff0c\u6709\u4e09\u4e2a\u521b\u65b0\u70b9\uff1a\u591a\u6837\u672c\u751f\u6210\u7b56\u7565\u3001\u7ec4\u76f4\u63a5\u5bf9\u9f50\u635f\u5931\u516c\u5f0f\u3001\u53c2\u8003\u611f\u77e5\u53c2\u6570\u66f4\u65b0\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eGRAO\u6709\u6536\u655b\u4fdd\u8bc1\u548c\u6837\u672c\u6548\u7387\u4f18\u52bf\uff0c\u7efc\u5408\u8bc4\u4f30\u4e2d\u6bd4SFT\u3001DPO\u3001PPO\u548cGRPO\u57fa\u7ebf\u5206\u522b\u670957.70%\u300117.65%\u30017.95%\u548c5.18%\u7684\u76f8\u5bf9\u63d0\u5347\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u7406\u8bba\u53ef\u9760\u7684\u5bf9\u9f50\u6846\u67b6\u548c\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u9ad8\u6548\u8fdb\u5316\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002"}}
{"id": "2508.07763", "pdf": "https://arxiv.org/pdf/2508.07763", "abs": "https://arxiv.org/abs/2508.07763", "authors": ["Martin Rektoris", "Milan Pape\u017e", "V\u00e1clav \u0160m\u00eddl", "Tom\u00e1\u0161 Pevn\u00fd"], "title": "Sparse Probabilistic Graph Circuits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep generative models (DGMs) for graphs achieve impressively high expressive\npower thanks to very efficient and scalable neural networks. However, these\nnetworks contain non-linearities that prevent analytical computation of many\nstandard probabilistic inference queries, i.e., these DGMs are considered\n\\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs)\naddress this issue by enabling \\emph{tractable} probabilistic inference, they\noperate on dense graph representations with $\\mathcal{O}(n^2)$ complexity for\ngraphs with $n$ nodes and \\emph{$m$ edges}. To address this scalability issue,\nwe introduce Sparse PGCs, a new class of tractable generative models that\noperate directly on sparse graph representation, reducing the complexity to\n$\\mathcal{O}(n + m)$, which is particularly beneficial for $m \\ll n^2$. In the\ncontext of de novo drug design, we empirically demonstrate that SPGCs retain\nexact inference capabilities, improve memory efficiency and inference speed,\nand match the performance of intractable DGMs in key metrics.", "AI": {"tldr": "\u63d0\u51faSparse PGCs\u5904\u7406\u56fe\u751f\u6210\u6a21\u578b\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u836f\u7269\u8bbe\u8ba1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u56fe\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u96be\u4ee5\u8fdb\u884c\u6982\u7387\u63a8\u7406\uff0cProbabilistic Graph Circuits\u867d\u53ef\u89e3\u51b3\u4f46\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165Sparse PGCs\uff0c\u76f4\u63a5\u5728\u7a00\u758f\u56fe\u8868\u793a\u4e0a\u64cd\u4f5c\uff0c\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "result": "\u5728\u836f\u7269\u8bbe\u8ba1\u4e2d\uff0cSPGCs\u4fdd\u7559\u7cbe\u786e\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u9ad8\u5185\u5b58\u6548\u7387\u548c\u63a8\u7406\u901f\u5ea6\uff0c\u5173\u952e\u6307\u6807\u8868\u73b0\u4e0e\u96be\u5904\u7406\u7684\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "Sparse PGCs\u80fd\u6709\u6548\u89e3\u51b3\u56fe\u751f\u6210\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2508.07768", "pdf": "https://arxiv.org/pdf/2508.07768", "abs": "https://arxiv.org/abs/2508.07768", "authors": ["Qiang He", "Setareh Maghsudi"], "title": "Pareto Multi-Objective Alignment for Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted at ECML/PKDD 2025", "summary": "Large language models (LLMs) are increasingly deployed in real-world\napplications that require careful balancing of multiple, often conflicting,\nobjectives, such as informativeness versus conciseness, or helpfulness versus\ncreativity. However, current alignment methods, primarily based on RLHF,\noptimize LLMs toward a single reward function, resulting in rigid behavior that\nfails to capture the complexity and diversity of human preferences. This\nlimitation hinders the adaptability of LLMs to practical scenarios, making\nmulti-objective alignment (MOA) a critical yet underexplored area. To bridge\nthis gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and\ncomputationally efficient algorithm designed explicitly for MOA in LLMs. In\ncontrast to computationally prohibitive multi-objective optimization (MOO)\nmethods, PAMA transforms multi-objective RLHF into a convex optimization with a\nclosed-form solution, significantly enhancing scalability. Traditional MOO\napproaches suffer from prohibitive O(n^2*d) complexity, where d represents the\nnumber of model parameters, typically in the billions for LLMs, rendering\ndirect optimization infeasible. PAMA reduces this complexity to O(n) where n is\nthe number of objectives, enabling optimization to be completed within\nmilliseconds. We provide theoretical guarantees that PAMA converges to a Pareto\nstationary point, where no objective can be improved without degrading at least\none other. Extensive experiments across language models ranging from 125M to 7B\nparameters demonstrate PAMA's robust and effective MOA capabilities, aligning\nwith its theoretical advantages. PAMA provides a highly efficient solution to\nthe MOA problem that was previously considered intractable, offering a\npractical and theoretically grounded approach to aligning LLMs with diverse\nhuman values, paving the way for versatile and adaptable real-world AI\ndeployments.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\u57fa\u4e8e\u5355\u4e00\u5956\u52b1\u51fd\u6570\uff0c\u7f3a\u4e4f\u591a\u76ee\u6807\u5bf9\u9f50\u80fd\u529b\u3002\u672c\u6587\u63d0\u51faPAMA\u7b97\u6cd5\uff0c\u5c06\u591a\u76ee\u6807RLHF\u8f6c\u5316\u4e3a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u964d\u4f4e\u590d\u6742\u5ea6\u4e14\u6709\u7406\u8bba\u4fdd\u8bc1\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eRLHF\u7684\u5bf9\u9f50\u65b9\u6cd5\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5355\u4e00\u5956\u52b1\u51fd\u6570\uff0c\u5bfc\u81f4\u884c\u4e3a\u50f5\u5316\uff0c\u65e0\u6cd5\u9002\u5e94\u5b9e\u9645\u573a\u666f\u7684\u591a\u76ee\u6807\u9700\u6c42\uff0c\u591a\u76ee\u6807\u5bf9\u9f50\u662f\u5173\u952e\u4f46\u672a\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002", "method": "\u63d0\u51faPareto Multi-Objective Alignment (PAMA)\u7b97\u6cd5\uff0c\u5c06\u591a\u76ee\u6807RLHF\u8f6c\u5316\u4e3a\u6709\u95ed\u5f0f\u89e3\u7684\u51f8\u4f18\u5316\u95ee\u9898\u3002", "result": "PAMA\u5c06\u590d\u6742\u5ea6\u4eceO(n^2*d)\u964d\u81f3O(n)\uff0c\u80fd\u5728\u6beb\u79d2\u5185\u5b8c\u6210\u4f18\u5316\uff0c\u7406\u8bba\u4e0a\u6536\u655b\u5230Pareto\u5e73\u7a33\u70b9\uff0c\u5728125M\u52307B\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u4e86\u5f3a\u5927\u6709\u6548\u7684\u591a\u76ee\u6807\u5bf9\u9f50\u80fd\u529b\u3002", "conclusion": "PAMA\u4e3a\u591a\u76ee\u6807\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u591a\u6837\u4ef7\u503c\u89c2\u5bf9\u9f50\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u6709\u7406\u8bba\u4f9d\u636e\u7684\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8eAI\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u7075\u6d3b\u90e8\u7f72\u3002"}}
{"id": "2508.07807", "pdf": "https://arxiv.org/pdf/2508.07807", "abs": "https://arxiv.org/abs/2508.07807", "authors": ["Rahul Khorana"], "title": "Topological Feature Compression for Molecular Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in molecular representation learning have produced highly\neffective encodings of molecules for numerous cheminformatics and\nbioinformatics tasks. However, extracting general chemical insight while\nbalancing predictive accuracy, interpretability, and computational efficiency\nremains a major challenge. In this work, we introduce a novel Graph Neural\nNetwork (GNN) architecture that combines compressed higher-order topological\nsignals with standard molecular features. Our approach captures global\ngeometric information while preserving computational tractability and\nhuman-interpretable structure. We evaluate our model across a range of\nbenchmarks, from small-molecule datasets to complex material datasets, and\ndemonstrate superior performance using a parameter-efficient architecture. We\nachieve the best performing results in both accuracy and robustness across\nalmost all benchmarks. We open source all code \\footnote{All code and results\ncan be found on Github https://github.com/rahulkhorana/TFC-PACT-Net}.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u538b\u7f29\u9ad8\u9636\u62d3\u6251\u4fe1\u53f7\u4e0e\u6807\u51c6\u5206\u5b50\u7279\u5f81\u7684\u65b0\u578bGNN\u67b6\u6784\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u5e76\u5f00\u6e90\u4ee3\u7801", "motivation": "\u73b0\u6709\u5206\u5b50\u8868\u793a\u5b66\u4e60\u5728\u63d0\u53d6\u5316\u5b66\u89c1\u89e3\u65f6\u96be\u4ee5\u5e73\u8861\u9884\u6d4b\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387", "method": "\u5f15\u5165\u7ed3\u5408\u538b\u7f29\u9ad8\u9636\u62d3\u6251\u4fe1\u53f7\u4e0e\u6807\u51c6\u5206\u5b50\u7279\u5f81\u7684\u65b0\u578bGNN\u67b6\u6784", "result": "\u5728\u4ece\u5c0f\u5206\u5b50\u6570\u636e\u96c6\u5230\u590d\u6742\u6750\u6599\u6570\u636e\u96c6\u7b49\u4e00\u7cfb\u5217\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u7684\u67b6\u6784\u5c55\u793a\u4e86\u5353\u8d8a\u6027\u80fd\uff0c\u5728\u51e0\u4e4e\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u53d6\u5f97\u4e86\u6700\u4f73\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u7ed3\u679c", "conclusion": "\u8be5\u65b0\u578bGNN\u67b6\u6784\u6709\u6548\uff0c\u80fd\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d"}}
{"id": "2508.07809", "pdf": "https://arxiv.org/pdf/2508.07809", "abs": "https://arxiv.org/abs/2508.07809", "authors": ["Huanyu Liu", "Jia Li", "Chang Yu", "Taozhi Chen", "Yihong Dong", "Lecheng Wang", "Hu XiaoLong", "Ge Li"], "title": "EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning with verifiable reward (RLVR) has become a promising\nparadigm for post-training large language models (LLMs) to improve their\nreasoning capability. However, when the rollout accuracy is low on hard\nproblems, the reward becomes sparse, limiting learning efficiency and causing\nexploration bottlenecks. Existing approaches either rely on stronger LLMs for\ndistillation or filter out difficult problems, which limits scalability or\nrestricts reasoning improvement through exploration.\n  We propose EvoCoT, a self-evolving curriculum learning framework based on\ntwo-stage chain-of-thought (CoT) reasoning optimization. EvoCoT constrains the\nexploration space by self-generating and verifying CoT trajectories, then\ngradually shortens them to expand the space in a controlled way. This enables\nLLMs to stably learn from initially unsolved hard problems under sparse\nrewards. We apply EvoCoT to multiple LLM families, including Qwen, DeepSeek,\nand Llama. Experiments show that EvoCoT enables LLMs to solve previously\nunsolved problems, improves reasoning capability without external CoT\nsupervision, and is compatible with various RL fine-tuning methods. We release\nthe source code to support future research.", "AI": {"tldr": "\u63d0\u51faEvoCoT\u6846\u67b6\u89e3\u51b3RLVR\u5728\u786c\u95ee\u9898\u4e0a\u5956\u52b1\u7a00\u758f\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709RLVR\u5728\u786c\u95ee\u9898\u4e0a\u5956\u52b1\u7a00\u758f\uff0c\u9650\u5236\u5b66\u4e60\u6548\u7387\u548c\u63a2\u7d22\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e24\u9636\u6bb5\u601d\u7ef4\u94fe\u63a8\u7406\u4f18\u5316\u7684\u81ea\u8fdb\u5316\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6EvoCoT\uff0c\u901a\u8fc7\u81ea\u751f\u6210\u548c\u9a8c\u8bc1\u601d\u7ef4\u94fe\u8f68\u8ff9\u7ea6\u675f\u63a2\u7d22\u7a7a\u95f4\u5e76\u9010\u6b65\u6269\u5c55\u3002", "result": "EvoCoT\u4f7f\u5927\u6a21\u578b\u89e3\u51b3\u4e4b\u524d\u65e0\u6cd5\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u5728\u65e0\u5916\u90e8\u601d\u7ef4\u94fe\u76d1\u7763\u4e0b\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u517c\u5bb9\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u3002", "conclusion": "EvoCoT\u6709\u6548\uff0c\u5df2\u5f00\u6e90\u4ee3\u7801\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2508.06799", "pdf": "https://arxiv.org/pdf/2508.06799", "abs": "https://arxiv.org/abs/2508.06799", "authors": ["Naiyi Li", "Zihui Ma", "Runlong Yu", "Lingyao Li"], "title": "LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning", "categories": ["cs.ET", "cs.AI"], "comment": null, "summary": "Digital Twins (DTs) offer powerful tools for managing complex infrastructure\nsystems, but their effectiveness is often limited by challenges in integrating\nunstructured knowledge. Recent advances in Large Language Models (LLMs) bring\nnew potential to address this gap, with strong abilities in extracting and\norganizing diverse textual information. We therefore propose LSDTs\n(LLM-Augmented Semantic Digital Twins), a framework that helps LLMs extract\nplanning knowledge from unstructured documents like environmental regulations\nand technical guidelines, and organize it into a formal ontology. This ontology\nforms a semantic layer that powers a digital twin-a virtual model of the\nphysical system-allowing it to simulate realistic, regulation-aware planning\nscenarios. We evaluate LSDTs through a case study of offshore wind farm\nplanning in Maryland, including its application during Hurricane Sandy. Results\ndemonstrate that LSDTs support interpretable, regulation-aware layout\noptimization, enable high-fidelity simulation, and enhance adaptability in\ninfrastructure planning. This work shows the potential of combining generative\nAI with digital twins to support complex, knowledge-driven planning tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLSDTs\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6570\u5b57\u5b6a\u751f\uff0c\u4ece\u975e\u7ed3\u6784\u5316\u6587\u6863\u63d0\u53d6\u89c4\u5212\u77e5\u8bc6\u5e76\u7ec4\u7ec7\u4e3a\u672c\u4f53\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u5728\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u5728\u6574\u5408\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u53d6\u548c\u7ec4\u7ec7\u6587\u672c\u4fe1\u606f\u4e0a\u6709\u4f18\u52bf\uff0c\u56e0\u6b64\u63d0\u51faLSDTs\u6846\u67b6\u4ee5\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51faLSDTs\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u975e\u7ed3\u6784\u5316\u6587\u6863\u63d0\u53d6\u89c4\u5212\u77e5\u8bc6\u5e76\u7ec4\u7ec7\u4e3a\u5f62\u5f0f\u5316\u672c\u4f53\uff0c\u4e3a\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u8bed\u4e49\u5c42\u3002", "result": "\u901a\u8fc7\u9a6c\u91cc\u5170\u5dde\u6d77\u4e0a\u98ce\u7535\u573a\u89c4\u5212\u6848\u4f8b\u7814\u7a76\uff0c\u7ed3\u679c\u8868\u660eLSDTs\u652f\u6301\u53ef\u89e3\u91ca\u3001\u7b26\u5408\u6cd5\u89c4\u7684\u5e03\u5c40\u4f18\u5316\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6a21\u62df\uff0c\u589e\u5f3a\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u7ed3\u5408\u751f\u6210\u5f0fAI\u4e0e\u6570\u5b57\u5b6a\u751f\u5728\u652f\u6301\u590d\u6742\u3001\u77e5\u8bc6\u9a71\u52a8\u7684\u89c4\u5212\u4efb\u52a1\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.07841", "pdf": "https://arxiv.org/pdf/2508.07841", "abs": "https://arxiv.org/abs/2508.07841", "authors": ["Carlo Cena", "Mauro Martini", "Marcello Chiaberge"], "title": "Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "In review", "summary": "Attitude control is a fundamental aspect of spacecraft operations. Model\nPredictive Control (MPC) has emerged as a powerful strategy for these tasks,\nrelying on accurate models of the system dynamics to optimize control actions\nover a prediction horizon. In scenarios where physics models are incomplete,\ndifficult to derive, or computationally expensive, machine learning offers a\nflexible alternative by learning the system behavior directly from data.\nHowever, purely data-driven models often struggle with generalization and\nstability, especially when applied to inputs outside their training domain. To\naddress these limitations, we investigate the benefits of incorporating\nPhysics-Informed Neural Networks (PINNs) into the learning of spacecraft\nattitude dynamics, comparing their performance with that of purely data-driven\napproaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network\narchitecture with a self-attention mechanism, we trained several models on\nsimulated data generated with the Basilisk simulator. Two training strategies\nwere considered: a purely data-driven baseline and a physics-informed variant\nto improve robustness and stability. Our results demonstrate that the inclusion\nof physics-based information significantly enhances the performance in terms of\nthe mean relative error of the best architectures found by 27.08%. These\nadvantages are particularly evident when the learned models are integrated into\nan MPC framework, where PINN-based models consistently outperform their purely\ndata-driven counterparts in terms of control accuracy and robustness, yielding\nimprovements of up to 42.86% in performance stability error and increased\nrobustness-to-noise.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5c06\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u7528\u4e8e\u822a\u5929\u5668\u59ff\u6001\u52a8\u529b\u5b66\u5b66\u4e60\uff0c\u5bf9\u6bd4\u7eaf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u7ed3\u679c\u8868\u660ePINNs\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u4f9d\u8d56\u7cbe\u786e\u7269\u7406\u6a21\u578b\uff0c\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\u6cdb\u5316\u548c\u7a33\u5b9a\u6027\u5dee\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\uff0c\u7814\u7a76PINNs\u5728\u822a\u5929\u5668\u59ff\u6001\u52a8\u529b\u5b66\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u5e26\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684Real NVP\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u57fa\u4e8eBasilisk\u6a21\u62df\u5668\u751f\u6210\u7684\u6a21\u62df\u6570\u636e\u8bad\u7ec3\u6a21\u578b\uff0c\u91c7\u7528\u7eaf\u6570\u636e\u9a71\u52a8\u548c\u7269\u7406\u4fe1\u606f\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5305\u542b\u7269\u7406\u4fe1\u606f\u7684\u6a21\u578b\u4f7f\u6700\u4f73\u67b6\u6784\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u663e\u8457\u964d\u4f4e27.08%\uff1b\u96c6\u6210\u5230MPC\u6846\u67b6\u4e2d\uff0cPINN\u6a21\u578b\u5728\u63a7\u5236\u7cbe\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u6297\u566a\u6027\u4e0a\u4f18\u4e8e\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u6027\u80fd\u7a33\u5b9a\u6027\u8bef\u5dee\u6700\u591a\u6539\u558442.86%\u3002", "conclusion": "\u5c06\u7269\u7406\u4fe1\u606f\u878d\u5165\u795e\u7ecf\u7f51\u7edc\u53ef\u663e\u8457\u63d0\u5347\u822a\u5929\u5668\u59ff\u6001\u52a8\u529b\u5b66\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2508.07887", "pdf": "https://arxiv.org/pdf/2508.07887", "abs": "https://arxiv.org/abs/2508.07887", "authors": ["Sabrina Namazova", "Alessandra Brondetta", "Younes Strittmatter", "Matthew Nassar", "Sebastian Musslick"], "title": "Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Simulators have revolutionized scientific practice across the natural\nsciences. By generating data that reliably approximate real-world phenomena,\nthey enable scientists to accelerate hypothesis testing and optimize\nexperimental designs. This is perhaps best illustrated by AlphaFold, a\nNobel-prize winning simulator in chemistry that predicts protein structures\nfrom amino acid sequences, enabling rapid prototyping of molecular\ninteractions, drug targets, and protein functions. In the behavioral sciences,\na reliable participant simulator - a system capable of producing human-like\nbehavior across cognitive tasks - would represent a similarly transformative\nadvance. Recently, Binz et al. introduced Centaur, a large language model (LLM)\nfine-tuned on human data from 160 experiments, proposing its use not only as a\nmodel of cognition but also as a participant simulator for \"in silico\nprototyping of experimental studies\", e.g., to advance automated cognitive\nscience. Here, we review the core criteria for a participant simulator and\nassess how well Centaur meets them. Although Centaur demonstrates strong\npredictive accuracy, its generative behavior - a critical criterion for a\nparticipant simulator - systematically diverges from human data. This suggests\nthat, while Centaur is a significant step toward predicting human behavior, it\ndoes not yet meet the standards of a reliable participant simulator or an\naccurate model of cognition.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u53c2\u4e0e\u8005\u6a21\u62df\u5668\u7684\u6838\u5fc3\u6807\u51c6\uff0c\u8bc4\u4f30Centaur\u662f\u5426\u8fbe\u6807\uff0c\u6307\u51fa\u5176\u867d\u6709\u5f3a\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u751f\u6210\u884c\u4e3a\u4e0e\u4eba\u7c7b\u6570\u636e\u6709\u504f\u5dee\uff0c\u8fd8\u672a\u8fbe\u53ef\u9760\u53c2\u4e0e\u8005\u6a21\u62df\u5668\u6807\u51c6\u3002", "motivation": "\u53ef\u9760\u7684\u53c2\u4e0e\u8005\u6a21\u62df\u5668\u5bf9\u884c\u4e3a\u79d1\u5b66\u6709\u53d8\u9769\u6027\u610f\u4e49\uff0c\u8bc4\u4f30Centaur\u80fd\u5426\u6210\u4e3a\u53ef\u9760\u7684\u53c2\u4e0e\u8005\u6a21\u62df\u5668\u3002", "method": "\u56de\u987e\u53c2\u4e0e\u8005\u6a21\u62df\u5668\u7684\u6838\u5fc3\u6807\u51c6\uff0c\u4ee5\u6b64\u8bc4\u4f30Centaur\u3002", "result": "Centaur\u6709\u8f83\u5f3a\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u751f\u6210\u884c\u4e3a\u4e0e\u4eba\u7c7b\u6570\u636e\u7cfb\u7edf\u5730\u504f\u79bb\u3002", "conclusion": "Centaur\u662f\u9884\u6d4b\u4eba\u7c7b\u884c\u4e3a\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u4f46\u672a\u8fbe\u5230\u53ef\u9760\u53c2\u4e0e\u8005\u6a21\u62df\u5668\u6216\u51c6\u786e\u8ba4\u77e5\u6a21\u578b\u7684\u6807\u51c6\u3002"}}
{"id": "2508.07926", "pdf": "https://arxiv.org/pdf/2508.07926", "abs": "https://arxiv.org/abs/2508.07926", "authors": ["Liang Hou", "Yuan Gao", "Boyuan Jiang", "Xin Tao", "Qi Yan", "Renjie Liao", "Pengfei Wan", "Di Zhang", "Kun Gai"], "title": "Score Augmentation for Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models have achieved remarkable success in generative modeling.\nHowever, this study confirms the existence of overfitting in diffusion model\ntraining, particularly in data-limited regimes. To address this challenge, we\npropose Score Augmentation (ScoreAug), a novel data augmentation framework\nspecifically designed for diffusion models. Unlike conventional augmentation\napproaches that operate on clean data, ScoreAug applies transformations to\nnoisy data, aligning with the inherent denoising mechanism of diffusion.\nCrucially, ScoreAug further requires the denoiser to predict the augmentation\nof the original target. This design establishes an equivariant learning\nobjective, enabling the denoiser to learn scores across varied denoising\nspaces, thereby realizing what we term score augmentation. We also\ntheoretically analyze the relationship between scores in different spaces under\ngeneral transformations. In experiments, we extensively validate ScoreAug on\nmultiple benchmarks including CIFAR-10, FFHQ, AFHQv2, and ImageNet, with\nresults demonstrating significant performance improvements over baselines.\nNotably, ScoreAug effectively mitigates overfitting across diverse scenarios,\nsuch as varying data scales and model capacities, while exhibiting stable\nconvergence properties. Another advantage of ScoreAug over standard data\naugmentation lies in its ability to circumvent data leakage issues under\ncertain conditions. Furthermore, we show that ScoreAug can be synergistically\ncombined with traditional data augmentation techniques to achieve additional\nperformance gains.", "AI": {"tldr": "\u7814\u7a76\u786e\u8ba4\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u51faScoreAug\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u7f13\u89e3\u8fc7\u62df\u5408\u7b49\u3002", "motivation": "\u89e3\u51b3\u6269\u6563\u6a21\u578b\u5728\u6570\u636e\u6709\u9650\u65f6\u8bad\u7ec3\u7684\u8fc7\u62df\u5408\u95ee\u9898\u3002", "method": "\u63d0\u51faScoreAug\u6846\u67b6\uff0c\u5bf9\u566a\u58f0\u6570\u636e\u8fdb\u884c\u53d8\u6362\uff0c\u8981\u6c42\u53bb\u566a\u5668\u9884\u6d4b\u539f\u59cb\u76ee\u6807\u7684\u589e\u5f3a\uff0c\u7406\u8bba\u5206\u6790\u4e0d\u540c\u7a7a\u95f4\u5206\u6570\u5173\u7cfb\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u6709\u6548\u7f13\u89e3\u8fc7\u62df\u5408\uff0c\u6536\u655b\u7a33\u5b9a\uff0c\u80fd\u907f\u514d\u6570\u636e\u6cc4\u6f0f\uff0c\u53ef\u4e0e\u4f20\u7edf\u65b9\u6cd5\u7ed3\u5408\u83b7\u66f4\u591a\u589e\u76ca\u3002", "conclusion": "ScoreAug\u662f\u6709\u6548\u7684\u6269\u6563\u6a21\u578b\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u53ef\u7f13\u89e3\u8fc7\u62df\u5408\uff0c\u6709\u826f\u597d\u6027\u80fd\u548c\u4f18\u52bf\u3002"}}
{"id": "2508.06811", "pdf": "https://arxiv.org/pdf/2508.06811", "abs": "https://arxiv.org/abs/2508.06811", "authors": ["Benjamin Laufer", "Hamidah Oderinwale", "Jon Kleinberg"], "title": "Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face", "categories": ["cs.SI", "cs.AI", "cs.CY", "cs.LG"], "comment": "29 pages, 18 figures and tables", "summary": "Many have observed that the development and deployment of generative machine\nlearning (ML) and artificial intelligence (AI) models follow a distinctive\npattern in which pre-trained models are adapted and fine-tuned for specific\ndownstream tasks. However, there is limited empirical work that examines the\nstructure of these interactions. This paper analyzes 1.86 million models on\nHugging Face, a leading peer production platform for model development. Our\nstudy of model family trees -- networks that connect fine-tuned models to their\nbase or parent -- reveals sprawling fine-tuning lineages that vary widely in\nsize and structure. Using an evolutionary biology lens to study ML models, we\nuse model metadata and model cards to measure the genetic similarity and\nmutation of traits over model families. We find that models tend to exhibit a\nfamily resemblance, meaning their genetic markers and traits exhibit more\noverlap when they belong to the same model family. However, these similarities\ndepart in certain ways from standard models of asexual reproduction, because\nmutations are fast and directed, such that two `sibling' models tend to exhibit\nmore similarity than parent/child pairs. Further analysis of the directional\ndrifts of these mutations reveals qualitative insights about the open machine\nlearning ecosystem: Licenses counter-intuitively drift from restrictive,\ncommercial licenses towards permissive or copyleft licenses, often in violation\nof upstream license's terms; models evolve from multi-lingual compatibility\ntowards english-only compatibility; and model cards reduce in length and\nstandardize by turning, more often, to templates and automatically generated\ntext. Overall, this work takes a step toward an empirically grounded\nunderstanding of model fine-tuning and suggests that ecological models and\nmethods can yield novel scientific insights.", "AI": {"tldr": "\u672c\u6587\u5206\u6790Hugging Face\u4e0a186\u4e07\u4e2a\u6a21\u578b\uff0c\u7528\u8fdb\u5316\u751f\u7269\u5b66\u89c6\u89d2\u7814\u7a76\u6a21\u578b\u5fae\u8c03\uff0c\u53d1\u73b0\u6a21\u578b\u6709\u5bb6\u65cf\u76f8\u4f3c\u6027\uff0c\u7a81\u53d8\u6709\u7279\u70b9\uff0c\u8fd8\u63ed\u793a\u673a\u5668\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u7684\u4e00\u4e9b\u53d8\u5316\uff0c\u8868\u660e\u751f\u6001\u6a21\u578b\u548c\u65b9\u6cd5\u80fd\u5e26\u6765\u65b0\u89c1\u89e3\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u4ea4\u4e92\u7ed3\u6784\u7684\u5b9e\u8bc1\u7814\u7a76\u6709\u9650\uff0c\u672c\u6587\u65e8\u5728\u8fdb\u884c\u76f8\u5173\u5206\u6790\u3002", "method": "\u5206\u6790Hugging Face\u4e0a\u7684\u6a21\u578b\uff0c\u6784\u5efa\u6a21\u578b\u5bb6\u65cf\u6811\uff0c\u5229\u7528\u6a21\u578b\u5143\u6570\u636e\u548c\u6a21\u578b\u5361\u7247\u6d4b\u91cf\u6a21\u578b\u5bb6\u65cf\u7684\u9057\u4f20\u76f8\u4f3c\u6027\u548c\u7279\u5f81\u7a81\u53d8\u3002", "result": "\u6a21\u578b\u6709\u5bb6\u65cf\u76f8\u4f3c\u6027\uff0c\u7a81\u53d8\u5feb\u4e14\u6709\u65b9\u5411\uff0c\u2018\u5144\u5f1f\u2019\u6a21\u578b\u6bd4\u4eb2\u5b50\u6a21\u578b\u66f4\u76f8\u4f3c\uff1b\u8bb8\u53ef\u8bc1\u4ece\u9650\u5236\u6027\u5411\u5bbd\u677e\u6216\u5171\u4eab\u8bb8\u53ef\u6f02\u79fb\uff0c\u6a21\u578b\u4ece\u591a\u8bed\u8a00\u517c\u5bb9\u5411\u82f1\u8bed\u517c\u5bb9\u8f6c\u53d8\uff0c\u6a21\u578b\u5361\u7247\u957f\u5ea6\u51cf\u5c11\u4e14\u6807\u51c6\u5316\u3002", "conclusion": "\u671d\u7740\u57fa\u4e8e\u5b9e\u8bc1\u7406\u89e3\u6a21\u578b\u5fae\u8c03\u8fc8\u51fa\u4e00\u6b65\uff0c\u751f\u6001\u6a21\u578b\u548c\u65b9\u6cd5\u53ef\u4ea7\u751f\u65b0\u7684\u79d1\u5b66\u89c1\u89e3\u3002"}}
{"id": "2508.07927", "pdf": "https://arxiv.org/pdf/2508.07927", "abs": "https://arxiv.org/abs/2508.07927", "authors": ["Amal Saadallah", "Abdulaziz Al-Ademi"], "title": "Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting poses significant challenges in non-stationary\nenvironments where underlying patterns evolve over time. In this work, we\npropose a novel framework that enhances deep neural network (DNN) performance\nby leveraging specialized model adaptation and selection. Initially, a base DNN\nis trained offline on historical time series data. A reserved validation subset\nis then segmented to extract and cluster the most dominant patterns within the\nseries, thereby identifying distinct regimes. For each identified cluster, the\nbase DNN is fine-tuned to produce a specialized version that captures unique\npattern characteristics. At inference, the most recent input is matched against\nthe cluster centroids, and the corresponding fine-tuned version is deployed\nbased on the closest similarity measure. Additionally, our approach integrates\na concept drift detection mechanism to identify and adapt to emerging patterns\ncaused by non-stationary behavior. The proposed framework is generalizable\nacross various DNN architectures and has demonstrated significant performance\ngains on both traditional DNNs and recent advanced architectures implemented in\nthe GluonTS library.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u6a21\u578b\u81ea\u9002\u5e94\u548c\u9009\u62e9\u63d0\u5347DNN\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u7684\u6846\u67b6\uff0c\u6709\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u673a\u5236\uff0c\u5728\u591a\u79cd\u67b6\u6784\u4e0a\u8868\u73b0\u4f73\u3002", "motivation": "\u89e3\u51b3\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u6f5c\u5728\u6a21\u5f0f\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u6311\u6218\u3002", "method": "\u5148\u79bb\u7ebf\u8bad\u7ec3\u57fa\u7840DNN\uff0c\u5bf9\u9a8c\u8bc1\u5b50\u96c6\u805a\u7c7b\u5212\u5206\u4e0d\u540c\u6a21\u5f0f\u533a\u57df\uff0c\u4e3a\u5404\u533a\u57df\u5fae\u8c03\u57fa\u7840DNN\u5f97\u5230\u4e13\u95e8\u7248\u672c\uff1b\u63a8\u7406\u65f6\u6839\u636e\u8f93\u5165\u4e0e\u805a\u7c7b\u4e2d\u5fc3\u5339\u914d\u9009\u62e9\u5fae\u8c03\u6a21\u578b\uff1b\u96c6\u6210\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u673a\u5236\u3002", "result": "\u8be5\u6846\u67b6\u53ef\u63a8\u5e7f\u5230\u5404\u79cdDNN\u67b6\u6784\uff0c\u5728\u4f20\u7edf\u548c\u5148\u8fdb\u67b6\u6784\u4e0a\u90fd\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86DNN\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2508.07952", "pdf": "https://arxiv.org/pdf/2508.07952", "abs": "https://arxiv.org/abs/2508.07952", "authors": ["Richard J. Fawley", "Renato Cordeiro de Amorim"], "title": "Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters", "categories": ["cs.LG"], "comment": null, "summary": "Clustering algorithms often assume all features contribute equally to the\ndata structure, an assumption that usually fails in high-dimensional or noisy\nsettings. Feature weighting methods can address this, but most require\nadditional parameter tuning. We propose SHARK (Shapley Reweighted $k$-means), a\nfeature-weighted clustering algorithm motivated by the use of Shapley values\nfrom cooperative game theory to quantify feature relevance, which requires no\nadditional parameters beyond those in $k$-means. We prove that the $k$-means\nobjective can be decomposed into a sum of per-feature Shapley values, providing\nan axiomatic foundation for unsupervised feature relevance and reducing Shapley\ncomputation from exponential to polynomial time. SHARK iteratively re-weights\nfeatures by the inverse of their Shapley contribution, emphasising informative\ndimensions and down-weighting irrelevant ones. Experiments on synthetic and\nreal-world data sets show that SHARK consistently matches or outperforms\nexisting methods, achieving superior robustness and accuracy, particularly in\nscenarios where noise may be present. Software:\nhttps://github.com/rickfawley/shark.", "AI": {"tldr": "\u63d0\u51faSHARK\u7279\u5f81\u52a0\u6743\u805a\u7c7b\u7b97\u6cd5\uff0c\u7528Shapley\u503c\u91cf\u5316\u7279\u5f81\u76f8\u5173\u6027\uff0c\u65e0\u9700\u989d\u5916\u53c2\u6570\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u805a\u7c7b\u7b97\u6cd5\u5047\u8bbe\u6240\u6709\u7279\u5f81\u5bf9\u6570\u636e\u7ed3\u6784\u8d21\u732e\u76f8\u540c\uff0c\u5728\u9ad8\u7ef4\u6216\u6709\u566a\u58f0\u573a\u666f\u4e0d\u9002\u7528\uff0c\u4e14\u591a\u6570\u7279\u5f81\u52a0\u6743\u65b9\u6cd5\u9700\u989d\u5916\u8c03\u53c2\u3002", "method": "\u63d0\u51faSHARK\u7b97\u6cd5\uff0c\u8bc1\u660ek - means\u76ee\u6807\u53ef\u5206\u89e3\u4e3a\u7279\u5f81Shapley\u503c\u4e4b\u548c\uff0c\u8fed\u4ee3\u5730\u7528\u7279\u5f81Shapley\u8d21\u732e\u7684\u5012\u6570\u91cd\u65b0\u52a0\u6743\u7279\u5f81\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cSHARK\u59cb\u7ec8\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u6216\u8868\u73b0\u66f4\u4f18\uff0c\u5728\u6709\u566a\u58f0\u573a\u666f\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u66f4\u9ad8\u3002", "conclusion": "SHARK\u662f\u4e00\u79cd\u6709\u6548\u7684\u7279\u5f81\u52a0\u6743\u805a\u7c7b\u7b97\u6cd5\uff0c\u5728\u591a\u79cd\u573a\u666f\u6709\u826f\u597d\u8868\u73b0\u3002"}}
{"id": "2508.06846", "pdf": "https://arxiv.org/pdf/2508.06846", "abs": "https://arxiv.org/abs/2508.06846", "authors": ["Hyo Jin Do", "Rachel Ostrand", "Werner Geyer", "Keerthiram Murugesan", "Dennis Wei", "Justin Weisz"], "title": "Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators", "categories": ["cs.HC", "cs.AI"], "comment": "16 pages, 8 figures, To be published in Proceedings of the 8th\n  AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)", "summary": "Large language models (LLMs) are susceptible to generating inaccurate or\nfalse information, often referred to as \"hallucinations\" or \"confabulations.\"\nWhile several technical advancements have been made to detect hallucinated\ncontent by assessing the factuality of the model's responses, there is still\nlimited research on how to effectively communicate this information to users.\nTo address this gap, we conducted two scenario-based experiments with a total\nof 208 participants to systematically compare the effects of various design\nstrategies for communicating factuality scores by assessing participants'\nratings of trust, ease in validating response accuracy, and preference. Our\nfindings reveal that participants preferred and trusted a design in which all\nphrases within a response were color-coded based on factuality scores.\nParticipants also found it easier to validate accuracy of the response in this\nstyle compared to a baseline with no style applied. Our study offers practical\ndesign guidelines for LLM application developers and designers, aimed at\ncalibrating user trust, aligning with user preferences, and enhancing users'\nability to scrutinize LLM outputs.", "AI": {"tldr": "\u6587\u7ae0\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4\u4e0d\u540c\u8bbe\u8ba1\u7b56\u7565\u5bf9\u4f20\u8fbe\u5927\u8bed\u8a00\u6a21\u578b\u4e8b\u5b9e\u6027\u5f97\u5206\u7684\u6548\u679c\uff0c\u53d1\u73b0\u6309\u4e8b\u5b9e\u6027\u5f97\u5206\u5bf9\u56de\u590d\u77ed\u8bed\u8fdb\u884c\u989c\u8272\u7f16\u7801\u7684\u8bbe\u8ba1\u66f4\u53d7\u53c2\u4e0e\u8005\u9752\u7750\u548c\u4fe1\u4efb\uff0c\u8fd8\u4e3a\u5f00\u53d1\u8005\u548c\u8bbe\u8ba1\u5e08\u63d0\u4f9b\u5b9e\u7528\u8bbe\u8ba1\u6307\u5357\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u5982\u4f55\u6709\u6548\u5411\u7528\u6237\u4f20\u8fbe\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5185\u5bb9\u7684\u4e8b\u5b9e\u6027\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u8fdb\u884c\u4e24\u4e2a\u57fa\u4e8e\u573a\u666f\u7684\u5b9e\u9a8c\uff0c\u8ba9208\u540d\u53c2\u4e0e\u8005\u5bf9\u4e0d\u540c\u8bbe\u8ba1\u7b56\u7565\u8fdb\u884c\u8bc4\u4f30\uff0c\u6307\u6807\u5305\u62ec\u4fe1\u4efb\u5ea6\u3001\u9a8c\u8bc1\u56de\u590d\u51c6\u786e\u6027\u7684\u96be\u6613\u7a0b\u5ea6\u548c\u504f\u597d\u3002", "result": "\u53c2\u4e0e\u8005\u66f4\u504f\u597d\u548c\u4fe1\u4efb\u6309\u4e8b\u5b9e\u6027\u5f97\u5206\u5bf9\u56de\u590d\u4e2d\u6240\u6709\u77ed\u8bed\u8fdb\u884c\u989c\u8272\u7f16\u7801\u7684\u8bbe\u8ba1\uff0c\u4e14\u8ba4\u4e3a\u8fd9\u79cd\u8bbe\u8ba1\u66f4\u6613\u9a8c\u8bc1\u56de\u590d\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u5f00\u53d1\u8005\u548c\u8bbe\u8ba1\u5e08\u63d0\u4f9b\u5b9e\u7528\u8bbe\u8ba1\u6307\u5357\uff0c\u6709\u52a9\u4e8e\u6821\u51c6\u7528\u6237\u4fe1\u4efb\u3001\u5951\u5408\u7528\u6237\u504f\u597d\u5e76\u589e\u5f3a\u7528\u6237\u5ba1\u67e5\u6a21\u578b\u8f93\u51fa\u7684\u80fd\u529b\u3002"}}
{"id": "2508.07970", "pdf": "https://arxiv.org/pdf/2508.07970", "abs": "https://arxiv.org/abs/2508.07970", "authors": ["Junyu Wu", "Weiming Chang", "Xiaotao Liu", "Guanyou He", "Tingfeng Xian", "Haoqiang Hong", "Boqi Chen", "Haotao Tian", "Tao Yang", "Yunsheng Shi", "Feng Lin", "Ting Yao"], "title": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2507.22789", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent\nparadigm for training large language models and multimodal systems. Despite\nnotable advances enabled by existing RLHF training frameworks, significant\nchallenges remain in scaling to complex multimodal workflows and adapting to\ndynamic workloads. In particular, current systems often encounter limitations\nrelated to controller scalability when managing large models, as well as\ninefficiencies in orchestrating intricate RLHF pipelines, especially in\nscenarios that require dynamic sampling and resource allocation. In this paper,\nwe introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple,\nscalable, and balanced RLHF training framework specifically designed to address\nthese challenges. WeChat-YATT features a parallel controller programming model\nthat enables flexible and efficient orchestration of complex RLHF workflows,\neffectively mitigating the bottlenecks associated with centralized controller\narchitectures and facilitating scalability in large-scale data scenarios. In\naddition, we propose a dynamic placement schema that adaptively partitions\ncomputational resources and schedules workloads, thereby significantly reducing\nhardware idle time and improving GPU utilization under variable training\nconditions. We evaluate WeChat-YATT across a range of experimental scenarios,\ndemonstrating that it achieves substantial improvements in throughput compared\nto state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been\nsuccessfully deployed to train models supporting WeChat product features for a\nlarge-scale user base, underscoring its effectiveness and robustness in\nreal-world applications.", "AI": {"tldr": "\u63d0\u51faWeChat - YATT\u6846\u67b6\u89e3\u51b3\u73b0\u6709RLHF\u8bad\u7ec3\u6846\u67b6\u5728\u590d\u6742\u591a\u6a21\u6001\u5de5\u4f5c\u6d41\u548c\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u65b9\u9762\u7684\u6311\u6218\uff0c\u5b9e\u9a8c\u663e\u793a\u541e\u5410\u91cf\u63d0\u5347\u4e14\u5df2\u7528\u4e8e\u5fae\u4fe1\u4ea7\u54c1\u6a21\u578b\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709RLHF\u8bad\u7ec3\u6846\u67b6\u5728\u6269\u5c55\u5230\u590d\u6742\u591a\u6a21\u6001\u5de5\u4f5c\u6d41\u548c\u9002\u5e94\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u5982\u63a7\u5236\u5668\u53ef\u6269\u5c55\u6027\u548c\u7ba1\u9053\u7f16\u6392\u6548\u7387\u95ee\u9898\u3002", "method": "\u5f15\u5165WeChat - YATT\u6846\u67b6\uff0c\u91c7\u7528\u5e76\u884c\u63a7\u5236\u5668\u7f16\u7a0b\u6a21\u578b\u7f16\u6392\u590d\u6742\u5de5\u4f5c\u6d41\uff0c\u63d0\u51fa\u52a8\u6001\u653e\u7f6e\u65b9\u6848\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u548c\u8c03\u5ea6\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u5b9e\u9a8c\u8868\u660eWeChat - YATT\u76f8\u6bd4\u73b0\u6709\u6846\u67b6\u541e\u5410\u91cf\u5927\u5e45\u63d0\u5347\uff0c\u4e14\u5df2\u6210\u529f\u7528\u4e8e\u652f\u6301\u5fae\u4fe1\u4ea7\u54c1\u7279\u5f81\u7684\u6a21\u578b\u8bad\u7ec3\u3002", "conclusion": "WeChat - YATT\u6846\u67b6\u6709\u6548\u89e3\u51b3\u73b0\u6709\u95ee\u9898\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u5907\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.06849", "pdf": "https://arxiv.org/pdf/2508.06849", "abs": "https://arxiv.org/abs/2508.06849", "authors": ["Sanjana Gautam", "Mohit Chandra", "Ankolika De", "Tatiana Chakravorti", "Girik Malik", "Munmun De Choudhury"], "title": "Towards Experience-Centered AI: A Framework for Integrating Lived Experience in Design and Development", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Lived experiences fundamentally shape how individuals interact with AI\nsystems, influencing perceptions of safety, trust, and usability. While prior\nresearch has focused on developing techniques to emulate human preferences, and\nproposed taxonomies to categorize risks (such as psychological harms and\nalgorithmic biases), these efforts have provided limited systematic\nunderstanding of lived human experiences or actionable strategies for embedding\nthem meaningfully into the AI development lifecycle. This work proposes a\nframework for meaningfully integrating lived experience into the design and\nevaluation of AI systems. We synthesize interdisciplinary literature across\nlived experience philosophy, human-centered design, and human-AI interaction,\narguing that centering lived experience can lead to models that more accurately\nreflect the retrospective, emotional, and contextual dimensions of human\ncognition. Drawing from a wide body of work across psychology, education,\nhealthcare, and social policy, we present a targeted taxonomy of lived\nexperiences with specific applicability to AI systems. To ground our framework,\nwe examine three application domains (i) education, (ii) healthcare, and (iii)\ncultural alignment, illustrating how lived experience informs user goals,\nsystem expectations, and ethical considerations in each context. We further\nincorporate insights from AI system operators and human-AI partnerships to\nhighlight challenges in responsibility allocation, mental model calibration,\nand long-term system adaptation. We conclude with actionable recommendations\nfor developing experience-centered AI systems that are not only technically\nrobust but also empathetic, context-aware, and aligned with human realities.\nThis work offers a foundation for future research that bridges technical\ndevelopment with the lived experiences of those impacted by AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u751f\u6d3b\u7ecf\u9a8c\u878d\u5165AI\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u8bc4\u4f30\u7684\u6846\u67b6\uff0c\u7efc\u5408\u8de8\u5b66\u79d1\u6587\u732e\uff0c\u7ed9\u51fa\u76f8\u5173\u5206\u7c7b\uff0c\u901a\u8fc7\u4e09\u4e2a\u5e94\u7528\u9886\u57df\u4e3e\u4f8b\uff0c\u7ed3\u5408\u4ece\u4e1a\u8005\u89c1\u89e3\uff0c\u6700\u540e\u7ed9\u51fa\u5f00\u53d1\u4ee5\u7ecf\u9a8c\u4e3a\u4e2d\u5fc3AI\u7cfb\u7edf\u7684\u5efa\u8bae\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5bf9\u4eba\u7c7b\u751f\u6d3b\u7ecf\u9a8c\u7684\u7cfb\u7edf\u7406\u89e3\u6709\u9650\uff0c\u7f3a\u4e4f\u5c06\u5176\u878d\u5165AI\u5f00\u53d1\u751f\u547d\u5468\u671f\u7684\u6709\u6548\u7b56\u7565\uff0c\u9700\u63d0\u51fa\u6846\u67b6\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u7efc\u5408\u751f\u6d3b\u7ecf\u9a8c\u54f2\u5b66\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u548c\u4eba\u673a\u4ea4\u4e92\u7b49\u8de8\u5b66\u79d1\u6587\u732e\uff0c\u63d0\u51fa\u751f\u6d3b\u7ecf\u9a8c\u5206\u7c7b\uff0c\u7814\u7a76\u4e09\u4e2a\u5e94\u7528\u9886\u57df\uff0c\u7ed3\u5408AI\u7cfb\u7edf\u64cd\u4f5c\u5458\u548c\u4eba\u673a\u4f19\u4f34\u5173\u7cfb\u7684\u89c1\u89e3\u3002", "result": "\u63d0\u51fa\u5c06\u751f\u6d3b\u7ecf\u9a8c\u878d\u5165AI\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u8bc4\u4f30\u7684\u6846\u67b6\uff0c\u7ed9\u51fa\u9488\u5bf9\u6027\u5206\u7c7b\uff0c\u5206\u6790\u4e09\u4e2a\u5e94\u7528\u9886\u57df\u4e2d\u751f\u6d3b\u7ecf\u9a8c\u7684\u5f71\u54cd\uff0c\u6307\u51fa\u8d23\u4efb\u5206\u914d\u3001\u5fc3\u7406\u6a21\u578b\u6821\u51c6\u548c\u7cfb\u7edf\u957f\u671f\u9002\u5e94\u7b49\u6311\u6218\u3002", "conclusion": "\u7ed9\u51fa\u5f00\u53d1\u4ee5\u7ecf\u9a8c\u4e3a\u4e2d\u5fc3AI\u7cfb\u7edf\u7684\u53ef\u884c\u5efa\u8bae\uff0c\u4e3a\u8fde\u63a5\u6280\u672f\u5f00\u53d1\u4e0e\u53d7AI\u5f71\u54cd\u4eba\u7fa4\u751f\u6d3b\u7ecf\u9a8c\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.08002", "pdf": "https://arxiv.org/pdf/2508.08002", "abs": "https://arxiv.org/abs/2508.08002", "authors": ["Hongxin Yu", "Yibing Wang", "Fengyue Jin", "Meng Zhang", "Anni Chen"], "title": "A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation", "categories": ["cs.LG", "physics.app-ph"], "comment": "18 pages, 9 figures", "summary": "Traffic state estimation (TSE) falls methodologically into three categories:\nmodel-driven, data-driven, and model-data dual-driven. Model-driven TSE relies\non macroscopic traffic flow models originated from hydrodynamics. Data-driven\nTSE leverages historical sensing data and employs statistical models or machine\nlearning methods to infer traffic state. Model-data dual-driven traffic state\nestimation attempts to harness the strengths of both aspects to achieve more\naccurate TSE. From the perspective of mathematical operator theory, TSE can be\nviewed as a type of operator that maps available measurements of inerested\ntraffic state into unmeasured traffic state variables in real time. For the\nfirst time this paper proposes to study real-time freeway TSE in the idea of\nphysics-informed deep operator network (PI-DeepONet), which is an\noperator-oriented architecture embedding traffic flow models based on deep\nneural networks. The paper has developed an extended architecture from the\noriginal PI-DeepONet. The extended architecture is featured with: (1) the\nacceptance of 2-D data input so as to support CNN-based computations; (2) the\nintroduction of a nonlinear expansion layer, an attention mechanism, and a MIMO\nmechanism; (3) dedicated neural network design for adaptive identification of\ntraffic flow model parameters. A traffic state estimator built on the basis of\nthis extended PI-DeepONet architecture was evaluated with respect to a short\nfreeway stretch of NGSIM and a large-scale urban expressway in China, along\nwith other four baseline TSE methods. The evaluation results demonstrated that\nthis novel TSE method outperformed the baseline methods with high-precision\nestimation results of flow and mean speed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u7269\u7406\u4fe1\u606f\u6df1\u5ea6\u7b97\u5b50\u7f51\u7edc\uff08PI - DeepONet\uff09\u7814\u7a76\u5b9e\u65f6\u9ad8\u901f\u516c\u8def\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\uff0c\u5f00\u53d1\u6269\u5c55\u67b6\u6784\uff0c\u8bc4\u4f30\u663e\u793a\u65b0\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u9700\u66f4\u51c6\u786e\u65b9\u6cd5\uff0c\u6545\u5f15\u5165PI - DeepONet\u7814\u7a76\u5b9e\u65f6\u9ad8\u901f\u516c\u8def\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\u3002", "method": "\u63d0\u51fa\u57fa\u4e8ePI - DeepONet\u7814\u7a76\u5b9e\u65f6\u9ad8\u901f\u516c\u8def\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\uff0c\u5f00\u53d1\u6269\u5c55\u67b6\u6784\uff0c\u5305\u542b\u63a5\u53d7\u4e8c\u7ef4\u6570\u636e\u8f93\u5165\u3001\u5f15\u5165\u975e\u7ebf\u6027\u6269\u5c55\u5c42\u7b49\uff0c\u6784\u5efa\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\u5668\u3002", "result": "\u7528NGSIM\u77ed\u9ad8\u901f\u516c\u8def\u8def\u6bb5\u548c\u4e2d\u56fd\u5927\u578b\u57ce\u5e02\u5feb\u901f\u8def\u8bc4\u4f30\uff0c\u65b0\u65b9\u6cd5\u5728\u6d41\u91cf\u548c\u5e73\u5747\u901f\u5ea6\u4f30\u8ba1\u4e0a\u9ad8\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u5176\u4ed6\u56db\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u6269\u5c55PI - DeepONet\u67b6\u6784\u7684\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\u80fd\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2508.06853", "pdf": "https://arxiv.org/pdf/2508.06853", "abs": "https://arxiv.org/abs/2508.06853", "authors": ["L. D. M. S. Sai Teja", "Ashok Urlana", "Pruthwik Mishra"], "title": "AGIC: Attention-Guided Image Captioning to Improve Caption Relevance", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 5 Figures", "summary": "Despite significant progress in image captioning, generating accurate and\ndescriptive captions remains a long-standing challenge. In this study, we\npropose Attention-Guided Image Captioning (AGIC), which amplifies salient\nvisual regions directly in the feature space to guide caption generation. We\nfurther introduce a hybrid decoding strategy that combines deterministic and\nprobabilistic sampling to balance fluency and diversity. To evaluate AGIC, we\nconduct extensive experiments on the Flickr8k and Flickr30k datasets. The\nresults show that AGIC matches or surpasses several state-of-the-art models\nwhile achieving faster inference. Moreover, AGIC demonstrates strong\nperformance across multiple evaluation metrics, offering a scalable and\ninterpretable solution for image captioning.", "AI": {"tldr": "\u63d0\u51faAttention - Guided Image Captioning (AGIC)\u7528\u4e8e\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\uff0c\u7ed3\u5408\u6df7\u5408\u89e3\u7801\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e14\u63a8\u7406\u5feb\u3002", "motivation": "\u89e3\u51b3\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u4e2d\u751f\u6210\u51c6\u786e\u548c\u63cf\u8ff0\u6027\u5f3a\u7684\u6587\u672c\u8fd9\u4e00\u957f\u671f\u6311\u6218\u3002", "method": "\u63d0\u51faAGIC\u5728\u7279\u5f81\u7a7a\u95f4\u653e\u5927\u663e\u8457\u89c6\u89c9\u533a\u57df\u5f15\u5bfc\u63cf\u8ff0\u751f\u6210\uff0c\u5f15\u5165\u7ed3\u5408\u786e\u5b9a\u6027\u548c\u6982\u7387\u6027\u91c7\u6837\u7684\u6df7\u5408\u89e3\u7801\u7b56\u7565\u3002", "result": "\u5728Flickr8k\u548cFlickr30k\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cAGIC\u5339\u914d\u6216\u8d85\u8d8a\u591a\u4e2a\u5148\u8fdb\u6a21\u578b\uff0c\u63a8\u7406\u66f4\u5feb\uff0c\u591a\u8bc4\u4f30\u6307\u6807\u8868\u73b0\u597d\u3002", "conclusion": "AGIC\u4e3a\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.08005", "pdf": "https://arxiv.org/pdf/2508.08005", "abs": "https://arxiv.org/abs/2508.08005", "authors": ["Xiang Li", "Shanshan Wang", "Chenglong Xiao"], "title": "Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 6 figures", "summary": "Extensive experiments and prior studies show that no single maximum clique\nalgorithm consistently performs best across all instances, highlighting the\nimportance of selecting suitable algorithms based on instance features. Through\nan extensive analysis of relevant studies, it is found that there is a lack of\nresearch work concerning algorithm selection oriented toward the Maximum Clique\nProblem (MCP). In this work, we propose a learning-based framework that\nintegrates both traditional machine learning and graph neural networks to\naddress this gap. We construct a labeled dataset by running four exact MCP\nalgorithms on a diverse collection of graph instances, accompanied by\nstructural and global statistical features extracted from each graph. We first\nevaluate four conventional classifiers: Support Vector Machine (SVM), Random\nForest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple\ndataset variants. Experimental results show that RF consistently shows strong\nperformance across metrics and dataset variants, making it a reliable baseline.\nIn addition, feature importance analysis indicates that connectivity and\ntopological structure are strong predictors of algorithm performance. Building\non these findings, we develop a dual-channel model named GAT-MLP, which\ncombines a Graph Attention Network (GAT) for local structural encoding with a\nMultilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model\nshows strong and consistent performance across all metrics. Our results\nhighlight the effectiveness of dual-channel architectures and the promise of\ngraph neural networks in combinatorial algorithm selection.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u6700\u5927\u56e2\u95ee\u9898\uff08MCP\uff09\u7f3a\u5c11\u7b97\u6cd5\u9009\u62e9\u7814\u7a76\uff0c\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u8bc4\u4f30\u4f20\u7edf\u5206\u7c7b\u5668\uff0c\u5f00\u53d1GAT - MLP\u6a21\u578b\uff0c\u8bc1\u660e\u53cc\u901a\u9053\u67b6\u6784\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u7ec4\u5408\u7b97\u6cd5\u9009\u62e9\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e2d\u7f3a\u4e4f\u9488\u5bf9MCP\u7684\u7b97\u6cd5\u9009\u62e9\u7814\u7a76\uff0c\u9700\u627e\u5230\u5408\u9002\u7684\u7b97\u6cd5\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u3001\u968f\u673a\u68ee\u6797\uff08RF\uff09\u7b49\u4f20\u7edf\u5206\u7c7b\u5668\uff0c\u5206\u6790\u7279\u5f81\u91cd\u8981\u6027\uff0c\u5f00\u53d1\u7ed3\u5408\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\u548c\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u7684GAT - MLP\u6a21\u578b\u3002", "result": "RF\u5728\u5404\u6307\u6807\u548c\u6570\u636e\u96c6\u53d8\u4f53\u4e2d\u8868\u73b0\u7a33\u5b9a\uff0cGAT - MLP\u6a21\u578b\u5728\u6240\u6709\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u53cc\u901a\u9053\u67b6\u6784\u6709\u6548\uff0c\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u7ec4\u5408\u7b97\u6cd5\u9009\u62e9\u4e2d\u6709\u524d\u666f\u3002"}}
{"id": "2508.06869", "pdf": "https://arxiv.org/pdf/2508.06869", "abs": "https://arxiv.org/abs/2508.06869", "authors": ["Jianxiang He", "Shaoguang Wang", "Weiyu Guo", "Meisheng Hong", "Jungang Li", "Yijie Xu", "Ziyang Chen", "Hui Xiong"], "title": "VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding", "categories": ["cs.CV", "cs.AI", "I.2.10"], "comment": "9 pages,3 figures", "summary": "Long video understanding presents a significant challenge to multimodal large\nlanguage models (MLLMs) primarily due to the immense data scale. A critical and\nwidely adopted strategy for making this task computationally tractable is\nkeyframe retrieval, which seeks to identify a sparse set of video frames that\nare most salient to a given textual query. However, the efficacy of this\napproach is hindered by weak multimodal alignment between textual queries and\nvisual content and fails to capture the complex temporal semantic information\nrequired for precise reasoning. To address this, we propose Visual-Subtitle\nIntegeration(VSI), a multimodal keyframe search method that integrates\nsubtitles, timestamps, and scene boundaries into a unified multimodal search\nprocess. The proposed method captures the visual information of video frames as\nwell as the complementary textual information through a dual-stream search\nmechanism by Video Search Stream as well as Subtitle Match Stream,\nrespectively, and improves the keyframe search accuracy through the interaction\nof the two search streams. Experimental results show that VSI achieve 40.00%\nkey frame localization accuracy on the text-relevant subset of LongVideoBench\nand 68.48% accuracy on downstream long Video-QA tasks, surpassing competitive\nbaselines by 20.35% and 15.79%, respectively. Furthermore, on the\nLongVideoBench, VSI achieved state-of-the-art(SOTA) in medium-to-long video-QA\ntasks, demonstrating the robustness and generalizability of the proposed\nmultimodal search strategy.", "AI": {"tldr": "\u9488\u5bf9\u957f\u89c6\u9891\u7406\u89e3\u4e2d\u5173\u952e\u5e27\u68c0\u7d22\u96be\u9898\uff0c\u63d0\u51faVSI\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5173\u952e\u5e27\u5b9a\u4f4d\u548c\u957f\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u5173\u952e\u5e27\u68c0\u7d22\u65b9\u6cd5\u56e0\u591a\u6a21\u6001\u5bf9\u9f50\u5f31\u3001\u65e0\u6cd5\u6355\u6349\u590d\u6742\u65f6\u95f4\u8bed\u4e49\u4fe1\u606f\uff0c\u5bfc\u81f4\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51faVisual - Subtitle Integeration (VSI)\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c6\u9891\u641c\u7d22\u6d41\u548c\u5b57\u5e55\u5339\u914d\u6d41\u7684\u53cc\u6d41\u641c\u7d22\u673a\u5236\uff0c\u6574\u5408\u5b57\u5e55\u3001\u65f6\u95f4\u6233\u548c\u573a\u666f\u8fb9\u754c\u8fdb\u884c\u591a\u6a21\u6001\u5173\u952e\u5e27\u641c\u7d22\u3002", "result": "VSI\u5728LongVideoBench\u6587\u672c\u76f8\u5173\u5b50\u96c6\u4e0a\u5173\u952e\u5e27\u5b9a\u4f4d\u51c6\u786e\u7387\u8fbe40.00%\uff0c\u4e0b\u6e38\u957f\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u51c6\u786e\u7387\u8fbe68.48%\uff0c\u8d85\u8d8a\u57fa\u7ebf\uff0c\u5728\u4e2d\u957f\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u8fbeSOTA\u3002", "conclusion": "VSI\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\uff0c\u662f\u6709\u6548\u7684\u591a\u6a21\u6001\u641c\u7d22\u7b56\u7565\u3002"}}
{"id": "2508.08013", "pdf": "https://arxiv.org/pdf/2508.08013", "abs": "https://arxiv.org/abs/2508.08013", "authors": ["Mohamad Assaad", "Zeinab Nehme", "Merouane Debbah"], "title": "Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) is an emerging learning framework that enables edge\ndevices to collaboratively train ML models without sharing their local data. FL\nfaces, however, a significant challenge due to the high amount of information\nthat must be exchanged between the devices and the aggregator in the training\nphase, which can exceed the limited capacity of wireless systems. In this\npaper, two communication-efficient FL methods are considered where\ncommunication overhead is reduced by communicating scalar values instead of\nlong vectors and by allowing high number of users to send information\nsimultaneously. The first approach employs a zero-order optimization technique\nwith two-point gradient estimator, while the second involves a first-order\ngradient computation strategy. The novelty lies in leveraging channel\ninformation in the learning algorithms, eliminating hence the need for\nadditional resources to acquire channel state information (CSI) and to remove\nits impact, as well as in considering asynchronous devices. We provide a\nrigorous analytical framework for the two methods, deriving convergence\nguarantees and establishing appropriate performance bounds.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u901a\u4fe1\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f20\u8f93\u6807\u91cf\u503c\u548c\u5141\u8bb8\u591a\u7528\u6237\u540c\u65f6\u53d1\u9001\u4fe1\u606f\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\uff0c\u7ed9\u51fa\u5206\u6790\u6846\u67b6\u548c\u6536\u655b\u4fdd\u8bc1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u8bad\u7ec3\u9636\u6bb5\u8bbe\u5907\u4e0e\u805a\u5408\u5668\u95f4\u4fe1\u606f\u4ea4\u6362\u91cf\u5927\uff0c\u8d85\u51fa\u65e0\u7ebf\u7cfb\u7edf\u5bb9\u91cf\uff0c\u9700\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "method": "\u7b2c\u4e00\u79cd\u91c7\u7528\u5e26\u4e24\u70b9\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u96f6\u9636\u4f18\u5316\u6280\u672f\uff0c\u7b2c\u4e8c\u79cd\u91c7\u7528\u4e00\u9636\u68af\u5ea6\u8ba1\u7b97\u7b56\u7565\uff0c\u5229\u7528\u4fe1\u9053\u4fe1\u606f\uff0c\u8003\u8651\u5f02\u6b65\u8bbe\u5907\u3002", "result": "\u4e3a\u4e24\u79cd\u65b9\u6cd5\u63d0\u4f9b\u4e25\u683c\u5206\u6790\u6846\u67b6\uff0c\u63a8\u5bfc\u51fa\u6536\u655b\u4fdd\u8bc1\u5e76\u5efa\u7acb\u5408\u9002\u6027\u80fd\u8fb9\u754c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e24\u79cd\u901a\u4fe1\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\uff0c\u4e14\u6709\u7406\u8bba\u4e0a\u7684\u6536\u655b\u4fdd\u8bc1\u548c\u6027\u80fd\u8fb9\u754c\u3002"}}
{"id": "2508.08034", "pdf": "https://arxiv.org/pdf/2508.08034", "abs": "https://arxiv.org/abs/2508.08034", "authors": ["Roksana Yahyaabadi", "Ghazal Farhani", "Taufiq Rahman", "Soodeh Nikan", "Abdullah Jirjees", "Fadi Araji"], "title": "Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Accurate power consumption prediction is crucial for improving efficiency and\nreducing environmental impact, yet traditional methods relying on specialized\ninstruments or rigid physical models are impractical for large-scale,\nreal-world deployment. This study introduces a scalable data-driven method\nusing powertrain dynamic feature sets and both traditional machine learning and\ndeep neural networks to estimate instantaneous and cumulative power consumption\nin internal combustion engine (ICE), electric vehicle (EV), and hybrid electric\nvehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with\nmean absolute error and root mean squared error on the order of $10^{-3}$, and\ncumulative errors under 3%. Transformer and long short-term memory models\nperformed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%,\nrespectively. Results confirm the approach's effectiveness across vehicles and\nmodels. Uncertainty analysis revealed greater variability in EV and HEV\ndatasets than ICE, due to complex power management, emphasizing the need for\nrobust models for advanced powertrains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u9884\u6d4b\u8f66\u8f86\u529f\u8017\uff0c\u5728\u4e0d\u540c\u8f66\u578b\u5e73\u53f0\u9a8c\u8bc1\u6709\u6548\uff0c\u5206\u6790\u4e86\u6570\u636e\u96c6\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u529f\u8017\u9884\u6d4b\u65b9\u6cd5\u4e0d\u9002\u5408\u5927\u89c4\u6a21\u5b9e\u9645\u90e8\u7f72\uff0c\u9700\u51c6\u786e\u3001\u53ef\u6269\u5c55\u7684\u529f\u8017\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u52a8\u529b\u7cfb\u7edf\u52a8\u6001\u7279\u5f81\u96c6\uff0c\u7ed3\u5408\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5bf9ICE\u3001EV\u548cHEV\u5e73\u53f0\u8fdb\u884c\u77ac\u65f6\u548c\u7d2f\u79ef\u529f\u8017\u4f30\u8ba1\u3002", "result": "ICE\u6a21\u578b\u77ac\u65f6\u7cbe\u5ea6\u9ad8\uff0c\u7d2f\u79ef\u8bef\u5dee\u4f4e\uff1bTransformer\u548cLSTM\u6a21\u578b\u5bf9EV\u548cHEV\u6548\u679c\u4f73\uff0c\u7d2f\u79ef\u8bef\u5dee\u5206\u522b\u4f4e\u4e8e4.1%\u548c2.1%\uff1bEV\u548cHEV\u6570\u636e\u96c6\u4e0d\u786e\u5b9a\u6027\u5927\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u8f66\u8f86\u548c\u6a21\u578b\u4e2d\u6709\u6548\uff0c\u5148\u8fdb\u52a8\u529b\u7cfb\u7edf\u9700\u9c81\u68d2\u6a21\u578b\u3002"}}
{"id": "2508.06877", "pdf": "https://arxiv.org/pdf/2508.06877", "abs": "https://arxiv.org/abs/2508.06877", "authors": ["Xiaobo Zhang", "Congqing He", "Ying He", "Jian Peng", "Dajie Fu", "Tien-Ping Tan"], "title": "ESNERA: Empirical and semantic named entity alignment for named entity dataset merging", "categories": ["cs.CL", "cs.AI"], "comment": "30 pages, 12 figures", "summary": "Named Entity Recognition (NER) is a fundamental task in natural language\nprocessing. It remains a research hotspot due to its wide applicability across\ndomains. Although recent advances in deep learning have significantly improved\nNER performance, they rely heavily on large, high-quality annotated datasets.\nHowever, building these datasets is expensive and time-consuming, posing a\nmajor bottleneck for further research. Current dataset merging approaches\nmainly focus on strategies like manual label mapping or constructing label\ngraphs, which lack interpretability and scalability. To address this, we\npropose an automatic label alignment method based on label similarity. The\nmethod combines empirical and semantic similarities, using a greedy pairwise\nmerging strategy to unify label spaces across different datasets. Experiments\nare conducted in two stages: first, merging three existing NER datasets into a\nunified corpus with minimal impact on NER performance; second, integrating this\ncorpus with a small-scale, self-built dataset in the financial domain. The\nresults show that our method enables effective dataset merging and enhances NER\nperformance in the low-resource financial domain. This study presents an\nefficient, interpretable, and scalable solution for integrating multi-source\nNER corpora.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6807\u7b7e\u76f8\u4f3c\u5ea6\u7684\u81ea\u52a8\u6807\u7b7e\u5bf9\u9f50\u65b9\u6cd5\u89e3\u51b3NER\u6570\u636e\u96c6\u5408\u5e76\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4f4e\u8d44\u6e90\u91d1\u878d\u9886\u57dfNER\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7684NER\u4f9d\u8d56\u5927\u91cf\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u4f46\u6784\u5efa\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u6570\u636e\u96c6\u5408\u5e76\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6807\u7b7e\u76f8\u4f3c\u5ea6\u7684\u81ea\u52a8\u6807\u7b7e\u5bf9\u9f50\u65b9\u6cd5\uff0c\u7ed3\u5408\u7ecf\u9a8c\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u91c7\u7528\u8d2a\u5a6a\u6210\u5bf9\u5408\u5e76\u7b56\u7565\u7edf\u4e00\u4e0d\u540c\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7a7a\u95f4\u3002", "result": "\u5c06\u4e09\u4e2a\u73b0\u6709NER\u6570\u636e\u96c6\u5408\u5e76\u6210\u7edf\u4e00\u8bed\u6599\u5e93\uff0c\u4e0e\u91d1\u878d\u9886\u57df\u81ea\u5efa\u5c0f\u6570\u636e\u96c6\u96c6\u6210\uff0c\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u91d1\u878d\u9886\u57dfNER\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u6e90NER\u8bed\u6599\u96c6\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.08040", "pdf": "https://arxiv.org/pdf/2508.08040", "abs": "https://arxiv.org/abs/2508.08040", "authors": ["Maozhen Zhang", "Mengnan Zhao", "Bo Wang"], "title": "BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Prompt-based tuning has emerged as a lightweight alternative to full\nfine-tuning in large vision-language models, enabling efficient adaptation via\nlearned contextual prompts. This paradigm has recently been extended to\nfederated learning settings (e.g., PromptFL), where clients collaboratively\ntrain prompts under data privacy constraints. However, the security\nimplications of prompt-based aggregation in federated multimodal learning\nremain largely unexplored, leaving a critical attack surface unaddressed. In\nthis paper, we introduce \\textbf{BadPromptFL}, the first backdoor attack\ntargeting prompt-based federated learning in multimodal contrastive models. In\nBadPromptFL, compromised clients jointly optimize local backdoor triggers and\nprompt embeddings, injecting poisoned prompts into the global aggregation\nprocess. These prompts are then propagated to benign clients, enabling\nuniversal backdoor activation at inference without modifying model parameters.\nLeveraging the contextual learning behavior of CLIP-style architectures,\nBadPromptFL achieves high attack success rates (e.g., \\(>90\\%\\)) with minimal\nvisibility and limited client participation. Extensive experiments across\nmultiple datasets and aggregation protocols validate the effectiveness,\nstealth, and generalizability of our attack, raising critical concerns about\nthe robustness of prompt-based federated learning in real-world deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u591a\u6a21\u6001\u5bf9\u6bd4\u6a21\u578b\u4e2d\u57fa\u4e8e\u63d0\u793a\u7684\u8054\u90a6\u5b66\u4e60\u7684\u9996\u4e2a\u540e\u95e8\u653b\u51fbBadPromptFL\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u7b49\uff0c\u5f15\u53d1\u5bf9\u76f8\u5173\u5b66\u4e60\u9c81\u68d2\u6027\u7684\u5173\u6ce8\u3002", "motivation": "\u57fa\u4e8e\u63d0\u793a\u7684\u805a\u5408\u5728\u8054\u90a6\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u5f71\u54cd\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u5b58\u5728\u653b\u51fb\u9762\u672a\u89e3\u51b3\u3002", "method": "\u53d7\u635f\u5ba2\u6237\u7aef\u8054\u5408\u4f18\u5316\u672c\u5730\u540e\u95e8\u89e6\u53d1\u5668\u548c\u63d0\u793a\u5d4c\u5165\uff0c\u5c06\u4e2d\u6bd2\u63d0\u793a\u6ce8\u5165\u5168\u5c40\u805a\u5408\u8fc7\u7a0b\uff0c\u5229\u7528CLIP\u98ce\u683c\u67b6\u6784\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u884c\u4e3a\u3002", "result": "BadPromptFL\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u805a\u5408\u534f\u8bae\u4e0a\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff08>90%\uff09\uff0c\u5177\u6709\u4f4e\u53ef\u89c1\u6027\u548c\u4f4e\u5ba2\u6237\u7aef\u53c2\u4e0e\u5ea6\u3002", "conclusion": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u653b\u51fb\u7684\u6709\u6548\u6027\u3001\u9690\u853d\u6027\u548c\u901a\u7528\u6027\uff0c\u5f15\u53d1\u5bf9\u73b0\u5b9e\u90e8\u7f72\u4e2d\u57fa\u4e8e\u63d0\u793a\u7684\u8054\u90a6\u5b66\u4e60\u9c81\u68d2\u6027\u7684\u62c5\u5fe7\u3002"}}
{"id": "2508.06878", "pdf": "https://arxiv.org/pdf/2508.06878", "abs": "https://arxiv.org/abs/2508.06878", "authors": ["Maoxun Yuan", "Duanni Meng", "Ziteng Xi", "Tianyi Zhao", "Shiji Zhao", "Yimian Dai", "Xingxing Wei"], "title": "NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Infrared small target detection and segmentation (IRSTDS) is a critical yet\nchallenging task in defense and civilian applications, owing to the dim,\nshapeless appearance of targets and severe background clutter. Recent CNN-based\nmethods have achieved promising target perception results, but they only focus\non enhancing feature representation to offset the impact of noise, which\nresults in the increased false alarms problem. In this paper, through analyzing\nthe problem from the frequency domain, we pioneer in improving performance from\nnoise suppression perspective and propose a novel noise-suppression feature\npyramid network (NS-FPN), which integrates a low-frequency guided feature\npurification (LFP) module and a spiral-aware feature sampling (SFS) module into\nthe original FPN structure. The LFP module suppresses the noise features by\npurifying high-frequency components to achieve feature enhancement devoid of\nnoise interference, while the SFS module further adopts spiral sampling to fuse\ntarget-relevant features in feature fusion process. Our NS-FPN is designed to\nbe lightweight yet effective and can be easily plugged into existing IRSTDS\nframeworks. Extensive experiments on the public IRSTDS datasets demonstrate\nthat our method significantly reduces false alarms and achieves superior\nperformance on IRSTDS tasks.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u7ea2\u5916\u5c0f\u76ee\u6807\u68c0\u6d4b\u4e0e\u5206\u5272\u4efb\u52a1\uff0c\u4ece\u9891\u57df\u5206\u6790\u95ee\u9898\uff0c\u63d0\u51faNS - FPN\u7f51\u7edc\uff0c\u964d\u4f4e\u8bef\u62a5\u7387\uff0c\u63d0\u5347\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eCNN\u7684\u65b9\u6cd5\u4ec5\u5173\u6ce8\u589e\u5f3a\u7279\u5f81\u8868\u793a\u6765\u62b5\u6d88\u566a\u58f0\u5f71\u54cd\uff0c\u5bfc\u81f4\u8bef\u62a5\u7387\u589e\u52a0\uff0c\u9700\u4ece\u566a\u58f0\u6291\u5236\u89d2\u5ea6\u63d0\u5347\u7ea2\u5916\u5c0f\u76ee\u6807\u68c0\u6d4b\u4e0e\u5206\u5272\u6027\u80fd\u3002", "method": "\u63d0\u51faNS - FPN\u7f51\u7edc\uff0c\u5c06LFP\u6a21\u5757\u548cSFS\u6a21\u5757\u96c6\u6210\u5230\u539f\u59cbFPN\u7ed3\u6784\u4e2d\uff0cLFP\u6a21\u5757\u51c0\u5316\u9ad8\u9891\u5206\u91cf\u6291\u5236\u566a\u58f0\u7279\u5f81\uff0cSFS\u6a21\u5757\u91c7\u7528\u87ba\u65cb\u91c7\u6837\u878d\u5408\u76ee\u6807\u76f8\u5173\u7279\u5f81\u3002", "result": "\u5728\u516c\u5171IRSTDS\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u8bef\u62a5\u7387\uff0c\u5728IRSTDS\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6027\u80fd\uff0c\u4e14\u7f51\u7edc\u8f7b\u91cf\uff0c\u53ef\u8f7b\u677e\u96c6\u6210\u5230\u73b0\u6709IRSTDS\u6846\u67b6\u4e2d\u3002"}}
{"id": "2508.08052", "pdf": "https://arxiv.org/pdf/2508.08052", "abs": "https://arxiv.org/abs/2508.08052", "authors": ["Supriyo Chakraborty", "Krishnan Raghavan"], "title": "On Understanding of the Dynamics of Model Capacity in Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The stability-plasticity dilemma, closely related to a neural network's (NN)\ncapacity-its ability to represent tasks-is a fundamental challenge in continual\nlearning (CL). Within this context, we introduce CL's effective model capacity\n(CLEMC) that characterizes the dynamic behavior of the stability-plasticity\nbalance point. We develop a difference equation to model the evolution of the\ninterplay between the NN, task data, and optimization procedure. We then\nleverage CLEMC to demonstrate that the effective capacity-and, by extension,\nthe stability-plasticity balance point is inherently non-stationary. We show\nthat regardless of the NN architecture or optimization method, a NN's ability\nto represent new tasks diminishes when incoming task distributions differ from\nprevious ones. We conduct extensive experiments to support our theoretical\nfindings, spanning a range of architectures-from small feedforward network and\nconvolutional networks to medium-sized graph neural networks and\ntransformer-based large language models with millions of parameters.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165CL\u7684\u6709\u6548\u6a21\u578b\u5bb9\u91cfCLEMC\uff0c\u5efa\u6a21NN\u3001\u4efb\u52a1\u6570\u636e\u548c\u4f18\u5316\u8fc7\u7a0b\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u8bc1\u660e\u6709\u6548\u5bb9\u91cf\u548c\u7a33\u5b9a - \u53ef\u5851\u6027\u5e73\u8861\u70b9\u975e\u5e73\u7a33\uff0c\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u53d1\u73b0\u3002", "motivation": "\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u7a33\u5b9a\u6027 - \u53ef\u5851\u6027\u56f0\u5883\u8fd9\u4e00\u57fa\u672c\u6311\u6218\u3002", "method": "\u5f15\u5165CLEMC\uff0c\u5f00\u53d1\u5dee\u5206\u65b9\u7a0b\u5efa\u6a21\u76f8\u4e92\u4f5c\u7528\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u8bc1\u660e\u6709\u6548\u5bb9\u91cf\u548c\u7a33\u5b9a - \u53ef\u5851\u6027\u5e73\u8861\u70b9\u975e\u5e73\u7a33\uff0c\u5f53\u65b0\u4efb\u52a1\u5206\u5e03\u4e0e\u65e7\u4efb\u52a1\u4e0d\u540c\u65f6\uff0cNN\u8868\u793a\u65b0\u4efb\u52a1\u7684\u80fd\u529b\u964d\u4f4e\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u9002\u7528\u4e8e\u591a\u79cd\u67b6\u6784\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u53d1\u73b0\u3002"}}
{"id": "2508.06890", "pdf": "https://arxiv.org/pdf/2508.06890", "abs": "https://arxiv.org/abs/2508.06890", "authors": ["Jinsung Yoon", "Wooyeol Jeong", "Jio Gim", "Young-Joo Suh"], "title": "Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "Accepted at ASRU 2025", "summary": "Emotional voice conversion (EVC) aims to modify the emotional style of speech\nwhile preserving its linguistic content. In practical EVC, controllability, the\nability to independently control speaker identity and emotional style using\ndistinct references, is crucial. However, existing methods often struggle to\nfully disentangle these attributes and lack the ability to model fine-grained\nemotional expressions such as temporal dynamics. We propose Maestro-EVC, a\ncontrollable EVC framework that enables independent control of content, speaker\nidentity, and emotion by effectively disentangling each attribute from separate\nreferences. We further introduce a temporal emotion representation and an\nexplicit prosody modeling with prosody augmentation to robustly capture and\ntransfer the temporal dynamics of the target emotion, even under\nprosody-mismatched conditions. Experimental results confirm that Maestro-EVC\nachieves high-quality, controllable, and emotionally expressive speech\nsynthesis.", "AI": {"tldr": "\u63d0\u51faMaestro - EVC\u6846\u67b6\u7528\u4e8e\u60c5\u611f\u8bed\u97f3\u8f6c\u6362\uff0c\u5b9e\u73b0\u5185\u5bb9\u3001\u8bf4\u8bdd\u4eba\u8eab\u4efd\u548c\u60c5\u611f\u7684\u72ec\u7acb\u63a7\u5236\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u9ad8\u8d28\u91cf\u3001\u53ef\u63a7\u548c\u5bcc\u6709\u60c5\u611f\u8868\u8fbe\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u8bed\u97f3\u8f6c\u6362\u65b9\u6cd5\u96be\u4ee5\u5b8c\u5168\u5206\u79bb\u8bf4\u8bdd\u4eba\u8eab\u4efd\u548c\u60c5\u611f\u98ce\u683c\u5c5e\u6027\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u7ec6\u7c92\u5ea6\u60c5\u611f\u8868\u8fbe\uff08\u5982\u65f6\u95f4\u52a8\u6001\uff09\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u5bf9\u8fd9\u4e9b\u5c5e\u6027\u8fdb\u884c\u72ec\u7acb\u63a7\u5236\u3002", "method": "\u63d0\u51faMaestro - EVC\u6846\u67b6\uff0c\u6709\u6548\u5206\u79bb\u5185\u5bb9\u3001\u8bf4\u8bdd\u4eba\u8eab\u4efd\u548c\u60c5\u611f\u5c5e\u6027\uff1b\u5f15\u5165\u65f6\u95f4\u60c5\u611f\u8868\u793a\u548c\u663e\u5f0f\u97f5\u5f8b\u5efa\u6a21\u53ca\u97f5\u5f8b\u589e\u5f3a\uff0c\u4ee5\u6355\u6349\u548c\u4f20\u9012\u76ee\u6807\u60c5\u611f\u7684\u65f6\u95f4\u52a8\u6001\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9eMaestro - EVC\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u53ef\u63a7\u4e14\u5bcc\u6709\u60c5\u611f\u8868\u8fbe\u7684\u8bed\u97f3\u5408\u6210\u3002", "conclusion": "Maestro - EVC\u6846\u67b6\u5728\u60c5\u611f\u8bed\u97f3\u8f6c\u6362\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.06895", "pdf": "https://arxiv.org/pdf/2508.06895", "abs": "https://arxiv.org/abs/2508.06895", "authors": ["Jianting Tang", "Yubo Wang", "Haoyu Cao", "Linli Xu"], "title": "BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICCV 2025", "summary": "Mainstream Multimodal Large Language Models (MLLMs) achieve visual\nunderstanding by using a vision projector to bridge well-pretrained vision\nencoders and large language models (LLMs). The inherent gap between visual and\ntextual modalities makes the embeddings from the vision projector critical for\nvisual comprehension. However, current alignment approaches treat visual\nembeddings as contextual cues and merely apply auto-regressive supervision to\ntextual outputs, neglecting the necessity of introducing equivalent direct\nvisual supervision, which hinders the potential finer alignment of visual\nembeddings. In this paper, based on our analysis of the refinement process of\nvisual embeddings in the LLM's shallow layers, we propose BASIC, a method that\nutilizes refined visual embeddings within the LLM as supervision to directly\nguide the projector in generating initial visual embeddings. Specifically, the\nguidance is conducted from two perspectives: (i) optimizing embedding\ndirections by reducing angles between initial and supervisory embeddings in\nsemantic space; (ii) improving semantic matching by minimizing disparities\nbetween the logit distributions of both visual embeddings. Without additional\nsupervisory models or artificial annotations, BASIC significantly improves the\nperformance of MLLMs across a wide range of benchmarks, demonstrating the\neffectiveness of our introduced direct visual supervision.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u89c6\u89c9\u5bf9\u9f50\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u63d0\u51faBASIC\u65b9\u6cd5\uff0c\u65e0\u9700\u989d\u5916\u76d1\u7763\u6a21\u578b\u6216\u4eba\u5de5\u6807\u6ce8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u89c6\u89c9\u5bf9\u9f50\u65b9\u6cd5\u4ec5\u5bf9\u6587\u672c\u8f93\u51fa\u8fdb\u884c\u81ea\u56de\u5f52\u76d1\u7763\uff0c\u5ffd\u7565\u4e86\u76f4\u63a5\u89c6\u89c9\u76d1\u7763\uff0c\u963b\u788d\u4e86\u89c6\u89c9\u5d4c\u5165\u7684\u7cbe\u7ec6\u5bf9\u9f50\u3002", "method": "\u63d0\u51faBASIC\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7cbe\u70bc\u7684\u89c6\u89c9\u5d4c\u5165\u4f5c\u4e3a\u76d1\u7763\uff0c\u4ece\u4f18\u5316\u5d4c\u5165\u65b9\u5411\u548c\u63d0\u9ad8\u8bed\u4e49\u5339\u914d\u4e24\u4e2a\u89d2\u5ea6\u6307\u5bfc\u6295\u5f71\u4eea\u751f\u6210\u521d\u59cb\u89c6\u89c9\u5d4c\u5165\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u5f15\u5165\u7684\u76f4\u63a5\u89c6\u89c9\u76d1\u7763\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2508.08071", "pdf": "https://arxiv.org/pdf/2508.08071", "abs": "https://arxiv.org/abs/2508.08071", "authors": ["Yunqing Li", "Zixiang Tang", "Jiaying Zhuang", "Zhenyu Yang", "Farhad Ameri", "Jianbang Zhang"], "title": "C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction", "categories": ["cs.LG", "cs.AI", "J.1; I.2.4; H.2.8"], "comment": "Accepted as a poster presentation at the KDD 2025 Workshop on AI for\n  Supply Chain (AI4SupplyChain)", "summary": "Connecting an ever-expanding catalogue of products with suitable\nmanufacturers and suppliers is critical for resilient, efficient global supply\nchains, yet traditional methods struggle to capture complex capabilities,\ncertifications, geographic constraints, and rich multimodal data of real-world\nmanufacturer profiles. To address these gaps, we introduce PMGraph, a public\nbenchmark of bipartite and heterogeneous multimodal supply-chain graphs linking\n8,888 manufacturers, over 70k products, more than 110k manufacturer-product\nedges, and over 29k product images. Building on this benchmark, we propose the\nCascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first\naligns and aggregates textual and visual attributes into intermediate group\nembeddings, then propagates them through a manufacturer-product hetero-graph\nvia multiscale message passing to enhance link prediction accuracy. C-MAG also\nprovides practical guidelines for modality-aware fusion, preserving predictive\nperformance in noisy, real-world settings.", "AI": {"tldr": "\u63d0\u51faPMGraph\u57fa\u51c6\u548cCascade Multimodal Attributed Graph (C - MAG)\u67b6\u6784\u89e3\u51b3\u4f9b\u5e94\u94fe\u8fde\u63a5\u95ee\u9898", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5236\u9020\u5546\u590d\u6742\u4fe1\u606f\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u8fde\u63a5\u4ea7\u54c1\u4e0e\u5236\u9020\u5546\u548c\u4f9b\u5e94\u5546\u4ee5\u6784\u5efa\u9ad8\u6548\u4f9b\u5e94\u94fe", "method": "\u5f15\u5165PMGraph\u57fa\u51c6\uff0c\u63d0\u51faC - MAG\u67b6\u6784\uff0c\u5148\u805a\u5408\u6587\u672c\u548c\u89c6\u89c9\u5c5e\u6027\u5230\u4e2d\u95f4\u5d4c\u5165\uff0c\u518d\u901a\u8fc7\u591a\u5c3a\u5ea6\u6d88\u606f\u4f20\u9012\u63d0\u5347\u94fe\u63a5\u9884\u6d4b\u51c6\u786e\u6027", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c", "conclusion": "C - MAG\u4e3a\u6a21\u6001\u611f\u77e5\u878d\u5408\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\uff0c\u80fd\u5728\u73b0\u5b9e\u566a\u58f0\u73af\u5883\u4e2d\u4fdd\u6301\u9884\u6d4b\u6027\u80fd"}}
{"id": "2508.06900", "pdf": "https://arxiv.org/pdf/2508.06900", "abs": "https://arxiv.org/abs/2508.06900", "authors": ["Weiran Chen", "Guiqian Zhu", "Ying Li", "Yi Ji", "Chunping Liu"], "title": "Advancements in Chinese font generation since deep learning era: A survey", "categories": ["cs.CV", "cs.AI"], "comment": "42 Pages, 25 figures", "summary": "Chinese font generation aims to create a new Chinese font library based on\nsome reference samples. It is a topic of great concern to many font designers\nand typographers. Over the past years, with the rapid development of deep\nlearning algorithms, various new techniques have achieved flourishing and\nthriving progress. Nevertheless, how to improve the overall quality of\ngenerated Chinese character images remains a tough issue. In this paper, we\nconduct a holistic survey of the recent Chinese font generation approaches\nbased on deep learning. To be specific, we first illustrate the research\nbackground of the task. Then, we outline our literature selection and analysis\nmethodology, and review a series of related fundamentals, including classical\ndeep learning architectures, font representation formats, public datasets, and\nfrequently-used evaluation metrics. After that, relying on the number of\nreference samples required to generate a new font, we categorize the existing\nmethods into two major groups: many-shot font generation and few-shot font\ngeneration methods. Within each category, representative approaches are\nsummarized, and their strengths and limitations are also discussed in detail.\nFinally, we conclude our paper with the challenges and future directions, with\nthe expectation to provide some valuable illuminations for the researchers in\nthis field.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4e2d\u6587\u5b57\u4f53\u751f\u6210\u65b9\u6cd5\u8fdb\u884c\u5168\u9762\u8c03\u7814\uff0c\u5206\u7c7b\u603b\u7ed3\u65b9\u6cd5\u5e76\u8ba8\u8bba\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u63d0\u9ad8\u751f\u6210\u4e2d\u6587\u6c49\u5b57\u56fe\u50cf\u7684\u6574\u4f53\u8d28\u91cf\uff0c\u89e3\u51b3\u73b0\u6709\u96be\u9898\uff0c\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u5148\u9610\u8ff0\u7814\u7a76\u80cc\u666f\uff0c\u8bf4\u660e\u6587\u732e\u9009\u62e9\u548c\u5206\u6790\u65b9\u6cd5\uff0c\u56de\u987e\u76f8\u5173\u57fa\u7840\u77e5\u8bc6\uff0c\u6309\u6240\u9700\u53c2\u8003\u6837\u672c\u6570\u91cf\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u591a\u6837\u672c\u548c\u5c11\u6837\u672c\u5b57\u4f53\u751f\u6210\u65b9\u6cd5\u5e76\u603b\u7ed3\u4ee3\u8868\u65b9\u6cd5\u53ca\u4f18\u7f3a\u70b9\u3002", "result": "\u5b8c\u6210\u5bf9\u8fd1\u671f\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4e2d\u6587\u5b57\u4f53\u751f\u6210\u65b9\u6cd5\u7684\u5168\u9762\u8c03\u7814\u3002", "conclusion": "\u6307\u51fa\u8be5\u9886\u57df\u5b58\u5728\u7684\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u671f\u671b\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u542f\u793a\u3002"}}
{"id": "2508.08073", "pdf": "https://arxiv.org/pdf/2508.08073", "abs": "https://arxiv.org/abs/2508.08073", "authors": ["Dimitris Tsaras", "Xing Li", "Lei Chen", "Zhiyao Xie", "Mingxuan Yuan"], "title": "ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring", "categories": ["cs.LG", "cs.AR", "cs.ET"], "comment": "Accepted to DAC 2025", "summary": "In electronic design automation, logic optimization operators play a crucial\nrole in minimizing the gate count of logic circuits. However, their computation\ndemands are high. Operators such as refactor conventionally form iterative cuts\nfor each node, striving for a more compact representation - a task which often\nfails 98% on average. Prior research has sought to mitigate computational cost\nthrough parallelization. In contrast, our approach leverages a classifier to\nprune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis\noperations. Experiments on the refactor operator using the EPFL benchmark suite\nand 10 large industrial designs demonstrate that this technique can speedup\nlogic optimization by 3.9x on average compared with the state-of-the-art ABC\nimplementation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5206\u7c7b\u5668\u9884\u5148\u4fee\u526a\u4e0d\u6210\u529f\u7684\u5207\u5272\u4ee5\u52a0\u901f\u903b\u8f91\u4f18\u5316\uff0c\u5b9e\u9a8c\u8868\u660e\u76f8\u6bd4\u73b0\u6709ABC\u5b9e\u73b0\u5e73\u5747\u53ef\u63d0\u901f3.9\u500d\u3002", "motivation": "\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u4e2d\u903b\u8f91\u4f18\u5316\u7b97\u5b50\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u4f20\u7edf\u7b97\u5b50\u5f62\u6210\u8fed\u4ee3\u5207\u5272\u4efb\u52a1\u5e73\u574798%\u5931\u8d25\uff0c\u6b64\u524d\u5e76\u884c\u5316\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5229\u7528\u5206\u7c7b\u5668\u9884\u5148\u4fee\u526a\u4e0d\u6210\u529f\u7684\u5207\u5272\uff0c\u6d88\u9664\u4e0d\u5fc5\u8981\u7684\u91cd\u65b0\u5408\u6210\u64cd\u4f5c\u3002", "result": "\u5728EPFL\u57fa\u51c6\u5957\u4ef6\u548c10\u4e2a\u5927\u578b\u5de5\u4e1a\u8bbe\u8ba1\u4e0a\u5bf9refactor\u7b97\u5b50\u5b9e\u9a8c\uff0c\u8be5\u6280\u672f\u76f8\u6bd4\u73b0\u6709ABC\u5b9e\u73b0\u5e73\u5747\u53ef\u63d0\u901f3.9\u500d\u3002", "conclusion": "\u5229\u7528\u5206\u7c7b\u5668\u9884\u5148\u4fee\u526a\u5207\u5272\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u52a0\u901f\u903b\u8f91\u4f18\u5316\u3002"}}
{"id": "2508.06908", "pdf": "https://arxiv.org/pdf/2508.06908", "abs": "https://arxiv.org/abs/2508.06908", "authors": ["Jinhao Li", "Zijian Chen", "Lirong Deng", "Changbo Wang", "Guangtao Zhai"], "title": "MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Person re-identification (ReID) aims to retrieve the images of an interested\nperson in the gallery images, with wide applications in medical rehabilitation,\nabnormal behavior detection, and public security. However, traditional person\nReID models suffer from uni-modal capability, leading to poor generalization\nability in multi-modal data, such as RGB, thermal, infrared, sketch images,\ntextual descriptions, etc. Recently, the emergence of multi-modal large\nlanguage models (MLLMs) shows a promising avenue for addressing this problem.\nDespite this potential, existing methods merely regard MLLMs as feature\nextractors or caption generators, which do not fully unleash their reasoning,\ninstruction-following, and cross-modal understanding capabilities. To bridge\nthis gap, we introduce MMReID-Bench, the first multi-task multi-modal benchmark\nspecifically designed for person ReID. The MMReID-Bench includes 20,710\nmulti-modal queries and gallery images covering 10 different person ReID tasks.\nComprehensive experiments demonstrate the remarkable capabilities of MLLMs in\ndelivering effective and versatile person ReID. Nevertheless, they also have\nlimitations in handling a few modalities, particularly thermal and infrared\ndata. We hope MMReID-Bench can facilitate the community to develop more robust\nand generalizable multimodal foundation models for person ReID.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u884c\u4eba\u91cd\u8bc6\u522b\u7684\u591a\u4efb\u52a1\u591a\u6a21\u6001\u57fa\u51c6MMReID - Bench\uff0c\u5b9e\u9a8c\u5c55\u793a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u53ca\u5c40\u9650\uff0c\u671b\u63a8\u52a8\u76f8\u5173\u6a21\u578b\u53d1\u5c55\u3002", "motivation": "\u4f20\u7edf\u884c\u4eba\u91cd\u8bc6\u522b\u6a21\u578b\u5355\u6a21\u6001\u80fd\u529b\u5dee\uff0c\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u672a\u5145\u5206\u53d1\u6325\u5176\u80fd\u529b\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u9996\u4e2a\u4e13\u95e8\u7528\u4e8e\u884c\u4eba\u91cd\u8bc6\u522b\u7684\u591a\u4efb\u52a1\u591a\u6a21\u6001\u57fa\u51c6MMReID - Bench\uff0c\u542b20,710\u4e2a\u591a\u6a21\u6001\u67e5\u8be2\u548c\u56fe\u5e93\u56fe\u50cf\uff0c\u6db5\u76d610\u4e2a\u4e0d\u540c\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u884c\u4eba\u91cd\u8bc6\u522b\u4e0a\u6709\u6548\u4e14\u901a\u7528\uff0c\u4f46\u5904\u7406\u90e8\u5206\u6a21\u6001\uff08\u5982\u70ed\u6210\u50cf\u548c\u7ea2\u5916\u6570\u636e\uff09\u6709\u5c40\u9650\u3002", "conclusion": "\u671f\u671bMMReID - Bench\u80fd\u63a8\u52a8\u793e\u533a\u4e3a\u884c\u4eba\u91cd\u8bc6\u522b\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u66f4\u901a\u7528\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u3002"}}
{"id": "2508.06917", "pdf": "https://arxiv.org/pdf/2508.06917", "abs": "https://arxiv.org/abs/2508.06917", "authors": ["Jianting Tang", "Yubo Wang", "Haoyu Cao", "Linli Xu"], "title": "CROP: Integrating Topological and Spatial Structures via Cross-View Prefixes for Molecular LLMs", "categories": ["q-bio.QM", "cs.AI"], "comment": "Accepted to ACMMM 2025", "summary": "Recent advances in molecular science have been propelled significantly by\nlarge language models (LLMs). However, their effectiveness is limited when\nrelying solely on molecular sequences, which fail to capture the complex\nstructures of molecules. Beyond sequence representation, molecules exhibit two\ncomplementary structural views: the first focuses on the topological\nrelationships between atoms, as exemplified by the graph view; and the second\nemphasizes the spatial configuration of molecules, as represented by the image\nview. The two types of views provide unique insights into molecular structures.\nTo leverage these views collaboratively, we propose the CROss-view Prefixes\n(CROP) to enhance LLMs' molecular understanding through efficient multi-view\nintegration. CROP possesses two advantages: (i) efficiency: by jointly\nresampling multiple structural views into fixed-length prefixes, it avoids\nexcessive consumption of the LLM's limited context length and allows easy\nexpansion to more views; (ii) effectiveness: by utilizing the LLM's\nself-encoded molecular sequences to guide the resampling process, it boosts the\nquality of the generated prefixes. Specifically, our framework features a\ncarefully designed SMILES Guided Resampler for view resampling, and a\nStructural Embedding Gate for converting the resulting embeddings into LLM's\nprefixes. Extensive experiments demonstrate the superiority of CROP in tasks\nincluding molecule captioning, IUPAC name prediction and molecule property\nprediction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCROP\u65b9\u6cd5\u901a\u8fc7\u591a\u89c6\u56fe\u96c6\u6210\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u5206\u5b50\u7684\u7406\u89e3\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u9879\u5206\u5b50\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u4f9d\u8d56\u5206\u5b50\u5e8f\u5217\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u5206\u5b50\u590d\u6742\u7ed3\u6784\u4e0a\u6548\u679c\u6709\u9650\uff0c\u800c\u5206\u5b50\u7684\u56fe\u548c\u56fe\u50cf\u4e24\u79cd\u7ed3\u6784\u89c6\u56fe\u80fd\u63d0\u4f9b\u72ec\u7279\u89c1\u89e3\uff0c\u9700\u5229\u7528\u591a\u89c6\u56fe\u534f\u4f5c\u63d0\u5347\u6a21\u578b\u80fd\u529b\u3002", "method": "\u63d0\u51faCROss - view Prefixes (CROP)\u65b9\u6cd5\uff0c\u5305\u542bSMILES Guided Resampler\u8fdb\u884c\u89c6\u56fe\u91cd\u91c7\u6837\u548cStructural Embedding Gate\u5c06\u5d4c\u5165\u8f6c\u6362\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u524d\u7f00\u3002", "result": "\u5728\u5206\u5b50\u63cf\u8ff0\u3001IUPAC\u540d\u79f0\u9884\u6d4b\u548c\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u7b49\u4efb\u52a1\u4e2d\uff0cCROP\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "conclusion": "CROP\u65b9\u6cd5\u5728\u591a\u89c6\u56fe\u96c6\u6210\u65b9\u9762\u6709\u6548\uff0c\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u5206\u5b50\u7684\u7406\u89e3\uff0c\u53ef\u7528\u4e8e\u591a\u79cd\u5206\u5b50\u76f8\u5173\u4efb\u52a1\u3002"}}
{"id": "2508.08087", "pdf": "https://arxiv.org/pdf/2508.08087", "abs": "https://arxiv.org/abs/2508.08087", "authors": ["Amir Ali Panahi", "Daniel Luder", "Billy Wu", "Gregory Offer", "Dirk Uwe Sauer", "Weihan Li"], "title": "Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation", "categories": ["cs.LG", "physics.chem-ph"], "comment": "31 pages, 6 figures", "summary": "Reliable digital twins of lithium-ion batteries must achieve high physical\nfidelity with sub-millisecond speed. In this work, we benchmark three\noperator-learning surrogates for the Single Particle Model (SPM): Deep Operator\nNetworks (DeepONets), Fourier Neural Operators (FNOs) and a newly proposed\nparameter-embedded Fourier Neural Operator (PE-FNO), which conditions each\nspectral layer on particle radius and solid-phase diffusivity. Models are\ntrained on simulated trajectories spanning four current families (constant,\ntriangular, pulse-train, and Gaussian-random-field) and a full range of\nState-of-Charge (SOC) (0 % to 100 %). DeepONet accurately replicates\nconstant-current behaviour but struggles with more dynamic loads. The basic FNO\nmaintains mesh invariance and keeps concentration errors below 1 %, with\nvoltage mean-absolute errors under 1.7 mV across all load types. Introducing\nparameter embedding marginally increases error, but enables generalisation to\nvarying radii and diffusivities. PE-FNO executes approximately 200 times faster\nthan a 16-thread SPM solver. Consequently, PE-FNO's capabilities in inverse\ntasks are explored in a parameter estimation task with Bayesian optimisation,\nrecovering anode and cathode diffusivities with 1.14 % and 8.4 % mean absolute\npercentage error, respectively, and 0.5918 percentage points higher error in\ncomparison with classical methods. These results pave the way for neural\noperators to meet the accuracy, speed and parametric flexibility demands of\nreal-time battery management, design-of-experiments and large-scale inference.\nPE-FNO outperforms conventional neural surrogates, offering a practical path\ntowards high-speed and high-fidelity electrochemical digital twins.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e09\u79cd\u7b97\u5b50\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u7528\u4e8e\u9502\u79bb\u5b50\u7535\u6c60\u5355\u7c92\u5b50\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793aPE - FNO\u5728\u901f\u5ea6\u3001\u6cdb\u5316\u6027\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u7535\u5316\u5b66\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u5b9e\u7528\u9014\u5f84\u3002", "motivation": "\u5b9e\u73b0\u5177\u6709\u4e9a\u6beb\u79d2\u901f\u5ea6\u548c\u9ad8\u7269\u7406\u4fdd\u771f\u5ea6\u7684\u53ef\u9760\u9502\u79bb\u5b50\u7535\u6c60\u6570\u5b57\u5b6a\u751f\u3002", "method": "\u5bf9\u4e09\u79cd\u7b97\u5b50\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\uff08DeepONets\u3001FNOs\u548cPE - FNO\uff09\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u591a\u79cd\u7535\u6d41\u7c7b\u578b\u548c\u8377\u7535\u72b6\u6001\u6570\u636e\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\u3002", "result": "DeepONet\u5904\u7406\u52a8\u6001\u8d1f\u8f7d\u6709\u56f0\u96be\uff1bFNO\u6d53\u5ea6\u8bef\u5dee\u4f4e\u4e8e1%\uff0c\u7535\u538b\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4f4e\u4e8e1.7mV\uff1bPE - FNO\u6267\u884c\u901f\u5ea6\u6bd416\u7ebf\u7a0bSPM\u6c42\u89e3\u5668\u5feb\u7ea6200\u500d\uff0c\u53c2\u6570\u4f30\u8ba1\u6709\u4e00\u5b9a\u8bef\u5dee\u4f46\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "PE - FNO\u80fd\u6ee1\u8db3\u5b9e\u65f6\u7535\u6c60\u7ba1\u7406\u7b49\u9700\u6c42\uff0c\u4f18\u4e8e\u4f20\u7edf\u795e\u7ecf\u66ff\u4ee3\u6a21\u578b\uff0c\u4e3a\u9ad8\u901f\u9ad8\u4fdd\u771f\u7535\u5316\u5b66\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2508.06937", "pdf": "https://arxiv.org/pdf/2508.06937", "abs": "https://arxiv.org/abs/2508.06937", "authors": ["Weiyan Xie", "Han Gao", "Didan Deng", "Kaican Li", "April Hua Liu", "Yongxiang Huang", "Nevin L. Zhang"], "title": "CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing", "categories": ["cs.CV", "cs.AI"], "comment": "Project Page: vaynexie.github.io/CannyEdit/", "summary": "Recent advances in text-to-image (T2I) models have enabled training-free\nregional image editing by leveraging the generative priors of foundation\nmodels. However, existing methods struggle to balance text adherence in edited\nregions, context fidelity in unedited areas, and seamless integration of edits.\nWe introduce CannyEdit, a novel training-free framework that addresses these\nchallenges through two key innovations: (1) Selective Canny Control, which\nmasks the structural guidance of Canny ControlNet in user-specified editable\nregions while strictly preserving details of the source images in unedited\nareas via inversion-phase ControlNet information retention. This enables\nprecise, text-driven edits without compromising contextual integrity. (2)\nDual-Prompt Guidance, which combines local prompts for object-specific edits\nwith a global target prompt to maintain coherent scene interactions. On\nreal-world image editing tasks (addition, replacement, removal), CannyEdit\noutperforms prior methods like KV-Edit, achieving a 2.93 to 10.49 percent\nimprovement in the balance of text adherence and context fidelity. In terms of\nediting seamlessness, user studies reveal only 49.2 percent of general users\nand 42.0 percent of AIGC experts identified CannyEdit's results as AI-edited\nwhen paired with real images without edits, versus 76.08 to 89.09 percent for\ncompetitor methods.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u6846\u67b6CannyEdit\u89e3\u51b3\u6587\u672c\u56fe\u50cf\u7f16\u8f91\u96be\u9898\u5e76\u8868\u73b0\u4f18\u5f02", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u7f16\u8f91\u533a\u57df\u6587\u672c\u4e00\u81f4\u6027\u3001\u672a\u7f16\u8f91\u533a\u57df\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u548c\u7f16\u8f91\u65e0\u7f1d\u96c6\u6210", "method": "\u91c7\u7528\u9009\u62e9\u6027Canny\u63a7\u5236\u548c\u53cc\u63d0\u793a\u5f15\u5bfc\u4e24\u9879\u521b\u65b0\u6280\u672f", "result": "\u5728\u771f\u5b9e\u56fe\u50cf\u7f16\u8f91\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u6587\u672c\u4e00\u81f4\u6027\u548c\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u5e73\u8861\u63d0\u53472.93 - 10.49%\uff0c\u7f16\u8f91\u65e0\u7f1d\u6027\u4e0a\u666e\u901a\u7528\u6237\u548c\u4e13\u5bb6\u8bc6\u522b\u4e3aAI\u7f16\u8f91\u7684\u6bd4\u4f8b\u4f4e", "conclusion": "CannyEdit\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6587\u672c\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u6027\u80fd\u8868\u73b0\u826f\u597d"}}
{"id": "2508.08100", "pdf": "https://arxiv.org/pdf/2508.08100", "abs": "https://arxiv.org/abs/2508.08100", "authors": ["Md. Wasiul Haque", "Sagar Dasgupta", "Mizanur Rahman"], "title": "Grid2Guide: A* Enabled Small Language Model for Indoor Navigation", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 8 figures, 6 tables", "summary": "Reliable indoor navigation remains a significant challenge in complex\nenvironments, particularly where external positioning signals and dedicated\ninfrastructures are unavailable. This research presents Grid2Guide, a hybrid\nnavigation framework that combines the A* search algorithm with a Small\nLanguage Model (SLM) to generate clear, human-readable route instructions. The\nframework first conducts a binary occupancy matrix from a given indoor map.\nUsing this matrix, the A* algorithm computes the optimal path between origin\nand destination, producing concise textual navigation steps. These steps are\nthen transformed into natural language instructions by the SLM, enhancing\ninterpretability for end users. Experimental evaluations across various indoor\nscenarios demonstrate the method's effectiveness in producing accurate and\ntimely navigation guidance. The results validate the proposed approach as a\nlightweight, infrastructure-free solution for real-time indoor navigation\nsupport.", "AI": {"tldr": "\u63d0\u51faGrid2Guide\u6df7\u5408\u5bfc\u822a\u6846\u67b6\uff0c\u7ed3\u5408A*\u7b97\u6cd5\u4e0e\u5c0f\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5ba4\u5185\u5bfc\u822a\u6307\u4ee4\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u73af\u5883\u4e2d\u65e0\u5916\u90e8\u5b9a\u4f4d\u4fe1\u53f7\u548c\u4e13\u7528\u57fa\u7840\u8bbe\u65bd\u65f6\u53ef\u9760\u5ba4\u5185\u5bfc\u822a\u7684\u96be\u9898\u3002", "method": "\u6784\u5efaGrid2Guide\u6846\u67b6\uff0c\u4ece\u5ba4\u5185\u5730\u56fe\u751f\u6210\u4e8c\u8fdb\u5236\u5360\u7528\u77e9\u9635\uff0c\u7528A*\u7b97\u6cd5\u8ba1\u7b97\u6700\u4f18\u8def\u5f84\uff0c\u518d\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\u5c06\u8def\u5f84\u6b65\u9aa4\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u3002", "result": "\u5728\u591a\u79cd\u5ba4\u5185\u573a\u666f\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u4f9b\u51c6\u786e\u53ca\u65f6\u7684\u5bfc\u822a\u6307\u5f15\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u57fa\u7840\u8bbe\u65bd\u7684\u5b9e\u65f6\u5ba4\u5185\u5bfc\u822a\u652f\u6301\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.08120", "pdf": "https://arxiv.org/pdf/2508.08120", "abs": "https://arxiv.org/abs/2508.08120", "authors": ["Keyan Rahimi", "Md. Wasiul Haque", "Sagar Dasgupta", "Mizanur Rahman"], "title": "Vision-Based Localization and LLM-based Navigation for Indoor Environments", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "20 pages, 6 figures, 1 table", "summary": "Indoor navigation remains a complex challenge due to the absence of reliable\nGPS signals and the architectural intricacies of large enclosed environments.\nThis study presents an indoor localization and navigation approach that\nintegrates vision-based localization with large language model (LLM)-based\nnavigation. The localization system utilizes a ResNet-50 convolutional neural\nnetwork fine-tuned through a two-stage process to identify the user's position\nusing smartphone camera input. To complement localization, the navigation\nmodule employs an LLM, guided by a carefully crafted system prompt, to\ninterpret preprocessed floor plan images and generate step-by-step directions.\nExperimental evaluation was conducted in a realistic office corridor with\nrepetitive features and limited visibility to test localization robustness. The\nmodel achieved high confidence and an accuracy of 96% across all tested\nwaypoints, even under constrained viewing conditions and short-duration\nqueries. Navigation tests using ChatGPT on real building floor maps yielded an\naverage instruction accuracy of 75%, with observed limitations in zero-shot\nreasoning and inference time. This research demonstrates the potential for\nscalable, infrastructure-free indoor navigation using off-the-shelf cameras and\npublicly available floor plans, particularly in resource-constrained settings\nlike hospitals, airports, and educational institutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u89c6\u89c9\u5b9a\u4f4d\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u5bfc\u822a\u7684\u5ba4\u5185\u5b9a\u4f4d\u5bfc\u822a\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6709\u4e00\u5b9a\u51c6\u786e\u6027\u548c\u6f5c\u529b\u3002", "motivation": "\u56e0\u5ba4\u5185\u7f3a\u4e4f\u53ef\u9760GPS\u4fe1\u53f7\u548c\u5efa\u7b51\u7ed3\u6784\u590d\u6742\uff0c\u5ba4\u5185\u5bfc\u822a\u9762\u4e34\u6311\u6218\uff0c\u9700\u65b0\u7684\u5b9a\u4f4d\u5bfc\u822a\u65b9\u6cd5\u3002", "method": "\u5b9a\u4f4d\u7cfb\u7edf\u7528ResNet - 50\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ecf\u4e24\u9636\u6bb5\u5fae\u8c03\uff0c\u5229\u7528\u624b\u673a\u76f8\u673a\u8f93\u5165\u5b9a\u4f4d\uff1b\u5bfc\u822a\u6a21\u5757\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u7cfb\u7edf\u63d0\u793a\u89e3\u8bfb\u9884\u5904\u7406\u7684\u5e73\u9762\u56fe\u751f\u6210\u5bfc\u822a\u6307\u4ee4\u3002", "result": "\u5b9a\u4f4d\u6a21\u578b\u5728\u5404\u6d4b\u8bd5\u70b9\u51c6\u786e\u7387\u8fbe96%\uff1b\u4f7f\u7528ChatGPT\u7684\u5bfc\u822a\u6d4b\u8bd5\u6307\u4ee4\u5e73\u5747\u51c6\u786e\u738775%\uff0c\u4f46\u96f6\u6837\u672c\u63a8\u7406\u548c\u63a8\u7406\u65f6\u95f4\u6709\u5c40\u9650\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5229\u7528\u73b0\u6210\u76f8\u673a\u548c\u516c\u5f00\u5e73\u9762\u56fe\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u65e0\u57fa\u7840\u8bbe\u65bd\u4f9d\u8d56\u7684\u5ba4\u5185\u5bfc\u822a\u7684\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2508.08122", "pdf": "https://arxiv.org/pdf/2508.08122", "abs": "https://arxiv.org/abs/2508.08122", "authors": ["Mingrong Lin", "Ke Deng", "Zhengyang Wu", "Zetao Zheng", "Jie Li"], "title": "MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Knowledge Tracing (KT) is committed to capturing students' knowledge mastery\nfrom their historical interactions. Simulating students' memory states is a\npromising approach to enhance both the performance and interpretability of\nknowledge tracing models. Memory consists of three fundamental processes:\nencoding, storage, and retrieval. Although forgetting primarily manifests\nduring the storage stage, most existing studies rely on a single,\nundifferentiated forgetting mechanism, overlooking other memory processes as\nwell as personalized forgetting patterns. To address this, this paper proposes\nmemoryKT, a knowledge tracing model based on a novel temporal variational\nautoencoder. The model simulates memory dynamics through a three-stage process:\n(i) Learning the distribution of students' knowledge memory features, (ii)\nReconstructing their exercise feedback, while (iii) Embedding a personalized\nforgetting module within the temporal workflow to dynamically modulate memory\nstorage strength. This jointly models the complete encoding-storage-retrieval\ncycle, significantly enhancing the model's perception capability for individual\ndifferences. Extensive experiments on four public datasets demonstrate that our\nproposed approach significantly outperforms state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65b0\u578b\u65f6\u95f4\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578bmemoryKT\uff0c\u6a21\u62df\u8bb0\u5fc6\u52a8\u6001\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4f9d\u8d56\u5355\u4e00\u9057\u5fd8\u673a\u5236\uff0c\u5ffd\u7565\u5176\u4ed6\u8bb0\u5fc6\u8fc7\u7a0b\u548c\u4e2a\u6027\u5316\u9057\u5fd8\u6a21\u5f0f\uff0c\u9700\u6539\u8fdb\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u3002", "method": "\u63d0\u51famemoryKT\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8fc7\u7a0b\u6a21\u62df\u8bb0\u5fc6\u52a8\u6001\uff0c\u8054\u5408\u5efa\u6a21\u7f16\u7801 - \u5b58\u50a8 - \u68c0\u7d22\u5468\u671f\uff0c\u5d4c\u5165\u4e2a\u6027\u5316\u9057\u5fd8\u6a21\u5757\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "memoryKT\u6a21\u578b\u80fd\u6709\u6548\u6a21\u62df\u8bb0\u5fc6\u52a8\u6001\uff0c\u589e\u5f3a\u5bf9\u4e2a\u4f53\u5dee\u5f02\u7684\u611f\u77e5\u80fd\u529b\uff0c\u63d0\u5347\u77e5\u8bc6\u8ffd\u8e2a\u6027\u80fd\u3002"}}
{"id": "2508.08124", "pdf": "https://arxiv.org/pdf/2508.08124", "abs": "https://arxiv.org/abs/2508.08124", "authors": ["Guanghao Jin", "Yuan Liang", "Yihan Ma", "Jingpei Wu", "Guoyang Liu"], "title": "NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection", "categories": ["cs.LG"], "comment": null, "summary": "Large-scale models pre-trained on Electroencephalography (EEG) have shown\npromise in clinical applications such as neurological disorder detection.\nHowever, the practical deployment of EEG-based large-scale models faces\ncritical challenges such as limited labeled EEG data and suboptimal performance\nin clinical scenarios. To address these issues, we propose NeuroDx-LM, a novel\nlarge-scale model specifically designed for detecting EEG-based neurological\ndisorders. Our key contributions include (i) a Selective Temporal-Frequency\nEmbedding mechanism that adaptively captures complex temporal and spectral\npatterns in EEG signals; and (ii) a Progressive Feature-Aware Training strategy\nthat refines feature representation in a two-stage process. In the first stage,\nour model learns the fundamental discriminative features of EEG activities; in\nthe second stage, the model further extracts more specialized fine-grained\nfeatures for accurate diagnostic performance. We evaluated NeuroDx-LM on the\nCHB-MIT and Schizophrenia datasets, achieving state-of-the-art performance in\nEEG-based seizure and schizophrenia detection, respectively. These results\ndemonstrate the great potential of EEG-based large-scale models to advance\nclinical applicability. Our code is available at\nhttps://github.com/LetItBe12345/NeuroDx-LM.", "AI": {"tldr": "\u63d0\u51faNeuroDx - LM\u6a21\u578b\u89e3\u51b3EEG\u5927\u6a21\u578b\u4e34\u5e8a\u5e94\u7528\u95ee\u9898\uff0c\u5728\u76f8\u5173\u6570\u636e\u96c6\u8fbeSOTA\uff0c\u5c55\u793a\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "EEG\u5927\u6a21\u578b\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u6807\u6ce8\u6570\u636e\u6709\u9650\u548c\u4e34\u5e8a\u573a\u666f\u6027\u80fd\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faNeuroDx - LM\u6a21\u578b\uff0c\u5305\u542b\u9009\u62e9\u6027\u65f6\u9891\u5d4c\u5165\u673a\u5236\u548c\u6e10\u8fdb\u7279\u5f81\u611f\u77e5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728CHB - MIT\u548c\u7cbe\u795e\u5206\u88c2\u75c7\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5728\u766b\u75eb\u548c\u7cbe\u795e\u5206\u88c2\u75c7\u68c0\u6d4b\u4e2d\u8fbe\u5230SOTA\u3002", "conclusion": "EEG\u5927\u6a21\u578b\u5728\u63a8\u8fdb\u4e34\u5e8a\u5e94\u7528\u65b9\u9762\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2508.08126", "pdf": "https://arxiv.org/pdf/2508.08126", "abs": "https://arxiv.org/abs/2508.08126", "authors": ["Hadi Khorsand", "Vahid Pourahmadi"], "title": "OFAL: An Oracle-Free Active Learning Framework", "categories": ["cs.LG"], "comment": null, "summary": "In the active learning paradigm, using an oracle to label data has always\nbeen a complex and expensive task, and with the emersion of large unlabeled\ndata pools, it would be highly beneficial If we could achieve better results\nwithout relying on an oracle. This research introduces OFAL, an oracle-free\nactive learning scheme that utilizes neural network uncertainty. OFAL uses the\nmodel's own uncertainty to transform highly confident unlabeled samples into\ninformative uncertain samples. First, we start with separating and quantifying\ndifferent parts of uncertainty and introduce Monte Carlo Dropouts as an\napproximation of the Bayesian Neural Network model. Secondly, by adding a\nvariational autoencoder, we go on to generate new uncertain samples by stepping\ntoward the uncertain part of latent space starting from a confidence seed\nsample. By generating these new informative samples, we can perform active\nlearning and enhance the model's accuracy. Lastly, we try to compare and\nintegrate our method with other widely used active learning sampling methods.", "AI": {"tldr": "\u4ecb\u7ecd\u4e00\u79cd\u65e0\u9700\u795e\u8c15\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6848OFAL\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u4e0d\u786e\u5b9a\u6027\u751f\u6210\u65b0\u6837\u672c\u63d0\u5347\u6a21\u578b\u51c6\u786e\u7387\uff0c\u5e76\u4e0e\u5176\u4ed6\u65b9\u6cd5\u6bd4\u8f83\u6574\u5408\u3002", "motivation": "\u5728\u4e3b\u52a8\u5b66\u4e60\u4e2d\uff0c\u4f7f\u7528\u795e\u8c15\u6807\u8bb0\u6570\u636e\u590d\u6742\u6602\u8d35\uff0c\u5e0c\u671b\u4e0d\u4f9d\u8d56\u795e\u8c15\u53d6\u5f97\u66f4\u597d\u7ed3\u679c\u3002", "method": "\u5f15\u5165OFAL\uff0c\u5206\u79bb\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u7528\u8499\u7279\u5361\u7f57Dropout\u8fd1\u4f3c\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u6dfb\u52a0\u53d8\u5206\u81ea\u7f16\u7801\u5668\u4ece\u7f6e\u4fe1\u79cd\u5b50\u6837\u672c\u5411\u6f5c\u5728\u7a7a\u95f4\u4e0d\u786e\u5b9a\u90e8\u5206\u751f\u6210\u65b0\u6837\u672c\uff0c\u6700\u540e\u4e0e\u5176\u4ed6\u65b9\u6cd5\u6bd4\u8f83\u6574\u5408\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2508.06956", "pdf": "https://arxiv.org/pdf/2508.06956", "abs": "https://arxiv.org/abs/2508.06956", "authors": ["Keqiang Guo", "Yuheng Zhong", "Xin Tong", "Jiangbin Lyu", "Rui Zhang"], "title": "Neural Beam Field for Spatial Beam RSRP Prediction", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "comment": "Keywords: Neural Beam Field, Multipath Conditional Power Profile,\n  Channel Knowledge Map, Beam-level RSRP, Transformer", "summary": "Accurately predicting beam-level reference signal received power (RSRP) is\nessential for beam management in dense multi-user wireless networks, yet\nchallenging due to high measurement overhead and fast channel variations. This\npaper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for\nefficient and interpretable spatial beam RSRP prediction. Central to our\napproach is the introduction of the Multi-path Conditional Power Profile\n(MCPP), which bridges site-specific multipath propagation with antenna/beam\nconfigurations via closed-form analytical modeling. We adopt a decoupled\n``blackbox-whitebox\" design: a Transformer-based deep neural network (DNN)\nlearns the MCPP from sparse user measurements and positions, while a\nphysics-inspired module analytically infers beam RSRP statistics. To improve\nconvergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC)\nstrategy that leverages ray-tracing priors and on-site calibration using RSRP\ndata. Extensive simulations results demonstrate that NBF significantly\noutperforms conventional table-based channel knowledge maps (CKMs) and pure\nblackbox DNNs in prediction accuracy, training efficiency, and generalization,\nwhile maintaining a compact model size. The proposed framework offers a\nscalable and physically grounded solution for intelligent beam management in\nnext-generation dense wireless networks.", "AI": {"tldr": "\u63d0\u51faNeural Beam Field (NBF)\u6846\u67b6\u7528\u4e8e\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u7a7a\u95f4\u6ce2\u675fRSRP\u9884\u6d4b\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u6ce2\u675f\u7ea7\u53c2\u8003\u4fe1\u53f7\u63a5\u6536\u529f\u7387\u5bf9\u5bc6\u96c6\u591a\u7528\u6237\u65e0\u7ebf\u7f51\u7edc\u7684\u6ce2\u675f\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56e0\u9ad8\u6d4b\u91cf\u5f00\u9500\u548c\u5feb\u901f\u4fe1\u9053\u53d8\u5316\u800c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165Multi - path Conditional Power Profile (MCPP)\uff0c\u91c7\u7528\u89e3\u8026\u7684\u201c\u9ed1\u76d2 - \u767d\u76d2\u201d\u8bbe\u8ba1\uff0c\u7528Transformer - \u57faDNN\u5b66\u4e60MCPP\uff0c\u7269\u7406\u542f\u53d1\u6a21\u5757\u63a8\u65ad\u6ce2\u675fRSRP\u7edf\u8ba1\uff0c\u8fd8\u5f15\u5165Pretrain - and - Calibrate (PaC)\u7b56\u7565\u3002", "result": "\u5e7f\u6cdb\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cNBF\u5728\u9884\u6d4b\u7cbe\u5ea6\u3001\u8bad\u7ec3\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u8868\u7684\u4fe1\u9053\u77e5\u8bc6\u5730\u56fe\u548c\u7eaf\u9ed1\u76d2DNN\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u7d27\u51d1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0b\u4e00\u4ee3\u5bc6\u96c6\u65e0\u7ebf\u7f51\u7edc\u7684\u667a\u80fd\u6ce2\u675f\u7ba1\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u57fa\u4e8e\u7269\u7406\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.08137", "pdf": "https://arxiv.org/pdf/2508.08137", "abs": "https://arxiv.org/abs/2508.08137", "authors": ["Pravallika Abbineni", "Saoud Aldowaish", "Colin Liechty", "Soroosh Noorzad", "Ali Ghazizadeh", "Morteza Fayazi"], "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Conducting a comprehensive literature review is crucial for advancing circuit\ndesign methodologies. However, the rapid influx of state-of-the-art research,\ninconsistent data representation, and the complexity of optimizing circuit\ndesign objectives make this task significantly challenging. In this paper, we\npropose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for\ncircuit design assistance that integrates a hybrid Retrieval-Augmented\nGeneration (RAG) framework with an adaptive vector database of circuit design\nresearch papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason +\nAct (ReAct) workflow for iterative reasoning, goal-setting, and multi-step\ninformation retrieval. It functions as a question-answering design assistant,\ncapable of interpreting complex queries and providing reasoned responses\ngrounded in circuit literature. Its multimodal capabilities enable processing\nof both textual and visual data, facilitating more efficient and comprehensive\nanalysis. The system dynamically adapts using intelligent search tools,\nautomated document retrieval from the internet, and real-time database updates.\nUnlike conventional approaches constrained by model context limits, MuaLLM\ndecouples retrieval from inference, enabling scalable reasoning over\narbitrarily large corpora. At the maximum context length supported by standard\nLLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining\nthe same accuracy. This allows rapid, no-human-in-the-loop database generation,\novercoming the bottleneck of simulation-based dataset creation for circuits. To\nevaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval\nand citation performance, and Reasoning-100 (Reas-100), focused on multistep\nreasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8%\naccuracy on Reas-100.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u7535\u8def\u8bbe\u8ba1\u8f85\u52a9\u7684\u5f00\u6e90\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bMuaLLM\uff0c\u5b83\u96c6\u6210\u6df7\u5408RAG\u6846\u67b6\u4e0e\u81ea\u9002\u5e94\u5411\u91cf\u6570\u636e\u5e93\uff0c\u6027\u80fd\u4f18\u4e14\u6210\u672c\u4f4e\uff0c\u8fd8\u5f15\u5165\u4e24\u4e2a\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u8fdb\u884c\u7535\u8def\u8bbe\u8ba1\u65b9\u6cd5\u5b66\u7684\u5168\u9762\u6587\u732e\u7efc\u8ff0\u9762\u4e34\u7814\u7a76\u6d8c\u5165\u5feb\u3001\u6570\u636e\u8868\u793a\u4e0d\u4e00\u81f4\u548c\u4f18\u5316\u76ee\u6807\u590d\u6742\u7b49\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u5de5\u5177\u8f85\u52a9\u3002", "method": "\u63d0\u51faMuaLLM\uff0c\u96c6\u6210\u6df7\u5408RAG\u6846\u67b6\u4e0e\u81ea\u9002\u5e94\u5411\u91cf\u6570\u636e\u5e93\uff0c\u91c7\u7528ReAct\u5de5\u4f5c\u6d41\uff0c\u5177\u5907\u591a\u6a21\u6001\u80fd\u529b\uff0c\u52a8\u6001\u81ea\u9002\u5e94\uff0c\u89e3\u8026\u68c0\u7d22\u548c\u63a8\u7406\u3002", "result": "\u5728\u6700\u5927\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\uff0cMuaLLM\u6210\u672c\u4f4e\u81f310\u500d\u4e14\u901f\u5ea6\u5feb1.6\u500d\uff0c\u51c6\u786e\u7387\u76f8\u540c\uff1b\u5728RAG - 250\u4e0a\u53ec\u56de\u7387\u8fbe90.1%\uff0c\u5728Reas - 100\u4e0a\u51c6\u786e\u7387\u8fbe86.8%\u3002", "conclusion": "MuaLLM\u80fd\u6709\u6548\u8f85\u52a9\u7535\u8def\u8bbe\u8ba1\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5b9e\u73b0\u5feb\u901f\u65e0\u4eba\u5de5\u5e72\u9884\u7684\u6570\u636e\u5e93\u751f\u6210\u3002"}}
{"id": "2508.06959", "pdf": "https://arxiv.org/pdf/2508.06959", "abs": "https://arxiv.org/abs/2508.06959", "authors": ["Qin Xu", "Lili Zhu", "Xiaoxia Cheng", "Bo Jiang"], "title": "Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The crux of resolving fine-grained visual classification (FGVC) lies in\ncapturing discriminative and class-specific cues that correspond to subtle\nvisual characteristics. Recently, frequency decomposition/transform based\napproaches have attracted considerable interests since its appearing\ndiscriminative cue mining ability. However, the frequency-domain methods are\nbased on fixed basis functions, lacking adaptability to image content and\nunable to dynamically adjust feature extraction according to the discriminative\nrequirements of different images. To address this, we propose a novel method\nfor FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively\nenhances the representational capability of low-level details and high-level\nsemantics in the spatial domain, breaking through the limitations of fixed\nscales in the frequency domain and improving the flexibility of multi-scale\nfusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor\n(SDE), which dynamically enhances subtle details such as edges and textures\nfrom shallow features, and the Salient Semantic Refiner (SSR), which learns\nsemantically coherent and structure-aware refinement features from the\nhigh-level features guided by the enhanced shallow features. The SDE and SSR\nare cascaded stage-by-stage to progressively combine local details with global\nsemantics. Extensive experiments demonstrate that our method achieves new\nstate-of-the-art on four popular fine-grained image classification benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u7684SCOPE\u65b9\u6cd5\uff0c\u542bSDE\u548cSSR\u6a21\u5757\uff0c\u5b9e\u9a8c\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u9891\u57df\u65b9\u6cd5\u57fa\u4e8e\u56fa\u5b9a\u57fa\u51fd\u6570\uff0c\u7f3a\u4e4f\u5bf9\u56fe\u50cf\u5185\u5bb9\u9002\u5e94\u6027\uff0c\u65e0\u6cd5\u6309\u9700\u52a8\u6001\u8c03\u6574\u7279\u5f81\u63d0\u53d6\u3002", "method": "\u63d0\u51faSCOPE\u65b9\u6cd5\uff0c\u542b\u52a8\u6001\u589e\u5f3a\u6d45\u5c42\u7279\u5f81\u7ec6\u8282\u7684SDE\u6a21\u5757\u548c\u5b66\u4e60\u9ad8\u5c42\u7279\u5f81\u7ec6\u5316\u7279\u5f81\u7684SSR\u6a21\u5757\uff0c\u4e8c\u8005\u7ea7\u8054\u7ed3\u5408\u5c40\u90e8\u7ec6\u8282\u4e0e\u5168\u5c40\u8bed\u4e49\u3002", "result": "\u5728\u56db\u4e2a\u6d41\u884c\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u8fbe\u5230\u65b0\u7684SOTA\u3002", "conclusion": "SCOPE\u65b9\u6cd5\u6709\u6548\u7a81\u7834\u9891\u57df\u56fa\u5b9a\u5c3a\u5ea6\u9650\u5236\uff0c\u63d0\u9ad8\u591a\u5c3a\u5ea6\u878d\u5408\u7075\u6d3b\u6027\u3002"}}
{"id": "2508.08159", "pdf": "https://arxiv.org/pdf/2508.08159", "abs": "https://arxiv.org/abs/2508.08159", "authors": ["Cem Ata Baykara", "Saurav Raj Pandey", "Ali Burak \u00dcnal", "Harlin Lee", "Mete Akg\u00fcn"], "title": "Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets", "categories": ["cs.LG"], "comment": null, "summary": "Developing accurate and generalizable epileptic seizure prediction models\nfrom electroencephalography (EEG) data across multiple clinical sites is\nhindered by patient privacy regulations and significant data heterogeneity\n(non-IID characteristics). Federated Learning (FL) offers a privacy-preserving\nframework for collaborative training, but standard aggregation methods like\nFederated Averaging (FedAvg) can be biased by dominant datasets in\nheterogeneous settings. This paper investigates FL for seizure prediction using\na single EEG channel across four diverse public datasets (Siena, CHB-MIT,\nHelsinki, NCH), representing distinct patient populations (adult, pediatric,\nneonate) and recording conditions. We implement privacy-preserving global\nnormalization and propose a Random Subset Aggregation strategy, where each\nclient trains on a fixed-size random subset of its data per round, ensuring\nequal contribution during aggregation. Our results show that locally trained\nmodels fail to generalize across sites, and standard weighted FedAvg yields\nhighly skewed performance (e.g., 89.0% accuracy on CHB-MIT but only 50.8% on\nHelsinki and 50.6% on NCH). In contrast, Random Subset Aggregation\nsignificantly improves performance on under-represented clients (accuracy\nincreases to 81.7% on Helsinki and 68.7% on NCH) and achieves a superior\nmacro-average accuracy of 77.1% and pooled accuracy of 80.0% across all sites,\ndemonstrating a more robust and fair global model. This work highlights the\npotential of balanced FL approaches for building effective and generalizable\nseizure prediction systems in realistic, heterogeneous multi-hospital\nenvironments while respecting data privacy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8de8\u591a\u4e34\u5e8a\u7ad9\u70b9\u7684\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u6a21\u578b\uff0c\u4f7f\u7528\u8054\u90a6\u5b66\u4e60\uff0c\u63d0\u51fa\u968f\u673a\u5b50\u96c6\u805a\u5408\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u6027\u3002", "motivation": "\u60a3\u8005\u9690\u79c1\u6cd5\u89c4\u548c\u6570\u636e\u5f02\u8d28\u6027\u963b\u788d\u8de8\u591a\u4e34\u5e8a\u7ad9\u70b9\u7684\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u6a21\u578b\u5f00\u53d1\uff0c\u6807\u51c6\u8054\u90a6\u5e73\u5747\u805a\u5408\u65b9\u6cd5\u5728\u5f02\u8d28\u73af\u5883\u4e2d\u6709\u504f\u5dee\u3002", "method": "\u5728\u56db\u4e2a\u4e0d\u540c\u516c\u5171\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u5355\u8111\u7535\u56fe\u901a\u9053\u8fdb\u884c\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\uff0c\u5b9e\u65bd\u9690\u79c1\u4fdd\u62a4\u5168\u5c40\u5f52\u4e00\u5316\uff0c\u63d0\u51fa\u968f\u673a\u5b50\u96c6\u805a\u5408\u7b56\u7565\u3002", "result": "\u672c\u5730\u8bad\u7ec3\u6a21\u578b\u65e0\u6cd5\u8de8\u7ad9\u70b9\u6cdb\u5316\uff0c\u6807\u51c6\u52a0\u6743\u8054\u90a6\u5e73\u5747\u6027\u80fd\u6709\u504f\u5dee\uff0c\u968f\u673a\u5b50\u96c6\u805a\u5408\u663e\u8457\u63d0\u5347\u8868\u73b0\u4e0d\u4f73\u5ba2\u6237\u7aef\u7684\u6027\u80fd\uff0c\u5b8f\u89c2\u5e73\u5747\u51c6\u786e\u7387\u8fbe77.1%\uff0c\u7efc\u5408\u51c6\u786e\u7387\u8fbe80.0%\u3002", "conclusion": "\u5e73\u8861\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u5c0a\u91cd\u6570\u636e\u9690\u79c1\u7684\u73b0\u5b9e\u5f02\u8d28\u591a\u533b\u9662\u73af\u5883\u4e2d\u6784\u5efa\u6709\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u7cfb\u7edf\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.06982", "pdf": "https://arxiv.org/pdf/2508.06982", "abs": "https://arxiv.org/abs/2508.06982", "authors": ["Yixin Zhu", "Zuoliang Zhu", "Milo\u0161 Ha\u0161an", "Jian Yang", "Jin Xie", "Beibei Wang"], "title": "WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Forward and inverse rendering have emerged as key techniques for enabling\nunderstanding and reconstruction in the context of autonomous driving (AD).\nHowever, complex weather and illumination pose great challenges to this task.\nThe emergence of large diffusion models has shown promise in achieving\nreasonable results through learning from 2D priors, but these models are\ndifficult to control and lack robustness. In this paper, we introduce\nWeatherDiffusion, a diffusion-based framework for forward and inverse rendering\non AD scenes with various weather and lighting conditions. Our method enables\nauthentic estimation of material properties, scene geometry, and lighting, and\nfurther supports controllable weather and illumination editing through the use\nof predicted intrinsic maps guided by text descriptions. We observe that\ndifferent intrinsic maps should correspond to different regions of the original\nimage. Based on this observation, we propose Intrinsic map-aware attention\n(MAA) to enable high-quality inverse rendering. Additionally, we introduce a\nsynthetic dataset (\\ie WeatherSynthetic) and a real-world dataset (\\ie\nWeatherReal) for forward and inverse rendering on AD scenes with diverse\nweather and lighting. Extensive experiments show that our WeatherDiffusion\noutperforms state-of-the-art methods on several benchmarks. Moreover, our\nmethod demonstrates significant value in downstream tasks for AD, enhancing the\nrobustness of object detection and image segmentation in challenging weather\nscenarios.", "AI": {"tldr": "\u63d0\u51faWeatherDiffusion\u6846\u67b6\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u7684\u6b63\u53cd\u6e32\u67d3\uff0c\u5f15\u5165\u65b0\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8eSOTA\u65b9\u6cd5\uff0c\u5bf9\u4e0b\u6e38\u4efb\u52a1\u6709\u4ef7\u503c\u3002", "motivation": "\u590d\u6742\u5929\u6c14\u548c\u5149\u7167\u7ed9\u81ea\u52a8\u9a7e\u9a76\u7684\u6b63\u53cd\u6e32\u67d3\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u5927\u6269\u6563\u6a21\u578b\u96be\u63a7\u5236\u4e14\u7f3a\u4e4f\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faWeatherDiffusion\u6846\u67b6\uff0c\u4f7f\u7528\u9884\u6d4b\u7684\u56fa\u6709\u56fe\u5b9e\u73b0\u53ef\u63a7\u7684\u5929\u6c14\u548c\u5149\u7167\u7f16\u8f91\uff0c\u63d0\u51fa\u56fa\u6709\u56fe\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5f15\u5165\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u3002", "result": "WeatherDiffusion\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6076\u52a3\u5929\u6c14\u573a\u666f\u4e0b\u76ee\u6807\u68c0\u6d4b\u548c\u56fe\u50cf\u5206\u5272\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "WeatherDiffusion\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\u590d\u6742\u5929\u6c14\u548c\u5149\u7167\u4e0b\u7684\u6b63\u53cd\u6e32\u67d3\u95ee\u9898\uff0c\u5bf9\u4e0b\u6e38\u4efb\u52a1\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2508.08172", "pdf": "https://arxiv.org/pdf/2508.08172", "abs": "https://arxiv.org/abs/2508.08172", "authors": ["Vincent Perreault", "Katsumi Inoue", "Richard Labib", "Alain Hertz"], "title": "Neural Logic Networks for Interpretable Classification", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "21 pages, 6 figures, pre-print", "summary": "Traditional neural networks have an impressive classification performance,\nbut what they learn cannot be inspected, verified or extracted. Neural Logic\nNetworks on the other hand have an interpretable structure that enables them to\nlearn a logical mechanism relating the inputs and outputs with AND and OR\noperations. We generalize these networks with NOT operations and biases that\ntake into account unobserved data and develop a rigorous logical and\nprobabilistic modeling in terms of concept combinations to motivate their use.\nWe also propose a novel factorized IF-THEN rule structure for the model as well\nas a modified learning algorithm. Our method improves the state-of-the-art in\nBoolean networks discovery and is able to learn relevant, interpretable rules\nin tabular classification, notably on an example from the medical field where\ninterpretability has tangible value.", "AI": {"tldr": "\u672c\u6587\u63a8\u5e7f\u542bNOT\u8fd0\u7b97\u548c\u504f\u7f6e\u7684\u795e\u7ecf\u903b\u8f91\u7f51\u7edc\uff0c\u63d0\u51fa\u65b0\u89c4\u5219\u7ed3\u6784\u548c\u5b66\u4e60\u7b97\u6cd5\uff0c\u63d0\u5347\u5e03\u5c14\u7f51\u7edc\u53d1\u73b0\u6c34\u5e73\uff0c\u80fd\u5b66\u4e60\u53ef\u89e3\u91ca\u89c4\u5219\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u5185\u5bb9\u4e0d\u53ef\u68c0\u67e5\u3001\u9a8c\u8bc1\u548c\u63d0\u53d6\uff0c\u800c\u795e\u7ecf\u903b\u8f91\u7f51\u7edc\u6709\u53ef\u89e3\u91ca\u7ed3\u6784\uff0c\u63a8\u5e7f\u5176\u542bNOT\u8fd0\u7b97\u548c\u504f\u7f6e\u4ee5\u8003\u8651\u672a\u89c2\u6d4b\u6570\u636e\u5e76\u8fdb\u884c\u4e25\u683c\u5efa\u6a21\u3002", "method": "\u63a8\u5e7f\u542bNOT\u8fd0\u7b97\u548c\u504f\u7f6e\u7684\u795e\u7ecf\u903b\u8f91\u7f51\u7edc\uff0c\u63d0\u51fa\u65b0\u9896\u7684\u56e0\u5f0f\u5206\u89e3IF - THEN\u89c4\u5219\u7ed3\u6784\u548c\u4fee\u6539\u540e\u7684\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u6539\u8fdb\u4e86\u5e03\u5c14\u7f51\u7edc\u53d1\u73b0\u7684\u73b0\u6709\u6c34\u5e73\uff0c\u80fd\u5728\u8868\u683c\u5206\u7c7b\u4e2d\u5b66\u4e60\u76f8\u5173\u3001\u53ef\u89e3\u91ca\u89c4\u5219\uff0c\u5728\u533b\u5b66\u9886\u57df\u793a\u4f8b\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u5e03\u5c14\u7f51\u7edc\u53d1\u73b0\u548c\u8868\u683c\u5206\u7c7b\u5b66\u4e60\u53ef\u89e3\u91ca\u89c4\u5219\u65b9\u9762\u6709\u6548\uff0c\u5728\u6709\u89e3\u91ca\u9700\u6c42\u7684\u9886\u57df\u6709\u4ef7\u503c\u3002"}}
{"id": "2508.08216", "pdf": "https://arxiv.org/pdf/2508.08216", "abs": "https://arxiv.org/abs/2508.08216", "authors": ["Nicole Lai-Tan", "Xiao Gu", "Marios G. Philiastides", "Fani Deligianni"], "title": "Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion", "categories": ["cs.LG", "eess.SP"], "comment": "12 pages, 5 figures", "summary": "Personalised music-based interventions offer a powerful means of supporting\nmotor rehabilitation by dynamically tailoring auditory stimuli to provide\nexternal timekeeping cues, modulate affective states, and stabilise gait\npatterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for\nadapting these interventions across individuals. However, inter-subject\nvariability in EEG signals, further compounded by movement-induced artefacts\nand motor planning differences, hinders the generalisability of BCIs and\nresults in lengthy calibration processes. We propose Individual Tangent Space\nAlignment (ITSA), a novel pre-alignment strategy incorporating subject-specific\nrecentering, distribution matching, and supervised rotational alignment to\nenhance cross-subject generalisation. Our hybrid architecture fuses Regularised\nCommon Spatial Patterns (RCSP) with Riemannian geometry in parallel and\nsequential configurations, improving class separability while maintaining the\ngeometric structure of covariance matrices for robust statistical computation.\nUsing leave-one-subject-out cross-validation, `ITSA' demonstrates significant\nperformance improvements across subjects and conditions. The parallel fusion\napproach shows the greatest enhancement over its sequential counterpart, with\nrobust performance maintained across varying data conditions and electrode\nconfigurations. The code will be made publicly available at the time of\npublication.", "AI": {"tldr": "\u63d0\u51faITSA\u7b56\u7565\u548c\u6df7\u5408\u67b6\u6784\u7528\u4e8e\u4e2a\u6027\u5316\u97f3\u4e50\u5e72\u9884\u7684BCI\uff0c\u63d0\u5347\u8de8\u4e3b\u4f53\u6cdb\u5316\u6027\u80fd\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u3002", "motivation": "\u4e2a\u6027\u5316\u97f3\u4e50\u5e72\u9884\u652f\u6301\u8fd0\u52a8\u5eb7\u590d\uff0c\u901a\u7528BCI\u6709\u5e94\u7528\u524d\u666f\uff0c\u4f46\u8111\u7535\u4fe1\u53f7\u4e2a\u4f53\u5dee\u5f02\u7b49\u963b\u788d\u5176\u6cdb\u5316\u4e14\u6821\u51c6\u8fc7\u7a0b\u957f\u3002", "method": "\u63d0\u51faITSA\u7b56\u7565\uff0c\u878d\u5408RCSP\u4e0e\u9ece\u66fc\u51e0\u4f55\u7684\u6df7\u5408\u67b6\u6784\u3002", "result": "ITSA\u5728\u8de8\u4e3b\u4f53\u548c\u6761\u4ef6\u4e0b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u5e76\u884c\u878d\u5408\u65b9\u6cd5\u6bd4\u987a\u5e8f\u65b9\u6cd5\u6548\u679c\u66f4\u597d\uff0c\u4e14\u5728\u4e0d\u540c\u6570\u636e\u6761\u4ef6\u548c\u7535\u6781\u914d\u7f6e\u4e0b\u6027\u80fd\u7a33\u5065\u3002", "conclusion": "ITSA\u548c\u6df7\u5408\u67b6\u6784\u80fd\u6709\u6548\u589e\u5f3aBCI\u8de8\u4e3b\u4f53\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.07001", "pdf": "https://arxiv.org/pdf/2508.07001", "abs": "https://arxiv.org/abs/2508.07001", "authors": ["Myeung Suk Oh", "Zhiyao Zhang", "FNU Hairi", "Alvaro Velasquez", "Jia Liu"], "title": "Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": "This paper has been accepted in ACM International Symposium on\n  Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and\n  Mobile Computing (MobiHoc) 2025", "summary": "With wireless devices increasingly forming a unified smart network for\nseamless, user-friendly operations, random access (RA) medium access control\n(MAC) design is considered a key solution for handling unpredictable data\ntraffic from multiple terminals. However, it remains challenging to design an\neffective RA-based MAC protocol to minimize collisions and ensure transmission\nfairness across the devices. While existing multi-agent reinforcement learning\n(MARL) approaches with centralized training and decentralized execution (CTDE)\nhave been proposed to optimize RA performance, their reliance on centralized\ntraining and the significant overhead required for information collection can\nmake real-world applications unrealistic. In this work, we adopt a fully\ndecentralized MARL architecture, where policy learning does not rely on\ncentralized tasks but leverages consensus-based information exchanges across\ndevices. We design our MARL algorithm over an actor-critic (AC) network and\npropose exchanging only local rewards to minimize communication overhead.\nFurthermore, we provide a theoretical proof of global convergence for our\napproach. Numerical experiments show that our proposed MARL algorithm can\nsignificantly improve RA network performance compared to other baselines.", "AI": {"tldr": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5904\u7406\u968f\u673a\u63a5\u5165\u6709\u5c40\u9650\uff0c\u672c\u6587\u91c7\u7528\u5168\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u8bc1\u660e\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u968f\u673a\u63a5\u5165\u7684MAC\u534f\u8bae\u96be\u4ee5\u51cf\u5c11\u51b2\u7a81\u548c\u4fdd\u8bc1\u516c\u5e73\u6027\uff0c\u4e14\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u96c6\u4e2d\u8bad\u7ec3\u65b9\u5f0f\u4e0d\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u5168\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\uff0c\u57fa\u4e8e\u6f14\u5458 - \u8bc4\u8bba\u5bb6\u7f51\u7edc\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u4ec5\u4ea4\u6362\u672c\u5730\u5956\u52b1\u4ee5\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u7ed9\u51fa\u5168\u5c40\u6536\u655b\u6027\u7684\u7406\u8bba\u8bc1\u660e\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u5176\u4ed6\u57fa\u7ebf\uff0c\u6240\u63d0\u7b97\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u968f\u673a\u63a5\u5165\u7f51\u7edc\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u5168\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u968f\u673a\u63a5\u5165\u7f51\u7edc\u6027\u80fd\u4f18\u5316\u4e0a\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2508.08221", "pdf": "https://arxiv.org/pdf/2508.08221", "abs": "https://arxiv.org/abs/2508.08221", "authors": ["Zihe Liu", "Jiashun Liu", "Yancheng He", "Weixun Wang", "Jiaheng Liu", "Ling Pan", "Xinyu Hu", "Shaopan Xiong", "Ju Huang", "Jian Hu", "Shengyi Huang", "Siran Yang", "Jiamang Wang", "Wenbo Su", "Bo Zheng"], "title": "Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": "26 pages, 21 figures", "summary": "Reinforcement learning for LLM reasoning has rapidly emerged as a prominent\nresearch area, marked by a significant surge in related studies on both\nalgorithmic innovations and practical applications. Despite this progress,\nseveral critical challenges remain, including the absence of standardized\nguidelines for employing RL techniques and a fragmented understanding of their\nunderlying mechanisms. Additionally, inconsistent experimental settings,\nvariations in training data, and differences in model initialization have led\nto conflicting conclusions, obscuring the key characteristics of these\ntechniques and creating confusion among practitioners when selecting\nappropriate techniques. This paper systematically reviews widely adopted RL\ntechniques through rigorous reproductions and isolated evaluations within a\nunified open-source framework. We analyze the internal mechanisms, applicable\nscenarios, and core principles of each technique through fine-grained\nexperiments, including datasets of varying difficulty, model sizes, and\narchitectures. Based on these insights, we present clear guidelines for\nselecting RL techniques tailored to specific setups, and provide a reliable\nroadmap for practitioners navigating the RL for the LLM domain. Finally, we\nreveal that a minimalist combination of two techniques can unlock the learning\ncapability of critic-free policies using vanilla PPO loss. The results\ndemonstrate that our simple combination consistently improves performance,\nsurpassing strategies like GRPO and DAPO.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u56de\u987e\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff0c\u5206\u6790\u5176\u673a\u5236\u4e0e\u9002\u7528\u573a\u666f\uff0c\u7ed9\u51fa\u9009\u62e9\u6307\u5357\uff0c\u53d1\u73b0\u4e24\u79cd\u6280\u672f\u7684\u7b80\u5355\u7ec4\u5408\u53ef\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u6307\u5357\uff0c\u5bf9\u5e95\u5c42\u673a\u5236\u7406\u89e3\u5206\u6563\uff0c\u5b9e\u9a8c\u8bbe\u7f6e\u7b49\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7ed3\u8bba\u51b2\u7a81\u3002", "method": "\u5728\u7edf\u4e00\u5f00\u6e90\u6846\u67b6\u4e0b\u8fdb\u884c\u4e25\u683c\u590d\u73b0\u548c\u72ec\u7acb\u8bc4\u4f30\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5b9e\u9a8c\u5206\u6790\u6280\u672f\u3002", "result": "\u63d0\u51fa\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u9009\u62e9\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u7684\u660e\u786e\u6307\u5357\uff0c\u4e24\u79cd\u6280\u672f\u7684\u7b80\u5355\u7ec4\u5408\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u8d85\u8d8aGRPO\u548cDAPO\u7b49\u7b56\u7565\u3002", "conclusion": "\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u9886\u57df\u5f3a\u5316\u5b66\u4e60\u4ece\u4e1a\u8005\u63d0\u4f9b\u53ef\u9760\u8def\u7ebf\u56fe\uff0c\u8bc1\u660e\u7b80\u5355\u6280\u672f\u7ec4\u5408\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.07009", "pdf": "https://arxiv.org/pdf/2508.07009", "abs": "https://arxiv.org/abs/2508.07009", "authors": ["Xintong Chen", "Zhenyu Jiang", "Jiangbin Lyu", "Liqun Fu"], "title": "Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "comment": "Propose Neural Channel Knowledge Map for multi-user scheduling", "summary": "Intelligent Reflecting Surfaces (IRSs) have potential for significant\nperformance gains in next-generation wireless networks but face key challenges,\nnotably severe double-pathloss and complex multi-user scheduling due to\nhardware constraints. Active IRSs partially address pathloss but still require\nefficient scheduling in cell-level multi-IRS multi-user systems, whereby the\noverhead/delay of channel state acquisition and the scheduling complexity both\nrise dramatically as the user density and channel dimensions increase.\nMotivated by these challenges, this paper proposes a novel scheduling framework\nbased on neural Channel Knowledge Map (CKM), designing Transformer-based deep\nneural networks (DNNs) to predict ergodic spectral efficiency (SE) from\nhistorical channel/throughput measurements tagged with user positions.\nSpecifically, two cascaded networks, LPS-Net and SE-Net, are designed to\npredict link power statistics (LPS) and ergodic SE accurately. We further\npropose a low-complexity Stable Matching-Iterative Balancing (SM-IB) scheduling\nalgorithm. Numerical evaluations verify that the proposed neural CKM\nsignificantly enhances prediction accuracy and computational efficiency, while\nthe SM-IB algorithm effectively achieves near-optimal max-min throughput with\ngreatly reduced complexity.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u667a\u80fd\u53cd\u5c04\u9762\uff08IRS\uff09\u5728\u591a\u7528\u6237\u7cfb\u7edf\u4e2d\u7684\u8c03\u5ea6\u6311\u6218\uff0c\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u4fe1\u9053\u77e5\u8bc6\u56fe\uff08CKM\uff09\u7684\u8c03\u5ea6\u6846\u67b6\u548c\u4f4e\u590d\u6742\u5ea6\u8c03\u5ea6\u7b97\u6cd5\uff0c\u7ecf\u8bc4\u4f30\u53ef\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "motivation": "IRS\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u6709\u6027\u80fd\u63d0\u5347\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u53cc\u8def\u5f84\u635f\u8017\u548c\u590d\u6742\u591a\u7528\u6237\u8c03\u5ea6\u6311\u6218\uff0c\u4e3b\u52a8IRS\u867d\u90e8\u5206\u89e3\u51b3\u8def\u5f84\u635f\u8017\uff0c\u4f46\u591aIRS\u591a\u7528\u6237\u7cfb\u7edf\u4ecd\u9700\u9ad8\u6548\u8c03\u5ea6\uff0c\u4e14\u968f\u7740\u7528\u6237\u5bc6\u5ea6\u548c\u4fe1\u9053\u7ef4\u5ea6\u589e\u52a0\uff0c\u4fe1\u9053\u72b6\u6001\u83b7\u53d6\u5f00\u9500/\u5ef6\u8fdf\u548c\u8c03\u5ea6\u590d\u6742\u5ea6\u5267\u589e\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u4fe1\u9053\u77e5\u8bc6\u56fe\uff08CKM\uff09\u7684\u8c03\u5ea6\u6846\u67b6\uff0c\u8bbe\u8ba1\u57fa\u4e8eTransformer\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNNs\uff09\uff0c\u901a\u8fc7\u4e24\u4e2a\u7ea7\u8054\u7f51\u7edcLPS - Net\u548cSE - Net\u5206\u522b\u9884\u6d4b\u94fe\u8def\u529f\u7387\u7edf\u8ba1\uff08LPS\uff09\u548c\u904d\u5386\u9891\u8c31\u6548\u7387\uff08SE\uff09\uff0c\u8fd8\u63d0\u51fa\u4f4e\u590d\u6742\u5ea6\u7684\u7a33\u5b9a\u5339\u914d - \u8fed\u4ee3\u5e73\u8861\uff08SM - IB\uff09\u8c03\u5ea6\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u8bc4\u4f30\u8868\u660e\uff0c\u795e\u7ecfCKM\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0cSM - IB\u7b97\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u6700\u5927\u6700\u5c0f\u541e\u5410\u91cf\uff0c\u4e14\u590d\u6742\u5ea6\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u795e\u7ecfCKM\u7684\u8c03\u5ea6\u6846\u67b6\u548cSM - IB\u8c03\u5ea6\u7b97\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9IRS\u5728\u591a\u7528\u6237\u7cfb\u7edf\u4e2d\u7684\u8c03\u5ea6\u6311\u6218\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.07014", "pdf": "https://arxiv.org/pdf/2508.07014", "abs": "https://arxiv.org/abs/2508.07014", "authors": ["Andrei Andrusenko", "Vladimir Bataev", "Lilit Grigoryan", "Vitaly Lavrukhin", "Boris Ginsburg"], "title": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "comment": "Accepted by ASRU 2025", "summary": "Recognizing specific key phrases is an essential task for contextualized\nAutomatic Speech Recognition (ASR). However, most existing context-biasing\napproaches have limitations associated with the necessity of additional model\ntraining, significantly slow down the decoding process, or constrain the choice\nof the ASR system type. This paper proposes a universal ASR context-biasing\nframework that supports all major types: CTC, Transducers, and Attention\nEncoder-Decoder models. The framework is based on a GPU-accelerated word\nboosting tree, which enables it to be used in shallow fusion mode for greedy\nand beam search decoding without noticeable speed degradation, even with a vast\nnumber of key phrases (up to 20K items). The obtained results showed high\nefficiency of the proposed method, surpassing the considered open-source\ncontext-biasing approaches in accuracy and decoding speed. Our context-biasing\nframework is open-sourced as a part of the NeMo toolkit.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u7528ASR\u4e0a\u4e0b\u6587\u504f\u7f6e\u6846\u67b6\uff0c\u57fa\u4e8eGPU\u52a0\u901f\u8bcd\u63d0\u5347\u6811\uff0c\u9ad8\u6548\u4e14\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u504f\u7f6e\u65b9\u6cd5\u5b58\u5728\u9700\u989d\u5916\u6a21\u578b\u8bad\u7ec3\u3001\u89e3\u7801\u6162\u3001\u9650\u5236ASR\u7cfb\u7edf\u7c7b\u578b\u7b49\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eGPU\u52a0\u901f\u8bcd\u63d0\u5347\u6811\u7684\u901a\u7528ASR\u4e0a\u4e0b\u6587\u504f\u7f6e\u6846\u67b6\uff0c\u652f\u6301\u4e3b\u8981\u6a21\u578b\u7c7b\u578b\uff0c\u53ef\u7528\u4e8e\u6d45\u878d\u5408\u6a21\u5f0f\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u6548\u7387\u9ad8\uff0c\u5728\u51c6\u786e\u6027\u548c\u89e3\u7801\u901f\u5ea6\u4e0a\u8d85\u8d8a\u5f00\u6e90\u4e0a\u4e0b\u6587\u504f\u7f6e\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u4e0a\u4e0b\u6587\u504f\u7f6e\u6846\u67b6\u5177\u6709\u4f18\u52bf\uff0c\u5df2\u4f5c\u4e3aNeMo\u5de5\u5177\u5305\u4e00\u90e8\u5206\u5f00\u6e90\u3002"}}
{"id": "2508.07027", "pdf": "https://arxiv.org/pdf/2508.07027", "abs": "https://arxiv.org/abs/2508.07027", "authors": ["Catherine Mason"], "title": "Making Effective Decisions: Machine Learning and the Ecogame in 1970", "categories": ["cs.CY", "cs.AI"], "comment": "In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts\n  2025) arXiv:2406.14485", "summary": "This paper considers Ecogame, an innovative art project of 1970, whose\ncreators believed in a positive vision of a technological future; an\nunderstanding, posited on cybernetics, of a future that could be participatory\nvia digital means, and therefore more democratised. Using simulation and early\nmachine learning techniques over a live network, Ecogame combined the power of\nvisual art with cybernetic concepts of adaptation, feedback, and control to\npropose that behaviour had implications for the total system. It provides an\nhistorical precedent for contemporary AI-driven art about using AI in a more\nhuman-centred way.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd1970\u5e74\u521b\u65b0\u827a\u672f\u9879\u76eeEcogame\uff0c\u7ed3\u5408\u89c6\u89c9\u827a\u672f\u4e0e\u63a7\u5236\u8bba\u6982\u5ff5\uff0c\u4e3a\u5f53\u4ee3\u4ee5\u4eba\u7c7b\u4e3a\u4e2d\u5fc3\u4f7f\u7528AI\u7684\u827a\u672f\u63d0\u4f9b\u5386\u53f2\u5148\u4f8b\u3002", "motivation": "\u4ecb\u7ecdEcogame\u9879\u76ee\u5e76\u63a2\u8ba8\u5176\u5bf9\u5f53\u4ee3AI\u9a71\u52a8\u827a\u672f\u7684\u610f\u4e49\u3002", "method": "\u8fd0\u7528\u6a21\u62df\u548c\u65e9\u671f\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u7ed3\u5408\u89c6\u89c9\u827a\u672f\u4e0e\u63a7\u5236\u8bba\u6982\u5ff5\u3002", "result": "\u63d0\u51fa\u884c\u4e3a\u5bf9\u6574\u4e2a\u7cfb\u7edf\u6709\u5f71\u54cd\uff0c\u4e3a\u5f53\u4ee3AI\u9a71\u52a8\u827a\u672f\u63d0\u4f9b\u5386\u53f2\u5148\u4f8b\u3002", "conclusion": "Ecogame\u4e3a\u4ee5\u66f4\u4eba\u6027\u5316\u65b9\u5f0f\u4f7f\u7528AI\u7684\u5f53\u4ee3\u827a\u672f\u63d0\u4f9b\u4e86\u5386\u53f2\u4f9d\u636e\u3002"}}
{"id": "2508.06513", "pdf": "https://arxiv.org/pdf/2508.06513", "abs": "https://arxiv.org/abs/2508.06513", "authors": ["Chaeyeon Han", "Seung Jae Lieu", "Uijeong Hwang", "Subhrajit Guhathakurta"], "title": "Do Streetscapes Still Matter for Customer Ratings of Eating and Drinking Establishments in Car-Dependent Cities?", "categories": ["physics.soc-ph", "cs.CY", "cs.LG"], "comment": "Soon to be published in Journal of Urban Design", "summary": "This study examines how indoor and outdoor aesthetics, streetscapes, and\nneighborhood features shape customer satisfaction at eating and dining\nestablishments (EDEs) across different urban contexts, varying in car\ndependency, in Washington, DC. Using review photos and street view images,\ncomputer vision models quantified perceived safety and visual appeal. Ordinal\nlogistic regression analyzed their effects on Yelp ratings. Findings reveal\nthat both indoor and outdoor environments significantly impact EDE ratings,\nwhile streetscape quality's influence diminishes in car-dependent areas. The\nstudy highlights the need for context-sensitive planning that integrates indoor\nand outdoor factors to enhance customer experiences in diverse settings.", "AI": {"tldr": "\u7814\u7a76\u534e\u76db\u987f\u7279\u533a\u4e0d\u540c\u6c7d\u8f66\u4f9d\u8d56\u7a0b\u5ea6\u57ce\u5e02\u73af\u5883\u4e2d\uff0c\u5ba4\u5185\u5916\u7f8e\u5b66\u3001\u8857\u666f\u548c\u793e\u533a\u7279\u5f81\u5bf9\u9910\u996e\u573a\u6240\u987e\u5ba2\u6ee1\u610f\u5ea6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5ba4\u5185\u5916\u73af\u5883\u5747\u663e\u8457\u5f71\u54cd\u8bc4\u5206\uff0c\u8857\u666f\u8d28\u91cf\u5728\u6c7d\u8f66\u4f9d\u8d56\u533a\u5f71\u54cd\u51cf\u5f31\uff0c\u5f3a\u8c03\u56e0\u5730\u5236\u5b9c\u89c4\u5212\u3002", "motivation": "\u63a2\u7a76\u4e0d\u540c\u57ce\u5e02\u73af\u5883\u4e2d\uff0c\u5ba4\u5185\u5916\u7f8e\u5b66\u3001\u8857\u666f\u548c\u793e\u533a\u7279\u5f81\u5982\u4f55\u5851\u9020\u9910\u996e\u573a\u6240\u7684\u987e\u5ba2\u6ee1\u610f\u5ea6\u3002", "method": "\u5229\u7528\u70b9\u8bc4\u7167\u7247\u548c\u8857\u666f\u56fe\u50cf\uff0c\u901a\u8fc7\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u91cf\u5316\u611f\u77e5\u5b89\u5168\u548c\u89c6\u89c9\u5438\u5f15\u529b\uff0c\u7528\u6709\u5e8f\u903b\u8f91\u56de\u5f52\u5206\u6790\u5176\u5bf9Yelp\u8bc4\u5206\u7684\u5f71\u54cd\u3002", "result": "\u5ba4\u5185\u5916\u73af\u5883\u5747\u663e\u8457\u5f71\u54cd\u9910\u996e\u573a\u6240\u8bc4\u5206\uff0c\u8857\u666f\u8d28\u91cf\u5728\u6c7d\u8f66\u4f9d\u8d56\u533a\u7684\u5f71\u54cd\u51cf\u5f31\u3002", "conclusion": "\u9700\u8981\u8fdb\u884c\u56e0\u5730\u5236\u5b9c\u7684\u89c4\u5212\uff0c\u6574\u5408\u5ba4\u5185\u5916\u56e0\u7d20\u4ee5\u63d0\u5347\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u987e\u5ba2\u4f53\u9a8c\u3002"}}
{"id": "2508.07031", "pdf": "https://arxiv.org/pdf/2508.07031", "abs": "https://arxiv.org/abs/2508.07031", "authors": ["Anindya Bijoy Das", "Shahnewaz Karim Sakib", "Shibbir Ahmed"], "title": "Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied to medical imaging\ntasks, including image interpretation and synthetic image generation. However,\nthese models often produce hallucinations, which are confident but incorrect\noutputs that can mislead clinical decisions. This study examines hallucinations\nin two directions: image to text, where LLMs generate reports from X-ray, CT,\nor MRI scans, and text to image, where models create medical images from\nclinical prompts. We analyze errors such as factual inconsistencies and\nanatomical inaccuracies, evaluating outputs using expert informed criteria\nacross imaging modalities. Our findings reveal common patterns of hallucination\nin both interpretive and generative tasks, with implications for clinical\nreliability. We also discuss factors contributing to these failures, including\nmodel architecture and training data. By systematically studying both image\nunderstanding and generation, this work provides insights into improving the\nsafety and trustworthiness of LLM driven medical imaging systems.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u5f71\u50cf\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5206\u6790\u56fe\u50cf\u5230\u6587\u672c\u548c\u6587\u672c\u5230\u56fe\u50cf\u4e24\u4e2a\u65b9\u5411\uff0c\u63ed\u793a\u5e38\u89c1\u5e7b\u89c9\u6a21\u5f0f\u5e76\u8ba8\u8bba\u5f71\u54cd\u56e0\u7d20\uff0c\u4e3a\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u5f71\u50cf\u4efb\u52a1\u4e2d\u5e38\u4ea7\u751f\u8bef\u5bfc\u4e34\u5e8a\u51b3\u7b56\u7684\u5e7b\u89c9\uff0c\u9700\u5bf9\u5176\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u4ece\u56fe\u50cf\u5230\u6587\u672c\u548c\u6587\u672c\u5230\u56fe\u50cf\u4e24\u4e2a\u65b9\u5411\u5206\u6790\uff0c\u901a\u8fc7\u4e13\u5bb6\u6807\u51c6\u8bc4\u4f30\u4e0d\u540c\u6210\u50cf\u65b9\u5f0f\u7684\u8f93\u51fa\uff0c\u5206\u6790\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u548c\u89e3\u5256\u5b66\u4e0d\u51c6\u786e\u7b49\u9519\u8bef\u3002", "result": "\u63ed\u793a\u4e86\u89e3\u91ca\u6027\u548c\u751f\u6210\u6027\u4efb\u52a1\u4e2d\u5e38\u89c1\u7684\u5e7b\u89c9\u6a21\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u7814\u7a76\u56fe\u50cf\u7406\u89e3\u548c\u751f\u6210\uff0c\u4e3a\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u533b\u5b66\u5f71\u50cf\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2508.06529", "pdf": "https://arxiv.org/pdf/2508.06529", "abs": "https://arxiv.org/abs/2508.06529", "authors": ["Jiayuan Wang", "Q. M. Jonathan Wu", "Katsuya Suto", "Ning Zhang"], "title": "RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Autonomous driving systems rely on panoptic driving perception that requires\nboth precision and real-time performance. In this work, we propose RMT-PPAD, a\nreal-time, transformer-based multi-task model that jointly performs object\ndetection, drivable area segmentation, and lane line segmentation. We introduce\na lightweight module, a gate control with an adapter to adaptively fuse shared\nand task-specific features, effectively alleviating negative transfer between\ntasks. Additionally, we design an adaptive segmentation decoder to learn the\nweights over multi-scale features automatically during the training stage. This\navoids the manual design of task-specific structures for different segmentation\ntasks. We also identify and resolve the inconsistency between training and\ntesting labels in lane line segmentation. This allows fairer evaluation.\nExperiments on the BDD100K dataset demonstrate that RMT-PPAD achieves\nstate-of-the-art results with mAP50 of 84.9% and Recall of 95.4% for object\ndetection, mIoU of 92.6% for drivable area segmentation, and IoU of 56.8% and\naccuracy of 84.7% for lane line segmentation. The inference speed reaches 32.6\nFPS. Moreover, we introduce real-world scenarios to evaluate RMT-PPAD\nperformance in practice. The results show that RMT-PPAD consistently delivers\nstable performance. The source codes and pre-trained models are released at\nhttps://github.com/JiayuanWang-JW/RMT-PPAD.", "AI": {"tldr": "\u63d0\u51fa\u5b9e\u65f6\u591a\u4efb\u52a1\u6a21\u578bRMT - PPAD\u8fdb\u884c\u5168\u666f\u9a7e\u9a76\u611f\u77e5\uff0c\u5728BDD100K\u6570\u636e\u96c6\u5b9e\u9a8c\u6548\u679c\u597d\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u9700\u8981\u517c\u5177\u7cbe\u5ea6\u548c\u5b9e\u65f6\u6027\u7684\u5168\u666f\u9a7e\u9a76\u611f\u77e5\u3002", "method": "\u63d0\u51faRMT - PPAD\u6a21\u578b\uff0c\u5f15\u5165\u8f7b\u91cf\u7ea7\u6a21\u5757\u81ea\u9002\u5e94\u878d\u5408\u7279\u5f81\uff0c\u8bbe\u8ba1\u81ea\u9002\u5e94\u5206\u5272\u89e3\u7801\u5668\uff0c\u89e3\u51b3\u8f66\u9053\u7ebf\u5206\u5272\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6807\u7b7e\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "result": "\u5728BDD100K\u6570\u636e\u96c6\u4e0a\u5404\u4efb\u52a1\u53d6\u5f97\u5148\u8fdb\u7ed3\u679c\uff0c\u63a8\u7406\u901f\u5ea6\u8fbe32.6 FPS\uff0c\u5728\u771f\u5b9e\u573a\u666f\u6027\u80fd\u7a33\u5b9a\u3002", "conclusion": "RMT - PPAD\u6a21\u578b\u80fd\u6709\u6548\u7528\u4e8e\u5168\u666f\u9a7e\u9a76\u611f\u77e5\uff0c\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2508.07048", "pdf": "https://arxiv.org/pdf/2508.07048", "abs": "https://arxiv.org/abs/2508.07048", "authors": ["Taeyoun Kwon", "Junhyuk Ahn", "Taegeun Yun", "Heeju Jwa", "Yoonchae Choi", "Siwon Park", "Nam-Joon Kim", "Jangchan Kim", "Hyun Gon Ryu", "Hyuk-Jae Lee"], "title": "Whisfusion: Parallel ASR Decoding via a Diffusion Transformer", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "16 pages, 9 figures", "summary": "Fast Automatic Speech Recognition (ASR) is critical for latency-sensitive\napplications such as real-time captioning and meeting transcription. However,\ntruly parallel ASR decoding remains challenging due to the sequential nature of\nautoregressive (AR) decoders and the context limitations of non-autoregressive\n(NAR) methods. While modern ASR encoders can process up to 30 seconds of audio\nat once, AR decoders still generate tokens sequentially, creating a latency\nbottleneck. We propose Whisfusion, the first framework to fuse a pre-trained\nWhisper encoder with a text diffusion decoder. This NAR architecture resolves\nthe AR latency bottleneck by processing the entire acoustic context in parallel\nat every decoding step. A lightweight cross-attention adapter trained via\nparameter-efficient fine-tuning (PEFT) bridges the two modalities. We also\nintroduce a batch-parallel, multi-step decoding strategy that improves accuracy\nby increasing the number of candidates with minimal impact on speed. Fine-tuned\nsolely on LibriSpeech (960h), Whisfusion achieves a lower WER than Whisper-tiny\n(8.3% vs. 9.7%), and offers comparable latency on short audio. For longer\nutterances (>20s), it is up to 2.6x faster than the AR baseline, establishing a\nnew, efficient operating point for long-form ASR. The implementation and\ntraining scripts are available at https://github.com/taeyoun811/Whisfusion.", "AI": {"tldr": "\u63d0\u51faWhisfusion\u6846\u67b6\u878d\u5408Whisper\u7f16\u7801\u5668\u4e0e\u6587\u672c\u6269\u6563\u89e3\u7801\u5668\uff0c\u89e3\u51b3AR\u89e3\u7801\u5ef6\u8fdf\u74f6\u9888\uff0c\u5728\u957f\u97f3\u9891\u4e0a\u6709\u901f\u5ea6\u4f18\u52bf\u3002", "motivation": "\u5feb\u901f\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u5bf9\u4f4e\u5ef6\u8fdf\u5e94\u7528\u5f88\u5173\u952e\uff0c\u4f46\u771f\u6b63\u7684\u5e76\u884cASR\u89e3\u7801\u56e0AR\u89e3\u7801\u5668\u7684\u987a\u5e8f\u6027\u548cNAR\u65b9\u6cd5\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u800c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faWhisfusion\u6846\u67b6\uff0c\u878d\u5408\u9884\u8bad\u7ec3\u7684Whisper\u7f16\u7801\u5668\u4e0e\u6587\u672c\u6269\u6563\u89e3\u7801\u5668\uff0c\u7528\u8f7b\u91cf\u7ea7\u8de8\u6ce8\u610f\u529b\u9002\u914d\u5668\u8fde\u63a5\u4e24\u79cd\u6a21\u6001\uff0c\u5f15\u5165\u6279\u5e76\u884c\u3001\u591a\u6b65\u89e3\u7801\u7b56\u7565\u3002", "result": "\u4ec5\u5728LibriSpeech\u4e0a\u5fae\u8c03\uff0cWhisfusion\u7684WER\u4f4e\u4e8eWhisper - tiny\uff0c\u77ed\u97f3\u9891\u5ef6\u8fdf\u76f8\u5f53\uff0c\u957f\u97f3\u9891\u6bd4AR\u57fa\u7ebf\u5feb\u8fbe2.6\u500d\u3002", "conclusion": "Whisfusion\u4e3a\u957f\u683c\u5f0fASR\u5efa\u7acb\u4e86\u65b0\u7684\u9ad8\u6548\u64cd\u4f5c\u70b9\u3002"}}
{"id": "2508.06530", "pdf": "https://arxiv.org/pdf/2508.06530", "abs": "https://arxiv.org/abs/2508.06530", "authors": ["Ming-Kun Xie", "Jia-Hao Xiao", "Gang Niu", "Lei Feng", "Zhiqiang Kou", "Min-Ling Zhang", "Masashi Sugiyama"], "title": "What Makes \"Good\" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large Vision-Language Models (LVLMs), empowered by the success of Large\nLanguage Models (LLMs), have achieved impressive performance across domains.\nDespite the great advances in LVLMs, they still suffer from the unavailable\nobject hallucination issue, which tends to generate objects inconsistent with\nthe image content. The most commonly used Polling-based Object Probing\nEvaluation (POPE) benchmark evaluates this issue by sampling negative\ncategories according to category-level statistics, \\textit{e.g.}, category\nfrequencies and co-occurrence. However, with the continuous advancement of\nLVLMs, the POPE benchmark has shown diminishing effectiveness in assessing\nobject hallucination, as it employs a simplistic sampling strategy that\noverlooks image-specific information and restricts distractors to negative\nobject categories only. In this paper, we introduce the Hallucination\nsearching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate\nthe most misleading distractors (\\textit{i.e.}, non-existent objects or\nincorrect image descriptions) that can trigger hallucination in LVLMs, which\nserves as a means to more rigorously assess their immunity to hallucination. To\nexplore the image-specific information, the content-aware hallucination\nsearching leverages Contrastive Language-Image Pre-Training (CLIP) to\napproximate the predictive behavior of LVLMs by selecting negative objects with\nthe highest predicted likelihood as distractors. To expand the scope of\nhallucination assessment, the description-based hallucination searching\nconstructs highly misleading distractors by pairing true objects with false\ndescriptions. Experimental results show that HOPE leads to a precision drop of\nat least 9\\% and up to 23\\% across various state-of-the-art LVLMs,\nsignificantly outperforming POPE in exposing hallucination vulnerabilities. The\ncode is available at https://github.com/xiemk/HOPE.", "AI": {"tldr": "\u73b0\u6709\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5b58\u5728\u7269\u4f53\u5e7b\u89c9\u95ee\u9898\uff0c\u5e38\u7528\u7684POPE\u57fa\u51c6\u8bc4\u4f30\u6548\u679c\u6e10\u5f31\uff0c\u672c\u6587\u63d0\u51faHOPE\u57fa\u51c6\uff0c\u5b9e\u9a8c\u663e\u793a\u5b83\u80fd\u66f4\u597d\u66b4\u9732\u6a21\u578b\u5e7b\u89c9\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709POPE\u57fa\u51c6\u5728\u8bc4\u4f30LVLMs\u7269\u4f53\u5e7b\u89c9\u95ee\u9898\u4e0a\u6548\u679c\u6e10\u5f31\uff0c\u9700\u65b0\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165Hallucination searching - based Object Probing Evaluation (HOPE) \u57fa\u51c6\uff0c\u5229\u7528CLIP\u8fdb\u884c\u5185\u5bb9\u611f\u77e5\u5e7b\u89c9\u641c\u7d22\uff0c\u901a\u8fc7\u914d\u5bf9\u771f\u5047\u63cf\u8ff0\u8fdb\u884c\u57fa\u4e8e\u63cf\u8ff0\u7684\u5e7b\u89c9\u641c\u7d22\u3002", "result": "HOPE\u4f7f\u5404\u79cd\u6700\u5148\u8fdb\u7684LVLMs\u7cbe\u5ea6\u81f3\u5c11\u4e0b\u964d9%\uff0c\u6700\u591a\u4e0b\u964d23%\uff0c\u663e\u8457\u4f18\u4e8ePOPE\u3002", "conclusion": "HOPE\u57fa\u51c6\u5728\u66b4\u9732LVLMs\u5e7b\u89c9\u6f0f\u6d1e\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.06535", "pdf": "https://arxiv.org/pdf/2508.06535", "abs": "https://arxiv.org/abs/2508.06535", "authors": ["Faisal Ahmed"], "title": "Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification", "categories": ["eess.IV", "cs.CV", "cs.LG", "F.2.2; I.2.7"], "comment": "8 pages, 1 figure", "summary": "Accurate classification of Acute Lymphoblastic Leukemia (ALL) from peripheral\nblood smear images is essential for early diagnosis and effective treatment\nplanning. This study investigates the use of transfer learning with pretrained\nconvolutional neural networks (CNNs) to improve diagnostic performance. To\naddress the class imbalance in the dataset of 3,631 Hematologic and 7,644 ALL\nimages, we applied extensive data augmentation techniques to create a balanced\ntraining set of 10,000 images per class. We evaluated several models, including\nResNet50, ResNet101, and EfficientNet variants B0, B1, and B3. EfficientNet-B3\nachieved the best results, with an F1-score of 94.30%, accuracy of 92.02%,\nandAUCof94.79%,outperformingpreviouslyreported methods in the C-NMCChallenge.\nThesefindings demonstrate the effectiveness of combining data augmentation with\nadvanced transfer learning models, particularly EfficientNet-B3, in developing\naccurate and robust diagnostic tools for hematologic malignancy detection.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u9884\u8bad\u7ec3CNN\u7684\u8fc1\u79fb\u5b66\u4e60\u63d0\u9ad8\u6025\u6027\u6dcb\u5df4\u7ec6\u80de\u767d\u8840\u75c5\uff08ALL\uff09\u8bca\u65ad\u6027\u80fd\uff0c\u7ecf\u6570\u636e\u589e\u5f3a\u540e\u8bc4\u4f30\u591a\u6a21\u578b\uff0cEfficientNet - B3\u6548\u679c\u6700\u4f73\uff0c\u8bc1\u660e\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u548c\u5148\u8fdb\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u51c6\u786e\u5206\u7c7bALL\u5916\u5468\u8840\u6d82\u7247\u56fe\u50cf\u5bf9\u65e9\u671f\u8bca\u65ad\u548c\u6cbb\u7597\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u9700\u63d0\u9ad8\u8bca\u65ad\u6027\u80fd\u3002", "method": "\u91c7\u7528\u9884\u8bad\u7ec3CNN\u7684\u8fc1\u79fb\u5b66\u4e60\uff0c\u5e94\u7528\u6570\u636e\u589e\u5f3a\u6280\u672f\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u8bc4\u4f30ResNet50\u3001ResNet101\u548cEfficientNet\u591a\u4e2a\u53d8\u4f53\u6a21\u578b\u3002", "result": "EfficientNet - B3\u53d6\u5f97\u6700\u4f73\u7ed3\u679c\uff0cF1\u5206\u657094.30%\uff0c\u51c6\u786e\u738792.02%\uff0cAUC\u4e3a94.79%\uff0c\u4f18\u4e8eC - NMC\u6311\u6218\u4e2d\u5148\u524d\u62a5\u544a\u7684\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u4e0e\u5148\u8fdb\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\uff0c\u7279\u522b\u662fEfficientNet - B3\uff0c\u5728\u5f00\u53d1\u51c6\u786e\u3001\u7a33\u5065\u7684\u8840\u6db2\u6076\u6027\u80bf\u7624\u8bca\u65ad\u5de5\u5177\u65b9\u9762\u6709\u6548\u3002"}}
{"id": "2508.07069", "pdf": "https://arxiv.org/pdf/2508.07069", "abs": "https://arxiv.org/abs/2508.07069", "authors": ["Muhammad Dehan Al Kautsar", "Aswin Candra", "Muhammad Alif Al Hakim", "Maxalmina Satria Kahfi", "Fajri Koto", "Alham Fikri Aji", "Peerat Limkonchotiwat", "Ekapol Chuangsuwanich", "Genta Indra Winata"], "title": "SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Although numerous datasets have been developed to support dialogue systems,\nmost existing chit-chat datasets overlook the cultural nuances inherent in\nnatural human conversations. To address this gap, we introduce SEADialogues, a\nculturally grounded dialogue dataset centered on Southeast Asia, a region with\nover 700 million people and immense cultural diversity. Our dataset features\ndialogues in eight languages from six Southeast Asian countries, many of which\nare low-resource despite having sizable speaker populations. To enhance\ncultural relevance and personalization, each dialogue includes persona\nattributes and two culturally grounded topics that reflect everyday life in the\nrespective communities. Furthermore, we release a multi-turn dialogue dataset\nto advance research on culturally aware and human-centric large language\nmodels, including conversational dialogue agents.", "AI": {"tldr": "\u63d0\u51fa\u4ee5\u4e1c\u5357\u4e9a\u4e3a\u4e2d\u5fc3\u7684\u6587\u5316\u5bf9\u8bdd\u6570\u636e\u96c6SEADialogues\uff0c\u542b\u591a\u8bed\u8a00\u548c\u6587\u5316\u4e3b\u9898\uff0c\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u95f2\u804a\u6570\u636e\u96c6\u5ffd\u7565\u81ea\u7136\u5bf9\u8bdd\u4e2d\u7684\u6587\u5316\u7ec6\u5fae\u5dee\u522b\uff0c\u9700\u5f00\u53d1\u8003\u8651\u6587\u5316\u56e0\u7d20\u7684\u6570\u636e\u96c6\u3002", "method": "\u521b\u5efa\u4ee5\u4e1c\u5357\u4e9a\u4e3a\u4e2d\u5fc3\u7684SEADialogues\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u516d\u56fd\u516b\u79cd\u8bed\u8a00\uff0c\u5bf9\u8bdd\u5305\u542b\u4eba\u7269\u5c5e\u6027\u548c\u6587\u5316\u4e3b\u9898\u3002", "result": "\u53d1\u5e03\u4e86\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u63a8\u8fdb\u6587\u5316\u611f\u77e5\u548c\u4ee5\u4eba\u4e3a\u672c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u3002"}}
{"id": "2508.06552", "pdf": "https://arxiv.org/pdf/2508.06552", "abs": "https://arxiv.org/abs/2508.06552", "authors": ["Unisha Joshi"], "title": "Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection", "categories": ["cs.CV", "cs.LG"], "comment": "11 pages, 4 figures, and 7 tables", "summary": "The challenges associated with deepfake detection are increasing\nsignificantly with the latest advancements in technology and the growing\npopularity of deepfake videos and images. Despite the presence of numerous\ndetection models, demographic bias in the deepfake dataset remains largely\nunaddressed. This paper focuses on the mitigation of age-specific bias in the\ndeepfake dataset by introducing an age-diverse deepfake dataset that will\nimprove fairness across age groups. The dataset is constructed through a\nmodular pipeline incorporating the existing deepfake datasets Celeb-DF,\nFaceForensics++, and UTKFace datasets, and the creation of synthetic data to\nfill the age distribution gaps. The effectiveness and generalizability of this\ndataset are evaluated using three deepfake detection models: XceptionNet,\nEfficientNet, and LipForensics. Evaluation metrics, including AUC, pAUC, and\nEER, revealed that models trained on the age-diverse dataset demonstrated\nfairer performance across age groups, improved overall accuracy, and higher\ngeneralization across datasets. This study contributes a reproducible,\nfairness-aware deepfake dataset and model pipeline that can serve as a\nfoundation for future research in fairer deepfake detection. The complete\ndataset and implementation code are available at\nhttps://github.com/unishajoshi/age-diverse-deepfake-detection.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6\u7684\u5e74\u9f84\u504f\u5dee\u95ee\u9898\uff0c\u6784\u5efa\u5e74\u9f84\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u7ecf\u8bc4\u4f30\u8be5\u6570\u636e\u96c6\u53ef\u63d0\u5347\u6a21\u578b\u516c\u5e73\u6027\u3001\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u8fd8\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u548c\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6a21\u578b\u672a\u89e3\u51b3\u6570\u636e\u96c6\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u5dee\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5e74\u9f84\u504f\u5dee\u3002", "method": "\u6784\u5efa\u6a21\u5757\u5316\u7ba1\u9053\uff0c\u6574\u5408\u73b0\u6709\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6\u5e76\u521b\u5efa\u5408\u6210\u6570\u636e\uff0c\u4ee5\u586b\u8865\u5e74\u9f84\u5206\u5e03\u5dee\u8ddd\uff1b\u7528XceptionNet\u3001EfficientNet\u548cLipForensics\u4e09\u79cd\u6a21\u578b\u8bc4\u4f30\u6570\u636e\u96c6\u6548\u679c\u3002", "result": "\u5728\u5e74\u9f84\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u5404\u5e74\u9f84\u7ec4\u8868\u73b0\u66f4\u516c\u5e73\uff0c\u6574\u4f53\u51c6\u786e\u7387\u63d0\u9ad8\uff0c\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u6027\u589e\u5f3a\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u91cd\u73b0\u3001\u6ce8\u91cd\u516c\u5e73\u6027\u7684\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6\u548c\u6a21\u578b\u7ba1\u9053\uff0c\u4e3a\u672a\u6765\u516c\u5e73\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.07079", "pdf": "https://arxiv.org/pdf/2508.07079", "abs": "https://arxiv.org/abs/2508.07079", "authors": ["Mohamed Parvez Aslam", "Bojan Derajic", "Mohamed-Khalil Bouzidi", "Sebastian Bernhard", "Jan Oliver Ringert"], "title": "Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Safe navigation in pedestrian-rich environments remains a key challenge for\nautonomous robots. This work evaluates the integration of a deep learning-based\nSocial-Implicit (SI) pedestrian trajectory predictor within a Model Predictive\nControl (MPC) framework on the physical Continental Corriere robot. Tested\nacross varied pedestrian densities, the SI-MPC system is compared to a\ntraditional Constant Velocity (CV) model in both open-loop prediction and\nclosed-loop navigation. Results show that SI improves trajectory prediction -\nreducing errors by up to 76% in low-density settings - and enhances safety and\nmotion smoothness in crowded scenes. Moreover, real-world deployment reveals\ndiscrepancies between open-loop metrics and closed-loop performance, as the SI\nmodel yields broader, more cautious predictions. These findings emphasize the\nimportance of system-level evaluation and highlight the SI-MPC framework's\npromise for safer, more adaptive navigation in dynamic, human-populated\nenvironments.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684SI\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u5668\u96c6\u6210\u5230MPC\u6846\u67b6\u5728\u673a\u5668\u4eba\u4e0a\u7684\u6548\u679c\uff0c\u663e\u793aSI\u80fd\u6539\u5584\u8f68\u8ff9\u9884\u6d4b\u3001\u63d0\u5347\u5b89\u5168\u6027\u548c\u5e73\u987a\u6027\uff0c\u5f3a\u8c03\u7cfb\u7edf\u7ea7\u8bc4\u4f30\u91cd\u8981\u6027\u3002", "motivation": "\u89e3\u51b3\u81ea\u4e3b\u673a\u5668\u4eba\u5728\u884c\u4eba\u5bc6\u96c6\u73af\u5883\u4e2d\u7684\u5b89\u5168\u5bfc\u822a\u6311\u6218\u3002", "method": "\u5728\u7269\u7406\u673a\u5668\u4eba\u4e0a\uff0c\u5c06\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684SI\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u5668\u96c6\u6210\u5230MPC\u6846\u67b6\uff0c\u5728\u4e0d\u540c\u884c\u4eba\u5bc6\u5ea6\u4e0b\u6d4b\u8bd5\uff0c\u4e0e\u4f20\u7edfCV\u6a21\u578b\u5728\u5f00\u73af\u9884\u6d4b\u548c\u95ed\u73af\u5bfc\u822a\u4e2d\u5bf9\u6bd4\u3002", "result": "SI\u51cf\u5c11\u8f68\u8ff9\u9884\u6d4b\u8bef\u5dee\uff0c\u5728\u4f4e\u5bc6\u5ea6\u73af\u5883\u8bef\u5dee\u6700\u591a\u964d\u4f4e76%\uff0c\u5728\u62e5\u6324\u573a\u666f\u63d0\u5347\u5b89\u5168\u6027\u548c\u5e73\u987a\u6027\uff1b\u5f00\u73af\u6307\u6807\u4e0e\u95ed\u73af\u6027\u80fd\u6709\u5dee\u5f02\uff0cSI\u6a21\u578b\u9884\u6d4b\u66f4\u5bbd\u6cdb\u8c28\u614e\u3002", "conclusion": "\u5f3a\u8c03\u7cfb\u7edf\u7ea7\u8bc4\u4f30\u91cd\u8981\u6027\uff0cSI - MPC\u6846\u67b6\u5728\u52a8\u6001\u6709\u4eba\u73af\u5883\u5b89\u5168\u81ea\u9002\u5e94\u5bfc\u822a\u6709\u524d\u666f\u3002"}}
{"id": "2508.06556", "pdf": "https://arxiv.org/pdf/2508.06556", "abs": "https://arxiv.org/abs/2508.06556", "authors": ["Sarina Penquitt", "Jonathan Klees", "Rinor Cakaj", "Daniel Kondermann", "Matthias Rottmann", "Lars Schmarje"], "title": "From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Object detection has advanced rapidly in recent years, driven by increasingly\nlarge and diverse datasets. However, label errors, defined as missing labels,\nincorrect classification or inaccurate localization, often compromise the\nquality of these datasets. This can have a significant impact on the outcomes\nof training and benchmark evaluations. Although several methods now exist for\ndetecting label errors in object detection datasets, they are typically\nvalidated only on synthetic benchmarks or limited manual inspection. How to\ncorrect such errors systemically and at scale therefore remains an open\nproblem. We introduce a semi-automated framework for label-error correction\ncalled REC$\\checkmark$D (Rechecked). Building on existing detectors, the\nframework pairs their error proposals with lightweight, crowd-sourced\nmicrotasks. These tasks enable multiple annotators to independently verify each\ncandidate bounding box, and their responses are aggregated to estimate\nambiguity and improve label quality. To demonstrate the effectiveness of\nREC$\\checkmark$D, we apply it to the class pedestrian in the KITTI dataset. Our\ncrowdsourced review yields high-quality corrected annotations, which indicate a\nrate of at least 24% of missing and inaccurate annotations in original\nannotations. This validated set will be released as a new real-world benchmark\nfor label error detection and correction. We show that current label error\ndetection methods, when combined with our correction framework, can recover\nhundreds of errors in the time it would take a human to annotate bounding boxes\nfrom scratch. However, even the best methods still miss up to 66% of the true\nerrors and with low quality labels introduce more errors than they find. This\nhighlights the urgent need for further research, now enabled by our released\nbenchmark.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u6807\u7b7e\u9519\u8bef\u7ea0\u6b63\u7684\u534a\u81ea\u52a8\u5316\u6846\u67b6REC\u221aD\uff0c\u4ee5KITTI\u6570\u636e\u96c6\u884c\u4eba\u7c7b\u522b\u4e3a\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u6307\u51fa\u5f53\u524d\u6807\u7b7e\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u5b58\u5728\u6807\u7b7e\u9519\u8bef\u5f71\u54cd\u8bad\u7ec3\u548c\u8bc4\u4f30\u7ed3\u679c\uff0c\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u5927\u89c4\u6a21\u7ea0\u6b63\u9519\u8bef\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u534a\u81ea\u52a8\u5316\u6846\u67b6REC\u221aD\uff0c\u7ed3\u5408\u73b0\u6709\u68c0\u6d4b\u5668\u7684\u9519\u8bef\u63d0\u8bae\u548c\u4f17\u5305\u5fae\u4efb\u52a1\uff0c\u8ba9\u591a\u4e2a\u6807\u6ce8\u8005\u72ec\u7acb\u9a8c\u8bc1\u5019\u9009\u8fb9\u754c\u6846\u5e76\u6c47\u603b\u54cd\u5e94\u3002", "result": "\u5bf9KITTI\u6570\u636e\u96c6\u884c\u4eba\u7c7b\u522b\u5e94\u7528\u6846\u67b6\u5f97\u5230\u9ad8\u8d28\u91cf\u4fee\u6b63\u6807\u6ce8\uff0c\u539f\u6807\u6ce8\u4e2d\u81f3\u5c1124%\u7f3a\u5931\u548c\u4e0d\u51c6\u786e\uff1b\u5f53\u524d\u6807\u7b7e\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\u7ed3\u5408\u6846\u67b6\u80fd\u5feb\u901f\u53d1\u73b0\u9519\u8bef\uff0c\u4f46\u4ecd\u4f1a\u9057\u6f0f\u5927\u91cf\u9519\u8bef\u4e14\u4f4e\u8d28\u91cf\u6807\u7b7e\u4f1a\u5f15\u5165\u66f4\u591a\u9519\u8bef\u3002", "conclusion": "\u9700\u8981\u57fa\u4e8e\u53d1\u5e03\u7684\u57fa\u51c6\u8fdb\u884c\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.07080", "pdf": "https://arxiv.org/pdf/2508.07080", "abs": "https://arxiv.org/abs/2508.07080", "authors": ["Haolin Liu", "Zijun Guo", "Yanbo Chen", "Jiaqi Chen", "Huilong Yu", "Junqiang Xi"], "title": "An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Highway on-ramp merging is of great challenge for autonomous vehicles (AVs),\nsince they have to proactively interact with surrounding vehicles to enter the\nmain road safely within limited time. However, existing decision-making\nalgorithms fail to adequately address dynamic complexities and social\nacceptance of AVs, leading to suboptimal or unsafe merging decisions. To\naddress this, we propose an evolutionary game-theoretic (EGT) merging\ndecision-making framework, grounded in the bounded rationality of human\ndrivers, which dynamically balances the benefits of both AVs and main-road\nvehicles (MVs). We formulate the cut-in decision-making process as an EGT\nproblem with a multi-objective payoff function that reflects human-like driving\npreferences. By solving the replicator dynamic equation for the evolutionarily\nstable strategy (ESS), the optimal cut-in timing is derived, balancing\nefficiency, comfort, and safety for both AVs and MVs. A real-time driving style\nestimation algorithm is proposed to adjust the game payoff function online by\nobserving the immediate reactions of MVs. Empirical results demonstrate that we\nimprove the efficiency, comfort and safety of both AVs and MVs compared with\nexisting game-theoretic and traditional planning approaches across multi-object\nmetrics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8fdb\u5316\u535a\u5f08\u8bba\u7684\u9ad8\u901f\u516c\u8def\u531d\u9053\u6c47\u5165\u51b3\u7b56\u6846\u67b6\uff0c\u8003\u8651\u4eba\u7c7b\u9a7e\u9a76\u5458\u6709\u9650\u7406\u6027\uff0c\u5e73\u8861\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u548c\u4e3b\u8def\u8f66\u8f86\u5229\u76ca\uff0c\u63d0\u5347\u6c47\u5165\u6548\u7387\u3001\u8212\u9002\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u51b3\u7b56\u7b97\u6cd5\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u52a8\u6001\u590d\u6742\u6027\u548c\u793e\u4f1a\u63a5\u53d7\u5ea6\u95ee\u9898\uff0c\u5bfc\u81f4\u6b21\u4f18\u6216\u4e0d\u5b89\u5168\u6c47\u5165\u51b3\u7b56\u3002", "method": "\u5c06\u5207\u5165\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u5177\u6709\u591a\u76ee\u6807\u6536\u76ca\u51fd\u6570\u7684\u8fdb\u5316\u535a\u5f08\u8bba\u95ee\u9898\uff0c\u6c42\u89e3\u590d\u5236\u52a8\u6001\u65b9\u7a0b\u5f97\u5230\u6700\u4f18\u5207\u5165\u65f6\u673a\uff0c\u540c\u65f6\u63d0\u51fa\u5b9e\u65f6\u9a7e\u9a76\u98ce\u683c\u4f30\u8ba1\u7b97\u6cd5\u5728\u7ebf\u8c03\u6574\u535a\u5f08\u6536\u76ca\u51fd\u6570\u3002", "result": "\u4e0e\u73b0\u6709\u535a\u5f08\u8bba\u548c\u4f20\u7edf\u89c4\u5212\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u591a\u76ee\u6807\u6307\u6807\u4e0a\u63d0\u9ad8\u4e86\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u548c\u4e3b\u8def\u8f66\u8f86\u7684\u6548\u7387\u3001\u8212\u9002\u6027\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8fdb\u5316\u535a\u5f08\u8bba\u6c47\u5165\u51b3\u7b56\u6846\u67b6\u6709\u6548\u53ef\u884c\uff0c\u80fd\u66f4\u597d\u5730\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u531d\u9053\u6c47\u5165\u95ee\u9898\u3002"}}
{"id": "2508.06557", "pdf": "https://arxiv.org/pdf/2508.06557", "abs": "https://arxiv.org/abs/2508.06557", "authors": ["Zihao Hu", "Jia Yan", "Ying-Jun Angela Zhang"], "title": "Communication-Learning Co-Design for Differentially Private Over-the-Air Federated Distillation", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": "9 pages, 2 figures, submitted to IEEE Wireless Communication Letters", "summary": "The ever-growing learning model size nowadays challenges the communication\nefficiency and privacy preservation of the traditional federated learning (FL).\nIn this paper, we propose a novel differentially private (DP) over-the-air\nfederated distillation (FD) framework, where wireless devices (WDs)\nperiodically share noise-perturbed model outputs with the parameter server by\nharnessing the superposition property of multi-access channels. Accordingly,\nover-the-air FD enables the shared responsibility of the DP preservation on the\nlow-dimensional disclosed signals among WDs. We study the\ncommunication-learning co-design problem in differentially private over-the-air\nFD, aiming to maximize the learning convergence rate while meeting the transmit\npower and DP requirements of WDs. The main challenge is rooted in the\nintractable learning and privacy analysis in over-the-air FD, together with the\nstrong coupling among the decision variables spanning two timescales. To tackle\nthis problem, we first derive the analytical learning convergence rate and\nprivacy losses of WDs, based on which the optimal transceiver design per FD\nround and long-term training rounds decision are obtained in the closed forms.\nNumerical results demonstrate that the proposed differentially private\nover-the-air FD approach achieves a better learning-privacy trade-off with\nlargely-reduced communication overhead than the conventional FL benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u5dee\u5206\u9690\u79c1\u7684\u7a7a\u4e2d\u8054\u90a6\u84b8\u998f\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u901a\u4fe1\u6548\u7387\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u5b9e\u73b0\u66f4\u597d\u5b66\u4e60 - \u9690\u79c1\u6743\u8861\u5e76\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u6a21\u578b\u89c4\u6a21\u589e\u957f\u5bf9\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7684\u901a\u4fe1\u6548\u7387\u548c\u9690\u79c1\u4fdd\u62a4\u63d0\u51fa\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5dee\u5206\u9690\u79c1\u7684\u7a7a\u4e2d\u8054\u90a6\u84b8\u998f\u6846\u67b6\uff0c\u7814\u7a76\u901a\u4fe1 - \u5b66\u4e60\u534f\u540c\u8bbe\u8ba1\u95ee\u9898\uff0c\u63a8\u5bfc\u5b66\u4e60\u6536\u655b\u7387\u548c\u9690\u79c1\u635f\u5931\uff0c\u4ee5\u95ed\u5f0f\u6c42\u89e3\u6700\u4f18\u6536\u53d1\u5668\u8bbe\u8ba1\u548c\u957f\u671f\u8bad\u7ec3\u8f6e\u6b21\u51b3\u7b56\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u57fa\u51c6\u80fd\u5b9e\u73b0\u66f4\u597d\u7684\u5b66\u4e60 - \u9690\u79c1\u6743\u8861\uff0c\u5927\u5e45\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "\u6240\u63d0\u5dee\u5206\u9690\u79c1\u7684\u7a7a\u4e2d\u8054\u90a6\u84b8\u998f\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5728\u6ee1\u8db3\u8981\u6c42\u4e0b\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.06558", "pdf": "https://arxiv.org/pdf/2508.06558", "abs": "https://arxiv.org/abs/2508.06558", "authors": ["Simon Baur", "Alexandra Benova", "Emilio Dolgener Cant\u00fa", "Jackie Ma"], "title": "On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deploying deep learning models in clinical practice often requires leveraging\nmultiple data modalities, such as images, text, and structured data, to achieve\nrobust and trustworthy decisions. However, not all modalities are always\navailable at inference time. In this work, we propose multimodal privileged\nknowledge distillation (MMPKD), a training strategy that utilizes additional\nmodalities available solely during training to guide a unimodal vision model.\nSpecifically, we used a text-based teacher model for chest radiographs\n(MIMIC-CXR) and a tabular metadata-based teacher model for mammography\n(CBIS-DDSM) to distill knowledge into a vision transformer student model. We\nshow that MMPKD can improve the resulting attention maps' zero-shot\ncapabilities of localizing ROI in input images, while this effect does not\ngeneralize across domains, as contrarily suggested by prior research.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u7279\u6743\u77e5\u8bc6\u84b8\u998f\uff08MMPKD\uff09\u7b56\u7565\uff0c\u7528\u989d\u5916\u6a21\u6001\u6307\u5bfc\u5355\u6a21\u6001\u89c6\u89c9\u6a21\u578b\uff0c\u53ef\u63d0\u5347\u6ce8\u610f\u529b\u56fe\u96f6\u6837\u672c\u5b9a\u4f4d\u80fd\u529b\uff0c\u4f46\u6548\u679c\u56e0\u9886\u57df\u800c\u5f02\u3002", "motivation": "\u4e34\u5e8a\u5b9e\u8df5\u90e8\u7f72\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9700\u591a\u6a21\u6001\u6570\u636e\uff0c\u4f46\u63a8\u7406\u65f6\u5e76\u975e\u6240\u6709\u6a21\u6001\u90fd\u53ef\u7528\uff0c\u9700\u5229\u7528\u8bad\u7ec3\u65f6\u989d\u5916\u6a21\u6001\u6307\u5bfc\u5355\u6a21\u6001\u6a21\u578b\u3002", "method": "\u63d0\u51faMMPKD\u7b56\u7565\uff0c\u7528\u57fa\u4e8e\u6587\u672c\u7684\u6559\u5e08\u6a21\u578b\u548c\u57fa\u4e8e\u8868\u683c\u5143\u6570\u636e\u7684\u6559\u5e08\u6a21\u578b\u5c06\u77e5\u8bc6\u84b8\u998f\u5230\u89c6\u89c9\u53d8\u538b\u5668\u5b66\u751f\u6a21\u578b\u3002", "result": "MMPKD\u80fd\u63d0\u9ad8\u6ce8\u610f\u529b\u56fe\u5728\u8f93\u5165\u56fe\u50cf\u4e2d\u96f6\u6837\u672c\u5b9a\u4f4d\u611f\u5174\u8da3\u533a\u57df\uff08ROI\uff09\u7684\u80fd\u529b\u3002", "conclusion": "MMPKD\u6548\u679c\u5728\u4e0d\u540c\u9886\u57df\u65e0\u6cd5\u6cdb\u5316\uff0c\u4e0e\u5148\u524d\u7814\u7a76\u4e0d\u540c\u3002"}}
{"id": "2508.07095", "pdf": "https://arxiv.org/pdf/2508.07095", "abs": "https://arxiv.org/abs/2508.07095", "authors": ["Hyo Jin Do", "Werner Geyer"], "title": "Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust", "categories": ["cs.HC", "cs.AI"], "comment": "17 pages, 3 figures, To be published in Proceedings of the 8th\n  AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)", "summary": "Large language models are known to produce outputs that are plausible but\nfactually incorrect. To prevent people from making erroneous decisions by\nblindly trusting AI, researchers have explored various ways of communicating\nfactuality estimates in AI-generated outputs to end-users. However, little is\nknown about whether revealing content estimated to be factually incorrect\ninfluences users' trust when compared to hiding it altogether. We tested four\ndifferent ways of disclosing an AI-generated output with factuality\nassessments: transparent (highlights less factual content), attention\n(highlights factual content), opaque (removes less factual content), ambiguity\n(makes less factual content vague), and compared them with a baseline response\nwithout factuality information. We conducted a human subjects research (N =\n148) using the strategies in question-answering scenarios. We found that the\nopaque and ambiguity strategies led to higher trust while maintaining perceived\nanswer quality, compared to the other strategies. We discuss the efficacy of\nhiding presumably less factual content to build end-user trust.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u540c\u4e8b\u5b9e\u6027\u8bc4\u4f30\u62ab\u9732\u65b9\u5f0f\u5bf9\u7528\u6237\u4fe1\u4efb\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e0d\u900f\u660e\u548c\u6a21\u7cca\u7b56\u7565\u66f4\u80fd\u63d0\u5347\u4fe1\u4efb\u3002", "motivation": "\u9632\u6b62\u4eba\u4eec\u76f2\u76ee\u4fe1\u4efbAI\u800c\u505a\u51fa\u9519\u8bef\u51b3\u7b56\uff0c\u63a2\u7a76\u62ab\u9732\u6216\u9690\u85cf\u4e8b\u5b9e\u6027\u4f30\u8ba1\u5185\u5bb9\u5bf9\u7528\u6237\u4fe1\u4efb\u7684\u5f71\u54cd\u3002", "method": "\u6d4b\u8bd5\u56db\u79cd\u4e0d\u540c\u7684\u62ab\u9732\u65b9\u5f0f\uff08\u900f\u660e\u3001\u5173\u6ce8\u3001\u4e0d\u900f\u660e\u3001\u6a21\u7cca\uff09\uff0c\u5e76\u4e0e\u65e0\u4e8b\u5b9e\u6027\u4fe1\u606f\u7684\u57fa\u7ebf\u54cd\u5e94\u5bf9\u6bd4\uff0c\u5728\u95ee\u7b54\u573a\u666f\u4e2d\u5f00\u5c55148\u4eba\u7684\u53d7\u8bd5\u8005\u7814\u7a76\u3002", "result": "\u4e0d\u900f\u660e\u548c\u6a21\u7cca\u7b56\u7565\u5728\u4fdd\u6301\u611f\u77e5\u7b54\u6848\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u6bd4\u5176\u4ed6\u7b56\u7565\u5e26\u6765\u66f4\u9ad8\u7684\u4fe1\u4efb\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u9690\u85cf\u53ef\u80fd\u4e8b\u5b9e\u6027\u8f83\u4f4e\u7684\u5185\u5bb9\u4ee5\u5efa\u7acb\u7ec8\u7aef\u7528\u6237\u4fe1\u4efb\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.07101", "pdf": "https://arxiv.org/pdf/2508.07101", "abs": "https://arxiv.org/abs/2508.07101", "authors": ["Lijie Yang", "Zhihao Zhang", "Arti Jain", "Shijie Cao", "Baihong Yuan", "Yiwei Chen", "Zhihao Jia", "Ravi Netravali"], "title": "Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large reasoning models achieve strong performance through test-time scaling\nbut incur substantial computational overhead, particularly from excessive token\ngeneration when processing short input prompts. While sparse attention\nmechanisms can reduce latency and memory usage, existing approaches suffer from\nsignificant accuracy degradation due to accumulated errors during\nlong-generation reasoning. These methods generally require either high token\nretention rates or expensive retraining. We introduce LessIsMore, a\ntraining-free sparse attention mechanism for reasoning tasks, which leverages\nglobal attention patterns rather than relying on traditional head-specific\nlocal optimizations. LessIsMore aggregates token selections from local\nattention heads with recent contextual information, enabling unified cross-head\ntoken ranking for future decoding layers. This unified selection improves\ngeneralization and efficiency by avoiding the need to maintain separate token\nsubsets per head. Evaluation across diverse reasoning tasks and benchmarks\nshows that LessIsMore preserves -- and in some cases improves -- accuracy while\nachieving a $1.1\\times$ average decoding speed-up compared to full attention.\nMoreover, LessIsMore attends to $2\\times$ fewer tokens without accuracy loss,\nachieving a $1.13\\times$ end-to-end speed-up compared to existing sparse\nattention methods.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236LessIsMore\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u63d0\u5347\u6548\u7387\u4e14\u4e0d\u635f\u5931\u7cbe\u5ea6\u3002", "motivation": "\u5927\u63a8\u7406\u6a21\u578b\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u5b58\u5728\u7cbe\u5ea6\u4e0b\u964d\u3001\u9700\u9ad8\u4fdd\u7559\u7387\u6216\u6602\u8d35\u518d\u8bad\u7ec3\u95ee\u9898\u3002", "method": "\u5f15\u5165LessIsMore\uff0c\u5229\u7528\u5168\u5c40\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u805a\u5408\u5c40\u90e8\u6ce8\u610f\u529b\u5934\u7684token\u9009\u62e9\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u8fdb\u884c\u7edf\u4e00token\u6392\u5e8f\u3002", "result": "\u5728\u4e0d\u540c\u63a8\u7406\u4efb\u52a1\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u5168\u6ce8\u610f\u529b\u89e3\u7801\u901f\u5ea6\u63d0\u53471.1\u500d\uff0c\u76f8\u6bd4\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u7aef\u5230\u7aef\u901f\u5ea6\u63d0\u53471.13\u500d\uff0c\u4e14\u4e0d\u635f\u5931\u7cbe\u5ea6\u3002", "conclusion": "LessIsMore\u80fd\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u6709\u6548\u63d0\u5347\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u7cbe\u5ea6\u3002"}}
{"id": "2508.06565", "pdf": "https://arxiv.org/pdf/2508.06565", "abs": "https://arxiv.org/abs/2508.06565", "authors": ["Jing Zhang", "Xiaowei Yu", "Minheng Chen", "Lu Zhang", "Tong Chen", "Yan Zhuang", "Chao Cao", "Yanjun Lyu", "Li Su", "Tianming Liu", "Dajiang Zhu"], "title": "Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Integrating brain imaging data with clinical reports offers a valuable\nopportunity to leverage complementary multimodal information for more effective\nand timely diagnosis in practical clinical settings. This approach has gained\nsignificant attention in brain disorder research, yet a key challenge remains:\nhow to effectively link objective imaging data with subjective text-based\nreports, such as doctors' notes. In this work, we propose a novel framework\nthat aligns brain connectomes with clinical reports in a shared cross-modal\nlatent space at both the subject and connectome levels, thereby enhancing\nrepresentation learning. The key innovation of our approach is that we treat\nbrain subnetworks as tokens of imaging data, rather than raw image patches, to\nalign with word tokens in clinical reports. This enables a more efficient\nidentification of system-level associations between neuroimaging findings and\nclinical observations, which is critical since brain disorders often manifest\nas network-level abnormalities rather than isolated regional alterations. We\napplied our method to mild cognitive impairment (MCI) using the ADNI dataset.\nOur approach not only achieves state-of-the-art predictive performance but also\nidentifies clinically meaningful connectome-text pairs, offering new insights\ninto the early mechanisms of Alzheimer's disease and supporting the development\nof clinically useful multimodal biomarkers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u6846\u67b6\u5c06\u8111\u8fde\u63a5\u7ec4\u4e0e\u4e34\u5e8a\u62a5\u544a\u5728\u8de8\u6a21\u6001\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\uff0c\u5e94\u7528\u4e8eMCI\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u4e3a\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u673a\u5236\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002", "motivation": "\u89e3\u51b3\u5c06\u5ba2\u89c2\u6210\u50cf\u6570\u636e\u4e0e\u4e3b\u89c2\u6587\u672c\u62a5\u544a\u6709\u6548\u5173\u8054\u7684\u6311\u6218\uff0c\u4ee5\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\u8fdb\u884c\u66f4\u6709\u6548\u7684\u4e34\u5e8a\u8bca\u65ad\u3002", "method": "\u63d0\u51fa\u65b0\u6846\u67b6\uff0c\u5728\u4e3b\u4f53\u548c\u8fde\u63a5\u7ec4\u5c42\u9762\u5c06\u8111\u8fde\u63a5\u7ec4\u4e0e\u4e34\u5e8a\u62a5\u544a\u5728\u5171\u4eab\u8de8\u6a21\u6001\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\uff0c\u5c06\u8111\u5b50\u7f51\u89c6\u4e3a\u6210\u50cf\u6570\u636e\u7684\u6807\u8bb0\u3002", "result": "\u5e94\u7528\u4e8eMCI\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u8bc6\u522b\u51fa\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u8fde\u63a5\u7ec4 - \u6587\u672c\u5bf9\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u673a\u5236\u63d0\u4f9b\u65b0\u89c1\u89e3\uff0c\u652f\u6301\u5f00\u53d1\u4e34\u5e8a\u6709\u7528\u7684\u591a\u6a21\u6001\u751f\u7269\u6807\u5fd7\u7269\u3002"}}
{"id": "2508.06570", "pdf": "https://arxiv.org/pdf/2508.06570", "abs": "https://arxiv.org/abs/2508.06570", "authors": ["Mohammad Zia Ur Rehman", "Anukriti Bhatnagar", "Omkar Kabde", "Shubhi Bansal", "Nagendra Kumar"], "title": "ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos", "categories": ["cs.CV", "cs.LG"], "comment": "Published in ACL 2025", "summary": "The existing research has primarily focused on text and image-based hate\nspeech detection, video-based approaches remain underexplored. In this work, we\nintroduce a novel dataset, ImpliHateVid, specifically curated for implicit hate\nspeech detection in videos. ImpliHateVid consists of 2,009 videos comprising\n509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos,\nmaking it one of the first large-scale video datasets dedicated to implicit\nhate detection. We also propose a novel two-stage contrastive learning\nframework for hate speech detection in videos. In the first stage, we train\nmodality-specific encoders for audio, text, and image using contrastive loss by\nconcatenating features from the three encoders. In the second stage, we train\ncross-encoders using contrastive learning to refine multimodal representations.\nAdditionally, we incorporate sentiment, emotion, and caption-based features to\nenhance implicit hate detection. We evaluate our method on two datasets,\nImpliHateVid for implicit hate speech detection and another dataset for general\nhate speech detection in videos, HateMM dataset, demonstrating the\neffectiveness of the proposed multimodal contrastive learning for hateful\ncontent detection in videos and the significance of our dataset.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u89c6\u9891\u6570\u636e\u96c6 ImpliHateVid \u7528\u4e8e\u9690\u5f0f\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u8bc4\u4f30\u8bc1\u660e\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u6587\u672c\u548c\u56fe\u50cf\u7684\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\uff0c\u57fa\u4e8e\u89c6\u9891\u7684\u65b9\u6cd5\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f15\u5165 ImpliHateVid \u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u7279\u5f81\u3002\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\uff0c\u7b2c\u4e8c\u9636\u6bb5\u8bad\u7ec3\u4ea4\u53c9\u7f16\u7801\u5668\uff0c\u878d\u5165\u60c5\u611f\u3001\u60c5\u7eea\u548c\u57fa\u4e8e\u5b57\u5e55\u7684\u7279\u5f81\u3002", "result": "\u5728 ImpliHateVid \u548c HateMM \u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u8bc1\u660e\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u7528\u4e8e\u89c6\u9891\u4ec7\u6068\u5185\u5bb9\u68c0\u6d4b\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5bf9\u89c6\u9891\u4ec7\u6068\u5185\u5bb9\u68c0\u6d4b\u6709\u6548\uff0c\u6570\u636e\u96c6\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.07111", "pdf": "https://arxiv.org/pdf/2508.07111", "abs": "https://arxiv.org/abs/2508.07111", "authors": ["Falaah Arif Khan", "Nivedha Sivakumar", "Yinong Oliver Wang", "Katherine Metcalf", "Cezanne Camacho", "Barry-John Theobald", "Luca Zappella", "Nicholas Apostoloff"], "title": "Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved impressive performance, leading to\ntheir widespread adoption as decision-support tools in resource-constrained\ncontexts like hiring and admissions. There is, however, scientific consensus\nthat AI systems can reflect and exacerbate societal biases, raising concerns\nabout identity-based harm when used in critical social contexts. Prior work has\nlaid a solid foundation for assessing bias in LLMs by evaluating demographic\ndisparities in different language reasoning tasks. In this work, we extend\nsingle-axis fairness evaluations to examine intersectional bias, recognizing\nthat when multiple axes of discrimination intersect, they create distinct\npatterns of disadvantage. We create a new benchmark called WinoIdentity by\naugmenting the WinoBias dataset with 25 demographic markers across 10\nattributes, including age, nationality, and race, intersected with binary\ngender, yielding 245,700 prompts to evaluate 50 distinct bias patterns.\nFocusing on harms of omission due to underrepresentation, we investigate bias\nthrough the lens of uncertainty and propose a group (un)fairness metric called\nCoreference Confidence Disparity which measures whether models are more or less\nconfident for some intersectional identities than others. We evaluate five\nrecently published LLMs and find confidence disparities as high as 40% along\nvarious demographic attributes including body type, sexual orientation and\nsocio-economic status, with models being most uncertain about\ndoubly-disadvantaged identities in anti-stereotypical settings. Surprisingly,\ncoreference confidence decreases even for hegemonic or privileged markers,\nindicating that the recent impressive performance of LLMs is more likely due to\nmemorization than logical reasoning. Notably, these are two independent\nfailures in value alignment and validity that can compound to cause social\nharm.", "AI": {"tldr": "\u6587\u7ae0\u6269\u5c55\u5355\u8f74\u516c\u5e73\u6027\u8bc4\u4f30\u4ee5\u8003\u5bdf\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u53c9\u504f\u89c1\uff0c\u521b\u5efaWinoIdentity\u57fa\u51c6\uff0c\u63d0\u51fa\u65b0\u6307\u6807\u8bc4\u4f30\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u9ad8\u7f6e\u4fe1\u5ea6\u5dee\u5f02\uff0c\u6027\u80fd\u53ef\u80fd\u6e90\u4e8e\u8bb0\u5fc6\u800c\u975e\u63a8\u7406\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5173\u952e\u793e\u4f1a\u573a\u666f\u5e94\u7528\u5f15\u53d1\u8eab\u4efd\u4f24\u5bb3\u62c5\u5fe7\uff0c\u6b64\u524d\u5de5\u4f5c\u591a\u4e3a\u5355\u8f74\u516c\u5e73\u6027\u8bc4\u4f30\uff0c\u9700\u8003\u5bdf\u4ea4\u53c9\u504f\u89c1\u3002", "method": "\u521b\u5efaWinoIdentity\u57fa\u51c6\uff0c\u7528245,700\u4e2a\u63d0\u793a\u8bc4\u4f3050\u79cd\u504f\u89c1\u6a21\u5f0f\uff0c\u63d0\u51faCoreference Confidence Disparity\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u8bc4\u4f305\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u73b0\u9ad8\u8fbe40%\u7684\u7f6e\u4fe1\u5ea6\u5dee\u5f02\uff0c\u6a21\u578b\u5bf9\u53cc\u91cd\u52a3\u52bf\u8eab\u4efd\u6700\u4e0d\u786e\u5b9a\uff0c\u9738\u6743\u6216\u7279\u6743\u6807\u8bb0\u7684\u5171\u6307\u7f6e\u4fe1\u5ea6\u4e5f\u964d\u4f4e\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4ef7\u503c\u5bf9\u9f50\u548c\u6709\u6548\u6027\u4e24\u65b9\u9762\u72ec\u7acb\u5931\u8d25\uff0c\u53ef\u80fd\u9020\u6210\u793e\u4f1a\u5371\u5bb3\uff0c\u5176\u6027\u80fd\u66f4\u53ef\u80fd\u6e90\u4e8e\u8bb0\u5fc6\u800c\u975e\u903b\u8f91\u63a8\u7406\u3002"}}
{"id": "2508.06642", "pdf": "https://arxiv.org/pdf/2508.06642", "abs": "https://arxiv.org/abs/2508.06642", "authors": ["Adedire D. Adesiji", "Jiashuo Wang", "Cheng-Shu Kuo", "Keith A. Brown"], "title": "Benchmarking Self-Driving Labs", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.LG", "physics.data-an"], "comment": null, "summary": "A key goal of modern materials science is accelerating the pace of materials\ndiscovery. Self-driving labs, or systems that select experiments using machine\nlearning and then execute them using automation, are designed to fulfil this\npromise by performing experiments faster, more intelligently, more reliably,\nand with richer metadata than conventional means. This review summarizes\nprogress in understanding the degree to which SDLs accelerate learning by\nquantifying how much they reduce the number of experiments required for a given\ngoal. The review begins by summarizing the theory underlying two key metrics,\nnamely acceleration factor AF and enhancement factor EF, which quantify how\nmuch faster and better an algorithm is relative to a reference strategy. Next,\nwe provide a comprehensive review of the literature, which reveals a wide range\nof AFs with a median of 6, and that tends to increase with the dimensionality\nof the space, reflecting an interesting blessing of dimensionality. In\ncontrast, reported EF values vary by over two orders of magnitude, although\nthey consistently peak at 10-20 experiments per dimension. To understand these\nresults, we perform a series of simulated Bayesian optimization campaigns that\nreveal how EF depends upon the statistical properties of the parameter space\nwhile AF depends on its complexity. Collectively, these results reinforce the\nmotivation for using SDLs by revealing their value across a wide range of\nmaterial parameter spaces and provide a common language for quantifying and\nunderstanding this acceleration.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u81ea\u52a8\u9a7e\u9a76\u5b9e\u9a8c\u5ba4\uff08SDLs\uff09\u52a0\u901f\u6750\u6599\u53d1\u73b0\u7684\u8fdb\u5c55\uff0c\u91cf\u5316\u5176\u51cf\u5c11\u5b9e\u9a8c\u6b21\u6570\u7684\u7a0b\u5ea6\uff0c\u5206\u6790\u5173\u952e\u6307\u6807\u5e76\u8fdb\u884c\u6a21\u62df\u5b9e\u9a8c\uff0c\u5f3a\u5316\u4f7f\u7528SDLs\u7684\u52a8\u673a\u3002", "motivation": "\u73b0\u4ee3\u6750\u6599\u79d1\u5b66\u65e8\u5728\u52a0\u901f\u6750\u6599\u53d1\u73b0\uff0cSDLs\u53ef\u66f4\u9ad8\u6548\u5b8c\u6210\u5b9e\u9a8c\uff0c\u672c\u6587\u65e8\u5728\u91cf\u5316\u5176\u52a0\u901f\u5b66\u4e60\u7684\u7a0b\u5ea6\u3002", "method": "\u603b\u7ed3\u5173\u952e\u6307\u6807AF\u548cEF\u7684\u7406\u8bba\uff0c\u5168\u9762\u56de\u987e\u6587\u732e\uff0c\u8fdb\u884c\u4e00\u7cfb\u5217\u6a21\u62df\u8d1d\u53f6\u65af\u4f18\u5316\u5b9e\u9a8c\u3002", "result": "\u6587\u732e\u4e2dAF\u4e2d\u4f4d\u6570\u4e3a6\u4e14\u968f\u7a7a\u95f4\u7ef4\u5ea6\u589e\u52a0\uff0cEF\u503c\u53d8\u5316\u8d85\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u5728\u6bcf\u7ef410 - 20\u6b21\u5b9e\u9a8c\u65f6\u8fbe\u5cf0\u503c\uff1b\u6a21\u62df\u5b9e\u9a8c\u63ed\u793aEF\u4f9d\u8d56\u53c2\u6570\u7a7a\u95f4\u7edf\u8ba1\u7279\u6027\uff0cAF\u4f9d\u8d56\u5176\u590d\u6742\u6027\u3002", "conclusion": "\u7ed3\u679c\u5f3a\u5316\u4e86\u5728\u5e7f\u6cdb\u6750\u6599\u53c2\u6570\u7a7a\u95f4\u4f7f\u7528SDLs\u7684\u52a8\u673a\uff0c\u5e76\u63d0\u4f9b\u91cf\u5316\u548c\u7406\u89e3\u8fd9\u79cd\u52a0\u901f\u7684\u901a\u7528\u8bed\u8a00\u3002"}}
{"id": "2508.07128", "pdf": "https://arxiv.org/pdf/2508.07128", "abs": "https://arxiv.org/abs/2508.07128", "authors": ["Gregory Schuit", "Denis Parra", "Cecilia Besa"], "title": "Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to the Workshop on Human-AI Collaboration at MICCAI 2025", "summary": "Generative image models have achieved remarkable progress in both natural and\nmedical imaging. In the medical context, these techniques offer a potential\nsolution to data scarcity-especially for low-prevalence anomalies that impair\nthe performance of AI-driven diagnostic and segmentation tools. However,\nquestions remain regarding the fidelity and clinical utility of synthetic\nimages, since poor generation quality can undermine model generalizability and\ntrust. In this study, we evaluate the effectiveness of state-of-the-art\ngenerative models-Generative Adversarial Networks (GANs) and Diffusion Models\n(DMs)-for synthesizing chest X-rays conditioned on four abnormalities:\nAtelectasis (AT), Lung Opacity (LO), Pleural Effusion (PE), and Enlarged\nCardiac Silhouette (ECS). Using a benchmark composed of real images from the\nMIMIC-CXR dataset and synthetic images from both GANs and DMs, we conducted a\nreader study with three radiologists of varied experience. Participants were\nasked to distinguish real from synthetic images and assess the consistency\nbetween visual features and the target abnormality. Our results show that while\nDMs generate more visually realistic images overall, GANs can report better\naccuracy for specific conditions, such as absence of ECS. We further identify\nvisual cues radiologists use to detect synthetic images, offering insights into\nthe perceptual gaps in current models. These findings underscore the\ncomplementary strengths of GANs and DMs and point to the need for further\nrefinement to ensure generative models can reliably augment training datasets\nfor AI diagnostic systems.", "AI": {"tldr": "\u8bc4\u4f30GANs\u548cDMs\u5408\u6210\u80f8\u90e8X\u5149\u7247\u6548\u679c\uff0c\u53d1\u73b0\u5404\u6709\u4f18\u52bf\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "motivation": "\u751f\u6210\u5f0f\u56fe\u50cf\u6a21\u578b\u53ef\u89e3\u51b3\u533b\u5b66\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4f46\u5408\u6210\u56fe\u50cf\u4fdd\u771f\u5ea6\u548c\u4e34\u5e8a\u5b9e\u7528\u6027\u5b58\u7591\uff0c\u9700\u8bc4\u4f30\u5176\u6548\u679c\u3002", "method": "\u7528MIMIC - CXR\u6570\u636e\u96c6\u771f\u5b9e\u56fe\u50cf\u548cGANs\u3001DMs\u5408\u6210\u56fe\u50cf\u6784\u6210\u57fa\u51c6\uff0c\u8ba9\u4e09\u4f4d\u4e0d\u540c\u7ecf\u9a8c\u653e\u5c04\u79d1\u533b\u751f\u533a\u5206\u771f\u5047\u56fe\u50cf\u5e76\u8bc4\u4f30\u89c6\u89c9\u7279\u5f81\u4e0e\u76ee\u6807\u5f02\u5e38\u7684\u4e00\u81f4\u6027\u3002", "result": "DMs\u751f\u6210\u56fe\u50cf\u6574\u4f53\u66f4\u903c\u771f\uff0cGANs\u5728\u7279\u5b9a\u60c5\u51b5\uff08\u5982\u65e0ECS\uff09\u4e0b\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u8fd8\u627e\u51fa\u653e\u5c04\u79d1\u533b\u751f\u68c0\u6d4b\u5408\u6210\u56fe\u50cf\u7684\u89c6\u89c9\u7ebf\u7d22\u3002", "conclusion": "GANs\u548cDMs\u4f18\u52bf\u4e92\u8865\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u53ef\u9760\u6269\u5145AI\u8bca\u65ad\u7cfb\u7edf\u8bad\u7ec3\u6570\u636e\u96c6\u3002"}}
{"id": "2508.07129", "pdf": "https://arxiv.org/pdf/2508.07129", "abs": "https://arxiv.org/abs/2508.07129", "authors": ["Caroline M. Johnston", "Olga Koumoundouros", "Angel Hsing-Chi Hwang", "Laura Onasch-Vera", "Eric Rice", "Phebe Vayanos"], "title": "Toward AI Matching Policies in Homeless Services: A Qualitative Study with Policymakers", "categories": ["cs.HC", "cs.AI"], "comment": "21 pages, 1 figure, 2 tables", "summary": "Artificial intelligence researchers have proposed various data-driven\nalgorithms to improve the processes that match individuals experiencing\nhomelessness to scarce housing resources. It remains unclear whether and how\nthese algorithms are received or adopted by practitioners and what their\ncorresponding consequences are. Through semi-structured interviews with 13\npolicymakers in homeless services in Los Angeles, we investigate whether such\nchange-makers are open to the idea of integrating AI into the housing resource\nmatching process, identifying where they see potential gains and drawbacks from\nsuch a system in issues of efficiency, fairness, and transparency. Our\nqualitative analysis indicates that, even when aware of various complicating\nfactors, policymakers welcome the idea of an AI matching tool if thoughtfully\ndesigned and used in tandem with human decision-makers. Though there is no\nconsensus as to the exact design of such an AI system, insights from\npolicymakers raise open questions and design considerations that can be\nenlightening for future researchers and practitioners who aim to build\nresponsible algorithmic systems to support decision-making in low-resource\nscenarios.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5bf9\u6d1b\u6749\u77f613\u4f4d\u65e0\u5bb6\u53ef\u5f52\u8005\u670d\u52a1\u653f\u7b56\u5236\u5b9a\u8005\u7684\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u63a2\u8ba8\u4ed6\u4eec\u5bf9\u5c06AI\u96c6\u6210\u5230\u4f4f\u623f\u8d44\u6e90\u5339\u914d\u8fc7\u7a0b\u7684\u770b\u6cd5\uff0c\u53d1\u73b0\u653f\u7b56\u5236\u5b9a\u8005\u6b22\u8fce\u8bbe\u8ba1\u5408\u7406\u4e14\u4e0e\u4eba\u534f\u540c\u7684AI\u5339\u914d\u5de5\u5177\u3002", "motivation": "\u4e0d\u6e05\u695a\u6570\u636e\u9a71\u52a8\u7b97\u6cd5\u662f\u5426\u4ee5\u53ca\u5982\u4f55\u88ab\u4ece\u4e1a\u8005\u63a5\u53d7\u548c\u91c7\u7528\uff0c\u53ca\u5176\u76f8\u5e94\u540e\u679c\uff0c\u9700\u4e86\u89e3\u653f\u7b56\u5236\u5b9a\u8005\u5bf9AI\u878d\u5165\u4f4f\u623f\u8d44\u6e90\u5339\u914d\u8fc7\u7a0b\u7684\u6001\u5ea6\u3002", "method": "\u5bf9\u6d1b\u6749\u77f613\u4f4d\u65e0\u5bb6\u53ef\u5f52\u8005\u670d\u52a1\u653f\u7b56\u5236\u5b9a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u5e76\u8fdb\u884c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u653f\u7b56\u5236\u5b9a\u8005\u5728\u8003\u8651\u5230\u5404\u79cd\u590d\u6742\u56e0\u7d20\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u6b22\u8fce\u7ecf\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u4e14\u4e0e\u4eba\u534f\u540c\u7684AI\u5339\u914d\u5de5\u5177\uff0c\u5173\u4e8eAI\u7cfb\u7edf\u7684\u5177\u4f53\u8bbe\u8ba1\u5c1a\u65e0\u5171\u8bc6\u3002", "conclusion": "\u653f\u7b56\u5236\u5b9a\u8005\u7684\u89c1\u89e3\u4e3a\u672a\u6765\u6784\u5efa\u8d1f\u8d23\u4efb\u7684\u7b97\u6cd5\u7cfb\u7edf\u4ee5\u652f\u6301\u4f4e\u8d44\u6e90\u573a\u666f\u51b3\u7b56\u7684\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u51fa\u4e86\u5f00\u653e\u6027\u95ee\u9898\u548c\u8bbe\u8ba1\u8003\u91cf\u3002"}}
{"id": "2508.06670", "pdf": "https://arxiv.org/pdf/2508.06670", "abs": "https://arxiv.org/abs/2508.06670", "authors": ["Kyu-Hwan Lee", "Seewoo Lee"], "title": "Machines Learn Number Fields, But How? The Case of Galois Groups", "categories": ["math.NT", "cs.LG", "11R32, 11R42, 11S15, 11S20"], "comment": "31+10+3 pages", "summary": "By applying interpretable machine learning methods such as decision trees, we\nstudy how simple models can classify the Galois groups of Galois extensions\nover $\\mathbb{Q}$ of degrees 4, 6, 8, 9, and 10, using Dedekind zeta\ncoefficients. Our interpretation of the machine learning results allows us to\nunderstand how the distribution of zeta coefficients depends on the Galois\ngroup, and to prove new criteria for classifying the Galois groups of these\nextensions. Combined with previous results, this work provides another example\nof a new paradigm in mathematical research driven by machine learning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.07132", "pdf": "https://arxiv.org/pdf/2508.07132", "abs": "https://arxiv.org/abs/2508.07132", "authors": ["Dirk HR Spennemann"], "title": "\"Draw me a curator\" Examining the visual stereotyping of a cultural services profession by generative AI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Based on 230 visualisations, this paper examines the depiction of museum\ncurators by the popular generative Artificial Intelligence (AI) model,\nChatGPT4o. While the AI-generated representations do not reiterate popular\nstereotypes of curators as nerdy, conservative in dress and stuck in time\nrummaging through collections, they contrast sharply with real-world\ndemographics. AI-generated imagery extremely underrepresents women (3.5% vs 49%\nto 72% in reality) and disregards ethnic communities other than Caucasian (0%\nvs 18% to 36%). It only over-represents young curators (79% vs approx. 27%) but\nalso renders curators to resemble yuppie professionals or people featuring in\nfashion advertising. Stereotypical attributes are prevalent, with curators\nwidely depicted as wearing beards and holding clipboards or digital tablets.\nThe findings highlight biases in the generative AI image creation dataset,\nwhich is poised to shape an inaccurate portrayal of museum professionals if the\nimages were to be taken uncritically at face value.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e230\u4e2a\u53ef\u89c6\u5316\u7ed3\u679c\uff0c\u7814\u7a76ChatGPT4o\u5bf9\u535a\u7269\u9986\u7b56\u5c55\u4eba\u7684\u63cf\u7ed8\uff0c\u53d1\u73b0\u5176\u751f\u6210\u56fe\u50cf\u5b58\u5728\u6027\u522b\u3001\u79cd\u65cf\u548c\u5e74\u9f84\u7b49\u65b9\u9762\u7684\u504f\u5dee\uff0c\u51f8\u663e\u751f\u6210\u5f0fAI\u56fe\u50cf\u521b\u5efa\u6570\u636e\u96c6\u7684\u504f\u89c1\u3002", "motivation": "\u7814\u7a76\u6d41\u884c\u751f\u6210\u5f0fAI\u6a21\u578bChatGPT4o\u5bf9\u535a\u7269\u9986\u7b56\u5c55\u4eba\u7684\u63cf\u7ed8\u60c5\u51b5\u3002", "method": "\u57fa\u4e8e230\u4e2a\u53ef\u89c6\u5316\u7ed3\u679c\u8fdb\u884c\u5206\u6790\u3002", "result": "AI\u751f\u6210\u7684\u56fe\u50cf\u4e0e\u73b0\u5b9e\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff0c\u5973\u6027\u548c\u975e\u767d\u4eba\u65cf\u88d4\u4e25\u91cd\u4ee3\u8868\u6027\u4e0d\u8db3\uff0c\u8fc7\u5ea6\u4ee3\u8868\u5e74\u8f7b\u7b56\u5c55\u4eba\uff0c\u4e14\u5b58\u5728\u523b\u677f\u5c5e\u6027\u63cf\u7ed8\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u56fe\u50cf\u521b\u5efa\u6570\u636e\u96c6\u5b58\u5728\u504f\u89c1\uff0c\u82e5\u4e0d\u52a0\u4ee5\u6279\u5224\u5730\u770b\u5f85\u8fd9\u4e9b\u56fe\u50cf\uff0c\u5c06\u5851\u9020\u5bf9\u535a\u7269\u9986\u4e13\u4e1a\u4eba\u5458\u7684\u4e0d\u51c6\u786e\u63cf\u7ed8\u3002"}}
{"id": "2508.06691", "pdf": "https://arxiv.org/pdf/2508.06691", "abs": "https://arxiv.org/abs/2508.06691", "authors": ["Agada Joseph Oche", "Arpan Biswas"], "title": "Role of Large Language Models and Retrieval-Augmented Generation for Accelerating Crystalline Material Discovery: A Systematic Review", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": "10 pages, 2 figures", "summary": "Large language models (LLMs) have emerged as powerful tools for\nknowledge-intensive tasks across domains. In materials science, to find novel\nmaterials for various energy efficient devices for various real-world\napplications, requires several time and cost expensive simulations and\nexperiments. In order to tune down the uncharted material search space,\nminimizing the experimental cost, LLMs can play a bigger role to first provide\nan accelerated search of promising known material candidates. Furthermore, the\nintegration of LLMs with domain-specific information via retrieval-augmented\ngeneration (RAG) is poised to revolutionize how researchers predict materials\nstructures, analyze defects, discover novel compounds, and extract knowledge\nfrom literature and databases. In motivation to the potentials of LLMs and RAG\nin accelerating material discovery, this paper presents a broad and systematic\nreview to examine the recent advancements in applying LLMs and RAG to key\nmaterials science problems. We survey state-of-the-art developments in crystal\nstructure prediction, defect analysis, materials discovery, literature mining,\ndatabase integration, and multi-modal retrieval, highlighting how combining\nLLMs with external knowledge sources enables new capabilities. We discuss the\nperformance, limitations, and implications of these approaches, and outline\nfuture directions for leveraging LLMs to accelerate materials research and\ndiscovery for advancement in technologies in the area of electronics, optics,\nbiomedical, and energy storage.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u6750\u6599\u79d1\u5b66\u95ee\u9898\u5e94\u7528\u7684\u8fdb\u5c55\u8fdb\u884c\u7efc\u8ff0\uff0c\u8ba8\u8bba\u6027\u80fd\u3001\u5c40\u9650\u7b49\u5e76\u7ed9\u51fa\u672a\u6765\u65b9\u5411\u3002", "motivation": "LLMs\u548cRAG\u5728\u52a0\u901f\u6750\u6599\u53d1\u73b0\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4e3a\u6316\u6398\u5176\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u5e94\u7528\u4ef7\u503c\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5bf9\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\u3001\u7f3a\u9677\u5206\u6790\u7b49\u591a\u4e2a\u65b9\u9762\u7684\u524d\u6cbf\u53d1\u5c55\u8fdb\u884c\u8c03\u7814\u3002", "result": "\u68b3\u7406\u4e86LLMs\u548cRAG\u5728\u6750\u6599\u79d1\u5b66\u5404\u65b9\u9762\u5e94\u7528\u7684\u8fdb\u5c55\uff0c\u660e\u786e\u4e86\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\u6e90\u5e26\u6765\u7684\u65b0\u80fd\u529b\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u76f8\u5173\u65b9\u6cd5\u7684\u8868\u73b0\u3001\u5c40\u9650\u548c\u5f71\u54cd\uff0c\u6307\u51fa\u5229\u7528LLMs\u52a0\u901f\u6750\u6599\u7814\u7a76\u548c\u53d1\u73b0\u7684\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2508.07139", "pdf": "https://arxiv.org/pdf/2508.07139", "abs": "https://arxiv.org/abs/2508.07139", "authors": ["Ivan Zhang"], "title": "A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection", "categories": ["cs.CR", "cs.AI"], "comment": "10 pages, 1 figure", "summary": "Ensuring LLM alignment is critical to information security as AI models\nbecome increasingly widespread and integrated in society. Unfortunately, many\ndefenses against adversarial attacks and jailbreaking on LLMs cannot adapt\nquickly to new attacks, degrade model responses to benign prompts, or introduce\nsignificant barriers to scalable implementation. To mitigate these challenges,\nwe introduce a real-time, self-tuning (RTST) moderator framework to defend\nagainst adversarial attacks while maintaining a lightweight training footprint.\nWe empirically evaluate its effectiveness using Google's Gemini models against\nmodern, effective jailbreaks. Our results demonstrate the advantages of an\nadaptive, minimally intrusive framework for jailbreak defense over traditional\nfine-tuning or classifier models.", "AI": {"tldr": "\u4ecb\u7ecd\u5b9e\u65f6\u81ea\u8c03\u8c10\uff08RTST\uff09\u5ba1\u6838\u6846\u67b6\u9632\u5fa1\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u653b\u51fb\uff0c\u7528Gemini\u6a21\u578b\u8bc4\u4f30\u5176\u6709\u6548\u6027\uff0c\u663e\u793a\u8be5\u6846\u67b6\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u548c\u8d8a\u72f1\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u65e0\u6cd5\u5feb\u901f\u9002\u5e94\u65b0\u653b\u51fb\u3001\u964d\u4f4e\u6a21\u578b\u5bf9\u826f\u6027\u63d0\u793a\u54cd\u5e94\u3001\u96be\u4ee5\u6269\u5c55\u5b9e\u65bd\u7b49\u95ee\u9898\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u5f15\u5165\u5b9e\u65f6\u81ea\u8c03\u8c10\uff08RTST\uff09\u5ba1\u6838\u6846\u67b6\uff0c\u7528Google\u7684Gemini\u6a21\u578b\u5bf9\u73b0\u4ee3\u6709\u6548\u8d8a\u72f1\u653b\u51fb\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u8bc1\u660e\u81ea\u9002\u5e94\u3001\u4f4e\u4fb5\u5165\u6027\u7684\u8d8a\u72f1\u9632\u5fa1\u6846\u67b6\u76f8\u6bd4\u4f20\u7edf\u5fae\u8c03\u6216\u5206\u7c7b\u5668\u6a21\u578b\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u5b9e\u65f6\u81ea\u8c03\u8c10\uff08RTST\uff09\u5ba1\u6838\u6846\u67b6\u5728\u9632\u5fa1\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2508.07143", "pdf": "https://arxiv.org/pdf/2508.07143", "abs": "https://arxiv.org/abs/2508.07143", "authors": ["Anna Seo Gyeong Choi", "Hoon Choi"], "title": "Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Automatic Speech Recognition (ASR) systems now mediate countless\nhuman-technology interactions, yet research on their fairness implications\nremains surprisingly limited. This paper examines ASR bias through a\nphilosophical lens, arguing that systematic misrecognition of certain speech\nvarieties constitutes more than a technical limitation -- it represents a form\nof disrespect that compounds historical injustices against marginalized\nlinguistic communities. We distinguish between morally neutral classification\n(discriminate1) and harmful discrimination (discriminate2), demonstrating how\nASR systems can inadvertently transform the former into the latter when they\nconsistently misrecognize non-standard dialects. We identify three unique\nethical dimensions of speech technologies that differentiate ASR bias from\nother algorithmic fairness concerns: the temporal burden placed on speakers of\nnon-standard varieties (\"temporal taxation\"), the disruption of conversational\nflow when systems misrecognize speech, and the fundamental connection between\nspeech patterns and personal/cultural identity. These factors create asymmetric\npower relationships that existing technical fairness metrics fail to capture.\nThe paper analyzes the tension between linguistic standardization and pluralism\nin ASR development, arguing that current approaches often embed and reinforce\nproblematic language ideologies. We conclude that addressing ASR bias requires\nmore than technical interventions; it demands recognition of diverse speech\nvarieties as legitimate forms of expression worthy of technological\naccommodation. This philosophical reframing offers new pathways for developing\nASR systems that respect linguistic diversity and speaker autonomy.", "AI": {"tldr": "\u672c\u6587\u4ece\u54f2\u5b66\u89c6\u89d2\u5ba1\u89c6\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\u7684\u504f\u89c1\u95ee\u9898\uff0c\u6307\u51fa\u5176\u5bf9\u7279\u5b9a\u8bed\u97f3\u53d8\u4f53\u7684\u8bef\u8bc6\u522b\u662f\u4e00\u79cd\u4e0d\u5c0a\u91cd\uff0c\u5206\u6790\u4f26\u7406\u7ef4\u5ea6\u548c\u8bed\u8a00\u6807\u51c6\u5316\u4e0e\u591a\u5143\u5316\u7684\u77db\u76fe\uff0c\u8ba4\u4e3a\u89e3\u51b3\u8be5\u95ee\u9898\u9700\u6280\u672f\u4e4b\u5916\u7684\u63aa\u65bd\u3002", "motivation": "\u5f53\u524d\u5bf9ASR\u7cfb\u7edf\u516c\u5e73\u6027\u5f71\u54cd\u7684\u7814\u7a76\u6709\u9650\uff0c\u9700\u4ece\u54f2\u5b66\u89c6\u89d2\u5ba1\u89c6\u5176\u504f\u89c1\u95ee\u9898\u3002", "method": "\u533a\u5206\u9053\u5fb7\u4e2d\u7acb\u7684\u5206\u7c7b\u548c\u6709\u5bb3\u7684\u6b67\u89c6\uff0c\u5206\u6790\u8bed\u97f3\u6280\u672f\u7684\u4e09\u4e2a\u72ec\u7279\u4f26\u7406\u7ef4\u5ea6\uff0c\u63a2\u8ba8\u8bed\u8a00\u6807\u51c6\u5316\u4e0e\u591a\u5143\u5316\u7684\u5f20\u529b\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u6280\u672f\u516c\u5e73\u6307\u6807\u65e0\u6cd5\u6355\u6349\u56e0\u8bed\u97f3\u8bef\u8bc6\u522b\u4ea7\u751f\u7684\u4e0d\u5bf9\u79f0\u6743\u529b\u5173\u7cfb\uff0c\u5f53\u524dASR\u5f00\u53d1\u65b9\u6cd5\u5e38\u5d4c\u5165\u5e76\u5f3a\u5316\u6709\u95ee\u9898\u7684\u8bed\u8a00\u610f\u8bc6\u5f62\u6001\u3002", "conclusion": "\u89e3\u51b3ASR\u504f\u89c1\u95ee\u9898\u4e0d\u4ec5\u9700\u8981\u6280\u672f\u5e72\u9884\uff0c\u8fd8\u9700\u8ba4\u53ef\u591a\u6837\u8bed\u97f3\u53d8\u4f53\uff0c\u4e3a\u5f00\u53d1\u5c0a\u91cd\u8bed\u8a00\u591a\u6837\u6027\u548c\u8bf4\u8bdd\u8005\u81ea\u4e3b\u6027\u7684ASR\u7cfb\u7edf\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2508.06732", "pdf": "https://arxiv.org/pdf/2508.06732", "abs": "https://arxiv.org/abs/2508.06732", "authors": ["Yuya Kawakami", "Daniel Cayan", "Dongyu Liu", "Kwan-Liu Ma"], "title": "ClimateSOM: A Visual Analysis Workflow for Climate Ensemble Datasets", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Ensemble datasets are ever more prevalent in various scientific domains. In\nclimate science, ensemble datasets are used to capture variability in\nprojections under plausible future conditions including greenhouse and aerosol\nemissions. Each ensemble model run produces projections that are fundamentally\nsimilar yet meaningfully distinct. Understanding this variability among\nensemble model runs and analyzing its magnitude and patterns is a vital task\nfor climate scientists. In this paper, we present ClimateSOM, a visual analysis\nworkflow that leverages a self-organizing map (SOM) and Large Language Models\n(LLMs) to support interactive exploration and interpretation of climate\nensemble datasets. The workflow abstracts climate ensemble model runs -\nspatiotemporal time series - into a distribution over a 2D space that captures\nthe variability among the ensemble model runs using a SOM. LLMs are integrated\nto assist in sensemaking of this SOM-defined 2D space, the basis for the visual\nanalysis tasks. In all, ClimateSOM enables users to explore the variability\namong ensemble model runs, identify patterns, compare and cluster the ensemble\nmodel runs. To demonstrate the utility of ClimateSOM, we apply the workflow to\nan ensemble dataset of precipitation projections over California and the\nNorthwestern United States. Furthermore, we conduct a short evaluation of our\nLLM integration, and conduct an expert review of the visual workflow and the\ninsights from the case studies with six domain experts to evaluate our approach\nand its utility.", "AI": {"tldr": "\u63d0\u51faClimateSOM\u53ef\u89c6\u5316\u5206\u6790\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408SOM\u548cLLM\u63a2\u7d22\u6c14\u5019\u96c6\u5408\u6570\u636e\u96c6\uff0c\u5e94\u7528\u4e8e\u7f8e\u56fd\u964d\u6c34\u9884\u6d4b\u6570\u636e\u96c6\u5e76\u8bc4\u4f30\u3002", "motivation": "\u7406\u89e3\u6c14\u5019\u96c6\u5408\u6a21\u578b\u8fd0\u884c\u95f4\u7684\u53d8\u5f02\u6027\u5e76\u5206\u6790\u5176\u5927\u5c0f\u548c\u6a21\u5f0f\u5bf9\u6c14\u5019\u79d1\u5b66\u5bb6\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faClimateSOM\u5de5\u4f5c\u6d41\uff0c\u7528SOM\u5c06\u6c14\u5019\u96c6\u5408\u6a21\u578b\u8fd0\u884c\u62bd\u8c61\u4e3a\u4e8c\u7ef4\u7a7a\u95f4\u5206\u5e03\uff0c\u96c6\u6210LLM\u8f85\u52a9\u7406\u89e3\u8be5\u7a7a\u95f4\u3002", "result": "\u5e94\u7528ClimateSOM\u5230\u7f8e\u56fd\u964d\u6c34\u9884\u6d4b\u6570\u636e\u96c6\uff0c\u8fdb\u884cLLM\u96c6\u6210\u8bc4\u4f30\u548c\u4e13\u5bb6\u8bc4\u5ba1\u3002", "conclusion": "ClimateSOM\u80fd\u8ba9\u7528\u6237\u63a2\u7d22\u96c6\u5408\u6a21\u578b\u8fd0\u884c\u7684\u53d8\u5f02\u6027\u3001\u8bc6\u522b\u6a21\u5f0f\u3001\u6bd4\u8f83\u548c\u805a\u7c7b\u6a21\u578b\u8fd0\u884c\u3002"}}
{"id": "2508.07146", "pdf": "https://arxiv.org/pdf/2508.07146", "abs": "https://arxiv.org/abs/2508.07146", "authors": ["Yu Liu", "Zhijie Liu", "Xiao Ren", "You-Fu Li", "He Kong"], "title": "Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Predicting pedestrian motion trajectories is critical for the path planning\nand motion control of autonomous vehicles. Recent diffusion-based models have\nshown promising results in capturing the inherent stochasticity of pedestrian\nbehavior for trajectory prediction. However, the absence of explicit semantic\nmodelling of pedestrian intent in many diffusion-based methods may result in\nmisinterpreted behaviors and reduced prediction accuracy. To address the above\nchallenges, we propose a diffusion-based pedestrian trajectory prediction\nframework that incorporates both short-term and long-term motion intentions.\nShort-term intent is modelled using a residual polar representation, which\ndecouples direction and magnitude to capture fine-grained local motion\npatterns. Long-term intent is estimated through a learnable, token-based\nendpoint predictor that generates multiple candidate goals with associated\nprobabilities, enabling multimodal and context-aware intention modelling.\nFurthermore, we enhance the diffusion process by incorporating adaptive\nguidance and a residual noise predictor that dynamically refines denoising\naccuracy. The proposed framework is evaluated on the widely used ETH, UCY, and\nSDD benchmarks, demonstrating competitive results against state-of-the-art\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u542b\u77ed\u957f\u671f\u610f\u56fe\u7684\u6269\u6563\u5f0f\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u8bb8\u591a\u57fa\u4e8e\u6269\u6563\u7684\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u884c\u4eba\u610f\u56fe\u7684\u663e\u5f0f\u8bed\u4e49\u5efa\u6a21\uff0c\u5bfc\u81f4\u884c\u4e3a\u8bef\u5224\u548c\u7cbe\u5ea6\u964d\u4f4e\u3002", "method": "\u63d0\u51fa\u542b\u77ed\u957f\u671f\u8fd0\u52a8\u610f\u56fe\u7684\u6269\u6563\u5f0f\u9884\u6d4b\u6846\u67b6\uff0c\u77ed\u671f\u610f\u56fe\u7528\u6b8b\u5dee\u6781\u5750\u6807\u8868\u793a\uff0c\u957f\u671f\u610f\u56fe\u7528\u53ef\u5b66\u4e60\u7684\u57fa\u4e8e\u4ee4\u724c\u7684\u7ec8\u70b9\u9884\u6d4b\u5668\u4f30\u8ba1\uff0c\u8fd8\u901a\u8fc7\u81ea\u9002\u5e94\u5f15\u5bfc\u548c\u6b8b\u5dee\u566a\u58f0\u9884\u6d4b\u5668\u589e\u5f3a\u6269\u6563\u8fc7\u7a0b\u3002", "result": "\u5728ETH\u3001UCY\u548cSDD\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6269\u6563\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u6709\u8f83\u597d\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2508.06734", "pdf": "https://arxiv.org/pdf/2508.06734", "abs": "https://arxiv.org/abs/2508.06734", "authors": ["Ngoc N. Tran", "Anwar Said", "Waseem Abbas", "Tyler Derr", "Xenofon D. Koutsoukos"], "title": "Mitigating Distribution Shift in Graph-Based Android Malware Classification via Function Metadata and LLM Embeddings", "categories": ["cs.CR", "cs.LG"], "comment": "13 pages, 3 figures, 7 tables, under review", "summary": "Graph-based malware classifiers can achieve over 94% accuracy on standard\nAndroid datasets, yet we find they suffer accuracy drops of up to 45% when\nevaluated on previously unseen malware variants from the same family - a\nscenario where strong generalization would typically be expected. This\nhighlights a key limitation in existing approaches: both the model\narchitectures and their structure-only representations often fail to capture\ndeeper semantic patterns. In this work, we propose a robust semantic enrichment\nframework that enhances function call graphs with contextual features,\nincluding function-level metadata and, when available, code embeddings derived\nfrom large language models. The framework is designed to operate under\nreal-world constraints where feature availability is inconsistent, and supports\nflexible integration of semantic signals. To evaluate generalization under\nrealistic domain and temporal shifts, we introduce two new benchmarks:\nMalNet-Tiny-Common and MalNet-Tiny-Distinct, constructed using malware family\npartitioning to simulate cross-family generalization and evolving threat\nbehavior. Experiments across multiple graph neural network backbones show that\nour method improves classification performance by up to 8% under distribution\nshift and consistently enhances robustness when integrated with\nadaptation-based methods. These results offer a practical path toward building\nresilient malware detection systems in evolving threat environments.", "AI": {"tldr": "\u73b0\u6709\u56fe\u57fa\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u5668\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51fa\u8bed\u4e49\u589e\u5f3a\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u57fa\u51c6\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u57fa\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u5668\u5728\u9762\u5bf9\u672a\u77e5\u53d8\u4f53\u65f6\u51c6\u786e\u7387\u5927\u5e45\u4e0b\u964d\uff0c\u6a21\u578b\u67b6\u6784\u548c\u7ed3\u6784\u8868\u793a\u96be\u4ee5\u6355\u6349\u6df1\u5c42\u8bed\u4e49\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e0a\u4e0b\u6587\u7279\u5f81\u4e30\u5bcc\u51fd\u6570\u8c03\u7528\u56fe\uff0c\u5f15\u5165 MalNet - Tiny - Common \u548c MalNet - Tiny - Distinct \u4e24\u4e2a\u65b0\u57fa\u51c6\u3002", "result": "\u8de8\u591a\u4e2a\u56fe\u795e\u7ecf\u7f51\u7edc\u9aa8\u5e72\u5b9e\u9a8c\u663e\u793a\uff0c\u65b9\u6cd5\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u6700\u591a\u63d0\u5347 8% \u5206\u7c7b\u6027\u80fd\uff0c\u4e0e\u81ea\u9002\u5e94\u65b9\u6cd5\u7ed3\u5408\u65f6\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5728\u4e0d\u65ad\u53d8\u5316\u7684\u5a01\u80c1\u73af\u5883\u4e2d\u6784\u5efa\u6709\u5f39\u6027\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2508.07165", "pdf": "https://arxiv.org/pdf/2508.07165", "abs": "https://arxiv.org/abs/2508.07165", "authors": ["Zelin Qiu", "Xi Wang", "Zhuoyao Xie", "Juan Zhou", "Yu Wang", "Lingjie Yang", "Xinrui Jiang", "Juyoung Bae", "Moo Hyun Son", "Qiang Ye", "Dexuan Chen", "Rui Zhang", "Tao Li", "Neeraj Ramesh Mahboobani", "Varut Vardhanabhuti", "Xiaohui Duan", "Yinghua Zhao", "Hao Chen"], "title": "Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Multi-sequence Magnetic Resonance Imaging (MRI) offers remarkable\nversatility, enabling the distinct visualization of different tissue types.\nNevertheless, the inherent heterogeneity among MRI sequences poses significant\nchallenges to the generalization capability of deep learning models. These\nchallenges undermine model performance when faced with varying acquisition\nparameters, thereby severely restricting their clinical utility. In this study,\nwe present PRISM, a foundation model PRe-trained with large-scale\nmultI-Sequence MRI. We collected a total of 64 datasets from both public and\nprivate sources, encompassing a wide range of whole-body anatomical structures,\nwith scans spanning diverse MRI sequences. Among them, 336,476 volumetric MRI\nscans from 34 datasets (8 public and 26 private) were curated to construct the\nlargest multi-organ multi-sequence MRI pretraining corpus to date. We propose a\nnovel pretraining paradigm that disentangles anatomically invariant features\nfrom sequence-specific variations in MRI, while preserving high-level semantic\nrepresentations. We established a benchmark comprising 44 downstream tasks,\nincluding disease diagnosis, image segmentation, registration, progression\nprediction, and report generation. These tasks were evaluated on 32 public\ndatasets and 5 private cohorts. PRISM consistently outperformed both\nnon-pretrained models and existing foundation models, achieving first-rank\nresults in 39 out of 44 downstream benchmarks with statistical significance\nimprovements. These results underscore its ability to learn robust and\ngeneralizable representations across unseen data acquired under diverse MRI\nprotocols. PRISM provides a scalable framework for multi-sequence MRI analysis,\nthereby enhancing the translational potential of AI in radiology. It delivers\nconsistent performance across diverse imaging protocols, reinforcing its\nclinical applicability.", "AI": {"tldr": "\u63d0\u51faPRISM\u57fa\u7840\u6a21\u578b\uff0c\u7528\u5927\u89c4\u6a21\u591a\u5e8f\u5217MRI\u9884\u8bad\u7ec3\uff0c\u572844\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u5347AI\u5728\u653e\u5c04\u5b66\u7684\u8f6c\u5316\u6f5c\u529b\u3002", "motivation": "\u591a\u5e8f\u5217MRI\u5e8f\u5217\u95f4\u5f02\u8d28\u6027\u5f71\u54cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u9650\u5236\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u6536\u96c664\u4e2a\u6570\u636e\u96c6\uff0c\u6784\u5efa\u6700\u5927\u591a\u5668\u5b98\u591a\u5e8f\u5217MRI\u9884\u8bad\u7ec3\u8bed\u6599\u5e93\uff1b\u63d0\u51fa\u65b0\u9884\u8bad\u7ec3\u8303\u5f0f\uff0c\u5206\u79bb\u89e3\u5256\u4e0d\u53d8\u7279\u5f81\u548c\u5e8f\u5217\u7279\u5b9a\u53d8\u5316\uff1b\u5efa\u7acb44\u4e2a\u4e0b\u6e38\u4efb\u52a1\u57fa\u51c6\u3002", "result": "PRISM\u572844\u4e2a\u4e0b\u6e38\u57fa\u51c6\u4e2d\u768439\u4e2a\u6392\u540d\u7b2c\u4e00\uff0c\u663e\u8457\u4f18\u4e8e\u672a\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u73b0\u6709\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "PRISM\u4e3a\u591a\u5e8f\u5217MRI\u5206\u6790\u63d0\u4f9b\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u589e\u5f3aAI\u5728\u653e\u5c04\u5b66\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.07170", "pdf": "https://arxiv.org/pdf/2508.07170", "abs": "https://arxiv.org/abs/2508.07170", "authors": ["Yunpeng Shi", "Lei Chen", "Xiaolu Shen", "Yanju Guo"], "title": "Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In the domain of computer vision, multi-scale feature extraction is vital for\ntasks such as salient object detection. However, achieving this capability in\nlightweight networks remains challenging due to the trade-off between\nefficiency and performance. This paper proposes a novel lightweight multi-scale\nfeature extraction layer, termed the LMF layer, which employs depthwise\nseparable dilated convolutions in a fully connected structure. By integrating\nmultiple LMF layers, we develop LMFNet, a lightweight network tailored for\nsalient object detection. Our approach significantly reduces the number of\nparameters while maintaining competitive performance. Here, we show that LMFNet\nachieves state-of-the-art or comparable results on five benchmark datasets with\nonly 0.81M parameters, outperforming several traditional and lightweight models\nin terms of both efficiency and accuracy. Our work not only addresses the\nchallenge of multi-scale learning in lightweight networks but also demonstrates\nthe potential for broader applications in image processing tasks. The related\ncode files are available at https://github.com/Shi-Yun-peng/LMFNet", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLMF\u5c42\u548cLMFNet\u7528\u4e8e\u663e\u8457\u76ee\u6807\u68c0\u6d4b\uff0c\u51cf\u5c11\u53c2\u6570\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u597d\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3\u8f7b\u91cf\u7ea7\u7f51\u7edc\u4e2d\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u5728\u6548\u7387\u548c\u6027\u80fd\u95f4\u7684\u5e73\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faLMF\u5c42\uff0c\u91c7\u7528\u6df1\u5ea6\u53ef\u5206\u79bb\u6269\u5f20\u5377\u79ef\u7684\u5168\u8fde\u63a5\u7ed3\u6784\uff0c\u96c6\u6210\u591a\u4e2aLMF\u5c42\u6784\u5efaLMFNet\u3002", "result": "LMFNet\u4ec50.81M\u53c2\u6570\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\u6216\u76f8\u5f53\u7ed3\u679c\uff0c\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u8d85\u8d8a\u591a\u4e2a\u4f20\u7edf\u548c\u8f7b\u91cf\u7ea7\u6a21\u578b\u3002", "conclusion": "\u89e3\u51b3\u8f7b\u91cf\u7ea7\u7f51\u7edc\u591a\u5c3a\u5ea6\u5b66\u4e60\u6311\u6218\uff0c\u5c55\u793a\u5728\u56fe\u50cf\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.07178", "pdf": "https://arxiv.org/pdf/2508.07178", "abs": "https://arxiv.org/abs/2508.07178", "authors": ["Kejin Liu", "Junhong Lian", "Xiang Ao", "Ningtao Wang", "Xing Fu", "Yu Cheng", "Weiqiang Wang", "Xinyu Liu"], "title": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by the 34th ACM International Conference on Information and\n  Knowledge Management (CIKM '25), Full Research Papers track", "summary": "Accurate personalized headline generation hinges on precisely capturing user\ninterests from historical behaviors. However, existing methods neglect\npersonalized-irrelevant click noise in entire historical clickstreams, which\nmay lead to hallucinated headlines that deviate from genuine user preferences.\nIn this paper, we reveal the detrimental impact of click noise on personalized\ngeneration quality through rigorous analysis in both user and news dimensions.\nBased on these insights, we propose a novel Personalized Headline Generation\nframework via Denoising Fake Interests from Implicit Feedback (PHG-DIF).\nPHG-DIF first employs dual-stage filtering to effectively remove clickstream\nnoise, identified by short dwell times and abnormal click bursts, and then\nleverages multi-level temporal fusion to dynamically model users' evolving and\nmulti-faceted interests for precise profiling. Moreover, we release DT-PENS, a\nnew benchmark dataset comprising the click behavior of 1,000 carefully curated\nusers and nearly 10,000 annotated personalized headlines with historical dwell\ntime annotations. Extensive experiments demonstrate that PHG-DIF substantially\nmitigates the adverse effects of click noise and significantly improves\nheadline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our\nframework implementation and dataset are available at\nhttps://github.com/liukejin-up/PHG-DIF.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u5386\u53f2\u70b9\u51fb\u6d41\u4e2d\u4e0e\u4e2a\u6027\u5316\u65e0\u5173\u7684\u70b9\u51fb\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u51faPHG - DIF\u6846\u67b6\u53bb\u566a\u5e76\u5efa\u6a21\u7528\u6237\u5174\u8da3\uff0c\u8fd8\u53d1\u5e03DT - PENS\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u5386\u53f2\u70b9\u51fb\u6d41\u4e2d\u7684\u70b9\u51fb\u566a\u58f0\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u6807\u9898\u53ef\u80fd\u504f\u79bb\u7528\u6237\u771f\u5b9e\u504f\u597d\uff0c\u5f71\u54cd\u4e2a\u6027\u5316\u6807\u9898\u751f\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51faPHG - DIF\u6846\u67b6\uff0c\u5148\u901a\u8fc7\u53cc\u9636\u6bb5\u8fc7\u6ee4\u53bb\u9664\u70b9\u51fb\u6d41\u566a\u58f0\uff0c\u518d\u5229\u7528\u591a\u7ea7\u65f6\u95f4\u878d\u5408\u52a8\u6001\u5efa\u6a21\u7528\u6237\u5174\u8da3\uff1b\u53d1\u5e03DT - PENS\u6570\u636e\u96c6\u3002", "result": "PHG - DIF\u663e\u8457\u51cf\u8f7b\u4e86\u70b9\u51fb\u566a\u58f0\u7684\u4e0d\u5229\u5f71\u54cd\uff0c\u63d0\u9ad8\u4e86\u6807\u9898\u8d28\u91cf\uff0c\u5728DT - PENS\u4e0a\u53d6\u5f97\u4e86\u6700\u4f18\u7ed3\u679c\u3002", "conclusion": "PHG - DIF\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u70b9\u51fb\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u5347\u4e2a\u6027\u5316\u6807\u9898\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2508.06772", "pdf": "https://arxiv.org/pdf/2508.06772", "abs": "https://arxiv.org/abs/2508.06772", "authors": ["Catherine Yeh", "Tara Menon", "Robin Singh Arya", "Helen He", "Moira Weigel", "Fernanda Vi\u00e9gas", "Martin Wattenberg"], "title": "Story Ribbons: Reimagining Storyline Visualizations with Large Language Models", "categories": ["cs.HC", "cs.CL", "cs.LG"], "comment": "Accepted to IEEE VIS 2025 (11 pages, 9 figures)", "summary": "Analyzing literature involves tracking interactions between characters,\nlocations, and themes. Visualization has the potential to facilitate the\nmapping and analysis of these complex relationships, but capturing structured\ninformation from unstructured story data remains a challenge. As large language\nmodels (LLMs) continue to advance, we see an opportunity to use their text\nprocessing and analysis capabilities to augment and reimagine existing\nstoryline visualization techniques. Toward this goal, we introduce an\nLLM-driven data parsing pipeline that automatically extracts relevant narrative\ninformation from novels and scripts. We then apply this pipeline to create\nStory Ribbons, an interactive visualization system that helps novice and expert\nliterary analysts explore detailed character and theme trajectories at multiple\nnarrative levels. Through pipeline evaluations and user studies with Story\nRibbons on 36 literary works, we demonstrate the potential of LLMs to\nstreamline narrative visualization creation and reveal new insights about\nfamiliar stories. We also describe current limitations of AI-based systems, and\ninteraction motifs designed to address these issues.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u89e3\u6790\u7ba1\u9053\uff0c\u521b\u5efaStory Ribbons\u53ef\u89c6\u5316\u7cfb\u7edf\u5206\u6790\u6587\u5b66\u4f5c\u54c1\uff0c\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53d9\u4e8b\u53ef\u89c6\u5316\u4e2d\u7684\u6f5c\u529b\u53ca\u5f53\u524d\u7cfb\u7edf\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u4ece\u975e\u7ed3\u6784\u5316\u6545\u4e8b\u6570\u636e\u4e2d\u83b7\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\u4ee5\u8fdb\u884c\u53ef\u89c6\u5316\u5206\u6790\u5b58\u5728\u6311\u6218\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u5904\u7406\u548c\u5206\u6790\u80fd\u529b\u6539\u8fdb\u73b0\u6709\u53d9\u4e8b\u53ef\u89c6\u5316\u6280\u672f\u3002", "method": "\u5f15\u5165LLM\u9a71\u52a8\u7684\u6570\u636e\u89e3\u6790\u7ba1\u9053\u81ea\u52a8\u63d0\u53d6\u5c0f\u8bf4\u548c\u5267\u672c\u4e2d\u7684\u53d9\u4e8b\u4fe1\u606f\uff0c\u521b\u5efaStory Ribbons\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u7cfb\u7edf\u3002", "result": "\u901a\u8fc7\u5bf936\u90e8\u6587\u5b66\u4f5c\u54c1\u7684\u7ba1\u9053\u8bc4\u4f30\u548c\u7528\u6237\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7b80\u5316\u53d9\u4e8b\u53ef\u89c6\u5316\u521b\u5efa\u3001\u63ed\u793a\u6545\u4e8b\u65b0\u89c1\u89e3\u7684\u6f5c\u529b\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u6709\u52a9\u4e8e\u53d9\u4e8b\u53ef\u89c6\u5316\uff0c\u4f46AI\u7cfb\u7edf\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4ea4\u4e92\u6a21\u5f0f\u6765\u89e3\u51b3\u95ee\u9898\u3002"}}
{"id": "2508.07183", "pdf": "https://arxiv.org/pdf/2508.07183", "abs": "https://arxiv.org/abs/2508.07183", "authors": ["Ahmed M. Abuzuraiq", "Philippe Pasquier"], "title": "Explainability-in-Action: Enabling Expressive Manipulation and Tacit Understanding by Bending Diffusion Models in ComfyUI", "categories": ["cs.HC", "cs.AI", "cs.LG", "cs.MM", "I.2; J.5"], "comment": "In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts\n  2025) arXiv:2406.14485", "summary": "Explainable AI (XAI) in creative contexts can go beyond transparency to\nsupport artistic engagement, modifiability, and sustained practice. While\ncurated datasets and training human-scale models can offer artists greater\nagency and control, large-scale generative models like text-to-image diffusion\nsystems often obscure these possibilities. We suggest that even large models\ncan be treated as creative materials if their internal structure is exposed and\nmanipulable. We propose a craft-based approach to explainability rooted in\nlong-term, hands-on engagement akin to Sch\\\"on's \"reflection-in-action\" and\ndemonstrate its application through a model-bending and inspection plugin\nintegrated into the node-based interface of ComfyUI. We demonstrate that by\ninteractively manipulating different parts of a generative model, artists can\ndevelop an intuition about how each component influences the output.", "AI": {"tldr": "\u63d0\u51fa\u4ee5\u5de5\u827a\u4e3a\u57fa\u7840\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7ComfyUI\u63d2\u4ef6\u5c55\u793a\u5176\u5e94\u7528\uff0c\u8ba9\u827a\u672f\u5bb6\u80fd\u7406\u89e3\u751f\u6210\u6a21\u578b\u7ec4\u4ef6\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002", "motivation": "\u5728\u521b\u610f\u573a\u666f\u4e2d\uff0c\u5927\u578b\u751f\u6210\u6a21\u578b\u5e38\u63a9\u76d6\u827a\u672f\u5bb6\u521b\u4f5c\u7684\u53ef\u80fd\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9\u6a21\u578b\u652f\u6301\u827a\u672f\u521b\u4f5c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u957f\u671f\u5b9e\u8df5\u53c2\u4e0e\u7684\u5de5\u827a\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u96c6\u6210\u5230ComfyUI\u7684\u63d2\u4ef6\u5c55\u793a\u5e94\u7528\u3002", "result": "\u827a\u672f\u5bb6\u901a\u8fc7\u4ea4\u4e92\u5f0f\u64cd\u4f5c\u751f\u6210\u6a21\u578b\u4e0d\u540c\u90e8\u5206\uff0c\u80fd\u5f62\u6210\u5404\u7ec4\u4ef6\u5982\u4f55\u5f71\u54cd\u8f93\u51fa\u7684\u76f4\u89c9\u3002", "conclusion": "\u5373\u4f7f\u662f\u5927\u578b\u6a21\u578b\uff0c\u82e5\u5176\u5185\u90e8\u7ed3\u6784\u53ef\u66b4\u9732\u548c\u64cd\u4f5c\uff0c\u4e5f\u80fd\u4f5c\u4e3a\u521b\u610f\u6750\u6599\u3002"}}
{"id": "2508.07185", "pdf": "https://arxiv.org/pdf/2508.07185", "abs": "https://arxiv.org/abs/2508.07185", "authors": ["Kabir Khan", "Priya Sharma", "Arjun Mehta", "Neha Gupta", "Ravi Narayanan"], "title": "DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; H.3.3; H.2.8"], "comment": "Preprint; 7 figures, 3 tables, 1 algorithm; v1. Code and data will be\n  released", "summary": "Large Language Models (LLMs) suffer from a critical limitation: their\nknowledge is static and quickly becomes outdated. Retraining these massive\nmodels is computationally prohibitive, while existing knowledge editing\ntechniques can be slow and may introduce unforeseen side effects. To address\nthis, we propose DySK-Attn, a novel framework that enables LLMs to efficiently\nintegrate real-time knowledge from a dynamic external source. Our approach\nsynergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated\ninstantaneously. The core of our framework is a sparse knowledge attention\nmechanism, which allows the LLM to perform a coarse-to-fine grained search,\nefficiently identifying and focusing on a small, highly relevant subset of\nfacts from the vast KG. This mechanism avoids the high computational cost of\ndense attention over the entire knowledge base and mitigates noise from\nirrelevant information. We demonstrate through extensive experiments on\ntime-sensitive question-answering tasks that DySK-Attn significantly\noutperforms strong baselines, including standard Retrieval-Augmented Generation\n(RAG) and model editing techniques, in both factual accuracy for updated\nknowledge and computational efficiency. Our framework offers a scalable and\neffective solution for building LLMs that can stay current with the\never-changing world.", "AI": {"tldr": "\u63d0\u51faDySK - Attn\u6846\u67b6\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u6574\u5408\u5b9e\u65f6\u77e5\u8bc6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u9759\u6001\u6613\u8fc7\u65f6\uff0c\u91cd\u65b0\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u6162\u4e14\u6709\u526f\u4f5c\u7528\u3002", "method": "\u63d0\u51faDySK - Attn\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\u534f\u540c\uff0c\u91c7\u7528\u7a00\u758f\u77e5\u8bc6\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u7c97\u5230\u7ec6\u641c\u7d22\u3002", "result": "\u5728\u65f6\u95f4\u654f\u611f\u95ee\u7b54\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cDySK - Attn\u5728\u66f4\u65b0\u77e5\u8bc6\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "DySK - Attn\u6846\u67b6\u4e3a\u6784\u5efa\u80fd\u8ddf\u4e0a\u4e16\u754c\u53d8\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07195", "pdf": "https://arxiv.org/pdf/2508.07195", "abs": "https://arxiv.org/abs/2508.07195", "authors": ["Yanru Sun", "Emadeldeen Eldele", "Zongxia Xie", "Yucheng Wang", "Wenzhe Niu", "Qinghua Hu", "Chee Keong Kwoh", "Min Wu"], "title": "Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have recently demonstrated impressive\ncapabilities in natural language processing due to their strong generalization\nand sequence modeling capabilities. However, their direct application to time\nseries forecasting remains challenging due to two fundamental issues: the\ninherent heterogeneity of temporal patterns and the modality gap between\ncontinuous numerical signals and discrete language representations. In this\nwork, we propose TALON, a unified framework that enhances LLM-based forecasting\nby modeling temporal heterogeneity and enforcing semantic alignment.\nSpecifically, we design a Heterogeneous Temporal Encoder that partitions\nmultivariate time series into structurally coherent segments, enabling\nlocalized expert modeling across diverse temporal patterns. To bridge the\nmodality gap, we introduce a Semantic Alignment Module that aligns temporal\nfeatures with LLM-compatible representations, enabling effective integration of\ntime series into language-based models while eliminating the need for\nhandcrafted prompts during inference. Extensive experiments on seven real-world\nbenchmarks demonstrate that TALON achieves superior performance across all\ndatasets, with average MSE improvements of up to 11\\% over recent\nstate-of-the-art methods. These results underscore the effectiveness of\nincorporating both pattern-aware and semantic-aware designs when adapting LLMs\nfor time series forecasting. The code is available at:\nhttps://github.com/syrGitHub/TALON.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTALON\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5b58\u5728\u65f6\u95f4\u6a21\u5f0f\u5f02\u8d28\u6027\u548c\u6a21\u6001\u5dee\u8ddd\u4e24\u4e2a\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5f02\u8d28\u65f6\u95f4\u7f16\u7801\u5668\u5bf9\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5206\u6bb5\uff0c\u5f15\u5165\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\u5f25\u5408\u6a21\u6001\u5dee\u8ddd\u3002", "result": "\u5728\u4e03\u4e2a\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTALON\u6027\u80fd\u4f18\u8d8a\uff0c\u5e73\u5747MSE\u6bd4\u73b0\u6709\u65b9\u6cd5\u6700\u591a\u63d0\u534711%\u3002", "conclusion": "\u5c06\u6a21\u5f0f\u611f\u77e5\u548c\u8bed\u4e49\u611f\u77e5\u8bbe\u8ba1\u878d\u5165\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2508.07196", "pdf": "https://arxiv.org/pdf/2508.07196", "abs": "https://arxiv.org/abs/2508.07196", "authors": ["Mike Thelwall"], "title": "Can Smaller Large Language Models Evaluate Research Quality?", "categories": ["cs.DL", "cs.AI"], "comment": null, "summary": "Although both Google Gemini (1.5 Flash) and ChatGPT (4o and 4o-mini) give\nresearch quality evaluation scores that correlate positively with expert scores\nin nearly all fields, and more strongly that citations in most, it is not known\nwhether this is true for smaller Large Language Models (LLMs). In response,\nthis article assesses Google's Gemma-3-27b-it, a downloadable LLM (60Gb). The\nresults for 104,187 articles show that Gemma-3-27b-it scores correlate\npositively with an expert research quality score proxy for all 34 Units of\nAssessment (broad fields) from the UK Research Excellence Framework 2021. The\nGemma-3-27b-it correlations have 83.8% of the strength of ChatGPT 4o and 94.7%\nof the strength of ChatGPT 4o-mini correlations. Differently from the two\nlarger LLMs, the Gemma-3-27b-it correlations do not increase substantially when\nthe scores are averaged across five repetitions, its scores tend to be lower,\nand its reports are relatively uniform in style. Overall, the results show that\nresearch quality score estimation can be conducted by offline LLMs, so this\ncapability is not an emergent property of the largest LLMs. Moreover, score\nimprovement through repetition is not a universal feature of LLMs. In\nconclusion, although the largest LLMs still have the highest research\nevaluation score estimation capability, smaller ones can also be used for this\ntask, and this can be helpful for cost saving or when secure offline processing\nis needed.", "AI": {"tldr": "\u6587\u7ae0\u8bc4\u4f30\u4e86Gemma - 3 - 27b - it\u5bf9\u7814\u7a76\u8d28\u91cf\u8bc4\u5206\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5b83\u4e0e\u4e13\u5bb6\u8bc4\u5206\u6b63\u76f8\u5173\uff0c\u867d\u80fd\u529b\u4e0d\u53ca\u5927\u6a21\u578b\uff0c\u4f46\u5c0f\u6a21\u578b\u4e5f\u53ef\u7528\u4e8e\u6b64\u4efb\u52a1\u3002", "motivation": "\u63a2\u7a76\u8f83\u5c0f\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u50cfGoogle Gemini\u548cChatGPT\u4e00\u6837\u7ed9\u51fa\u4e0e\u4e13\u5bb6\u8bc4\u5206\u6b63\u76f8\u5173\u7684\u7814\u7a76\u8d28\u91cf\u8bc4\u4f30\u5206\u6570\u3002", "method": "\u5bf9104,187\u7bc7\u6587\u7ae0\u8fdb\u884c\u8bc4\u4f30\uff0c\u7528Gemma - 3 - 27b - it\u6253\u5206\u5e76\u4e0e\u82f1\u56fd\u7814\u7a76\u5353\u8d8a\u6846\u67b62021\u768434\u4e2a\u8bc4\u4f30\u5355\u5143\u7684\u4e13\u5bb6\u7814\u7a76\u8d28\u91cf\u5206\u6570\u4ee3\u7406\u5bf9\u6bd4\u3002", "result": "Gemma - 3 - 27b - it\u5206\u6570\u4e0e\u4e13\u5bb6\u5206\u6570\u6b63\u76f8\u5173\uff0c\u76f8\u5173\u6027\u5f3a\u5ea6\u4e3aChatGPT 4o\u768483.8%\u548cChatGPT 4o - mini\u768494.7%\uff1b\u91cd\u590d\u6253\u5206\u65f6\u76f8\u5173\u6027\u65e0\u663e\u8457\u63d0\u5347\uff0c\u5206\u6570\u8f83\u4f4e\u4e14\u62a5\u544a\u98ce\u683c\u76f8\u5bf9\u7edf\u4e00\u3002", "conclusion": "\u867d\u5927\u6a21\u578b\u7814\u7a76\u8bc4\u4f30\u5206\u6570\u4f30\u8ba1\u80fd\u529b\u6700\u5f3a\uff0c\u4f46\u5c0f\u6a21\u578b\u4e5f\u53ef\u7528\u4e8e\u6b64\u4efb\u52a1\uff0c\u6709\u52a9\u4e8e\u8282\u7701\u6210\u672c\u6216\u8fdb\u884c\u5b89\u5168\u79bb\u7ebf\u5904\u7406\u3002"}}
{"id": "2508.06863", "pdf": "https://arxiv.org/pdf/2508.06863", "abs": "https://arxiv.org/abs/2508.06863", "authors": ["Hamidreza Asadian-Rad", "Hossein Soleimani", "Shahrokh Farahmand"], "title": "Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach", "categories": ["cs.MA", "cs.LG"], "comment": null, "summary": "Unmanned aerial vehicles (UAVs) have been recently utilized in multi-access\nedge computing (MEC) as edge servers. It is desirable to design UAVs'\ntrajectories and user to UAV assignments to ensure satisfactory service to the\nusers and energy efficient operation simultaneously. The posed optimization\nproblem is challenging to solve because: (i) The formulated problem is\nnon-convex, (ii) Due to the mobility of ground users, their future positions\nand channel gains are not known in advance, (iii) Local UAVs' observations\nshould be communicated to a central entity that solves the optimization\nproblem. The (semi-) centralized processing leads to communication overhead,\ncommunication/processing bottlenecks, lack of flexibility and scalability, and\nloss of robustness to system failures. To simultaneously address all these\nlimitations, we advocate a fully decentralized setup with no centralized\nentity. Each UAV obtains its local observation and then communicates with its\nimmediate neighbors only. After sharing information with neighbors, each UAV\ndetermines its next position via a locally run deep reinforcement learning\n(DRL) algorithm. None of the UAVs need to know the global communication graph.\nTwo main components of our proposed solution are (i) Graph attention layers\n(GAT), and (ii) Experience and parameter sharing proximal policy optimization\n(EPS-PPO). Our proposed approach eliminates all the limitations of\nsemi-centralized MADRL methods such as MAPPO and MA deep deterministic policy\ngradient (MADDPG), while guaranteeing a better performance than independent\nlocal DRLs such as in IPPO. Numerical results reveal notable performance gains\nin several different criteria compared to the existing MADDPG algorithm,\ndemonstrating the potential for offering a better performance, while utilizing\nlocal communications only.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5168\u5206\u6563\u5f0f\u8bbe\u7f6e\u89e3\u51b3\u65e0\u4eba\u673a\u8f68\u8ff9\u8bbe\u8ba1\u548c\u7528\u6237\u5206\u914d\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528\u56fe\u6ce8\u610f\u529b\u5c42\u548c\u7ecf\u9a8c\u53c2\u6570\u5171\u4eab\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff0c\u76f8\u6bd4\u73b0\u6709\u7b97\u6cd5\u6709\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u534a\u96c6\u4e2d\u5f0f\u5904\u7406\u5728\u89e3\u51b3\u65e0\u4eba\u673a\u8f68\u8ff9\u8bbe\u8ba1\u548c\u7528\u6237\u5206\u914d\u4f18\u5316\u95ee\u9898\u65f6\u5b58\u5728\u901a\u4fe1\u5f00\u9500\u3001\u74f6\u9888\u3001\u7f3a\u4e4f\u7075\u6d3b\u6027\u7b49\u5c40\u9650\u3002", "method": "\u91c7\u7528\u5168\u5206\u6563\u5f0f\u8bbe\u7f6e\uff0c\u6bcf\u67b6\u65e0\u4eba\u673a\u83b7\u53d6\u672c\u5730\u89c2\u6d4b\u5e76\u4e0e\u90bb\u5c45\u901a\u4fe1\uff0c\u901a\u8fc7\u672c\u5730\u8fd0\u884c\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u786e\u5b9a\u4e0b\u4e00\u4f4d\u7f6e\uff0c\u4f7f\u7528\u56fe\u6ce8\u610f\u529b\u5c42\u548c\u7ecf\u9a8c\u53c2\u6570\u5171\u4eab\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\u5728\u591a\u4e2a\u6807\u51c6\u4e0a\u6bd4\u73b0\u6709MADDPG\u7b97\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86\u534a\u96c6\u4e2d\u5f0fMADRL\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u4ec5\u5229\u7528\u672c\u5730\u901a\u4fe1\u5c31\u80fd\u63d0\u4f9b\u66f4\u597d\u6027\u80fd\u3002"}}
{"id": "2508.07201", "pdf": "https://arxiv.org/pdf/2508.07201", "abs": "https://arxiv.org/abs/2508.07201", "authors": ["Chaoqun Cui", "Caiyan Jia"], "title": "Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection", "categories": ["cs.SI", "cs.AI", "cs.CL"], "comment": "This paper is accepted by AAAI2024", "summary": "Rumor detection on social media has become increasingly important. Most\nexisting graph-based models presume rumor propagation trees (RPTs) have deep\nstructures and learn sequential stance features along branches. However,\nthrough statistical analysis on real-world datasets, we find RPTs exhibit wide\nstructures, with most nodes being shallow 1-level replies. To focus learning on\nintensive substructures, we propose Rumor Adaptive Graph Contrastive Learning\n(RAGCL) method with adaptive view augmentation guided by node centralities. We\nsummarize three principles for RPT augmentation: 1) exempt root nodes, 2)\nretain deep reply nodes, 3) preserve lower-level nodes in deep sections. We\nemploy node dropping, attribute masking and edge dropping with probabilities\nfrom centrality-based importance scores to generate views. A graph contrastive\nobjective then learns robust rumor representations. Extensive experiments on\nfour benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods.\nOur work reveals the wide-structure nature of RPTs and contributes an effective\ngraph contrastive learning approach tailored for rumor detection through\nprincipled adaptive augmentation. The proposed principles and augmentation\ntechniques can potentially benefit other applications involving tree-structured\ngraphs.", "AI": {"tldr": "\u73b0\u6709\u56fe\u6a21\u578b\u5047\u5b9a\u8c23\u8a00\u4f20\u64ad\u6811\u4e3a\u6df1\u5ea6\u7ed3\u6784\uff0c\u672c\u6587\u53d1\u73b0\u5176\u4e3a\u5bbd\u7ed3\u6784\uff0c\u63d0\u51faRAGCL\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5176\u539f\u7406\u548c\u6280\u672f\u6216\u6709\u76ca\u4e8e\u5176\u4ed6\u6811\u7ed3\u6784\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u8c23\u8a00\u68c0\u6d4b\u6a21\u578b\u5047\u5b9a\u8c23\u8a00\u4f20\u64ad\u6811\u4e3a\u6df1\u5ea6\u7ed3\u6784\uff0c\u4e0e\u5b9e\u9645\u60c5\u51b5\u4e0d\u7b26\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRumor Adaptive Graph Contrastive Learning (RAGCL) \u65b9\u6cd5\uff0c\u6839\u636e\u8282\u70b9\u4e2d\u5fc3\u6027\u8fdb\u884c\u81ea\u9002\u5e94\u89c6\u56fe\u589e\u5f3a\uff0c\u91c7\u7528\u8282\u70b9\u4e22\u5f03\u3001\u5c5e\u6027\u63a9\u7801\u548c\u8fb9\u4e22\u5f03\u751f\u6210\u89c6\u56fe\uff0c\u901a\u8fc7\u56fe\u5bf9\u6bd4\u76ee\u6807\u5b66\u4e60\u8c23\u8a00\u8868\u793a\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRAGCL\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u63ed\u793a\u4e86\u8c23\u8a00\u4f20\u64ad\u6811\u7684\u5bbd\u7ed3\u6784\u7279\u6027\uff0c\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u8c23\u8a00\u68c0\u6d4b\u7684\u6709\u6548\u56fe\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u5176\u539f\u7406\u548c\u589e\u5f3a\u6280\u672f\u53ef\u80fd\u6709\u76ca\u4e8e\u5176\u4ed6\u6d89\u53ca\u6811\u7ed3\u6784\u7684\u5e94\u7528\u3002"}}
{"id": "2508.06870", "pdf": "https://arxiv.org/pdf/2508.06870", "abs": "https://arxiv.org/abs/2508.06870", "authors": ["Gangular Singh Irengbam", "Nirvash Singh Wahengbam", "Lanthoiba Meitei Khumanthem", "Paikhomba Oinam"], "title": "Text to Speech System for Meitei Mayek Script", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "This paper presents the development of a Text-to-Speech (TTS) system for the\nManipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and\nHiFi-GAN, we introduce a neural TTS architecture adapted to support tonal\nphonology and under-resourced linguistic environments. We develop a phoneme\nmapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and\ndemonstrate intelligible and natural speech synthesis, validated through\nsubjective and objective metrics. This system lays the groundwork for\nlinguistic preservation and technological inclusion of Manipuri.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u57fa\u4e8eMeitei Mayek\u6587\u5b57\u7684\u66fc\u5c3c\u666e\u5c14\u8bedTTS\u7cfb\u7edf\uff0c\u5229\u7528Tacotron 2\u548cHiFi - GAN\u5b9e\u73b0\u8bed\u97f3\u5408\u6210\uff0c\u4e3a\u8bed\u8a00\u4fdd\u62a4\u548c\u6280\u672f\u878d\u5165\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u66fc\u5c3c\u666e\u5c14\u8bed\u7684TTS\u7cfb\u7edf\uff0c\u4ee5\u652f\u6301\u8be5\u8bed\u8a00\u7684\u8bed\u97f3\u5408\u6210\uff0c\u4fc3\u8fdb\u8bed\u8a00\u4fdd\u62a4\u548c\u6280\u672f\u878d\u5165\u3002", "method": "\u5229\u7528Tacotron 2\u548cHiFi - GAN\u642d\u5efa\u9002\u5e94\u58f0\u8c03\u97f3\u97f5\u548c\u8d44\u6e90\u532e\u4e4f\u8bed\u8a00\u73af\u5883\u7684\u795e\u7ecfTTS\u67b6\u6784\uff0c\u5f00\u53d1Meitei Mayek\u5230ARPAbet\u7684\u97f3\u7d20\u6620\u5c04\uff0c\u6574\u7406\u5355\u8bf4\u8bdd\u4eba\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u7406\u89e3\u4e14\u81ea\u7136\u7684\u8bed\u97f3\u5408\u6210\uff0c\u901a\u8fc7\u4e3b\u89c2\u548c\u5ba2\u89c2\u6307\u6807\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u66fc\u5c3c\u666e\u5c14\u8bed\u7684\u8bed\u8a00\u4fdd\u62a4\u548c\u6280\u672f\u878d\u5165\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.07207", "pdf": "https://arxiv.org/pdf/2508.07207", "abs": "https://arxiv.org/abs/2508.07207", "authors": ["S. Akshay", "A. R. Balasubramanian", "Supratik Chakraborty", "Georg Zetzsche"], "title": "Presburger Functional Synthesis: Complexity and Tractable Normal Forms", "categories": ["cs.LO", "cs.AI"], "comment": "Full version of conference paper at KR 2025 (22nd International\n  Conference on Principles of Knowledge Representation and Reasoning)", "summary": "Given a relational specification between inputs and outputs as a logic\nformula, the problem of functional synthesis is to automatically synthesize a\nfunction from inputs to outputs satisfying the relation. Recently, a rich line\nof work has emerged tackling this problem for specifications in different\ntheories, from Boolean to general first-order logic. In this paper, we launch\nan investigation of this problem for the theory of Presburger Arithmetic, that\nwe call Presburger Functional Synthesis (PFnS). We show that PFnS can be solved\nin EXPTIME and provide a matching exponential lower bound. This is unlike the\ncase for Boolean functional synthesis (BFnS), where only conditional\nexponential lower bounds are known. Further, we show that PFnS for one input\nand one output variable is as hard as BFnS in general. We then identify a\nspecial normal form, called PSyNF, for the specification formula that\nguarantees poly-time and poly-size solvability of PFnS. We prove several\nproperties of PSyNF, including how to check and compile to this form, and\nconditions under which any other form that guarantees poly-time solvability of\nPFnS can be compiled in poly-time to PSyNF. Finally, we identify a syntactic\nnormal form that is easier to check but is exponentially less succinct than\nPSyNF.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76Presburger\u7b97\u672f\u7684\u51fd\u6570\u5408\u6210\u95ee\u9898\uff08PFnS\uff09\uff0c\u8bc1\u660e\u5176\u53ef\u5728EXPTIME\u5185\u6c42\u89e3\uff0c\u7ed9\u51fa\u5339\u914d\u7684\u6307\u6570\u4e0b\u754c\uff0c\u5206\u6790\u4e0e\u5e03\u5c14\u51fd\u6570\u5408\u6210\uff08BFnS\uff09\u7684\u5173\u7cfb\uff0c\u627e\u5230\u7279\u6b8a\u8303\u5f0fPSyNF\u4fdd\u8bc1PFnS\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u89c4\u6a21\u53ef\u89e3\u6027\uff0c\u8fd8\u7ed9\u51fa\u4e00\u79cd\u66f4\u6613\u68c0\u67e5\u4f46\u7b80\u6d01\u6027\u8f83\u5dee\u7684\u8303\u5f0f\u3002", "motivation": "\u9488\u5bf9\u4e0d\u540c\u7406\u8bba\u4e0b\u7684\u51fd\u6570\u5408\u6210\u95ee\u9898\u7814\u7a76\u73b0\u72b6\uff0c\u5bf9Presburger\u7b97\u672f\u7684\u51fd\u6570\u5408\u6210\u95ee\u9898\u5c55\u5f00\u7814\u7a76\u3002", "method": "\u7406\u8bba\u5206\u6790\u548c\u8bc1\u660e\uff0c\u5305\u62ec\u590d\u6742\u5ea6\u5206\u6790\u3001\u8303\u5f0f\u6027\u8d28\u8bc1\u660e\u7b49\u3002", "result": "\u8bc1\u660ePFnS\u53ef\u5728EXPTIME\u5185\u6c42\u89e3\uff0c\u7ed9\u51fa\u6307\u6570\u4e0b\u754c\uff1b\u53d1\u73b0PFnS\u5355\u8f93\u5165\u5355\u8f93\u51fa\u4e0eBFnS\u96be\u5ea6\u76f8\u5f53\uff1b\u627e\u5230PSyNF\u8303\u5f0f\u4fdd\u8bc1\u591a\u9879\u5f0f\u53ef\u89e3\u6027\uff1b\u7ed9\u51fa\u66f4\u6613\u68c0\u67e5\u4f46\u7b80\u6d01\u6027\u5dee\u7684\u8303\u5f0f\u3002", "conclusion": "\u5bf9Presburger\u7b97\u672f\u7684\u51fd\u6570\u5408\u6210\u95ee\u9898\u6709\u4e86\u8f83\u4e3a\u6df1\u5165\u7684\u7814\u7a76\uff0c\u660e\u786e\u4e86\u590d\u6742\u5ea6\u3001\u4e0eBFnS\u5173\u7cfb\u4ee5\u53ca\u4e0d\u540c\u8303\u5f0f\u7684\u6027\u8d28\u548c\u4f5c\u7528\u3002"}}
{"id": "2508.06884", "pdf": "https://arxiv.org/pdf/2508.06884", "abs": "https://arxiv.org/abs/2508.06884", "authors": ["Alexander Tyurin"], "title": "Near-Optimal Convergence of Accelerated Gradient Methods under Generalized and $(L_0, L_1)$-Smoothness", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "We study first-order methods for convex optimization problems with functions\n$f$ satisfying the recently proposed $\\ell$-smoothness condition\n$||\\nabla^{2}f(x)|| \\le \\ell\\left(||\\nabla f(x)||\\right),$ which generalizes\nthe $L$-smoothness and $(L_{0},L_{1})$-smoothness. While accelerated gradient\ndescent AGD is known to reach the optimal complexity $O(\\sqrt{L} R /\n\\sqrt{\\varepsilon})$ under $L$-smoothness, where $\\varepsilon$ is an error\ntolerance and $R$ is the distance between a starting and an optimal point,\nexisting extensions to $\\ell$-smoothness either incur extra dependence on the\ninitial gradient, suffer exponential factors in $L_{1} R$, or require costly\nauxiliary sub-routines, leaving open whether an AGD-type $O(\\sqrt{\\ell(0)} R /\n\\sqrt{\\varepsilon})$ rate is possible for small-$\\varepsilon$, even in the\n$(L_{0},L_{1})$-smoothness case.\n  We resolve this open question. Leveraging a new Lyapunov function and\ndesigning new algorithms, we achieve $O(\\sqrt{\\ell(0)} R / \\sqrt{\\varepsilon})$\noracle complexity for small-$\\varepsilon$ and virtually any $\\ell$. For\ninstance, for $(L_{0},L_{1})$-smoothness, our bound $O(\\sqrt{L_0} R /\n\\sqrt{\\varepsilon})$ is provably optimal in the small-$\\varepsilon$ regime and\nremoves all non-constant multiplicative factors present in prior accelerated\nalgorithms.", "AI": {"tldr": "\u7814\u7a76\u6ee1\u8db3\u2113 - \u5e73\u6ed1\u6761\u4ef6\u7684\u51f8\u4f18\u5316\u95ee\u9898\u7684\u4e00\u9636\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86AGD\u578b\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u2113 - \u5e73\u6ed1\u6761\u4ef6\u4e0b\u7684\u65b9\u6cd5\u5b58\u5728\u4f9d\u8d56\u521d\u59cb\u68af\u5ea6\u3001\u6709\u6307\u6570\u56e0\u5b50\u6216\u9700\u6602\u8d35\u8f85\u52a9\u5b50\u7a0b\u5e8f\u7b49\u95ee\u9898\uff0c\u8981\u89e3\u51b3AGD\u578bO(\u221a\u2113(0)R / \u221a\u03b5)\u590d\u6742\u5ea6\u662f\u5426\u53ef\u884c\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u65b0\u7684Lyapunov\u51fd\u6570\u5e76\u8bbe\u8ba1\u65b0\u7b97\u6cd5\u3002", "result": "\u5bf9\u4e8e\u5c0f\u03b5\u548c\u4efb\u610f\u2113\uff0c\u5b9e\u73b0\u4e86O(\u221a\u2113(0)R / \u221a\u03b5)\u7684oracle\u590d\u6742\u5ea6\uff0c\u5728\u5c0f\u03b5\u60c5\u51b5\u4e0b(L\u2080,L\u2081) - \u5e73\u6ed1\u7684\u754cO(\u221aL\u2080R / \u221a\u03b5)\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u89e3\u51b3\u4e86\u5728\u2113 - \u5e73\u6ed1\u6761\u4ef6\u4e0bAGD\u578b\u590d\u6742\u5ea6\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u65b0\u7b97\u6cd5\u6709\u66f4\u597d\u7684\u590d\u6742\u5ea6\u8868\u73b0\u3002"}}
{"id": "2508.06906", "pdf": "https://arxiv.org/pdf/2508.06906", "abs": "https://arxiv.org/abs/2508.06906", "authors": ["Morteza Kimiaei", "Vyacheslav Kungurtsev", "Brian Olimba"], "title": "Machine Learning Algorithms for Improving Exact Classical Solvers in Mixed Integer Continuous Optimization", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Integer and mixed-integer nonlinear programming (INLP, MINLP) are central to\nlogistics, energy, and scheduling, but remain computationally challenging. This\nsurvey examines how machine learning and reinforcement learning can enhance\nexact optimization methods - particularly branch-and-bound (BB), without\ncompromising global optimality. We cover discrete, continuous, and\nmixed-integer formulations, and highlight applications such as crew scheduling,\nvehicle routing, and hydropower planning. We introduce a unified BB framework\nthat embeds learning-based strategies into branching, cut selection, node\nordering, and parameter control. Classical algorithms are augmented using\nsupervised, imitation, and reinforcement learning models to accelerate\nconvergence while maintaining correctness. We conclude with a taxonomy of\nlearning methods by solver class and learning paradigm, and outline open\nchallenges in generalization, hybridization, and scaling intelligent solvers.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u673a\u5668\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u5982\u4f55\u589e\u5f3a\u6574\u6570\u548c\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u7684\u7cbe\u786e\u4f18\u5316\u65b9\u6cd5\uff0c\u4ecb\u7ecd\u7edf\u4e00\u6846\u67b6\uff0c\u6700\u540e\u7ed9\u51fa\u5b66\u4e60\u65b9\u6cd5\u5206\u7c7b\u5e76\u6307\u51fa\u6311\u6218\u3002", "motivation": "\u6574\u6570\u548c\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u5728\u591a\u4e2a\u9886\u57df\u91cd\u8981\u4f46\u8ba1\u7b97\u6709\u6311\u6218\uff0c\u9700\u589e\u5f3a\u7cbe\u786e\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u7684\u5206\u652f\u5b9a\u754c\u6846\u67b6\uff0c\u5d4c\u5165\u57fa\u4e8e\u5b66\u4e60\u7684\u7b56\u7565\uff0c\u7528\u76d1\u7763\u3001\u6a21\u4eff\u548c\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u589e\u5f3a\u7ecf\u5178\u7b97\u6cd5\u3002", "result": "\u53ef\u5728\u4fdd\u6301\u6b63\u786e\u6027\u7684\u540c\u65f6\u52a0\u901f\u6536\u655b\u3002", "conclusion": "\u7ed9\u51fa\u6309\u6c42\u89e3\u5668\u7c7b\u522b\u548c\u5b66\u4e60\u8303\u5f0f\u7684\u5b66\u4e60\u65b9\u6cd5\u5206\u7c7b\uff0c\u6307\u51fa\u6cdb\u5316\u3001\u6df7\u5408\u548c\u6269\u5c55\u667a\u80fd\u6c42\u89e3\u5668\u65b9\u9762\u7684\u6311\u6218\u3002"}}
{"id": "2508.06913", "pdf": "https://arxiv.org/pdf/2508.06913", "abs": "https://arxiv.org/abs/2508.06913", "authors": ["Siyuan Li", "Xi Lin", "Guangyan Li", "Zehao Liu", "Aodu Wulianghai", "Li Ding", "Jun Wu", "Jianhua Li"], "title": "Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has resulted in\nincreasingly sophisticated AI-generated content, posing significant challenges\nin distinguishing LLM-generated text from human-written language. Existing\ndetection methods, primarily based on lexical heuristics or fine-tuned\nclassifiers, often suffer from limited generalizability and are vulnerable to\nparaphrasing, adversarial perturbations, and cross-domain shifts. In this work,\nwe propose SentiDetect, a model-agnostic framework for detecting LLM-generated\ntext by analyzing the divergence in sentiment distribution stability. Our\nmethod is motivated by the empirical observation that LLM outputs tend to\nexhibit emotionally consistent patterns, whereas human-written texts display\ngreater emotional variability. To capture this phenomenon, we define two\ncomplementary metrics: sentiment distribution consistency and sentiment\ndistribution preservation, which quantify stability under sentiment-altering\nand semantic-preserving transformations. We evaluate SentiDetect on five\ndiverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro,\nClaude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its\nsuperiority over state-of-the-art baselines, with over 16% and 11% F1 score\nimprovements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover,\nSentiDetect also shows greater robustness to paraphrasing, adversarial attacks,\nand text length variations, outperforming existing detectors in challenging\nscenarios.", "AI": {"tldr": "\u63d0\u51faSentiDetect\u6846\u67b6\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\uff0c\u5728\u591a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\u6cdb\u5316\u6027\u6709\u9650\uff0c\u6613\u53d7\u6539\u5199\u3001\u5bf9\u6297\u6270\u52a8\u548c\u8de8\u9886\u57df\u5f71\u54cd\u3002", "method": "\u63d0\u51faSentiDetect\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u60c5\u611f\u5206\u5e03\u7a33\u5b9a\u6027\u5dee\u5f02\u68c0\u6d4b\uff0c\u5b9a\u4e49\u60c5\u611f\u5206\u5e03\u4e00\u81f4\u6027\u548c\u4fdd\u7559\u6027\u4e24\u4e2a\u4e92\u8865\u6307\u6807\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u548c\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0cF1\u5206\u6570\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u63d0\u5347\uff0c\u5bf9\u6539\u5199\u3001\u5bf9\u6297\u653b\u51fb\u548c\u6587\u672c\u957f\u5ea6\u53d8\u5316\u66f4\u9c81\u68d2\u3002", "conclusion": "SentiDetect\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u6311\u6218\u6027\u573a\u666f\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2508.07273", "pdf": "https://arxiv.org/pdf/2508.07273", "abs": "https://arxiv.org/abs/2508.07273", "authors": ["Qiongqiong Wang", "Hardik B. Sailor", "Jeremy H. M. Wong", "Tianchi Liu", "Shuo Sun", "Wenyu Zhang", "Muhammad Huzaifah", "Nancy Chen", "Ai Ti Aw"], "title": "Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models", "categories": ["cs.CL", "cs.AI", "eess.AS"], "comment": "Accepted at (ASRU 2025) 2025 IEEE Automatic Speech Recognition and\n  Understanding Workshop", "summary": "Current large speech language models (Speech-LLMs) often exhibit limitations\nin empathetic reasoning, primarily due to the absence of training datasets that\nintegrate both contextual content and paralinguistic cues. In this work, we\npropose two approaches to incorporate contextual paralinguistic information\ninto model training: (1) an explicit method that provides paralinguistic\nmetadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit\nmethod that automatically generates novel training question-answer (QA) pairs\nusing both categorical and dimensional emotion annotations alongside speech\ntranscriptions. Our implicit method boosts performance (LLM-judged) by 38.41%\non a human-annotated QA benchmark, reaching 46.02% when combined with the\nexplicit approach, showing effectiveness in contextual paralinguistic\nunderstanding. We also validate the LLM judge by demonstrating its correlation\nwith classification metrics, providing support for its reliability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u5c06\u4e0a\u4e0b\u6587\u526f\u8bed\u8a00\u4fe1\u606f\u878d\u5165\u6a21\u578b\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u9690\u5f0f\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\uff0c\u7ed3\u5408\u663e\u5f0f\u65b9\u6cd5\u6548\u679c\u66f4\u4f73\uff0c\u5e76\u9a8c\u8bc1\u4e86LLM\u8bc4\u5224\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u5728\u5171\u60c5\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u539f\u56e0\u662f\u7f3a\u4e4f\u6574\u5408\u4e0a\u4e0b\u6587\u5185\u5bb9\u548c\u526f\u8bed\u8a00\u7ebf\u7d22\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a\u663e\u5f0f\u65b9\u6cd5\u76f4\u63a5\u5411\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u526f\u8bed\u8a00\u5143\u6570\u636e\uff1b\u9690\u5f0f\u65b9\u6cd5\u5229\u7528\u5206\u7c7b\u548c\u7ef4\u5ea6\u60c5\u611f\u6ce8\u91ca\u4e0e\u8bed\u97f3\u8f6c\u5f55\u81ea\u52a8\u751f\u6210\u65b0\u7684\u8bad\u7ec3\u95ee\u7b54\u5bf9\u3002", "result": "\u9690\u5f0f\u65b9\u6cd5\u5728\u4eba\u5de5\u6807\u6ce8\u7684\u95ee\u7b54\u57fa\u51c6\u4e0a\u4f7fLLM\u8bc4\u5224\u7684\u6027\u80fd\u63d0\u534738.41%\uff0c\u4e0e\u663e\u5f0f\u65b9\u6cd5\u7ed3\u5408\u65f6\u8fbe\u523046.02%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u4e0a\u4e0b\u6587\u526f\u8bed\u8a00\u7406\u89e3\u65b9\u9762\u6709\u6548\uff0c\u4e14LLM\u8bc4\u5224\u5177\u6709\u53ef\u9760\u6027\u3002"}}
{"id": "2508.06996", "pdf": "https://arxiv.org/pdf/2508.06996", "abs": "https://arxiv.org/abs/2508.06996", "authors": ["M. Adeel Ajaib", "Fariha Nasir", "Abdul Rehman"], "title": "Explainable AI for Curie Temperature Prediction in Magnetic Materials", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": "6 pages, 5 figures", "summary": "We explore machine learning techniques for predicting Curie temperatures of\nmagnetic materials using the NEMAD database. By augmenting the dataset with\ncomposition-based and domain-aware descriptors, we evaluate the performance of\nseveral machine learning models. We find that the Extra Trees Regressor\ndelivers the best performance reaching an R^2 score of up to 0.85 $\\pm$ 0.01\n(cross-validated) for a balanced dataset. We employ the k-means clustering\nalgorithm to gain insights into the performance of chemically distinct material\ngroups. Furthermore, we perform the SHAP analysis to identify key\nphysicochemical drivers of Curie behavior, such as average atomic number and\nmagnetic moment. By employing explainable AI techniques, this analysis offers\ninsights into the model's predictive behavior, thereby advancing scientific\ninterpretability.", "AI": {"tldr": "\u4f7f\u7528NEMAD\u6570\u636e\u5e93\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u6280\u672f\u9884\u6d4b\u78c1\u6027\u6750\u6599\u5c45\u91cc\u6e29\u5ea6\uff0cExtra Trees Regressor\u8868\u73b0\u6700\u4f73\uff0c\u8fd8\u7528\u805a\u7c7b\u548cSHAP\u5206\u6790\u3002", "motivation": "\u63a2\u7d22\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u9884\u6d4b\u78c1\u6027\u6750\u6599\u5c45\u91cc\u6e29\u5ea6\u3002", "method": "\u7528NEMAD\u6570\u636e\u5e93\uff0c\u7528\u57fa\u4e8e\u6210\u5206\u548c\u9886\u57df\u611f\u77e5\u7684\u63cf\u8ff0\u7b26\u6269\u5145\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u591a\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7528k-means\u805a\u7c7b\u7b97\u6cd5\u548cSHAP\u5206\u6790\u3002", "result": "Extra Trees Regressor\u8868\u73b0\u6700\u4f73\uff0c\u5e73\u8861\u6570\u636e\u96c6\u4ea4\u53c9\u9a8c\u8bc1R^2\u5f97\u5206\u8fbe0.85 \u00b1 0.01\u3002", "conclusion": "\u53ef\u89e3\u91caAI\u6280\u672f\u5206\u6790\u4e3a\u6a21\u578b\u9884\u6d4b\u884c\u4e3a\u63d0\u4f9b\u89c1\u89e3\uff0c\u63d0\u5347\u79d1\u5b66\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.07279", "pdf": "https://arxiv.org/pdf/2508.07279", "abs": "https://arxiv.org/abs/2508.07279", "authors": ["Vasudha Varadarajan", "Hui Xu", "Rebecca Astrid Boehme", "Mariam Marlan Mirstrom", "Sverker Sikstrom", "H. Andrew Schwartz"], "title": "MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) offer new opportunities for\nscalable, interactive mental health assessment, but excessive querying by LLMs\nburdens users and is inefficient for real-world screening across\ntransdiagnostic symptom profiles. We introduce MAQuA, an adaptive\nquestion-asking framework for simultaneous, multidimensional mental health\nscreening. Combining multi-outcome modeling on language responses with item\nresponse theory (IRT) and factor analysis, MAQuA selects the questions with\nmost informative responses across multiple dimensions at each turn to optimize\ndiagnostic information, improving accuracy and potentially reducing response\nburden. Empirical results on a novel dataset reveal that MAQuA reduces the\nnumber of assessment questions required for score stabilization by 50-87%\ncompared to random ordering (e.g., achieving stable depression scores with 71%\nfewer questions and eating disorder scores with 85% fewer questions). MAQuA\ndemonstrates robust performance across both internalizing (depression, anxiety)\nand externalizing (substance use, eating disorder) domains, with early stopping\nstrategies further reducing patient time and burden. These findings position\nMAQuA as a powerful and efficient tool for scalable, nuanced, and interactive\nmental health screening, advancing the integration of LLM-based agents into\nreal-world clinical workflows.", "AI": {"tldr": "\u63d0\u51faMAQuA\u6846\u67b6\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u7b5b\u67e5\uff0c\u80fd\u51cf\u5c11\u95ee\u9898\u6570\u91cf\uff0c\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u4e2d\u5b58\u5728\u67e5\u8be2\u8fc7\u591a\u3001\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u7b5b\u67e5\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u8bed\u8a00\u54cd\u5e94\u7684\u591a\u7ed3\u679c\u5efa\u6a21\u3001\u9879\u76ee\u53cd\u5e94\u7406\u8bba\uff08IRT\uff09\u548c\u56e0\u5b50\u5206\u6790\uff0c\u6bcf\u8f6e\u9009\u62e9\u591a\u7ef4\u5ea6\u6700\u5177\u4fe1\u606f\u6027\u54cd\u5e94\u7684\u95ee\u9898\u3002", "result": "\u5728\u65b0\u6570\u636e\u96c6\u4e0a\uff0cMAQuA\u4f7f\u5206\u6570\u7a33\u5b9a\u6240\u9700\u7684\u8bc4\u4f30\u95ee\u9898\u6570\u91cf\u51cf\u5c1150 - 87%\uff0c\u5728\u5185\u5916\u5316\u9886\u57df\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "MAQuA\u662f\u5f3a\u5927\u9ad8\u6548\u7684\u5fc3\u7406\u5065\u5eb7\u7b5b\u67e5\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5c06\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u96c6\u6210\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2508.07281", "pdf": "https://arxiv.org/pdf/2508.07281", "abs": "https://arxiv.org/abs/2508.07281", "authors": ["Hongbo Zhu", "Angelo Cangelosi"], "title": "Representation Understanding via Activation Maximization", "categories": ["cs.CV", "cs.AI"], "comment": "7 pages,12 figures", "summary": "Understanding internal feature representations of deep neural networks (DNNs)\nis a fundamental step toward model interpretability. Inspired by neuroscience\nmethods that probe biological neurons using visual stimuli, recent deep\nlearning studies have employed Activation Maximization (AM) to synthesize\ninputs that elicit strong responses from artificial neurons. In this work, we\npropose a unified feature visualization framework applicable to both\nConvolutional Neural Networks (CNNs) and Vision Transformers (ViTs). Unlike\nprior efforts that predominantly focus on the last output-layer neurons in\nCNNs, we extend feature visualization to intermediate layers as well, offering\ndeeper insights into the hierarchical structure of learned feature\nrepresentations. Furthermore, we investigate how activation maximization can be\nleveraged to generate adversarial examples, revealing potential vulnerabilities\nand decision boundaries of DNNs. Our experiments demonstrate the effectiveness\nof our approach in both traditional CNNs and modern ViT, highlighting its\ngeneralizability and interpretive value.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8eCNN\u548cViT\u7684\u7edf\u4e00\u7279\u5f81\u53ef\u89c6\u5316\u6846\u67b6\uff0c\u5c06\u7279\u5f81\u53ef\u89c6\u5316\u62d3\u5c55\u5230\u4e2d\u95f4\u5c42\uff0c\u8fd8\u7814\u7a76\u7528\u6fc0\u6d3b\u6700\u5927\u5316\u751f\u6210\u5bf9\u6297\u6837\u672c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u7406\u89e3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u7279\u5f81\u8868\u793a\uff0c\u5b9e\u73b0\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7279\u5f81\u53ef\u89c6\u5316\u6846\u67b6\uff0c\u5c06\u7279\u5f81\u53ef\u89c6\u5316\u62d3\u5c55\u5230\u4e2d\u95f4\u5c42\uff0c\u7814\u7a76\u7528\u6fc0\u6d3b\u6700\u5927\u5316\u751f\u6210\u5bf9\u6297\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4f20\u7edfCNN\u548c\u73b0\u4ee3ViT\u4e2d\u5747\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u901a\u7528\u6027\u548c\u89e3\u91ca\u4ef7\u503c\u3002"}}
{"id": "2508.07283", "pdf": "https://arxiv.org/pdf/2508.07283", "abs": "https://arxiv.org/abs/2508.07283", "authors": ["Bujar Raufi"], "title": "Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment", "categories": ["cs.HC", "cs.AI", "eess.SP", "q-bio.NC", "97R40", "I.2"], "comment": "17 Pages, 7 figures, 3 tables and one prompt template", "summary": "This study explores the intersection of electroencephalography (EEG)\nmicrostates and Large Language Models (LLMs) to enhance the assessment of\ncognitive load states. By utilizing EEG microstate features, the research aims\nto fine-tune LLMs for improved predictions of distinct cognitive states,\nspecifically 'Rest' and 'Load'. The experimental design is delineated in four\ncomprehensive stages: dataset collection and preprocessing, microstate\nsegmentation and EEG backfitting, feature extraction paired with prompt\nengineering, and meticulous LLM model selection and refinement. Employing a\nsupervised learning paradigm, the LLM is trained to identify cognitive load\nstates based on EEG microstate features integrated into prompts, producing\naccurate discrimination of cognitive load. A curated dataset, linking EEG\nfeatures to specified cognitive load conditions, underpins the experimental\nframework. The results indicate a significant improvement in model performance\nfollowing the proposed fine-tuning, showcasing the potential of EEG-informed\nLLMs in cognitive neuroscience and cognitive AI applications. This approach not\nonly contributes to the understanding of brain dynamics but also paves the way\nfor advancements in machine learning techniques applicable to cognitive load\nand cognitive AI research.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22EEG\u5fae\u72b6\u6001\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u4ee5\u8bc4\u4f30\u8ba4\u77e5\u8d1f\u8377\u72b6\u6001\uff0c\u7ecf\u591a\u9636\u6bb5\u5b9e\u9a8c\u8bbe\u8ba1\u5fae\u8c03\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u6027\u80fd\u63d0\u5347\uff0c\u6709\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u63a2\u7d22EEG\u5fae\u72b6\u6001\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u53c9\u70b9\uff0c\u4ee5\u589e\u5f3a\u5bf9\u8ba4\u77e5\u8d1f\u8377\u72b6\u6001\u7684\u8bc4\u4f30\u3002", "method": "\u5b9e\u9a8c\u5206\u56db\u9636\u6bb5\uff1a\u6570\u636e\u96c6\u6536\u96c6\u4e0e\u9884\u5904\u7406\u3001\u5fae\u72b6\u6001\u5206\u5272\u4e0eEEG\u56de\u62df\u5408\u3001\u7279\u5f81\u63d0\u53d6\u4e0e\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u9009\u62e9\u4e0e\u4f18\u5316\uff0c\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5fae\u8c03\u540e\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u7406\u89e3\u5927\u8111\u52a8\u529b\u5b66\uff0c\u4e3a\u8ba4\u77e5\u8d1f\u8377\u548c\u8ba4\u77e5AI\u7814\u7a76\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u8fdb\u6b65\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.07020", "pdf": "https://arxiv.org/pdf/2508.07020", "abs": "https://arxiv.org/abs/2508.07020", "authors": ["Tanjim Bin Faruk", "Abdul Matin", "Shrideep Pallickara", "Sangmi Lee Pallickara"], "title": "TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Hyperspectral satellite imagery offers sub-30 m views of Earth in hundreds of\ncontiguous spectral bands, enabling fine-grained mapping of soils, crops, and\nland cover. While self-supervised Masked Autoencoders excel on RGB and low-band\nmultispectral data, they struggle to exploit the intricate spatial-spectral\ncorrelations in 200+ band hyperspectral images. We introduce TerraMAE, a novel\nHSI encoding framework specifically designed to learn highly representative\nspatial-spectral embeddings for diverse geospatial analyses. TerraMAE features\nan adaptive channel grouping strategy, based on statistical reflectance\nproperties to capture spectral similarities, and an enhanced reconstruction\nloss function that incorporates spatial and spectral quality metrics. We\ndemonstrate TerraMAE's effectiveness through superior spatial-spectral\ninformation preservation in high-fidelity image reconstruction. Furthermore, we\nvalidate its practical utility and the quality of its learned representations\nthrough strong performance on three key downstream geospatial tasks: crop\nidentification, land cover classification, and soil texture prediction.", "AI": {"tldr": "\u63d0\u51faTerraMAE\u7528\u4e8e\u9ad8\u5149\u8c31\u56fe\u50cf\u7f16\u7801\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u81ea\u76d1\u7763\u63a9\u7801\u81ea\u7f16\u7801\u5668\u96be\u4ee5\u5229\u7528200+\u6ce2\u6bb5\u9ad8\u5149\u8c31\u56fe\u50cf\u590d\u6742\u7684\u7a7a\u95f4 - \u5149\u8c31\u76f8\u5173\u6027\uff0c\u9700\u65b0\u6846\u67b6\u7528\u4e8e\u5730\u7406\u7a7a\u95f4\u5206\u6790\u3002", "method": "\u5f15\u5165TerraMAE\u6846\u67b6\uff0c\u6709\u57fa\u4e8e\u7edf\u8ba1\u53cd\u5c04\u7279\u6027\u7684\u81ea\u9002\u5e94\u901a\u9053\u5206\u7ec4\u7b56\u7565\u548c\u7ed3\u5408\u7a7a\u95f4\u4e0e\u5149\u8c31\u8d28\u91cf\u6307\u6807\u7684\u589e\u5f3a\u91cd\u5efa\u635f\u5931\u51fd\u6570\u3002", "result": "TerraMAE\u5728\u9ad8\u4fdd\u771f\u56fe\u50cf\u91cd\u5efa\u4e2d\u80fd\u66f4\u597d\u5730\u4fdd\u7559\u7a7a\u95f4 - \u5149\u8c31\u4fe1\u606f\uff0c\u5728\u4f5c\u7269\u8bc6\u522b\u3001\u571f\u5730\u8986\u76d6\u5206\u7c7b\u548c\u571f\u58e4\u8d28\u5730\u9884\u6d4b\u4e09\u4e2a\u5173\u952e\u4e0b\u6e38\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "TerraMAE\u80fd\u5b66\u4e60\u5177\u6709\u9ad8\u5ea6\u4ee3\u8868\u6027\u7684\u7a7a\u95f4 - \u5149\u8c31\u5d4c\u5165\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5730\u7406\u7a7a\u95f4\u5206\u6790\u3002"}}
{"id": "2508.07284", "pdf": "https://arxiv.org/pdf/2508.07284", "abs": "https://arxiv.org/abs/2508.07284", "authors": ["Junchen Ding", "Penghao Jiang", "Zihao Xu", "Ziqi Ding", "Yichen Zhu", "Jiaojiao Jiang", "Yuekang Li"], "title": "\"Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "As large language models (LLMs) increasingly mediate ethically sensitive\ndecisions, understanding their moral reasoning processes becomes imperative.\nThis study presents a comprehensive empirical evaluation of 14 leading LLMs,\nboth reasoning enabled and general purpose, across 27 diverse trolley problem\nscenarios, framed by ten moral philosophies, including utilitarianism,\ndeontology, and altruism. Using a factorial prompting protocol, we elicited\n3,780 binary decisions and natural language justifications, enabling analysis\nalong axes of decisional assertiveness, explanation answer consistency, public\nmoral alignment, and sensitivity to ethically irrelevant cues. Our findings\nreveal significant variability across ethical frames and model types: reasoning\nenhanced models demonstrate greater decisiveness and structured justifications,\nyet do not always align better with human consensus. Notably, \"sweet zones\"\nemerge in altruistic, fairness, and virtue ethics framings, where models\nachieve a balance of high intervention rates, low explanation conflict, and\nminimal divergence from aggregated human judgments. However, models diverge\nunder frames emphasizing kinship, legality, or self interest, often producing\nethically controversial outcomes. These patterns suggest that moral prompting\nis not only a behavioral modifier but also a diagnostic tool for uncovering\nlatent alignment philosophies across providers. We advocate for moral reasoning\nto become a primary axis in LLM alignment, calling for standardized benchmarks\nthat evaluate not just what LLMs decide, but how and why.", "AI": {"tldr": "\u7814\u7a76\u5bf914\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u572827\u4e2a\u7535\u8f66\u96be\u9898\u573a\u666f\u4e0b\u8fdb\u884c\u9053\u5fb7\u63a8\u7406\u8bc4\u4f30\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u4f26\u7406\u6846\u67b6\u548c\u7c7b\u578b\u4e0b\u8868\u73b0\u6709\u5dee\u5f02\uff0c\u5efa\u8bae\u5c06\u9053\u5fb7\u63a8\u7406\u4f5c\u4e3a\u5927\u6a21\u578b\u5bf9\u9f50\u7684\u4e3b\u8981\u7ef4\u5ea6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9053\u5fb7\u654f\u611f\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u7406\u89e3\u5176\u9053\u5fb7\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u5bf914\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u572827\u4e2a\u7535\u8f66\u96be\u9898\u573a\u666f\u4e0b\uff0c\u57fa\u4e8e\u5341\u79cd\u9053\u5fb7\u54f2\u5b66\u8fdb\u884c\u8bc4\u4f30\uff0c\u91c7\u7528\u56e0\u5b50\u63d0\u793a\u534f\u8bae\u83b7\u53d6\u51b3\u7b56\u548c\u89e3\u91ca\u3002", "result": "\u4e0d\u540c\u4f26\u7406\u6846\u67b6\u548c\u6a21\u578b\u7c7b\u578b\u8868\u73b0\u5dee\u5f02\u5927\uff0c\u63a8\u7406\u589e\u5f3a\u6a21\u578b\u66f4\u679c\u65ad\u4f46\u4e0d\u4e00\u5b9a\u66f4\u7b26\u5408\u4eba\u7c7b\u5171\u8bc6\uff0c\u90e8\u5206\u4f26\u7406\u6846\u67b6\u4e0b\u6709\u201c\u751c\u871c\u533a\u201d\uff0c\u90e8\u5206\u6846\u67b6\u4e0b\u6a21\u578b\u4ea7\u751f\u6709\u4e89\u8bae\u7ed3\u679c\u3002", "conclusion": "\u9053\u5fb7\u63d0\u793a\u53ef\u4f5c\u4e3a\u8bca\u65ad\u5de5\u5177\uff0c\u5e94\u5c06\u9053\u5fb7\u63a8\u7406\u4f5c\u4e3a\u5927\u6a21\u578b\u5bf9\u9f50\u7684\u4e3b\u8981\u7ef4\u5ea6\uff0c\u5efa\u7acb\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2508.07304", "pdf": "https://arxiv.org/pdf/2508.07304", "abs": "https://arxiv.org/abs/2508.07304", "authors": ["Fabio Vitali"], "title": "From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "This paper introduces a new family of cognitive modal logics designed to\nformalize conjectural reasoning: a modal system in which cognitive contexts\nextend known facts with hypothetical assumptions to explore their consequences.\nUnlike traditional doxastic and epistemic systems, conjectural logics rely on a\nprinciple, called Axiom C ($\\varphi \\rightarrow \\Box\\varphi$), that ensures\nthat all established facts are preserved across hypothetical layers. While\nAxiom C was dismissed in the past due to its association with modal collapse,\nwe show that the collapse only arises under classical and bivalent assumptions,\nand specifically in the presence of Axiom T. Hence we avoid Axiom T and adopt a\nparacomplete semantic framework, grounded in Weak Kleene logic or Description\nLogic, where undefined propositions coexist with modal assertions. This\nprevents the modal collapse and guarantees a layering to distinguish between\nfactual and conjectural statements. Under this framework we define new modal\nsystems, e.g., KC and KDC, and show that they are complete, decidable, and\nrobust under partial knowledge. Finally, we introduce a dynamic operation,\n$\\mathsf{settle}(\\varphi)$, which formalizes the transition from conjecture to\naccepted fact, capturing the event of the update of a world's cognitive state\nthrough the resolution of uncertainty.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.07306", "pdf": "https://arxiv.org/pdf/2508.07306", "abs": "https://arxiv.org/abs/2508.07306", "authors": ["Md Zahurul Haquea", "Yeahyea Sarker", "Muhammed Farhan Sadique Mahi", "Syed Jubayer Jaman", "Md Robiul Islam"], "title": "DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Dragon fruit, renowned for its nutritional benefits and economic value, has\nexperienced rising global demand due to its affordability and local\navailability. As dragon fruit cultivation expands, efficient pre- and\npost-harvest quality inspection has become essential for improving agricultural\nproductivity and minimizing post-harvest losses. This study presents\nDragonFruitQualityNet, a lightweight Convolutional Neural Network (CNN)\noptimized for real-time quality assessment of dragon fruits on mobile devices.\nWe curated a diverse dataset of 13,789 images, integrating self-collected\nsamples with public datasets (dataset from Mendeley Data), and classified them\ninto four categories: fresh, immature, mature, and defective fruits to ensure\nrobust model training. The proposed model achieves an impressive 93.98%\naccuracy, outperforming existing methods in fruit quality classification. To\nfacilitate practical adoption, we embedded the model into an intuitive mobile\napplication, enabling farmers and agricultural stakeholders to conduct\non-device, real-time quality inspections. This research provides an accurate,\nefficient, and scalable AI-driven solution for dragon fruit quality control,\nsupporting digital agriculture and empowering smallholder farmers with\naccessible technology. By bridging the gap between research and real-world\napplication, our work advances post-harvest management and promotes sustainable\nfarming practices.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7CNN\u6a21\u578bDragonFruitQualityNet\u7528\u4e8e\u706b\u9f99\u679c\u5b9e\u65f6\u8d28\u91cf\u8bc4\u4f30\uff0c\u51c6\u786e\u738793.98%\uff0c\u5d4c\u5165\u624b\u673a\u5e94\u7528\uff0c\u4e3a\u706b\u9f99\u679c\u8d28\u91cf\u63a7\u5236\u63d0\u4f9bAI\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u706b\u9f99\u679c\u79cd\u690d\u6269\u5927\uff0c\u9ad8\u6548\u7684\u91c7\u524d\u548c\u91c7\u540e\u8d28\u91cf\u68c0\u6d4b\u5bf9\u63d0\u9ad8\u519c\u4e1a\u751f\u4ea7\u529b\u548c\u51cf\u5c11\u91c7\u540e\u635f\u5931\u81f3\u5173\u91cd\u8981\u3002", "method": "\u521b\u5efa\u5305\u542b13789\u5f20\u56fe\u50cf\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u5c06\u56fe\u50cf\u5206\u4e3a\u65b0\u9c9c\u3001\u672a\u6210\u719f\u3001\u6210\u719f\u548c\u6709\u7f3a\u9677\u56db\u7c7b\uff1b\u63d0\u51fa\u8f7b\u91cf\u7ea7CNN\u6a21\u578bDragonFruitQualityNet\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u51c6\u786e\u7387\u8fbe93.98%\uff0c\u4f18\u4e8e\u73b0\u6709\u6c34\u679c\u8d28\u91cf\u5206\u7c7b\u65b9\u6cd5\uff1b\u5c06\u6a21\u578b\u5d4c\u5165\u624b\u673a\u5e94\u7528\u3002", "conclusion": "\u7814\u7a76\u4e3a\u706b\u9f99\u679c\u8d28\u91cf\u63a7\u5236\u63d0\u4f9b\u51c6\u786e\u3001\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684AI\u89e3\u51b3\u65b9\u6848\uff0c\u4fc3\u8fdb\u91c7\u540e\u7ba1\u7406\u548c\u53ef\u6301\u7eed\u519c\u4e1a\u5b9e\u8df5\u3002"}}
{"id": "2508.07062", "pdf": "https://arxiv.org/pdf/2508.07062", "abs": "https://arxiv.org/abs/2508.07062", "authors": ["Jason C. Furtado", "Maria J. Molina", "Marybeth C. Arcodia", "Weston Anderson", "Tom Beucler", "John A. Callahan", "Laura M. Ciasto", "Vittorio A. Gensini", "Michelle L'Heureux", "Kathleen Pegion", "Jhayron S. P\u00e9rez-Carrasquilla", "Maike Sonnewald", "Ken Takahashi", "Baoqiang Xiang", "Brian G. Zimmerman"], "title": "Taking the Garbage Out of Data-Driven Prediction Across Climate Timescales", "categories": ["physics.data-an", "cs.LG", "physics.ao-ph"], "comment": "24 pages, 4 figures, 3 tables", "summary": "Artificial intelligence (AI) -- and specifically machine learning (ML) --\napplications for climate prediction across timescales are proliferating\nquickly. The emergence of these methods prompts a revisit to the impact of data\npreprocessing, a topic familiar to the climate community, as more traditional\nstatistical models work with relatively small sample sizes. Indeed, the skill\nand confidence in the forecasts produced by data-driven models are directly\ninfluenced by the quality of the datasets and how they are treated during model\ndevelopment, thus yielding the colloquialism \"garbage in, garbage out.\" As\nsuch, this article establishes protocols for the proper preprocessing of input\ndata for AI/ML models designed for climate prediction (i.e., subseasonal to\ndecadal and longer). The three aims are to: (1) educate researchers,\ndevelopers, and end users on the effects that preprocessing has on climate\npredictions; (2) provide recommended practices for data preprocessing for such\napplications; and (3) empower end users to decipher whether the models they are\nusing are properly designed for their objectives. Specific topics covered in\nthis article include the creation of (standardized) anomalies, dealing with\nnon-stationarity and the spatiotemporally correlated nature of climate data,\nand handling of extreme values and variables with potentially complex\ndistributions. Case studies will illustrate how using different preprocessing\ntechniques can produce different predictions from the same model, which can\ncreate confusion and decrease confidence in the overall process. Ultimately,\nimplementing the recommended practices set forth in this article will enhance\nthe robustness and transparency of AI/ML in climate prediction studies.", "AI": {"tldr": "\u6587\u7ae0\u4e3a\u6c14\u5019\u9884\u6d4b\u7684AI/ML\u6a21\u578b\u8f93\u5165\u6570\u636e\u9884\u5904\u7406\u5236\u5b9a\u534f\u8bae\uff0c\u4ecb\u7ecd\u76f8\u5173\u8bdd\u9898\u548c\u6848\u4f8b\uff0c\u5f3a\u8c03\u5b9e\u65bd\u63a8\u8350\u505a\u6cd5\u53ef\u589e\u5f3a\u6c14\u5019\u9884\u6d4b\u7814\u7a76\u7684\u7a33\u5065\u6027\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u968f\u7740AI/ML\u5728\u6c14\u5019\u9884\u6d4b\u5e94\u7528\u589e\u591a\uff0c\u4f20\u7edf\u7edf\u8ba1\u6a21\u578b\u6837\u672c\u5c0f\uff0c\u6570\u636e\u9884\u5904\u7406\u5f71\u54cd\u6a21\u578b\u9884\u6d4b\u6280\u80fd\u548c\u4fe1\u5fc3\uff0c\u9700\u91cd\u65b0\u5ba1\u89c6\u5176\u5f71\u54cd\u3002", "method": "\u5efa\u7acb\u6c14\u5019\u9884\u6d4bAI/ML\u6a21\u578b\u8f93\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u534f\u8bae\uff0c\u6db5\u76d6\u521b\u5efa\u6807\u51c6\u5316\u5f02\u5e38\u503c\u3001\u5904\u7406\u975e\u5e73\u7a33\u6027\u548c\u65f6\u7a7a\u76f8\u5173\u6027\u3001\u5904\u7406\u6781\u503c\u548c\u590d\u6742\u5206\u5e03\u53d8\u91cf\u7b49\u3002", "result": "\u4e0d\u540c\u9884\u5904\u7406\u6280\u672f\u4f1a\u4f7f\u540c\u4e00\u6a21\u578b\u4ea7\u751f\u4e0d\u540c\u9884\u6d4b\u7ed3\u679c\uff0c\u9020\u6210\u56f0\u60d1\u5e76\u964d\u4f4e\u6574\u4f53\u8fc7\u7a0b\u7684\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u5b9e\u65bd\u6587\u7ae0\u4e2d\u7684\u63a8\u8350\u505a\u6cd5\u80fd\u589e\u5f3a\u6c14\u5019\u9884\u6d4b\u7814\u7a76\u4e2dAI/ML\u7684\u7a33\u5065\u6027\u548c\u900f\u660e\u5ea6\u3002"}}
{"id": "2508.07307", "pdf": "https://arxiv.org/pdf/2508.07307", "abs": "https://arxiv.org/abs/2508.07307", "authors": ["Haiyang Guo", "Fei Zhu", "Hongbo Zhao", "Fanhu Zeng", "Wenzhuo Liu", "Shijie Ma", "Da-Han Wang", "Xu-Yao Zhang"], "title": "MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint", "summary": "Continual learning aims to equip AI systems with the ability to continuously\nacquire and adapt to new knowledge without forgetting previously learned\ninformation, similar to human learning. While traditional continual learning\nmethods focusing on unimodal tasks have achieved notable success, the emergence\nof Multimodal Large Language Models has brought increasing attention to\nMultimodal Continual Learning tasks involving multiple modalities, such as\nvision and language. In this setting, models are expected to not only mitigate\ncatastrophic forgetting but also handle the challenges posed by cross-modal\ninteractions and coordination. To facilitate research in this direction, we\nintroduce MCITlib, a comprehensive and constantly evolving code library for\ncontinual instruction tuning of Multimodal Large Language Models. In MCITlib,\nwe have currently implemented 8 representative algorithms for Multimodal\nContinual Instruction Tuning and systematically evaluated them on 2 carefully\nselected benchmarks. MCITlib will be continuously updated to reflect advances\nin the Multimodal Continual Learning field. The codebase is released at\nhttps://github.com/Ghy0501/MCITlib.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u7684\u4ee3\u7801\u5e93MCITlib\uff0c\u542b8\u79cd\u7b97\u6cd5\uff0c\u57282\u4e2a\u57fa\u51c6\u4e0a\u8bc4\u4f30\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u4f20\u7edf\u5355\u6a21\u6001\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u6210\u529f\uff0c\u4f46\u591a\u6a21\u6001\u6301\u7eed\u5b66\u4e60\u53d7\u5173\u6ce8\uff0c\u9700\u5e94\u5bf9\u8de8\u6a21\u6001\u4ea4\u4e92\u7b49\u6311\u6218\uff0c\u63a8\u52a8\u8be5\u65b9\u5411\u7814\u7a76\u3002", "method": "\u5f15\u5165MCITlib\u4ee3\u7801\u5e93\uff0c\u5b9e\u73b08\u79cd\u591a\u6a21\u6001\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u7b97\u6cd5\uff0c\u5e76\u57282\u4e2a\u7cbe\u5fc3\u6311\u9009\u7684\u57fa\u51c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5b8c\u6210MCITlib\u4ee3\u7801\u5e93\u642d\u5efa\uff0c\u5b9e\u73b08\u79cd\u7b97\u6cd5\u5e76\u5b8c\u6210\u8bc4\u4f30\uff0c\u4ee3\u7801\u5e93\u4f1a\u6301\u7eed\u66f4\u65b0\u3002", "conclusion": "MCITlib\u80fd\u63a8\u52a8\u591a\u6a21\u6001\u6301\u7eed\u5b66\u4e60\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2508.07065", "pdf": "https://arxiv.org/pdf/2508.07065", "abs": "https://arxiv.org/abs/2508.07065", "authors": ["Haodi Jiang", "Qin Li", "Jason T. L. Wang", "Haimin Wang", "Serena Criscuoli"], "title": "Reconstruction of Solar EUV Irradiance Using CaII K Images and SOHO/SEM Data with Bayesian Deep Learning and Uncertainty Quantification", "categories": ["astro-ph.SR", "astro-ph.IM", "cs.LG"], "comment": "18 pages, 10 figures", "summary": "Solar extreme ultraviolet (EUV) irradiance plays a crucial role in heating\nthe Earth's ionosphere, thermosphere, and mesosphere, affecting atmospheric\ndynamics over varying time scales. Although significant effort has been spent\nstudying short-term EUV variations from solar transient events, there is little\nwork to explore the long-term evolution of the EUV flux over multiple solar\ncycles. Continuous EUV flux measurements have only been available since 1995,\nleaving significant gaps in earlier data. In this study, we propose a Bayesian\ndeep learning model, named SEMNet, to fill the gaps. We validate our approach\nby applying SEMNet to construct SOHO/SEM EUV flux measurements in the period\nbetween 1998 and 2014 using CaII K images from the Precision Solar Photometric\nTelescope. We then extend SEMNet through transfer learning to reconstruct solar\nEUV irradiance in the period between 1950 and 1960 using CaII K images from the\nKodaikanal Solar Observatory. Experimental results show that SEMNet provides\nreliable predictions along with uncertainty bounds, demonstrating the\nfeasibility of CaII K images as a robust proxy for long-term EUV fluxes. These\nfindings contribute to a better understanding of solar influences on Earth's\nclimate over extended periods.", "AI": {"tldr": "\u63d0\u51fa\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bSEMNet\u586b\u8865\u592a\u9633EUV\u901a\u91cf\u6570\u636e\u7f3a\u53e3\uff0c\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u5e76\u62d3\u5c55\u5e94\u7528\uff0c\u52a9\u4e8e\u957f\u671f\u592a\u9633\u5bf9\u5730\u7403\u6c14\u5019\u5f71\u54cd\u7814\u7a76\u3002", "motivation": "\u592a\u9633EUV\u8f90\u7167\u5ea6\u5bf9\u5730\u7403\u5927\u6c14\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u7f3a\u4e4f\u591a\u592a\u9633\u5468\u671fEUV\u901a\u91cf\u957f\u671f\u6f14\u53d8\u7814\u7a76\u4e14\u65e9\u671f\u6570\u636e\u6709\u7f3a\u53e3\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bSEMNet\uff0c\u7528CaII K\u56fe\u50cf\u6784\u5efaEUV\u901a\u91cf\u6d4b\u91cf\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u62d3\u5c55\u5e94\u7528\u3002", "result": "SEMNet\u80fd\u63d0\u4f9b\u53ef\u9760\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u8fb9\u754c\uff0c\u8bc1\u660eCaII K\u56fe\u50cf\u53ef\u4f5c\u4e3a\u957f\u671fEUV\u901a\u91cf\u53ef\u9760\u66ff\u4ee3\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u7406\u89e3\u592a\u9633\u5bf9\u5730\u7403\u6c14\u5019\u7684\u957f\u671f\u5f71\u54cd\u3002"}}
{"id": "2508.07315", "pdf": "https://arxiv.org/pdf/2508.07315", "abs": "https://arxiv.org/abs/2508.07315", "authors": ["Lilit Grigoryan", "Vladimir Bataev", "Nikolay Karpov", "Andrei Andrusenko", "Vitaly Lavrukhin", "Boris Ginsburg"], "title": "FlexCTC: GPU-powered CTC Beam Decoding with advanced Contextual Abilities", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "comment": "Accepted to Automatic Speech Recognition and Understanding Workshop\n  (ASRU) 2025", "summary": "While beam search improves speech recognition quality over greedy decoding,\nstandard implementations are slow, often sequential, and CPU-bound. To fully\nleverage modern hardware capabilities, we present a novel open-source FlexCTC\ntoolkit for fully GPU-based beam decoding, designed for Connectionist Temporal\nClassification (CTC) models. Developed entirely in Python and PyTorch, it\noffers a fast, user-friendly, and extensible alternative to traditional C++,\nCUDA, or WFST-based decoders. The toolkit features a high-performance, fully\nbatched GPU implementation with eliminated CPU-GPU synchronization and\nminimized kernel launch overhead via CUDA Graphs. It also supports advanced\ncontextualization techniques, including GPU-powered N-gram language model\nfusion and phrase-level boosting. These features enable accurate and efficient\ndecoding, making them suitable for both research and production use.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u57fa\u4e8eCTC\u6a21\u578b\u7684\u5168GPU\u675f\u89e3\u7801\u7684\u5f00\u6e90FlexCTC\u5de5\u5177\u5305\uff0c\u5177\u6709\u5feb\u901f\u3001\u6613\u7528\u548c\u53ef\u6269\u5c55\u7684\u7279\u70b9\uff0c\u9002\u7528\u4e8e\u7814\u7a76\u548c\u751f\u4ea7\u3002", "motivation": "\u6807\u51c6\u675f\u641c\u7d22\u5b9e\u73b0\u901f\u5ea6\u6162\u3001\u5e38\u4e3a\u987a\u5e8f\u6267\u884c\u4e14\u53d7CPU\u9650\u5236\uff0c\u4e3a\u5145\u5206\u5229\u7528\u73b0\u4ee3\u786c\u4ef6\u80fd\u529b\u3002", "method": "\u7528Python\u548cPyTorch\u5f00\u53d1FlexCTC\u5de5\u5177\u5305\uff0c\u91c7\u7528\u5168\u6279\u5904\u7406GPU\u5b9e\u73b0\uff0c\u901a\u8fc7CUDA Graphs\u6d88\u9664CPU - GPU\u540c\u6b65\u5e76\u6700\u5c0f\u5316\u5185\u6838\u542f\u52a8\u5f00\u9500\uff0c\u652f\u6301\u9ad8\u7ea7\u4e0a\u4e0b\u6587\u6280\u672f\u3002", "result": "\u5b9e\u73b0\u4e86\u51c6\u786e\u9ad8\u6548\u7684\u89e3\u7801\u3002", "conclusion": "\u8be5\u5de5\u5177\u5305\u9002\u5408\u7814\u7a76\u548c\u751f\u4ea7\u4f7f\u7528\u3002"}}
{"id": "2508.07086", "pdf": "https://arxiv.org/pdf/2508.07086", "abs": "https://arxiv.org/abs/2508.07086", "authors": ["Beilong Tang", "Xiaoxiao Miao", "Xin Wang", "Ming Li"], "title": "SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "8 pages, 3 figures, accepted by 2025 IEEE Automatic Speech\n  Recognition and Understanding Workshop (ASRU)", "summary": "Voice anonymization protects speaker privacy by concealing identity while\npreserving linguistic and paralinguistic content. Self-supervised learning\n(SSL) representations encode linguistic features but preserve speaker traits.\nWe propose a novel speaker-embedding-free framework called SEF-MK. Instead of\nusing a single k-means model trained on the entire dataset, SEF-MK anonymizes\nSSL representations for each utterance by randomly selecting one of multiple\nk-means models, each trained on a different subset of speakers. We explore this\napproach from both attacker and user perspectives. Extensive experiments show\nthat, compared to a single k-means model, SEF-MK with multiple k-means models\nbetter preserves linguistic and emotional content from the user's viewpoint.\nHowever, from the attacker's perspective, utilizing multiple k-means models\nboosts the effectiveness of privacy attacks. These insights can aid users in\ndesigning voice anonymization systems to mitigate attacker threats.", "AI": {"tldr": "\u63d0\u51faSEF - MK\u6846\u67b6\u5bf9\u8bed\u97f3SSL\u8868\u5f81\u8fdb\u884c\u533f\u540d\u5316\uff0c\u4ece\u653b\u9632\u89c6\u89d2\u5b9e\u9a8c\uff0c\u53d1\u73b0\u591ak - means\u6a21\u578b\u5728\u4fdd\u7559\u5185\u5bb9\u548c\u9690\u79c1\u653b\u51fb\u65b9\u9762\u6709\u4e0d\u540c\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u81ea\u76d1\u7763\u5b66\u4e60\u8868\u5f81\u5728\u7f16\u7801\u8bed\u8a00\u7279\u5f81\u65f6\u4f1a\u4fdd\u7559\u8bf4\u8bdd\u4eba\u7279\u5f81\uff0c\u9700\u63a2\u7d22\u66f4\u597d\u7684\u8bed\u97f3\u533f\u540d\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSEF - MK\u6846\u67b6\uff0c\u4e3a\u6bcf\u4e2a\u8bdd\u8bed\u968f\u673a\u9009\u62e9\u591a\u4e2ak - means\u6a21\u578b\u4e4b\u4e00\u5bf9SSL\u8868\u5f81\u8fdb\u884c\u533f\u540d\u5316\uff0c\u6bcf\u4e2a\u6a21\u578b\u5728\u4e0d\u540c\u8bf4\u8bdd\u4eba\u5b50\u96c6\u4e0a\u8bad\u7ec3\u3002", "result": "\u4ece\u7528\u6237\u89d2\u5ea6\uff0c\u591ak - means\u6a21\u578b\u7684SEF - MK\u80fd\u66f4\u597d\u4fdd\u7559\u8bed\u8a00\u548c\u60c5\u611f\u5185\u5bb9\uff1b\u4ece\u653b\u51fb\u8005\u89d2\u5ea6\uff0c\u591ak - means\u6a21\u578b\u63d0\u9ad8\u4e86\u9690\u79c1\u653b\u51fb\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u7528\u6237\u8bbe\u8ba1\u8bed\u97f3\u533f\u540d\u5316\u7cfb\u7edf\u4ee5\u51cf\u8f7b\u653b\u51fb\u8005\u5a01\u80c1\u3002"}}
{"id": "2508.07321", "pdf": "https://arxiv.org/pdf/2508.07321", "abs": "https://arxiv.org/abs/2508.07321", "authors": ["Shubhra Ghosh", "Abhilekh Borah", "Aditya Kumar Guru", "Kripabandhu Ghosh"], "title": "ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": null, "summary": "The rapid proliferation of Large Language Models (LLMs) has significantly\ncontributed to the development of equitable AI systems capable of factual\nquestion-answering (QA). However, no known study tests the LLMs' robustness\nwhen presented with obfuscated versions of questions. To systematically\nevaluate these limitations, we propose a novel technique, ObfusQAte and,\nleveraging the same, introduce ObfusQA, a comprehensive, first of its kind,\nframework with multi-tiered obfuscation levels designed to examine LLM\ncapabilities across three distinct dimensions: (i) Named-Entity Indirection,\n(ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these\nfine-grained distinctions in language, ObfusQA provides a comprehensive\nbenchmark for evaluating LLM robustness and adaptability. Our study observes\nthat LLMs exhibit a tendency to fail or generate hallucinated responses when\nconfronted with these increasingly nuanced variations. To foster research in\nthis direction, we make ObfusQAte publicly available.", "AI": {"tldr": "\u63d0\u51faObfusQA\u6846\u67b6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u9762\u5bf9\u6df7\u6dc6\u95ee\u9898\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u6613\u5931\u8d25\u6216\u4ea7\u751f\u5e7b\u89c9\u56de\u7b54\uff0c\u4e14\u516c\u5f00ObfusQAte\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u9762\u5bf9\u6df7\u6dc6\u95ee\u9898\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30\u5176\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faObfusQAte\u6280\u672f\uff0c\u5f15\u5165ObfusQA\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u3001\u591a\u5c42\u7ea7\u7684\u6df7\u6dc6\u6c34\u5e73\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u9762\u5bf9\u7ec6\u5fae\u53d8\u5316\u7684\u6df7\u6dc6\u95ee\u9898\u65f6\uff0c\u6613\u5931\u8d25\u6216\u4ea7\u751f\u5e7b\u89c9\u56de\u7b54\u3002", "conclusion": "ObfusQA\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u63d0\u4f9b\u4e86\u7efc\u5408\u57fa\u51c6\uff0c\u516c\u5f00ObfusQAte\u4ee5\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2508.07104", "pdf": "https://arxiv.org/pdf/2508.07104", "abs": "https://arxiv.org/abs/2508.07104", "authors": ["Yaswitha Gujju", "Romain Harang", "Chao Li", "Tetsuo Shibuya", "Qibin Zhao"], "title": "QuProFS: An Evolutionary Training-free Approach to Efficient Quantum Feature Map Search", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "The quest for effective quantum feature maps for data encoding presents\nsignificant challenges, particularly due to the flat training landscapes and\nlengthy training processes associated with parameterised quantum circuits. To\naddress these issues, we propose an evolutionary training-free quantum\narchitecture search (QAS) framework that employs circuit-based heuristics\nfocused on trainability, hardware robustness, generalisation ability,\nexpressivity, complexity, and kernel-target alignment. By ranking circuit\narchitectures with various proxies, we reduce evaluation costs and incorporate\nhardware-aware circuits to enhance robustness against noise. We evaluate our\napproach on classification tasks (using quantum support vector machine) across\ndiverse datasets using both artificial and quantum-generated datasets. Our\napproach demonstrates competitive accuracy on both simulators and real quantum\nhardware, surpassing state-of-the-art QAS methods in terms of sampling\nefficiency and achieving up to a 2x speedup in architecture search runtime.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u7684\u91cf\u5b50\u67b6\u6784\u641c\u7d22\u6846\u67b6\uff0c\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u8bad\u7ec3\u666f\u89c2\u5e73\u5766\u548c\u8bad\u7ec3\u8fc7\u7a0b\u957f\u7684\u95ee\u9898\uff0c\u5bfb\u627e\u6709\u6548\u7684\u91cf\u5b50\u7279\u5f81\u6620\u5c04\u8fdb\u884c\u6570\u636e\u7f16\u7801\u3002", "method": "\u63d0\u51fa\u8fdb\u5316\u65e0\u8bad\u7ec3\u91cf\u5b50\u67b6\u6784\u641c\u7d22\u6846\u67b6\uff0c\u7528\u57fa\u4e8e\u7535\u8def\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u5bf9\u7535\u8def\u67b6\u6784\u6392\u540d\uff0c\u7ed3\u5408\u786c\u4ef6\u611f\u77e5\u7535\u8def\u3002", "result": "\u5728\u6a21\u62df\u5668\u548c\u771f\u5b9e\u91cf\u5b50\u786c\u4ef6\u4e0a\u6709\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\uff0c\u5728\u91c7\u6837\u6548\u7387\u4e0a\u8d85\u8d8a\u73b0\u6709QAS\u65b9\u6cd5\uff0c\u67b6\u6784\u641c\u7d22\u8fd0\u884c\u65f6\u95f4\u6700\u591a\u52a0\u901f2\u500d\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u91cf\u5b50\u67b6\u6784\u641c\u7d22\u65b9\u9762\u6709\u6548\uff0c\u80fd\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.07325", "pdf": "https://arxiv.org/pdf/2508.07325", "abs": "https://arxiv.org/abs/2508.07325", "authors": ["Dean Geckt", "Melinda Fricke", "Shuly Wintner"], "title": "Strategies of Code-switching in Human-Machine Dialogs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Most people are multilingual, and most multilinguals code-switch, yet the\ncharacteristics of code-switched language are not fully understood. We\ndeveloped a chatbot capable of completing a Map Task with human participants\nusing code-switched Spanish and English. In two experiments, we prompted the\nbot to code-switch according to different strategies, examining (1) the\nfeasibility of such experiments for investigating bilingual language use, and\n(2) whether participants would be sensitive to variations in discourse and\ngrammatical patterns. Participants generally enjoyed code-switching with our\nbot as long as it produced predictable code-switching behavior; when\ncode-switching was random or ungrammatical (as when producing unattested\nincongruent mixed-language noun phrases, such as `la fork'), participants\nenjoyed the task less and were less successful at completing it. These results\nunderscore the potential downsides of deploying insufficiently developed\nmultilingual language technology, while also illustrating the promise of such\ntechnology for conducting research on bilingual language use.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u80fd\u548c\u4eba\u7c7b\u8fdb\u884c\u897f\u82f1\u8bed\u7801\u8f6c\u6362\u4ea4\u6d41\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u5b9e\u9a8c\u53d1\u73b0\u53c2\u4e0e\u8005\u5bf9\u53ef\u9884\u6d4b\u7684\u7801\u8f6c\u6362\u66f4\u6ee1\u610f\uff0c\u7ed3\u679c\u663e\u793a\u591a\u8bed\u8a00\u6280\u672f\u6709\u7814\u7a76\u6f5c\u529b\u4f46\u672a\u6210\u719f\u65f6\u6709\u5f0a\u7aef\u3002", "motivation": "\u591a\u6570\u4eba\u4f1a\u4f7f\u7528\u591a\u8bed\u8a00\u4e14\u8fdb\u884c\u7801\u8f6c\u6362\uff0c\u4f46\u7801\u8f6c\u6362\u8bed\u8a00\u7684\u7279\u5f81\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u5e0c\u671b\u7814\u7a76\u53cc\u8bed\u8bed\u8a00\u4f7f\u7528\u60c5\u51b5\u3002", "method": "\u5f00\u53d1\u804a\u5929\u673a\u5668\u4eba\u4e0e\u4eba\u7c7b\u5b8c\u6210\u5730\u56fe\u4efb\u52a1\uff0c\u5728\u4e24\u4e2a\u5b9e\u9a8c\u4e2d\u8ba9\u673a\u5668\u4eba\u6309\u4e0d\u540c\u7b56\u7565\u8fdb\u884c\u7801\u8f6c\u6362\uff0c\u8003\u5bdf\u5b9e\u9a8c\u53ef\u884c\u6027\u53ca\u53c2\u4e0e\u8005\u5bf9\u4e0d\u540c\u8bdd\u8bed\u548c\u8bed\u6cd5\u6a21\u5f0f\u7684\u654f\u611f\u5ea6\u3002", "result": "\u53ea\u8981\u673a\u5668\u4eba\u7801\u8f6c\u6362\u884c\u4e3a\u53ef\u9884\u6d4b\uff0c\u53c2\u4e0e\u8005\u5c31\u559c\u6b22\u4e0e\u4e4b\u4ea4\u6d41\uff1b\u968f\u673a\u6216\u4e0d\u5408\u8bed\u6cd5\u7684\u7801\u8f6c\u6362\u4f1a\u8ba9\u53c2\u4e0e\u8005\u5174\u8da3\u964d\u4f4e\u4e14\u5b8c\u6210\u4efb\u52a1\u6210\u529f\u7387\u4e0b\u964d\u3002", "conclusion": "\u90e8\u7f72\u672a\u5145\u5206\u53d1\u5c55\u7684\u591a\u8bed\u8a00\u6280\u672f\u6709\u6f5c\u5728\u5f0a\u7aef\uff0c\u540c\u65f6\u8be5\u6280\u672f\u5728\u53cc\u8bed\u8bed\u8a00\u4f7f\u7528\u7814\u7a76\u65b9\u9762\u6709\u524d\u666f\u3002"}}
{"id": "2508.07112", "pdf": "https://arxiv.org/pdf/2508.07112", "abs": "https://arxiv.org/abs/2508.07112", "authors": ["Nikolai Warner", "Wenjin Zhang", "Irfan Essa", "Apaar Sadhwani"], "title": "AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation", "categories": ["cs.CV", "cs.LG"], "comment": "Preprint. Under review", "summary": "Lifting-based methods for 3D Human Pose Estimation (HPE), which predict 3D\nposes from detected 2D keypoints, often generalize poorly to new datasets and\nreal-world settings. To address this, we propose \\emph{AugLift}, a simple yet\neffective reformulation of the standard lifting pipeline that significantly\nimproves generalization performance without requiring additional data\ncollection or sensors. AugLift sparsely enriches the standard input -- the 2D\nkeypoint coordinates $(x, y)$ -- by augmenting it with a keypoint detection\nconfidence score $c$ and a corresponding depth estimate $d$. These additional\nsignals are computed from the image using off-the-shelf, pre-trained models\n(e.g., for monocular depth estimation), thereby inheriting their strong\ngeneralization capabilities. Importantly, AugLift serves as a modular add-on\nand can be readily integrated into existing lifting architectures.\n  Our extensive experiments across four datasets demonstrate that AugLift\nboosts cross-dataset performance on unseen datasets by an average of $10.1\\%$,\nwhile also improving in-distribution performance by $4.0\\%$. These gains are\nconsistent across various lifting architectures, highlighting the robustness of\nour method. Our analysis suggests that these sparse, keypoint-aligned cues\nprovide robust frame-level context, offering a practical way to significantly\nimprove the generalization of any lifting-based pose estimation model. Code\nwill be made publicly available.", "AI": {"tldr": "\u63d0\u51faAugLift\u65b9\u6cd5\u6539\u55843D\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u63d0\u5347\u65b9\u6cd5\u6cdb\u5316\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u63d0\u5347\u76843D\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u5728\u65b0\u6570\u636e\u96c6\u548c\u73b0\u5b9e\u573a\u666f\u6cdb\u5316\u6027\u5dee\u3002", "method": "AugLift\u901a\u8fc7\u6dfb\u52a0\u5173\u952e\u70b9\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\u5206\u6570\u548c\u6df1\u5ea6\u4f30\u8ba1\u4e30\u5bcc\u6807\u51c6\u8f93\u5165\uff0c\u4fe1\u53f7\u7531\u9884\u8bad\u7ec3\u6a21\u578b\u8ba1\u7b97\uff0c\u53ef\u96c6\u6210\u5230\u73b0\u6709\u63d0\u5347\u67b6\u6784\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c\u663e\u793a\uff0cAugLift\u4f7f\u672a\u89c1\u6570\u636e\u96c6\u8de8\u6570\u636e\u96c6\u6027\u80fd\u5e73\u5747\u63d0\u534710.1%\uff0c\u5206\u5e03\u5185\u6027\u80fd\u63d0\u53474.0%\u3002", "conclusion": "\u7a00\u758f\u3001\u5173\u952e\u70b9\u5bf9\u9f50\u7684\u7ebf\u7d22\u80fd\u63d0\u4f9b\u7a33\u5065\u7684\u5e27\u7ea7\u4e0a\u4e0b\u6587\uff0c\u53ef\u663e\u8457\u6539\u5584\u63d0\u5347\u5f0f\u59ff\u6001\u4f30\u8ba1\u6a21\u578b\u6cdb\u5316\u6027\u3002"}}
{"id": "2508.07115", "pdf": "https://arxiv.org/pdf/2508.07115", "abs": "https://arxiv.org/abs/2508.07115", "authors": ["Antonino Greco", "Marco D'Alessandro", "Karl J. Friston", "Giovanni Pezzulo", "Markus Siegel"], "title": "Sensory robustness through top-down feedback and neural stochasticity in recurrent vision models", "categories": ["q-bio.NC", "cs.CV", "cs.LG"], "comment": null, "summary": "Biological systems leverage top-down feedback for visual processing, yet most\nartificial vision models succeed in image classification using purely\nfeedforward or recurrent architectures, calling into question the functional\nsignificance of descending cortical pathways. Here, we trained convolutional\nrecurrent neural networks (ConvRNN) on image classification in the presence or\nabsence of top-down feedback projections to elucidate the specific\ncomputational contributions of those feedback pathways. We found that ConvRNNs\nwith top-down feedback exhibited remarkable speed-accuracy trade-off and\nrobustness to noise perturbations and adversarial attacks, but only when they\nwere trained with stochastic neural variability, simulated by randomly\nsilencing single units via dropout. By performing detailed analyses to identify\nthe reasons for such benefits, we observed that feedback information\nsubstantially shaped the representational geometry of the post-integration\nlayer, combining the bottom-up and top-down streams, and this effect was\namplified by dropout. Moreover, feedback signals coupled with dropout optimally\nconstrained network activity onto a low-dimensional manifold and encoded object\ninformation more efficiently in out-of-distribution regimes, with top-down\ninformation stabilizing the representational dynamics at the population level.\nTogether, these findings uncover a dual mechanism for resilient sensory coding.\nOn the one hand, neural stochasticity prevents unit-level co-adaptation albeit\nat the cost of more chaotic dynamics. On the other hand, top-down feedback\nharnesses high-level information to stabilize network activity on compact\nlow-dimensional manifolds.", "AI": {"tldr": "\u7814\u7a76\u5377\u79ef\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08ConvRNN\uff09\u4e2d\u81ea\u4e0a\u800c\u4e0b\u53cd\u9988\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u6709\u53cd\u9988\u4e14\u7ecf\u968f\u673a\u5931\u6d3b\u8bad\u7ec3\u7684\u7f51\u7edc\u5728\u901f\u5ea6 - \u51c6\u786e\u7387\u6743\u8861\u3001\u6297\u566a\u548c\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u63ed\u793a\u4e86\u5f39\u6027\u611f\u5b98\u7f16\u7801\u7684\u53cc\u91cd\u673a\u5236\u3002", "motivation": "\u751f\u7269\u89c6\u89c9\u5904\u7406\u5229\u7528\u81ea\u4e0a\u800c\u4e0b\u53cd\u9988\uff0c\u800c\u591a\u6570\u4eba\u5de5\u89c6\u89c9\u6a21\u578b\u9760\u524d\u9988\u6216\u5faa\u73af\u67b6\u6784\u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\uff0c\u9700\u9610\u660e\u81ea\u4e0a\u800c\u4e0b\u53cd\u9988\u901a\u8def\u7684\u8ba1\u7b97\u8d21\u732e\u3002", "method": "\u8bad\u7ec3\u6709\u6216\u65e0\u81ea\u4e0a\u800c\u4e0b\u53cd\u9988\u6295\u5f71\u7684ConvRNN\u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\uff0c\u7528\u968f\u673a\u5931\u6d3b\u6a21\u62df\u795e\u7ecf\u968f\u673a\u53d8\u5f02\u6027\u3002", "result": "\u6709\u53cd\u9988\u4e14\u7ecf\u968f\u673a\u5931\u6d3b\u8bad\u7ec3\u7684ConvRNN\u5728\u901f\u5ea6 - \u51c6\u786e\u7387\u6743\u8861\u3001\u6297\u566a\u548c\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u8868\u73b0\u597d\uff1b\u53cd\u9988\u4fe1\u606f\u5851\u9020\u540e\u6574\u5408\u5c42\u8868\u5f81\u51e0\u4f55\uff0c\u4e0e\u968f\u673a\u5931\u6d3b\u7ed3\u5408\u5c06\u7f51\u7edc\u6d3b\u52a8\u7ea6\u675f\u5230\u4f4e\u7ef4\u6d41\u5f62\uff0c\u66f4\u6709\u6548\u5730\u7f16\u7801\u5206\u5e03\u5916\u7269\u4f53\u4fe1\u606f\u3002", "conclusion": "\u53d1\u73b0\u5f39\u6027\u611f\u5b98\u7f16\u7801\u7684\u53cc\u91cd\u673a\u5236\uff0c\u795e\u7ecf\u968f\u673a\u6027\u9632\u6b62\u5355\u5143\u5171\u9002\u5e94\uff0c\u81ea\u4e0a\u800c\u4e0b\u53cd\u9988\u7a33\u5b9a\u7f51\u7edc\u6d3b\u52a8\u3002"}}
{"id": "2508.07390", "pdf": "https://arxiv.org/pdf/2508.07390", "abs": "https://arxiv.org/abs/2508.07390", "authors": ["Gustavo Moreira", "Leonardo Ferreira", "Carolina Veiga", "Maryam Hosseini", "Fabio Miranda"], "title": "Urbanite: A Dataflow-Based Framework for Human-AI Interactive Alignment in Urban Visual Analytics", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted at IEEE VIS 2025. Urbanite is available at\n  https://urbantk.org/urbanite", "summary": "With the growing availability of urban data and the increasing complexity of\nsocietal challenges, visual analytics has become essential for deriving\ninsights into pressing real-world problems. However, analyzing such data is\ninherently complex and iterative, requiring expertise across multiple domains.\nThe need to manage diverse datasets, distill intricate workflows, and integrate\nvarious analytical methods presents a high barrier to entry, especially for\nresearchers and urban experts who lack proficiency in data management, machine\nlearning, and visualization. Advancements in large language models offer a\npromising solution to lower the barriers to the construction of analytics\nsystems by enabling users to specify intent rather than define precise\ncomputational operations. However, this shift from explicit operations to\nintent-based interaction introduces challenges in ensuring alignment throughout\nthe design and development process. Without proper mechanisms, gaps can emerge\nbetween user intent, system behavior, and analytical outcomes. To address these\nchallenges, we propose Urbanite, a framework for human-AI collaboration in\nurban visual analytics. Urbanite leverages a dataflow-based model that allows\nusers to specify intent at multiple scopes, enabling interactive alignment\nacross the specification, process, and evaluation stages of urban analytics.\nBased on findings from a survey to uncover challenges, Urbanite incorporates\nfeatures to facilitate explainability, multi-resolution definition of tasks\nacross dataflows, nodes, and parameters, while supporting the provenance of\ninteractions. We demonstrate Urbanite's effectiveness through usage scenarios\ncreated in collaboration with urban experts. Urbanite is available at\nhttps://urbantk.org/urbanite.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u57ce\u5e02\u6570\u636e\u53ef\u89c6\u5316\u5206\u6790\u6709\u9ad8\u95e8\u69db\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u867d\u6709\u6f5c\u529b\u4f46\u5b58\u5728\u6311\u6218\uff0c\u63d0\u51faUrbanite\u6846\u67b6\u5e76\u5c55\u793a\u5176\u6709\u6548\u6027\u3002", "motivation": "\u57ce\u5e02\u6570\u636e\u53ef\u89c6\u5316\u5206\u6790\u95e8\u69db\u9ad8\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u6709\u8bbe\u8ba1\u5f00\u53d1\u8fc7\u7a0b\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u3002", "method": "\u63d0\u51faUrbanite\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u6570\u636e\u6d41\u6a21\u578b\uff0c\u5141\u8bb8\u7528\u6237\u591a\u8303\u56f4\u6307\u5b9a\u610f\u56fe\uff0c\u7ed3\u5408\u8c03\u67e5\u7ed3\u679c\u878d\u5165\u76f8\u5173\u7279\u6027\u3002", "result": "\u901a\u8fc7\u4e0e\u57ce\u5e02\u4e13\u5bb6\u5408\u4f5c\u521b\u5efa\u7684\u4f7f\u7528\u573a\u666f\u8bc1\u660e\u4e86Urbanite\u7684\u6709\u6548\u6027\u3002", "conclusion": "Urbanite\u6846\u67b6\u80fd\u89e3\u51b3\u57ce\u5e02\u53ef\u89c6\u5316\u5206\u6790\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u53ef\u964d\u4f4e\u5206\u6790\u7cfb\u7edf\u6784\u5efa\u95e8\u69db\u3002"}}
{"id": "2508.07229", "pdf": "https://arxiv.org/pdf/2508.07229", "abs": "https://arxiv.org/abs/2508.07229", "authors": ["Itai Allouche", "Itay Asael", "Rotem Rousso", "Vered Dassa", "Ann Bradlow", "Seung-Eun Kim", "Matthew Goldrick", "Joseph Keshet"], "title": "How Does a Deep Neural Network Look at Lexical Stress?", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "comment": "10 pages, 4 figures, submitted to the Journal of the Acoustical\n  Society of America (JASA)", "summary": "Despite their success in speech processing, neural networks often operate as\nblack boxes, prompting the question: what informs their decisions, and how can\nwe interpret them? This work examines this issue in the context of lexical\nstress. A dataset of English disyllabic words was automatically constructed\nfrom read and spontaneous speech. Several Convolutional Neural Network (CNN)\narchitectures were trained to predict stress position from a spectrographic\nrepresentation of disyllabic words lacking minimal stress pairs (e.g., initial\nstress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out\ntest data. Layerwise Relevance Propagation (LRP), a technique for CNN\ninterpretability analysis, revealed that predictions for held-out minimal pairs\n(PROtest vs. proTEST ) were most strongly influenced by information in stressed\nversus unstressed syllables, particularly the spectral properties of stressed\nvowels. However, the classifiers also attended to information throughout the\nword. A feature-specific relevance analysis is proposed, and its results\nsuggest that our best-performing classifier is strongly influenced by the\nstressed vowel's first and second formants, with some evidence that its pitch\nand third formant also contribute. These results reveal deep learning's ability\nto acquire distributed cues to stress from naturally occurring data, extending\ntraditional phonetic work based around highly controlled stimuli.", "AI": {"tldr": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5728\u82f1\u8bed\u53cc\u97f3\u8282\u8bcd\u91cd\u97f3\u9884\u6d4b\u4e2d\u7684\u51b3\u7b56\u4f9d\u636e\uff0c\u6784\u5efa\u6570\u636e\u96c6\uff0c\u7528CNN\u8bad\u7ec3\u9884\u6d4b\uff0c\u7528LRP\u5206\u6790\uff0c\u63ed\u793a\u91cd\u97f3\u9884\u6d4b\u53d7\u591a\u56e0\u7d20\u5f71\u54cd\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u8bed\u97f3\u5904\u7406\u4e2d\u5e38\u4e3a\u9ed1\u7bb1\uff0c\u9700\u63a2\u7a76\u5176\u5728\u8bcd\u91cd\u97f3\u51b3\u7b56\u4e2d\u7684\u4f9d\u636e\u548c\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u81ea\u52a8\u6784\u5efa\u82f1\u8bed\u53cc\u97f3\u8282\u8bcd\u6570\u636e\u96c6\uff0c\u7528\u591a\u79cdCNN\u67b6\u6784\u4ece\u9891\u8c31\u56fe\u9884\u6d4b\u91cd\u97f3\u4f4d\u7f6e\uff0c\u7528LRP\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u63d0\u51fa\u7279\u5f81\u7279\u5b9a\u76f8\u5173\u6027\u5206\u6790\u3002", "result": "CNN\u5728\u6d4b\u8bd5\u6570\u636e\u4e0a\u51c6\u786e\u7387\u8fbe92%\uff0cLRP\u663e\u793a\u91cd\u97f3\u4e0e\u975e\u91cd\u97f3\u97f3\u8282\u4fe1\u606f\u5f71\u54cd\u9884\u6d4b\uff0c\u7279\u5f81\u5206\u6790\u8868\u660e\u6700\u4f73\u5206\u7c7b\u5668\u53d7\u91cd\u97f3\u5143\u97f3\u7684\u7b2c\u4e00\u3001\u4e8c\u5171\u632f\u5cf0\u5f71\u54cd\u5927\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u80fd\u4ece\u81ea\u7136\u6570\u636e\u4e2d\u83b7\u53d6\u91cd\u97f3\u5206\u5e03\u7ebf\u7d22\uff0c\u6269\u5c55\u4e86\u57fa\u4e8e\u9ad8\u5ea6\u63a7\u5236\u523a\u6fc0\u7684\u4f20\u7edf\u8bed\u97f3\u5b66\u7814\u7a76\u3002"}}
{"id": "2508.07397", "pdf": "https://arxiv.org/pdf/2508.07397", "abs": "https://arxiv.org/abs/2508.07397", "authors": ["Jun Li"], "title": "A Spin Glass Characterization of Neural Networks", "categories": ["cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "This work presents a statistical mechanics characterization of neural\nnetworks, motivated by the replica symmetry breaking (RSB) phenomenon in spin\nglasses. A Hopfield-type spin glass model is constructed from a given\nfeedforward neural network (FNN). Overlaps between simulated replica samples\nserve as a characteristic descriptor of the FNN. The connection between the\nspin-glass description and commonly studied properties of the FNN -- such as\ndata fitting, capacity, generalization, and robustness -- has been investigated\nand empirically demonstrated. Unlike prior analytical studies that focus on\nmodel ensembles, this method provides a computable descriptor for individual\nnetwork instances, which reveals nontrivial structural properties that are not\ncaptured by conventional metrics such as loss or accuracy. Preliminary results\nsuggests its potential for practical applications such as model inspection,\nsafety verification, and detection of hidden vulnerabilities.", "AI": {"tldr": "\u672c\u6587\u53d7\u81ea\u65cb\u73bb\u7483\u4e2d\u590d\u672c\u5bf9\u79f0\u7834\u7f3a\u73b0\u8c61\u542f\u53d1\uff0c\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u7edf\u8ba1\u529b\u5b66\u8868\u5f81\uff0c\u6784\u5efa\u6a21\u578b\u7814\u7a76\u81ea\u65cb\u73bb\u7483\u63cf\u8ff0\u4e0eFNN\u5c5e\u6027\u8054\u7cfb\uff0c\u7ed3\u679c\u663e\u793a\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u53d7\u81ea\u65cb\u73bb\u7483\u4e2d\u590d\u672c\u5bf9\u79f0\u7834\u7f3a\uff08RSB\uff09\u73b0\u8c61\u542f\u53d1\uff0c\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u7edf\u8ba1\u529b\u5b66\u8868\u5f81\u3002", "method": "\u4ece\u7ed9\u5b9a\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff08FNN\uff09\u6784\u5efaHopfield\u578b\u81ea\u65cb\u73bb\u7483\u6a21\u578b\uff0c\u7528\u6a21\u62df\u590d\u672c\u6837\u672c\u95f4\u7684\u91cd\u53e0\u4f5c\u4e3aFNN\u7684\u7279\u5f81\u63cf\u8ff0\u7b26\uff0c\u7814\u7a76\u81ea\u65cb\u73bb\u7483\u63cf\u8ff0\u4e0eFNN\u5e38\u89c1\u5c5e\u6027\u7684\u8054\u7cfb\u3002", "result": "\u8be5\u65b9\u6cd5\u4e3a\u5355\u4e2a\u7f51\u7edc\u5b9e\u4f8b\u63d0\u4f9b\u4e86\u53ef\u8ba1\u7b97\u7684\u63cf\u8ff0\u7b26\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u6307\u6807\u672a\u6355\u6349\u5230\u7684\u975e\u5e73\u51e1\u7ed3\u6784\u5c5e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u68c0\u67e5\u3001\u5b89\u5168\u9a8c\u8bc1\u548c\u9690\u85cf\u6f0f\u6d1e\u68c0\u6d4b\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.07239", "pdf": "https://arxiv.org/pdf/2508.07239", "abs": "https://arxiv.org/abs/2508.07239", "authors": ["Raunak Narwal", "Syed Abbas"], "title": "BIGBOY1.2: Generating Realistic Synthetic Data for Disease Outbreak Modelling and Analytics", "categories": ["q-bio.PE", "cs.LG", "92D30, 97M10", "I.2.6; J.3"], "comment": null, "summary": "Modelling disease outbreak models remains challenging due to incomplete\nsurveillance data, noise, and limited access to standardized datasets. We have\ncreated BIGBOY1.2, an open synthetic dataset generator that creates\nconfigurable epidemic time series and population-level trajectories suitable\nfor benchmarking modelling, forecasting, and visualisation. The framework\nsupports SEIR and SIR-like compartmental logic, custom seasonality, and noise\ninjection to mimic real reporting artifacts. BIGBOY1.2 can produce datasets\nwith diverse characteristics, making it suitable for comparing traditional\nepidemiological models (e.g., SIR, SEIR) with modern machine learning\napproaches (e.g., SVM, neural networks).", "AI": {"tldr": "\u521b\u5efa\u4e86\u5f00\u653e\u5408\u6210\u6570\u636e\u96c6\u751f\u6210\u5668BIGBOY1.2\uff0c\u53ef\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u75be\u75c5\u6a21\u578b\u3002", "motivation": "\u56e0\u76d1\u6d4b\u6570\u636e\u4e0d\u5b8c\u6574\u3001\u6709\u566a\u58f0\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u6570\u636e\u96c6\uff0c\u75be\u75c5\u7206\u53d1\u6a21\u578b\u5efa\u6a21\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u521b\u5efaBIGBOY1.2\uff0c\u652f\u6301SEIR\u548cSIR\u7c7b\u903b\u8f91\u3001\u81ea\u5b9a\u4e49\u5b63\u8282\u6027\u548c\u566a\u58f0\u6ce8\u5165\u3002", "result": "BIGBOY1.2\u80fd\u751f\u6210\u5177\u6709\u4e0d\u540c\u7279\u5f81\u7684\u6570\u636e\u96c6\u3002", "conclusion": "BIGBOY1.2\u9002\u5408\u6bd4\u8f83\u4f20\u7edf\u6d41\u884c\u75c5\u5b66\u6a21\u578b\u548c\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2508.07406", "pdf": "https://arxiv.org/pdf/2508.07406", "abs": "https://arxiv.org/abs/2508.07406", "authors": ["Xiaobei Zhao", "Xingqi Lyu", "Xiang Li"], "title": "AgriVLN: Vision-and-Language Navigation for Agricultural Robots", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Agricultural robots have emerged as powerful members in agricultural tasks,\nnevertheless, still heavily rely on manual operation or untransportable railway\nfor movement, resulting in limited mobility and poor adaptability.\nVision-and-Language Navigation (VLN) enables robots to navigate to the target\ndestinations following natural language instructions, demonstrating strong\nperformance on several domains. However, none of the existing benchmarks or\nmethods is specifically designed for agricultural scenes. To bridge this gap,\nwe propose Agriculture to Agriculture (A2A) benchmark, containing 1,560\nepisodes across six diverse agricultural scenes, in which all realistic RGB\nvideos are captured by front-facing camera on a quadruped robot at a height of\n0.38 meters, aligning with the practical deployment conditions. Meanwhile, we\npropose Vision-and-Language Navigation for Agricultural Robots (AgriVLN)\nbaseline based on Vision-Language Model (VLM) prompted with carefully crafted\ntemplates, which can understand both given instructions and agricultural\nenvironments to generate appropriate low-level actions for robot control. When\nevaluated on A2A, AgriVLN performs well on short instructions but struggles\nwith long instructions, because it often fails to track which part of the\ninstruction is currently being executed. To address this, we further propose\nSubtask List (STL) instruction decomposition module and integrate it into\nAgriVLN, improving Success Rate (SR) from 0.33 to 0.47. We additionally compare\nAgriVLN with several existing VLN methods, demonstrating the state-of-the-art\nperformance in the agricultural domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u519c\u4e1a\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u57fa\u51c6A2A\u548c\u57fa\u7ebf\u65b9\u6cd5AgriVLN\uff0c\u9488\u5bf9\u5176\u5904\u7406\u957f\u6307\u4ee4\u95ee\u9898\u63d0\u51faSTL\u6a21\u5757\u6539\u8fdb\u6027\u80fd\uff0c\u4e14\u5c55\u73b0\u51fa\u519c\u4e1a\u9886\u57df\u7684SOTA\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u519c\u4e1a\u673a\u5668\u4eba\u79fb\u52a8\u53d7\u9650\u3001\u9002\u5e94\u6027\u5dee\uff0c\u4e14\u65e0\u4e13\u95e8\u7528\u4e8e\u519c\u4e1a\u573a\u666f\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u57fa\u51c6\u548c\u65b9\u6cd5\u3002", "method": "\u63d0\u51faA2A\u57fa\u51c6\uff0c\u5305\u542b1560\u4e2a\u8de8\u516d\u79cd\u519c\u4e1a\u573a\u666f\u7684\u60c5\u8282\uff1b\u63d0\u51fa\u57fa\u4e8eVLM\u7684AgriVLN\u57fa\u7ebf\u65b9\u6cd5\uff1b\u63d0\u51faSTL\u6307\u4ee4\u5206\u89e3\u6a21\u5757\u5e76\u96c6\u6210\u5230AgriVLN\u4e2d\u3002", "result": "AgriVLN\u5728\u77ed\u6307\u4ee4\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5904\u7406\u957f\u6307\u4ee4\u6709\u56f0\u96be\uff1b\u96c6\u6210STL\u6a21\u5757\u540e\u6210\u529f\u7387\u4ece0.33\u63d0\u5347\u52300.47\uff1b\u4e0e\u73b0\u6709VLN\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u5728\u519c\u4e1a\u9886\u57df\u5c55\u73b0SOTA\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0A2A\u57fa\u51c6\u548cAgriVLN\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u519c\u4e1a\u673a\u5668\u4eba\u5728\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u96c6\u6210STL\u6a21\u5757\u53ef\u6539\u5584\u957f\u6307\u4ee4\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2508.07410", "pdf": "https://arxiv.org/pdf/2508.07410", "abs": "https://arxiv.org/abs/2508.07410", "authors": ["Saghar Ganji", "Mohammad Naisipour"], "title": "Leveraging GNN to Enhance MEF Method in Predicting ENSO", "categories": ["physics.ao-ph", "cs.AI", "I.2.6"], "comment": "16 pages, 4 figures, 2 tables", "summary": "Reliable long-lead forecasting of the El Nino Southern Oscillation (ENSO)\nremains a long-standing challenge in climate science. The previously developed\nMultimodal ENSO Forecast (MEF) model uses 80 ensemble predictions by two\nindependent deep learning modules: a 3D Convolutional Neural Network (3D-CNN)\nand a time-series module. In their approach, outputs of the two modules are\ncombined using a weighting strategy wherein one is prioritized over the other\nas a function of global performance. Separate weighting or testing of\nindividual ensemble members did not occur, however, which may have limited the\nmodel to optimize the use of high-performing but spread-out forecasts. In this\nstudy, we propose a better framework that employs graph-based analysis to\ndirectly model similarity between all 80 members of the ensemble. By\nconstructing an undirected graph whose vertices are ensemble outputs and whose\nweights on edges measure similarity (via RMSE and correlation), we identify and\ncluster structurally similar and accurate predictions. From which we obtain an\noptimized subset of 20 members using community detection methods. The final\nprediction is then obtained by averaging this optimized subset. This method\nimproves the forecast skill through noise removal and emphasis on ensemble\ncoherence. Interestingly, our graph-based selection shows robust statistical\ncharacteristics among top performers, offering new ensemble behavior insights.\nIn addition, we observe that while the GNN-based approach does not always\noutperform the baseline MEF under every scenario, it produces more stable and\nconsistent outputs, particularly in compound long-lead situations. The approach\nis model-agnostic too, suggesting that it can be applied directly to other\nforecasting models with gargantuan ensemble outputs, such as statistical,\nphysical, or hybrid models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u56fe\u5206\u6790\u6846\u67b6\u4f18\u5316ENSO\u9884\u6d4b\uff0c\u53bb\u9664\u566a\u58f0\u5e76\u5f3a\u8c03\u96c6\u5408\u4e00\u81f4\u6027\uff0c\u63d0\u5347\u9884\u6d4b\u6280\u5de7\uff0c\u8be5\u65b9\u6cd5\u7a33\u5b9a\u4e14\u6a21\u578b\u65e0\u5173\u3002", "motivation": "\u4ee5\u5f80MEF\u6a21\u578b\u672a\u5bf9\u5355\u4e2a\u96c6\u5408\u6210\u5458\u5355\u72ec\u52a0\u6743\u6216\u6d4b\u8bd5\uff0c\u9650\u5236\u4e86\u5bf9\u9ad8\u6027\u80fd\u5206\u6563\u9884\u6d4b\u7684\u4f18\u5316\u5229\u7528\uff0c\u9700\u6539\u8fdbENSO\u957f\u671f\u53ef\u9760\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u56fe\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u6784\u5efa\u65e0\u5411\u56fe\uff0c\u901a\u8fc7RMSE\u548c\u76f8\u5173\u6027\u8861\u91cf\u76f8\u4f3c\u5ea6\uff0c\u5229\u7528\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\u5f97\u523020\u4e2a\u6210\u5458\u7684\u4f18\u5316\u5b50\u96c6\uff0c\u6700\u7ec8\u9884\u6d4b\u901a\u8fc7\u5bf9\u8be5\u5b50\u96c6\u6c42\u5e73\u5747\u5f97\u5230\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u9884\u6d4b\u6280\u5de7\uff0c\u56fe\u9009\u62e9\u5728\u8868\u73b0\u6700\u4f73\u8005\u4e2d\u6709\u7a33\u5065\u7edf\u8ba1\u7279\u5f81\uff0c\u867d\u4e0d\u603b\u662f\u4f18\u4e8e\u57fa\u7ebfMEF\uff0c\u4f46\u8f93\u51fa\u66f4\u7a33\u5b9a\u4e00\u81f4\uff0c\u5c24\u5176\u5728\u590d\u5408\u957f\u671f\u9884\u6d4b\u4e2d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6a21\u578b\u65e0\u5173\uff0c\u53ef\u5e94\u7528\u4e8e\u5176\u4ed6\u6709\u5927\u91cf\u96c6\u5408\u8f93\u51fa\u7684\u9884\u6d4b\u6a21\u578b\u3002"}}
{"id": "2508.07305", "pdf": "https://arxiv.org/pdf/2508.07305", "abs": "https://arxiv.org/abs/2508.07305", "authors": ["Mahdi Maleki", "Reza Agahzadeh Ayoubi", "Marouan Mizmizi", "Umberto Spagnolini"], "title": "Channel Charting in Smart Radio Environments", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "This paper introduces the use of static electromagnetic skins (EMSs) to\nenable robust device localization via channel charting (CC) in realistic urban\nenvironments. We develop a rigorous optimization framework that leverages EMS\nto enhance channel dissimilarity and spatial fingerprinting, formulating EMS\nphase profile design as a codebook-based problem targeting the upper quantiles\nof key embedding metric, localization error, trustworthiness, and continuity.\nThrough 3D ray-traced simulations of a representative city scenario, we\ndemonstrate that optimized EMS configurations, in addition to significant\nimprovement of the average positioning error, reduce the 90th-percentile\nlocalization error from over 60 m (no EMS) to less than 25 m, while drastically\nimproving trustworthiness and continuity. To the best of our knowledge, this is\nthe first work to exploit Smart Radio Environment (SRE) with static EMS for\nenhancing CC, achieving substantial gains in localization performance under\nchallenging None-Line-of-Sight (NLoS) conditions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u9759\u6001\u7535\u78c1\u76ae\uff08EMS\uff09\u5728\u73b0\u5b9e\u57ce\u5e02\u73af\u5883\u4e2d\u901a\u8fc7\u4fe1\u9053\u7ed8\u56fe\uff08CC\uff09\u5b9e\u73b0\u7a33\u5065\u8bbe\u5907\u5b9a\u4f4d\uff0c\u7ecf\u6a21\u62df\u9a8c\u8bc1\u5176\u53ef\u63d0\u5347\u5b9a\u4f4d\u6027\u80fd\u3002", "motivation": "\u5728\u73b0\u5b9e\u57ce\u5e02\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u7684\u8bbe\u5907\u5b9a\u4f4d\uff0c\u89e3\u51b3\u975e\u89c6\u8ddd\uff08NLoS\uff09\u6761\u4ef6\u4e0b\u5b9a\u4f4d\u96be\u9898\u3002", "method": "\u5f00\u53d1\u4e25\u683c\u7684\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528EMS\u589e\u5f3a\u4fe1\u9053\u5dee\u5f02\u548c\u7a7a\u95f4\u6307\u7eb9\u8bc6\u522b\uff0c\u5c06EMS\u76f8\u4f4d\u8f6e\u5ed3\u8bbe\u8ba1\u4e3a\u57fa\u4e8e\u7801\u672c\u7684\u95ee\u9898\u3002", "result": "\u4f18\u5316\u540e\u7684EMS\u914d\u7f6e\u9664\u663e\u8457\u6539\u5584\u5e73\u5747\u5b9a\u4f4d\u8bef\u5dee\u5916\uff0c\u5c0690%\u5206\u4f4d\u7684\u5b9a\u4f4d\u8bef\u5dee\u4ece\u8d8560\u7c73\u964d\u81f3\u4e0d\u8db325\u7c73\uff0c\u8fd8\u5927\u5e45\u63d0\u5347\u53ef\u4fe1\u5ea6\u548c\u8fde\u7eed\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5229\u7528\u9759\u6001EMS\u7684\u667a\u80fd\u65e0\u7ebf\u7535\u73af\u5883\uff08SRE\uff09\u589e\u5f3aCC\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684NLoS\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u5347\u5b9a\u4f4d\u6027\u80fd\u3002"}}
{"id": "2508.07432", "pdf": "https://arxiv.org/pdf/2508.07432", "abs": "https://arxiv.org/abs/2508.07432", "authors": ["Vivek Hruday Kavuri", "Vysishtya Karanam", "Venkata Jahnavi Venkamsetty", "Kriti Madumadukala", "Lakshmipathi Balaji Darur", "Ponnurangam Kumaraguru"], "title": "Freeze and Reveal: Exposing Modality Bias in Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision Language Models achieve impressive multi-modal performance but often\ninherit gender biases from their training data. This bias might be coming from\nboth the vision and text modalities. In this work, we dissect the contributions\nof vision and text backbones to these biases by applying targeted debiasing\nusing Counterfactual Data Augmentation and Task Vector methods. Inspired by\ndata-efficient approaches in hate-speech classification, we introduce a novel\nmetric, Degree of Stereotypicality and a corresponding debiasing method, Data\nAugmentation Using Degree of Stereotypicality - DAUDoS, to reduce bias with\nminimal computational cost. We curate a gender annotated dataset and evaluate\nall methods on VisoGender benchmark to quantify improvements and identify\ndominant source of bias. Our results show that CDA reduces the gender gap by 6%\nand DAUDoS by 3% but using only one-third of the data. Both methods also\nimprove the model's ability to correctly identify gender in images by 3%, with\nDAUDoS achieving this improvement using only almost one-third of training data.\nFrom our experiment's, we observed that CLIP's vision encoder is more biased\nwhereas PaliGemma2's text encoder is more biased. By identifying whether bias\nstems more from vision or text encoders, our work enables more targeted and\neffective bias mitigation strategies in future multi-modal systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7279\u5b9a\u65b9\u6cd5\u5256\u6790\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u89c6\u89c9\u548c\u6587\u672c\u9aa8\u5e72\u5bf9\u6027\u522b\u504f\u5dee\u7684\u8d21\u732e\uff0c\u5f15\u5165\u65b0\u6307\u6807\u548c\u53bb\u504f\u65b9\u6cd5\uff0c\u8bc4\u4f30\u540e\u53d1\u73b0\u65b9\u6cd5\u80fd\u51cf\u5c11\u504f\u5dee\u5e76\u8bc6\u522b\u4e3b\u8981\u504f\u5dee\u6e90\uff0c\u5229\u4e8e\u672a\u6765\u591a\u6a21\u6001\u7cfb\u7edf\u53bb\u504f\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4f1a\u4ece\u8bad\u7ec3\u6570\u636e\u7ee7\u627f\u6027\u522b\u504f\u5dee\uff0c\u9700\u5256\u6790\u89c6\u89c9\u548c\u6587\u672c\u9aa8\u5e72\u5bf9\u504f\u5dee\u7684\u8d21\u732e\u5e76\u51cf\u5c11\u504f\u5dee\u3002", "method": "\u5e94\u7528\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u548c\u4efb\u52a1\u5411\u91cf\u65b9\u6cd5\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u53bb\u504f\uff0c\u5f15\u5165Degree of Stereotypicality\u6307\u6807\u548cDAUDoS\u53bb\u504f\u65b9\u6cd5\uff0c\u6574\u7406\u6027\u522b\u6807\u6ce8\u6570\u636e\u96c6\u5e76\u5728VisoGender\u57fa\u51c6\u4e0a\u8bc4\u4f30\u3002", "result": "CDA\u4f7f\u6027\u522b\u5dee\u8ddd\u51cf\u5c116%\uff0cDAUDoS\u51cf\u5c113%\u4e14\u53ea\u7528\u4e09\u5206\u4e4b\u4e00\u6570\u636e\uff0c\u4e24\u79cd\u65b9\u6cd5\u4f7f\u6a21\u578b\u6b63\u786e\u8bc6\u522b\u56fe\u50cf\u4e2d\u6027\u522b\u7684\u80fd\u529b\u63d0\u9ad83%\uff0cDAUDoS\u7528\u7ea6\u4e09\u5206\u4e4b\u4e00\u8bad\u7ec3\u6570\u636e\u8fbe\u6210\uff0c\u53d1\u73b0CLIP\u89c6\u89c9\u7f16\u7801\u5668\u548cPaliGemma2\u6587\u672c\u7f16\u7801\u5668\u66f4\u6709\u504f\u5dee\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u504f\u5dee\u4e3b\u8981\u6765\u6e90\uff0c\u5229\u4e8e\u672a\u6765\u591a\u6a21\u6001\u7cfb\u7edf\u5236\u5b9a\u66f4\u6709\u9488\u5bf9\u6027\u548c\u6709\u6548\u7684\u53bb\u504f\u7b56\u7565\u3002"}}
{"id": "2508.07326", "pdf": "https://arxiv.org/pdf/2508.07326", "abs": "https://arxiv.org/abs/2508.07326", "authors": ["Polina V. Banushkina", "Sergei V. Krivov"], "title": "Nonparametric Reaction Coordinate Optimization with Histories: A Framework for Rare Event Dynamics", "categories": ["physics.chem-ph", "cs.LG", "math.PR", "physics.comp-ph", "q-bio.BM"], "comment": null, "summary": "Rare but critical events in complex systems, such as protein folding,\nchemical reactions, disease progression, and extreme weather or climate\nphenomena, are governed by complex, high-dimensional, stochastic dynamics.\nIdentifying an optimal reaction coordinate (RC) that accurately captures the\nprogress of these dynamics is crucial for understanding and simulating such\nprocesses. This work introduces a nonparametric RC optimization framework that\nincorporates trajectory histories, enabling robust analysis even for irregular\nor incomplete data. The power of the method is demonstrated through\nincreasingly challenging analyses of protein folding dynamics, where it\nprovides accurate committor estimates that pass a stringent validation test and\nyield high-resolution free energy profiles. Its generality is further\nillustrated through applications to dynamics in phase space, a conceptual ocean\ncirculation model, and a longitudinal clinical dataset. These results\ndemonstrate that rare event dynamics can be accurately characterized without\nexhaustive sampling of the configuration space, establishing a general,\nflexible, and robust framework for analyzing complex dynamical systems and\nlongitudinal datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u975e\u53c2\u6570\u53cd\u5e94\u5750\u6807\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u8f68\u8ff9\u5386\u53f2\uff0c\u53ef\u5206\u6790\u590d\u6742\u7cfb\u7edf\u7f55\u89c1\u4e8b\u4ef6\u52a8\u6001\uff0c\u901a\u8fc7\u591a\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u590d\u6742\u7cfb\u7edf\u4e2d\u7f55\u89c1\u4f46\u5173\u952e\u4e8b\u4ef6\u7531\u590d\u6742\u968f\u673a\u52a8\u6001\u652f\u914d\uff0c\u8bc6\u522b\u80fd\u51c6\u786e\u6355\u6349\u52a8\u6001\u8fdb\u5c55\u7684\u6700\u4f18\u53cd\u5e94\u5750\u6807\u5bf9\u7406\u89e3\u548c\u6a21\u62df\u8fd9\u4e9b\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\u7ed3\u5408\u8f68\u8ff9\u5386\u53f2\u7684\u975e\u53c2\u6570\u53cd\u5e94\u5750\u6807\u4f18\u5316\u6846\u67b6\u3002", "result": "\u5728\u86cb\u767d\u8d28\u6298\u53e0\u52a8\u6001\u5206\u6790\u4e2d\u63d0\u4f9b\u51c6\u786e\u7684\u627f\u8bfa\u8005\u4f30\u8ba1\uff0c\u901a\u8fc7\u4e25\u683c\u9a8c\u8bc1\u6d4b\u8bd5\u5e76\u4ea7\u751f\u9ad8\u5206\u8fa8\u7387\u81ea\u7531\u80fd\u8c31\uff1b\u8fd8\u5e94\u7528\u4e8e\u76f8\u7a7a\u95f4\u52a8\u6001\u3001\u6982\u5ff5\u6d77\u6d0b\u73af\u6d41\u6a21\u578b\u548c\u7eb5\u5411\u4e34\u5e8a\u6570\u636e\u96c6\u3002", "conclusion": "\u65e0\u9700\u5bf9\u914d\u7f6e\u7a7a\u95f4\u8fdb\u884c\u8be6\u5c3d\u91c7\u6837\u5c31\u80fd\u51c6\u786e\u8868\u5f81\u7f55\u89c1\u4e8b\u4ef6\u52a8\u6001\uff0c\u4e3a\u5206\u6790\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u548c\u7eb5\u5411\u6570\u636e\u96c6\u5efa\u7acb\u4e86\u901a\u7528\u3001\u7075\u6d3b\u4e14\u7a33\u5065\u7684\u6846\u67b6\u3002"}}
{"id": "2508.07453", "pdf": "https://arxiv.org/pdf/2508.07453", "abs": "https://arxiv.org/abs/2508.07453", "authors": ["Vindula Jayawardana", "Catherine Tang", "Junyi Ji", "Jonah Philion", "Xue Bin Peng", "Cathy Wu"], "title": "Noise-Aware Generative Microscopic Traffic Simulation", "categories": ["eess.SY", "cs.AI", "cs.MA", "cs.RO", "cs.SY"], "comment": null, "summary": "Accurately modeling individual vehicle behavior in microscopic traffic\nsimulation remains a key challenge in intelligent transportation systems, as it\nrequires vehicles to realistically generate and respond to complex traffic\nphenomena such as phantom traffic jams. While traditional human driver\nsimulation models offer computational tractability, they do so by abstracting\naway the very complexity that defines human driving. On the other hand, recent\nadvances in infrastructure-mounted camera-based roadway sensing have enabled\nthe extraction of vehicle trajectory data, presenting an opportunity to shift\ntoward generative, agent-based models. Yet, a major bottleneck remains: most\nexisting datasets are either overly sanitized or lack standardization, failing\nto reflect the noisy, imperfect nature of real-world sensing. Unlike data from\nvehicle-mounted sensors-which can mitigate sensing artifacts like occlusion\nthrough overlapping fields of view and sensor fusion-infrastructure-based\nsensors surface a messier, more practical view of challenges that traffic\nengineers encounter. To this end, we present the I-24 MOTION Scenario Dataset\n(I24-MSD)-a standardized, curated dataset designed to preserve a realistic\nlevel of sensor imperfection, embracing these errors as part of the learning\nproblem rather than an obstacle to overcome purely from preprocessing. Drawing\nfrom noise-aware learning strategies in computer vision, we further adapt\nexisting generative models in the autonomous driving community for I24-MSD with\nnoise-aware loss functions. Our results show that such models not only\noutperform traditional baselines in realism but also benefit from explicitly\nengaging with, rather than suppressing, data imperfection. We view I24-MSD as a\nstepping stone toward a new generation of microscopic traffic simulation that\nembraces the real-world challenges and is better aligned with practical needs.", "AI": {"tldr": "\u63d0\u51faI - 24 MOTION Scenario Dataset (I24 - MSD)\u6570\u636e\u96c6\uff0c\u7528\u542b\u566a\u58f0\u611f\u77e5\u635f\u5931\u51fd\u6570\u7684\u751f\u6210\u6a21\u578b\u5904\u7406\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u4eba\u7c7b\u9a7e\u9a76\u6a21\u62df\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u590d\u6742\u4ea4\u901a\u73b0\u8c61\uff0c\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u6807\u51c6\u5316\u4e14\u672a\u53cd\u6620\u73b0\u5b9e\u611f\u77e5\u7684\u566a\u58f0\u548c\u4e0d\u5b8c\u7f8e\uff0c\u9700\u65b0\u6570\u636e\u96c6\u548c\u6a21\u578b\u3002", "method": "\u521b\u5efaI24 - MSD\u6807\u51c6\u5316\u6570\u636e\u96c6\uff0c\u501f\u9274\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u566a\u58f0\u611f\u77e5\u5b66\u4e60\u7b56\u7565\uff0c\u7528\u542b\u566a\u58f0\u611f\u77e5\u635f\u5931\u51fd\u6570\u9002\u914d\u81ea\u52a8\u9a7e\u9a76\u793e\u533a\u73b0\u6709\u751f\u6210\u6a21\u578b\u3002", "result": "\u542b\u566a\u58f0\u611f\u77e5\u635f\u5931\u51fd\u6570\u7684\u6a21\u578b\u5728\u771f\u5b9e\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\uff0c\u4e14\u80fd\u5229\u7528\u6570\u636e\u4e0d\u5b8c\u7f8e\u6027\u3002", "conclusion": "I24 - MSD\u662f\u8fc8\u5411\u65b0\u4e00\u4ee3\u5fae\u89c2\u4ea4\u901a\u4eff\u771f\u7684\u57ab\u811a\u77f3\uff0c\u80fd\u5e94\u5bf9\u73b0\u5b9e\u6311\u6218\u5e76\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\u3002"}}
{"id": "2508.07484", "pdf": "https://arxiv.org/pdf/2508.07484", "abs": "https://arxiv.org/abs/2508.07484", "authors": ["Archchana Sindhujan", "Shenbin Qian", "Chan Chi Chun Matthew", "Constantin Orasan", "Diptesh Kanojia"], "title": "ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to COLM 2025 Conference", "summary": "Large Language Models (LLMs) have shown remarkable performance across a wide\nrange of natural language processing tasks. Quality Estimation (QE) for Machine\nTranslation (MT), which assesses the quality of a source-target pair without\nrelying on reference translations, remains a challenging cross-lingual task for\nLLMs. The challenges stem from the inherent limitations of existing LLM-based\nQE systems, which are pre-trained for causal language modelling rather than\nregression-specific tasks, further elevated by the presence of low-resource\nlanguages given pre-training data distribution. This paper introduces ALOPE, an\nadaptive layer-optimization framework designed to enhance LLM-based QE by\nrestructuring Transformer representations through layer-wise adaptation for\nimproved regression-based prediction. Our framework integrates low-rank\nadapters (LoRA) with regression task heads, leveraging selected pre-trained\nTransformer layers for improved cross-lingual alignment. In addition to the\nlayer-specific adaptation, ALOPE introduces two strategies-dynamic weighting,\nwhich adaptively combines representations from multiple layers, and multi-head\nregression, which aggregates regression losses from multiple heads for QE. Our\nframework shows improvements over various existing LLM-based QE approaches.\nEmpirical evidence suggests that intermediate Transformer layers in LLMs\nprovide contextual representations that are more aligned with the cross-lingual\nnature of the QE task. We make resultant models and framework code publicly\navailable for further research, also allowing existing LLM-based MT frameworks\nto be scaled with QE capabilities.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\uff08QE\uff09\u7684ALOPE\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6709\u5c42\u81ea\u9002\u5e94\u7b49\u7b56\u7565\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u516c\u5f00\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684QE\u7cfb\u7edf\u6709\u5c40\u9650\u6027\uff0c\u9884\u8bad\u7ec3\u7528\u4e8e\u56e0\u679c\u8bed\u8a00\u5efa\u6a21\u800c\u975e\u56de\u5f52\u4efb\u52a1\uff0c\u4e14\u53d7\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u9884\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u5f71\u54cd\uff0c\u5728QE\u8fd9\u4e00\u8de8\u8bed\u8a00\u4efb\u52a1\u4e0a\u6709\u6311\u6218\u3002", "method": "\u5f15\u5165ALOPE\u6846\u67b6\uff0c\u5c06\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\u4e0e\u56de\u5f52\u4efb\u52a1\u5934\u96c6\u6210\uff0c\u5229\u7528\u9009\u5b9a\u7684\u9884\u8bad\u7ec3Transformer\u5c42\uff1b\u91c7\u7528\u52a8\u6001\u52a0\u6743\u548c\u591a\u5934\u56de\u5f52\u4e24\u79cd\u7b56\u7565\u3002", "result": "\u8be5\u6846\u67b6\u5728\u591a\u79cd\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684QE\u65b9\u6cd5\u4e0a\u6709\u6539\u8fdb\uff0c\u5b9e\u8bc1\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e2d\u95f4Transformer\u5c42\u63d0\u4f9b\u7684\u4e0a\u4e0b\u6587\u8868\u793a\u66f4\u7b26\u5408QE\u4efb\u52a1\u7684\u8de8\u8bed\u8a00\u6027\u8d28\u3002", "conclusion": "\u516c\u5f00\u6a21\u578b\u548c\u6846\u67b6\u4ee3\u7801\uff0c\u4fbf\u4e8e\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u53ef\u8ba9\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u673a\u5668\u7ffb\u8bd1\u6846\u67b6\u5177\u5907QE\u80fd\u529b\u3002"}}
{"id": "2508.07494", "pdf": "https://arxiv.org/pdf/2508.07494", "abs": "https://arxiv.org/abs/2508.07494", "authors": ["Mircea Lazar"], "title": "From Product Hilbert Spaces to the Generalized Koopman Operator and the Nonlinear Fundamental Lemma", "categories": ["math.OC", "cs.AI"], "comment": null, "summary": "The generalization of the Koopman operator to systems with control input and\nthe derivation of a nonlinear fundamental lemma are two open problems that play\na key role in the development of data-driven control methods for nonlinear\nsystems. Both problems hinge on the construction of observable or basis\nfunctions and their corresponding Hilbert space that enable an\ninfinite-dimensional, linear system representation. In this paper we derive a\nnovel solution to these problems based on orthonormal expansion in a product\nHilbert space constructed as the tensor product between the Hilbert spaces of\nthe state and input observable functions, respectively. We prove that there\nexists an infinite-dimensional linear operator, i.e. the generalized Koopman\noperator, from the constructed product Hilbert space to the Hilbert space\ncorresponding to the lifted state propagated forward in time. A scalable\ndata-driven method for computing finite-dimensional approximations of\ngeneralized Koopman operators and several choices of observable functions are\nalso presented. Moreover, we derive a nonlinear fundamental lemma by exploiting\nthe bilinear structure of the infinite-dimensional generalized Koopman model.\nThe effectiveness of the developed generalized Koopman embedding is illustrated\non the Van der Pol oscillator.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u4e58\u79ef\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u6b63\u4ea4\u5c55\u5f00\uff0c\u4e3a\u542b\u63a7\u5236\u8f93\u5165\u7cfb\u7edf\u7684Koopman\u7b97\u5b50\u63a8\u5e7f\u548c\u975e\u7ebf\u6027\u57fa\u672c\u5f15\u7406\u63a8\u5bfc\u95ee\u9898\u63d0\u4f9b\u65b0\u89e3\uff0c\u7ed9\u51fa\u8ba1\u7b97\u5e7f\u4e49Koopman\u7b97\u5b50\u6709\u9650\u7ef4\u8fd1\u4f3c\u7684\u65b9\u6cd5\uff0c\u5e76\u5728Van der Pol\u632f\u8361\u5668\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u542b\u63a7\u5236\u8f93\u5165\u7cfb\u7edf\u7684Koopman\u7b97\u5b50\u63a8\u5e7f\u548c\u975e\u7ebf\u6027\u57fa\u672c\u5f15\u7406\u63a8\u5bfc\u662f\u6570\u636e\u9a71\u52a8\u975e\u7ebf\u6027\u7cfb\u7edf\u63a7\u5236\u65b9\u6cd5\u53d1\u5c55\u4e2d\u7684\u5173\u952e\u5f00\u653e\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u72b6\u6001\u548c\u8f93\u5165\u53ef\u89c2\u6d4b\u51fd\u6570\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u5f20\u91cf\u79ef\u6784\u5efa\u4e58\u79ef\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u8fdb\u884c\u6b63\u4ea4\u5c55\u5f00\uff0c\u5229\u7528\u65e0\u9650\u7ef4\u5e7f\u4e49Koopman\u6a21\u578b\u7684\u53cc\u7ebf\u6027\u7ed3\u6784\u3002", "result": "\u8bc1\u660e\u5b58\u5728\u4ece\u6784\u9020\u7684\u4e58\u79ef\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u5230\u5bf9\u5e94\u63d0\u5347\u72b6\u6001\u65f6\u95f4\u524d\u5411\u4f20\u64ad\u7684\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u65e0\u9650\u7ef4\u7ebf\u6027\u7b97\u5b50\uff08\u5e7f\u4e49Koopman\u7b97\u5b50\uff09\uff0c\u7ed9\u51fa\u8ba1\u7b97\u5176\u6709\u9650\u7ef4\u8fd1\u4f3c\u7684\u53ef\u6269\u5c55\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u548c\u53ef\u89c2\u6d4b\u51fd\u6570\u7684\u51e0\u79cd\u9009\u62e9\uff0c\u63a8\u5bfc\u4e86\u975e\u7ebf\u6027\u57fa\u672c\u5f15\u7406\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5e7f\u4e49Koopman\u5d4c\u5165\u65b9\u6cd5\u5728Van der Pol\u632f\u8361\u5668\u4e0a\u6709\u6548\u3002"}}
{"id": "2508.07497", "pdf": "https://arxiv.org/pdf/2508.07497", "abs": "https://arxiv.org/abs/2508.07497", "authors": ["Leonardo Ferreira", "Gustavo Moreira", "Fabio Miranda"], "title": "VA-Blueprint: Uncovering Building Blocks for Visual Analytics System Design", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted at IEEE VIS 2025. VA-Blueprint is available at\n  https://urbantk.org/va-blueprint", "summary": "Designing and building visual analytics (VA) systems is a complex, iterative\nprocess that requires the seamless integration of data processing, analytics\ncapabilities, and visualization techniques. While prior research has\nextensively examined the social and collaborative aspects of VA system\nauthoring, the practical challenges of developing these systems remain\nunderexplored. As a result, despite the growing number of VA systems, there are\nonly a few structured knowledge bases to guide their design and development. To\ntackle this gap, we propose VA-Blueprint, a methodology and knowledge base that\nsystematically reviews and categorizes the fundamental building blocks of urban\nVA systems, a domain particularly rich and representative due to its intricate\ndata and unique problem sets. Applying this methodology to an initial set of 20\nsystems, we identify and organize their core components into a multi-level\nstructure, forming an initial knowledge base with a structured blueprint for VA\nsystem development. To scale this effort, we leverage a large language model to\nautomate the extraction of these components for other 81 papers (completing a\ncorpus of 101 papers), assessing its effectiveness in scaling knowledge base\nconstruction. We evaluate our method through interviews with experts and a\nquantitative analysis of annotation metrics. Our contributions provide a deeper\nunderstanding of VA systems' composition and establish a practical foundation\nto support more structured, reproducible, and efficient system development.\nVA-Blueprint is available at https://urbantk.org/va-blueprint.", "AI": {"tldr": "\u63d0\u51faVA - Blueprint\u65b9\u6cd5\u548c\u77e5\u8bc6\u5e93\uff0c\u5bf9\u57ce\u5e02VA\u7cfb\u7edf\u57fa\u672c\u6784\u5efa\u5757\u5206\u7c7b\u5f62\u6210\u521d\u59cb\u77e5\u8bc6\u5e93\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6269\u5c55\uff0c\u7ecf\u8bc4\u4f30\u4e3a\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u73b0\u6709VA\u7cfb\u7edf\u5f00\u53d1\u5b9e\u8df5\u6311\u6218\u7814\u7a76\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u7ed3\u6784\u5316\u77e5\u8bc6\u5e93\u6307\u5bfc\u8bbe\u8ba1\u5f00\u53d1\u3002", "method": "\u63d0\u51faVA - Blueprint\u65b9\u6cd5\u5bf920\u4e2a\u7cfb\u7edf\u6838\u5fc3\u7ec4\u4ef6\u5206\u7c7b\u5f62\u6210\u521d\u59cb\u77e5\u8bc6\u5e93\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5904\u740681\u7bc7\u8bba\u6587\u6269\u5c55\uff0c\u901a\u8fc7\u4e13\u5bb6\u8bbf\u8c08\u548c\u6ce8\u91ca\u6307\u6807\u5b9a\u91cf\u5206\u6790\u8bc4\u4f30\u3002", "result": "\u5f62\u6210\u4e86\u521d\u59cb\u77e5\u8bc6\u5e93\uff0c\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u77e5\u8bc6\u5e93\u6784\u5efa\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u52a0\u6df1\u5bf9VA\u7cfb\u7edf\u7ec4\u6210\u7684\u7406\u89e3\uff0c\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u91cd\u590d\u548c\u9ad8\u6548\u7684\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2508.07414", "pdf": "https://arxiv.org/pdf/2508.07414", "abs": "https://arxiv.org/abs/2508.07414", "authors": ["Jean de Dieu Nyandwi", "Yueqi Song", "Simran Khanuja", "Graham Neubig"], "title": "Grounding Multilingual Multimodal LLMs With Cultural Knowledge", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multimodal Large Language Models excel in high-resource settings, but often\nmisinterpret long-tail cultural entities and underperform in low-resource\nlanguages. To address this gap, we propose a data-centric approach that\ndirectly grounds MLLMs in cultural knowledge. Leveraging a large scale\nknowledge graph from Wikidata, we collect images that represent culturally\nsignificant entities, and generate synthetic multilingual visual question\nanswering data. The resulting dataset, CulturalGround, comprises 22 million\nhigh-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages.\nWe train an open-source MLLM CulturalPangea on CulturalGround, interleaving\nstandard multilingual instruction-tuning data to preserve general abilities.\nCulturalPangea achieves state-of-the-art performance among open models on\nvarious culture-focused multilingual multimodal benchmarks, outperforming prior\nmodels by an average of 5.0 without degrading results on mainstream\nvision-language tasks. Our findings show that our targeted, culturally grounded\napproach could substantially narrow the cultural gap in MLLMs and offer a\npractical path towards globally inclusive multimodal systems.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u6784\u5efaCulturalGround\u6570\u636e\u96c6\u8bad\u7ec3MLLM CulturalPangea\uff0c\u7f29\u5c0fMLLM\u6587\u5316\u5dee\u8ddd\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5c3e\u6587\u5316\u5b9e\u4f53\u7406\u89e3\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528Wikidata\u77e5\u8bc6\u56fe\u8c31\u6536\u96c6\u56fe\u50cf\uff0c\u751f\u6210\u5408\u6210\u591a\u8bed\u8a00\u89c6\u89c9\u95ee\u7b54\u6570\u636e\uff0c\u6784\u5efaCulturalGround\u6570\u636e\u96c6\uff0c\u8bad\u7ec3CulturalPangea\u6a21\u578b\u5e76\u7ed3\u5408\u6807\u51c6\u591a\u8bed\u8a00\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u3002", "result": "CulturalPangea\u5728\u6587\u5316\u76f8\u5173\u591a\u8bed\u8a00\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5f00\u6e90\u6a21\u578b\u6700\u4f18\uff0c\u4e3b\u6d41\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u7ed3\u679c\u672a\u4e0b\u964d\u3002", "conclusion": "\u6709\u9488\u5bf9\u6027\u7684\u6587\u5316\u63a5\u5730\u65b9\u6cd5\u80fd\u7f29\u5c0fMLLM\u6587\u5316\u5dee\u8ddd\uff0c\u4e3a\u5168\u7403\u5305\u5bb9\u6027\u591a\u6a21\u6001\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u8df5\u8def\u5f84\u3002"}}
{"id": "2508.07507", "pdf": "https://arxiv.org/pdf/2508.07507", "abs": "https://arxiv.org/abs/2508.07507", "authors": ["Rashid Mushkani"], "title": "Intersectoral Knowledge in AI and Urban Studies: A Framework for Transdisciplinary Research", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Transdisciplinary approaches are increasingly essential for addressing grand\nsocietal challenges, particularly in complex domains such as Artificial\nIntelligence (AI), urban planning, and social sciences. However, effectively\nvalidating and integrating knowledge across distinct epistemic and ontological\nperspectives poses significant difficulties. This article proposes a\nsix-dimensional framework for assessing and strengthening transdisciplinary\nknowledge validity in AI and city studies, based on an extensive analysis of\nthe most cited research (2014--2024). Specifically, the framework classifies\nresearch orientations according to ontological, epistemological,\nmethodological, teleological, axiological, and valorization dimensions. Our\nfindings show a predominance of perspectives aligned with critical realism\n(ontological), positivism (epistemological), analytical methods\n(methodological), consequentialism (teleological), epistemic values\n(axiological), and social/economic valorization. Less common stances, such as\nidealism, mixed methods, and cultural valorization, are also examined for their\npotential to enrich knowledge production. We highlight how early career\nresearchers and transdisciplinary teams can leverage this framework to\nreconcile divergent disciplinary viewpoints and promote socially accountable\noutcomes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bc4\u4f30\u548c\u52a0\u5f3a\u4eba\u5de5\u667a\u80fd\u4e0e\u57ce\u5e02\u7814\u7a76\u4e2d\u8de8\u5b66\u79d1\u77e5\u8bc6\u6709\u6548\u6027\u7684\u516d\u7ef4\u6846\u67b6\uff0c\u5206\u6790\u5e38\u89c1\u4e0e\u5c11\u89c1\u7acb\u573a\uff0c\u4f9b\u65e9\u671f\u7814\u7a76\u8005\u548c\u56e2\u961f\u8c03\u548c\u5206\u6b67\u5e76\u4fc3\u8fdb\u793e\u4f1a\u8d1f\u8d23\u6210\u679c\u3002", "motivation": "\u8de8\u5b66\u79d1\u65b9\u6cd5\u5bf9\u89e3\u51b3\u91cd\u5927\u793e\u4f1a\u6311\u6218\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6709\u6548\u9a8c\u8bc1\u548c\u6574\u5408\u4e0d\u540c\u89c6\u89d2\u77e5\u8bc6\u5b58\u5728\u56f0\u96be\u3002", "method": "\u57fa\u4e8e2014 - 2024\u5e74\u9ad8\u88ab\u5f15\u7814\u7a76\u8fdb\u884c\u5e7f\u6cdb\u5206\u6790\uff0c\u63d0\u51fa\u516d\u7ef4\u6846\u67b6\u5206\u7c7b\u7814\u7a76\u53d6\u5411\u3002", "result": "\u53d1\u73b0\u4e3b\u6d41\u89c6\u89d2\uff0c\u4e5f\u7814\u7a76\u4e86\u5c11\u89c1\u7acb\u573a\u7684\u77e5\u8bc6\u751f\u4ea7\u6f5c\u529b\u3002", "conclusion": "\u65e9\u671f\u7814\u7a76\u8005\u548c\u8de8\u5b66\u79d1\u56e2\u961f\u53ef\u5229\u7528\u8be5\u6846\u67b6\u8c03\u548c\u5206\u6b67\uff0c\u4fc3\u8fdb\u793e\u4f1a\u8d1f\u8d23\u6210\u679c\u3002"}}
{"id": "2508.07419", "pdf": "https://arxiv.org/pdf/2508.07419", "abs": "https://arxiv.org/abs/2508.07419", "authors": ["Xinjia Lu", "Chuhan Wang", "Qian Zhao", "Lixing Zhu", "Xuehu Zhu"], "title": "Statistical Theory of Multi-stage Newton Iteration Algorithm for Online Continual Learning", "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "We focus on the critical challenge of handling non-stationary data streams in\nonline continual learning environments, where constrained storage capacity\nprevents complete retention of historical data, leading to catastrophic\nforgetting during sequential task training. To more effectively analyze and\naddress the problem of catastrophic forgetting in continual learning, we\npropose a novel continual learning framework from a statistical perspective.\nOur approach incorporates random effects across all model parameters and allows\nthe dimension of parameters to diverge to infinity, offering a general\nformulation for continual learning problems. To efficiently process streaming\ndata, we develop a Multi-step Newton Iteration algorithm that significantly\nreduces computational costs in certain scenarios by alleviating the burden of\nmatrix inversion. Theoretically, we derive the asymptotic normality of the\nestimator, enabling subsequent statistical inference. Comprehensive validation\nthrough synthetic data experiments and two real datasets analyses demonstrates\nthe effectiveness of our proposed method.", "AI": {"tldr": "\u9488\u5bf9\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u4e2d\u5904\u7406\u975e\u5e73\u7a33\u6570\u636e\u6d41\u53ca\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u6846\u67b6\u548c\u7b97\u6cd5\uff0c\u7406\u8bba\u63a8\u5bfc\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u73af\u5883\u4e2d\u5904\u7406\u975e\u5e73\u7a33\u6570\u636e\u6d41\u65f6\u56e0\u5b58\u50a8\u53d7\u9650\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\u3002", "method": "\u4ece\u7edf\u8ba1\u89c6\u89d2\u63d0\u51fa\u65b0\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u5f15\u5165\u968f\u673a\u6548\u5e94\u548c\u5141\u8bb8\u53c2\u6570\u7ef4\u5ea6\u8d8b\u4e8e\u65e0\u7a77\uff1b\u5f00\u53d1\u591a\u6b65\u725b\u987f\u8fed\u4ee3\u7b97\u6cd5\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u63a8\u5bfc\u51fa\u4f30\u8ba1\u91cf\u7684\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u5b9e\u9a8c\u548c\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u5206\u6790\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002"}}
{"id": "2508.07514", "pdf": "https://arxiv.org/pdf/2508.07514", "abs": "https://arxiv.org/abs/2508.07514", "authors": ["Artzai Picon", "Itziar Eguskiza", "Daniel Mugica", "Javier Romero", "Carlos Javier Jimenez", "Eric White", "Gabriel Do-Lago-Junqueira", "Christian Klukas", "Ramon Navarra-Mestre"], "title": "From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Field trials are vital in herbicide research and development to assess\neffects on crops and weeds under varied conditions. Traditionally, evaluations\nrely on manual visual assessments, which are time-consuming, labor-intensive,\nand subjective. Automating species and damage identification is challenging due\nto subtle visual differences, but it can greatly enhance efficiency and\nconsistency.\n  We present an improved segmentation model combining a general-purpose\nself-supervised visual model with hierarchical inference based on botanical\ntaxonomy. Trained on a multi-year dataset (2018-2020) from Germany and Spain\nusing digital and mobile cameras, the model was tested on digital camera data\n(year 2023) and drone imagery from the United States, Germany, and Spain (year\n2024) to evaluate robustness under domain shift. This cross-device evaluation\nmarks a key step in assessing generalization across platforms of the model.\n  Our model significantly improved species identification (F1-score: 0.52 to\n0.85, R-squared: 0.75 to 0.98) and damage classification (F1-score: 0.28 to\n0.44, R-squared: 0.71 to 0.87) over prior methods. Under domain shift (drone\nimages), it maintained strong performance with moderate degradation (species:\nF1-score 0.60, R-squared 0.80; damage: F1-score 0.41, R-squared 0.62), where\nearlier models failed.\n  These results confirm the model's robustness and real-world applicability. It\nis now deployed in BASF's phenotyping pipeline, enabling large-scale, automated\ncrop and weed monitoring across diverse geographies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u7684\u5206\u5272\u6a21\u578b\u7528\u4e8e\u9664\u8349\u5242\u7814\u7a76\u4e2d\u4f5c\u7269\u548c\u6742\u8349\u7684\u7269\u79cd\u4e0e\u635f\u4f24\u8bc6\u522b\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u5f02\u4e14\u5df2\u90e8\u7f72\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u9664\u8349\u5242\u7814\u7a76\u7684\u4eba\u5de5\u8bc4\u4f30\u65b9\u5f0f\u8017\u65f6\u3001\u8d39\u529b\u4e14\u4e3b\u89c2\uff0c\u81ea\u52a8\u8bc6\u522b\u6709\u6311\u6218\u4f46\u53ef\u63d0\u5347\u6548\u7387\u548c\u4e00\u81f4\u6027\u3002", "method": "\u7ed3\u5408\u901a\u7528\u81ea\u76d1\u7763\u89c6\u89c9\u6a21\u578b\u548c\u57fa\u4e8e\u690d\u7269\u5206\u7c7b\u5b66\u7684\u5206\u5c42\u63a8\u7406\u6784\u5efa\u6539\u8fdb\u7684\u5206\u5272\u6a21\u578b\uff0c\u5728\u591a\u5e74\u591a\u5730\u533a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u8de8\u8bbe\u5907\u6d4b\u8bd5\u3002", "result": "\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\uff0c\u6a21\u578b\u5728\u7269\u79cd\u8bc6\u522b\u548c\u635f\u4f24\u5206\u7c7b\u4e0a\u663e\u8457\u63d0\u5347\uff0c\u5728\u57df\u8f6c\u79fb\u4e0b\u4ecd\u4fdd\u6301\u8f83\u597d\u6027\u80fd\u3002", "conclusion": "\u6a21\u578b\u5177\u6709\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u5df2\u90e8\u7f72\u7528\u4e8e\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u4f5c\u7269\u548c\u6742\u8349\u76d1\u6d4b\u3002"}}
{"id": "2508.07517", "pdf": "https://arxiv.org/pdf/2508.07517", "abs": "https://arxiv.org/abs/2508.07517", "authors": ["Joseph T. Colonel", "Baihan Lin"], "title": "Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Word clouds are a common way to summarize qualitative interviews, yet\ntraditional frequency-based methods often fail in conversational contexts: they\nsurface filler words, ignore paraphrase, and fragment semantically related\nideas. This limits their usefulness in early-stage analysis, when researchers\nneed fast, interpretable overviews of what participant actually said. We\nintroduce ThemeClouds, an open-source visualization tool that uses large\nlanguage models (LLMs) to generate thematic, participant-weighted word clouds\nfrom dialogue transcripts. The system prompts an LLM to identify concept-level\nthemes across a corpus and then counts how many unique participants mention\neach topic, yielding a visualization grounded in breadth of mention rather than\nraw term frequency. Researchers can customize prompts and visualization\nparameters, providing transparency and control. Using interviews from a user\nstudy comparing five recording-device configurations (31 participants; 155\ntranscripts, Whisper ASR), our approach surfaces more actionable device\nconcerns than frequency clouds and topic-modeling baselines (e.g., LDA,\nBERTopic). We discuss design trade-offs for integrating LLM assistance into\nqualitative workflows, implications for interpretability and researcher agency,\nand opportunities for interactive analyses such as per-condition contrasts\n(``diff clouds'').", "AI": {"tldr": "\u4ecb\u7ecd\u5f00\u6e90\u53ef\u89c6\u5316\u5de5\u5177ThemeClouds\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u5bf9\u8bdd\u8f6c\u5f55\u672c\u751f\u6210\u4e3b\u9898\u3001\u53c2\u4e0e\u8005\u52a0\u6743\u8bcd\u4e91\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u4f18\u5e76\u63a2\u8ba8\u76f8\u5173\u8bbe\u8ba1\u6743\u8861\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u9891\u7387\u7684\u8bcd\u4e91\u65b9\u6cd5\u5728\u5bf9\u8bdd\u8bed\u5883\u4e2d\u5b58\u5728\u7f3a\u9677\uff0c\u65e0\u6cd5\u6ee1\u8db3\u65e9\u671f\u5206\u6790\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u8bed\u6599\u5e93\u4e2d\u7684\u6982\u5ff5\u7ea7\u4e3b\u9898\uff0c\u7edf\u8ba1\u63d0\u53ca\u6bcf\u4e2a\u4e3b\u9898\u7684\u72ec\u7279\u53c2\u4e0e\u8005\u6570\u91cf\uff0c\u751f\u6210\u8bcd\u4e91\uff0c\u7814\u7a76\u8005\u53ef\u81ea\u5b9a\u4e49\u53c2\u6570\u3002", "result": "\u5728\u7528\u6237\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6bd4\u9891\u7387\u8bcd\u4e91\u548c\u4e3b\u9898\u5efa\u6a21\u57fa\u7ebf\u65b9\u6cd5\u6316\u6398\u51fa\u66f4\u591a\u53ef\u884c\u7684\u8bbe\u5907\u95ee\u9898\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u96c6\u6210\u5230\u5b9a\u6027\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u8bbe\u8ba1\u6743\u8861\u3001\u5bf9\u53ef\u89e3\u91ca\u6027\u548c\u7814\u7a76\u8005\u80fd\u52a8\u6027\u7684\u5f71\u54cd\u4ee5\u53ca\u4ea4\u4e92\u5f0f\u5206\u6790\u673a\u4f1a\u3002"}}
{"id": "2508.07520", "pdf": "https://arxiv.org/pdf/2508.07520", "abs": "https://arxiv.org/abs/2508.07520", "authors": ["Baihan Lin"], "title": "Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "What if the patterns hidden within dialogue reveal more about communication\nthan the words themselves? We introduce Conversational DNA, a novel visual\nlanguage that treats any dialogue -- whether between humans, between human and\nAI, or among groups -- as a living system with interpretable structure that can\nbe visualized, compared, and understood. Unlike traditional conversation\nanalysis that reduces rich interaction to statistical summaries, our approach\nreveals the temporal architecture of dialogue through biological metaphors.\nLinguistic complexity flows through strand thickness, emotional trajectories\ncascade through color gradients, conversational relevance forms through\nconnecting elements, and topic coherence maintains structural integrity through\nhelical patterns. Through exploratory analysis of therapeutic conversations and\nhistorically significant human-AI dialogues, we demonstrate how this\nvisualization approach reveals interaction patterns that traditional methods\nmiss. Our work contributes a new creative framework for understanding\ncommunication that bridges data visualization, human-computer interaction, and\nthe fundamental question of what makes dialogue meaningful in an age where\nhumans increasingly converse with artificial minds.", "AI": {"tldr": "\u63d0\u51faConversational DNA\u8fd9\u4e00\u65b0\u578b\u89c6\u89c9\u8bed\u8a00\u6765\u5206\u6790\u5bf9\u8bdd\uff0c\u901a\u8fc7\u751f\u7269\u9690\u55bb\u63ed\u793a\u5bf9\u8bdd\u7ed3\u6784\uff0c\u7ecf\u6848\u4f8b\u5206\u6790\u5c55\u793a\u5176\u4f18\u52bf\u5e76\u8d21\u732e\u65b0\u6846\u67b6\u3002", "motivation": "\u63a2\u7a76\u5bf9\u8bdd\u4e2d\u9690\u85cf\u6a21\u5f0f\u5bf9\u4ea4\u6d41\u7684\u63ed\u793a\u4f5c\u7528\uff0c\u5f25\u8865\u4f20\u7edf\u5bf9\u8bdd\u5206\u6790\u4ec5\u7ed9\u51fa\u7edf\u8ba1\u603b\u7ed3\u7684\u4e0d\u8db3\u3002", "method": "\u5f15\u5165Conversational DNA\uff0c\u7528\u751f\u7269\u9690\u55bb\u63ed\u793a\u5bf9\u8bdd\u7684\u65f6\u95f4\u67b6\u6784\uff0c\u5982\u7528\u7ebf\u6761\u7c97\u7ec6\u8868\u793a\u8bed\u8a00\u590d\u6742\u6027\u7b49\u3002", "result": "\u901a\u8fc7\u5bf9\u6cbb\u7597\u5bf9\u8bdd\u548c\u91cd\u8981\u4eba\u673a\u5bf9\u8bdd\u7684\u63a2\u7d22\u6027\u5206\u6790\uff0c\u53d1\u73b0\u8be5\u53ef\u89c6\u5316\u65b9\u6cd5\u80fd\u63ed\u793a\u4f20\u7edf\u65b9\u6cd5\u9057\u6f0f\u7684\u4ea4\u4e92\u6a21\u5f0f\u3002", "conclusion": "\u4e3a\u7406\u89e3\u4ea4\u6d41\u8d21\u732e\u4e86\u65b0\u7684\u521b\u9020\u6027\u6846\u67b6\uff0c\u8fde\u63a5\u4e86\u6570\u636e\u53ef\u89c6\u5316\u3001\u4eba\u673a\u4ea4\u4e92\u7b49\u9886\u57df\u3002"}}
{"id": "2508.07538", "pdf": "https://arxiv.org/pdf/2508.07538", "abs": "https://arxiv.org/abs/2508.07538", "authors": ["Hongzhu Jiang", "Sihan Xie", "Zhiyu Wan"], "title": "A DICOM Image De-identification Algorithm in the MIDI-B Challenge", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 5 figures", "summary": "Image de-identification is essential for the public sharing of medical\nimages, particularly in the widely used Digital Imaging and Communications in\nMedicine (DICOM) format as required by various regulations and standards,\nincluding Health Insurance Portability and Accountability Act (HIPAA) privacy\nrules, the DICOM PS3.15 standard, and best practices recommended by the Cancer\nImaging Archive (TCIA). The Medical Image De-Identification Benchmark (MIDI-B)\nChallenge at the 27th International Conference on Medical Image Computing and\nComputer Assisted Intervention (MICCAI 2024) was organized to evaluate\nrule-based DICOM image de-identification algorithms with a large dataset of\nclinical DICOM images. In this report, we explore the critical challenges of\nde-identifying DICOM images, emphasize the importance of removing personally\nidentifiable information (PII) to protect patient privacy while ensuring the\ncontinued utility of medical data for research, diagnostics, and treatment, and\nprovide a comprehensive overview of the standards and regulations that govern\nthis process. Additionally, we detail the de-identification methods we applied\n- such as pixel masking, date shifting, date hashing, text recognition, text\nreplacement, and text removal - to process datasets during the test phase in\nstrict compliance with these standards. According to the final leaderboard of\nthe MIDI-B challenge, the latest version of our solution algorithm correctly\nexecuted 99.92% of the required actions and ranked 2nd out of 10 teams that\ncompleted the challenge (from a total of 22 registered teams). Finally, we\nconducted a thorough analysis of the resulting statistics and discussed the\nlimitations of current approaches and potential avenues for future improvement.", "AI": {"tldr": "\u6587\u7ae0\u805a\u7126DICOM\u533b\u5b66\u56fe\u50cf\u53bb\u6807\u8bc6\u5316\uff0c\u4ecb\u7ecdMIDI - B\u6311\u6218\uff0c\u8be6\u8ff0\u53bb\u6807\u8bc6\u65b9\u6cd5\uff0c\u7b97\u6cd5\u8868\u73b0\u826f\u597d\u5e76\u5206\u6790\u7ed3\u679c\u4e0e\u4e0d\u8db3\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u516c\u5f00\u5171\u4eab\u9700\u9075\u5faa\u6cd5\u89c4\u53bb\u9664\u4e2a\u4eba\u53ef\u8bc6\u522b\u4fe1\u606f\uff0c\u7ec4\u7ec7MIDI - B\u6311\u6218\u8bc4\u4f30\u57fa\u4e8e\u89c4\u5219\u7684DICOM\u56fe\u50cf\u53bb\u6807\u8bc6\u7b97\u6cd5\u3002", "method": "\u91c7\u7528\u50cf\u7d20\u63a9\u7801\u3001\u65e5\u671f\u504f\u79fb\u3001\u65e5\u671f\u54c8\u5e0c\u3001\u6587\u672c\u8bc6\u522b\u3001\u6587\u672c\u66ff\u6362\u548c\u6587\u672c\u5220\u9664\u7b49\u53bb\u6807\u8bc6\u65b9\u6cd5\u5904\u7406\u6570\u636e\u96c6\u3002", "result": "\u7b97\u6cd5\u5728MIDI - B\u6311\u6218\u6700\u7ec8\u6392\u884c\u699c\u4e2d\u6b63\u786e\u6267\u884c99.92%\u7684\u6240\u9700\u64cd\u4f5c\uff0c\u5728\u5b8c\u6210\u6311\u6218\u768410\u652f\u961f\u4f0d\u4e2d\u6392\u540d\u7b2c2\u3002", "conclusion": "\u5bf9\u7ed3\u679c\u7edf\u8ba1\u8fdb\u884c\u5206\u6790\uff0c\u8ba8\u8bba\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u548c\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2508.07487", "pdf": "https://arxiv.org/pdf/2508.07487", "abs": "https://arxiv.org/abs/2508.07487", "authors": ["Vukan Ninkovic", "Dejan Vukobratovic"], "title": "Structured Superposition of Autoencoders for UEP Codes at Intermediate Blocklengths", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": "Accepted for publication at IEEE Communication Letters", "summary": "Unequal error protection (UEP) coding that enables differentiated reliability\nlevels within a transmitted message is essential for modern communication\nsystems. Autoencoder (AE)-based code designs have shown promise in the context\nof learned equal error protection (EEP) coding schemes. However, their\napplication to UEP remains largely unexplored, particularly at intermediate\nblocklengths, due to the increasing complexity of AE-based models. Inspired by\nthe proven effectiveness of superposition coding and successive interference\ncancellation (SIC) decoding in conventional UEP schemes, we propose a\nstructured AE-based architecture that extends AE-based UEP codes to\nsubstantially larger blocklengths while maintaining efficient training. By\nstructuring encoding and decoding into smaller AE subblocks, our method\nprovides a flexible framework for fine-tuning UEP reliability levels while\nadapting to diverse system parameters. Numerical results show that the proposed\napproach improves over established achievability bounds of randomized\nsuperposition coding-based UEP schemes with SIC decoding, making the proposed\nstructured AE-based UEP codes a scalable and efficient solution for\nnext-generation networks.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u6784\u5316\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u67b6\u6784\u6269\u5c55\u4e0d\u7b49\u5dee\u9519\u4fdd\u62a4\uff08UEP\uff09\u7801\u5230\u66f4\u5927\u5757\u957f\uff0c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u81ea\u52a8\u7f16\u7801\u5668\uff08AE\uff09\u5728UEP\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u4e2d\u7b49\u5757\u957f\u4e0b\u672a\u5145\u5206\u63a2\u7d22\uff0c\u4e14AE\u6a21\u578b\u590d\u6742\u5ea6\u589e\u52a0\u3002", "method": "\u5c06\u7f16\u7801\u548c\u89e3\u7801\u6784\u5efa\u4e3a\u66f4\u5c0f\u7684AE\u5b50\u5757\uff0c\u63d0\u4f9b\u7075\u6d3b\u6846\u67b6\u8c03\u6574UEP\u53ef\u9760\u6027\u6c34\u5e73\u5e76\u9002\u5e94\u4e0d\u540c\u7cfb\u7edf\u53c2\u6570\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u57fa\u4e8e\u968f\u673a\u53e0\u52a0\u7f16\u7801\u548c\u8fde\u7eed\u5e72\u6270\u6d88\u9664\uff08SIC\uff09\u89e3\u7801\u7684UEP\u65b9\u6848\u7684\u53ef\u8fbe\u6027\u8fb9\u754c\u3002", "conclusion": "\u6240\u63d0\u7ed3\u6784\u5316\u57fa\u4e8eAE\u7684UEP\u7801\u662f\u4e0b\u4e00\u4ee3\u7f51\u7edc\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07543", "pdf": "https://arxiv.org/pdf/2508.07543", "abs": "https://arxiv.org/abs/2508.07543", "authors": ["Chidaksh Ravuru"], "title": "Commentary Generation for Soccer Highlights", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Automated soccer commentary generation has evolved from template-based\nsystems to advanced neural architectures, aiming to produce real-time\ndescriptions of sports events. While frameworks like SoccerNet-Caption laid\nfoundational work, their inability to achieve fine-grained alignment between\nvideo content and commentary remains a significant challenge. Recent efforts\nsuch as MatchTime, with its MatchVoice model, address this issue through coarse\nand fine-grained alignment techniques, achieving improved temporal\nsynchronization. In this paper, we extend MatchVoice to commentary generation\nfor soccer highlights using the GOAL dataset, which emphasizes short clips over\nentire games. We conduct extensive experiments to reproduce the original\nMatchTime results and evaluate our setup, highlighting the impact of different\ntraining configurations and hardware limitations. Furthermore, we explore the\neffect of varying window sizes on zero-shot performance. While MatchVoice\nexhibits promising generalization capabilities, our findings suggest the need\nfor integrating techniques from broader video-language domains to further\nenhance performance. Our code is available at\nhttps://github.com/chidaksh/SoccerCommentary.", "AI": {"tldr": "\u672c\u6587\u5728MatchVoice\u57fa\u7840\u4e0a\uff0c\u7528GOAL\u6570\u636e\u96c6\u4e3a\u8db3\u7403\u9ad8\u5149\u7247\u6bb5\u751f\u6210\u89e3\u8bf4\uff0c\u5b9e\u9a8c\u8bc4\u4f30\u4e0d\u540c\u8bad\u7ec3\u914d\u7f6e\u548c\u7a97\u53e3\u5927\u5c0f\u5f71\u54cd\uff0c\u6307\u51fa\u9700\u7ed3\u5408\u66f4\u591a\u89c6\u9891 - \u8bed\u8a00\u6280\u672f\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8db3\u7403\u89e3\u8bf4\u751f\u6210\u6846\u67b6\u96be\u4ee5\u5b9e\u73b0\u89c6\u9891\u5185\u5bb9\u4e0e\u89e3\u8bf4\u7684\u7ec6\u7c92\u5ea6\u5bf9\u9f50\uff0c\u9700\u6539\u8fdb\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u6269\u5c55MatchVoice\u6a21\u578b\u7528\u4e8e\u8db3\u7403\u9ad8\u5149\u89e3\u8bf4\u751f\u6210\uff0c\u4f7f\u7528GOAL\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u5b9e\u9a8c\u91cd\u73b0\u548c\u8bc4\u4f30\uff0c\u63a2\u7d22\u4e0d\u540c\u7a97\u53e3\u5927\u5c0f\u5bf9\u96f6\u6837\u672c\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "MatchVoice\u6709\u4e00\u5b9a\u6cdb\u5316\u80fd\u529b\uff0c\u4e0d\u540c\u8bad\u7ec3\u914d\u7f6e\u548c\u786c\u4ef6\u6709\u5f71\u54cd\uff0c\u4e0d\u540c\u7a97\u53e3\u5927\u5c0f\u5f71\u54cd\u96f6\u6837\u672c\u6027\u80fd\u3002", "conclusion": "\u9700\u8981\u96c6\u6210\u66f4\u5e7f\u6cdb\u89c6\u9891 - \u8bed\u8a00\u9886\u57df\u7684\u6280\u672f\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2508.07561", "pdf": "https://arxiv.org/pdf/2508.07561", "abs": "https://arxiv.org/abs/2508.07561", "authors": ["Yiheng Jiang", "Tian Biao"], "title": "A Small-footprint Acoustic Echo Cancellation Solution for Mobile Full-Duplex Speech Interactions", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "This paper is accepted to ICASSP 2025", "summary": "In full-duplex speech interaction systems, effective Acoustic Echo\nCancellation (AEC) is crucial for recovering echo-contaminated speech. This\npaper presents a neural network-based AEC solution to address challenges in\nmobile scenarios with varying hardware, nonlinear distortions and long latency.\nWe first incorporate diverse data augmentation strategies to enhance the\nmodel's robustness across various environments. Moreover, progressive learning\nis employed to incrementally improve AEC effectiveness, resulting in a\nconsiderable improvement in speech quality. To further optimize AEC's\ndownstream applications, we introduce a novel post-processing strategy\nemploying tailored parameters designed specifically for tasks such as Voice\nActivity Detection (VAD) and Automatic Speech Recognition (ASR), thus enhancing\ntheir overall efficacy. Finally, our method employs a small-footprint model\nwith streaming inference, enabling seamless deployment on mobile devices.\nEmpirical results demonstrate effectiveness of the proposed method in Echo\nReturn Loss Enhancement and Perceptual Evaluation of Speech Quality, alongside\nsignificant improvements in both VAD and ASR results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684AEC\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u3001\u6e10\u8fdb\u5b66\u4e60\u548c\u540e\u5904\u7406\u7b56\u7565\uff0c\u7528\u5c0f\u6a21\u578b\u5b9e\u73b0\u79fb\u52a8\u8bbe\u5907\u90e8\u7f72\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5168\u53cc\u5de5\u8bed\u97f3\u4ea4\u4e92\u7cfb\u7edf\u5728\u79fb\u52a8\u573a\u666f\u4e2d\uff0c\u56e0\u786c\u4ef6\u4e0d\u540c\u3001\u975e\u7ebf\u6027\u5931\u771f\u548c\u957f\u5ef6\u8fdf\u5e26\u6765\u7684\u58f0\u5b66\u56de\u58f0\u6d88\u9664\u6311\u6218\u3002", "method": "\u7ed3\u5408\u591a\u6837\u6570\u636e\u589e\u5f3a\u7b56\u7565\u3001\u6e10\u8fdb\u5b66\u4e60\u3001\u65b0\u9896\u540e\u5904\u7406\u7b56\u7565\uff0c\u4f7f\u7528\u5c0f\u6a21\u578b\u8fdb\u884c\u6d41\u5f0f\u63a8\u7406\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u56de\u58f0\u8fd4\u56de\u635f\u8017\u589e\u5f3a\u548c\u8bed\u97f3\u8d28\u91cf\u611f\u77e5\u8bc4\u4f30\u4e2d\u6709\u6548\uff0c\u8bed\u97f3\u6d3b\u52a8\u68c0\u6d4b\u548c\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7ed3\u679c\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u79fb\u52a8\u573a\u666f\u58f0\u5b66\u56de\u58f0\u6d88\u9664\u95ee\u9898\uff0c\u53ef\u5728\u79fb\u52a8\u8bbe\u5907\u65e0\u7f1d\u90e8\u7f72\u3002"}}
{"id": "2508.07559", "pdf": "https://arxiv.org/pdf/2508.07559", "abs": "https://arxiv.org/abs/2508.07559", "authors": ["Ziang Chen", "Liqiang Huang"], "title": "Barron Space Representations for Elliptic PDEs with Homogeneous Boundary Conditions", "categories": ["math.NA", "cs.LG", "cs.NA", "math.AP"], "comment": null, "summary": "We study the approximation complexity of high-dimensional second-order\nelliptic PDEs with homogeneous boundary conditions on the unit hypercube,\nwithin the framework of Barron spaces. Under the assumption that the\ncoefficients belong to suitably defined Barron spaces, we prove that the\nsolution can be efficiently approximated by two-layer neural networks,\ncircumventing the curse of dimensionality. Our results demonstrate the\nexpressive power of shallow networks in capturing high-dimensional PDE\nsolutions under appropriate structural assumptions.", "AI": {"tldr": "\u7814\u7a76\u9ad8\u7ef4\u4e8c\u9636\u692d\u5706PDE\u5728Barron\u7a7a\u95f4\u6846\u67b6\u4e0b\u7684\u8fd1\u4f3c\u590d\u6742\u5ea6\uff0c\u8bc1\u660e\u89e3\u53ef\u7528\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u6709\u6548\u903c\u8fd1\uff0c\u89c4\u907f\u7ef4\u6570\u707e\u96be\u3002", "motivation": "\u63a2\u7a76\u9ad8\u7ef4\u4e8c\u9636\u692d\u5706PDE\u7684\u8fd1\u4f3c\u590d\u6742\u5ea6\uff0c\u6316\u6398\u6d45\u7f51\u7edc\u5bf9\u9ad8\u7ef4PDE\u89e3\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u5728Barron\u7a7a\u95f4\u6846\u67b6\u4e0b\uff0c\u5047\u8bbe\u7cfb\u6570\u5c5e\u4e8e\u9002\u5f53\u5b9a\u4e49\u7684Barron\u7a7a\u95f4\u3002", "result": "\u8bc1\u660e\u89e3\u53ef\u7528\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u6709\u6548\u903c\u8fd1\uff0c\u89c4\u907f\u7ef4\u6570\u707e\u96be\u3002", "conclusion": "\u5728\u9002\u5f53\u7ed3\u6784\u5047\u8bbe\u4e0b\uff0c\u6d45\u7f51\u7edc\u5bf9\u9ad8\u7ef4PDE\u89e3\u6709\u5f3a\u5927\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2508.07569", "pdf": "https://arxiv.org/pdf/2508.07569", "abs": "https://arxiv.org/abs/2508.07569", "authors": ["Amulya Suravarjhula", "Rashi Chandrashekhar Agrawal", "Sakshi Jayesh Patel", "Rahul Gupta"], "title": "Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation", "categories": ["cs.MA", "cs.AI"], "comment": "7 pages", "summary": "Drafting a Statement of Work (SOW) is a vital part of business and legal\nprojects. It outlines key details like deliverables, timelines,\nresponsibilities, and legal terms. However, creating these documents is often a\nslow and complex process. It usually involves multiple people, takes several\ndays, and leaves room for errors or outdated content. This paper introduces a\nnew AI-driven automation system that makes the entire SOW drafting process\nfaster, easier, and more accurate. Instead of relying completely on humans, the\nsystem uses three intelligent components or 'agents' that each handle a part of\nthe job. One agent writes the first draft, another checks if everything is\nlegally correct, and the third agent formats the document and ensures\neverything is in order. Unlike basic online tools that just fill in templates,\nthis system understands the meaning behind the content and customizes the SOW\nto match the needs of the project. It also checks legal compliance and\nformatting so that users can trust the result. The system was tested using real\nbusiness examples. It was able to create a full SOW in under three minutes,\ncompared to several hours or days using manual methods. It also performed well\nin accuracy and quality, showing that it can reduce legal risks and save a lot\nof time. This solution shows how artificial intelligence can be used to support\nlegal and business professionals by taking care of routine work and helping\nthem focus on more important decisions. It's a step toward making legal\nprocesses smarter, faster, and more reliable.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684AI\u9a71\u52a8\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u53ef\u4f7f\u5de5\u4f5c\u8bf4\u660e\u4e66\uff08SOW\uff09\u8d77\u8349\u8fc7\u7a0b\u66f4\u5feb\u3001\u66f4\u7b80\u5355\u3001\u66f4\u51c6\u786e\uff0c\u7ecf\u6d4b\u8bd5\u8868\u73b0\u826f\u597d\uff0c\u6709\u52a9\u4e8e\u6cd5\u5f8b\u548c\u5546\u4e1a\u4e13\u4e1a\u4eba\u58eb\u3002", "motivation": "\u4f20\u7edfSOW\u8d77\u8349\u8fc7\u7a0b\u7f13\u6162\u3001\u590d\u6742\uff0c\u6613\u51fa\u9519\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165\u7531\u4e09\u4e2a\u667a\u80fd\u7ec4\u4ef6\uff08\u4ee3\u7406\uff09\u6784\u6210\u7684AI\u9a71\u52a8\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u5206\u522b\u8d1f\u8d23\u521d\u7a3f\u64b0\u5199\u3001\u6cd5\u5f8b\u5408\u89c4\u68c0\u67e5\u548c\u6587\u6863\u683c\u5f0f\u5904\u7406\u3002", "result": "\u7cfb\u7edf\u901a\u8fc7\u5b9e\u9645\u5546\u4e1a\u6848\u4f8b\u6d4b\u8bd5\uff0c\u80fd\u5728\u4e09\u5206\u949f\u5185\u5b8c\u6210\u5b8c\u6574SOW\uff0c\u51c6\u786e\u6027\u548c\u8d28\u91cf\u8868\u73b0\u826f\u597d\uff0c\u53ef\u964d\u4f4e\u6cd5\u5f8b\u98ce\u9669\u5e76\u8282\u7701\u5927\u91cf\u65f6\u95f4\u3002", "conclusion": "\u8be5\u89e3\u51b3\u65b9\u6848\u5c55\u793a\u4e86\u4eba\u5de5\u667a\u80fd\u53ef\u7528\u4e8e\u652f\u6301\u6cd5\u5f8b\u548c\u5546\u4e1a\u4e13\u4e1a\u4eba\u58eb\uff0c\u63a8\u52a8\u6cd5\u5f8b\u6d41\u7a0b\u66f4\u667a\u80fd\u3001\u5feb\u901f\u548c\u53ef\u9760\u3002"}}
{"id": "2508.07577", "pdf": "https://arxiv.org/pdf/2508.07577", "abs": "https://arxiv.org/abs/2508.07577", "authors": ["Zhaorui Tan", "Tan Pan", "Kaizhu Huang", "Weimiao Yu", "Kai Yao", "Chen Jiang", "Qiufeng Wang", "Anh Nguyen", "Xin Guo", "Yuan Cheng", "Xi Yang"], "title": "Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "LayerNorm is pivotal in Vision Transformers (ViTs), yet its fine-tuning\ndynamics under data scarcity and domain shifts remain underexplored. This paper\nshows that shifts in LayerNorm parameters after fine-tuning (LayerNorm shifts)\nare indicative of the transitions between source and target domains; its\nefficacy is contingent upon the degree to which the target training samples\naccurately represent the target domain, as quantified by our proposed\nFine-tuning Shift Ratio ($FSR$). Building on this, we propose a simple yet\neffective rescaling mechanism using a scalar $\\lambda$ that is negatively\ncorrelated to $FSR$ to align learned LayerNorm shifts with those ideal shifts\nachieved under fully representative data, combined with a cyclic framework that\nfurther enhances the LayerNorm fine-tuning. Extensive experiments across\nnatural and pathological images, in both in-distribution (ID) and\nout-of-distribution (OOD) settings, and various target training sample regimes\nvalidate our framework. Notably, OOD tasks tend to yield lower $FSR$ and higher\n$\\lambda$ in comparison to ID cases, especially with scarce data, indicating\nunder-represented target training samples. Moreover, ViTFs fine-tuned on\npathological data behave more like ID settings, favoring conservative LayerNorm\nupdates. Our findings illuminate the underexplored dynamics of LayerNorm in\ntransfer learning and provide practical strategies for LayerNorm fine-tuning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u89c6\u89c9Transformer\u4e2dLayerNorm\u5728\u6570\u636e\u7a00\u7f3a\u548c\u9886\u57df\u8f6c\u79fb\u4e0b\u7684\u5fae\u8c03\u52a8\u6001\uff0c\u63d0\u51fa\u57fa\u4e8eFSR\u7684\u91cd\u7f29\u653e\u673a\u5236\u548c\u5faa\u73af\u6846\u67b6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u5e76\u5f97\u51fa\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u7279\u70b9\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9Transformer\u4e2dLayerNorm\u5728\u6570\u636e\u7a00\u7f3a\u548c\u9886\u57df\u8f6c\u79fb\u4e0b\u7684\u5fae\u8c03\u52a8\u6001\u3002", "method": "\u63d0\u51fa\u7528\u4e0eFSR\u8d1f\u76f8\u5173\u7684\u6807\u91cf\u03bb\u7684\u91cd\u7f29\u653e\u673a\u5236\uff0c\u7ed3\u5408\u5faa\u73af\u6846\u67b6\u6765\u589e\u5f3aLayerNorm\u5fae\u8c03\u3002", "result": "\u5728\u81ea\u7136\u548c\u75c5\u7406\u56fe\u50cf\u7684\u591a\u79cd\u8bbe\u7f6e\u548c\u6837\u672c\u5236\u5ea6\u4e0b\u9a8c\u8bc1\u4e86\u6846\u67b6\uff0c\u53d1\u73b0OOD\u4efb\u52a1FSR\u4f4e\u3001\u03bb\u9ad8\uff0c\u75c5\u7406\u6570\u636e\u5fae\u8c03\u7c7b\u4f3cID\u8bbe\u7f6e\u3002", "conclusion": "\u63ed\u793a\u4e86\u8fc1\u79fb\u5b66\u4e60\u4e2dLayerNorm\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u52a8\u6001\uff0c\u4e3a\u5176\u5fae\u8c03\u63d0\u4f9b\u5b9e\u7528\u7b56\u7565\u3002"}}
{"id": "2508.07592", "pdf": "https://arxiv.org/pdf/2508.07592", "abs": "https://arxiv.org/abs/2508.07592", "authors": ["Puspesh Kumar Srivastava", "Uddeshya Raj", "Praveen Patel", "/Shubham Kumar Nigam", "Noel Shallum", "Arnab Bhattacharya"], "title": "IBPS: Indian Bail Prediction System", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Bail decisions are among the most frequently adjudicated matters in Indian\ncourts, yet they remain plagued by subjectivity, delays, and inconsistencies.\nWith over 75% of India's prison population comprising undertrial prisoners,\nmany from socioeconomically disadvantaged backgrounds, the lack of timely and\nfair bail adjudication exacerbates human rights concerns and contributes to\nsystemic judicial backlog. In this paper, we present the Indian Bail Prediction\nSystem (IBPS), an AI-powered framework designed to assist in bail\ndecision-making by predicting outcomes and generating legally sound rationales\nbased solely on factual case attributes and statutory provisions. We curate and\nrelease a large-scale dataset of 150,430 High Court bail judgments, enriched\nwith structured annotations such as age, health, criminal history, crime\ncategory, custody duration, statutes, and judicial reasoning. We fine-tune a\nlarge language model using parameter-efficient techniques and evaluate its\nperformance across multiple configurations, with and without statutory context,\nand with RAG. Our results demonstrate that models fine-tuned with statutory\nknowledge significantly outperform baselines, achieving strong accuracy and\nexplanation quality, and generalize well to a test set independently annotated\nby legal experts. IBPS offers a transparent, scalable, and reproducible\nsolution to support data-driven legal assistance, reduce bail delays, and\npromote procedural fairness in the Indian judicial system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAI\u6846\u67b6IBPS\u8f85\u52a9\u5370\u5ea6\u4fdd\u91ca\u51b3\u7b56\uff0c\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5fae\u8c03\u5927\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u7ed3\u5408\u6cd5\u89c4\u77e5\u8bc6\u7684\u6a21\u578b\u8868\u73b0\u4f73\uff0c\u80fd\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u6cd5\u5f8b\u534f\u52a9\u3002", "motivation": "\u5370\u5ea6\u4fdd\u91ca\u51b3\u7b56\u5b58\u5728\u4e3b\u89c2\u6027\u3001\u5ef6\u8fdf\u548c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5927\u91cf\u5ba1\u524d\u56da\u72af\u52a0\u5267\u4eba\u6743\u548c\u53f8\u6cd5\u79ef\u538b\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u4fdd\u91ca\u51b3\u7b56\u65b9\u5f0f\u3002", "method": "\u6784\u5efa150,430\u4e2a\u9ad8\u7b49\u6cd5\u9662\u4fdd\u91ca\u5224\u51b3\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u7528\u53c2\u6570\u9ad8\u6548\u6280\u672f\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u79cd\u914d\u7f6e\u4e0b\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u7ed3\u5408\u6cd5\u89c4\u77e5\u8bc6\u5fae\u8c03\u7684\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u548c\u89e3\u91ca\u8d28\u91cf\u9ad8\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u6cdb\u5316\u80fd\u529b\u597d\u3002", "conclusion": "IBPS\u4e3a\u5370\u5ea6\u53f8\u6cd5\u7cfb\u7edf\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u6269\u5c55\u548c\u53ef\u590d\u73b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u51cf\u5c11\u4fdd\u91ca\u5ef6\u8fdf\uff0c\u4fc3\u8fdb\u7a0b\u5e8f\u516c\u5e73\u3002"}}
{"id": "2508.07648", "pdf": "https://arxiv.org/pdf/2508.07648", "abs": "https://arxiv.org/abs/2508.07648", "authors": ["Mehrshad Zandigohar", "Mallesham Dasari", "Gunar Schirner"], "title": "Grasp-HGN: Grasping the Unexpected", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Paper accepted at ACM Transactions on Embedded Computing Systems", "summary": "For transradial amputees, robotic prosthetic hands promise to regain the\ncapability to perform daily living activities. To advance next-generation\nprosthetic hand control design, it is crucial to address current shortcomings\nin robustness to out of lab artifacts, and generalizability to new\nenvironments. Due to the fixed number of object to interact with in existing\ndatasets, contrasted with the virtually infinite variety of objects encountered\nin the real world, current grasp models perform poorly on unseen objects,\nnegatively affecting users' independence and quality of life.\n  To address this: (i) we define semantic projection, the ability of a model to\ngeneralize to unseen object types and show that conventional models like YOLO,\ndespite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose\nGrasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to\ninfer the suitable grasp type estimate based on the object's physical\ncharacteristics resulting in a significant 50.2% accuracy over unseen object\ntypes compared to 36.7% accuracy of an SOTA grasp estimation model.\n  Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp\nNetwork (HGN), an edge-cloud deployment infrastructure enabling fast grasp\nestimation on edge and accurate cloud inference as a fail-safe, effectively\nexpanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC)\nenables dynamic switching between edge and cloud models, improving semantic\nprojection accuracy by 5.6% (to 42.3%) with 3.5x speedup over the unseen object\ntypes. Over a real-world sample mix, it reaches 86% average accuracy (12.2%\ngain over edge-only), and 2.2x faster inference than Grasp-LLaVA alone.", "AI": {"tldr": "\u6587\u7ae0\u9488\u5bf9\u7ecf\u6861\u622a\u80a2\u8005\u5047\u80a2\u624b\u63a7\u5236\u95ee\u9898\uff0c\u63d0\u51fa\u8bed\u4e49\u6295\u5f71\u6982\u5ff5\uff0c\u4ecb\u7ecdGrasp - LLaVA\u6a21\u578b\u548cHybrid Grasp Network\uff08HGN\uff09\u67b6\u6784\u4ee5\u63d0\u5347\u5bf9\u672a\u77e5\u7269\u4f53\u6293\u63e1\u4f30\u8ba1\u6027\u80fd\u548c\u89e3\u51b3\u6027\u80fd - \u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6293\u63e1\u6a21\u578b\u5728\u5b9e\u9a8c\u5ba4\u5916\u9c81\u68d2\u6027\u548c\u65b0\u73af\u5883\u6cdb\u5316\u6027\u4e0d\u8db3\uff0c\u5bf9\u672a\u77e5\u7269\u4f53\u8868\u73b0\u5dee\uff0c\u5f71\u54cd\u7528\u6237\u72ec\u7acb\u6027\u548c\u751f\u6d3b\u8d28\u91cf\uff0c\u9700\u6539\u8fdb\u5047\u80a2\u624b\u63a7\u5236\u8bbe\u8ba1\u3002", "method": "\u5b9a\u4e49\u8bed\u4e49\u6295\u5f71\uff1b\u63d0\u51faGrasp - LLaVA\u6a21\u578b\u8fdb\u884c\u7c7b\u4eba\u63a8\u7406\u4f30\u8ba1\u6293\u63e1\u7c7b\u578b\uff1b\u63d0\u51faHGN\u8fb9\u7f18 - \u4e91\u90e8\u7f72\u67b6\u6784\uff0c\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u6821\u51c6\u5b9e\u73b0\u52a8\u6001\u5207\u6362\u3002", "result": "Grasp - LLaVA\u5bf9\u672a\u77e5\u7269\u4f53\u7c7b\u578b\u51c6\u786e\u7387\u8fbe50.2%\uff1bHGN\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u6821\u51c6\u4f7f\u8bed\u4e49\u6295\u5f71\u51c6\u786e\u7387\u63d0\u5347\u523042.3%\uff0c\u901f\u5ea6\u63d0\u53473.5\u500d\uff0c\u5728\u771f\u5b9e\u6837\u672c\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u8fbe86%\uff0c\u63a8\u7406\u901f\u5ea6\u6bd4Grasp - LLaVA\u5feb2.2\u500d\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5047\u80a2\u624b\u6293\u63e1\u6a21\u578b\u5bf9\u672a\u77e5\u7269\u4f53\u7684\u6027\u80fd\uff0c\u7f29\u5c0f\u4e86\u6027\u80fd - \u5ef6\u8fdf\u5dee\u8ddd\u3002"}}
{"id": "2508.07597", "pdf": "https://arxiv.org/pdf/2508.07597", "abs": "https://arxiv.org/abs/2508.07597", "authors": ["Yuang Zhang", "Junqi Cheng", "Haoyu Zhao", "Jiaxi Gu", "Fangyuan Zou", "Zenghui Lu", "Peng Shu"], "title": "ShoulderShot: Generating Over-the-Shoulder Dialogue Videos", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Over-the-shoulder dialogue videos are essential in films, short dramas, and\nadvertisements, providing visual variety and enhancing viewers' emotional\nconnection. Despite their importance, such dialogue scenes remain largely\nunderexplored in video generation research. The main challenges include\nmaintaining character consistency across different shots, creating a sense of\nspatial continuity, and generating long, multi-turn dialogues within limited\ncomputational budgets. Here, we present ShoulderShot, a framework that combines\ndual-shot generation with looping video, enabling extended dialogues while\npreserving character consistency. Our results demonstrate capabilities that\nsurpass existing methods in terms of shot-reverse-shot layout, spatial\ncontinuity, and flexibility in dialogue length, thereby opening up new\npossibilities for practical dialogue video generation. Videos and comparisons\nare available at https://shouldershot.github.io.", "AI": {"tldr": "\u63d0\u51faShoulderShot\u6846\u67b6\u7528\u4e8e\u8fc7\u80a9\u5bf9\u8bdd\u89c6\u9891\u751f\u6210\uff0c\u6548\u679c\u8d85\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8fc7\u80a9\u5bf9\u8bdd\u89c6\u9891\u91cd\u8981\u4f46\u5728\u89c6\u9891\u751f\u6210\u7814\u7a76\u4e2d\u672a\u5145\u5206\u63a2\u7d22\uff0c\u5b58\u5728\u4fdd\u6301\u89d2\u8272\u4e00\u81f4\u6027\u3001\u7a7a\u95f4\u8fde\u7eed\u6027\u548c\u751f\u6210\u591a\u8f6e\u5bf9\u8bdd\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u53cc\u955c\u5934\u751f\u6210\u4e0e\u5faa\u73af\u89c6\u9891\u7684ShoulderShot\u6846\u67b6\u3002", "result": "\u5728\u6b63\u53cd\u6253\u5e03\u5c40\u3001\u7a7a\u95f4\u8fde\u7eed\u6027\u548c\u5bf9\u8bdd\u957f\u5ea6\u7075\u6d3b\u6027\u65b9\u9762\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u4e3a\u5b9e\u9645\u5bf9\u8bdd\u89c6\u9891\u751f\u6210\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u3002"}}
{"id": "2508.07617", "pdf": "https://arxiv.org/pdf/2508.07617", "abs": "https://arxiv.org/abs/2508.07617", "authors": ["Sarah Jabbour", "David Fouhey", "Nikola Banovic", "Stephanie D. Shepard", "Ella Kazerooni", "Michael W. Sjoding", "Jenna Wiens"], "title": "On the Limits of Selective AI Prediction: A Case Study in Clinical Decision Making", "categories": ["cs.HC", "cs.AI"], "comment": "14 pages, 10 figures, 5 tables", "summary": "AI has the potential to augment human decision making. However, even\nhigh-performing models can produce inaccurate predictions when deployed. These\ninaccuracies, combined with automation bias, where humans overrely on AI\npredictions, can result in worse decisions. Selective prediction, in which\npotentially unreliable model predictions are hidden from users, has been\nproposed as a solution. This approach assumes that when AI abstains and informs\nthe user so, humans make decisions as they would without AI involvement. To\ntest this assumption, we study the effects of selective prediction on human\ndecisions in a clinical context. We conducted a user study of 259 clinicians\ntasked with diagnosing and treating hospitalized patients. We compared their\nbaseline performance without any AI involvement to their AI-assisted accuracy\nwith and without selective prediction. Our findings indicate that selective\nprediction mitigates the negative effects of inaccurate AI in terms of decision\naccuracy. Compared to no AI assistance, clinician accuracy declined when shown\ninaccurate AI predictions (66% [95% CI: 56%-75%] vs. 56% [95% CI: 46%-66%]),\nbut recovered under selective prediction (64% [95% CI: 54%-73%]). However,\nwhile selective prediction nearly maintains overall accuracy, our results\nsuggest that it alters patterns of mistakes: when informed the AI abstains,\nclinicians underdiagnose (18% increase in missed diagnoses) and undertreat (35%\nincrease in missed treatments) compared to no AI input at all. Our findings\nunderscore the importance of empirically validating assumptions about how\nhumans engage with AI within human-AI systems.", "AI": {"tldr": "\u7814\u7a76\u9009\u62e9\u6027\u9884\u6d4b\u5bf9\u4e34\u5e8a\u533b\u751f\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u53ef\u7f13\u89e3\u4e0d\u51c6\u786eAI\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u4f46\u4f1a\u6539\u53d8\u9519\u8bef\u6a21\u5f0f\uff0c\u5f3a\u8c03\u9a8c\u8bc1\u4eba\u673a\u7cfb\u7edf\u4e2d\u4eba\u7c7b\u4e0eAI\u4ea4\u4e92\u5047\u8bbe\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u6d4b\u8bd5\u9009\u62e9\u6027\u9884\u6d4b\u4e2dAI\u5f03\u6743\u65f6\u4eba\u7c7b\u51b3\u7b56\u4e0e\u65e0AI\u53c2\u4e0e\u65f6\u76f8\u540c\u8fd9\u4e00\u5047\u8bbe\uff0c\u7814\u7a76\u5176\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u5bf9\u4eba\u7c7b\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "method": "\u5bf9259\u540d\u4e34\u5e8a\u533b\u751f\u8fdb\u884c\u7528\u6237\u7814\u7a76\uff0c\u6bd4\u8f83\u65e0AI\u53c2\u4e0e\u3001\u6709\u4e0d\u51c6\u786eAI\u9884\u6d4b\u548c\u6709\u9009\u62e9\u6027\u9884\u6d4b\u65f6\u7684\u8bca\u65ad\u548c\u6cbb\u7597\u51c6\u786e\u6027\u3002", "result": "\u9009\u62e9\u6027\u9884\u6d4b\u7f13\u89e3\u4e86\u4e0d\u51c6\u786eAI\u5bf9\u51b3\u7b56\u51c6\u786e\u6027\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u4f7f\u51c6\u786e\u6027\u6709\u6240\u6062\u590d\uff0c\u4f46\u6539\u53d8\u4e86\u9519\u8bef\u6a21\u5f0f\uff0c\u51fa\u73b0\u66f4\u591a\u6f0f\u8bca\u548c\u6f0f\u6cbb\u60c5\u51b5\u3002", "conclusion": "\u5f3a\u8c03\u5728\u4eba\u673a\u7cfb\u7edf\u4e2d\uff0c\u5bf9\u4eba\u7c7b\u4e0eAI\u4ea4\u4e92\u5047\u8bbe\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.07621", "pdf": "https://arxiv.org/pdf/2508.07621", "abs": "https://arxiv.org/abs/2508.07621", "authors": ["Yunsung Chung", "Chanho Lim", "Ghassan Bidaoui", "Christian Massad", "Nassir Marrouche", "Jihun Hamm"], "title": "SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at MICCAI 2025. This is the author's original preprint", "summary": "Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with\ncatheter ablation procedures, but procedural outcomes are highly variable.\nEvaluating and improving ablation efficacy is challenging due to the complex\ninteraction between patient-specific tissue and procedural factors. This paper\nasks two questions: Can AF recurrence be predicted by simulating the effects of\nprocedural parameters? How should we ablate to reduce AF recurrence? We propose\nSOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel\ndeep-learning framework that addresses these questions. SOFA first simulates\nthe outcome of an ablation strategy by generating a post-ablation image\ndepicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and\nthe specific procedural parameters used (e.g., ablation locations, duration,\ntemperature, power, and force). During this simulation, it predicts AF\nrecurrence risk. Critically, SOFA then introduces an optimization scheme that\nrefines these procedural parameters to minimize the predicted risk. Our method\nleverages a multi-modal, multi-view generator that processes 2.5D\nrepresentations of the atrium. Quantitative evaluations show that SOFA\naccurately synthesizes post-ablation images and that our optimization scheme\nleads to a 22.18\\% reduction in the model-predicted recurrence risk. To the\nbest of our knowledge, SOFA is the first framework to integrate the simulation\nof procedural effects, recurrence prediction, and parameter optimization,\noffering a novel tool for personalizing AF ablation.", "AI": {"tldr": "\u63d0\u51faSOFA\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u53ef\u6a21\u62df\u623f\u98a4\u6d88\u878d\u6548\u679c\u3001\u9884\u6d4b\u590d\u53d1\u98ce\u9669\u5e76\u4f18\u5316\u53c2\u6570\uff0c\u4f7f\u9884\u6d4b\u590d\u53d1\u98ce\u9669\u964d\u4f4e22.18%\u3002", "motivation": "\u623f\u98a4\u5bfc\u7ba1\u6d88\u878d\u7ed3\u679c\u5dee\u5f02\u5927\uff0c\u8bc4\u4f30\u548c\u63d0\u9ad8\u6d88\u878d\u6548\u679c\u5177\u6311\u6218\u6027\uff0c\u9700\u9884\u6d4b\u590d\u53d1\u53ca\u4f18\u5316\u6d88\u878d\u7b56\u7565\u3002", "method": "\u63d0\u51faSOFA\u6846\u67b6\uff0c\u5148\u57fa\u4e8e\u60a3\u8005\u6d88\u878d\u524dLGE - MRI\u548c\u624b\u672f\u53c2\u6570\u6a21\u62df\u6d88\u878d\u7ed3\u679c\u5e76\u9884\u6d4b\u590d\u53d1\u98ce\u9669\uff0c\u518d\u4f18\u5316\u53c2\u6570\u4ee5\u964d\u4f4e\u98ce\u9669\uff0c\u5229\u7528\u591a\u6a21\u6001\u3001\u591a\u89c6\u56fe\u751f\u6210\u5668\u5904\u7406\u5fc3\u623f2.5D\u8868\u793a\u3002", "result": "SOFA\u80fd\u51c6\u786e\u5408\u6210\u6d88\u878d\u540e\u56fe\u50cf\uff0c\u4f18\u5316\u65b9\u6848\u4f7f\u6a21\u578b\u9884\u6d4b\u7684\u590d\u53d1\u98ce\u9669\u964d\u4f4e22.18%\u3002", "conclusion": "SOFA\u662f\u9996\u4e2a\u96c6\u6210\u624b\u672f\u6548\u679c\u6a21\u62df\u3001\u590d\u53d1\u9884\u6d4b\u548c\u53c2\u6570\u4f18\u5316\u7684\u6846\u67b6\uff0c\u4e3a\u4e2a\u6027\u5316\u623f\u98a4\u6d88\u878d\u63d0\u4f9b\u65b0\u5de5\u5177\u3002"}}
{"id": "2508.07773", "pdf": "https://arxiv.org/pdf/2508.07773", "abs": "https://arxiv.org/abs/2508.07773", "authors": ["Mohammed Salah", "Numan Saeed", "Davor Svetinovic", "Stefano Sfarra", "Mohammed Omar", "Yusra Abdulrahman"], "title": "PCA-Guided Autoencoding for Structured Dimensionality Reduction in Active Infrared Thermography", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "Infrared thermography, Non-Destructive Testing, Principal Component\n  Analysis, PCA-Guided Autoencoder, PCA Distillation Loss, Dimensionality\n  Reduction", "summary": "Active Infrared thermography (AIRT) is a widely adopted non-destructive\ntesting (NDT) technique for detecting subsurface anomalies in industrial\ncomponents. Due to the high dimensionality of AIRT data, current approaches\nemploy non-linear autoencoders (AEs) for dimensionality reduction. However, the\nlatent space learned by AIRT AEs lacks structure, limiting their effectiveness\nin downstream defect characterization tasks. To address this limitation, this\npaper proposes a principal component analysis guided (PCA-guided) autoencoding\nframework for structured dimensionality reduction to capture intricate,\nnon-linear features in thermographic signals while enforcing a structured\nlatent space. A novel loss function, PCA distillation loss, is introduced to\nguide AIRT AEs to align the latent representation with structured PCA\ncomponents while capturing the intricate, non-linear patterns in thermographic\nsignals. To evaluate the utility of the learned, structured latent space, we\npropose a neural network-based evaluation metric that assesses its suitability\nfor defect characterization. Experimental results show that the proposed\nPCA-guided AE outperforms state-of-the-art dimensionality reduction methods on\nPVC, CFRP, and PLA samples in terms of contrast, signal-to-noise ratio (SNR),\nand neural network-based metrics.", "AI": {"tldr": "\u63d0\u51faPCA\u5f15\u5bfc\u81ea\u52a8\u7f16\u7801\u6846\u67b6\u7528\u4e8e\u4e3b\u52a8\u7ea2\u5916\u70ed\u6210\u50cf\u6570\u636e\u964d\u7ef4\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4e3b\u52a8\u7ea2\u5916\u70ed\u6210\u50cf\u91c7\u7528\u975e\u7ebf\u6027\u81ea\u7f16\u7801\u5668\u964d\u7ef4\uff0c\u4f46\u5176\u6f5c\u5728\u7a7a\u95f4\u7f3a\u4e4f\u7ed3\u6784\uff0c\u9650\u5236\u7f3a\u9677\u8868\u5f81\u6548\u679c\u3002", "method": "\u63d0\u51faPCA\u5f15\u5bfc\u81ea\u52a8\u7f16\u7801\u6846\u67b6\uff0c\u5f15\u5165PCA\u84b8\u998f\u635f\u5931\u51fd\u6570\uff0c\u8fd8\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5728PVC\u3001CFRP\u548cPLA\u6837\u672c\u4e0a\uff0c\u6240\u63d0PCA\u5f15\u5bfc\u81ea\u7f16\u7801\u5668\u5728\u5bf9\u6bd4\u5ea6\u3001\u4fe1\u566a\u6bd4\u548c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u964d\u7ef4\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0PCA\u5f15\u5bfc\u81ea\u52a8\u7f16\u7801\u6846\u67b6\u80fd\u6709\u6548\u8fdb\u884c\u7ed3\u6784\u5316\u964d\u7ef4\uff0c\u63d0\u5347\u7f3a\u9677\u8868\u5f81\u6548\u679c\u3002"}}
{"id": "2508.07630", "pdf": "https://arxiv.org/pdf/2508.07630", "abs": "https://arxiv.org/abs/2508.07630", "authors": ["Anirudh Iyengar Kaniyar Narayana Iyengar", "Srija Mukhopadhyay", "Adnan Qidwai", "Shubhankar Singh", "Dan Roth", "Vivek Gupta"], "title": "InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information", "categories": ["cs.CL", "cs.AI", "cs.CV", "I.2.7; I.2.10; I.4.10; I.7.5"], "comment": "18 pages, 6 figures, 12 tables. Benchmark dataset and evaluation code\n  will be publicly made available", "summary": "We introduce InterChart, a diagnostic benchmark that evaluates how well\nvision-language models (VLMs) reason across multiple related charts, a task\ncentral to real-world applications such as scientific reporting, financial\nanalysis, and public policy dashboards. Unlike prior benchmarks focusing on\nisolated, visually uniform charts, InterChart challenges models with diverse\nquestion types ranging from entity inference and trend correlation to numerical\nestimation and abstract multi-step reasoning grounded in 2-3 thematically or\nstructurally related charts. We organize the benchmark into three tiers of\nincreasing difficulty: (1) factual reasoning over individual charts, (2)\nintegrative analysis across synthetically aligned chart sets, and (3) semantic\ninference over visually complex, real-world chart pairs. Our evaluation of\nstate-of-the-art open and closed-source VLMs reveals consistent and steep\naccuracy declines as chart complexity increases. We find that models perform\nbetter when we decompose multi-entity charts into simpler visual units,\nunderscoring their struggles with cross-chart integration. By exposing these\nsystematic limitations, InterChart provides a rigorous framework for advancing\nmultimodal reasoning in complex, multi-visual environments.", "AI": {"tldr": "\u4ecb\u7ecdInterChart\u57fa\u51c6\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8de8\u591a\u56fe\u8868\u63a8\u7406\u80fd\u529b\uff0c\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u5728\u56fe\u8868\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u5206\u89e3\u56fe\u8868\u53ef\u63d0\u5347\u8868\u73b0\u3002", "motivation": "\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u591a\u4e2a\u76f8\u5173\u56fe\u8868\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\uff0c\u8fd9\u5bf9\u73b0\u5b9e\u5e94\u7528\u5f88\u91cd\u8981\uff0c\u800c\u6b64\u524d\u57fa\u51c6\u591a\u5173\u6ce8\u5b64\u7acb\u56fe\u8868\u3002", "method": "\u7ec4\u7ec7InterChart\u57fa\u51c6\uff0c\u5206\u4e09\u4e2a\u96be\u5ea6\u7b49\u7ea7\uff0c\u7528\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\u6311\u6218\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u968f\u7740\u56fe\u8868\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u6a21\u578b\u51c6\u786e\u7387\u5927\u5e45\u4e0b\u964d\uff0c\u5206\u89e3\u56fe\u8868\u53ef\u63d0\u5347\u8868\u73b0\u3002", "conclusion": "InterChart\u63ed\u793a\u6a21\u578b\u5c40\u9650\uff0c\u4e3a\u590d\u6742\u591a\u89c6\u89c9\u73af\u5883\u4e0b\u591a\u6a21\u6001\u63a8\u7406\u63d0\u4f9b\u4e25\u8c28\u6846\u67b6\u3002"}}
{"id": "2508.07798", "pdf": "https://arxiv.org/pdf/2508.07798", "abs": "https://arxiv.org/abs/2508.07798", "authors": ["Cheng Li", "Pengfei Danga", "Yuehui Xiana", "Yumei Zhou", "Bofeng Shi", "Xiangdong Ding", "Jun Suna", "Dezhen Xue"], "title": "Generative Inversion for Property-Targeted Materials Design: Application to Shape Memory Alloys", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "The design of shape memory alloys (SMAs) with high transformation\ntemperatures and large mechanical work output remains a longstanding challenge\nin functional materials engineering. Here, we introduce a data-driven framework\nbased on generative adversarial network (GAN) inversion for the inverse design\nof high-performance SMAs. By coupling a pretrained GAN with a property\nprediction model, we perform gradient-based latent space optimization to\ndirectly generate candidate alloy compositions and processing parameters that\nsatisfy user-defined property targets. The framework is experimentally\nvalidated through the synthesis and characterization of five NiTi-based SMAs.\nAmong them, the Ni$_{49.8}$Ti$_{26.4}$Hf$_{18.6}$Zr$_{5.2}$ alloy achieves a\nhigh transformation temperature of 404 $^\\circ$C, a large mechanical work\noutput of 9.9 J/cm$^3$, a transformation enthalpy of 43 J/g , and a thermal\nhysteresis of 29 {\\deg}C, outperforming existing NiTi alloys. The enhanced\nperformance is attributed to a pronounced transformation volume change and a\nfinely dispersed of Ti$_2$Ni-type precipitates, enabled by sluggish Zr and Hf\ndiffusion, and semi-coherent interfaces with localized strain fields. This\nstudy demonstrates that GAN inversion offers an efficient and generalizable\nroute for the property-targeted discovery of complex alloys.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8eGAN\u53cd\u6f14\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6\u7528\u4e8e\u9ad8\u6027\u80fd\u5f62\u72b6\u8bb0\u5fc6\u5408\u91d1\u9006\u5411\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u53d1\u73b0\u6027\u80fd\u4f18\u5f02\u5408\u91d1\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u9ad8\u8f6c\u53d8\u6e29\u5ea6\u548c\u5927\u673a\u68b0\u529f\u8f93\u51fa\u5f62\u72b6\u8bb0\u5fc6\u5408\u91d1\u8bbe\u8ba1\u7684\u957f\u671f\u6311\u6218\u3002", "method": "\u5c06\u9884\u8bad\u7ec3GAN\u4e0e\u6027\u80fd\u9884\u6d4b\u6a21\u578b\u8026\u5408\uff0c\u8fdb\u884c\u57fa\u4e8e\u68af\u5ea6\u7684\u6f5c\u5728\u7a7a\u95f4\u4f18\u5316\uff0c\u751f\u6210\u6ee1\u8db3\u76ee\u6807\u6027\u80fd\u7684\u5408\u91d1\u6210\u5206\u548c\u52a0\u5de5\u53c2\u6570\u3002", "result": "\u5408\u6210\u5e76\u8868\u5f81\u4e94\u79cdNiTi\u57fa\u5408\u91d1\uff0c\u5176\u4e2dNi\u2084\u2089.\u2088Ti\u2082\u2086.\u2084Hf\u2081\u2088.\u2086Zr\u2085.\u2082\u5408\u91d1\u6027\u80fd\u4f18\u4e8e\u73b0\u6709NiTi\u5408\u91d1\u3002", "conclusion": "GAN\u53cd\u6f14\u4e3a\u590d\u6742\u5408\u91d1\u7684\u6027\u80fd\u5bfc\u5411\u53d1\u73b0\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u901a\u7528\u7684\u9014\u5f84\u3002"}}
{"id": "2508.07817", "pdf": "https://arxiv.org/pdf/2508.07817", "abs": "https://arxiv.org/abs/2508.07817", "authors": ["Tao Tang", "Chengxu Yang"], "title": "MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "comment": "6 pages, 6 figures", "summary": "The core role of medical images in disease diagnosis makes their quality\ndirectly affect the accuracy of clinical judgment. However, due to factors such\nas low-dose scanning, equipment limitations and imaging artifacts, medical\nimages are often accompanied by non-uniform noise interference, which seriously\naffects structure recognition and lesion detection. This paper proposes a\nmedical image adaptive denoising model (MI-ND) that integrates multi-scale\nconvolutional and Transformer architecture, introduces a noise level estimator\n(NLE) and a noise adaptive attention module (NAAB), and realizes\nchannel-spatial attention regulation and cross-modal feature fusion driven by\nnoise perception. Systematic testing is carried out on multimodal public\ndatasets. Experiments show that this method significantly outperforms the\ncomparative methods in image quality indicators such as PSNR, SSIM, and LPIPS,\nand improves the F1 score and ROC-AUC in downstream diagnostic tasks, showing\nstrong prac-tical value and promotional potential. The model has outstanding\nbenefits in structural recovery, diagnostic sensitivity, and cross-modal\nrobustness, and provides an effective solution for medical image enhancement\nand AI-assisted diagnosis and treatment.", "AI": {"tldr": "\u63d0\u51fa\u96c6\u6210\u591a\u5c3a\u5ea6\u5377\u79ef\u548cTransformer\u67b6\u6784\u7684\u533b\u5b66\u56fe\u50cf\u81ea\u9002\u5e94\u53bb\u566a\u6a21\u578bMI - ND\uff0c\u7ecf\u6d4b\u8bd5\u5728\u56fe\u50cf\u8d28\u91cf\u6307\u6807\u548c\u4e0b\u6e38\u8bca\u65ad\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u5b9e\u7528\u548c\u63a8\u5e7f\u4ef7\u503c\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u5e38\u53d7\u975e\u5747\u5300\u566a\u58f0\u5e72\u6270\uff0c\u5f71\u54cd\u7ed3\u6784\u8bc6\u522b\u548c\u75c5\u53d8\u68c0\u6d4b\uff0c\u9700\u63d0\u9ad8\u56fe\u50cf\u8d28\u91cf\u4ee5\u63d0\u5347\u4e34\u5e8a\u5224\u65ad\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u533b\u5b66\u56fe\u50cf\u81ea\u9002\u5e94\u53bb\u566a\u6a21\u578bMI - ND\uff0c\u5f15\u5165\u566a\u58f0\u6c34\u5e73\u4f30\u8ba1\u5668NLE\u548c\u566a\u58f0\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u6a21\u5757NAAB\uff0c\u5b9e\u73b0\u901a\u9053 - \u7a7a\u95f4\u6ce8\u610f\u529b\u8c03\u8282\u548c\u8de8\u6a21\u6001\u7279\u5f81\u878d\u5408\u3002", "result": "\u5728\u591a\u6a21\u6001\u516c\u5171\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u8be5\u65b9\u6cd5\u5728PSNR\u3001SSIM\u3001LPIPS\u7b49\u56fe\u50cf\u8d28\u91cf\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u4e0b\u6e38\u8bca\u65ad\u4efb\u52a1\u7684F1\u5206\u6570\u548cROC - AUC\u3002", "conclusion": "\u6a21\u578b\u5728\u7ed3\u6784\u6062\u590d\u3001\u8bca\u65ad\u654f\u611f\u6027\u548c\u8de8\u6a21\u6001\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u533b\u5b66\u56fe\u50cf\u589e\u5f3a\u548cAI\u8f85\u52a9\u8bca\u7597\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07819", "pdf": "https://arxiv.org/pdf/2508.07819", "abs": "https://arxiv.org/abs/2508.07819", "authors": ["Ke Ma", "Jun Long", "Hongxiao Fei", "Liujie Hua", "Yueyi Luo"], "title": "Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "4 pages, 1 reference, 3 figures, icassp 2026", "summary": "Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap\nwhen applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of\nlocal inductive biases for dense prediction and their reliance on inflexible\nfeature fusion paradigms. We address these limitations through an Architectural\nCo-Design framework that jointly refines feature representation and cross-modal\nfusion. Our method integrates a parameter-efficient Convolutional Low-Rank\nAdaptation (Conv-LoRA) adapter to inject local inductive biases for\nfine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that\nleverages visual context to adaptively modulate text prompts, enabling a\npowerful bidirectional fusion. Extensive experiments on diverse industrial and\nmedical benchmarks demonstrate superior accuracy and robustness, validating\nthat this synergistic co-design is critical for robustly adapting foundation\nmodels to dense perception tasks.", "AI": {"tldr": "\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u96f6\u6837\u672c\u5f02\u5e38\u68c0\u6d4b\u5b58\u5728\u9002\u5e94\u5dee\u8ddd\uff0c\u63d0\u51fa\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\u89e3\u51b3\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u96f6\u6837\u672c\u5f02\u5e38\u68c0\u6d4b\u65f6\u5b58\u5728\u56e0\u7f3a\u4e4f\u5c40\u90e8\u5f52\u7eb3\u504f\u7f6e\u548c\u4f9d\u8d56\u4e0d\u7075\u6d3b\u7279\u5f81\u878d\u5408\u8303\u5f0f\u5bfc\u81f4\u7684\u9002\u5e94\u5dee\u8ddd\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u96c6\u6210\u53c2\u6570\u9ad8\u6548\u7684\u5377\u79ef\u4f4e\u79e9\u81ea\u9002\u5e94\u9002\u914d\u5668\u6ce8\u5165\u5c40\u90e8\u5f52\u7eb3\u504f\u7f6e\uff0c\u5f15\u5165\u52a8\u6001\u878d\u5408\u7f51\u5173\u5229\u7528\u89c6\u89c9\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u8c03\u8282\u6587\u672c\u63d0\u793a\u5b9e\u73b0\u53cc\u5411\u878d\u5408\u3002", "result": "\u5728\u4e0d\u540c\u5de5\u4e1a\u548c\u533b\u5b66\u57fa\u51c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u79cd\u534f\u540c\u8bbe\u8ba1\u5bf9\u4e8e\u5c06\u57fa\u7840\u6a21\u578b\u7a33\u5065\u5730\u5e94\u7528\u4e8e\u5bc6\u96c6\u611f\u77e5\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.07836", "pdf": "https://arxiv.org/pdf/2508.07836", "abs": "https://arxiv.org/abs/2508.07836", "authors": ["Vishwas M. Shetty", "Jiusi Zheng", "Abeer Alwan"], "title": "G-IFT: A Gated Linear Unit adapter with Iterative Fine-Tuning for Low-Resource Children's Speaker Verification", "categories": ["eess.AS", "cs.LG"], "comment": "Accepted at WOCCI, 2025 - Interspeech workshop", "summary": "Speaker Verification (SV) systems trained on adults speech often underperform\non children's SV due to the acoustic mismatch, and limited children speech data\nmakes fine-tuning not very effective. In this paper, we propose an innovative\nframework, a Gated Linear Unit adapter with Iterative Fine-Tuning (G-IFT), to\nenhance knowledge transfer efficiency between the high-resource adults speech\ndomain and the low-resource children's speech domain. In this framework, a\nGated Linear Unit adapter is first inserted between the pre-trained speaker\nembedding model and the classifier. Then the classifier, adapter, and\npre-trained speaker embedding model are optimized sequentially in an iterative\nway. This framework is agnostic to the type of the underlying architecture of\nthe SV system. Our experiments on ECAPA-TDNN, ResNet, and X-vector\narchitectures using the OGI and MyST datasets demonstrate that the G-IFT\nframework yields consistent reductions in Equal Error Rates compared to\nbaseline methods.", "AI": {"tldr": "\u63d0\u51faG - IFT\u6846\u67b6\u63d0\u5347\u6210\u4eba\u4e0e\u513f\u7ae5\u8bed\u97f3\u9886\u57df\u77e5\u8bc6\u8f6c\u79fb\u6548\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u964d\u4f4e\u7b49\u9519\u8bef\u7387\u3002", "motivation": "\u6210\u4eba\u8bed\u97f3\u8bad\u7ec3\u7684\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u7cfb\u7edf\u5728\u513f\u7ae5\u8bed\u97f3\u9a8c\u8bc1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u513f\u7ae5\u8bed\u97f3\u6570\u636e\u6709\u9650\u4f7f\u5fae\u8c03\u6548\u679c\u4e0d\u597d\u3002", "method": "\u5728\u9884\u8bad\u7ec3\u8bf4\u8bdd\u4eba\u5d4c\u5165\u6a21\u578b\u548c\u5206\u7c7b\u5668\u4e4b\u95f4\u63d2\u5165\u95e8\u63a7\u7ebf\u6027\u5355\u5143\u9002\u914d\u5668\uff0c\u7136\u540e\u8fed\u4ee3\u4f9d\u6b21\u4f18\u5316\u5206\u7c7b\u5668\u3001\u9002\u914d\u5668\u548c\u9884\u8bad\u7ec3\u8bf4\u8bdd\u4eba\u5d4c\u5165\u6a21\u578b\u3002", "result": "\u5728ECAPA - TDNN\u3001ResNet\u548cX - vector\u67b6\u6784\u4e0a\u4f7f\u7528OGI\u548cMyST\u6570\u636e\u96c6\u5b9e\u9a8c\uff0cG - IFT\u6846\u67b6\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6301\u7eed\u964d\u4f4e\u7b49\u9519\u8bef\u7387\u3002", "conclusion": "G - IFT\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u9ad8\u4f4e\u8d44\u6e90\u8bed\u97f3\u9886\u57df\u95f4\u7684\u77e5\u8bc6\u8f6c\u79fb\u6548\u7387\uff0c\u4e14\u5bf9\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u7cfb\u7edf\u5e95\u5c42\u67b6\u6784\u7c7b\u578b\u4e0d\u654f\u611f\u3002"}}
{"id": "2508.07863", "pdf": "https://arxiv.org/pdf/2508.07863", "abs": "https://arxiv.org/abs/2508.07863", "authors": ["Bin Cao", "Sipeng Zheng", "Ye Wang", "Lujie Xia", "Qianshan Wei", "Qin Jin", "Jing Liu", "Zongqing Lu"], "title": "Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model", "categories": ["cs.CV", "cs.LG"], "comment": "16 pages", "summary": "Human motion generation has emerged as a critical technology with\ntransformative potential for real-world applications. However, existing\nvision-language-motion models (VLMMs) face significant limitations that hinder\ntheir practical deployment. We identify controllability as a main bottleneck,\nmanifesting in five key aspects: inadequate response to diverse human commands,\nlimited pose initialization capabilities, poor performance on long-term\nsequences, insufficient handling of unseen scenarios, and lack of fine-grained\ncontrol over individual body parts. To overcome these limitations, we present\nBeing-M0.5, the first real-time, controllable VLMM that achieves\nstate-of-the-art performance across multiple motion generation tasks. Our\napproach is built upon HuMo100M, the largest and most comprehensive human\nmotion dataset to date, comprising over 5 million self-collected motion\nsequences, 100 million multi-task instructional instances, and detailed\npart-level annotations that address a critical gap in existing datasets. We\nintroduce a novel part-aware residual quantization technique for motion\ntokenization that enables precise, granular control over individual body parts\nduring generation. Extensive experimental validation demonstrates Being-M0.5's\nsuperior performance across diverse motion benchmarks, while comprehensive\nefficiency analysis confirms its real-time capabilities. Our contributions\ninclude design insights and detailed computational analysis to guide future\ndevelopment of practical motion generators. We believe that HuMo100M and\nBeing-M0.5 represent significant advances that will accelerate the adoption of\nmotion generation technologies in real-world applications. The project page is\navailable at https://beingbeyond.github.io/Being-M0.5.", "AI": {"tldr": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u8fd0\u52a8\u6a21\u578b\u5728\u53ef\u63a7\u6027\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51fa\u5b9e\u65f6\u53ef\u63a7\u7684VLMM Being - M0.5\uff0c\u57fa\u4e8eHuMo100M\u6570\u636e\u96c6\u548c\u65b0\u7684\u91cf\u5316\u6280\u672f\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u5e76\u5177\u5b9e\u65f6\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u8fd0\u52a8\u6a21\u578b\uff08VLMMs\uff09\u5b58\u5728\u53ef\u63a7\u6027\u74f6\u9888\uff0c\u5305\u62ec\u5bf9\u591a\u6837\u547d\u4ee4\u54cd\u5e94\u4e0d\u8db3\u7b49\u4e94\u65b9\u9762\u95ee\u9898\uff0c\u963b\u788d\u5176\u5b9e\u8df5\u5e94\u7528\u3002", "method": "\u57fa\u4e8eHuMo100M\u6570\u636e\u96c6\uff0c\u5f15\u5165\u65b0\u9896\u7684\u90e8\u5206\u611f\u77e5\u6b8b\u5dee\u91cf\u5316\u6280\u672f\u8fdb\u884c\u8fd0\u52a8\u6807\u8bb0\u5316\u3002", "result": "Being - M0.5\u5728\u591a\u6837\u8fd0\u52a8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u6548\u7387\u5206\u6790\u8bc1\u5b9e\u5176\u5b9e\u65f6\u80fd\u529b\u3002", "conclusion": "HuMo100M\u548cBeing - M0.5\u662f\u91cd\u8981\u8fdb\u5c55\uff0c\u5c06\u52a0\u901f\u8fd0\u52a8\u751f\u6210\u6280\u672f\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u91c7\u7528\u3002"}}
{"id": "2508.07872", "pdf": "https://arxiv.org/pdf/2508.07872", "abs": "https://arxiv.org/abs/2508.07872", "authors": ["Holli Sargeant", "Mackenzie Jorgensen", "Arina Shah", "Adrian Weller", "Umang Bhatt"], "title": "Unequal Uncertainty: Rethinking Algorithmic Interventions for Mitigating Discrimination from AI", "categories": ["cs.CY", "cs.HC", "cs.LG"], "comment": null, "summary": "Uncertainty in artificial intelligence (AI) predictions poses urgent legal\nand ethical challenges for AI-assisted decision-making. We examine two\nalgorithmic interventions that act as guardrails for human-AI collaboration:\nselective abstention, which withholds high-uncertainty predictions from human\ndecision-makers, and selective friction, which delivers those predictions\ntogether with salient warnings or disclosures that slow the decision process.\nResearch has shown that selective abstention based on uncertainty can\ninadvertently exacerbate disparities and disadvantage under-represented groups\nthat disproportionately receive uncertain predictions. In this paper, we\nprovide the first integrated socio-technical and legal analysis of\nuncertainty-based algorithmic interventions. Through two case studies,\nAI-assisted consumer credit decisions and AI-assisted content moderation, we\ndemonstrate how the seemingly neutral use of uncertainty thresholds can trigger\ndiscriminatory impacts. We argue that, although both interventions pose risks\nof unlawful discrimination under UK law, selective frictions offer a promising\npathway toward fairer and more accountable AI-assisted decision-making by\npreserving transparency and encouraging more cautious human judgment.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u7b97\u6cd5\u5e72\u9884\u8fdb\u884c\u793e\u4f1a\u6280\u672f\u548c\u6cd5\u5f8b\u5206\u6790\uff0c\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u4e0d\u786e\u5b9a\u6027\u9608\u503c\u4f7f\u7528\u7684\u6b67\u89c6\u5f71\u54cd\uff0c\u8ba4\u4e3a\u9009\u62e9\u6027\u6469\u64e6\u662f\u66f4\u516c\u5e73\u3001\u8d1f\u8d23\u7684AI\u8f85\u52a9\u51b3\u7b56\u9014\u5f84\u3002", "motivation": "\u89e3\u51b3AI\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7ed9AI\u8f85\u52a9\u51b3\u7b56\u5e26\u6765\u7684\u6cd5\u5f8b\u548c\u4f26\u7406\u6311\u6218\u3002", "method": "\u5bf9\u9009\u62e9\u6027\u5f03\u6743\u548c\u9009\u62e9\u6027\u6469\u64e6\u4e24\u79cd\u7b97\u6cd5\u5e72\u9884\u8fdb\u884c\u7814\u7a76\uff0c\u901a\u8fc7AI\u8f85\u52a9\u6d88\u8d39\u4fe1\u8d37\u51b3\u7b56\u548c\u5185\u5bb9\u5ba1\u6838\u4e24\u4e2a\u6848\u4f8b\u5206\u6790\u3002", "result": "\u770b\u4f3c\u4e2d\u7acb\u7684\u4e0d\u786e\u5b9a\u6027\u9608\u503c\u4f7f\u7528\u4f1a\u89e6\u53d1\u6b67\u89c6\u6027\u5f71\u54cd\uff0c\u4e24\u79cd\u5e72\u9884\u5728\u82f1\u56fd\u6cd5\u5f8b\u4e0b\u90fd\u6709\u975e\u6cd5\u6b67\u89c6\u98ce\u9669\u3002", "conclusion": "\u9009\u62e9\u6027\u6469\u64e6\u901a\u8fc7\u4fdd\u6301\u900f\u660e\u5ea6\u548c\u9f13\u52b1\u66f4\u8c28\u614e\u7684\u4eba\u7c7b\u5224\u65ad\uff0c\u662f\u5b9e\u73b0\u66f4\u516c\u5e73\u3001\u66f4\u8d1f\u8d23\u4efb\u7684AI\u8f85\u52a9\u51b3\u7b56\u7684\u6709\u5e0c\u671b\u9014\u5f84\u3002"}}
{"id": "2508.07683", "pdf": "https://arxiv.org/pdf/2508.07683", "abs": "https://arxiv.org/abs/2508.07683", "authors": ["Chaohong Guo", "Xun Mo", "Yongwei Nie", "Xuemiao Xu", "Chao Xu", "Fei Yu", "Chengjiang Long"], "title": "TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Temporal Video Grounding (TVG) aims to precisely localize video segments\ncorresponding to natural language queries, which is a critical capability for\nlong-form video understanding. Although existing reinforcement learning\napproaches encourage models to generate reasoning chains before predictions,\nthey fail to explicitly constrain the reasoning process to ensure the quality\nof the final temporal predictions. To address this limitation, we propose\nTimestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG),\na novel framework that introduces timestamp anchors within the reasoning\nprocess to enforce explicit supervision to the thought content. These anchors\nserve as intermediate verification points. More importantly, we require each\nreasoning step to produce increasingly accurate temporal estimations, thereby\nensuring that the reasoning process contributes meaningfully to the final\nprediction. To address the challenge of low-probability anchor generation in\nmodels (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation\ntraining strategy: (1) initial GRPO training to collect 30K high-quality\nreasoning traces containing multiple timestamp anchors, (2) supervised\nfine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the\nSFT-enhanced model. This three-stage training strategy enables robust anchor\ngeneration while maintaining reasoning quality. Experiments show that our model\nachieves state-of-the-art performance while producing interpretable, verifiable\nreasoning chains with progressively refined temporal estimations.", "AI": {"tldr": "\u63d0\u51faTAR - TVG\u6846\u67b6\u7528\u4e8e\u65f6\u95f4\u89c6\u9891\u5b9a\u4f4d\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u73b0\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u672a\u660e\u786e\u7ea6\u675f\u63a8\u7406\u8fc7\u7a0b\u4ee5\u4fdd\u8bc1\u6700\u7ec8\u65f6\u95f4\u9884\u6d4b\u8d28\u91cf\u3002", "method": "\u63d0\u51faTAR - TVG\u6846\u67b6\u5f15\u5165\u65f6\u95f4\u6233\u951a\u70b9\u7ea6\u675f\u63a8\u7406\u8fc7\u7a0b\uff1b\u5f00\u53d1\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5305\u62ec\u521d\u59cbGRPO\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u3001\u6700\u7ec8GRPO\u4f18\u5316\u3002", "result": "\u6a21\u578b\u8fbe\u5230\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\uff0c\u4ea7\u751f\u53ef\u89e3\u91ca\u3001\u53ef\u9a8c\u8bc1\u4e14\u65f6\u95f4\u4f30\u8ba1\u9010\u6b65\u7ec6\u5316\u7684\u63a8\u7406\u94fe\u3002", "conclusion": "TAR - TVG\u6846\u67b6\u53ca\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u6709\u6548\uff0c\u80fd\u63d0\u5347\u65f6\u95f4\u89c6\u9891\u5b9a\u4f4d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.07875", "pdf": "https://arxiv.org/pdf/2508.07875", "abs": "https://arxiv.org/abs/2508.07875", "authors": ["Shuo Han", "Ahmed Karam Eldaly", "Solomon Sunday Oyelere"], "title": "Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.HC"], "comment": null, "summary": "Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer,\nand early, accurate diagnosis is critical to improving patient survival rates\nby guiding treatment decisions. Combining medical expertise with artificial\nintelligence (AI) holds significant promise for enhancing the precision and\nefficiency of IDC detection. In this work, we propose a human-in-the-loop\n(HITL) deep learning system designed to detect IDC in histopathology images.\nThe system begins with an initial diagnosis provided by a high-performance\nEfficientNetV2S model, offering feedback from AI to the human expert. Medical\nprofessionals then review the AI-generated results, correct any misclassified\nimages, and integrate the revised labels into the training dataset, forming a\nfeedback loop from the human back to the AI. This iterative process refines the\nmodel's performance over time. The EfficientNetV2S model itself achieves\nstate-of-the-art performance compared to existing methods in the literature,\nwith an overall accuracy of 93.65\\%. Incorporating the human-in-the-loop system\nfurther improves the model's accuracy using four experimental groups with\nmisclassified images. These results demonstrate the potential of this\ncollaborative approach to enhance AI performance in diagnostic systems. This\nwork contributes to advancing automated, efficient, and highly accurate methods\nfor IDC detection through human-AI collaboration, offering a promising\ndirection for future AI-assisted medical diagnostics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4eba\u5728\u56de\u8def\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u68c0\u6d4b\u6d78\u6da6\u6027\u5bfc\u7ba1\u764c\uff08IDC\uff09\uff0c\u8fed\u4ee3\u4f18\u5316\u6a21\u578b\u6027\u80fd\uff0c\u8bc1\u660e\u4eba\u673a\u534f\u4f5c\u53ef\u63d0\u5347AI\u8bca\u65ad\u6027\u80fd\u3002", "motivation": "\u6d78\u6da6\u6027\u5bfc\u7ba1\u764c\u662f\u6700\u5e38\u89c1\u7684\u4e73\u817a\u764c\u5f62\u5f0f\uff0c\u65e9\u671f\u51c6\u786e\u8bca\u65ad\u5bf9\u63d0\u9ad8\u60a3\u8005\u751f\u5b58\u7387\u81f3\u5173\u91cd\u8981\uff0c\u7ed3\u5408\u533b\u5b66\u4e13\u4e1a\u77e5\u8bc6\u548c\u4eba\u5de5\u667a\u80fd\u6709\u671b\u63d0\u9ad8IDC\u68c0\u6d4b\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4eba\u5728\u56de\u8def\uff08HITL\uff09\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\uff0c\u5148\u7531EfficientNetV2S\u6a21\u578b\u8fdb\u884c\u521d\u59cb\u8bca\u65ad\uff0c\u533b\u5b66\u4e13\u5bb6\u5ba1\u67e5\u5e76\u4fee\u6b63\u9519\u8bef\u5206\u7c7b\u56fe\u50cf\uff0c\u5c06\u4fee\u6b63\u6807\u7b7e\u6574\u5408\u5230\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u5f62\u6210\u53cd\u9988\u5faa\u73af\u3002", "result": "EfficientNetV2S\u6a21\u578b\u672c\u8eab\u51c6\u786e\u7387\u8fbe93.65%\uff0c\u7ed3\u5408\u4eba\u5728\u56de\u8def\u7cfb\u7edf\uff0c\u901a\u8fc7\u56db\u4e2a\u5305\u542b\u9519\u8bef\u5206\u7c7b\u56fe\u50cf\u7684\u5b9e\u9a8c\u7ec4\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u4eba\u673a\u534f\u4f5c\u65b9\u6cd5\u6709\u6f5c\u529b\u63d0\u5347AI\u5728\u8bca\u65ad\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765AI\u8f85\u52a9\u533b\u5b66\u8bca\u65ad\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2508.07690", "pdf": "https://arxiv.org/pdf/2508.07690", "abs": "https://arxiv.org/abs/2508.07690", "authors": ["Luyao Zhuang", "Qinggang Zhang", "Huachi Zhou", "Juhua Liu", "Qing Li", "Xiao Huang"], "title": "LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Tool learning has emerged as a promising paradigm for large language models\n(LLMs) to solve many real-world tasks. Nonetheless, with the tool repository\nrapidly expanding, it is impractical to contain all tools within the limited\ninput length of LLMs. To alleviate these issues, researchers have explored\nincorporating a tool retrieval module to select the most relevant tools or\nrepresent tools as unique tokens within LLM parameters. However, most\nstate-of-the-art methods are under transductive settings, assuming all tools\nhave been observed during training. Such a setting deviates from reality as the\nreal-world tool repository is evolving and incorporates new tools frequently.\nWhen dealing with these unseen tools, which refer to tools not encountered\nduring the training phase, these methods are limited by two key issues,\nincluding the large distribution shift and the vulnerability of\nsimilarity-based retrieval. To this end, inspired by human cognitive processes\nof mastering unseen tools through discovering and applying the logical\ninformation from prior experience, we introduce a novel Logic-Guided Semantic\nBridging framework for inductive tool retrieval, namely, LoSemB, which aims to\nmine and transfer latent logical information for inductive tool retrieval\nwithout costly retraining. Specifically, LoSemB contains a logic-based\nembedding alignment module to mitigate distribution shifts and implements a\nrelational augmented retrieval mechanism to reduce the vulnerability of\nsimilarity-based retrieval. Extensive experiments demonstrate that LoSemB\nachieves advanced performance in inductive settings while maintaining desirable\neffectiveness in the transductive setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u5f52\u7eb3\u5f0f\u5de5\u5177\u68c0\u7d22\u7684\u903b\u8f91\u5f15\u5bfc\u8bed\u4e49\u6865\u63a5\u6846\u67b6LoSemB\uff0c\u53ef\u6316\u6398\u548c\u8f6c\u79fb\u6f5c\u5728\u903b\u8f91\u4fe1\u606f\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u5f52\u7eb3\u548c\u76f4\u63a8\u8bbe\u7f6e\u4e0b\u5747\u6709\u826f\u597d\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u591a\u4e3a\u76f4\u63a8\u5f0f\uff0c\u96be\u4ee5\u5904\u7406\u8bad\u7ec3\u4e2d\u672a\u89c1\u8fc7\u7684\u65b0\u5de5\u5177\uff0c\u5b58\u5728\u5206\u5e03\u504f\u79fb\u548c\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u68c0\u7d22\u6613\u53d7\u653b\u51fb\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165LoSemB\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u903b\u8f91\u7684\u5d4c\u5165\u5bf9\u9f50\u6a21\u5757\u548c\u5173\u7cfb\u589e\u5f3a\u68c0\u7d22\u673a\u5236\u3002", "result": "LoSemB\u5728\u5f52\u7eb3\u8bbe\u7f6e\u4e0b\u53d6\u5f97\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u76f4\u63a8\u8bbe\u7f6e\u4e0b\u4e5f\u4fdd\u6301\u4e86\u826f\u597d\u6548\u679c\u3002", "conclusion": "LoSemB\u80fd\u6709\u6548\u89e3\u51b3\u672a\u89c1\u8fc7\u5de5\u5177\u7684\u68c0\u7d22\u95ee\u9898\uff0c\u65e0\u9700\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\u3002"}}
{"id": "2508.07923", "pdf": "https://arxiv.org/pdf/2508.07923", "abs": "https://arxiv.org/abs/2508.07923", "authors": ["Jakub Binda", "Valentina Paneta", "Vasileios Eleftheriadis", "Hongkyou Chung", "Panagiotis Papadimitroulas", "Neo Christopher Chung"], "title": "Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "Generative AI holds great potentials to automate and enhance data synthesis\nin nuclear medicine. However, the high-stakes nature of biomedical imaging\nnecessitates robust mechanisms to detect and manage unexpected or erroneous\nmodel behavior. We introduce development and implementation of a hybrid anomaly\ndetection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems.\nTwo applications are demonstrated: Pose2Xray, which generates synthetic X-rays\nfrom photographic mouse images, and DosimetrEYE, which estimates 3D radiation\ndose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD)\nenhances reliability, reduces manual oversight, and supports real-time quality\ncontrol. This approach strengthens the industrial viability of GenAI in\npreclinical settings by increasing robustness, scalability, and regulatory\ncompliance.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\u4fdd\u969c\u6838\u533b\u5b66GenAI\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u4e2a\u5e94\u7528\u5c55\u793a\u5176\u589e\u5f3a\u53ef\u9760\u6027\u7b49\u4f18\u52bf\uff0c\u63d0\u5347GenAI\u5728\u4e34\u5e8a\u524d\u73af\u5883\u7684\u5de5\u4e1a\u53ef\u884c\u6027\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u6210\u50cf\u7684\u9ad8\u98ce\u9669\u6027\u8d28\u9700\u8981\u68c0\u6d4b\u548c\u7ba1\u7406GenAI\u6a21\u578b\u610f\u5916\u6216\u9519\u8bef\u884c\u4e3a\u7684\u673a\u5236\u3002", "method": "\u5f00\u53d1\u548c\u5b9e\u65bd\u6df7\u5408\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\u3002", "result": "\u5728Pose2Xray\u548cDosimetrEYE\u4e24\u4e2a\u5e94\u7528\u4e2d\uff0c\u5f02\u5e38\u68c0\u6d4b\u589e\u5f3a\u4e86\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u4eba\u5de5\u76d1\u7763\uff0c\u652f\u6301\u5b9e\u65f6\u8d28\u91cf\u63a7\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u63d0\u9ad8\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u5408\u89c4\u6027\uff0c\u63d0\u5347\u4e86GenAI\u5728\u4e34\u5e8a\u524d\u73af\u5883\u7684\u5de5\u4e1a\u53ef\u884c\u6027\u3002"}}
{"id": "2508.07714", "pdf": "https://arxiv.org/pdf/2508.07714", "abs": "https://arxiv.org/abs/2508.07714", "authors": ["Licheng Zhang", "Bach Le", "Naveed Akhtar", "Tuan Ngo"], "title": "DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.ET"], "comment": null, "summary": "Accurate detection and classification of diverse door types in floor plans\ndrawings is critical for multiple applications, such as building compliance\nchecking, and indoor scene understanding. Despite their importance, publicly\navailable datasets specifically designed for fine-grained multi-class door\ndetection remain scarce. In this work, we present a semi-automated pipeline\nthat leverages a state-of-the-art object detector and a large language model\n(LLM) to construct a multi-class door detection dataset with minimal manual\neffort. Doors are first detected as a unified category using a deep object\ndetection model. Next, an LLM classifies each detected instance based on its\nvisual and contextual features. Finally, a human-in-the-loop stage ensures\nhigh-quality labels and bounding boxes. Our method significantly reduces\nannotation cost while producing a dataset suitable for benchmarking neural\nmodels in floor plan analysis. This work demonstrates the potential of\ncombining deep learning and multimodal reasoning for efficient dataset\nconstruction in complex real-world domains.", "AI": {"tldr": "\u63d0\u51fa\u534a\u81ea\u52a8\u5316\u6d41\u7a0b\u6784\u5efa\u591a\u7c7b\u95e8\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u964d\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u5c55\u793a\u6df1\u5ea6\u5b66\u4e60\u4e0e\u591a\u6a21\u6001\u63a8\u7406\u6784\u5efa\u6570\u636e\u96c6\u6f5c\u529b\u3002", "motivation": "\u51c6\u786e\u68c0\u6d4b\u548c\u5206\u7c7b\u5e73\u9762\u56fe\u4e2d\u95e8\u7c7b\u578b\u5f88\u91cd\u8981\uff0c\u4f46\u516c\u5f00\u7684\u7ec6\u7c92\u5ea6\u591a\u7c7b\u95e8\u68c0\u6d4b\u6570\u636e\u96c6\u7a00\u7f3a\u3002", "method": "\u5229\u7528\u5148\u8fdb\u76ee\u6807\u68c0\u6d4b\u5668\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5148\u4ee5\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u95e8\uff0c\u518d\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u7c7b\uff0c\u6700\u540e\u6709\u4eba\u5728\u73af\u786e\u4fdd\u6807\u6ce8\u8d28\u91cf\u3002", "result": "\u663e\u8457\u964d\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u751f\u6210\u9002\u7528\u4e8e\u5e73\u9762\u56fe\u5206\u6790\u4e2d\u795e\u7ecf\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u591a\u6a21\u6001\u63a8\u7406\u5728\u590d\u6742\u73b0\u5b9e\u9886\u57df\u9ad8\u6548\u6784\u5efa\u6570\u636e\u96c6\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.07731", "pdf": "https://arxiv.org/pdf/2508.07731", "abs": "https://arxiv.org/abs/2508.07731", "authors": ["Abdul Basit", "Maha Nawaz", "Saim Rehman", "Muhammad Shafique"], "title": "CognitiveArm: Enabling Real-Time EEG-Controlled Prosthetic Arm Using Embodied Machine Learning", "categories": ["cs.HC", "cs.AI", "68T50, 68T40, 68T07, 92C55", "I.2.7; I.2.9"], "comment": "7 pages, 12 figures, Accepted to 62nd DAC 2025", "summary": "Efficient control of prosthetic limbs via non-invasive brain-computer\ninterfaces (BCIs) requires advanced EEG processing, including pre-filtering,\nfeature extraction, and action prediction, performed in real time on edge AI\nhardware. Achieving this on resource-constrained devices presents challenges in\nbalancing model complexity, computational efficiency, and latency. We present\nCognitiveArm, an EEG-driven, brain-controlled prosthetic system implemented on\nembedded AI hardware, achieving real-time operation without compromising\naccuracy. The system integrates BrainFlow, an open-source library for EEG data\nacquisition and streaming, with optimized deep learning (DL) models for precise\nbrain signal classification. Using evolutionary search, we identify\nPareto-optimal DL configurations through hyperparameter tuning, optimizer\nanalysis, and window selection, analyzed individually and in ensemble\nconfigurations. We apply model compression techniques such as pruning and\nquantization to optimize models for embedded deployment, balancing efficiency\nand accuracy. We collected an EEG dataset and designed an annotation pipeline\nenabling precise labeling of brain signals corresponding to specific intended\nactions, forming the basis for training our optimized DL models. CognitiveArm\nalso supports voice commands for seamless mode switching, enabling control of\nthe prosthetic arm's 3 degrees of freedom (DoF). Running entirely on embedded\nhardware, it ensures low latency and real-time responsiveness. A full-scale\nprototype, interfaced with the OpenBCI UltraCortex Mark IV EEG headset,\nachieved up to 90% accuracy in classifying three core actions (left, right,\nidle). Voice integration enables multiplexed, variable movement for everyday\ntasks (e.g., handshake, cup picking), enhancing real-world performance and\ndemonstrating CognitiveArm's potential for advanced prosthetic control.", "AI": {"tldr": "\u63d0\u51faCognitiveArm\u8111\u63a7\u5047\u80a2\u7cfb\u7edf\uff0c\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u5b9e\u73b0\u5b9e\u65f6\u8fd0\u884c\uff0c\u670990%\u5206\u7c7b\u51c6\u786e\u7387\u4e14\u652f\u6301\u8bed\u97f3\u547d\u4ee4\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u9ad8\u6548\u63a7\u5236\u5047\u80a2\uff0c\u5e73\u8861\u6a21\u578b\u590d\u6742\u5ea6\u3001\u8ba1\u7b97\u6548\u7387\u548c\u5ef6\u8fdf\u3002", "method": "\u96c6\u6210BrainFlow\u4e0e\u4f18\u5316\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u8fdb\u5316\u641c\u7d22\u8c03\u53c2\uff0c\u91c7\u7528\u6a21\u578b\u538b\u7f29\u6280\u672f\uff0c\u6536\u96c6\u6570\u636e\u96c6\u5e76\u6807\u6ce8\uff0c\u652f\u6301\u8bed\u97f3\u547d\u4ee4\u3002", "result": "\u5168\u5c3a\u5bf8\u539f\u578b\u4e0eEEG\u8033\u673a\u5bf9\u63a5\uff0c\u5bf9\u4e09\u4e2a\u6838\u5fc3\u52a8\u4f5c\u5206\u7c7b\u51c6\u786e\u7387\u8fbe90%\uff0c\u8bed\u97f3\u96c6\u6210\u63d0\u5347\u65e5\u5e38\u4efb\u52a1\u8868\u73b0\u3002", "conclusion": "CognitiveArm\u6709\u7528\u4e8e\u9ad8\u7ea7\u5047\u80a2\u63a7\u5236\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.07948", "pdf": "https://arxiv.org/pdf/2508.07948", "abs": "https://arxiv.org/abs/2508.07948", "authors": ["John D. Mayfield"], "title": "Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions", "categories": ["q-bio.OT", "cs.ET", "quant-ph", "81P68, 92C20, 42A38, 15A18, 81R05", "F.0; F.1.1; F.2.1; G.1.0; G.1.3; I.2; I.2.1; I.2.6; I.5; J.3"], "comment": "11 pages, 1 figure", "summary": "Progressive neurodegenerative diseases, including Alzheimer's disease (AD),\nmultiple sclerosis (MS), Parkinson's disease (PD), and amyotrophic lateral\nsclerosis (ALS), exhibit complex, nonlinear trajectories that challenge\ndeterministic modeling. Traditional time-domain analyses of multiomic and\nneuroimaging data often fail to capture hidden oscillatory patterns, limiting\npredictive accuracy. We propose a theoretical mathematical framework that\ntransforms time-series data into frequency or s-domain using Fourier and\nLaplace transforms, models neuronal dynamics via Hamiltonian formulations, and\nemploys quantum-classical hybrid computing with variational quantum\neigensolvers (VQE) for enhanced pattern detection. This theoretical construct\nserves as a foundation for future empirical works in quantum-enhanced analysis\nof neurodegenerative diseases. We extend this to quaternionic representations\nwith three imaginary axes ($i, j, k$) to model multistate Hamiltonians in\nmultifaceted disorders, drawing from quantum neuromorphic computing to capture\nentangled neural dynamics \\citep{Pehle2020, Emani2019}. This approach leverages\nquantum advantages in handling high-dimensional amplitude-phase data, enabling\noutlier detection and frequency signature analysis. Potential clinical\napplications include identifying high-risk patients with rapid progression or\ntherapy resistance using s-domain biomarkers, supported by quantum machine\nlearning (QML) precedents achieving up to 99.89% accuracy in Alzheimer's\nclassification \\citep{Belay2024, Bhowmik2025}. This framework aims to lay the\ngroundwork for redefining precision medicine for neurodegenerative diseases\nthrough future validations.", "AI": {"tldr": "\u63d0\u51fa\u7528\u5085\u91cc\u53f6\u548c\u62c9\u666e\u62c9\u65af\u53d8\u6362\u3001\u54c8\u5bc6\u987f\u516c\u5f0f\u3001\u91cf\u5b50 - \u7ecf\u5178\u6df7\u5408\u8ba1\u7b97\u7b49\u6784\u5efa\u6570\u5b66\u6846\u67b6\u5206\u6790\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\uff0c\u8fd8\u62d3\u5c55\u5230\u56db\u5143\u6570\u8868\u793a\uff0c\u6709\u6f5c\u5728\u4e34\u5e8a\u5e94\u7528\uff0c\u4e3a\u7cbe\u51c6\u533b\u7597\u5960\u57fa\u3002", "motivation": "\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u8f68\u8ff9\u590d\u6742\uff0c\u4f20\u7edf\u65f6\u57df\u5206\u6790\u96be\u4ee5\u6355\u6349\u9690\u85cf\u632f\u8361\u6a21\u5f0f\uff0c\u9650\u5236\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u8f6c\u6362\u5230\u9891\u7387\u6216s\u57df\uff0c\u7528\u54c8\u5bc6\u987f\u516c\u5f0f\u5efa\u6a21\u795e\u7ecf\u5143\u52a8\u529b\u5b66\uff0c\u91c7\u7528\u91cf\u5b50 - \u7ecf\u5178\u6df7\u5408\u8ba1\u7b97\u548c\u53d8\u5206\u91cf\u5b50\u672c\u5f81\u6c42\u89e3\u5668\uff0c\u62d3\u5c55\u5230\u56db\u5143\u6570\u8868\u793a\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u5229\u7528\u91cf\u5b50\u4f18\u52bf\u5904\u7406\u9ad8\u7ef4\u632f\u5e45 - \u76f8\u4f4d\u6570\u636e\uff0c\u5b9e\u73b0\u5f02\u5e38\u68c0\u6d4b\u548c\u9891\u7387\u7279\u5f81\u5206\u6790\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u7684\u91cf\u5b50\u589e\u5f3a\u5206\u6790\u5960\u5b9a\u57fa\u7840\uff0c\u6709\u671b\u91cd\u65b0\u5b9a\u4e49\u7cbe\u51c6\u533b\u7597\u3002"}}
{"id": "2508.07958", "pdf": "https://arxiv.org/pdf/2508.07958", "abs": "https://arxiv.org/abs/2508.07958", "authors": ["Dongxu Li", "Kai Yuan", "Jianhao Huang", "Chuan Huang", "Xiaoqi Qin", "Shuguang Cui", "Ping Zhang"], "title": "Adaptive Source-Channel Coding for Semantic Communications", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "Semantic communications (SemComs) have emerged as a promising paradigm for\njoint data and task-oriented transmissions, combining the demands for both the\nbit-accurate delivery and end-to-end (E2E) distortion minimization. However,\ncurrent joint source-channel coding (JSCC) in SemComs is not compatible with\nthe existing communication systems and cannot adapt to the variations of the\nsources or the channels, while separate source-channel coding (SSCC) is\nsuboptimal in the finite blocklength regime. To address these issues, we\npropose an adaptive source-channel coding (ASCC) scheme for SemComs over\nparallel Gaussian channels, where the deep neural network (DNN)-based semantic\nsource coding and conventional digital channel coding are separately deployed\nand adaptively designed. To enable efficient adaptation between the source and\nchannel coding, we first approximate the E2E data and semantic distortions as\nfunctions of source coding rate and bit error ratio (BER) via logistic\nregression, where BER is further modeled as functions of signal-to-noise ratio\n(SNR) and channel coding rate. Then, we formulate the weighted sum E2E\ndistortion minimization problem for joint source-channel coding rate and power\nallocation over parallel channels, which is solved by the successive convex\napproximation. Finally, simulation results demonstrate that the proposed ASCC\nscheme outperforms typical deep JSCC and SSCC schemes for both the single- and\nparallel-channel scenarios while maintaining full compatibility with practical\ndigital systems.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5e76\u884c\u9ad8\u65af\u4fe1\u9053\u8bed\u4e49\u901a\u4fe1\u7684\u81ea\u9002\u5e94\u4fe1\u6e90 - \u4fe1\u9053\u7f16\u7801\uff08ASCC\uff09\u65b9\u6848\uff0c\u6027\u80fd\u4f18\u4e8e\u5178\u578b\u65b9\u6848\u4e14\u4e0e\u5b9e\u9645\u6570\u5b57\u7cfb\u7edf\u517c\u5bb9\u3002", "motivation": "\u73b0\u6709\u8bed\u4e49\u901a\u4fe1\u4e2d\u8054\u5408\u4fe1\u6e90 - \u4fe1\u9053\u7f16\u7801\uff08JSCC\uff09\u4e0e\u73b0\u6709\u901a\u4fe1\u7cfb\u7edf\u4e0d\u517c\u5bb9\u3001\u65e0\u6cd5\u9002\u5e94\u4fe1\u6e90\u6216\u4fe1\u9053\u53d8\u5316\uff0c\u5206\u79bb\u4fe1\u6e90 - \u4fe1\u9053\u7f16\u7801\uff08SSCC\uff09\u5728\u6709\u9650\u7801\u957f\u4e0b\u6027\u80fd\u6b20\u4f73\u3002", "method": "\u5206\u522b\u90e8\u7f72\u5e76\u81ea\u9002\u5e94\u8bbe\u8ba1\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bed\u4e49\u4fe1\u6e90\u7f16\u7801\u548c\u4f20\u7edf\u6570\u5b57\u4fe1\u9053\u7f16\u7801\uff1b\u901a\u8fc7\u903b\u8f91\u56de\u5f52\u8fd1\u4f3c\u7aef\u5230\u7aef\u6570\u636e\u548c\u8bed\u4e49\u5931\u771f\uff1b\u5efa\u7acb\u52a0\u6743\u548c\u7aef\u5230\u7aef\u5931\u771f\u6700\u5c0f\u5316\u95ee\u9898\u5e76\u901a\u8fc7\u9010\u6b21\u51f8\u8fd1\u4f3c\u6c42\u89e3\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0cASCC \u65b9\u6848\u5728\u5355\u4fe1\u9053\u548c\u5e76\u884c\u4fe1\u9053\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u5178\u578b JSCC \u548c SSCC \u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684 ASCC \u65b9\u6848\u6027\u80fd\u4f18\u8d8a\u4e14\u4e0e\u5b9e\u9645\u6570\u5b57\u7cfb\u7edf\u5b8c\u5168\u517c\u5bb9\u3002"}}
{"id": "2508.07991", "pdf": "https://arxiv.org/pdf/2508.07991", "abs": "https://arxiv.org/abs/2508.07991", "authors": ["Pierre Perrault"], "title": "Sharper Perturbed-Kullback-Leibler Exponential Tail Bounds for Beta and Dirichlet Distributions", "categories": ["math.PR", "cs.LG"], "comment": null, "summary": "This paper presents an improved exponential tail bound for Beta\ndistributions, refining a result in [15]. This improvement is achieved by\ninterpreting their bound as a regular Kullback-Leibler (KL) divergence one,\nwhile introducing a specific perturbation $\\eta$ that shifts the mean of the\nBeta distribution closer to zero within the KL bound. Our contribution is to\nshow that a larger perturbation can be chosen, thereby tightening the bound. We\nthen extend this result from the Beta distribution to Dirichlet distributions\nand Dirichlet processes (DPs).", "AI": {"tldr": "\u8bba\u6587\u7ed9\u51fa\u6539\u8fdb\u7684Beta\u5206\u5e03\u6307\u6570\u5c3e\u754c\uff0c\u6269\u5c55\u7ed3\u679c\u81f3Dirichlet\u5206\u5e03\u548cDirichlet\u8fc7\u7a0b\u3002", "motivation": "\u6539\u8fdb\u6587\u732e[15]\u4e2d\u5173\u4e8eBeta\u5206\u5e03\u7684\u5c3e\u754c\u7ed3\u679c\u3002", "method": "\u5c06\u539f\u5c3e\u754c\u89e3\u91ca\u4e3a\u5e38\u89c4Kullback - Leibler (KL)\u6563\u5ea6\u5c3e\u754c\uff0c\u5f15\u5165\u7279\u5b9a\u6270\u52a8\u03b7\u4f7fBeta\u5206\u5e03\u5747\u503c\u5728KL\u754c\u5185\u66f4\u63a5\u8fd1\u96f6\uff0c\u5e76\u9009\u62e9\u66f4\u5927\u6270\u52a8\u6765\u6536\u7d27\u5c3e\u754c\u3002", "result": "\u5f97\u5230\u6539\u8fdb\u7684Beta\u5206\u5e03\u6307\u6570\u5c3e\u754c\uff0c\u5e76\u5c06\u7ed3\u679c\u6269\u5c55\u5230Dirichlet\u5206\u5e03\u548cDirichlet\u8fc7\u7a0b\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdb\u7684\u65b9\u6cd5\u53ef\u4ee5\u5f97\u5230\u66f4\u4f18\u7684\u5c3e\u754c\uff0c\u4e14\u80fd\u5c06\u7ed3\u679c\u4eceBeta\u5206\u5e03\u6269\u5c55\u5230\u5176\u4ed6\u5206\u5e03\u3002"}}
{"id": "2508.07766", "pdf": "https://arxiv.org/pdf/2508.07766", "abs": "https://arxiv.org/abs/2508.07766", "authors": ["Jinke Li", "Jiarui Yu", "Chenxing Wei", "Hande Dong", "Qiang Lin", "Liangjing Yang", "Zhicai Wang", "Yanbin Hao"], "title": "UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at ACM MM 2025 Dataset Track", "summary": "Unlike bitmap images, scalable vector graphics (SVG) maintain quality when\nscaled, frequently employed in computer vision and artistic design in the\nrepresentation of SVG code. In this era of proliferating AI-powered systems,\nenabling AI to understand and generate SVG has become increasingly urgent.\nHowever, AI-driven SVG understanding and generation (U&G) remain significant\nchallenges. SVG code, equivalent to a set of curves and lines controlled by\nfloating-point parameters, demands high precision in SVG U&G. Besides, SVG\ngeneration operates under diverse conditional constraints, including textual\nprompts and visual references, which requires powerful multi-modal processing\nfor condition-to-SVG transformation. Recently, the rapid growth of Multi-modal\nLarge Language Models (MLLMs) have demonstrated capabilities to process\nmulti-modal inputs and generate complex vector controlling parameters,\nsuggesting the potential to address SVG U&G tasks within a unified model. To\nunlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset\ncalled UniSVG, comprising 525k data items, tailored for MLLM training and\nevaluation. To our best knowledge, it is the first comprehensive dataset\ndesigned for unified SVG generation (from textual prompts and images) and SVG\nunderstanding (color, category, usage, etc.). As expected, learning on the\nproposed dataset boosts open-source MLLMs' performance on various SVG U&G\ntasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset,\nbenchmark, weights, codes and experiment details on\nhttps://ryanlijinke.github.io/.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u548c\u8bc4\u4f30\u7684 SVG \u6570\u636e\u96c6 UniSVG\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728 SVG \u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5728 AI \u7cfb\u7edf\u53d1\u5c55\u65f6\u4ee3\uff0c\u4f7f AI \u7406\u89e3\u548c\u751f\u6210 SVG \u5f88\u8feb\u5207\uff0c\u4f46 SVG \u7406\u89e3\u548c\u751f\u6210\u5b58\u5728\u6311\u6218\uff0c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6709\u89e3\u51b3\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u5305\u542b 525k \u6570\u636e\u9879\u7684 SVG \u4e2d\u5fc3\u6570\u636e\u96c6 UniSVG \u7528\u4e8e MLLM \u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u5728 UniSVG \u4e0a\u5b66\u4e60\u63d0\u5347\u4e86\u5f00\u6e90 MLLM \u5728 SVG \u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u8d85\u8d8a\u4e86\u5982 GPT - 4V \u7b49\u95ed\u6e90 SOTA \u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684 UniSVG \u6570\u636e\u96c6\u6709\u52a9\u4e8e\u91ca\u653e MLLM \u5728 SVG \u9886\u57df\u7684\u80fd\u529b\uff0c\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u53d1\u5c55\uff0c\u76f8\u5173\u8d44\u6e90\u5df2\u516c\u5f00\u3002"}}
{"id": "2508.07994", "pdf": "https://arxiv.org/pdf/2508.07994", "abs": "https://arxiv.org/abs/2508.07994", "authors": ["Birgit Hillebrecht", "Benjamin Unger"], "title": "Prediction error certification for PINNs: Theory, computation, and application to Stokes flow", "categories": ["math.NA", "cs.LG", "cs.NA", "65N15, 47D06, 35A35, 35F16, 41A65"], "comment": null, "summary": "Rigorous error estimation is a fundamental topic in numerical analysis. With\nthe increasing use of physics-informed neural networks (PINNs) for solving\npartial differential equations, several approaches have been developed to\nquantify the associated prediction error. In this work, we build upon a\nsemigroup-based framework previously introduced by the authors for estimating\nthe PINN error. While this estimator has so far been limited to academic\nexamples - due to the need to compute quantities related to input-to-state\nstability - we extend its applicability to a significantly broader class of\nproblems. This is accomplished by modifying the error bound and proposing\nnumerical strategies to approximate the required stability parameters. The\nextended framework enables the certification of PINN predictions in more\nrealistic scenarios, as demonstrated by a numerical study of Stokes flow around\na cylinder.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u57fa\u4e8e\u534a\u7fa4\u7684PINN\u8bef\u5dee\u4f30\u8ba1\u6846\u67b6\u9002\u7528\u6027\uff0c\u901a\u8fc7\u4fee\u6539\u8bef\u5dee\u754c\u548c\u63d0\u51fa\u6570\u503c\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u66f4\u73b0\u5b9e\u573a\u666f\u7684\u9884\u6d4b\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709PINN\u8bef\u5dee\u4f30\u8ba1\u5668\u53d7\u9650\u4e8e\u5b66\u672f\u793a\u4f8b\uff0c\u9700\u6269\u5c55\u5176\u9002\u7528\u6027\u5230\u66f4\u5e7f\u6cdb\u95ee\u9898\u3002", "method": "\u4fee\u6539\u8bef\u5dee\u754c\u5e76\u63d0\u51fa\u6570\u503c\u7b56\u7565\u8fd1\u4f3c\u6240\u9700\u7a33\u5b9a\u6027\u53c2\u6570\u3002", "result": "\u6269\u5c55\u6846\u67b6\u80fd\u5728\u66f4\u73b0\u5b9e\u573a\u666f\u4e2d\u5bf9PINN\u9884\u6d4b\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5982\u5706\u67f1\u7ed5\u6d41\u7684\u65af\u6258\u514b\u65af\u6d41\u6570\u503c\u7814\u7a76\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u6269\u5c55\u4e86PINN\u8bef\u5dee\u4f30\u8ba1\u6846\u67b6\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2508.08019", "pdf": "https://arxiv.org/pdf/2508.08019", "abs": "https://arxiv.org/abs/2508.08019", "authors": ["Hengyu Liu", "Yushuai Li", "Minghe Yu", "Tiancheng Zhang", "Ge Yu", "Torben Bach Pedersen", "Kristian Torp", "Christian S. Jensen", "Tianyi Li"], "title": "Advancing Knowledge Tracing by Exploring Follow-up Performance Trends", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "14 pages, 5 figures", "summary": "Intelligent Tutoring Systems (ITS), such as Massive Open Online Courses,\noffer new opportunities for human learning. At the core of such systems,\nknowledge tracing (KT) predicts students' future performance by analyzing their\nhistorical learning activities, enabling an accurate evaluation of students'\nknowledge states over time. We show that existing KT methods often encounter\ncorrelation conflicts when analyzing the relationships between historical\nlearning sequences and future performance. To address such conflicts, we\npropose to extract so-called Follow-up Performance Trends (FPTs) from\nhistorical ITS data and to incorporate them into KT. We propose a method called\nForward-Looking Knowledge Tracing (FINER) that combines historical learning\nsequences with FPTs to enhance student performance prediction accuracy. FINER\nconstructs learning patterns that facilitate the retrieval of FPTs from\nhistorical ITS data in linear time; FINER includes a novel similarity-aware\nattention mechanism that aggregates FPTs based on both frequency and contextual\nsimilarity; and FINER offers means of combining FPTs and historical learning\nsequences to enable more accurate prediction of student future performance.\nExperiments on six real-world datasets show that FINER can outperform ten\nstate-of-the-art KT methods, increasing accuracy by 8.74% to 84.85%.", "AI": {"tldr": "\u73b0\u6709\u77e5\u8bc6\u8ffd\u8e2a\u65b9\u6cd5\u5206\u6790\u5386\u53f2\u5b66\u4e60\u5e8f\u5217\u4e0e\u672a\u6765\u8868\u73b0\u5173\u7cfb\u65f6\u5b58\u5728\u51b2\u7a81\uff0c\u63d0\u51faFINER\u65b9\u6cd5\u7ed3\u5408\u5386\u53f2\u5b66\u4e60\u5e8f\u5217\u4e0e\u540e\u7eed\u8868\u73b0\u8d8b\u52bf\u63d0\u9ad8\u5b66\u751f\u8868\u73b0\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u65b9\u6cd5\u5728\u5206\u6790\u5386\u53f2\u5b66\u4e60\u5e8f\u5217\u4e0e\u672a\u6765\u8868\u73b0\u5173\u7cfb\u65f6\u5b58\u5728\u76f8\u5173\u6027\u51b2\u7a81\uff0c\u9700\u8981\u89e3\u51b3\u8be5\u95ee\u9898\u4ee5\u63d0\u9ad8\u5b66\u751f\u8868\u73b0\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faForward - Looking Knowledge Tracing\uff08FINER\uff09\u65b9\u6cd5\uff0c\u4ece\u5386\u53f2\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\uff08ITS\uff09\u6570\u636e\u4e2d\u63d0\u53d6\u540e\u7eed\u8868\u73b0\u8d8b\u52bf\uff08FPTs\uff09\uff0c\u5c06\u5176\u4e0e\u5386\u53f2\u5b66\u4e60\u5e8f\u5217\u7ed3\u5408\uff0c\u6784\u5efa\u5b66\u4e60\u6a21\u5f0f\uff0c\u5f15\u5165\u65b0\u9896\u7684\u76f8\u4f3c\u6027\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\u805a\u5408FPTs\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFINER\u80fd\u8d85\u8d8a\u5341\u79cd\u6700\u5148\u8fdb\u7684KT\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u9ad88.74%\u81f384.85%\u3002", "conclusion": "FINER\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709KT\u65b9\u6cd5\u7684\u76f8\u5173\u6027\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u9ad8\u5b66\u751f\u672a\u6765\u8868\u73b0\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.08029", "pdf": "https://arxiv.org/pdf/2508.08029", "abs": "https://arxiv.org/abs/2508.08029", "authors": ["Thusitha Dayaratne", "Ngoc Duy Pham", "Viet Vo", "Shangqi Lai", "Sharif Abuadbba", "Hajime Suzuki", "Xingliang Yuan", "Carsten Rudolph"], "title": "Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks", "categories": ["cs.CR", "cs.ET", "cs.LG"], "comment": null, "summary": "The introduction of 5G and the Open Radio Access Network (O-RAN) architecture\nhas enabled more flexible and intelligent network deployments. However, the\nincreased complexity and openness of these architectures also introduce novel\nsecurity challenges, such as data manipulation attacks on the semi-standardised\nShared Data Layer (SDL) within the O-RAN platform through malicious xApps. In\nparticular, malicious xApps can exploit this vulnerability by introducing\nsubtle Unicode-wise alterations (hypoglyphs) into the data that are being used\nby traditional machine learning (ML)-based anomaly detection methods. These\nUnicode-wise manipulations can potentially bypass detection and cause failures\nin anomaly detection systems based on traditional ML, such as AutoEncoders,\nwhich are unable to process hypoglyphed data without crashing. We investigate\nthe use of Large Language Models (LLMs) for anomaly detection within the O-RAN\narchitecture to address this challenge. We demonstrate that LLM-based xApps\nmaintain robust operational performance and are capable of processing\nmanipulated messages without crashing. While initial detection accuracy\nrequires further improvements, our results highlight the robustness of LLMs to\nadversarial attacks such as hypoglyphs in input data. There is potential to use\ntheir adaptability through prompt engineering to further improve the accuracy,\nalthough this requires further research. Additionally, we show that LLMs\nachieve low detection latency (under 0.07 seconds), making them suitable for\nNear-Real-Time (Near-RT) RIC deployments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89e3\u51b3O - RAN\u67b6\u6784\u4e2dSDL\u5c42\u6570\u636e\u64cd\u7eb5\u653b\u51fb\uff0c\u5c55\u793a\u5176\u9c81\u68d2\u6027\u548c\u4f4e\u68c0\u6d4b\u5ef6\u8fdf\uff0c\u4f46\u521d\u59cb\u68c0\u6d4b\u7cbe\u5ea6\u5f85\u63d0\u9ad8\u3002", "motivation": "5G\u548cO - RAN\u67b6\u6784\u589e\u52a0\u4e86\u5b89\u5168\u6311\u6218\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u6570\u636e\u64cd\u7eb5\u653b\u51fb\uff0c\u9700\u65b0\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884cO - RAN\u67b6\u6784\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u57fa\u4e8eLLM\u7684xApps\u8fd0\u884c\u6027\u80fd\u7a33\u5065\uff0c\u80fd\u5904\u7406\u64cd\u7eb5\u6d88\u606f\u4e0d\u5d29\u6e83\uff0c\u68c0\u6d4b\u5ef6\u8fdf\u4f4e\uff08\u4f4e\u4e8e0.07\u79d2\uff09\uff0c\u4f46\u521d\u59cb\u68c0\u6d4b\u7cbe\u5ea6\u6709\u5f85\u63d0\u9ad8\u3002", "conclusion": "LLMs\u5bf9\u8f93\u5165\u6570\u636e\u4e2d\u7684\u5bf9\u6297\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\uff0c\u6709\u6f5c\u529b\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u63d0\u9ad8\u7cbe\u5ea6\uff0c\u9002\u5408\u8fd1\u5b9e\u65f6RIC\u90e8\u7f72\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.08030", "pdf": "https://arxiv.org/pdf/2508.08030", "abs": "https://arxiv.org/abs/2508.08030", "authors": ["Hao Peng", "Yuanyuan Zhang", "Steve Jiang", "Robert Timmerman", "John Minna"], "title": "Exploring Strategies for Personalized Radiation Therapy: Part III Identifying genetic determinants for Radiation Response with Meta Learning", "categories": ["physics.med-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Radiation response in cancer is shaped by complex, patient specific biology,\nyet current treatment strategies often rely on uniform dose prescriptions\nwithout accounting for tumor heterogeneity. In this study, we introduce a meta\nlearning framework for one-shot prediction of radiosensitivity measured by SF2\nusing cell line level gene expression data. Unlike the widely used\nRadiosensitivity Index RSI a rank-based linear model trained on a fixed 10-gene\nsignature, our proposed meta-learned model allows the importance of each gene\nto vary by sample through fine tuning. This flexibility addresses key\nlimitations of static models like RSI, which assume uniform gene contributions\nacross tumor types and discard expression magnitude and gene gene interactions.\nOur results show that meta learning offers robust generalization to unseen\nsamples and performs well in tumor subgroups with high radiosensitivity\nvariability, such as adenocarcinoma and large cell carcinoma. By learning\ntransferable structure across tasks while preserving sample specific\nadaptability, our approach enables rapid adaptation to individual samples,\nimproving predictive accuracy across diverse tumor subtypes while uncovering\ncontext dependent patterns of gene influence that may inform personalized\ntherapy.", "AI": {"tldr": "\u63d0\u51fa\u5143\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u4e00\u6b21\u6027\u9884\u6d4b\u653e\u5c04\u654f\u611f\u6027\uff0c\u76f8\u6bd4RSI\u6a21\u578b\u6709\u4f18\u52bf\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6cdb\u5316\u6027\u597d\u3001\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u764c\u75c7\u653e\u7597\u7b56\u7565\u672a\u8003\u8651\u80bf\u7624\u5f02\u8d28\u6027\uff0c\u4f9d\u8d56\u7edf\u4e00\u5242\u91cf\u5904\u65b9\uff0c\u9700\u66f4\u597d\u7684\u653e\u5c04\u654f\u611f\u6027\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u7ec6\u80de\u7cfb\u6c34\u5e73\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u8fdb\u884c\u4e00\u6b21\u6027\u653e\u5c04\u654f\u611f\u6027\uff08SF2\uff09\u9884\u6d4b\uff0c\u5141\u8bb8\u6bcf\u4e2a\u57fa\u56e0\u91cd\u8981\u6027\u56e0\u6837\u672c\u800c\u5f02\u3002", "result": "\u5143\u5b66\u4e60\u5bf9\u672a\u89c1\u6837\u672c\u6709\u5f3a\u6cdb\u5316\u6027\uff0c\u5728\u9ad8\u653e\u5c04\u654f\u611f\u6027\u53d8\u5f02\u6027\u7684\u80bf\u7624\u4e9a\u7ec4\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5feb\u901f\u9002\u5e94\u4e2a\u4f53\u6837\u672c\uff0c\u63d0\u9ad8\u4e0d\u540c\u80bf\u7624\u4e9a\u578b\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u63ed\u793a\u57fa\u56e0\u5f71\u54cd\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6a21\u5f0f\uff0c\u4e3a\u4e2a\u6027\u5316\u6cbb\u7597\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2508.07829", "pdf": "https://arxiv.org/pdf/2508.07829", "abs": "https://arxiv.org/abs/2508.07829", "authors": ["Hyeonuk Nam"], "title": "Auditory Intelligence: Understanding the World Through Sound", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "Position paper without experimental/quantitative validation. Not\n  submitted to any journal/conference", "summary": "Recent progress in auditory intelligence has yielded high-performing systems\nfor sound event detection (SED), acoustic scene classification (ASC), automated\naudio captioning (AAC), and audio question answering (AQA). Yet these tasks\nremain largely constrained to surface-level recognition-capturing what happened\nbut not why, what it implies, or how it unfolds in context. I propose a\nconceptual reframing of auditory intelligence as a layered, situated process\nthat encompasses perception, reasoning, and interaction. To instantiate this\nview, I introduce four cognitively inspired task paradigms-ASPIRE, SODA, AUX,\nand AUGMENT-those structure auditory understanding across time-frequency\npattern captioning, hierarchical event/scene description, causal explanation,\nand goal-driven interpretation, respectively. Together, these paradigms provide\na roadmap toward more generalizable, explainable, and human-aligned auditory\nintelligence, and are intended to catalyze a broader discussion of what it\nmeans for machines to understand sound.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u542c\u89c9\u667a\u80fd\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u5206\u5c42\u3001\u60c5\u5883\u5316\u8fc7\u7a0b\uff0c\u5f15\u5165\u56db\u4e2a\u8ba4\u77e5\u542f\u53d1\u4efb\u52a1\u8303\u5f0f\uff0c\u4e3a\u66f4\u901a\u7528\u3001\u53ef\u89e3\u91ca\u548c\u4e0e\u4eba\u4e00\u81f4\u7684\u542c\u89c9\u667a\u80fd\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002", "motivation": "\u5f53\u524d\u542c\u89c9\u667a\u80fd\u4efb\u52a1\u5c40\u9650\u4e8e\u8868\u9762\u8bc6\u522b\uff0c\u65e0\u6cd5\u89e3\u91ca\u4e8b\u4ef6\u539f\u56e0\u3001\u542b\u4e49\u53ca\u60c5\u5883\u53d1\u5c55\uff0c\u9700\u91cd\u65b0\u6784\u5efa\u542c\u89c9\u667a\u80fd\u6982\u5ff5\u3002", "method": "\u5c06\u542c\u89c9\u667a\u80fd\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u5305\u542b\u611f\u77e5\u3001\u63a8\u7406\u548c\u4ea4\u4e92\u7684\u5206\u5c42\u3001\u60c5\u5883\u5316\u8fc7\u7a0b\uff0c\u5e76\u5f15\u5165\u56db\u4e2a\u8ba4\u77e5\u542f\u53d1\u4efb\u52a1\u8303\u5f0f\u3002", "result": "\u56db\u4e2a\u4efb\u52a1\u8303\u5f0f\u53ef\u4ece\u4e0d\u540c\u65b9\u9762\u6784\u5efa\u542c\u89c9\u7406\u89e3\u3002", "conclusion": "\u8fd9\u4e9b\u8303\u5f0f\u4e3a\u66f4\u901a\u7528\u3001\u53ef\u89e3\u91ca\u548c\u4e0e\u4eba\u4e00\u81f4\u7684\u542c\u89c9\u667a\u80fd\u63d0\u4f9b\u8def\u7ebf\u56fe\uff0c\u80fd\u5f15\u53d1\u5bf9\u673a\u5668\u7406\u89e3\u58f0\u97f3\u542b\u4e49\u7684\u66f4\u5e7f\u6cdb\u8ba8\u8bba\u3002"}}
{"id": "2508.08058", "pdf": "https://arxiv.org/pdf/2508.08058", "abs": "https://arxiv.org/abs/2508.08058", "authors": ["Ziad Al-Haj Hemidi", "Eytan Kats", "Mattias P. Heinrich"], "title": "PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI", "categories": ["cs.CV", "cs.LG"], "comment": "Submitted to the British Machine Vision Conference (BMVC) 2025\n  (Before peer review version)", "summary": "Accelerating Magnetic Resonance Imaging (MRI) reduces scan time but often\ndegrades image quality. While Implicit Neural Representations (INRs) show\npromise for MRI reconstruction, they struggle at high acceleration factors due\nto weak prior constraints, leading to structural loss and aliasing artefacts.\nTo address this, we propose PrIINeR, an INR-based MRI reconstruction method\nthat integrates prior knowledge from pre-trained deep learning models into the\nINR framework. By combining population-level knowledge with instance-based\noptimization and enforcing dual data consistency, PrIINeR aligns both with the\nacquired k-space data and the prior-informed reconstruction. Evaluated on the\nNYU fastMRI dataset, our method not only outperforms state-of-the-art INR-based\napproaches but also improves upon several learning-based state-of-the-art\nmethods, significantly improving structural preservation and fidelity while\neffectively removing aliasing artefacts.PrIINeR bridges deep learning and\nINR-based techniques, offering a more reliable solution for high-quality,\naccelerated MRI reconstruction. The code is publicly available on\nhttps://github.com/multimodallearning/PrIINeR.", "AI": {"tldr": "\u63d0\u51faPrIINeR\u65b9\u6cd5\u89e3\u51b3INR\u5728\u9ad8\u52a0\u901f\u56e0\u5b50\u4e0bMRI\u91cd\u5efa\u95ee\u9898\uff0c\u5728NYU fastMRI\u6570\u636e\u96c6\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u52a0\u901fMRI\u4f1a\u964d\u4f4e\u56fe\u50cf\u8d28\u91cf\uff0cINR\u5728\u9ad8\u52a0\u901f\u56e0\u5b50\u4e0b\u56e0\u5148\u9a8c\u7ea6\u675f\u5f31\u6709\u7ed3\u6784\u635f\u5931\u548c\u4f2a\u5f71\u95ee\u9898\u3002", "method": "\u63d0\u51faPrIINeR\u65b9\u6cd5\uff0c\u5c06\u9884\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5148\u9a8c\u77e5\u8bc6\u96c6\u6210\u5230INR\u6846\u67b6\uff0c\u7ed3\u5408\u7fa4\u4f53\u77e5\u8bc6\u4e0e\u5b9e\u4f8b\u4f18\u5316\uff0c\u6267\u884c\u53cc\u91cd\u6570\u636e\u4e00\u81f4\u6027\u3002", "result": "\u5728NYU fastMRI\u6570\u636e\u96c6\u4e0a\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8eINR\u548c\u4e00\u4e9b\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u6539\u5584\u7ed3\u6784\u4fdd\u7559\u548c\u4fdd\u771f\u5ea6\uff0c\u53bb\u9664\u4f2a\u5f71\u3002", "conclusion": "PrIINeR\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548cINR\u6280\u672f\uff0c\u4e3a\u9ad8\u8d28\u91cf\u52a0\u901fMRI\u91cd\u5efa\u63d0\u4f9b\u66f4\u53ef\u9760\u65b9\u6848\u3002"}}
{"id": "2508.07842", "pdf": "https://arxiv.org/pdf/2508.07842", "abs": "https://arxiv.org/abs/2508.07842", "authors": ["Yutong Shen", "Hangxu Liu", "Penghui Liu", "Ruizhe Xia", "Tianyi Yao", "Yitong Sun", "Tongtong Feng"], "title": "DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts", "categories": ["cs.RO", "cs.AI"], "comment": "14 pages,8 figures. Submitted to AAAI'26", "summary": "Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex\nmulti-step tasks that require continuous planning, sequential decision-making,\nand extended execution across domains to achieve the final goal. However,\nexisting methods heavily rely on skill chaining by concatenating pre-trained\nsubtasks, with environment observations and self-state tightly coupled, lacking\nthe ability to generalize to new combinations of environments and skills,\nfailing to complete various LH tasks across domains. To solve this problem,\nthis paper presents DETACH, a cross-domain learning framework for LH tasks via\nbiologically inspired dual-stream disentanglement. Inspired by the brain's\n\"where-what\" dual pathway mechanism, DETACH comprises two core modules: i) an\nenvironment learning module for spatial understanding, which captures object\nfunctions, spatial relationships, and scene semantics, achieving cross-domain\ntransfer through complete environment-self disentanglement; ii) a skill\nlearning module for task execution, which processes self-state information\nincluding joint degrees of freedom and motor patterns, enabling cross-skill\ntransfer through independent motor pattern encoding. We conducted extensive\nexperiments on various LH tasks in HSI scenes. Compared with existing methods,\nDETACH can achieve an average subtasks success rate improvement of 23% and\naverage execution efficiency improvement of 29%.", "AI": {"tldr": "\u63d0\u51faDETACH\u8de8\u57df\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u957f\u65f6\u7a0b\u4eba\u7c7b\u573a\u666f\u4ea4\u4e92\u4efb\u52a1\u6cdb\u5316\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6280\u80fd\u94fe\uff0c\u73af\u5883\u89c2\u6d4b\u4e0e\u81ea\u8eab\u72b6\u6001\u8026\u5408\uff0c\u7f3a\u4e4f\u8de8\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u6cd5\u5b8c\u6210\u5404\u7c7b\u8de8\u57df\u957f\u65f6\u7a0b\u4efb\u52a1\u3002", "method": "\u63d0\u51faDETACH\u6846\u67b6\uff0c\u53d7\u5927\u8111\u201cwhere - what\u201d\u53cc\u901a\u8def\u673a\u5236\u542f\u53d1\uff0c\u5305\u542b\u73af\u5883\u5b66\u4e60\u6a21\u5757\u548c\u6280\u80fd\u5b66\u4e60\u6a21\u5757\uff0c\u5206\u522b\u5b9e\u73b0\u73af\u5883 - \u81ea\u8eab\u89e3\u8026\u548c\u72ec\u7acb\u8fd0\u52a8\u6a21\u5f0f\u7f16\u7801\u3002", "result": "\u5728\u5404\u79cd\u4eba\u7c7b\u573a\u666f\u4ea4\u4e92\u957f\u65f6\u7a0b\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cDETACH\u5e73\u5747\u5b50\u4efb\u52a1\u6210\u529f\u7387\u63d0\u9ad823%\uff0c\u5e73\u5747\u6267\u884c\u6548\u7387\u63d0\u9ad829%\u3002", "conclusion": "DETACH\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u957f\u65f6\u7a0b\u4eba\u7c7b\u573a\u666f\u4ea4\u4e92\u4efb\u52a1\u7684\u8de8\u57df\u6cdb\u5316\u95ee\u9898\uff0c\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u6548\u679c\u3002"}}
{"id": "2508.08066", "pdf": "https://arxiv.org/pdf/2508.08066", "abs": "https://arxiv.org/abs/2508.08066", "authors": ["Weitai Kang", "Weiming Zhuang", "Zhizhong Li", "Yan Yan", "Lingjuan Lyu"], "title": "Investigating the Design Space of Visual Grounding in Multimodal Large Language Model", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "8 pages for the main paper", "summary": "Fine-grained multimodal capability in Multimodal Large Language Models\n(MLLMs) has emerged as a critical research direction, particularly for tackling\nthe visual grounding (VG) problem. Despite the strong performance achieved by\nexisting approaches, they often employ disparate design choices when\nfine-tuning MLLMs for VG, lacking systematic verification to support these\ndesigns. To bridge this gap, this paper presents a comprehensive study of\nvarious design choices that impact the VG performance of MLLMs. We conduct our\nanalysis using LLaVA-1.5, which has been widely adopted in prior empirical\nstudies of MLLMs. While more recent models exist, we follow this convention to\nensure our findings remain broadly applicable and extendable to other\narchitectures. We cover two key aspects: (1) exploring different visual\ngrounding paradigms in MLLMs, identifying the most effective design, and\nproviding our insights; and (2) conducting ablation studies on the design of\ngrounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our\nfindings contribute to a stronger MLLM for VG, achieving improvements of +5.6%\n/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5f71\u54cd\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u89c6\u89c9\u5b9a\u4f4d\uff08VG\uff09\u6027\u80fd\u7684\u8bbe\u8ba1\u9009\u62e9\u8fdb\u884c\u5168\u9762\u7814\u7a76\uff0c\u57fa\u4e8eLLaVA - 1.5\u5206\u6790\u4e0d\u540cVG\u8303\u5f0f\u548c\u5b9a\u4f4d\u6570\u636e\u8bbe\u8ba1\uff0c\u4f7f\u6a21\u578b\u5728VG\u4efb\u52a1\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709MLLMs\u5728VG\u4efb\u52a1\u5fae\u8c03\u65f6\u8bbe\u8ba1\u9009\u62e9\u7f3a\u4e4f\u7cfb\u7edf\u9a8c\u8bc1\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f7f\u7528LLaVA - 1.5\u8fdb\u884c\u5206\u6790\uff0c\u63a2\u7d22\u4e0d\u540cVG\u8303\u5f0f\uff0c\u5bf9\u5b9a\u4f4d\u6570\u636e\u8bbe\u8ba1\u8fdb\u884c\u6d88\u878d\u7814\u7a76\u3002", "result": "\u6a21\u578b\u5728RefCOCO/+/g\u4e0a\u6bd4LLaVA - 1.5\u5206\u522b\u63d0\u5347\u4e86+5.6% / +6.9% / +7.0%\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u5f3a\u7684\u7528\u4e8eVG\u4efb\u52a1\u7684MLLM\u3002"}}
{"id": "2508.07847", "pdf": "https://arxiv.org/pdf/2508.07847", "abs": "https://arxiv.org/abs/2508.07847", "authors": ["Shunya Nagashima", "Komei Sugiura"], "title": "Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images", "categories": ["cs.CV", "cs.AI"], "comment": "ICCV 2025", "summary": "Accurate, reliable solar flare prediction is crucial for mitigating potential\ndisruptions to critical infrastructure, while predicting solar flares remains a\nsignificant challenge. Existing methods based on heuristic physical features\noften lack representation learning from solar images. On the other hand,\nend-to-end learning approaches struggle to model long-range temporal\ndependencies in solar images. In this study, we propose Deep Space Weather\nModel (Deep SWM), which is based on multiple deep state space models for\nhandling both ten-channel solar images and long-range spatio-temporal\ndependencies. Deep SWM also features a sparse masked autoencoder, a novel\npretraining strategy that employs a two-phase masking approach to preserve\ncrucial regions such as sunspots while compressing spatial information.\nFurthermore, we built FlareBench, a new public benchmark for solar flare\nprediction covering a full 11-year solar activity cycle, to validate our\nmethod. Our method outperformed baseline methods and even human expert\nperformance on standard metrics in terms of performance and reliability. The\nproject page can be found at https://keio-smilab25.github.io/DeepSWM.", "AI": {"tldr": "\u63d0\u51faDeep SWM\u6a21\u578b\u7528\u4e8e\u592a\u9633\u8000\u6591\u9884\u6d4b\uff0c\u6784\u5efaFlareBench\u57fa\u51c6\u9a8c\u8bc1\uff0c\u6027\u80fd\u8d85\u57fa\u7ebf\u548c\u4eba\u7c7b\u4e13\u5bb6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u542f\u53d1\u5f0f\u7269\u7406\u7279\u5f81\u7684\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u592a\u9633\u56fe\u50cf\u7684\u8868\u793a\u5b66\u4e60\uff0c\u7aef\u5230\u7aef\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5efa\u6a21\u592a\u9633\u56fe\u50cf\u7684\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\uff0c\u800c\u51c6\u786e\u53ef\u9760\u7684\u592a\u9633\u8000\u6591\u9884\u6d4b\u5bf9\u51cf\u8f7b\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u6f5c\u5728\u7834\u574f\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u4e2a\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684Deep SWM\uff0c\u5904\u7406\u5341\u901a\u9053\u592a\u9633\u56fe\u50cf\u548c\u957f\u7a0b\u65f6\u7a7a\u4f9d\u8d56\uff0c\u91c7\u7528\u7a00\u758f\u63a9\u7801\u81ea\u7f16\u7801\u5668\u548c\u4e24\u9636\u6bb5\u63a9\u7801\u9884\u8bad\u7ec3\u7b56\u7565\uff1b\u6784\u5efa\u65b0\u7684\u516c\u5171\u57fa\u51c6FlareBench\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u6307\u6807\u4e0a\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u8d85\u8fc7\u57fa\u7ebf\u65b9\u6cd5\uff0c\u751a\u81f3\u8d85\u8fc7\u4eba\u7c7b\u4e13\u5bb6\u3002", "conclusion": "Deep SWM\u6a21\u578b\u548cFlareBench\u57fa\u51c6\u5728\u592a\u9633\u8000\u6591\u9884\u6d4b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.08093", "pdf": "https://arxiv.org/pdf/2508.08093", "abs": "https://arxiv.org/abs/2508.08093", "authors": ["Md Rezwanul Haque", "Md. Milon Islam", "S M Taslim Uddin Raju", "Hamdi Altaheri", "Lobna Nassar", "Fakhri Karray"], "title": "MDD-Net: Multimodal Depression Detection through Mutual Transformer", "categories": ["cs.CV", "cs.LG", "cs.MM", "eess.AS"], "comment": "Accepted for the 2025 IEEE International Conference on Systems, Man,\n  and Cybernetics (SMC), Vienna, Austria", "summary": "Depression is a major mental health condition that severely impacts the\nemotional and physical well-being of individuals. The simple nature of data\ncollection from social media platforms has attracted significant interest in\nproperly utilizing this information for mental health research. A Multimodal\nDepression Detection Network (MDD-Net), utilizing acoustic and visual data\nobtained from social media networks, is proposed in this work where mutual\ntransformers are exploited to efficiently extract and fuse multimodal features\nfor efficient depression detection. The MDD-Net consists of four core modules:\nan acoustic feature extraction module for retrieving relevant acoustic\nattributes, a visual feature extraction module for extracting significant\nhigh-level patterns, a mutual transformer for computing the correlations among\nthe generated features and fusing these features from multiple modalities, and\na detection layer for detecting depression using the fused feature\nrepresentations. The extensive experiments are performed using the multimodal\nD-Vlog dataset, and the findings reveal that the developed multimodal\ndepression detection network surpasses the state-of-the-art by up to 17.37% for\nF1-Score, demonstrating the greater performance of the proposed system. The\nsource code is accessible at\nhttps://github.com/rezwanh001/Multimodal-Depression-Detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMDD - Net\u5229\u7528\u793e\u4ea4\u5a92\u4f53\u7684\u58f0\u89c6\u89c9\u6570\u636e\u8fdb\u884c\u6291\u90c1\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u8d85\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6291\u90c1\u75c7\u4e25\u91cd\u5f71\u54cd\u4e2a\u4f53\u8eab\u5fc3\u5065\u5eb7\uff0c\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u6613\u6536\u96c6\uff0c\u53ef\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u7814\u7a76\u3002", "method": "\u63d0\u51faMDD - Net\uff0c\u5305\u542b\u58f0\u5b66\u3001\u89c6\u89c9\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u3001\u4e92\u53d8\u538b\u5668\u548c\u68c0\u6d4b\u5c42\uff0c\u5229\u7528\u4e92\u53d8\u538b\u5668\u63d0\u53d6\u548c\u878d\u5408\u591a\u6a21\u6001\u7279\u5f81\u3002", "result": "\u5728\u591a\u6a21\u6001D - Vlog\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cF1\u5f97\u5206\u6bd4\u73b0\u6709\u6280\u672f\u9ad8\u6700\u591a17.37%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u6a21\u6001\u6291\u90c1\u68c0\u6d4b\u7f51\u7edc\u6027\u80fd\u66f4\u4f18\uff0c\u6e90\u4ee3\u7801\u53ef\u5728\u6307\u5b9a\u94fe\u63a5\u83b7\u53d6\u3002"}}
{"id": "2508.07852", "pdf": "https://arxiv.org/pdf/2508.07852", "abs": "https://arxiv.org/abs/2508.07852", "authors": ["Rui Su", "Honghao Dong", "Haojie Jin", "Yisong Chen", "Guoping Wang", "Sheng Li"], "title": "Vertex Features for Neural Global Illumination", "categories": ["cs.GR", "cs.AI"], "comment": "Accepted by ACM SIGGRAPH Asia'2025", "summary": "Recent research on learnable neural representations has been widely adopted\nin the field of 3D scene reconstruction and neural rendering applications.\nHowever, traditional feature grid representations often suffer from substantial\nmemory footprint, posing a significant bottleneck for modern parallel computing\nhardware. In this paper, we present neural vertex features, a generalized\nformulation of learnable representation for neural rendering tasks involving\nexplicit mesh surfaces. Instead of uniformly distributing neural features\nthroughout 3D space, our method stores learnable features directly at mesh\nvertices, leveraging the underlying geometry as a compact and structured\nrepresentation for neural processing. This not only optimizes memory\nefficiency, but also improves feature representation by aligning compactly with\nthe surface using task-specific geometric priors. We validate our neural\nrepresentation across diverse neural rendering tasks, with a specific emphasis\non neural radiosity. Experimental results demonstrate that our method reduces\nmemory consumption to only one-fifth (or even less) of grid-based\nrepresentations, while maintaining comparable rendering quality and lowering\ninference overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u795e\u7ecf\u9876\u70b9\u7279\u5f81\u7528\u4e8e\u795e\u7ecf\u6e32\u67d3\u4efb\u52a1\uff0c\u4f18\u5316\u5185\u5b58\u6548\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u5927\u5e45\u964d\u4f4e\u5185\u5b58\u6d88\u8017\u5e76\u4fdd\u6301\u6e32\u67d3\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u7279\u5f81\u7f51\u683c\u8868\u793a\u5185\u5b58\u5360\u7528\u5927\uff0c\u6210\u4e3a\u73b0\u4ee3\u5e76\u884c\u8ba1\u7b97\u786c\u4ef6\u74f6\u9888\u3002", "method": "\u5c06\u53ef\u5b66\u4e60\u7279\u5f81\u76f4\u63a5\u5b58\u50a8\u5728\u7f51\u683c\u9876\u70b9\uff0c\u5229\u7528\u5e95\u5c42\u51e0\u4f55\u7ed3\u6784\u8fdb\u884c\u795e\u7ecf\u5904\u7406\u3002", "result": "\u65b9\u6cd5\u5c06\u5185\u5b58\u6d88\u8017\u964d\u81f3\u57fa\u4e8e\u7f51\u683c\u8868\u793a\u7684\u4e94\u5206\u4e4b\u4e00\u751a\u81f3\u66f4\u5c11\uff0c\u4fdd\u6301\u53ef\u6bd4\u6e32\u67d3\u8d28\u91cf\u5e76\u964d\u4f4e\u63a8\u7406\u5f00\u9500\u3002", "conclusion": "\u795e\u7ecf\u9876\u70b9\u7279\u5f81\u662f\u4e00\u79cd\u6709\u6548\u7684\u53ef\u5b66\u4e60\u8868\u793a\uff0c\u80fd\u4f18\u5316\u5185\u5b58\u6548\u7387\u5e76\u63d0\u5347\u7279\u5f81\u8868\u793a\u3002"}}
{"id": "2508.08096", "pdf": "https://arxiv.org/pdf/2508.08096", "abs": "https://arxiv.org/abs/2508.08096", "authors": ["Lukas Gehring", "Benjamin Paa\u00dfen"], "title": "Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?", "categories": ["cs.CL", "cs.LG"], "comment": "Preprint as provided by the authors (19 pages, 12 figures, 9 tables)", "summary": "Recent advancements in Large Language Models (LLMs) and their increased\naccessibility have made it easier than ever for students to automatically\ngenerate texts, posing new challenges for educational institutions. To enforce\nnorms of academic integrity and ensure students' learning, learning analytics\nmethods to automatically detect LLM-generated text appear increasingly\nappealing. This paper benchmarks the performance of different state-of-the-art\ndetectors in educational contexts, introducing a novel dataset, called\nGenerative Essay Detection in Education (GEDE), containing over 900\nstudent-written essays and over 12,500 LLM-generated essays from various\ndomains. To capture the diversity of LLM usage practices in generating text, we\npropose the concept of contribution levels, representing students' contribution\nto a given assignment. These levels range from purely human-written texts, to\nslightly LLM-improved versions, to fully LLM-generated texts, and finally to\nactive attacks on the detector by \"humanizing\" generated texts. We show that\nmost detectors struggle to accurately classify texts of intermediate student\ncontribution levels, like LLM-improved human-written texts. Detectors are\nparticularly likely to produce false positives, which is problematic in\neducational settings where false suspicions can severely impact students'\nlives. Our dataset, code, and additional supplementary materials are publicly\navailable at\nhttps://github.com/lukasgehring/Assessing-LLM-Text-Detection-in-Educational-Contexts.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6559\u80b2\u573a\u666f\u4e0b\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u68c0\u6d4b\u5668\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f15\u5165\u65b0\u6570\u636e\u96c6GEDE\uff0c\u6307\u51fa\u591a\u6570\u68c0\u6d4b\u5668\u5bf9\u4e2d\u7b49\u5b66\u751f\u8d21\u732e\u6587\u672c\u5206\u7c7b\u4e0d\u4f73\uff0c\u6613\u4ea7\u751f\u8bef\u5224\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4f7f\u5b66\u751f\u81ea\u52a8\u751f\u6210\u6587\u672c\u66f4\u4fbf\u6377\uff0c\u7ed9\u6559\u80b2\u673a\u6784\u5e26\u6765\u6311\u6218\uff0c\u9700\u5b66\u4e60\u5206\u6790\u65b9\u6cd5\u68c0\u6d4b\u6b64\u7c7b\u6587\u672c\u3002", "method": "\u5bf9\u4e0d\u540c\u68c0\u6d4b\u5668\u6027\u80fd\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f15\u5165GEDE\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u8d21\u732e\u6c34\u5e73\u6982\u5ff5\u3002", "result": "\u591a\u6570\u68c0\u6d4b\u5668\u96be\u4ee5\u51c6\u786e\u5206\u7c7b\u4e2d\u7b49\u5b66\u751f\u8d21\u732e\u6c34\u5e73\u6587\u672c\uff0c\u6613\u4ea7\u751f\u8bef\u5224\u3002", "conclusion": "\u5f53\u524d\u68c0\u6d4b\u5668\u5728\u6559\u80b2\u573a\u666f\u4e2d\u5bf9\u7279\u5b9a\u6587\u672c\u5206\u7c7b\u6548\u679c\u4e0d\u4f73\uff0c\u6570\u636e\u96c6\u7b49\u6750\u6599\u516c\u5f00\u53ef\u4fc3\u8fdb\u7814\u7a76\u3002"}}
{"id": "2508.08146", "pdf": "https://arxiv.org/pdf/2508.08146", "abs": "https://arxiv.org/abs/2508.08146", "authors": ["Adrian Baule"], "title": "An effective potential for generative modelling with active matter", "categories": ["cond-mat.stat-mech", "cond-mat.soft", "cs.LG"], "comment": null, "summary": "Score-based diffusion models generate samples from a complex underlying data\ndistribution by time-reversal of a diffusion process and represent the\nstate-of-the-art in many generative AI applications such as artificial image\nsynthesis. Here, I show how a generative diffusion model can be implemented\nbased on an underlying active particle process with finite correlation time. In\ncontrast to previous approaches that use a score function acting on the\nvelocity coordinate of the active particle, time reversal is here achieved by\nimposing an effective time-dependent potential on the position coordinate only.\nThe effective potential is valid to first order in the persistence time and\nleads to a force field that is fully determined by the standard score function\nand its derivatives up to 2nd order. Numerical experiments for artificial data\ndistributions confirm the validity of the effective potential.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u57fa\u4e8e\u6709\u9650\u5173\u8054\u65f6\u95f4\u7684\u6d3b\u6027\u7c92\u5b50\u8fc7\u7a0b\u5b9e\u73b0\u751f\u6210\u6269\u6563\u6a21\u578b\uff0c\u7528\u6709\u6548\u52bf\u5b9e\u73b0\u65f6\u95f4\u53cd\u8f6c\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u52bf\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22\u57fa\u4e8e\u6709\u9650\u5173\u8054\u65f6\u95f4\u7684\u6d3b\u6027\u7c92\u5b50\u8fc7\u7a0b\u5b9e\u73b0\u751f\u6210\u6269\u6563\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5bf9\u6d3b\u6027\u7c92\u5b50\u4f4d\u7f6e\u5750\u6807\u65bd\u52a0\u4e0e\u65f6\u95f4\u76f8\u5173\u7684\u6709\u6548\u52bf\u5b9e\u73b0\u65f6\u95f4\u53cd\u8f6c\uff0c\u6709\u6548\u52bf\u5728\u6301\u4e45\u65f6\u95f4\u4e00\u9636\u6709\u6548\uff0c\u529b\u573a\u7531\u6807\u51c6\u5f97\u5206\u51fd\u6570\u53ca\u5176\u4e8c\u9636\u5bfc\u6570\u786e\u5b9a\u3002", "result": "\u9488\u5bf9\u4eba\u5de5\u6570\u636e\u5206\u5e03\u7684\u6570\u503c\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u6709\u6548\u52bf\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u6709\u9650\u5173\u8054\u65f6\u95f4\u7684\u6d3b\u6027\u7c92\u5b50\u8fc7\u7a0b\uff0c\u901a\u8fc7\u65bd\u52a0\u6709\u6548\u52bf\u53ef\u5b9e\u73b0\u751f\u6210\u6269\u6563\u6a21\u578b\u3002"}}
{"id": "2508.07877", "pdf": "https://arxiv.org/pdf/2508.07877", "abs": "https://arxiv.org/abs/2508.07877", "authors": ["WonJun Moon", "Hyun Seok Seong", "Jae-Pil Heo"], "title": "Selective Contrastive Learning for Weakly Supervised Affordance Grounding", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICCV 2025", "summary": "Facilitating an entity's interaction with objects requires accurately\nidentifying parts that afford specific actions. Weakly supervised affordance\ngrounding (WSAG) seeks to imitate human learning from third-person\ndemonstrations, where humans intuitively grasp functional parts without needing\npixel-level annotations. To achieve this, grounding is typically learned using\na shared classifier across images from different perspectives, along with\ndistillation strategies incorporating part discovery process. However, since\naffordance-relevant parts are not always easily distinguishable, models\nprimarily rely on classification, often focusing on common class-specific\npatterns that are unrelated to affordance. To address this limitation, we move\nbeyond isolated part-level learning by introducing selective prototypical and\npixel contrastive objectives that adaptively learn affordance-relevant cues at\nboth the part and object levels, depending on the granularity of the available\ninformation. Initially, we find the action-associated objects in both\negocentric (object-focused) and exocentric (third-person example) images by\nleveraging CLIP. Then, by cross-referencing the discovered objects of\ncomplementary views, we excavate the precise part-level affordance clues in\neach perspective. By consistently learning to distinguish affordance-relevant\nregions from affordance-irrelevant background context, our approach effectively\nshifts activation from irrelevant areas toward meaningful affordance cues.\nExperimental results demonstrate the effectiveness of our method. Codes are\navailable at github.com/hynnsk/SelectiveCL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\u89e3\u51b3\u5f31\u76d1\u7763\u53ef\u53ca\u6027\u5b9a\u4f4d\u95ee\u9898\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u539f\u578b\u548c\u50cf\u7d20\u5bf9\u6bd4\u76ee\u6807\u5b66\u4e60\u76f8\u5173\u7ebf\u7d22\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u5f31\u76d1\u7763\u53ef\u53ca\u6027\u5b9a\u4f4d\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u5206\u7c7b\uff0c\u5e38\u5173\u6ce8\u4e0e\u53ef\u53ca\u6027\u65e0\u5173\u7684\u5e38\u89c1\u6a21\u5f0f\uff0c\u65e0\u6cd5\u5f88\u597d\u533a\u5206\u53ef\u53ca\u6027\u76f8\u5173\u90e8\u5206\u3002", "method": "\u5f15\u5165\u9009\u62e9\u6027\u539f\u578b\u548c\u50cf\u7d20\u5bf9\u6bd4\u76ee\u6807\uff0c\u5728\u90e8\u5206\u548c\u5bf9\u8c61\u5c42\u9762\u81ea\u9002\u5e94\u5b66\u4e60\u53ef\u53ca\u6027\u76f8\u5173\u7ebf\u7d22\uff1b\u5229\u7528CLIP\u627e\u5230\u4e0d\u540c\u89c6\u89d2\u56fe\u50cf\u4e2d\u4e0e\u52a8\u4f5c\u5173\u8054\u7684\u5bf9\u8c61\uff0c\u4ea4\u53c9\u53c2\u8003\u6316\u6398\u7cbe\u786e\u7684\u90e8\u5206\u7ea7\u53ef\u53ca\u6027\u7ebf\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u5c06\u6fc0\u6d3b\u4ece\u65e0\u5173\u533a\u57df\u8f6c\u79fb\u5230\u6709\u610f\u4e49\u7684\u53ef\u53ca\u6027\u7ebf\u7d22\u4e0a\u3002"}}
{"id": "2508.08163", "pdf": "https://arxiv.org/pdf/2508.08163", "abs": "https://arxiv.org/abs/2508.08163", "authors": ["Mandira Sawkar", "Samay U. Shetty", "Deepak Pandita", "Tharindu Cyril Weerasooriya", "Christopher M. Homan"], "title": "LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The Learning With Disagreements (LeWiDi) 2025 shared task is to model\nannotator disagreement through soft label distribution prediction and\nperspectivist evaluation, modeling annotators. We adapt DisCo (Distribution\nfrom Context), a neural architecture that jointly models item-level and\nannotator-level label distributions, and present detailed analysis and\nimprovements. In this paper, we extend the DisCo by incorporating annotator\nmetadata, enhancing input representations, and modifying the loss functions to\ncapture disagreement patterns better. Through extensive experiments, we\ndemonstrate substantial improvements in both soft and perspectivist evaluation\nmetrics across three datasets. We also conduct in-depth error and calibration\nanalyses, highlighting the conditions under which improvements occur. Our\nfindings underscore the value of disagreement-aware modeling and offer insights\ninto how system components interact with the complexity of human-annotated\ndata.", "AI": {"tldr": "\u672c\u6587\u53c2\u4e0eLeWiDi 2025\u5171\u4eab\u4efb\u52a1\uff0c\u6539\u8fdbDisCo\u6a21\u578b\u4ee5\u66f4\u597d\u6355\u83b7\u5206\u6b67\u6a21\u5f0f\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6307\u6807\u6709\u663e\u8457\u63d0\u5347\uff0c\u8fd8\u8fdb\u884c\u6df1\u5165\u5206\u6790\u5e76\u5f3a\u8c03\u5206\u6b67\u611f\u77e5\u5efa\u6a21\u7684\u4ef7\u503c\u3002", "motivation": "\u53c2\u4e0eLeWiDi 2025\u5171\u4eab\u4efb\u52a1\uff0c\u89e3\u51b3\u5982\u4f55\u901a\u8fc7\u8f6f\u6807\u7b7e\u5206\u5e03\u9884\u6d4b\u548c\u89c6\u89d2\u4e3b\u4e49\u8bc4\u4f30\u6765\u5efa\u6a21\u6ce8\u91ca\u8005\u5206\u6b67\u7684\u95ee\u9898\u3002", "method": "\u6269\u5c55DisCo\uff0c\u7eb3\u5165\u6ce8\u91ca\u8005\u5143\u6570\u636e\uff0c\u589e\u5f3a\u8f93\u5165\u8868\u793a\uff0c\u4fee\u6539\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u7684\u8f6f\u8bc4\u4f30\u548c\u89c6\u89d2\u4e3b\u4e49\u8bc4\u4f30\u6307\u6807\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u8fd8\u8fdb\u884c\u6df1\u5165\u7684\u9519\u8bef\u548c\u6821\u51c6\u5206\u6790\u3002", "conclusion": "\u5f3a\u8c03\u5206\u6b67\u611f\u77e5\u5efa\u6a21\u7684\u4ef7\u503c\uff0c\u4e3a\u7cfb\u7edf\u7ec4\u4ef6\u4e0e\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u590d\u6742\u6027\u7684\u4ea4\u4e92\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2508.07885", "pdf": "https://arxiv.org/pdf/2508.07885", "abs": "https://arxiv.org/abs/2508.07885", "authors": ["Shoaib Ahmmad", "Zubayer Ahmed Aditto", "Md Mehrab Hossain", "Noushin Yeasmin", "Shorower Hossain"], "title": "Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper introduces an advanced AI-driven perception system for autonomous\nquadcopter navigation in GPS-denied indoor environments. The proposed framework\nleverages cloud computing to offload computationally intensive tasks and\nincorporates a custom-designed printed circuit board (PCB) for efficient sensor\ndata acquisition, enabling robust navigation in confined spaces. The system\nintegrates YOLOv11 for object detection, Depth Anything V2 for monocular depth\nestimation, a PCB equipped with Time-of-Flight (ToF) sensors and an Inertial\nMeasurement Unit (IMU), and a cloud-based Large Language Model (LLM) for\ncontext-aware decision-making. A virtual safety envelope, enforced by\ncalibrated sensor offsets, ensures collision avoidance, while a multithreaded\narchitecture achieves low-latency processing. Enhanced spatial awareness is\nfacilitated by 3D bounding box estimation with Kalman filtering. Experimental\nresults in an indoor testbed demonstrate strong performance, with object\ndetection achieving a mean Average Precision (mAP50) of 0.6, depth estimation\nMean Absolute Error (MAE) of 7.2 cm, only 16 safety envelope breaches across 42\ntrials over approximately 11 minutes, and end-to-end system latency below 1\nsecond. This cloud-supported, high-intelligence framework serves as an\nauxiliary perception and navigation system, complementing state-of-the-art\ndrone autonomy for GPS-denied confined spaces.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u5ba4\u5185\u65e0GPS\u73af\u5883\u7684\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u5bfc\u822a\u7684AI\u611f\u77e5\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e91\u8ba1\u7b97\u548c\u5b9a\u5236PCB\uff0c\u96c6\u6210\u591a\u79cd\u6280\u672f\uff0c\u5b9e\u9a8c\u8868\u73b0\u826f\u597d\uff0c\u53ef\u4f5c\u4e3a\u8f85\u52a9\u5bfc\u822a\u7cfb\u7edf\u3002", "motivation": "\u89e3\u51b3\u5ba4\u5185\u65e0GPS\u73af\u5883\u4e0b\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7684\u5bfc\u822a\u95ee\u9898\u3002", "method": "\u5229\u7528\u4e91\u8ba1\u7b97\u5378\u8f7d\u8ba1\u7b97\u4efb\u52a1\uff0c\u91c7\u7528\u5b9a\u5236PCB\u91c7\u96c6\u6570\u636e\uff0c\u96c6\u6210YOLOv11\u3001Depth Anything V2\u3001ToF\u4f20\u611f\u5668\u3001IMU\u548c\u4e91LLM\uff0c\u8bbe\u7f6e\u865a\u62df\u5b89\u5168\u5305\u7edc\uff0c\u91c7\u7528\u591a\u7ebf\u7a0b\u67b6\u6784\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\u3002", "result": "\u5728\u5ba4\u5185\u6d4b\u8bd5\u5e73\u53f0\u4e0a\uff0c\u76ee\u6807\u68c0\u6d4bmAP50\u4e3a0.6\uff0c\u6df1\u5ea6\u4f30\u8ba1MAE\u4e3a7.2cm\uff0c42\u6b21\u8bd5\u9a8c\u4e2d\u5b89\u5168\u5305\u7edc\u4ec5\u7a81\u783416\u6b21\uff0c\u7cfb\u7edf\u7aef\u5230\u7aef\u5ef6\u8fdf\u4f4e\u4e8e1\u79d2\u3002", "conclusion": "\u8be5\u4e91\u652f\u6301\u7684\u9ad8\u667a\u80fd\u6846\u67b6\u53ef\u4f5c\u4e3a\u8f85\u52a9\u611f\u77e5\u548c\u5bfc\u822a\u7cfb\u7edf\uff0c\u8865\u5145\u73b0\u6709\u65e0\u4eba\u673a\u5728\u65e0GPS\u53d7\u9650\u7a7a\u95f4\u7684\u81ea\u4e3b\u6027\u3002"}}
{"id": "2508.08165", "pdf": "https://arxiv.org/pdf/2508.08165", "abs": "https://arxiv.org/abs/2508.08165", "authors": ["Yan Wang", "Da-Wei Zhou", "Han-Jia Ye"], "title": "Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025. Code is available at:\n  https://github.com/LAMDA-CL/ICCV2025-TUNA", "summary": "Class-Incremental Learning (CIL) requires a learning system to continually\nlearn new classes without forgetting. Existing pre-trained model-based CIL\nmethods often freeze the pre-trained network and adapt to incremental tasks\nusing additional lightweight modules such as adapters. However, incorrect\nmodule selection during inference hurts performance, and task-specific modules\noften overlook shared general knowledge, leading to errors on distinguishing\nbetween similar classes across tasks. To address the aforementioned challenges,\nwe propose integrating Task-Specific and Universal Adapters (TUNA) in this\npaper. Specifically, we train task-specific adapters to capture the most\ncrucial features relevant to their respective tasks and introduce an\nentropy-based selection mechanism to choose the most suitable adapter.\nFurthermore, we leverage an adapter fusion strategy to construct a universal\nadapter, which encodes the most discriminative features shared across tasks. We\ncombine task-specific and universal adapter predictions to harness both\nspecialized and general knowledge during inference. Extensive experiments on\nvarious benchmark datasets demonstrate the state-of-the-art performance of our\napproach. Code is available at: https://github.com/LAMDA-CL/ICCV2025-TUNA", "AI": {"tldr": "\u63d0\u51fa\u96c6\u6210\u4efb\u52a1\u7279\u5b9a\u548c\u901a\u7528\u9002\u914d\u5668\uff08TUNA\uff09\u65b9\u6cd5\u89e3\u51b3\u7c7b\u589e\u91cf\u5b66\u4e60\u95ee\u9898\uff0c\u5b9e\u9a8c\u6548\u679c\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684CIL\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u65f6\u6a21\u5757\u9009\u62e9\u9519\u8bef\u5f71\u54cd\u6027\u80fd\u3001\u4efb\u52a1\u7279\u5b9a\u6a21\u5757\u5ffd\u7565\u901a\u7528\u77e5\u8bc6\u5bfc\u81f4\u533a\u5206\u76f8\u4f3c\u7c7b\u6709\u8bef\u5dee\u7684\u95ee\u9898\u3002", "method": "\u8bad\u7ec3\u4efb\u52a1\u7279\u5b9a\u9002\u914d\u5668\u6355\u6349\u5173\u952e\u7279\u5f81\uff0c\u5f15\u5165\u57fa\u4e8e\u71b5\u7684\u9009\u62e9\u673a\u5236\u9009\u9002\u914d\u9002\u914d\u5668\uff0c\u5229\u7528\u9002\u914d\u5668\u878d\u5408\u7b56\u7565\u6784\u5efa\u901a\u7528\u9002\u914d\u5668\uff0c\u7ed3\u5408\u4e24\u8005\u9884\u6d4b\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u5728\u5404\u79cd\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684TUNA\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709CIL\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2508.08206", "pdf": "https://arxiv.org/pdf/2508.08206", "abs": "https://arxiv.org/abs/2508.08206", "authors": ["Amirhossein Taherpour", "Abbas Taherpour", "Tamer Khattab"], "title": "Adaptive Learning for IRS-Assisted Wireless Networks: Securing Opportunistic Communications Against Byzantine Eavesdroppers", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT", "math.OC"], "comment": null, "summary": "We propose a joint learning framework for Byzantine-resilient spectrum\nsensing and secure intelligent reflecting surface (IRS)--assisted opportunistic\naccess under channel state information (CSI) uncertainty. The sensing stage\nperforms logit-domain Bayesian updates with trimmed aggregation and\nattention-weighted consensus, and the base station (BS) fuses network beliefs\nwith a conservative minimum rule, preserving detection accuracy under a bounded\nnumber of Byzantine users. Conditioned on the sensing outcome, we pose downlink\ndesign as sum mean-squared error (MSE) minimization under transmit-power and\nsignal-leakage constraints and jointly optimize the BS precoder, IRS phase\nshifts, and user equalizers. With partial (or known) CSI, we develop an\naugmented-Lagrangian alternating algorithm with projected updates and provide\nprovable sublinear convergence, with accelerated rates under mild local\ncurvature. With unknown CSI, we perform constrained Bayesian optimization (BO)\nin a geometry-aware low-dimensional latent space using Gaussian process (GP)\nsurrogates; we prove regret bounds for a constrained upper confidence bound\n(UCB) variant of the BO module, and demonstrate strong empirical performance of\nthe implemented procedure. Simulations across diverse network conditions show\nhigher detection probability at fixed false-alarm rate under adversarial\nattacks, large reductions in sum MSE for honest users, strong suppression of\neavesdropper signal power, and fast convergence. The framework offers a\npractical path to secure opportunistic communication that adapts to CSI\navailability while coherently coordinating sensing and transmission through\njoint learning.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u62dc\u5360\u5ead\u5f39\u6027\u9891\u8c31\u611f\u77e5\u548c\u5b89\u5168\u667a\u80fd\u53cd\u5c04\u9762\u8f85\u52a9\u673a\u4f1a\u63a5\u5165\u7684\u8054\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u4e0d\u540c\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u6761\u4ef6\u4e0b\u91c7\u7528\u4e0d\u540c\u65b9\u6cd5\u4f18\u5316\uff0c\u6a21\u62df\u663e\u793a\u591a\u79cd\u4f18\u52bf\u3002", "motivation": "\u89e3\u51b3\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0d\u786e\u5b9a\u4e0b\u62dc\u5360\u5ead\u5f39\u6027\u9891\u8c31\u611f\u77e5\u548c\u5b89\u5168\u667a\u80fd\u53cd\u5c04\u9762\u8f85\u52a9\u673a\u4f1a\u63a5\u5165\u95ee\u9898\u3002", "method": "\u611f\u77e5\u9636\u6bb5\u7528logit\u57df\u8d1d\u53f6\u65af\u66f4\u65b0\u3001\u4fee\u526a\u805a\u5408\u548c\u6ce8\u610f\u529b\u52a0\u6743\u5171\u8bc6\uff1b\u6709\u90e8\u5206\u6216\u5df2\u77e5\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u65f6\u7528\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u4ea4\u66ff\u7b97\u6cd5\uff1b\u672a\u77e5\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u65f6\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u7528\u7ea6\u675f\u8d1d\u53f6\u65af\u4f18\u5316\u3002", "result": "\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u56fa\u5b9a\u865a\u8b66\u7387\u65f6\u68c0\u6d4b\u6982\u7387\u66f4\u9ad8\uff0c\u8bda\u5b9e\u7528\u6237\u7684\u603b\u5747\u65b9\u8bef\u5dee\u5927\u5e45\u964d\u4f4e\uff0c\u6709\u6548\u6291\u5236\u7a83\u542c\u8005\u4fe1\u53f7\u529f\u7387\uff0c\u6536\u655b\u5feb\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b89\u5168\u673a\u4f1a\u901a\u4fe1\u63d0\u4f9b\u5b9e\u7528\u9014\u5f84\uff0c\u80fd\u9002\u5e94\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u53ef\u7528\u6027\uff0c\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u534f\u8c03\u611f\u77e5\u548c\u4f20\u8f93\u3002"}}
{"id": "2508.07897", "pdf": "https://arxiv.org/pdf/2508.07897", "abs": "https://arxiv.org/abs/2508.07897", "authors": ["Tianle Zeng", "Junlei Hu", "Gerardo Loza Galindo", "Sharib Ali", "Duygu Sarikaya", "Pietro Valdastri", "Dominic Jones"], "title": "NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction", "categories": ["cs.CV", "cs.AI", "I.3.3"], "comment": "13 pages, 9 figures", "summary": "Computer vision-based technologies significantly enhance surgical automation\nby advancing tool tracking, detection, and localization. However, Current\ndata-driven approaches are data-voracious, requiring large, high-quality\nlabeled image datasets, which limits their application in surgical data\nscience. Our Work introduces a novel dynamic Gaussian Splatting technique to\naddress the data scarcity in surgical image datasets. We propose a dynamic\nGaussian model to represent dynamic surgical scenes, enabling the rendering of\nsurgical instruments from unseen viewpoints and deformations with real tissue\nbackgrounds. We utilize a dynamic training adjustment strategy to address\nchallenges posed by poorly calibrated camera poses from real-world scenarios.\nAdditionally, we propose a method based on dynamic Gaussians for automatically\ngenerating annotations for our synthetic data. For evaluation, we constructed a\nnew dataset featuring seven scenes with 14,000 frames of tool and camera motion\nand tool jaw articulation, with a background of an ex-vivo porcine model. Using\nthis dataset, we synthetically replicate the scene deformation from the ground\ntruth data, allowing direct comparisons of synthetic image quality.\nExperimental results illustrate that our method generates photo-realistic\nlabeled image datasets with the highest values in Peak-Signal-to-Noise Ratio\n(29.87). We further evaluate the performance of medical-specific neural\nnetworks trained on real and synthetic images using an unseen real-world image\ndataset. Our results show that the performance of models trained on synthetic\nimages generated by the proposed method outperforms those trained with\nstate-of-the-art standard data augmentation by 10%, leading to an overall\nimprovement in model performances by nearly 15%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u52a8\u6001\u9ad8\u65af\u6563\u70b9\u6280\u672f\u89e3\u51b3\u624b\u672f\u56fe\u50cf\u6570\u636e\u96c6\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u6784\u5efa\u65b0\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u751f\u6210\u56fe\u50cf\u8d28\u91cf\u9ad8\uff0c\u8bad\u7ec3\u6a21\u578b\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u9700\u5927\u91cf\u9ad8\u8d28\u91cf\u6807\u6ce8\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u9650\u5236\u5176\u5728\u624b\u672f\u6570\u636e\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u56e0\u6b64\u8981\u89e3\u51b3\u624b\u672f\u56fe\u50cf\u6570\u636e\u96c6\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u5f15\u5165\u52a8\u6001\u9ad8\u65af\u6563\u70b9\u6280\u672f\uff0c\u63d0\u51fa\u52a8\u6001\u9ad8\u65af\u6a21\u578b\u8868\u793a\u52a8\u6001\u624b\u672f\u573a\u666f\uff0c\u91c7\u7528\u52a8\u6001\u8bad\u7ec3\u8c03\u6574\u7b56\u7565\u5e94\u5bf9\u76f8\u673a\u59ff\u6001\u6821\u51c6\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u52a8\u6001\u9ad8\u65af\u7684\u5408\u6210\u6570\u636e\u81ea\u52a8\u6807\u6ce8\u65b9\u6cd5\u3002", "result": "\u751f\u6210\u7684\u6807\u6ce8\u56fe\u50cf\u6570\u636e\u96c6\u7684\u5cf0\u503c\u4fe1\u566a\u6bd4\u6700\u9ad8\uff0c\u7528\u5408\u6210\u56fe\u50cf\u8bad\u7ec3\u7684\u6a21\u578b\u6027\u80fd\u6bd4\u7528\u73b0\u6709\u6807\u51c6\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u9ad810%\uff0c\u6574\u4f53\u6a21\u578b\u6027\u80fd\u63d0\u5347\u8fd115%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u624b\u672f\u56fe\u50cf\u6570\u636e\u96c6\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u5347\u533b\u5b66\u7279\u5b9a\u795e\u7ecf\u7f51\u7edc\u7684\u6027\u80fd\u3002"}}
{"id": "2508.08211", "pdf": "https://arxiv.org/pdf/2508.08211", "abs": "https://arxiv.org/abs/2508.08211", "authors": ["Zhuohao Yu", "Xingru Jiang", "Weizheng Gu", "Yidong Wang", "Shikun Zhang", "Wei Ye"], "title": "SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "24 pages, 12 figures, code available:\n  https://zhuohaoyu.github.io/SAEMark", "summary": "Watermarking LLM-generated text is critical for content attribution and\nmisinformation prevention. However, existing methods compromise text quality,\nrequire white-box model access and logit manipulation. These limitations\nexclude API-based models and multilingual scenarios. We propose SAEMark, a\ngeneral framework for post-hoc multi-bit watermarking that embeds personalized\nmessages solely via inference-time, feature-based rejection sampling without\naltering model logits or requiring training. Our approach operates on\ndeterministic features extracted from generated text, selecting outputs whose\nfeature statistics align with key-derived targets. This framework naturally\ngeneralizes across languages and domains while preserving text quality through\nsampling LLM outputs instead of modifying. We provide theoretical guarantees\nrelating watermark success probability and compute budget that hold for any\nsuitable feature extractor. Empirically, we demonstrate the framework's\neffectiveness using Sparse Autoencoders (SAEs), achieving superior detection\naccuracy and text quality. Experiments across 4 datasets show SAEMark's\nconsistent performance, with 99.7% F1 on English and strong multi-bit detection\naccuracy. SAEMark establishes a new paradigm for scalable watermarking that\nworks out-of-the-box with closed-source LLMs while enabling content\nattribution.", "AI": {"tldr": "\u63d0\u51faSAEMark\u6846\u67b6\u7528\u4e8e\u4e8b\u540e\u591a\u4f4d\u6c34\u5370\u5d4c\u5165\uff0c\u5728\u591a\u8bed\u8a00\u548c\u95ed\u6e90\u6a21\u578b\u573a\u666f\u6709\u6548\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u6c34\u5370\u65b9\u6cd5\u5b58\u5728\u635f\u5bb3\u6587\u672c\u8d28\u91cf\u3001\u9700\u767d\u76d2\u6a21\u578b\u8bbf\u95ee\u548c\u64cd\u7eb5\u5bf9\u6570\u7b49\u5c40\u9650\uff0c\u4e0d\u9002\u7528\u4e8eAPI\u6a21\u578b\u548c\u591a\u8bed\u8a00\u573a\u666f\u3002", "method": "\u63d0\u51faSAEMark\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u57fa\u4e8e\u7279\u5f81\u7684\u62d2\u7edd\u91c7\u6837\u5d4c\u5165\u4e2a\u6027\u5316\u6d88\u606f\uff0c\u4e0d\u6539\u53d8\u6a21\u578b\u5bf9\u6570\u4e5f\u65e0\u9700\u8bad\u7ec3\uff0c\u57fa\u4e8e\u751f\u6210\u6587\u672c\u7684\u786e\u5b9a\u6027\u7279\u5f81\u9009\u62e9\u8f93\u51fa\u3002", "result": "\u4f7f\u7528\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u8bc1\u660e\u6846\u67b6\u6709\u6548\u6027\uff0c\u57284\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4e00\u81f4\uff0c\u82f1\u8bedF1\u8fbe99.7%\uff0c\u591a\u4f4d\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\u3002", "conclusion": "SAEMark\u4e3a\u53ef\u6269\u5c55\u6c34\u5370\u5efa\u7acb\u65b0\u8303\u5f0f\uff0c\u80fd\u4e0e\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u914d\u5408\uff0c\u5b9e\u73b0\u5185\u5bb9\u6eaf\u6e90\u3002"}}
{"id": "2508.07903", "pdf": "https://arxiv.org/pdf/2508.07903", "abs": "https://arxiv.org/abs/2508.07903", "authors": ["Johanna P. M\u00fcller", "Anika Knupfer", "Pedro Bl\u00f6ss", "Edoardo Berardi Vittur", "Bernhard Kainz", "Jana Hutter"], "title": "Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted at MICCAI CAPI 2025", "summary": "Despite significant progress in generative modelling, existing diffusion\nmodels often struggle to produce anatomically precise female pelvic images,\nlimiting their application in gynaecological imaging, where data scarcity and\npatient privacy concerns are critical. To overcome these barriers, we introduce\na novel diffusion-based framework for uterine MRI synthesis, integrating both\nunconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs)\nand Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates\nanatomically coherent, high fidelity synthetic images that closely mimic real\nscans and provide valuable resources for training robust diagnostic models. We\nevaluate generative quality using advanced perceptual and distributional\nmetrics, benchmarking against standard reconstruction methods, and demonstrate\nsubstantial gains in diagnostic accuracy on a key classification task. A\nblinded expert evaluation further validates the clinical realism of our\nsynthetic images. We release our models with privacy safeguards and a\ncomprehensive synthetic uterine MRI dataset to support reproducible research\nand advance equitable AI in gynaecology.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5b50\u5babMRI\u5408\u6210\u7684\u6269\u6563\u6846\u67b6\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u56fe\u50cf\uff0c\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u5e76\u53d1\u5e03\u6a21\u578b\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u96be\u4ee5\u751f\u6210\u89e3\u5256\u5b66\u7cbe\u786e\u7684\u5973\u6027\u76c6\u8154\u56fe\u50cf\uff0c\u6570\u636e\u7a00\u7f3a\u548c\u60a3\u8005\u9690\u79c1\u95ee\u9898\u9650\u5236\u5176\u5728\u5987\u79d1\u6210\u50cf\u5e94\u7528\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u96c6\u6210\u65e0\u6761\u4ef6\u548c\u6761\u4ef6\u7684Denoising Diffusion Probabilistic Models (DDPMs) \u548cLatent Diffusion Models (LDMs) \u8fdb\u884c2D\u548c3D\u5b50\u5babMRI\u5408\u6210\u3002", "result": "\u751f\u6210\u89e3\u5256\u5b66\u8fde\u8d2f\u3001\u9ad8\u4fdd\u771f\u5408\u6210\u56fe\u50cf\uff0c\u5728\u8bca\u65ad\u5206\u7c7b\u4efb\u52a1\u4e2d\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4e13\u5bb6\u8bc4\u4f30\u9a8c\u8bc1\u56fe\u50cf\u4e34\u5e8a\u771f\u5b9e\u6027\u3002", "conclusion": "\u53d1\u5e03\u5e26\u9690\u79c1\u4fdd\u62a4\u7684\u6a21\u578b\u548c\u7efc\u5408\u6570\u636e\u96c6\uff0c\u652f\u6301\u53ef\u91cd\u590d\u7814\u7a76\uff0c\u63a8\u52a8\u5987\u79d1\u516c\u5e73AI\u53d1\u5c55\u3002"}}
{"id": "2508.07944", "pdf": "https://arxiv.org/pdf/2508.07944", "abs": "https://arxiv.org/abs/2508.07944", "authors": ["Vojt\u011bch Stan\u011bk", "Karel Srna", "Anton Firc", "Kamil Malinka"], "title": "SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis", "categories": ["cs.SD", "cs.AI", "cs.CR"], "comment": null, "summary": "Despite growing attention to deepfake speech detection, the aspects of bias\nand fairness remain underexplored in the speech domain. To address this gap, we\nintroduce the Speaker Characteristics Deepfake (SCDF) dataset: a novel, richly\nannotated resource enabling systematic evaluation of demographic biases in\ndeepfake speech detection. SCDF contains over 237,000 utterances in a balanced\nrepresentation of both male and female speakers spanning five languages and a\nwide age range. We evaluate several state-of-the-art detectors and show that\nspeaker characteristics significantly influence detection performance,\nrevealing disparities across sex, language, age, and synthesizer type. These\nfindings highlight the need for bias-aware development and provide a foundation\nfor building non-discriminatory deepfake detection systems aligned with ethical\nand regulatory standards.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165SCDF\u6570\u636e\u96c6\u8bc4\u4f30\u6df1\u5ea6\u4f2a\u9020\u8bed\u97f3\u68c0\u6d4b\u4e2d\u7684\u4eba\u53e3\u504f\u5dee\uff0c\u53d1\u73b0\u8bf4\u8bdd\u8005\u7279\u5f81\u5f71\u54cd\u68c0\u6d4b\u6027\u80fd\uff0c\u5f3a\u8c03\u9700\u5f00\u53d1\u65e0\u504f\u68c0\u6d4b\u7cfb\u7edf\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u4f2a\u9020\u8bed\u97f3\u68c0\u6d4b\u4e2d\u504f\u5dee\u548c\u516c\u5e73\u6027\u7814\u7a76\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165SCDF\u6570\u636e\u96c6\uff0c\u5bf9\u591a\u79cd\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bf4\u8bdd\u8005\u7279\u5f81\u663e\u8457\u5f71\u54cd\u68c0\u6d4b\u6027\u80fd\uff0c\u5728\u6027\u522b\u3001\u8bed\u8a00\u3001\u5e74\u9f84\u548c\u5408\u6210\u5668\u7c7b\u578b\u65b9\u9762\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u9700\u8981\u8fdb\u884c\u8003\u8651\u504f\u5dee\u7684\u5f00\u53d1\uff0c\u4e3a\u6784\u5efa\u7b26\u5408\u9053\u5fb7\u548c\u76d1\u7ba1\u6807\u51c6\u7684\u65e0\u6b67\u89c6\u6027\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.07976", "pdf": "https://arxiv.org/pdf/2508.07976", "abs": "https://arxiv.org/abs/2508.07976", "authors": ["Jiaxuan Gao", "Wei Fu", "Minyang Xie", "Shusheng Xu", "Chuyi He", "Zhiyu Mei", "Banghua Zhu", "Yi Wu"], "title": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in LLM-based agents have demonstrated remarkable\ncapabilities in handling complex, knowledge-intensive tasks by integrating\nexternal tools. Among diverse choices of tools, search tools play a pivotal\nrole in accessing vast external knowledge. However, open-source agents still\nfall short of achieving expert-level Search Intelligence, the ability to\nresolve ambiguous queries, generate precise searches, analyze results, and\nconduct thorough exploration. Existing approaches fall short in scalability,\nefficiency, and data quality. For example, small turn limits in existing online\nRL methods, e.g. <=10, restrict complex strategy learning. This paper\nintroduces ASearcher, an open-source project for large-scale RL training of\nsearch agents. Our key contributions include: (1) Scalable fully asynchronous\nRL training that enables long-horizon search while maintaining high training\nefficiency. (2) A prompt-based LLM agent that autonomously synthesizes\nhigh-quality and challenging QAs, creating a large-scale QA dataset. Through RL\ntraining, our prompt-based QwQ-32B agent achieves substantial improvements,\nwith 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our\nagent exhibits extreme long-horizon search, with tool calls exceeding 40 turns\nand output tokens exceeding 150k during training time. With a simple agent\ndesign and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on\nxBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We\nopen-source our models, training data, and codes in\nhttps://github.com/inclusionAI/ASearcher.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5f00\u6e90\u9879\u76eeASearcher\u7528\u4e8e\u641c\u7d22\u4ee3\u7406\u7684\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u5f02\u6b65RL\u8bad\u7ec3\u548c\u57fa\u4e8e\u63d0\u793a\u7684LLM\u4ee3\u7406\u5408\u6210\u6570\u636e\u96c6\uff0c\u5728xBench\u548cGAIA\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5f00\u6e90\u6a21\u578b\u3001\u6570\u636e\u548c\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u5f00\u6e90\u4ee3\u7406\u5728\u641c\u7d22\u667a\u80fd\u65b9\u9762\u672a\u8fbe\u4e13\u5bb6\u6c34\u5e73\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u3001\u6548\u7387\u548c\u6570\u636e\u8d28\u91cf\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u53ef\u6269\u5c55\u7684\u5168\u5f02\u6b65RL\u8bad\u7ec3\uff0c\u4f7f\u7528\u57fa\u4e8e\u63d0\u793a\u7684LLM\u4ee3\u7406\u81ea\u4e3b\u5408\u6210\u9ad8\u8d28\u91cf\u4e14\u5177\u6311\u6218\u6027\u7684\u95ee\u7b54\u6570\u636e\u96c6\u3002", "result": "\u57fa\u4e8e\u63d0\u793a\u7684QwQ - 32B\u4ee3\u7406\u5728xBench\u548cGAIA\u4e0a\u5206\u522b\u670946.7%\u548c20.8%\u7684Avg@4\u63d0\u5347\uff1bASearcher - Web - QwQ\u5728xBench\u548cGAIA\u4e0a\u7684Avg@4\u5f97\u5206\u5206\u522b\u4e3a42.1\u548c52.8\uff0c\u8d85\u8d8a\u73b0\u6709\u5f00\u6e9032B\u4ee3\u7406\u3002", "conclusion": "ASearcher\u5728\u641c\u7d22\u4ee3\u7406\u7684\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e0a\u6709\u826f\u597d\u6548\u679c\uff0c\u53ef\u5b9e\u73b0\u957f\u65f6\u641c\u7d22\uff0c\u63d0\u9ad8\u6548\u7387\uff0c\u76f8\u5173\u6a21\u578b\u3001\u6570\u636e\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.07981", "pdf": "https://arxiv.org/pdf/2508.07981", "abs": "https://arxiv.org/abs/2508.07981", "authors": ["Fangyuan Mao", "Aiming Hao", "Jintao Chen", "Dongxia Liu", "Xiaokun Feng", "Jiashu Zhu", "Meiqi Wu", "Chubin Chen", "Jiahong Wu", "Xiangxiang Chu"], "title": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual effects (VFX) are essential visual enhancements fundamental to modern\ncinematic production. Although video generation models offer cost-efficient\nsolutions for VFX production, current methods are constrained by per-effect\nLoRA training, which limits generation to single effects. This fundamental\nlimitation impedes applications that require spatially controllable composite\neffects, i.e., the concurrent generation of multiple effects at designated\nlocations. However, integrating diverse effects into a unified framework faces\nmajor challenges: interference from effect variations and spatial\nuncontrollability during multi-VFX joint training. To tackle these challenges,\nwe propose Omni-Effects, a first unified framework capable of generating\nprompt-guided effects and spatially controllable composite effects. The core of\nour framework comprises two key innovations: (1) LoRA-based Mixture of Experts\n(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects\nwithin a unified model while effectively mitigating cross-task interference.\n(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the\ntext token, enabling precise spatial control. Furthermore, we introduce an\nIndependent-Information Flow (IIF) module integrated within the SAP, isolating\nthe control signals corresponding to individual effects to prevent any unwanted\nblending. To facilitate this research, we construct a comprehensive VFX dataset\nOmni-VFX via a novel data collection pipeline combining image editing and\nFirst-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX\nevaluation framework for validating model performance. Extensive experiments\ndemonstrate that Omni-Effects achieves precise spatial control and diverse\neffect generation, enabling users to specify both the category and location of\ndesired effects.", "AI": {"tldr": "\u63d0\u51faOmni - Effects\u6846\u67b6\u89e3\u51b3\u89c6\u9891\u7279\u6548\u751f\u6210\u96be\u9898\uff0c\u80fd\u5b9e\u73b0\u7cbe\u786e\u7a7a\u95f4\u63a7\u5236\u548c\u591a\u6837\u7279\u6548\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u7279\u6548\u751f\u6210\u65b9\u6cd5\u53d7\u9650\u4e8e\u5355\u7279\u6548\u8bad\u7ec3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u7a7a\u95f4\u53ef\u63a7\u7684\u590d\u5408\u7279\u6548\u751f\u6210\u9700\u6c42\uff0c\u4e14\u6574\u5408\u591a\u6837\u7279\u6548\u9762\u4e34\u5e72\u6270\u548c\u7a7a\u95f4\u4e0d\u53ef\u63a7\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5305\u542bLoRA - MoE\u3001Spatial - Aware Prompt (SAP)\u548cIndependent - Information Flow (IIF)\u6a21\u5757\u7684Omni - Effects\u6846\u67b6\uff0c\u6784\u5efaOmni - VFX\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eOmni - Effects\u80fd\u5b9e\u73b0\u7cbe\u786e\u7a7a\u95f4\u63a7\u5236\u548c\u591a\u6837\u7279\u6548\u751f\u6210\uff0c\u7528\u6237\u53ef\u6307\u5b9a\u7279\u6548\u7c7b\u522b\u548c\u4f4d\u7f6e\u3002", "conclusion": "Omni - Effects\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u89c6\u9891\u7279\u6548\u751f\u6210\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2508.08027", "pdf": "https://arxiv.org/pdf/2508.08027", "abs": "https://arxiv.org/abs/2508.08027", "authors": ["Ahmed Aboeitta", "Ahmed Sharshar", "Youssef Nafea", "Shady Shehata"], "title": "Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Speech Recognition (ASR) due to phoneme distortions and high variability.\nWhile self-supervised ASR models like Wav2Vec, HuBERT, and Whisper have shown\npromise, their effectiveness in dysarthric speech remains unclear. This study\nsystematically benchmarks these models with different decoding strategies,\nincluding CTC, seq2seq, and LLM-enhanced decoding (BART,GPT-2, Vicuna). Our\ncontributions include (1) benchmarking ASR architectures for dysarthric speech,\n(2) introducing LLM-based decoding to improve intelligibility, (3) analyzing\ngeneralization across datasets, and (4) providing insights into recognition\nerrors across severity levels. Findings highlight that LLM-enhanced decoding\nimproves dysarthric ASR by leveraging linguistic constraints for phoneme\nrestoration and grammatical correction.", "AI": {"tldr": "\u672c\u6587\u5bf9\u81ea\u76d1\u7763ASR\u6a21\u578b\u5728\u6784\u97f3\u969c\u788d\u8bed\u97f3\u4e0a\u7528\u4e0d\u540c\u89e3\u7801\u7b56\u7565\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u89e3\u7801\u53ef\u6539\u5584\u8bc6\u522b\u6548\u679c\u3002", "motivation": "\u81ea\u76d1\u7763ASR\u6a21\u578b\u5728\u6784\u97f3\u969c\u788d\u8bed\u97f3\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u5bf9Wav2Vec\u3001HuBERT\u3001Whisper\u7b49\u6a21\u578b\u91c7\u7528CTC\u3001seq2seq\u3001\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u89e3\u7801\uff08BART\u3001GPT - 2\u3001Vicuna\uff09\u7b49\u4e0d\u540c\u89e3\u7801\u7b56\u7565\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u89e3\u7801\u901a\u8fc7\u5229\u7528\u8bed\u8a00\u7ea6\u675f\u8fdb\u884c\u97f3\u7d20\u6062\u590d\u548c\u8bed\u6cd5\u7ea0\u6b63\uff0c\u6539\u5584\u4e86\u6784\u97f3\u969c\u788d\u8bed\u97f3\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u89e3\u7801\u5bf9\u6784\u97f3\u969c\u788d\u8bed\u97f3\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u6709\u79ef\u6781\u4f5c\u7528\uff0c\u7814\u7a76\u8fd8\u5728\u67b6\u6784\u57fa\u51c6\u6d4b\u8bd5\u3001\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u5206\u6790\u548c\u9519\u8bef\u5206\u6790\u7b49\u65b9\u9762\u6709\u8d21\u732e\u3002"}}
{"id": "2508.08047", "pdf": "https://arxiv.org/pdf/2508.08047", "abs": "https://arxiv.org/abs/2508.08047", "authors": ["Arend Hintze", "Clifford Bohm"], "title": "Rethinking Self-Replication: Detecting Distributed Selfhood in the Outlier Cellular Automaton", "categories": ["nlin.CG", "cs.AI"], "comment": null, "summary": "Spontaneous self-replication in cellular automata has long been considered\nrare, with most known examples requiring careful design or artificial\ninitialization. In this paper, we present formal, causal evidence that such\nreplication can emerge unassisted -- and that it can do so in a distributed,\nmulti-component form. Building on prior work identifying complex dynamics in\nthe Outlier rule, we introduce a data-driven framework that reconstructs the\nfull causal ancestry of patterns in a deterministic cellular automaton. This\nallows us to rigorously identify self-replicating structures via explicit\ncausal lineages. Our results show definitively that self-replicators in the\nOutlier CA are not only spontaneous and robust, but are also often composed of\nmultiple disjoint clusters working in coordination, raising questions about\nsome conventional notions of individuality and replication in artificial life\nsystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u5f62\u5f0f\u5316\u56e0\u679c\u8bc1\u636e\uff0c\u8868\u660e\u7ec6\u80de\u81ea\u52a8\u673a\u4e2d\u81ea\u53d1\u81ea\u6211\u590d\u5236\u53ef\u81ea\u7136\u51fa\u73b0\u4e14\u4e3a\u5206\u5e03\u5f0f\u591a\u7ec4\u4ef6\u5f62\u5f0f\uff0c\u8fd8\u4ecb\u7ecd\u6846\u67b6\u8bc6\u522b\u81ea\u590d\u5236\u7ed3\u6784\u3002", "motivation": "\u957f\u671f\u4ee5\u6765\u7ec6\u80de\u81ea\u52a8\u673a\u4e2d\u81ea\u53d1\u81ea\u6211\u590d\u5236\u88ab\u8ba4\u4e3a\u7f55\u89c1\uff0c\u5df2\u77e5\u4f8b\u5b50\u591a\u9700\u7cbe\u5fc3\u8bbe\u8ba1\u6216\u4eba\u5de5\u521d\u59cb\u5316\uff0c\u672c\u6587\u65e8\u5728\u8bc1\u660e\u5176\u53ef\u81ea\u7136\u51fa\u73b0\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u5bf9Outlier\u89c4\u5219\u4e2d\u590d\u6742\u52a8\u529b\u5b66\u7684\u7814\u7a76\uff0c\u5f15\u5165\u6570\u636e\u9a71\u52a8\u6846\u67b6\u91cd\u5efa\u786e\u5b9a\u6027\u7ec6\u80de\u81ea\u52a8\u673a\u4e2d\u6a21\u5f0f\u7684\u5b8c\u6574\u56e0\u679c\u8c31\u7cfb\u3002", "result": "\u660e\u786e\u8868\u660eOutlier CA\u4e2d\u7684\u81ea\u590d\u5236\u4f53\u4e0d\u4ec5\u662f\u81ea\u53d1\u4e14\u7a33\u5065\u7684\uff0c\u8fd8\u5e38\u7531\u591a\u4e2a\u4e0d\u76f8\u4ea4\u7684\u96c6\u7fa4\u534f\u540c\u7ec4\u6210\u3002", "conclusion": "\u8fd9\u5bf9\u4eba\u5de5\u751f\u547d\u7cfb\u7edf\u4e2d\u4e00\u4e9b\u5173\u4e8e\u4e2a\u4f53\u6027\u548c\u590d\u5236\u7684\u4f20\u7edf\u6982\u5ff5\u63d0\u51fa\u4e86\u8d28\u7591\u3002"}}
{"id": "2508.08095", "pdf": "https://arxiv.org/pdf/2508.08095", "abs": "https://arxiv.org/abs/2508.08095", "authors": ["Chun Wang", "Chenyang Liu", "Wenze Xu", "Weihong Deng"], "title": "Dual Information Speech Language Models for Emotional Conversations", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": "Presented at IEEE ICME 2025", "summary": "Conversational systems relying on text-based large language models (LLMs)\noften overlook paralinguistic cues, essential for understanding emotions and\nintentions. Speech-language models (SLMs), which use speech as input, are\nemerging as a promising solution. However, SLMs built by extending frozen LLMs\nstruggle to capture paralinguistic information and exhibit reduced context\nunderstanding. We identify entangled information and improper training\nstrategies as key issues. To address these issues, we propose two heterogeneous\nadapters and suggest a weakly supervised training strategy. Our approach\ndisentangles paralinguistic and linguistic information, enabling SLMs to\ninterpret speech through structured representations. It also preserves\ncontextual understanding by avoiding the generation of task-specific vectors\nthrough controlled randomness. This approach trains only the adapters on common\ndatasets, ensuring parameter and data efficiency. Experiments demonstrate\ncompetitive performance in emotional conversation tasks, showcasing the model's\nability to effectively integrate both paralinguistic and linguistic information\nwithin contextual settings.", "AI": {"tldr": "\u4f20\u7edf\u57fa\u4e8e\u6587\u672c\u7684\u5bf9\u8bdd\u7cfb\u7edf\u5ffd\u7565\u526f\u8bed\u8a00\u7ebf\u7d22\uff0c\u6269\u5c55\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u6709\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e24\u4e2a\u5f02\u6784\u9002\u914d\u5668\u548c\u5f31\u76d1\u7763\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u60c5\u611f\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6587\u672c\u7684\u5bf9\u8bdd\u7cfb\u7edf\u5ffd\u7565\u526f\u8bed\u8a00\u7ebf\u7d22\uff0c\u800c\u6269\u5c55\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u6355\u6349\u526f\u8bed\u8a00\u4fe1\u606f\u4e14\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u5f02\u6784\u9002\u914d\u5668\uff0c\u91c7\u7528\u5f31\u76d1\u7763\u8bad\u7ec3\u7b56\u7565\uff0c\u89e3\u8026\u526f\u8bed\u8a00\u548c\u8bed\u8a00\u4fe1\u606f\uff0c\u901a\u8fc7\u63a7\u5236\u968f\u673a\u6027\u907f\u514d\u751f\u6210\u7279\u5b9a\u4efb\u52a1\u5411\u91cf\u3002", "result": "\u5728\u60c5\u611f\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u80fd\u5728\u4e0a\u4e0b\u6587\u73af\u5883\u4e2d\u6709\u6548\u6574\u5408\u526f\u8bed\u8a00\u548c\u8bed\u8a00\u4fe1\u606f\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u53ef\u4f7f\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u6709\u6548\u6574\u5408\u526f\u8bed\u8a00\u548c\u8bed\u8a00\u4fe1\u606f\uff0c\u4e14\u5177\u6709\u53c2\u6570\u548c\u6570\u636e\u6548\u7387\u3002"}}
{"id": "2508.08107", "pdf": "https://arxiv.org/pdf/2508.08107", "abs": "https://arxiv.org/abs/2508.08107", "authors": ["Danfeng Hong", "Chenyu Li", "Naoto Yokoya", "Bing Zhang", "Xiuping Jia", "Antonio Plaza", "Paolo Gamba", "Jon Atli Benediktsson", "Jocelyn Chanussot"], "title": "Hyperspectral Imaging", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Hyperspectral imaging (HSI) is an advanced sensing modality that\nsimultaneously captures spatial and spectral information, enabling\nnon-invasive, label-free analysis of material, chemical, and biological\nproperties. This Primer presents a comprehensive overview of HSI, from the\nunderlying physical principles and sensor architectures to key steps in data\nacquisition, calibration, and correction. We summarize common data structures\nand highlight classical and modern analysis methods, including dimensionality\nreduction, classification, spectral unmixing, and AI-driven techniques such as\ndeep learning. Representative applications across Earth observation, precision\nagriculture, biomedicine, industrial inspection, cultural heritage, and\nsecurity are also discussed, emphasizing HSI's ability to uncover sub-visual\nfeatures for advanced monitoring, diagnostics, and decision-making. Persistent\nchallenges, such as hardware trade-offs, acquisition variability, and the\ncomplexity of high-dimensional data, are examined alongside emerging solutions,\nincluding computational imaging, physics-informed modeling, cross-modal fusion,\nand self-supervised learning. Best practices for dataset sharing,\nreproducibility, and metadata documentation are further highlighted to support\ntransparency and reuse. Looking ahead, we explore future directions toward\nscalable, real-time, and embedded HSI systems, driven by sensor\nminiaturization, self-supervised learning, and foundation models. As HSI\nevolves into a general-purpose, cross-disciplinary platform, it holds promise\nfor transformative applications in science, technology, and society.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u4ecb\u7ecd\u9ad8\u5149\u8c31\u6210\u50cf\uff08HSI\uff09\uff0c\u6db5\u76d6\u539f\u7406\u3001\u65b9\u6cd5\u3001\u5e94\u7528\u3001\u6311\u6218\u3001\u89e3\u51b3\u65b9\u6848\u53ca\u672a\u6765\u65b9\u5411\uff0c\u6307\u51fa\u5176\u6709\u671b\u6210\u4e3a\u8de8\u5b66\u79d1\u5e73\u53f0\u3002", "motivation": "\u4ecb\u7ecd\u9ad8\u5149\u8c31\u6210\u50cf\uff0c\u63a8\u52a8\u5176\u5728\u591a\u9886\u57df\u5e94\u7528\u548c\u53d1\u5c55\u3002", "method": "\u6982\u8ff0\u7269\u7406\u539f\u7406\u3001\u4f20\u611f\u5668\u67b6\u6784\uff0c\u603b\u7ed3\u6570\u636e\u7ed3\u6784\u548c\u5206\u6790\u65b9\u6cd5\uff0c\u8ba8\u8bba\u5e94\u7528\u3001\u6311\u6218\u53ca\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u660e\u786eHSI\u80fd\u63ed\u793a\u4e9a\u89c6\u89c9\u7279\u5f81\u7528\u4e8e\u76d1\u6d4b\u7b49\uff0c\u63d0\u51fa\u65b0\u5174\u89e3\u51b3\u65b9\u6848\u548c\u6700\u4f73\u5b9e\u8df5\u3002", "conclusion": "HSI\u6709\u671b\u53d1\u5c55\u4e3a\u901a\u7528\u8de8\u5b66\u79d1\u5e73\u53f0\uff0c\u5728\u591a\u9886\u57df\u6709\u53d8\u9769\u6027\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2508.08117", "pdf": "https://arxiv.org/pdf/2508.08117", "abs": "https://arxiv.org/abs/2508.08117", "authors": ["Xudong Han", "Pengcheng Fang", "Yueying Tian", "Jianhui Yu", "Xiaohao Cai", "Daniel Roggen", "Philip Birch"], "title": "GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multi-object tracking (MOT) in monocular videos is fundamentally challenged\nby occlusions and depth ambiguity, issues that conventional\ntracking-by-detection (TBD) methods struggle to resolve owing to a lack of\ngeometric awareness. To address these limitations, we introduce GRASPTrack, a\nnovel depth-aware MOT framework that integrates monocular depth estimation and\ninstance segmentation into a standard TBD pipeline to generate high-fidelity 3D\npoint clouds from 2D detections, thereby enabling explicit 3D geometric\nreasoning. These 3D point clouds are then voxelized to enable a precise and\nrobust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To\nfurther enhance tracking robustness, our approach incorporates Depth-aware\nAdaptive Noise Compensation, which dynamically adjusts the Kalman filter\nprocess noise based on occlusion severity for more reliable state estimation.\nAdditionally, we propose a Depth-enhanced Observation-Centric Momentum, which\nextends the motion direction consistency from the image plane into 3D space to\nimprove motion-based association cues, particularly for objects with complex\ntrajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack\nbenchmarks demonstrate that our method achieves competitive performance,\nsignificantly improving tracking robustness in complex scenes with frequent\nocclusions and intricate motion patterns.", "AI": {"tldr": "\u63d0\u51faGRASPTrack\u6846\u67b6\u89e3\u51b3\u5355\u76ee\u89c6\u9891\u591a\u76ee\u6807\u8ddf\u8e2a\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u590d\u6742\u573a\u666f\u6548\u679c\u597d\u3002", "motivation": "\u4f20\u7edfTBD\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u51e0\u4f55\u611f\u77e5\uff0c\u96be\u4ee5\u89e3\u51b3\u5355\u76ee\u89c6\u9891\u591a\u76ee\u6807\u8ddf\u8e2a\u4e2d\u7684\u906e\u6321\u548c\u6df1\u5ea6\u6a21\u7cca\u95ee\u9898\u3002", "method": "\u5c06\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u548c\u5b9e\u4f8b\u5206\u5272\u96c6\u6210\u5230TBD\u6d41\u7a0b\u751f\u62103D\u70b9\u4e91\uff0c\u8fdb\u884c\u4f53\u7d20\u5316\u7528\u4e8e\u7a7a\u95f4\u5173\u8054\uff1b\u91c7\u7528\u6df1\u5ea6\u81ea\u9002\u5e94\u566a\u58f0\u8865\u507f\u548c\u6df1\u5ea6\u589e\u5f3a\u89c2\u6d4b\u4e2d\u5fc3\u52a8\u91cf\u3002", "result": "\u5728MOT17\u3001MOT20\u548cDanceTrack\u57fa\u51c6\u4e0a\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u573a\u666f\u4e0b\u7684\u8ddf\u8e2a\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.08131", "pdf": "https://arxiv.org/pdf/2508.08131", "abs": "https://arxiv.org/abs/2508.08131", "authors": ["Wenze Xu", "Chun Wang", "Jiazhen Yu", "Sheng Chen", "Liang Gao", "Weihong Deng"], "title": "Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "To be presented at ACPR 2025 Conference", "summary": "Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to\nperceive speech inputs, have gained increasing attention for their potential to\nadvance speech understanding tasks. However, despite recent progress, studies\nshow that SLMs often struggle to generalize across datasets, even for trained\nlanguages and tasks, raising concerns about whether they process speech in a\ntext-like manner as intended. A key challenge underlying this limitation is the\nmodality gap between speech and text representations. The high variability in\nspeech embeddings may allow SLMs to achieve strong in-domain performance by\nexploiting unintended speech variations, ultimately hindering generalization.\nTo mitigate this modality gap, we introduce Optimal Transport Regularization\n(OTReg), a method that formulates speech-text alignment as an optimal transport\nproblem and derives a regularization loss to improve SLM training. In each\ntraining iteration, OTReg first establishes a structured correspondence between\nspeech and transcript embeddings by determining the optimal transport plan,\nthen incorporates the regularization loss based on this transport plan to\noptimize SLMs in generating speech embeddings that align more effectively with\ntranscript embeddings. OTReg is lightweight, requiring no additional labels or\nlearnable parameters, and integrates seamlessly into existing SLM training\nprocedures. Extensive multilingual ASR experiments demonstrate that OTReg\nenhances speech-text alignment, mitigates the modality gap, and consequently\nimproves SLM generalization across diverse datasets.", "AI": {"tldr": "\u672c\u6587\u6307\u51faSLMs\u5728\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u4e0a\u6709\u95ee\u9898\uff0c\u539f\u56e0\u662f\u8bed\u97f3\u548c\u6587\u672c\u8868\u5f81\u7684\u6a21\u6001\u5dee\u8ddd\uff0c\u63d0\u51faOTReg\u65b9\u6cd5\u7f13\u89e3\u6b64\u5dee\u8ddd\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524dSLMs\u5728\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u5b58\u5728\u56f0\u96be\uff0c\u539f\u56e0\u662f\u8bed\u97f3\u548c\u6587\u672c\u8868\u5f81\u7684\u6a21\u6001\u5dee\u8ddd\uff0c\u9700\u8981\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5f15\u5165OTReg\u65b9\u6cd5\uff0c\u5c06\u8bed\u97f3 - \u6587\u672c\u5bf9\u9f50\u8868\u8ff0\u4e3a\u6700\u4f18\u4f20\u8f93\u95ee\u9898\uff0c\u901a\u8fc7\u786e\u5b9a\u6700\u4f18\u4f20\u8f93\u8ba1\u5212\u5efa\u7acb\u5bf9\u5e94\u5173\u7cfb\uff0c\u5f15\u5165\u6b63\u5219\u5316\u635f\u5931\u4f18\u5316SLM\u8bad\u7ec3\u3002", "result": "\u5e7f\u6cdb\u7684\u591a\u8bed\u8a00ASR\u5b9e\u9a8c\u8868\u660e\uff0cOTReg\u589e\u5f3a\u4e86\u8bed\u97f3 - \u6587\u672c\u5bf9\u9f50\uff0c\u7f13\u89e3\u4e86\u6a21\u6001\u5dee\u8ddd\u3002", "conclusion": "OTReg\u80fd\u6709\u6548\u7f13\u89e3\u6a21\u6001\u5dee\u8ddd\uff0c\u63d0\u5347SLM\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.08139", "pdf": "https://arxiv.org/pdf/2508.08139", "abs": "https://arxiv.org/abs/2508.08139", "authors": ["Tianyi Zhou", "Johanne Medina", "Sanjay Chawla"], "title": "Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are prone to generating fluent but incorrect\ncontent, known as confabulation, which poses increasing risks in multi-turn or\nagentic applications where outputs may be reused as context. In this work, we\ninvestigate how in-context information influences model behavior and whether\nLLMs can identify their unreliable responses. We propose a reliability\nestimation that leverages token-level uncertainty to guide the aggregation of\ninternal model representations. Specifically, we compute aleatoric and\nepistemic uncertainty from output logits to identify salient tokens and\naggregate their hidden states into compact representations for response-level\nreliability prediction. Through controlled experiments on open QA benchmarks,\nwe find that correct in-context information improves both answer accuracy and\nmodel confidence, while misleading context often induces confidently incorrect\nresponses, revealing a misalignment between uncertainty and correctness. Our\nprobing-based method captures these shifts in model behavior and improves the\ndetection of unreliable outputs across multiple open-source LLMs. These results\nunderscore the limitations of direct uncertainty signals and highlight the\npotential of uncertainty-guided probing for reliability-aware generation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\u53ca\u6a21\u578b\u80fd\u5426\u8bc6\u522b\u4e0d\u53ef\u9760\u54cd\u5e94\uff0c\u63d0\u51fa\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u53ef\u9760\u6027\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u4e0d\u53ef\u9760\u8f93\u51fa\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6613\u751f\u6210\u9519\u8bef\u5185\u5bb9\uff0c\u5728\u591a\u8f6e\u6216\u667a\u80fd\u4f53\u5e94\u7528\u4e2d\u98ce\u9669\u589e\u5927\uff0c\u9700\u7814\u7a76\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\u53ca\u6a21\u578b\u8bc6\u522b\u4e0d\u53ef\u9760\u54cd\u5e94\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u53ef\u9760\u6027\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528\u4ee4\u724c\u7ea7\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u5185\u90e8\u6a21\u578b\u8868\u793a\u7684\u805a\u5408\uff0c\u901a\u8fc7\u8f93\u51fa\u5bf9\u6570\u8ba1\u7b97\u4e0d\u786e\u5b9a\u6027\u6765\u8bc6\u522b\u663e\u8457\u4ee4\u724c\u5e76\u805a\u5408\u5176\u9690\u85cf\u72b6\u6001\u8fdb\u884c\u54cd\u5e94\u7ea7\u53ef\u9760\u6027\u9884\u6d4b\u3002", "result": "\u6b63\u786e\u4e0a\u4e0b\u6587\u4fe1\u606f\u63d0\u9ad8\u7b54\u6848\u51c6\u786e\u6027\u548c\u6a21\u578b\u4fe1\u5fc3\uff0c\u8bef\u5bfc\u6027\u4e0a\u4e0b\u6587\u5bfc\u81f4\u81ea\u4fe1\u7684\u9519\u8bef\u54cd\u5e94\uff0c\u57fa\u4e8e\u63a2\u6d4b\u7684\u65b9\u6cd5\u80fd\u6355\u6349\u6a21\u578b\u884c\u4e3a\u53d8\u5316\uff0c\u63d0\u5347\u591a\u5f00\u6e90\u6a21\u578b\u4e0d\u53ef\u9760\u8f93\u51fa\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u76f4\u63a5\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\u6709\u5c40\u9650\uff0c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u63a2\u6d4b\u5bf9\u53ef\u9760\u6027\u611f\u77e5\u751f\u6210\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.08144", "pdf": "https://arxiv.org/pdf/2508.08144", "abs": "https://arxiv.org/abs/2508.08144", "authors": ["Ganesh Sundaram", "Jonas Ulmen", "Amjad Haider", "Daniel G\u00f6rges"], "title": "COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "Submitted in: The 2026 IEEE/SICE International Symposium on System\n  Integration (SII 2026)", "summary": "The rapid growth of resource-constrained mobile platforms, including mobile\nrobots, wearable systems, and Internet-of-Things devices, has increased the\ndemand for computationally efficient neural network controllers (NNCs) that can\noperate within strict hardware limitations. While deep neural networks (DNNs)\ndemonstrate superior performance in control applications, their substantial\ncomputational complexity and memory requirements present significant barriers\nto practical deployment on edge devices. This paper introduces a comprehensive\nmodel compression methodology that leverages component-aware structured pruning\nto determine the optimal pruning magnitude for each pruning group, ensuring a\nbalance between compression and stability for NNC deployment. Our approach is\nrigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC),\na state-of-the-art model-based reinforcement learning algorithm, with a\nsystematic integration of mathematical stability guarantee properties,\nspecifically Lyapunov criteria. The key contribution of this work lies in\nproviding a principled framework for determining the theoretical limits of\nmodel compression while preserving controller stability. Experimental\nvalidation demonstrates that our methodology successfully reduces model\ncomplexity while maintaining requisite control performance and stability\ncharacteristics. Furthermore, our approach establishes a quantitative boundary\nfor safe compression ratios, enabling practitioners to systematically determine\nthe maximum permissible model reduction before violating critical stability\nproperties, thereby facilitating the confident deployment of compressed NNCs in\nresource-limited environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\uff0c\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u79fb\u52a8\u5e73\u53f0\u7684\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\uff0c\u5728TD - MPC\u7b97\u6cd5\u4e0a\u9a8c\u8bc1\u53ef\u964d\u4f4e\u590d\u6742\u5ea6\u5e76\u4fdd\u6301\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u8fd8\u786e\u5b9a\u5b89\u5168\u538b\u7f29\u6bd4\u8fb9\u754c\u3002", "motivation": "\u8d44\u6e90\u53d7\u9650\u79fb\u52a8\u5e73\u53f0\u5bf9\u9ad8\u6548\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u9700\u6c42\u589e\u52a0\uff0c\u4f46DNN\u8ba1\u7b97\u590d\u6742\u548c\u5185\u5b58\u9700\u6c42\u5927\u9650\u5236\u5176\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "method": "\u5229\u7528\u7ec4\u4ef6\u611f\u77e5\u7ed3\u6784\u5316\u526a\u679d\u786e\u5b9a\u6bcf\u4e2a\u526a\u679d\u7ec4\u7684\u6700\u4f18\u526a\u679d\u5e45\u5ea6\uff0c\u7ed3\u5408TD - MPC\u7b97\u6cd5\u5e76\u96c6\u6210Lyapunov\u51c6\u5219\u3002", "result": "\u6210\u529f\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u4fdd\u6301\u63a7\u5236\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u786e\u5b9a\u5b89\u5168\u538b\u7f29\u6bd4\u8fb9\u754c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6a21\u578b\u538b\u7f29\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\uff0c\u53ef\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b89\u5168\u90e8\u7f72\u538b\u7f29\u540e\u7684\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u3002"}}
{"id": "2508.08158", "pdf": "https://arxiv.org/pdf/2508.08158", "abs": "https://arxiv.org/abs/2508.08158", "authors": ["Laura Spillner", "Rachel Ringe", "Robert Porzel", "Rainer Malaka"], "title": "Can AI Explanations Make You Change Your Mind?", "categories": ["cs.HC", "cs.AI"], "comment": "This paper was presented at the Explainable AI workshop at IJCAI\n  2025: https://sites.google.com/view/xai2025/proceedings", "summary": "In the context of AI-based decision support systems, explanations can help\nusers to judge when to trust the AI's suggestion, and when to question it. In\nthis way, human oversight can prevent AI errors and biased decision-making.\nHowever, this rests on the assumption that users will consider explanations in\nenough detail to be able to catch such errors. We conducted an online study on\ntrust in explainable DSS, and were surprised to find that in many cases,\nparticipants spent little time on the explanation and did not always consider\nit in detail. We present an exploratory analysis of this data, investigating\nwhat factors impact how carefully study participants consider AI explanations,\nand how this in turn impacts whether they are open to changing their mind based\non what the AI suggests.", "AI": {"tldr": "\u5728\u7ebf\u7814\u7a76\u53d1\u73b0\u7528\u6237\u5bf9\u53ef\u89e3\u91ca\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u89e3\u91ca\u5173\u6ce8\u4e0d\u8db3\uff0c\u6587\u7ae0\u63a2\u7d22\u5f71\u54cd\u7528\u6237\u8003\u91cf\u89e3\u91ca\u7684\u56e0\u7d20\u53ca\u5bf9\u6539\u53d8\u60f3\u6cd5\u7684\u5f71\u54cd\u3002", "motivation": "\u5728\u57fa\u4e8eAI\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\uff0c\u867d\u89e3\u91ca\u80fd\u52a9\u7528\u6237\u5224\u65ad\u5bf9AI\u5efa\u8bae\u7684\u4fe1\u4efb\uff0c\u4f46\u524d\u63d0\u662f\u7528\u6237\u4f1a\u4ed4\u7ec6\u8003\u91cf\u89e3\u91ca\uff0c\u9700\u7814\u7a76\u7528\u6237\u662f\u5426\u771f\u4f1a\u5982\u6b64\u3002", "method": "\u5f00\u5c55\u5173\u4e8e\u53ef\u89e3\u91ca\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4fe1\u4efb\u7684\u5728\u7ebf\u7814\u7a76\uff0c\u5e76\u5bf9\u6570\u636e\u8fdb\u884c\u63a2\u7d22\u6027\u5206\u6790\u3002", "result": "\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u53c2\u4e0e\u8005\u82b1\u5728\u89e3\u91ca\u4e0a\u7684\u65f6\u95f4\u5c11\uff0c\u5e76\u4e0d\u603b\u662f\u8be6\u7ec6\u8003\u91cf\u3002", "conclusion": "\u6587\u7ae0\u63a2\u7d22\u5f71\u54cd\u53c2\u4e0e\u8005\u8003\u91cfAI\u89e3\u91ca\u7684\u56e0\u7d20\uff0c\u4ee5\u53ca\u8fd9\u5bf9\u4ed6\u4eec\u662f\u5426\u63a5\u53d7AI\u5efa\u8bae\u7684\u5f71\u54cd\u3002"}}
{"id": "2508.08177", "pdf": "https://arxiv.org/pdf/2508.08177", "abs": "https://arxiv.org/abs/2508.08177", "authors": ["Zhonghao Yan", "Muxi Diao", "Yuxuan Yang", "Jiayuan Xu", "Kaizhou Zhang", "Ruoyan Jing", "Lele Yang", "Yanxi Liu", "Kongming Liang", "Zhanyu Ma"], "title": "MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision", "categories": ["cs.CV", "cs.AI"], "comment": "37 pages", "summary": "Accurately grounding regions of interest (ROIs) is critical for diagnosis and\ntreatment planning in medical imaging. While multimodal large language models\n(MLLMs) combine visual perception with natural language, current\nmedical-grounding pipelines still rely on supervised fine-tuning with explicit\nspatial hints, making them ill-equipped to handle the implicit queries common\nin clinical practice. This work makes three core contributions. We first define\nUnified Medical Reasoning Grounding (UMRG), a novel vision-language task that\ndemands clinical reasoning and pixel-level grounding. Second, we release\nU-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside\nimplicit clinical queries and reasoning traces, spanning 10 modalities, 15\nsuper-categories, and 108 specific categories. Finally, we introduce\nMedReasoner, a modular framework that distinctly separates reasoning from\nsegmentation: an MLLM reasoner is optimized with reinforcement learning, while\na frozen segmentation expert converts spatial prompts into masks, with\nalignment achieved through format and accuracy rewards. MedReasoner achieves\nstate-of-the-art performance on U-MRG-14K and demonstrates strong\ngeneralization to unseen clinical queries, underscoring the significant promise\nof reinforcement learning for interpretable medical grounding.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u533b\u5b66\u63a8\u7406\u5b9a\u4f4d\u4efb\u52a1UMRG\uff0c\u53d1\u5e03U - MRG - 14K\u6570\u636e\u96c6\uff0c\u4ecb\u7ecdMedReasoner\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u533b\u5b66\u5b9a\u4f4d\u6d41\u7a0b\u4f9d\u8d56\u5e26\u660e\u786e\u7a7a\u95f4\u63d0\u793a\u7684\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u96be\u4ee5\u5904\u7406\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u9690\u5f0f\u67e5\u8be2\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u5b9a\u4e49UMRG\u4efb\u52a1\uff0c\u53d1\u5e03U - MRG - 14K\u6570\u636e\u96c6\uff0c\u5f15\u5165MedReasoner\u6846\u67b6\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316MLLM\u63a8\u7406\u5668\uff0c\u7528\u51bb\u7ed3\u7684\u5206\u5272\u4e13\u5bb6\u5c06\u7a7a\u95f4\u63d0\u793a\u8f6c\u6362\u4e3a\u63a9\u7801\uff0c\u5e76\u901a\u8fc7\u683c\u5f0f\u548c\u51c6\u786e\u6027\u5956\u52b1\u5b9e\u73b0\u5bf9\u9f50\u3002", "result": "MedReasoner\u5728U - MRG - 14K\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5bf9\u672a\u89c1\u4e34\u5e8a\u67e5\u8be2\u6709\u5f88\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5728\u53ef\u89e3\u91ca\u533b\u5b66\u5b9a\u4f4d\u65b9\u9762\u6709\u663e\u8457\u524d\u666f\u3002"}}
{"id": "2508.08180", "pdf": "https://arxiv.org/pdf/2508.08180", "abs": "https://arxiv.org/abs/2508.08180", "authors": ["Luca Zedda", "Andrea Loddo", "Cecilia Di Ruberto", "Carsten Marr"], "title": "RedDino: A foundation model for red blood cell analysis", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Red blood cells (RBCs) are essential to human health, and their precise\nmorphological analysis is important for diagnosing hematological disorders.\nDespite the promise of foundation models in medical diagnostics, comprehensive\nAI solutions for RBC analysis remain scarce. We present RedDino, a\nself-supervised foundation model designed for RBC image analysis. RedDino uses\nan RBC-specific adaptation of the DINOv2 self-supervised learning framework and\nis trained on a curated dataset of 1.25 million RBC images from diverse\nacquisition modalities and sources. Extensive evaluations show that RedDino\noutperforms existing state-of-the-art models on RBC shape classification.\nThrough assessments including linear probing and nearest neighbor\nclassification, we confirm its strong feature representations and\ngeneralization ability. Our main contributions are: (1) a foundation model\ntailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations\nfor RBC modeling, and (3) a detailed evaluation of generalization performance.\nRedDino addresses key challenges in computational hematology by capturing\nnuanced morphological features, advancing the development of reliable\ndiagnostic tools. The source code and pretrained models for RedDino are\navailable at https://github.com/Snarci/RedDino, and the pretrained models can\nbe downloaded from our Hugging Face collection at\nhttps://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u7ea2\u7ec6\u80de\u56fe\u50cf\u5206\u6790\u7684\u81ea\u76d1\u7763\u57fa\u7840\u6a21\u578bRedDino\uff0c\u5728\u5f62\u72b6\u5206\u7c7b\u4e0a\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u6709\u4ee3\u7801\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u5f00\u6e90\u3002", "motivation": "\u7ea2\u7ec6\u80de\u5f62\u6001\u5206\u6790\u5bf9\u8bca\u65ad\u8840\u6db2\u75be\u75c5\u91cd\u8981\uff0c\u4f46\u5168\u9762\u7684AI\u89e3\u51b3\u65b9\u6848\u7a00\u7f3a\u3002", "method": "\u91c7\u7528DINOv2\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u7684\u7ea2\u7ec6\u80de\u7279\u5b9a\u9002\u5e94\u7248\u672c\uff0c\u5728125\u4e07\u5f20\u6765\u81ea\u4e0d\u540c\u6765\u6e90\u7684\u7ea2\u7ec6\u80de\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u3002", "result": "RedDino\u5728\u7ea2\u7ec6\u80de\u5f62\u72b6\u5206\u7c7b\u4e0a\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u6709\u5f3a\u7279\u5f81\u8868\u793a\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RedDino\u89e3\u51b3\u4e86\u8ba1\u7b97\u8840\u6db2\u5b66\u5173\u952e\u6311\u6218\uff0c\u63a8\u52a8\u53ef\u9760\u8bca\u65ad\u5de5\u5177\u53d1\u5c55\u3002"}}
{"id": "2508.08193", "pdf": "https://arxiv.org/pdf/2508.08193", "abs": "https://arxiv.org/abs/2508.08193", "authors": ["Gaurab Pokharel", "Shafkat Farabi", "Patrick J. Fowler", "Sanmay Das"], "title": "Street-Level AI: Are Large Language Models Ready for Real-World Judgments?", "categories": ["cs.CY", "cs.AI"], "comment": "This work has been accepted for publication as a full paper at the\n  AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)", "summary": "A surge of recent work explores the ethical and societal implications of\nlarge-scale AI models that make \"moral\" judgments. Much of this literature\nfocuses either on alignment with human judgments through various thought\nexperiments or on the group fairness implications of AI judgments. However, the\nmost immediate and likely use of AI is to help or fully replace the so-called\nstreet-level bureaucrats, the individuals deciding to allocate scarce social\nresources or approve benefits. There is a rich history underlying how\nprinciples of local justice determine how society decides on prioritization\nmechanisms in such domains. In this paper, we examine how well LLM judgments\nalign with human judgments, as well as with socially and politically determined\nvulnerability scoring systems currently used in the domain of homelessness\nresource allocation. Crucially, we use real data on those needing services\n(maintaining strict confidentiality by only using local large models) to\nperform our analyses. We find that LLM prioritizations are extremely\ninconsistent in several ways: internally on different runs, between different\nLLMs, and between LLMs and the vulnerability scoring systems. At the same time,\nLLMs demonstrate qualitative consistency with lay human judgments in pairwise\ntesting. Findings call into question the readiness of current generation AI\nsystems for naive integration in high-stakes societal decision-making.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u65e0\u5bb6\u53ef\u5f52\u8d44\u6e90\u5206\u914d\u4e2d\u7684\u5224\u65ad\uff0c\u53d1\u73b0LLM\u4f18\u5148\u7ea7\u6392\u5e8f\u4e0d\u4e00\u81f4\uff0c\u867d\u4e0e\u4eba\u7c7b\u5224\u65ad\u6709\u5b9a\u6027\u4e00\u81f4\u6027\uff0c\u4f46\u8d28\u7591\u5176\u7528\u4e8e\u9ad8\u98ce\u9669\u793e\u4f1a\u51b3\u7b56\u7684\u5c31\u7eea\u6027\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u591a\u5173\u6ce8AI\u9053\u5fb7\u5224\u65ad\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u6216\u7fa4\u4f53\u516c\u5e73\u6027\uff0c\u800cAI\u6700\u53ef\u80fd\u7528\u4e8e\u66ff\u4ee3\u57fa\u5c42\u5b98\u50da\u5206\u914d\u7a00\u7f3a\u793e\u4f1a\u8d44\u6e90\uff0c\u6545\u7814\u7a76LLM\u5224\u65ad\u4e0e\u4eba\u7c7b\u5224\u65ad\u53ca\u8106\u5f31\u6027\u8bc4\u5206\u7cfb\u7edf\u7684\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528\u9700\u8981\u670d\u52a1\u7684\u771f\u5b9e\u6570\u636e\uff08\u4ec5\u4f7f\u7528\u672c\u5730\u5927\u6a21\u578b\u4ee5\u4fdd\u62a4\u9690\u79c1\uff09\uff0c\u5206\u6790LLM\u5224\u65ad\u4e0e\u4eba\u7c7b\u5224\u65ad\u53ca\u8106\u5f31\u6027\u8bc4\u5206\u7cfb\u7edf\u7684\u4e00\u81f4\u6027\u3002", "result": "LLM\u4f18\u5148\u7ea7\u6392\u5e8f\u5728\u591a\u65b9\u9762\u6781\u4e0d\u4e00\u81f4\uff0c\u5305\u62ec\u4e0d\u540c\u8fd0\u884c\u3001\u4e0d\u540cLLM\u4e4b\u95f4\u4ee5\u53caLLM\u4e0e\u8106\u5f31\u6027\u8bc4\u5206\u7cfb\u7edf\u4e4b\u95f4\uff1b\u540c\u65f6\uff0cLLM\u5728\u6210\u5bf9\u6d4b\u8bd5\u4e2d\u4e0e\u666e\u901a\u4eba\u7c7b\u5224\u65ad\u6709\u5b9a\u6027\u4e00\u81f4\u6027\u3002", "conclusion": "\u5f53\u524d\u4e00\u4ee3AI\u7cfb\u7edf\u5c1a\u4e0d\u9002\u5408\u7b80\u5355\u96c6\u6210\u5230\u9ad8\u98ce\u9669\u793e\u4f1a\u51b3\u7b56\u4e2d\u3002"}}
{"id": "2508.08204", "pdf": "https://arxiv.org/pdf/2508.08204", "abs": "https://arxiv.org/abs/2508.08204", "authors": ["Kyle Moore", "Jesse Roberts", "Daryl Watson"], "title": "Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "preprint, under review", "summary": "There has been much recent interest in evaluating large language models for\nuncertainty calibration to facilitate model control and modulate user trust.\nInference time uncertainty, which may provide a real-time signal to the model\nor external control modules, is particularly important for applying these\nconcepts to improve LLM-user experience in practice. While many of the existing\npapers consider model calibration, comparatively little work has sought to\nevaluate how closely model uncertainty aligns to human uncertainty. In this\nwork, we evaluate a collection of inference-time uncertainty measures, using\nboth established metrics and novel variations, to determine how closely they\nalign with both human group-level uncertainty and traditional notions of model\ncalibration. We find that numerous measures show evidence of strong alignment\nto human uncertainty, even despite the lack of alignment to human answer\npreference. For those successful metrics, we find moderate to strong evidence\nof model calibration in terms of both correctness correlation and\ndistributional analysis.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u4e0e\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u548c\u6a21\u578b\u6821\u51c6\u7684\u5bf9\u9f50\u60c5\u51b5\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u8bc4\u4f30\u611f\u5174\u8da3\uff0c\u4e14\u8f83\u5c11\u5de5\u4f5c\u8bc4\u4f30\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0e\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u4e3a\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u4f7f\u7528\u65e2\u6709\u6307\u6807\u548c\u65b0\u53d8\u4f53\u8bc4\u4f30\u63a8\u7406\u65f6\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u3002", "result": "\u8bb8\u591a\u5ea6\u91cf\u4e0e\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u5f3a\u5bf9\u9f50\uff0c\u4e0e\u4eba\u7c7b\u7b54\u6848\u504f\u597d\u7f3a\u4e4f\u5bf9\u9f50\uff1b\u6210\u529f\u6307\u6807\u5728\u6b63\u786e\u6027\u76f8\u5173\u6027\u548c\u5206\u5e03\u5206\u6790\u4e0a\u6709\u4e2d\u5230\u5f3a\u7684\u6a21\u578b\u6821\u51c6\u8bc1\u636e\u3002", "conclusion": "\u90e8\u5206\u63a8\u7406\u65f6\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u5728\u4e0e\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u5bf9\u9f50\u548c\u6a21\u578b\u6821\u51c6\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2508.08224", "pdf": "https://arxiv.org/pdf/2508.08224", "abs": "https://arxiv.org/abs/2508.08224", "authors": ["Shansong Wang", "Mingzhe Hu", "Qiang Li", "Mojtaba Safari", "Xiaofeng Yang"], "title": "Capabilities of GPT-5 on Multimodal Medical Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled general-purpose\nsystems to perform increasingly complex domain-specific reasoning without\nextensive fine-tuning. In the medical domain, decision-making often requires\nintegrating heterogeneous information sources, including patient narratives,\nstructured data, and medical images. This study positions GPT-5 as a generalist\nmultimodal reasoner for medical decision support and systematically evaluates\nits zero-shot chain-of-thought reasoning performance on both text-based\nquestion answering and visual question answering tasks under a unified\nprotocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20\nagainst standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU\nmedical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that\nGPT-5 consistently outperforms all baselines, achieving state-of-the-art\naccuracy across all QA benchmarks and delivering substantial gains in\nmultimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and\nunderstanding scores by +29.62% and +36.18% over GPT-4o, respectively, and\nsurpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in\nunderstanding. In contrast, GPT-4o remains below human expert performance in\nmost dimensions. A representative case study demonstrates GPT-5's ability to\nintegrate visual and textual cues into a coherent diagnostic reasoning chain,\nrecommending appropriate high-stakes interventions. Our results show that, on\nthese controlled multimodal reasoning benchmarks, GPT-5 moves from\nhuman-comparable to above human-expert performance. This improvement may\nsubstantially inform the design of future clinical decision-support systems.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30GPT - 5\u5728\u533b\u5b66\u51b3\u7b56\u652f\u6301\u591a\u6a21\u6001\u63a8\u7406\u7684\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u63a8\u7406\u6027\u80fd\uff0c\u7ed3\u679c\u663e\u793a\u5176\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u548c\u4eba\u7c7b\u4e13\u5bb6\uff0c\u6216\u4e3a\u672a\u6765\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u4f7f\u901a\u7528\u7cfb\u7edf\u80fd\u8fdb\u884c\u590d\u6742\u9886\u57df\u63a8\u7406\uff0c\u533b\u5b66\u51b3\u7b56\u9700\u6574\u5408\u5f02\u8d28\u4fe1\u606f\u6e90\uff0c\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30GPT - 5\u4f5c\u4e3a\u901a\u7528\u591a\u6a21\u6001\u63a8\u7406\u5668\u7528\u4e8e\u533b\u5b66\u51b3\u7b56\u652f\u6301\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u534f\u8bae\uff0c\u5bf9GPT - 5\u3001GPT - 5 - mini\u3001GPT - 5 - nano\u548cGPT - 4o - 2024 - 11 - 20\u5728MedQA\u3001MedXpertQA\u7b49\u591a\u4e2a\u6807\u51c6\u5316\u6570\u636e\u96c6\u7684\u6587\u672c\u548c\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e0a\u8fdb\u884c\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u63a8\u7406\u6027\u80fd\u8bc4\u4f30\u3002", "result": "GPT - 5\u5728\u6240\u6709\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u591a\u6a21\u6001\u63a8\u7406\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u5728MedXpertQA MM\u4e0a\u63a8\u7406\u548c\u7406\u89e3\u5f97\u5206\u5927\u5e45\u63d0\u9ad8\uff0c\u8d85\u8fc7\u4eba\u7c7b\u4e13\u5bb6\u3002", "conclusion": "\u5728\u53d7\u63a7\u7684\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGPT - 5\u4ece\u4e0e\u4eba\u7c7b\u76f8\u5f53\u63d0\u5347\u5230\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u8868\u73b0\uff0c\u8fd9\u4e00\u6539\u8fdb\u6216\u4e3a\u672a\u6765\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u91cd\u8981\u4f9d\u636e\u3002"}}
{"id": "2508.08227", "pdf": "https://arxiv.org/pdf/2508.08227", "abs": "https://arxiv.org/abs/2508.08227", "authors": ["Zhiqiang Wu", "Zhaomang Sun", "Tong Zhou", "Bingtao Fu", "Ji Cong", "Yitong Dong", "Huaqi Zhang", "Xuan Tang", "Mingsong Chen", "Xian Wei"], "title": "OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM)\ngenerative models show promising potential for one-step Real-World Image\nSuper-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a\nLow-Quality (LQ) image latent distribution at the initial timestep. However, a\nfundamental gap exists between the LQ image latent distribution and the\nGaussian noisy latent distribution, limiting the effective utilization of\ngenerative priors. We observe that the noisy latent distribution at DDPM/FM\nmid-timesteps aligns more closely with the LQ image latent distribution. Based\non this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a\nuniversal framework applicable to DDPM/FM-based generative models. OMGSR\ninjects the LQ image latent distribution at a pre-computed mid-timestep,\nincorporating the proposed Latent Distribution Refinement loss to alleviate the\nlatent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to\neliminate checkerboard artifacts in image generation. Within this framework, we\ninstantiate OMGSR for DDPM/FM-based generative models with two variants:\nOMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate\nthat OMGSR-S/F achieves balanced/excellent performance across quantitative and\nqualitative metrics at 512-resolution. Notably, OMGSR-F establishes\noverwhelming dominance in all reference metrics. We further train a\n1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which\nyields excellent results, especially in the details of the image generation. We\nalso generate 2k-resolution images by the 1k-resolution OMGSR-F using our\ntwo-stage Tiled VAE & Diffusion.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8eDDPM/FM\u751f\u6210\u6a21\u578b\u7684\u901a\u7528\u6846\u67b6OMGSR\u7528\u4e8e\u5355\u6b65\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\uff0c\u5728\u4e0d\u540c\u5206\u8fa8\u7387\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5355\u6b65\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u6a21\u578b\u5728\u521d\u59cb\u65f6\u95f4\u6b65\u6ce8\u5165\u4f4e\u8d28\u91cf\u56fe\u50cf\u6f5c\u5728\u5206\u5e03\uff0c\u4e0e\u9ad8\u65af\u566a\u58f0\u6f5c\u5728\u5206\u5e03\u5b58\u5728\u5dee\u8ddd\uff0c\u9650\u5236\u751f\u6210\u5148\u9a8c\u6709\u6548\u5229\u7528\u3002", "method": "\u63d0\u51faOMGSR\u6846\u67b6\uff0c\u5728\u9884\u8ba1\u7b97\u7684\u4e2d\u95f4\u65f6\u95f4\u6b65\u6ce8\u5165\u4f4e\u8d28\u91cf\u56fe\u50cf\u6f5c\u5728\u5206\u5e03\uff0c\u5f15\u5165\u6f5c\u5728\u5206\u5e03\u7ec6\u5316\u635f\u5931\u7f13\u89e3\u5206\u5e03\u5dee\u8ddd\uff0c\u8bbe\u8ba1\u91cd\u53e0\u5206\u5757LPIPS/GAN\u635f\u5931\u6d88\u9664\u68cb\u76d8\u683c\u4f2a\u5f71\uff0c\u4e3aDDPM/FM\u6a21\u578b\u5b9e\u4f8b\u5316\u4e24\u4e2a\u53d8\u4f53\u3002", "result": "OMGSR - S/F\u5728512\u5206\u8fa8\u7387\u4e0b\u5b9a\u91cf\u548c\u5b9a\u6027\u6307\u6807\u8868\u73b0\u5e73\u8861/\u4f18\u79c0\uff0cOMGSR - F\u5728\u6240\u6709\u53c2\u8003\u6307\u6807\u5360\u4f18\uff0c1k\u5206\u8fa8\u7387\u7684OMGSR - F\u6548\u679c\u597d\uff0c\u7528\u4e24\u7ea7\u5e73\u94faVAE\u548c\u6269\u6563\u751f\u62102k\u5206\u8fa8\u7387\u56fe\u50cf\u3002", "conclusion": "OMGSR\u6846\u67b6\u6709\u6548\uff0c\u80fd\u63d0\u5347\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u7684\u6548\u679c\u3002"}}
{"id": "2508.08228", "pdf": "https://arxiv.org/pdf/2508.08228", "abs": "https://arxiv.org/abs/2508.08228", "authors": ["Sining Lu", "Guan Chen", "Nam Anh Dinh", "Itai Lang", "Ari Holtzman", "Rana Hanocka"], "title": "LL3M: Large Language 3D Modelers", "categories": ["cs.GR", "cs.AI"], "comment": "Our project page is at https://threedle.github.io/ll3m", "summary": "We present LL3M, a multi-agent system that leverages pretrained large\nlanguage models (LLMs) to generate 3D assets by writing interpretable Python\ncode in Blender. We break away from the typical generative approach that learns\nfrom a collection of 3D data. Instead, we reformulate shape generation as a\ncode-writing task, enabling greater modularity, editability, and integration\nwith artist workflows. Given a text prompt, LL3M coordinates a team of\nspecialized LLM agents to plan, retrieve, write, debug, and refine Blender\nscripts that generate and edit geometry and appearance. The generated code\nworks as a high-level, interpretable, human-readable, well-documented\nrepresentation of scenes and objects, making full use of sophisticated Blender\nconstructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse,\nunconstrained shapes, materials, and scenes. This code presents many avenues\nfor further agent and human editing and experimentation via code tweaks or\nprocedural parameters. This medium naturally enables a co-creative loop in our\nsystem: agents can automatically self-critique using code and visuals, while\niterative user instructions provide an intuitive way to refine assets. A shared\ncode context across agents enables awareness of previous attempts, and a\nretrieval-augmented generation knowledge base built from Blender API\ndocumentation, BlenderRAG, equips agents with examples, types, and functions\nempowering advanced modeling operations and code correctness. We demonstrate\nthe effectiveness of LL3M across diverse shape categories, style and material\nedits, and user-driven refinements. Our experiments showcase the power of code\nas a generative and interpretable medium for 3D asset creation. Our project\npage is at https://threedle.github.io/ll3m.", "AI": {"tldr": "\u63d0\u51faLL3M\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u7f16\u5199Blender\u4e2d\u7684Python\u4ee3\u7801\u751f\u62103D\u8d44\u4ea7\uff0c\u4ee5\u4ee3\u7801\u4e3a\u751f\u6210\u548c\u53ef\u89e3\u91ca\u5a92\u4ecb\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7a81\u7834\u4f20\u7edf\u4ece3D\u6570\u636e\u96c6\u5408\u5b66\u4e60\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u5b9e\u73b03D\u8d44\u4ea7\u751f\u6210\u7684\u66f4\u5927\u6a21\u5757\u5316\u3001\u53ef\u7f16\u8f91\u6027\u4ee5\u53ca\u4e0e\u827a\u672f\u5bb6\u5de5\u4f5c\u6d41\u7a0b\u7684\u96c6\u6210\u3002", "method": "LL3M\u534f\u8c03\u4e13\u4e1aLLM\u667a\u80fd\u4f53\u56e2\u961f\uff0c\u6839\u636e\u6587\u672c\u63d0\u793a\u89c4\u5212\u3001\u68c0\u7d22\u3001\u7f16\u5199\u3001\u8c03\u8bd5\u548c\u5b8c\u5584Blender\u811a\u672c\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u77e5\u8bc6\u5e93BlenderRAG\u8f85\u52a9\u64cd\u4f5c\u3002", "result": "\u5728\u4e0d\u540c\u5f62\u72b6\u7c7b\u522b\u3001\u98ce\u683c\u548c\u6750\u8d28\u7f16\u8f91\u4ee5\u53ca\u7528\u6237\u9a71\u52a8\u7684\u7ec6\u5316\u65b9\u9762\u5c55\u793a\u4e86LL3M\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4ee3\u7801\u4f5c\u4e3a3D\u8d44\u4ea7\u521b\u5efa\u7684\u751f\u6210\u548c\u53ef\u89e3\u91ca\u5a92\u4ecb\u5177\u6709\u5f3a\u5927\u80fd\u529b\u3002"}}
{"id": "2508.08237", "pdf": "https://arxiv.org/pdf/2508.08237", "abs": "https://arxiv.org/abs/2508.08237", "authors": ["Daniil Zverev", "Thadd\u00e4us Wiedemer", "Ameya Prabhu", "Matthias Bethge", "Wieland Brendel", "A. Sophia Koepke"], "title": "VGGSounder: Audio-Visual Evaluations for Foundation Models", "categories": ["cs.MM", "cs.AI", "cs.SD"], "comment": "Proceedings of the IEEE/CVF International Conference on Computer\n  Vision (ICCV) 2025", "summary": "The emergence of audio-visual foundation models underscores the importance of\nreliably assessing their multi-modal understanding. The VGGSounder dataset is\ncommonly used as a benchmark for evaluation audio-visual classification.\nHowever, our analysis identifies several limitations of VGGSounder, including\nincomplete labelling, partially overlapping classes, and misaligned modalities.\nThese lead to distorted evaluations of auditory and visual capabilities. To\naddress these limitations, we introduce VGGSounder, a comprehensively\nre-annotated, multi-label test set that extends VGGSound and is specifically\ndesigned to evaluate audio-visual foundation models. VGGSounder features\ndetailed modality annotations, enabling precise analyses of modality-specific\nperformance. Furthermore, we reveal model limitations by analysing performance\ndegradation when adding another input modality with our new modality confusion\nmetric.", "AI": {"tldr": "\u5206\u6790VGGSounder\u6570\u636e\u96c6\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u91cd\u65b0\u6807\u6ce8\u7684VGGSounder\u6d4b\u8bd5\u96c6\u5e76\u5f15\u5165\u65b0\u6307\u6807\u63ed\u793a\u6a21\u578b\u5c40\u9650\u3002", "motivation": "\u97f3\u9891\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u9700\u53ef\u9760\u8bc4\u4f30\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u5e38\u7528\u7684VGGSounder\u6570\u636e\u96c6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5f71\u54cd\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "method": "\u5f15\u5165\u5168\u9762\u91cd\u65b0\u6807\u6ce8\u7684\u591a\u6807\u7b7e\u6d4b\u8bd5\u96c6VGGSounder\uff0c\u6dfb\u52a0\u8be6\u7ec6\u6a21\u6001\u6ce8\u91ca\uff1b\u4f7f\u7528\u65b0\u7684\u6a21\u6001\u6df7\u6dc6\u6307\u6807\u5206\u6790\u6dfb\u52a0\u8f93\u5165\u6a21\u6001\u65f6\u7684\u6027\u80fd\u4e0b\u964d\u3002", "result": "\u63d0\u51fa\u4e86\u65b0\u7684\u6d4b\u8bd5\u96c6VGGSounder\uff0c\u80fd\u8fdb\u884c\u7cbe\u786e\u7684\u6a21\u6001\u6027\u80fd\u5206\u6790\uff1b\u7528\u65b0\u6307\u6807\u63ed\u793a\u4e86\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u65b0\u7684\u6d4b\u8bd5\u96c6\u548c\u6307\u6807\u6709\u52a9\u4e8e\u66f4\u53ef\u9760\u5730\u8bc4\u4f30\u97f3\u9891\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u7684\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2508.08244", "pdf": "https://arxiv.org/pdf/2508.08244", "abs": "https://arxiv.org/abs/2508.08244", "authors": ["Jingwen He", "Hongbo Liu", "Jiajun Li", "Ziqi Huang", "Yu Qiao", "Wanli Ouyang", "Ziwei Liu"], "title": "Cut2Next: Generating Next Shot via In-Context Tuning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Effective multi-shot generation demands purposeful, film-like transitions and\nstrict cinematic continuity. Current methods, however, often prioritize basic\nvisual consistency, neglecting crucial editing patterns (e.g., shot/reverse\nshot, cutaways) that drive narrative flow for compelling storytelling. This\nyields outputs that may be visually coherent but lack narrative sophistication\nand true cinematic integrity. To bridge this, we introduce Next Shot Generation\n(NSG): synthesizing a subsequent, high-quality shot that critically conforms to\nprofessional editing patterns while upholding rigorous cinematic continuity.\nOur framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs\nin-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This\nstrategy uses Relational Prompts to define overall context and inter-shot\nediting styles. Individual Prompts then specify per-shot content and\ncinematographic attributes. Together, these guide Cut2Next to generate\ncinematically appropriate next shots. Architectural innovations, Context-Aware\nCondition Injection (CACI) and Hierarchical Attention Mask (HAM), further\nintegrate these diverse signals without introducing new parameters. We\nconstruct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with\nhierarchical prompts, and introduce CutBench for evaluation. Experiments show\nCut2Next excels in visual consistency and text fidelity. Crucially, user\nstudies reveal a strong preference for Cut2Next, particularly for its adherence\nto intended editing patterns and overall cinematic continuity, validating its\nability to generate high-quality, narratively expressive, and cinematically\ncoherent subsequent shots.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNext Shot Generation (NSG)\uff0c\u5e76\u4ecb\u7ecdCut2Next\u6846\u67b6\u4ee5\u751f\u6210\u7b26\u5408\u4e13\u4e1a\u526a\u8f91\u6a21\u5f0f\u548c\u7535\u5f71\u8fde\u7eed\u6027\u7684\u9ad8\u8d28\u91cf\u540e\u7eed\u955c\u5934\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u591a\u955c\u5934\u751f\u6210\u65b9\u6cd5\u5e38\u5ffd\u89c6\u5173\u952e\u526a\u8f91\u6a21\u5f0f\uff0c\u5bfc\u81f4\u8f93\u51fa\u7f3a\u4e4f\u53d9\u4e8b\u590d\u6742\u6027\u548c\u7535\u5f71\u5b8c\u6574\u6027\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faCut2Next\u6846\u67b6\uff0c\u5229\u7528Diffusion Transformer (DiT)\uff0c\u91c7\u7528Hierarchical Multi - Prompting\u7b56\u7565\uff0c\u7ed3\u5408Relational Prompts\u548cIndividual Prompts\uff0c\u8fd8\u6709Context - Aware Condition Injection (CACI)\u548cHierarchical Attention Mask (HAM)\u7b49\u67b6\u6784\u521b\u65b0\uff0c\u6784\u5efa\u76f8\u5173\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u57fa\u51c6CutBench\u3002", "result": "\u5b9e\u9a8c\u663e\u793aCut2Next\u5728\u89c6\u89c9\u4e00\u81f4\u6027\u548c\u6587\u672c\u4fdd\u771f\u5ea6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u7528\u6237\u7814\u7a76\u8868\u660e\u7528\u6237\u66f4\u504f\u597dCut2Next\u3002", "conclusion": "Cut2Next\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53d9\u4e8b\u4e30\u5bcc\u4e14\u7b26\u5408\u7535\u5f71\u8fde\u8d2f\u6027\u7684\u540e\u7eed\u955c\u5934\u3002"}}
