<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [cs.CE](#cs.CE) [Total: 4]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [q-fin.TR](#q-fin.TR) [Total: 1]
- [stat.CO](#stat.CO) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Zero-Shot Adaptation of Parameter-Efficient Fine-Tuning in Diffusion Models](https://arxiv.org/abs/2506.04244)
*Farzad Farhadzadeh,Debasmit Das,Shubhankar Borse,Fatih Porikli*

Main category: cs.AI

TL;DR: ProLoRA实现文本到图像扩散模型中参数高效微调的零样本跨模型迁移，无需额外训练数据


<details>
  <summary>Details</summary>
Motivation: 解决传统方法切换基础模型需重新训练的问题（常受数据限制制约）

Method: 通过子空间/零空间相似性投影源模型调整参数到目标模型权重空间，并选择性对齐关键层

Result: 在主流文本到图像模型上实现知识迁移，性能与需重新训练的方法相当

Conclusion: 突破了模型迁移必须重新训练的限制，为参数高效微调提供跨模型适配新方案

Abstract: We introduce ProLoRA, enabling zero-shot adaptation of parameter-efficient
fine-tuning in text-to-image diffusion models. ProLoRA transfers pre-trained
low-rank adjustments (e.g., LoRA) from a source to a target model without
additional training data. This overcomes the limitations of traditional methods
that require retraining when switching base models, often challenging due to
data constraints. ProLoRA achieves this via projection of source adjustments
into the target model's weight space, leveraging subspace and null space
similarities and selectively targeting aligned layers. Evaluations on
established text-to-image models demonstrate successful knowledge transfer and
comparable performance without retraining.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [2] [ChemReservoir -- An Open-Source Framework for Chemically-Inspired Reservoir Computing](https://arxiv.org/abs/2506.04249)
*Mehmet Aziz Yirik,Jakob Lykke Andersen,Rolf Fagerberg,Daniel Merkle*

Main category: cs.CE

TL;DR: 提出开源框架ChemReservoir解决化学储层计算工具DNA专用化、维护不足的问题，实现通用化学储层构建与评估


<details>
  <summary>Details</summary>
Motivation: 现有DNA化学专用工具存在维护性差和通用性不足的缺陷，需开发可复现、易测试的通用化学储层框架

Method: 构建支持多种循环储层拓扑的开源框架，通过记忆容量任务验证不同配置下的稳定性

Result: 该框架在多种储层配置下均展现出稳定的记忆容量性能

Conclusion: ChemReservoir突破了领域专用工具的限制，为化学启发式计算提供了标准化、可扩展的解决方案

Abstract: Reservoir computing is a type of a recurrent neural network, mapping the
inputs into higher dimensional space using fixed and nonlinear dynamical
systems, called reservoirs. In the literature, there are various types of
reservoirs ranging from in-silico to in-vitro. In cheminformatics, previous
studies contributed to the field by developing simulation-based chemically
inspired in-silico reservoir models. Yahiro used a DNA-based chemical reaction
network as its reservoir and Nguyen developed a DNA chemistry-inspired tool
based on Gillespie algorithm. However, these software tools were designed
mainly with the focus on DNA chemistry and their maintenance status has limited
their current usability. Due to these limitations, there was a need for a
proper open-source tool. This study introduces ChemReservoir, an open-source
framework for chemically-inspired reservoir computing. In contrast to the
former studies focused on DNA-chemistry, ChemReservoir is a general framework
for the construction and analysis of chemically-inspired reservoirs, which also
addresses the limitations in these previous studies by ensuring enhanced
testing, evaluation, and reproducibility. The tool was evaluated using various
cycle-based reservoir topologies and demonstrated stable performance across a
range of configurations in memory capacity tasks.

</details>


### [3] [Adaptive recycled plastic architecture: Vacuum-Sealed Chainmail Structures Through Computational Design](https://arxiv.org/abs/2506.04660)
*Yi Xu,Farzin Lotfi-Jam,Mustafa Faruki*

Main category: cs.CE

TL;DR: 探索再生塑料作为建筑主材在模块化链甲系统中的创新应用，通过计算优化实现真空密封结构的轻量化与高性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决建筑业资源消耗与废弃物问题，开发再生塑料在极端环境（灾害区/外太空等）中的结构应用潜力。

Method: 采用计算工作流优化设计流程，结合2D截面测试、3D壳体生成及真空约束下的物理模型验证。

Result: 矩形链甲配置展现最佳变形能力（应变达0.6）与材料效率（密度0.5kg/m²），优化策略实现材料节省率20%与排水效率平衡。

Conclusion: 再生塑料链甲系统为极端环境提供轻质自适应解决方案，搭建起废弃物利用与高性能设计的创新桥梁。

Abstract: The construction industry is a major consumer of raw materials, accounting
for nearly half of global material usage annually, while generating significant
waste that poses sustainability challenges. This paper explores the untapped
potential of recycled plastics as a primary construction material, leveraging
their lightweight, flexible, and customizable properties for advanced
applications in modular chainmail systems. Through a computational workflow,
the study optimizes the design, testing, and fabrication of vacuum-sealed
chainmail structures composed of recycled plastic filaments, demonstrating
their adaptability and structural performance for architectural use.
  Key contributions include a novel methodology for integrating recycled
plastic filaments into chainmail geometries, validated through 2D sectional
testing, 3D shell structure generation, and physical modeling under vacuum
constraints. The research identifies the rectangular chainmail configuration as
the most efficient and adaptable, achieving superior deformation capacity,
material efficiency, and load-bearing performance. Optimization strategies for
temporary structures highlight practical deployment potential, balancing
material savings, usable area, and water drainage efficiency.
  The findings offer a foundation for innovative applications in extreme
conditions, including disaster-prone areas, high-altitude environments,
underwater platforms, and extraterrestrial habitats. These applications
leverage the lightweight, adaptable, and durable properties of recycled
plastics and modular chainmail systems, bridging the gap between waste
management and high-performance design while addressing unique challenges in
harsh and resource-constrained environments.

</details>


### [4] [Nonlinear elastodynamic material identification of heterogeneous isogeometric Bernoulli-Euler beams](https://arxiv.org/abs/2506.04960)
*Bartłomiej Łazorczyk,Roger A. Sauer*

Main category: cs.CE

TL;DR: 提出基于等几何分析的梁异质材料分布识别框架，通过准静态位移和模态数据两步优化，在噪声数据下实现可靠材料参数重构。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法难以精确识别大变形梁异质材料分布的问题，提升基于实验数据的材料参数反演精度。

Method: 1. 分两步优化：弹性参数（准静态位移）→密度（模态数据）；2. 采用等几何/实验/材料三套独立离散网格；3. 结合最小二乘误差与信赖域优化算法。

Result: 在4%噪声水平下，数据充足时可准确重建材料参数，正则化方法保障了密集材料网格的稳定性，密度重构精度依赖于已识别的弹性参数。

Conclusion: 该框架可扩展到壳和三维连续体，B2M1离散有效缓解膜锁定效应，验证了方法在复杂变形下的工程适用性。

Abstract: This paper presents a Finite Element Model Updating framework for identifying
heterogeneous material distributions in planar Bernoulli-Euler beams based on a
rotation-free isogeometric formulation. The procedure follows two steps: First,
the elastic properties are identified from quasi-static displacements; then,
the density is determined from modal data (low frequencies and mode shapes),
given the previously obtained elastic properties. The identification relies on
three independent discretizations: the isogeometric finite element mesh, a
high-resolution grid of experimental measurements, and a material mesh composed
of low-order Lagrange elements. The material mesh approximates the unknown
material distributions, with its nodal values serving as design variables. The
error between experiments and numerical model is expressed in a least squares
manner. The objective is minimized using local optimization with the
trust-region method, providing analytical derivatives to accelerate
computations. Several numerical examples exhibiting large displacements are
provided to test the proposed approach. To alleviate membrane locking, the B2M1
discretization is employed when necessary. Quasi-experimental data is generated
using refined finite element models with random noise applied up to 4%. The
method yields satisfactory results as long as a sufficient amount of
experimental data is available, even for high measurement noise. Regularization
is used to ensure a stable solution for dense material meshes. The density can
be accurately reconstructed based on the previously identified elastic
properties. The proposed framework can be straightforwardly extended to shells
and 3D continua.

</details>


### [5] [FinMultiTime: A Four-Modal Bilingual Dataset for Financial Time-Series Analysis](https://arxiv.org/abs/2506.05019)
*Wenyan Xu,Dawei Xiang,Yue Liu,Xiyu Wang,Yanxiang Ma,Liang Zhang,Chang Xu,Jiaheng Zhang*

Main category: cs.CE

TL;DR: 提出了首个大规模多模态金融时间序列数据集FinMultiTime，整合新闻/表格/K线图/价格序列四模态数据，验证数据规模质量可提升预测准确率，支持分钟级至季度的多时间粒度分析。


<details>
  <summary>Details</summary>
Motivation: 现有金融数据集仅含价格序列和新闻文本，局限于单一市场且规模不足，无法满足实际金融决策中对异构信息融合分析的需求。

Method: 构建覆盖标普500和沪深300指数共5105支股票的数据集（2009-2025），包含112.6GB金融新闻、结构化表格、K线图、价格序列数据，提供分钟/日/季度三时间分辨率。

Result: 实验表明：1. 数据规模与质量显著提升预测精度 2. 多模态融合使Transformer模型获得中等增益 3. 构建可复现数据管道支持持续更新

Conclusion: 成功创建跨市场多模态金融基准数据集，验证数据基础设施对预测模型的关键作用，并为后续研究提供可扩展的数据更新框架。

Abstract: Pure time series forecasting tasks typically focus exclusively on numerical
features; however, real-world financial decision-making demands the comparison
and analysis of heterogeneous sources of information. Recent advances in deep
learning and large scale language models (LLMs) have made significant strides
in capturing sentiment and other qualitative signals, thereby enhancing the
accuracy of financial time series predictions. Despite these advances, most
existing datasets consist solely of price series and news text, are confined to
a single market, and remain limited in scale. In this paper, we introduce
FinMultiTime, the first large scale, multimodal financial time series dataset.
FinMultiTime temporally aligns four distinct modalities financial news,
structured financial tables, K-line technical charts, and stock price time
series across both the S&P 500 and HS 300 universes. Covering 5,105 stocks from
2009 to 2025 in the United States and China, the dataset totals 112.6 GB and
provides minute-level, daily, and quarterly resolutions, thus capturing short,
medium, and long term market signals with high fidelity. Our experiments
demonstrate that (1) scale and data quality markedly boost prediction accuracy;
(2) multimodal fusion yields moderate gains in Transformer models; and (3) a
fully reproducible pipeline enables seamless dataset updates.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [6] [Computationally Intensive Research: Advancing a Role for Secondary Analysis of Qualitative Data](https://arxiv.org/abs/2506.04230)
*Kaveh Mohajeri,Amir Karami*

Main category: cs.DB

TL;DR: 探讨利用计算方法对历史定性研究数据进行二次分析的潜力与实施方案


<details>
  <summary>Details</summary>
Motivation: 定性研究产生的大量数据常被闲置，通过计算密集型二次分析可挖掘跨时空研究价值

Method: 提出计算密集型二次分析框架，整合多时空数据组合解决纵向研究问题

Result: 该方法能促进创新研究设计，扩展定性数据的科研价值复用

Conclusion: 需克服数据共享伦理、跨情境数据整合及分析方法标准化等核心挑战

Abstract: This paper draws attention to the potential of computational methods in
reworking data generated in past qualitative studies. While qualitative
inquiries often produce rich data through rigorous and resource-intensive
processes, much of this data usually remains unused. In this paper, we first
make a general case for secondary analysis of qualitative data by discussing
its benefits, distinctions, and epistemological aspects. We then argue for
opportunities with computationally intensive secondary analysis, highlighting
the possibility of drawing on data assemblages spanning multiple contexts and
timeframes to address cross-contextual and longitudinal research phenomena and
questions. We propose a scheme to perform computationally intensive secondary
analysis and advance ideas on how this approach can help facilitate the
development of innovative research designs. Finally, we enumerate some key
challenges and ongoing concerns associated with qualitative data sharing and
reuse.

</details>


### [7] [OxO2 -- A SSSOM mapping browser for logically sound crosswalks](https://arxiv.org/abs/2506.04286)
*Henriette Harmse,Haider Iqbal,Helen Parkinson,James McLaughlin*

Main category: cs.DB

TL;DR: EMBL-EBI开发OxO2解决本体映射工具在逻辑可靠性、来源追溯和系统稳定性方面的缺陷


<details>
  <summary>Details</summary>
Motivation: 原版OxO存在逻辑不可靠的映射结果、缺乏作者/评审者等溯源信息、请求处理不稳定等问题

Method: 采用SSSOM标准规范映射溯源，利用Nemo规则引擎实现逻辑可靠的Datalog推理，并实施多种性能优化策略

Result: 新系统OxO2实现了高效内存管理，保证所有请求的稳定处理，支持可靠的本体映射推导

Conclusion: 改进后的OxO2使用户能够更可靠地整合不同本体标注的生物数据集

Abstract: EMBL-EBI created OxO to enable users to map between datasets that are
annotated with different ontologies. Mappings identified by the first version
of OxO were not necessarily logically sound, missed important provenance
information such as author and reviewer, and could timeout or crash for certain
requests. In this paper we introduce OxO2 to address these concerns. Provenance
is addressed by implementing SSSOM, a mapping standard that defines provenance
for mappings. SSSOM defines the conditions under which logical sound mappings
can be derived and is implemented in OxO2 using, Nemo, a Datalog rule engine.
To ensure reasoning is performant and memory efficient, Nemo implements a
number of strategies that ensures OxO2 will be stable for all requests. Due to
these changes, OxO2 users will be able to integrate between disparate datasets
with greater confidence.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [8] [Fully-Distributed Construction of Byzantine-Resilient Dynamic Peer-to-Peer Networks](https://arxiv.org/abs/2506.04368)
*Aayush Gupta,Gopal Pandurangan*

Main category: cs.DC

TL;DR: 提出一种分布式P2P协议，能在高节点流失率和大量拜占庭节点存在下维持高扩展性网络拓扑


<details>
  <summary>Details</summary>
Motivation: 解决P2P网络中动态拓扑维护难题，传统方法难以在高流失率和恶意节点环境下维持网络连通性、低延迟和高扩展性等关键属性

Method: 基于随机化分布式协议，仅需局部初始知识，通过多项式对数级通信/计算开销维护常数度数的高扩展图

Result: 协议可容忍o(n/poly log n)拜占庭节点，拓扑维护仅需O(poly log n)开销，保持对数直径和高扩展性

Conclusion: 该协议为拜占庭协议、领导者选举等分布式问题提供基础支撑，能实现高效可扩展的解决方案

Abstract: We address a fundamental problem in Peer-to-Peer (P2P) networks, namely,
constructing and maintaining dynamic P2P overlay network topologies with
essential properties such as connectivity, low diameter, and high expansion,
that are resilient to continuous high churn and the presence of a large number
of malicious (Byzantine) nodes. Our main goal is to construct and maintain a
sparse (bounded degree) expander topology despite high churn and a large number
of Byzantine nodes. Such an expander topology has logarithmic diameter, high
expansion, and is robust to churn and the presence of a large number of bad
nodes, and facilitates efficient and robust algorithms for fundamental problems
in distributed computing, such as agreement, broadcasting, routing, etc.
  Our main contribution is a randomized, fully-distributed dynamic P2P protocol
that works with only local initial knowledge and guarantees, with a high
probability, the maintenance of a constant degree graph with high expansion
even under continuous churn and in the presence of a large number of Byzantine
nodes. Our protocol can tolerate up to $o(n/poly\log(n))$ Byzantine nodes
(where $n$ is the stable network size). Our protocol is efficient, lightweight,
and scalable, and it incurs only $O(poly\log(n))$ overhead for topology
maintenance: only polylogarithmic (in $n$) bits need to be processed and sent
by each honest node per round, and any honest node's computation cost per round
is also polylogarithmic.
  Our protocol can be used as a building block for solving fundamental
distributed computing problems in highly dynamic networks, such as Byzantine
agreement and Byzantine leader election, and enables fast and scalable
algorithms for these problems.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [9] [Rumors on evolving graphs through stationary times](https://arxiv.org/abs/2506.04386)
*Vicenzo Bonasorte*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study rumor spreading in dynamic random graphs. Starting with a single
informed vertex, the information flows until it reaches all the vertices of the
graph (completion), according to the following process. At each step $k$, the
information is propagated to neighbors of the informed vertices, in the $k$-th
generated random graph. The way this information propagates from vertex to
vertex at each step will depend on the ``protocol". We provide a method based
on strong stationary times to study the completion time when the graphs are
Markovian time dependent, using known results of the literature for independent
graphs. The concept of strong stationary times is then extended to
non-Markovian Dynamics using coupling from the past algorithms. This allows to
extend results on completion times for non-Markov dynamics

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [10] [User Altruism in Recommendation Systems](https://arxiv.org/abs/2506.04525)
*Ekaterina Fedorova,Madeline Kitch,Chara Podimata*

Main category: cs.GT

TL;DR: 用户通过'利他策略'集体操控推荐系统偏好矩阵，实证显示该行为能提升用户和平台效用


<details>
  <summary>Details</summary>
Motivation: 研究推荐系统用户如何通过策略性互动形成草根运动，对抗算法压制以提升被抑制内容的可见性

Method: 建立用户-推荐系统博弈模型，分析真实/利他偏好报告下的社会福利差异，结合GoodReads数据集和用户调查验证

Result: 满足特定条件时利他策略显著提升社会福利，且能同步增加推荐系统效用（尤其在低秩近似场景）

Conclusion: 传统推荐系统的激励机制可能意外促使用户形成集体行动，这对算法透明度和用户行为建模具有重要启示

Abstract: Users of social media platforms based on recommendation systems (RecSys)
(e.g. TikTok, X, YouTube) strategically interact with platform content to
influence future recommendations. On some such platforms, users have been
documented to form large-scale grassroots movements encouraging others to
purposefully interact with algorithmically suppressed content in order to
"boost" its recommendation; we term this behavior user altruism. To capture
this behavior, we study a game between users and a RecSys, where users provide
the RecSys (potentially manipulated) preferences over the contents available to
them, and the RecSys -- limited by data and computation constraints -- creates
a low-rank approximation preference matrix, and ultimately provides each user
her (approximately) most-preferred item. We compare the users' social welfare
under truthful preference reporting and under a class of strategies capturing
user altruism. In our theoretical analysis, we provide sufficient conditions to
ensure strict increases in user social welfare under user altruism, and provide
an algorithm to find an effective altruistic strategy. Interestingly, we show
that for commonly assumed recommender utility functions, effectively altruistic
strategies also improve the utility of the RecSys! We show that our results are
robust to several model misspecifications, thus strengthening our conclusions.
Our theoretical analysis is complemented by empirical results of effective
altruistic strategies on the GoodReads dataset, and an online survey on how
real-world users behave altruistically in RecSys. Overall, our findings serve
as a proof-of-concept of the reasons why traditional RecSys may incentivize
users to form collectives and/or follow altruistic strategies when interacting
with them.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [11] [I'm Sorry Dave, I'm Afraid I Can't Return That: On YouTube Search API Use in Research](https://arxiv.org/abs/2506.04422)
*Alexandros Efstratiou*

Main category: cs.IR

TL;DR: 研究发现YouTube数据API的搜索端点返回结果存在未公开的随机化机制，基于查询期间主题流行度返回不一致结果，影响历史数据收集有效性


<details>
  <summary>Details</summary>
Motivation: 尽管YouTube平台被广泛研究，但其官方API特别是搜索端口的实际工作机制尚未被充分理解，需要揭示其数据收集的可靠性问题

Method: 通过连续12周运行完全相同的查询请求，系统分析API返回结果的稳定性与规律性

Result: API返回结果存在未文档化的随机化机制，优先推荐短小热门视频，历史视频样本收集困难（尤其在非热门时段），频道影响力因素尚不明确

Conclusion: 建议研究者调整数据收集策略，并需要进一步探索API工作机制及其潜在应用场景

Abstract: YouTube is among the most widely-used platforms worldwide, and has seen a lot
of recent academic attention. Despite its popularity and the number of studies
conducted on it, much less is understood about the way in which YouTube's Data
API, and especially the Search endpoint, operates. In this paper, we analyze
the API's behavior by running identical queries across a period of 12 weeks.
Our findings suggest that the search endpoint returns highly inconsistent
results between queries in ways that are not officially documented.
Specifically, the API seems to randomize returned videos based on the relative
popularity of the respective topic during the query period, making it nearly
impossible to obtain representative historical video samples, especially during
non-peak topical periods. Our results also suggest that the API may prioritize
shorter, more popular videos, although the role of channel popularity is not as
clear. We conclude with suggested strategies for researchers using the API for
data collection, as well as future research directions on expanding the API's
use-cases.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [A Comprehensive Survey on the Risks and Limitations of Concept-based Models](https://arxiv.org/abs/2506.04237)
*Sanchit Sinha,Aidong Zhang*

Main category: cs.LG

TL;DR: 论文系统分析了基于概念模型的局限性（概念泄露/鲁棒性问题）并提出改进方向


<details>
  <summary>Details</summary>
Motivation: 基于概念模型在敏感领域应用广泛但存在可靠性隐患，需系统性研究其缺陷

Method: 通过文献综述整合监督/非监督范式下的常见挑战及架构改进方案

Result: 揭示模型存在概念纠缠、对抗脆弱性等问题，提出模块化设计等缓解方案

Conclusion: 需持续研究对抗性防御和有效人机协同机制以提升概念模型实用性

Abstract: Concept-based Models are a class of inherently explainable networks that
improve upon standard Deep Neural Networks by providing a rationale behind
their predictions using human-understandable `concepts'. With these models
being highly successful in critical applications like medical diagnosis and
financial risk prediction, there is a natural push toward their wider adoption
in sensitive domains to instill greater trust among diverse stakeholders.
However, recent research has uncovered significant limitations in the structure
of such networks, their training procedure, underlying assumptions, and their
susceptibility to adversarial vulnerabilities. In particular, issues such as
concept leakage, entangled representations, and limited robustness to
perturbations pose challenges to their reliability and generalization.
Additionally, the effectiveness of human interventions in these models remains
an open question, raising concerns about their real-world applicability. In
this paper, we provide a comprehensive survey on the risks and limitations
associated with Concept-based Models. In particular, we focus on aggregating
commonly encountered challenges and the architecture choices mitigating these
challenges for Supervised and Unsupervised paradigms. We also examine recent
advances in improving their reliability and discuss open problems and promising
avenues of future research in this domain.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [13] [A Comprehensive Survey on Bio-Inspired Algorithms: Taxonomy, Applications, and Future Directions](https://arxiv.org/abs/2506.04238)
*Shriyank Somvanshi,Md Monzurul Islam,Syed Aaqib Javed,Gaurab Chhetri,Kazi Sifatul Islam,Tausif Islam Chowdhury,Sazzad Bin Bashar Polock,Anandi Dutta,Subasish Das*

Main category: cs.NE

TL;DR: 该论文对生物启发算法进行系统分类，阐述其原理、应用领域及挑战，为相关研究提供基础参考框架。


<details>
  <summary>Details</summary>
Motivation: 通过梳理生物启发算法的分类体系、应用场景和未来挑战，为研究者和从业者建立系统化的知识图谱，推动该领域发展。

Method: 采用分类学方法将算法分为8大类，结合典型应用案例分析，并引入自适应策略等前沿进展进行系统性综述。

Result: 构建包含进化算法、群体智能等8类算法的分类体系，揭示算法在工程优化等领域的成功应用，提出可扩展性、可靠性等关键研究方向。

Conclusion: 生物启发算法在复杂问题求解中展现出独特优势，但需通过混合策略、理论深化等手段突破当前的技术瓶颈。

Abstract: Bio-inspired algorithms (BIAs) utilize natural processes such as evolution,
swarm behavior, foraging, and plant growth to solve complex, nonlinear,
high-dimensional optimization problems. This survey categorizes BIAs into eight
groups: evolutionary, swarm intelligence, physics-inspired, ecosystem and
plant-based, predator-prey, neural-inspired, human-inspired, and hybrid
approaches, and reviews their core principles, strengths, and limitations. We
illustrate the usage of these algorithms in machine learning, engineering
design, bioinformatics, and intelligent systems, and highlight recent advances
in hybridization, parameter tuning, and adaptive strategies. Finally, we
identify open challenges such as scalability, convergence, reliability, and
interpretability to suggest directions for future research. This work aims to
serve as a foundational resource for both researchers and practitioners
interested in understanding the current landscape and future directions of
bio-inspired computing.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [14] [Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges](https://arxiv.org/abs/2506.04418)
*Noor Nashid,Daniel Ding,Keheliya Gallaba,Ahmed E. Hassan,Ali Mesbah*

Main category: cs.SE

TL;DR: 研究揭示了大型语言模型在多块代码修复中的局限性，提出基于块间差异的评估指标，发现模型修复成功率随代码分散度增加而显著下降


<details>
  <summary>Details</summary>
Motivation: 现有自动程序修复技术过度关注单块错误，忽视了真实场景中广泛存在的多块协调修复需求，导致修复能力存在系统性缺陷

Method: 构建包含372个真实缺陷的HUNK4J数据集，提出量化编辑差异的块间差异指标（包含词法、结构、文件层次三维度）和空间邻近性分类体系，对六种LLM进行跨维度实证研究

Result: 所有模型在最高分散度的Fragment类修复完全失败，块间差异每增加1单位成功率下降32%，空间分散导致修复准确率最大降幅达47%

Conclusion: 多维度差异评估揭示了LLM多块修复能力的关键缺陷，需开发融合结构感知和差异自适应的新型修复策略

Abstract: Multi-hunk bugs, where fixes span disjoint regions of code, are common in
practice, yet remain underrepresented in automated repair. Existing techniques
and benchmarks pre-dominantly target single-hunk scenarios, overlooking the
added complexity of coordinating semantically related changes across the
codebase. In this work, we characterize HUNK4J, a dataset of multi-hunk patches
derived from 372 real-world defects. We propose hunk divergence, a metric that
quantifies the variation among edits in a patch by capturing lexical,
structural, and file-level differences, while incorporating the number of hunks
involved. We further define spatial proximity, a classification that models how
hunks are spatially distributed across the program hierarchy. Our empirical
study spanning six LLMs reveals that model success rates decline with increased
divergence and spatial dispersion. Notably, when using the LLM alone, no model
succeeds in the most dispersed Fragment class. These findings highlight a
critical gap in LLM capabilities and motivate divergence-aware repair
strategies.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [15] [Can Artificial Intelligence Trade the Stock Market?](https://arxiv.org/abs/2506.04658)
*Jędrzej Maskiewicz,Paweł Sakowski*

Main category: q-fin.TR

TL;DR: 研究证明深度强化学习（DRL）在股票交易中有效，通过DDQN和PPO算法对比显示其风险调整收益优于传统监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 探索DRL在动态金融市场中的应用潜力，解决传统监督学习方法在风险管理方面的不足。

Method: 使用DDQN和PPO算法，在2019-2023年期间对三种货币对、标普500和比特币的日数据进行回测，并与Buy and Hold基准策略对比。

Result: DRL算法展现出优异的主动风险管理能力，通过策略性规避不利交易环境，风险调整收益指标显著超越传统方法。

Conclusion: DRL为金融交易提供了更智能的决策框架，尤其在动态市场环境下具有更高的风险收益平衡能力。

Abstract: The paper explores the use of Deep Reinforcement Learning (DRL) in stock
market trading, focusing on two algorithms: Double Deep Q-Network (DDQN) and
Proximal Policy Optimization (PPO) and compares them with Buy and Hold
benchmark. It evaluates these algorithms across three currency pairs, the S&P
500 index and Bitcoin, on the daily data in the period of 2019-2023. The
results demonstrate DRL's effectiveness in trading and its ability to manage
risk by strategically avoiding trades in unfavorable conditions, providing a
substantial edge over classical approaches, based on supervised learning in
terms of risk-adjusted returns.

</details>


<div id='stat.CO'></div>

# stat.CO [[Back]](#toc)

### [16] [Amortized variational transdimensional inference](https://arxiv.org/abs/2506.04749)
*Laurence Davies,Dan Mackinlay,Rafael Oliveira,Scott A. Sisson*

Main category: stat.CO

TL;DR: 提出CoSMIC流和VTI方法，实现跨维度变分推断，解决传统流模型固定维度限制


<details>
  <summary>Details</summary>
Motivation: 现有基于流的随机变分推断(SVI)局限于固定维度问题，无法处理维度可变的复杂推断任务

Method: 1. 开发CoSMIC流架构，扩展神经自回归条件标准化流；2. 结合贝叶斯优化和蒙特卡洛梯度估计的VTI训练方法

Result: 在包含高基数模型空间的挑战性问题上验证了VTI的有效性

Conclusion: CoSMIC+VTI为跨维度贝叶斯推断提供了统一的变分密度框架，拓展了SVI的应用范围

Abstract: The expressiveness of flow-based models combined with stochastic variational
inference (SVI) has, in recent years, expanded the application of
optimization-based Bayesian inference to include problems with complex data
relationships. However, until now, SVI using flow-based models has been limited
to problems of fixed dimension. We introduce CoSMIC, normalizing flows
(COntextually-Specified Masking for Identity-mapped Components), an extension
to neural autoregressive conditional normalizing flow architectures that
enables using a single amortized variational density for inference over a
transdimensional target distribution. We propose a combined stochastic
variational transdimensional inference (VTI) approach to training CoSMIC flows
using techniques from Bayesian optimization and Monte Carlo gradient
estimation. Numerical experiments demonstrate the performance of VTI on
challenging problems that scale to high-cardinality model spaces.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [17] [TQml Simulator: Optimized Simulation of Quantum Machine Learning](https://arxiv.org/abs/2506.04891)
*Viacheslav Kuzmin,Basil Kyriacou,Mateusz Papierz,Mo Kordzanganeh,Alexey Melnikov*

Main category: quant-ph

TL;DR: 开发了TQml量子模拟器，通过分层优化模拟方法实现2-100倍的性能提升


<details>
  <summary>Details</summary>
Motivation: 现有量子机器学习电路模拟器效率不足，需加速算法前向/反向传播过程

Method: 通过基准测试选择最优模拟技术，针对不同量子门层动态组合门特定技术与通用技术

Result: 在IonQ/IBM量子硬件测试中，性能普遍优于Pennylane默认模拟器2-100倍

Conclusion: 定制化的分层模拟方法组合可显著提升量子机器学习算法模拟效率

Abstract: Hardware-efficient circuits employed in Quantum Machine Learning are
typically composed of alternating layers of uniformly applied gates. High-speed
numerical simulators for such circuits are crucial for advancing research in
this field. In this work, we numerically benchmark universal and gate-specific
techniques for simulating the action of layers of gates on quantum state
vectors, aiming to accelerate the overall simulation of Quantum Machine
Learning algorithms. Our analysis shows that the optimal simulation method for
a given layer of gates depends on the number of qubits involved, and that a
tailored combination of techniques can yield substantial performance gains in
the forward and backward passes for a given circuit. Building on these
insights, we developed a numerical simulator, named TQml Simulator, that
employs the most efficient simulation method for each layer in a given circuit.
We evaluated TQml Simulator on circuits constructed from standard gate sets,
such as rotations and CNOTs, as well as on native gates from IonQ and IBM
quantum processing units. In most cases, our simulator outperforms equivalent
Pennylane's default.qubit simulator by approximately 2- to 100-fold, depending
on the circuit, the number of qubits, the batch size of the input data, and the
hardware used.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [18] [The Determinants of Net Interest Margin in the Turkish Banking Sector: Does Bank Ownership Matter? Central Bank Digital Currencies](https://arxiv.org/abs/2506.04384)
*Fatih Kansoy*

Main category: econ.GN

TL;DR: 该研究通过2001-2012年土耳其商业银行数据，实证分析了不同所有权结构下净息差的影响因素差异。


<details>
  <summary>Details</summary>
Motivation: 探讨银行所有权结构（外资/国有/私营）对净息差决定机制的影响差异，揭示不同所有制银行的经营特性。

Method: 采用银行层面面板数据，通过实证模型分析运营多样性、信用风险、运营成本等变量对净息差的影响，并分组比较不同所有制银行。

Result: 信用风险、银行规模等核心因素在各类银行中影响程度不同；运营多样性、运营成本则呈现跨所有制一致性影响。高效银行和价格稳定环境有助于降低净息差。

Conclusion: 银行所有权结构显著调节部分关键因素对净息差的作用机制，监管政策需考虑所有制差异对货币政策传导的异质性影响。

Abstract: This research presented an empirical investigation of the determinants of the
net interest margin in Turkish Banking sector with a particular emphasis on the
bank ownership structure. This study employed a unique bank-level dataset
covering Turkey`s commercial banking sector for the 2001-2012. Our main results
are as follows. Operation diversity, credit risk and operating costs are
important determinants of margin in Turkey. More efficient banks exhibit lower
margin and also price stability contributes to lower margin. The effect of
principal determinants such as credit risk, bank size, market concentration and
inflation vary across foreign-owned, state-controlled and private banks. At the
same time, the impacts of implicit interest payment, operation diversity and
operating cost are homogeneous across all banks

</details>
