{"id": "2509.13524", "pdf": "https://arxiv.org/pdf/2509.13524", "abs": "https://arxiv.org/abs/2509.13524", "authors": ["Ginger Tsueng", "Emily Bullen", "Candice Czech", "Dylan Welzel", "Leandro Collares", "Jason Lin", "Everaldo Rodolpho", "Zubair Qazi", "Nichollette Acosta", "Lisa M. Mayer", "Sudha Venkatachari", "Zorana Mitrovi\u0107 Vu\u010di\u010devi\u0107", "Poromendro N. Burman", "Deepti Jain", "Jack DiGiovanna", "Maria Giovanni", "Asiyah Lin", "Wilbert Van Panhuis", "Laura D. Hughes", "Andrew I. Su", "Chunlei Wu"], "title": "The NIAID Discovery Portal: A Unified Search Engine for Infectious and Immune-Mediated Disease Datasets", "categories": ["cs.DB", "cs.DL", "J.3"], "comment": "20 pages, 3 figures, 1 table, submitted to mSystems", "summary": "The NIAID Data Ecosystem Discovery Portal (https://data.niaid.nih.gov)\nprovides a unified search interface for over 4 million datasets relevant to\ninfectious and immune-mediated disease (IID) research. Integrating metadata\nfrom domain-specific and generalist repositories, the Portal enables\nresearchers to identify and access datasets using user-friendly filters or\nadvanced queries, without requiring technical expertise. The Portal supports\ndiscovery of a wide range of resources, including epidemiological, clinical,\nand multi-omic datasets, and is designed to accommodate exploratory browsing\nand precise searches. The Portal provides filters, prebuilt queries, and\ndataset collections to simplify the discovery process for users. The Portal\nadditionally provides documentation and an API for programmatic access to\nharmonized metadata. By easing access barriers to important biomedical\ndatasets, the NIAID Data Ecosystem Discovery Portal serves as an entry point\nfor researchers working to understand, diagnose, or treat IID.\n  Valuable datasets are often overlooked because they are difficult to locate.\nThe NIAID Data Ecosystem Discovery Portal fills this gap by providing a\ncentralized, searchable interface that empowers users with varying levels of\ntechnical expertise to find and reuse data. By standardizing key metadata\nfields and harmonizing heterogeneous formats, the Portal improves data\nfindability, accessibility, and reusability. This resource supports hypothesis\ngeneration, comparative analysis, and secondary use of public data by the IID\nresearch community, including those funded by NIAID. The Portal supports data\nsharing by standardizing metadata and linking to source repositories, and\nmaximizes the impact of public investment in research data by supporting\nscientific advancement via secondary use.", "AI": {"tldr": "NIAID\u6570\u636e\u751f\u6001\u7cfb\u7edf\u53d1\u73b0\u95e8\u6237\u63d0\u4f9b\u7edf\u4e00\u641c\u7d22\u754c\u9762\uff0c\u4fbf\u4e8e\u7814\u7a76\u4eba\u5458\u67e5\u627e\u548c\u4f7f\u7528\u4f20\u67d3\u75c5\u548c\u514d\u75ab\u4ecb\u5bfc\u75be\u75c5\u76f8\u5173\u6570\u636e\u96c6\uff0c\u63d0\u5347\u6570\u636e\u53ef\u53d1\u73b0\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u91cd\u7528\u6027\u3002", "motivation": "\u89e3\u51b3\u6709\u4ef7\u503c\u6570\u636e\u96c6\u56e0\u96be\u4ee5\u5b9a\u4f4d\u800c\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\uff0c\u4e3a\u4e0d\u540c\u6280\u672f\u6c34\u5e73\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u67e5\u627e\u548c\u91cd\u7528\u6570\u636e\u7684\u9014\u5f84\u3002", "method": "\u6574\u5408\u7279\u5b9a\u9886\u57df\u548c\u901a\u7528\u5b58\u50a8\u5e93\u7684\u5143\u6570\u636e\uff0c\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684\u8fc7\u6ee4\u5668\u3001\u9884\u5efa\u67e5\u8be2\u548c\u6570\u636e\u96c6\u96c6\u5408\uff0c\u6807\u51c6\u5316\u5173\u952e\u5143\u6570\u636e\u5b57\u6bb5\uff0c\u534f\u8c03\u5f02\u6784\u683c\u5f0f\u3002", "result": "\u63d0\u4f9b\u7edf\u4e00\u641c\u7d22\u754c\u9762\uff0c\u652f\u6301\u591a\u79cd\u8d44\u6e90\u53d1\u73b0\uff0c\u63d0\u4f9b\u6587\u6863\u548cAPI\u7528\u4e8e\u7f16\u7a0b\u8bbf\u95ee\u5143\u6570\u636e\uff0c\u652f\u6301\u6570\u636e\u5171\u4eab\u3002", "conclusion": "\u8be5\u95e8\u6237\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\u4e86\u89e3\u3001\u8bca\u65ad\u6216\u6cbb\u7597\u4f20\u67d3\u75c5\u548c\u514d\u75ab\u4ecb\u5bfc\u75be\u75c5\u7684\u5165\u53e3\u70b9\uff0c\u652f\u6301\u79d1\u5b66\u8fdb\u6b65\u548c\u516c\u5171\u7814\u7a76\u6570\u636e\u7684\u4e8c\u6b21\u5229\u7528\u3002"}}
{"id": "2509.13565", "pdf": "https://arxiv.org/pdf/2509.13565", "abs": "https://arxiv.org/abs/2509.13565", "authors": ["Christoph Standke", "Benny Kimelfeld"], "title": "Tractability Frontiers of the Shapley Value for Aggregate Conjunctive Queries", "categories": ["cs.DB"], "comment": null, "summary": "In recent years, the Shapley value has emerged as a general game-theoretic\nmeasure for assessing the contribution of a tuple to the result of a database\nquery. We study the complexity of calculating the Shapley value of a tuple for\nan aggregate conjunctive query, which applies an aggregation function to the\nresult of a conjunctive query (CQ) based on a value function that assigns a\nnumber to each query answer. Prior work by Livshits, Bertossi, Kimelfeld, and\nSebag (2020) established that this task is #P-hard for every nontrivial\naggregation function when the query is non-hierarchical with respect to its\nexistential variables, assuming the absence of self-joins. They further showed\nthat this condition precisely characterizes the class of intractable CQs when\nthe aggregate function is sum or count. In addition, they posed as open\nproblems the complexity of other common aggregate functions such as min, max,\ncount-distinct, average, and quantile (including median). Towards the\nresolution of these problems, we identify for each aggregate function a class\nof hierarchical CQs where the Shapley value is tractable with every value\nfunction, as long as it is local (i.e., determined by the tuples of one\nrelation). We further show that each such class is maximal: for every CQ\noutside of this class, there is a local (easy-to-compute) value function that\nmakes the Shapley value #P-hard. Interestingly, our results reveal that each\naggregate function corresponds to a different generalization of the class of\nhierarchical CQs from Boolean to non-Boolean queries. In particular, max, min,\nand count-distinct match the class of CQs that are all-hierarchical (i.e.,\nhierarchical with respect to all variables), and average and quantile match the\nnarrower class of q-hierarchical CQs introduced by Berkholz, Keppeler, and\nSchweikardt (2017) in the context of the fine-grained complexity of query\nanswering.", "AI": {"tldr": "\u7814\u7a76\u805a\u5408\u8fde\u63a5\u67e5\u8be2\u5143\u7ec4Shapley\u503c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u786e\u5b9a\u4e0d\u540c\u805a\u5408\u51fd\u6570\u4e0b\u53ef\u5904\u7406\u7684\u5206\u5c42CQ\u7c7b\u5e76\u8bc1\u660e\u5176\u6700\u5927\u6027\u3002", "motivation": "\u89e3\u51b3\u5148\u524d\u5de5\u4f5c\u4e2d\u63d0\u51fa\u7684min\u3001max\u7b49\u5e38\u89c1\u805a\u5408\u51fd\u6570\u8ba1\u7b97Shapley\u503c\u590d\u6742\u5ea6\u7684\u5f00\u653e\u95ee\u9898\u3002", "method": "\u8bc6\u522b\u4e0d\u540c\u805a\u5408\u51fd\u6570\u4e0bShapley\u503c\u53ef\u5904\u7406\u7684\u5206\u5c42CQ\u7c7b\uff0c\u5e76\u8bc1\u660e\u5176\u6700\u5927\u6027\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u805a\u5408\u51fd\u6570\u5bf9\u5e94\u4ece\u5e03\u5c14\u67e5\u8be2\u5230\u975e\u5e03\u5c14\u67e5\u8be2\u7684\u5206\u5c42CQ\u7c7b\u7684\u4e0d\u540c\u6cdb\u5316\u3002", "conclusion": "\u786e\u5b9a\u4e86\u4e0d\u540c\u805a\u5408\u51fd\u6570\u4e0bShapley\u503c\u53ef\u5904\u7406\u7684\u5206\u5c42CQ\u7c7b\uff0c\u4e3a\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u89e3\u51b3\u601d\u8def\u3002"}}
{"id": "2509.13566", "pdf": "https://arxiv.org/pdf/2509.13566", "abs": "https://arxiv.org/abs/2509.13566", "authors": ["Denis Spasyuk"], "title": "XASDB -- Design and Implementation of an Open-Access Spectral Database", "categories": ["cs.DB", "physics.data-an"], "comment": null, "summary": "The increasing volume and complexity of X-ray absorption spectroscopy (XAS)\ndata generated at synchrotron facilities worldwide require robust\ninfrastructure for data management, sharing, and analysis. This paper\nintroduces the XAS Database (XASDB), a comprehensive web-based platform\ndeveloped and hosted by the Canadian Light Source (CLS). The database houses\nmore than 1000 reference spectra spanning 40 elements and 324 chemical\ncompounds. The platform employs a Node.js/MongoDB architecture designed to\nhandle diverse data formats from multiple beamlines and synchrotron facilities.\nA key innovation is the XASproc JavaScript library, which enables browser-based\nXAS data processing including normalization, background sub- traction, extended\nX-ray absorption fine structure (EXAFS) extraction, and preliminary analysis\ntraditionally limited to desktop applications. The integrated XASVue spectral\nviewer provides installation-free data visualization and analysis with broad\naccessibility across devices and operating systems. By offering standardized\ndata output, comprehensive metadata, and integrated analytical ca- pabilities,\nXASDB facilitates collaborative research and promotes FAIR (Findable,\nAccessible, In- teroperable, and Reusable) data principles. The platform serves\nas a valuable resource for linear combination fitting (LCF) analysis, machine\nlearning applications, and educational purposes. This initiative demonstrates\nthe potential for web-centric approaches in XAS data analysis, accelerating\nadvances in materials science, environmental research, chemistry, and biology.", "AI": {"tldr": "\u4ecb\u7ecdX\u5c04\u7ebf\u5438\u6536\u5149\u8c31\u6570\u636e\u5e93XASDB\uff0c\u5305\u62ec\u5176\u67b6\u6784\u3001\u529f\u80fd\u53ca\u4ef7\u503c\u3002", "motivation": "\u5e94\u5bf9\u5168\u7403\u540c\u6b65\u8f90\u5c04\u8bbe\u65bd\u4ea7\u751f\u7684X\u5c04\u7ebf\u5438\u6536\u5149\u8c31\u6570\u636e\u91cf\u548c\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u5f3a\u5927\u7684\u6570\u636e\u7ba1\u7406\u3001\u5171\u4eab\u548c\u5206\u6790\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eNode.js/MongoDB\u67b6\u6784\u7684XASDB\u5e73\u53f0\uff0c\u91c7\u7528XASproc JavaScript\u5e93\u8fdb\u884c\u6570\u636e\u5904\u7406\uff0c\u96c6\u6210XASVue\u5149\u8c31\u67e5\u770b\u5668\u3002", "result": "XASDB\u62e5\u6709\u8d851000\u6761\u53c2\u8003\u5149\u8c31\uff0c\u652f\u6301\u591a\u79cd\u6570\u636e\u5904\u7406\u548c\u53ef\u89c6\u5316\uff0c\u4fc3\u8fdb\u534f\u4f5c\u7814\u7a76\uff0c\u63a8\u52a8FAIR\u6570\u636e\u539f\u5219\u3002", "conclusion": "\u4ee5\u7f51\u7edc\u4e3a\u4e2d\u5fc3\u7684XAS\u6570\u636e\u5206\u6790\u65b9\u6cd5\u6709\u6f5c\u529b\u52a0\u901f\u591a\u9886\u57df\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2509.14054", "pdf": "https://arxiv.org/pdf/2509.14054", "abs": "https://arxiv.org/abs/2509.14054", "authors": ["Weihao Yan", "Christoph Brune", "Mengwu Guo"], "title": "Physics-based deep kernel learning for parameter estimation in high dimensional PDEs", "categories": ["cs.CE", "cs.LG", "cs.NA", "math.NA", "68T05", "I.2.6"], "comment": null, "summary": "Inferring parameters of high-dimensional partial differential equations\n(PDEs) poses significant computational and inferential challenges, primarily\ndue to the curse of dimensionality and the inherent limitations of traditional\nnumerical methods. This paper introduces a novel two-stage Bayesian framework\nthat synergistically integrates training, physics-based deep kernel learning\n(DKL) with Hamiltonian Monte Carlo (HMC) to robustly infer unknown PDE\nparameters and quantify their uncertainties from sparse, exact observations.\nThe first stage leverages physics-based DKL to train a surrogate model, which\njointly yields an optimized neural network feature extractor and robust initial\nestimates for the PDE parameters. In the second stage, with the neural network\nweights fixed, HMC is employed within a full Bayesian framework to efficiently\nsample the joint posterior distribution of the kernel hyperparameters and the\nPDE parameters. Numerical experiments on canonical and high-dimensional inverse\nPDE problems demonstrate that our framework accurately estimates parameters,\nprovides reliable uncertainty estimates, and effectively addresses challenges\nof data sparsity and model complexity, offering a robust and scalable tool for\ndiverse scientific and engineering applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u4e8e\u7269\u7406\u7684\u6df1\u5ea6\u6838\u5b66\u4e60\u4e0e\u54c8\u5bc6\u987f\u8499\u7279\u5361\u7f57\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a8\u65ad\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u53c2\u6570\u5e76\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u9ad8\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u53c2\u6570\u63a8\u65ad\u9762\u4e34\u8ba1\u7b97\u548c\u63a8\u7406\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u7528\u57fa\u4e8e\u7269\u7406\u7684\u6df1\u5ea6\u6838\u5b66\u4e60\u8bad\u7ec3\u4ee3\u7406\u6a21\u578b\u5f97\u5230\u521d\u59cb\u4f30\u8ba1\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7528\u54c8\u5bc6\u987f\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u5728\u5168\u8d1d\u53f6\u65af\u6846\u67b6\u4e0b\u91c7\u6837\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u51c6\u786e\u4f30\u8ba1\u53c2\u6570\u3001\u63d0\u4f9b\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u6709\u6548\u5e94\u5bf9\u6570\u636e\u7a00\u758f\u548c\u6a21\u578b\u590d\u6742\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u9002\u7528\u4e8e\u591a\u79cd\u79d1\u5b66\u548c\u5de5\u7a0b\u5e94\u7528\u7684\u5f3a\u5927\u4e14\u53ef\u6269\u5c55\u5de5\u5177\u3002"}}
{"id": "2509.14144", "pdf": "https://arxiv.org/pdf/2509.14144", "abs": "https://arxiv.org/abs/2509.14144", "authors": ["Zheng Luo", "Wim Van den Broeck", "Guy Van den Broeck", "Yisu Remy Wang"], "title": "Algorithms for Optimizing Acyclic Queries", "categories": ["cs.DB", "cs.DS"], "comment": null, "summary": "Most research on query optimization has centered on binary join algorithms\nlike hash join and sort-merge join. However, recent years have seen growing\ninterest in theoretically optimal algorithms, notably Yannakakis' algorithm.\nThese algorithms rely on join trees, which differ from the operator trees for\nbinary joins and require new optimization techniques. We propose three\napproaches to constructing join trees for acyclic queries. First, we give an\nalgorithm to enumerate all join trees of an alpha-acyclic query by edits with\namortized constant delay, which forms the basis of a cost-based optimizer for\nacyclic joins. Second, we show that the Maximum Cardinality Search algorithm by\nTarjan and Yannakakis constructs a unique shallowest join tree, rooted at any\nrelation, for a Berge-acyclic query; this tree enables parallel execution of\nlarge join queries. Finally, we prove that any connected left-deep linear plan\nfor a gamma-acyclic query can be converted into a join tree by a simple\nalgorithm, allowing reuse of optimization infrastructure developed for binary\njoins.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e09\u79cd\u4e3a\u65e0\u73af\u67e5\u8be2\u6784\u5efa\u8fde\u63a5\u6811\u7684\u65b9\u6cd5\uff0c\u5206\u522b\u57fa\u4e8e\u679a\u4e3e\u3001\u6700\u5927\u57fa\u6570\u641c\u7d22\u7b97\u6cd5\u548c\u7ebf\u6027\u8ba1\u5212\u8f6c\u6362\u3002", "motivation": "\u4ee5\u5f80\u67e5\u8be2\u4f18\u5316\u591a\u96c6\u4e2d\u5728\u4e8c\u5143\u8fde\u63a5\u7b97\u6cd5\uff0c\u800c\u7406\u8bba\u6700\u4f18\u7b97\u6cd5\u4f9d\u8d56\u8fde\u63a5\u6811\uff0c\u9700\u8981\u65b0\u7684\u4f18\u5316\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u6784\u5efa\u8fde\u63a5\u6811\u7684\u65b9\u6cd5\uff1a\u679a\u4e3e\u6240\u6709\u03b1 - \u65e0\u73af\u67e5\u8be2\u7684\u8fde\u63a5\u6811\uff1b\u5229\u7528Tarjan\u548cYannakakis\u7684\u6700\u5927\u57fa\u6570\u641c\u7d22\u7b97\u6cd5\u6784\u5efaBerge - \u65e0\u73af\u67e5\u8be2\u7684\u8fde\u63a5\u6811\uff1b\u5c06\u03b3 - \u65e0\u73af\u67e5\u8be2\u7684\u8fde\u901a\u5de6\u6df1\u7ebf\u6027\u8ba1\u5212\u8f6c\u6362\u4e3a\u8fde\u63a5\u6811\u3002", "result": "\u7b2c\u4e00\u79cd\u65b9\u6cd5\u4e3a\u65e0\u73af\u8fde\u63a5\u7684\u57fa\u4e8e\u6210\u672c\u7684\u4f18\u5316\u5668\u5960\u5b9a\u57fa\u7840\uff1b\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u53ef\u5b9e\u73b0\u5927\u578b\u8fde\u63a5\u67e5\u8be2\u7684\u5e76\u884c\u6267\u884c\uff1b\u7b2c\u4e09\u79cd\u65b9\u6cd5\u53ef\u590d\u7528\u4e8c\u5143\u8fde\u63a5\u7684\u4f18\u5316\u57fa\u7840\u8bbe\u65bd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e09\u79cd\u6784\u5efa\u8fde\u63a5\u6811\u7684\u65b9\u6cd5\u4e3a\u65e0\u73af\u67e5\u8be2\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2509.13588", "pdf": "https://arxiv.org/pdf/2509.13588", "abs": "https://arxiv.org/abs/2509.13588", "authors": ["Xuan Liu", "Haoyang Shang", "Haojian Jin"], "title": "Programmable Cognitive Bias in Social Agents", "categories": ["cs.AI", "cs.CE", "cs.CY"], "comment": null, "summary": "This paper introduces CoBRA, a novel toolkit for systematically specifying\nagent behavior in LLM-based social simulation. We found that conventional\napproaches that specify agent behaviors through implicit natural language\ndescriptions cannot yield consistent behaviors across models, and the produced\nagent behaviors do not capture the nuances of the descriptions. In contrast,\nCoBRA presents a new approach to program agents' cognitive biases explicitly,\nby grounding agents' expected behaviors using classic social science\nexperiments. CoBRA has two components: (1) Cognitive Bias Index that measures\nthe cognitive bias of a social agent, by quantifying the agent's reactions in a\nset of validated classical social science experiments; (2) Behavioral\nRegulation Engine that aligns the agent's behavior to demonstrate controlled\ncognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and\ntechnical benchmarks. Our results suggest that CoBRA can precisely program the\ncognitive bias demonstrated in a social agent in a model-agnostic manner.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u6a21\u62df\u4e2d\u7cfb\u7edf\u6307\u5b9a\u4ee3\u7406\u884c\u4e3a\u7684\u5de5\u5177\u5305CoBRA\uff0c\u8bc4\u4f30\u8868\u660e\u5b83\u80fd\u4ee5\u6a21\u578b\u65e0\u5173\u7684\u65b9\u5f0f\u7cbe\u786e\u7f16\u7a0b\u793e\u4f1a\u4ee3\u7406\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "motivation": "\u4f20\u7edf\u901a\u8fc7\u9690\u5f0f\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6307\u5b9a\u4ee3\u7406\u884c\u4e3a\u7684\u65b9\u6cd5\u65e0\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u4ea7\u751f\u4e00\u81f4\u884c\u4e3a\uff0c\u4e14\u4e0d\u80fd\u4f53\u73b0\u63cf\u8ff0\u7684\u7ec6\u5fae\u5dee\u522b\u3002", "method": "\u63d0\u51faCoBRA\u5de5\u5177\u5305\uff0c\u5305\u542b\u8861\u91cf\u793e\u4f1a\u4ee3\u7406\u8ba4\u77e5\u504f\u5dee\u7684\u8ba4\u77e5\u504f\u5dee\u6307\u6570\u548c\u4f7f\u4ee3\u7406\u884c\u4e3a\u8868\u73b0\u51fa\u53d7\u63a7\u8ba4\u77e5\u504f\u5dee\u7684\u884c\u4e3a\u8c03\u8282\u5f15\u64ce\u3002", "result": "\u901a\u8fc7\u6f14\u793a\u548c\u6280\u672f\u57fa\u51c6\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aCoBRA\u80fd\u4ee5\u6a21\u578b\u65e0\u5173\u7684\u65b9\u5f0f\u7cbe\u786e\u7f16\u7a0b\u793e\u4f1a\u4ee3\u7406\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "conclusion": "CoBRA\u53ef\u6709\u6548\u7528\u4e8e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u6a21\u62df\u4e2d\u5bf9\u4ee3\u7406\u884c\u4e3a\u7684\u7cfb\u7edf\u6307\u5b9a\u3002"}}
{"id": "2509.13327", "pdf": "https://arxiv.org/pdf/2509.13327", "abs": "https://arxiv.org/abs/2509.13327", "authors": ["Wissam Nakhle"], "title": "GTA -- An ATSP Method: Shifting the Bottleneck from Algorithm to RAM", "categories": ["cs.DS"], "comment": null, "summary": "We present a scalable, high-performance algorithm that deterministically\nsolves large-scale instances of the Traveling Salesman problem (in its\nasymmetric version, ATSP) to optimality using commercially available computing\nhardware. By combining an efficient heuristic warm start, capable of achieving\nnear-optimality within seconds in some cases, with a subtour elimination\nstrategy that removes the need for traditional MTZ constraints, our approach\nconsistently resolves instances up to 5,000 nodes (approximately 25 million\nbinary variables) in record time on widely accessible computers, with eight\nlogical processors. We demonstrate reproducible results with convergence rates\ncomparable to those of high-performance computing frameworks. Real-time\niteration tracking and an adaptable interface allow seamless integration into\nscheduling workflows in logistics, bioinformatics, and astronomy. Designed to\nstreamline solutions to large-scale TSP problems across disciplines, our\napproach is benchmarked against widely used public datasets, offering a\ndeterministic, resource-efficient alternative to conventional solvers that rely\non supercomputing hardware. Our GTA (Gurobi Tabu Algorithm) algorithm is a\nfundamental shift of TSP solution bottleneck from algorithmic complexity to the\nunderlying hardware (RAM and system memory), which is a highly desirable\ncharacteristic.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u6269\u5c55\u3001\u9ad8\u6027\u80fd\u7b97\u6cd5GTA\u89e3\u51b3\u5927\u89c4\u6a21ATSP\u95ee\u9898\uff0c\u6548\u7387\u9ad8\u4e14\u80fd\u96c6\u6210\u5230\u591a\u9886\u57df\u5de5\u4f5c\u6d41\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u65c5\u884c\u5546\u95ee\u9898\uff08ATSP\uff09\uff0c\u63d0\u4f9b\u6bd4\u4f9d\u8d56\u8d85\u7ea7\u8ba1\u7b97\u786c\u4ef6\u7684\u4f20\u7edf\u6c42\u89e3\u5668\u66f4\u9ad8\u6548\u7684\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u9ad8\u6548\u542f\u53d1\u5f0f\u70ed\u542f\u52a8\u548c\u5b50\u56de\u8def\u6d88\u9664\u7b56\u7565\uff0c\u53bb\u9664\u4f20\u7edfMTZ\u7ea6\u675f\u3002", "result": "\u80fd\u5728\u666e\u901a8\u903b\u8f91\u5904\u7406\u5668\u8ba1\u7b97\u673a\u4e0a\u521b\u7eaa\u5f55\u65f6\u95f4\u89e3\u51b3\u6700\u591a5000\u8282\u70b9\u7684\u5b9e\u4f8b\uff0c\u6536\u655b\u7387\u4e0e\u9ad8\u6027\u80fd\u8ba1\u7b97\u6846\u67b6\u76f8\u5f53\uff0c\u7ed3\u679c\u53ef\u590d\u73b0\u3002", "conclusion": "GTA\u7b97\u6cd5\u5c06TSP\u89e3\u51b3\u65b9\u6848\u74f6\u9888\u4ece\u7b97\u6cd5\u590d\u6742\u6027\u8f6c\u79fb\u5230\u786c\u4ef6\uff0c\u9002\u5408\u8de8\u5b66\u79d1\u5927\u89c4\u6a21TSP\u95ee\u9898\u6c42\u89e3\u3002"}}
{"id": "2509.13637", "pdf": "https://arxiv.org/pdf/2509.13637", "abs": "https://arxiv.org/abs/2509.13637", "authors": ["Yasunori Akagi", "Takeshi Kurashima"], "title": "Delta Matters: An Analytically Tractable Model for $\u03b2$-$\u03b4$ Discounting Agents", "categories": ["cs.GT"], "comment": null, "summary": "Humans exhibit time-inconsistent behavior, in which planned actions diverge\nfrom executed actions. Understanding time inconsistency and designing\nappropriate interventions is a key research challenge in computer science and\nbehavioral economics. Previous work focuses on progress-based tasks and derives\na closed-form description of agent behavior, from which they obtain optimal\nintervention strategies. They model time-inconsistency using the\n$\\beta$-$\\delta$ discounting (quasi-hyperbolic discounting), but the analysis\nis limited to the case $\\delta = 1$. In this paper, we relax that constraint\nand show that a closed-form description of agent behavior remains possible for\nthe general case $0 < \\delta \\le 1$. Based on this result, we derive the\nconditions under which agents abandon tasks and develop efficient methods for\ncomputing optimal interventions. Our analysis reveals that agent behavior and\noptimal interventions depend critically on the value of $\\delta$, suggesting\nthat fixing $\\delta = 1$ in many prior studies may unduly simplify real-world\ndecision-making processes.", "AI": {"tldr": "\u672c\u6587\u653e\u5bbd\u5148\u524d\u7814\u7a76\u5bf9\u65f6\u95f4\u4e0d\u4e00\u81f4\u6027\u5efa\u6a21\u65f6\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u7ed9\u51fa\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u5c01\u95ed\u5f62\u5f0f\u63cf\u8ff0\uff0c\u63a8\u5bfc\u4efb\u52a1\u653e\u5f03\u6761\u4ef6\u548c\u6700\u4f18\u5e72\u9884\u8ba1\u7b97\u65b9\u6cd5\uff0c\u6307\u51fa\u5148\u524d\u7814\u7a76\u56fa\u5b9a\u53c2\u6570\u53ef\u80fd\u8fc7\u5ea6\u7b80\u5316\u51b3\u7b56\u8fc7\u7a0b\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u5bf9\u65f6\u95f4\u4e0d\u4e00\u81f4\u6027\u7684\u5206\u6790\u5c40\u9650\u4e8e\u03b4 = 1\u7684\u60c5\u51b5\uff0c\u9700\u8981\u653e\u5bbd\u7ea6\u675f\u4ee5\u66f4\u8d34\u5408\u5b9e\u9645\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u653e\u5bbd\u03b4 = 1\u7684\u7ea6\u675f\uff0c\u5bf90 < \u03b4 \u2264 1\u7684\u4e00\u822c\u60c5\u51b5\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5f97\u51fa\u4e00\u822c\u60c5\u51b5\u4e0b\u4ee3\u7406\u884c\u4e3a\u7684\u5c01\u95ed\u5f62\u5f0f\u63cf\u8ff0\uff0c\u63a8\u5bfc\u4ee3\u7406\u653e\u5f03\u4efb\u52a1\u7684\u6761\u4ef6\u548c\u8ba1\u7b97\u6700\u4f18\u5e72\u9884\u7684\u6709\u6548\u65b9\u6cd5\u3002", "conclusion": "\u4ee3\u7406\u884c\u4e3a\u548c\u6700\u4f18\u5e72\u9884\u5173\u952e\u53d6\u51b3\u4e8e\u03b4\u7684\u503c\uff0c\u5148\u524d\u7814\u7a76\u56fa\u5b9a\u03b4 = 1\u53ef\u80fd\u8fc7\u5ea6\u7b80\u5316\u73b0\u5b9e\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2509.13562", "pdf": "https://arxiv.org/pdf/2509.13562", "abs": "https://arxiv.org/abs/2509.13562", "authors": ["Yifan Liu", "Qianfeng Wen", "Mark Zhao", "Jiazhou Liang", "Scott Sanner"], "title": "MA-DPR: Manifold-aware Distance Metrics for Dense Passage Retrieval", "categories": ["cs.IR"], "comment": "19 pages, 8 figures", "summary": "Dense Passage Retrieval (DPR) typically relies on Euclidean or cosine\ndistance to measure query-passage relevance in embedding space, which is\neffective when embeddings lie on a linear manifold. However, our experiments\nacross DPR benchmarks suggest that embeddings often lie on lower-dimensional,\nnon-linear manifolds, especially in out-of-distribution (OOD) settings, where\ncosine and Euclidean distance fail to capture semantic similarity. To address\nthis limitation, we propose a manifold-aware distance metric for DPR (MA-DPR)\nthat models the intrinsic manifold structure of passages using a nearest\nneighbor graph and measures query-passage distance based on their shortest path\nin this graph. We show that MA-DPR outperforms Euclidean and cosine distances\nby up to 26% on OOD passage retrieval with comparable in-distribution\nperformance across various embedding models while incurring a minimal increase\nin query inference time. Empirical evidence suggests that manifold-aware\ndistance allows DPR to leverage context from related neighboring passages,\nmaking it effective even in the absence of direct semantic overlap. MADPR can\nbe applied to a wide range of dense embedding and retrieval tasks, offering\npotential benefits across a wide spectrum of domains.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8eDPR\u7684\u6d41\u5f62\u611f\u77e5\u8ddd\u79bb\u5ea6\u91cfMA - DPR\uff0c\u5728OOD\u6bb5\u843d\u68c0\u7d22\u4e0a\u8868\u73b0\u66f4\u597d\u4e14\u9002\u7528\u591a\u79cd\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edfDPR\u4f7f\u7528\u7684\u6b27\u6c0f\u6216\u4f59\u5f26\u8ddd\u79bb\u5728\u5d4c\u5165\u4f4d\u4e8e\u4f4e\u7ef4\u975e\u7ebf\u6027\u6d41\u5f62\uff08\u5c24\u5176\u662fOOD\u8bbe\u7f6e\uff09\u65f6\uff0c\u65e0\u6cd5\u6355\u6349\u8bed\u4e49\u76f8\u4f3c\u6027\u3002", "method": "\u63d0\u51faMA - DPR\uff0c\u7528\u6700\u8fd1\u90bb\u56fe\u5efa\u6a21\u6bb5\u843d\u7684\u5185\u5728\u6d41\u5f62\u7ed3\u6784\uff0c\u57fa\u4e8e\u56fe\u4e2d\u6700\u77ed\u8def\u5f84\u6d4b\u91cf\u67e5\u8be2 - \u6bb5\u843d\u8ddd\u79bb\u3002", "result": "MA - DPR\u5728OOD\u6bb5\u843d\u68c0\u7d22\u4e0a\u6bd4\u6b27\u6c0f\u548c\u4f59\u5f26\u8ddd\u79bb\u6700\u591a\u9ad826%\uff0c\u5728\u5206\u5e03\u5185\u6027\u80fd\u76f8\u5f53\uff0c\u67e5\u8be2\u63a8\u7406\u65f6\u95f4\u589e\u52a0\u6781\u5c11\u3002", "conclusion": "\u6d41\u5f62\u611f\u77e5\u8ddd\u79bb\u4f7fDPR\u80fd\u5229\u7528\u76f8\u90bb\u6bb5\u843d\u4e0a\u4e0b\u6587\uff0cMA - DPR\u53ef\u7528\u4e8e\u591a\u79cd\u5bc6\u96c6\u5d4c\u5165\u548c\u68c0\u7d22\u4efb\u52a1\u3002"}}
{"id": "2509.13325", "pdf": "https://arxiv.org/pdf/2509.13325", "abs": "https://arxiv.org/abs/2509.13325", "authors": ["Matteo Zanotto", "Leonardo Vicentini", "Redi Vreto", "Francesco Lumpp", "Diego Braga", "Sandro Fiore"], "title": "A User-centric Kubernetes-based Architecture for Green Cloud Computing", "categories": ["cs.DC"], "comment": null, "summary": "To meet the increasing demand for cloud computing services, the scale and\nnumber of data centers keeps increasing worldwide. This growth comes at the\ncost of increased electricity consumption, which directly correlates to CO2\nemissions, the main driver of climate change. As such, researching ways to\nreduce cloud computing emissions is more relevant than ever. However, although\ncloud providers are reportedly already working near optimal power efficiency,\nthey fail in providing precise sustainability reporting. This calls for further\nimprovements on the cloud computing consumer's side. To this end, in this paper\nwe propose a user-centric, Kubernetes-based architecture for green cloud\ncomputing. We implement a carbon intensity forecaster and we use it to schedule\nworkloads based on the availability of green energy, exploiting both regional\nand temporal variations to minimize emissions. We evaluate our system using\nreal-world traces of cloud workloads execution comparing the achieved carbon\nemission savings against a baseline round-robin scheduler. Our findings\nindicate that our system can achieve up to a 13% reduction in emissions in a\nstrict scenario with heavy limitations on the available resources.", "AI": {"tldr": "\u4e3a\u51cf\u5c11\u4e91\u8ba1\u7b97\u78b3\u6392\u653e\uff0c\u63d0\u51fa\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u3001\u57fa\u4e8eKubernetes\u7684\u7eff\u8272\u4e91\u8ba1\u7b97\u67b6\u6784\uff0c\u8bc4\u4f30\u663e\u793a\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u53ef\u51cf\u639213%\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u89c4\u6a21\u6269\u5927\u81f4\u7535\u529b\u6d88\u8017\u548c\u78b3\u6392\u653e\u589e\u52a0\uff0c\u4e91\u63d0\u4f9b\u5546\u867d\u63a5\u8fd1\u6700\u4f18\u80fd\u6548\u4f46\u7f3a\u4e4f\u7cbe\u786e\u53ef\u6301\u7eed\u6027\u62a5\u544a\uff0c\u9700\u4ece\u6d88\u8d39\u8005\u7aef\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u3001\u57fa\u4e8eKubernetes\u7684\u67b6\u6784\uff0c\u5b9e\u73b0\u78b3\u5f3a\u5ea6\u9884\u6d4b\u5668\uff0c\u57fa\u4e8e\u7eff\u8272\u80fd\u6e90\u53ef\u7528\u6027\u8c03\u5ea6\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5229\u7528\u533a\u57df\u548c\u65f6\u95f4\u5dee\u5f02\u51cf\u6392\u3002", "result": "\u4e0e\u57fa\u7ebf\u8f6e\u8be2\u8c03\u5ea6\u5668\u76f8\u6bd4\uff0c\u5728\u8d44\u6e90\u4e25\u683c\u53d7\u9650\u573a\u666f\u4e0b\u7cfb\u7edf\u53ef\u5b9e\u73b0\u9ad8\u8fbe13%\u7684\u51cf\u6392\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u67b6\u6784\u80fd\u6709\u6548\u51cf\u5c11\u4e91\u8ba1\u7b97\u78b3\u6392\u653e\u3002"}}
{"id": "2509.13721", "pdf": "https://arxiv.org/pdf/2509.13721", "abs": "https://arxiv.org/abs/2509.13721", "authors": ["Kaustav Saha", "Ishaan R Kale", "Vivek Patel", "Anand J Kulkarni", "Puskaraj D Sonawwanay"], "title": "Snail Homing and Mating Search Algorithm for Weight Optimization of Stepped-Transmission Shaft", "categories": ["cs.NE"], "comment": null, "summary": "In this paper, the steeped-transmission shaft design problem is proposed for\nweight optimization. The bio-inspired search-based Snail Homing and Mating\nSearch (SHMS) algorithm is utilized to solve the problem. It is inspired by the\nsocial behaviour of snails and their inherent nature of finding better homes,\nand mate. The proposed steeped-transmission shaft design problem is modelled\nconsidering the fatigue loading, combined bending, torsion loads, and the\nprinciple of Modified Goodman criteria. The forces diagram and the bending\nmoment diagrams are obtained using the MDSOLIDS software. The forces and\nbending moment are then used to mathematical model the objective function and\nconstraints. The SHMS algorithm has yielded the desired solution with\nreasonable computational cost. The constraints are handled using a static\npenalty function approach. The statistical results obtained using SHMS\nalgorithm are further used for generating CAD model. The analysis is carried\nout in ANSYS Workbench. Further, the deflection obtained from SHMS algorithm\nand ANSYS Workbench are compared and results are discussed in details.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9636\u68af\u4f20\u52a8\u8f74\u8bbe\u8ba1\u95ee\u9898\u8fdb\u884c\u91cd\u91cf\u4f18\u5316\uff0c\u7528SHMS\u7b97\u6cd5\u6c42\u89e3\uff0c\u5efa\u6a21\u3001\u5206\u6790\u5e76\u5bf9\u6bd4\u7ed3\u679c\u3002", "motivation": "\u5bf9\u9636\u68af\u4f20\u52a8\u8f74\u8bbe\u8ba1\u8fdb\u884c\u91cd\u91cf\u4f18\u5316\u3002", "method": "\u5229\u7528\u53d7\u8717\u725b\u884c\u4e3a\u542f\u53d1\u7684SHMS\u7b97\u6cd5\uff0c\u7ed3\u5408\u75b2\u52b3\u52a0\u8f7d\u3001\u7ec4\u5408\u8f7d\u8377\u548c\u4fee\u6b63\u53e4\u5fb7\u66fc\u51c6\u5219\u5efa\u6a21\uff0c\u7528MDSOLIDS\u8f6f\u4ef6\u83b7\u53d6\u529b\u548c\u5f2f\u77e9\u56fe\uff0c\u7528\u9759\u6001\u60e9\u7f5a\u51fd\u6570\u5904\u7406\u7ea6\u675f\u3002", "result": "SHMS\u7b97\u6cd5\u4ee5\u5408\u7406\u8ba1\u7b97\u6210\u672c\u5f97\u5230\u7406\u60f3\u89e3\uff0c\u7528\u7edf\u8ba1\u7ed3\u679c\u751f\u6210CAD\u6a21\u578b\uff0c\u5728ANSYS Workbench\u5206\u6790\u5e76\u5bf9\u6bd4\u6320\u5ea6\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\u7ed3\u8bba\uff0c\u4f46\u901a\u8fc7\u7b97\u6cd5\u6c42\u89e3\u548c\u5bf9\u6bd4\u5206\u6790\u4e3a\u9636\u68af\u4f20\u52a8\u8f74\u8bbe\u8ba1\u4f18\u5316\u63d0\u4f9b\u4e86\u65b9\u6cd5\u3002"}}
{"id": "2509.13332", "pdf": "https://arxiv.org/pdf/2509.13332", "abs": "https://arxiv.org/abs/2509.13332", "authors": ["Pratik Jayarao", "Himanshu Gupta", "Neeraj Varshney", "Chaitanya Dwivedi"], "title": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly adopted as automated judges\nin benchmarking and reward modeling, ensuring their reliability, efficiency,\nand robustness has become critical. In this work, we present a systematic\ncomparison of \"thinking\" and \"non-thinking\" LLMs in the LLM-as-a-judge paradigm\nusing open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B\nparameters). We evaluate both accuracy and computational efficiency (FLOPs) on\nRewardBench tasks, and further examine augmentation strategies for non-thinking\nmodels, including in-context learning, rubric-guided judging, reference-based\nevaluation, and n-best aggregation. Our results show that despite these\nenhancements, non-thinking models generally fall short of their thinking\ncounterparts. Our results show that thinking models achieve approximately 10%\npoints higher accuracy with little overhead (under 2x), in contrast to\naugmentation strategies like few-shot learning, which deliver modest gains at a\nhigher cost (>8x). Bias and robustness analyses further demonstrate that\nthinking models maintain significantly greater consistency under a variety of\nbias conditions such as positional, bandwagon, identity, diversity, and random\nbiases (6% higher on average). We further extend our experiments to the\nmultilingual setting and our results confirm that explicit reasoning extends\nits benefits beyond English. Overall, our work results in several important\nfindings that provide systematic evidence that explicit reasoning offers clear\nadvantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency\nbut also in robustness.", "AI": {"tldr": "\u672c\u6587\u7528\u5f00\u6e90\u5c0f\u5c3a\u5bf8Qwen 3\u6a21\u578b\u7cfb\u7edf\u6bd4\u8f83\u4e86\u601d\u7ef4\u548c\u975e\u601d\u7ef4\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f5c\u4e3a\u8bc4\u5224\u8005\u65f6\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u601d\u7ef4\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u4e0a\u66f4\u4f18\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u81ea\u52a8\u8bc4\u5224\u8005\uff0c\u786e\u4fdd\u5176\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u5c0f\u5c3a\u5bf8Qwen 3\u6a21\u578b\uff0c\u5728RewardBench\u4efb\u52a1\u4e0a\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u7814\u7a76\u975e\u601d\u7ef4\u6a21\u578b\u7684\u589e\u5f3a\u7b56\u7565\uff0c\u8fdb\u884c\u504f\u5dee\u548c\u9c81\u68d2\u6027\u5206\u6790\uff0c\u5e76\u6269\u5c55\u5230\u591a\u8bed\u8a00\u573a\u666f\u3002", "result": "\u975e\u601d\u7ef4\u6a21\u578b\u5373\u4fbf\u6709\u589e\u5f3a\u7b56\u7565\u4ecd\u4e0d\u5982\u601d\u7ef4\u6a21\u578b\uff0c\u601d\u7ef4\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u7ea610%\u4e14\u5f00\u9500\u5c0f\uff0c\u5728\u591a\u79cd\u504f\u5dee\u6761\u4ef6\u4e0b\u66f4\u4e00\u81f4\uff0c\u591a\u8bed\u8a00\u573a\u666f\u4e2d\u663e\u5f0f\u63a8\u7406\u4e5f\u6709\u76ca\u3002", "conclusion": "\u663e\u5f0f\u63a8\u7406\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8303\u5f0f\u4e2d\uff0c\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u90fd\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2509.13436", "pdf": "https://arxiv.org/pdf/2509.13436", "abs": "https://arxiv.org/abs/2509.13436", "authors": ["Evan Eisinger", "Michael A. Heroux"], "title": "Is Research Software Science a Metascience?", "categories": ["cs.SE"], "comment": "5 pages", "summary": "As research increasingly relies on computational methods, the reliability of\nscientific results depends on the quality, reproducibility, and transparency of\nresearch software. Ensuring these qualities is critical for scientific\nintegrity and discovery. This paper asks whether Research Software Science\n(RSS)--the empirical study of how research software is developed and\nused--should be considered a form of metascience, the science of science.\nClassification matters because it could affect recognition, funding, and\nintegration of RSS into research improvement. We define metascience and RSS,\ncompare their principles and objectives, and examine their overlaps. Arguments\nfor classification highlight shared commitments to reproducibility,\ntransparency, and empirical study of research processes. Arguments against\nportraying RSS as a specialized domain focused on a tool rather than the\nbroader scientific enterprise. Our analysis finds RSS advances core goals of\nmetascience, especially in computational reproducibility, and bridges\ntechnical, social, and cognitive aspects of research. Its classification\ndepends on whether one adopts a broad definition of metascience--any empirical\neffort to improve science--or a narrow one focused on systemic and\nepistemological structures. We argue RSS is best understood as a distinct\ninterdisciplinary domain that aligns with, and in some definitions fits within,\nmetascience. Recognizing it as such can strengthen its role in improving\nreliability, justify funding, and elevate software development in research\ninstitutions. Regardless of classification, applying scientific rigor to\nresearch software ensures the tools of discovery meet the standards of the\ndiscoveries themselves.", "AI": {"tldr": "\u63a2\u8ba8\u7814\u7a76\u8f6f\u4ef6\u79d1\u5b66\uff08RSS\uff09\u662f\u5426\u5c5e\u4e8e\u5143\u79d1\u5b66\uff0c\u5206\u6790\u540e\u8ba4\u4e3aRSS\u662f\u72ec\u7279\u8de8\u5b66\u79d1\u9886\u57df\uff0c\u4e0e\u5143\u79d1\u5b66\u5951\u5408\uff0c\u8ba4\u53ef\u5176\u5730\u4f4d\u6709\u76ca\u79d1\u7814\u3002", "motivation": "\u79d1\u7814\u4f9d\u8d56\u8ba1\u7b97\u65b9\u6cd5\uff0c\u79d1\u7814\u7ed3\u679c\u53ef\u9760\u6027\u53d6\u51b3\u4e8e\u7814\u7a76\u8f6f\u4ef6\u8d28\u91cf\u7b49\uff0c\u9700\u660e\u786eRSS\u5206\u7c7b\u4ee5\u5f71\u54cd\u5176\u8ba4\u53ef\u3001\u8d44\u52a9\u548c\u878d\u5165\u79d1\u7814\u6539\u8fdb\u3002", "method": "\u5b9a\u4e49\u5143\u79d1\u5b66\u548cRSS\uff0c\u6bd4\u8f83\u539f\u5219\u4e0e\u76ee\u6807\uff0c\u5206\u6790\u91cd\u53e0\u90e8\u5206\uff0c\u5217\u4e3e\u652f\u6301\u548c\u53cd\u5bf9\u5206\u7c7b\u7684\u8bba\u636e\u3002", "result": "RSS\u63a8\u8fdb\u5143\u79d1\u5b66\u6838\u5fc3\u76ee\u6807\uff0c\u5c24\u5176\u5728\u8ba1\u7b97\u53ef\u91cd\u590d\u6027\u65b9\u9762\uff0c\u5176\u5206\u7c7b\u53d6\u51b3\u4e8e\u5bf9\u5143\u79d1\u5b66\u7684\u5bbd\u7a84\u5b9a\u4e49\u3002", "conclusion": "RSS\u662f\u72ec\u7279\u8de8\u5b66\u79d1\u9886\u57df\uff0c\u4e0e\u5143\u79d1\u5b66\u76f8\u7b26\uff0c\u8ba4\u53ef\u5176\u5730\u4f4d\u53ef\u5f3a\u5316\u5176\u4f5c\u7528\uff0c\u4e25\u683c\u5bf9\u5f85\u7814\u7a76\u8f6f\u4ef6\u53ef\u786e\u4fdd\u79d1\u7814\u5de5\u5177\u8fbe\u6807\u3002"}}
{"id": "2509.13374", "pdf": "https://arxiv.org/pdf/2509.13374", "abs": "https://arxiv.org/abs/2509.13374", "authors": ["Helin Zhao", "Junchi Shen"], "title": "Valuation of Exotic Options and Counterparty Games Based on Conditional Diffusion", "categories": ["q-fin.PR", "cs.LG", "q-fin.RM", "91G60", "I.2"], "comment": "28 pages, 12 figures", "summary": "This paper addresses the challenges of pricing exotic options and structured\nproducts, which traditional models often fail to handle due to their inability\nto capture real-world market phenomena like fat-tailed distributions and\nvolatility clustering. We introduce a Diffusion-Conditional Probability Model\n(DDPM) to generate more realistic price paths. Our method incorporates a\ncomposite loss function with financial-specific features, and we propose a P-Q\ndynamic game framework for evaluating the model's economic value through\nadversarial backtesting. Static validation shows our P-model effectively\nmatches market mean and volatility. In dynamic games, it demonstrates\nsignificantly higher profitability than a traditional Monte Carlo-based model\nfor European and Asian options. However, the model shows limitations in pricing\nproducts highly sensitive to extreme events, such as snowballs and\naccumulators, because it tends to underestimate tail risks. The study concludes\nthat diffusion models hold significant potential for enhancing pricing\naccuracy, though further research is needed to improve their ability to model\nextreme market risks.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165DDPM\u6a21\u578b\u5b9a\u4ef7\u5947\u5f02\u671f\u6743\u548c\u7ed3\u6784\u5316\u4ea7\u54c1\uff0c\u5728\u9759\u6001\u9a8c\u8bc1\u548c\u52a8\u6001\u535a\u5f08\u4e2d\u6709\u8f83\u597d\u8868\u73b0\uff0c\u4f46\u5bf9\u6781\u7aef\u4e8b\u4ef6\u654f\u611f\u4ea7\u54c1\u5b9a\u4ef7\u6709\u5c40\u9650\uff0c\u6269\u6563\u6a21\u578b\u6709\u63d0\u5347\u5b9a\u4ef7\u51c6\u786e\u6027\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u73b0\u5b9e\u5e02\u573a\u73b0\u8c61\uff0c\u96be\u4ee5\u5bf9\u5947\u5f02\u671f\u6743\u548c\u7ed3\u6784\u5316\u4ea7\u54c1\u5b9a\u4ef7\u3002", "method": "\u5f15\u5165Diffusion - Conditional Probability Model (DDPM)\u751f\u6210\u4ef7\u683c\u8def\u5f84\uff0c\u91c7\u7528\u542b\u91d1\u878d\u7279\u5b9a\u7279\u5f81\u7684\u590d\u5408\u635f\u5931\u51fd\u6570\uff0c\u63d0\u51faP - Q\u52a8\u6001\u535a\u5f08\u6846\u67b6\u8fdb\u884c\u5bf9\u6297\u56de\u6d4b\u3002", "result": "\u9759\u6001\u9a8c\u8bc1\u4e2dP\u6a21\u578b\u80fd\u5339\u914d\u5e02\u573a\u5747\u503c\u548c\u6ce2\u52a8\u7387\uff1b\u52a8\u6001\u535a\u5f08\u4e2d\uff0c\u5bf9\u6b27\u5f0f\u548c\u4e9a\u5f0f\u671f\u6743\u7684\u76c8\u5229\u80fd\u529b\u663e\u8457\u9ad8\u4e8e\u4f20\u7edf\u8499\u7279\u5361\u7f57\u6a21\u578b\uff1b\u5bf9\u96ea\u7403\u548c\u7d2f\u79ef\u671f\u6743\u7b49\u5bf9\u6781\u7aef\u4e8b\u4ef6\u654f\u611f\u4ea7\u54c1\u5b9a\u4ef7\u6709\u5c40\u9650\uff0c\u4f4e\u4f30\u5c3e\u90e8\u98ce\u9669\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u6709\u63d0\u5347\u5b9a\u4ef7\u51c6\u786e\u6027\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u63d0\u9ad8\u5bf9\u6781\u7aef\u5e02\u573a\u98ce\u9669\u7684\u5efa\u6a21\u80fd\u529b\u3002"}}
{"id": "2509.13425", "pdf": "https://arxiv.org/pdf/2509.13425", "abs": "https://arxiv.org/abs/2509.13425", "authors": ["Julian Evan Chrisnanto", "Yulison Herry Chrisnanto", "Ferry Faizal"], "title": "Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics", "categories": ["cs.LG", "physics.app-ph", "92D25, 35K57, 68T07", "I.2.6; J.3; G.1.8"], "comment": "20 pages, 11 figures. A preprint on using a unified physics-informed\n  neural network framework to model predator-prey dynamics", "summary": "Ecological systems exhibit complex multi-scale dynamics that challenge\ntraditional modeling. New methods must capture temporal oscillations and\nemergent spatiotemporal patterns while adhering to conservation principles. We\npresent the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,\na deep learning architecture integrating physics-informed neural networks\n(PINNs) and conservation laws to model predator-prey dynamics across\ndimensional scales. The framework provides a unified solution for both ordinary\n(ODE) and partial (PDE) differential equation systems, describing temporal\ncycles and reaction-diffusion patterns within a single neural network\narchitecture. Our methodology uses automatic differentiation to enforce physics\nconstraints and adaptive loss weighting to balance data fidelity with physical\nconsistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%\ncorrelation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures\ncomplex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).\nValidation confirms conservation law adherence within 0.5% and shows a 10-50x\ncomputational speedup for inference compared to numerical solvers. USPIL also\nenables mechanistic understanding through interpretable physics constraints,\nfacilitating parameter discovery and sensitivity analysis not possible with\npurely data-driven methods. Its ability to transition between dimensional\nformulations opens new avenues for multi-scale ecological modeling. These\ncapabilities make USPIL a transformative tool for ecological forecasting,\nconservation planning, and understanding ecosystem resilience, establishing\nphysics-informed deep learning as a powerful and scientifically rigorous\nparadigm.", "AI": {"tldr": "\u63d0\u51faUSPIL\u6846\u67b6\u7528\u4e8e\u591a\u5c3a\u5ea6\u751f\u6001\u5efa\u6a21\uff0c\u5e94\u7528\u4e8eLotka - Volterra\u7cfb\u7edf\u8868\u73b0\u826f\u597d\uff0c\u6709\u8ba1\u7b97\u901f\u5ea6\u4f18\u52bf\u548c\u65b0\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u751f\u6001\u7cfb\u7edf\u590d\u6742\u591a\u5c3a\u5ea6\u52a8\u6001\u6311\u6218\u4f20\u7edf\u5efa\u6a21\uff0c\u9700\u65b0\u65b9\u6cd5\u6355\u6349\u65f6\u7a7a\u6a21\u5f0f\u5e76\u9075\u5faa\u5b88\u6052\u539f\u5219\u3002", "method": "\u63d0\u51faUSPIL\u6846\u67b6\uff0c\u96c6\u6210\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u548c\u5b88\u6052\u5b9a\u5f8b\uff0c\u7528\u81ea\u52a8\u5fae\u5206\u548c\u81ea\u9002\u5e94\u635f\u5931\u52a0\u6743\u3002", "result": "\u5e94\u7528\u4e8eLotka - Volterra\u7cfb\u7edf\uff0c1D\u65f6\u95f4\u52a8\u6001\u76f8\u5173\u5ea698.9%\uff0c2D\u7cfb\u7edf\u6355\u83b7\u590d\u6742\u87ba\u65cb\u6ce2\uff0c\u9a8c\u8bc1\u5b88\u6052\u5f8b\u8bef\u5dee\u57280.5%\u5185\uff0c\u63a8\u7406\u8ba1\u7b97\u901f\u5ea6\u63d0\u534710 - 50\u500d\u3002", "conclusion": "USPIL\u662f\u751f\u6001\u9884\u6d4b\u3001\u4fdd\u62a4\u89c4\u5212\u7b49\u7684\u53d8\u9769\u6027\u5de5\u5177\uff0c\u786e\u7acb\u7269\u7406\u4fe1\u606f\u6df1\u5ea6\u5b66\u4e60\u8303\u5f0f\u3002"}}
{"id": "2509.14039", "pdf": "https://arxiv.org/pdf/2509.14039", "abs": "https://arxiv.org/abs/2509.14039", "authors": ["Marat Khusainov", "Marina Sheshukova", "Alain Durmus", "Sergey Samsonov"], "title": "On the Rate of Gaussian Approximation for Linear Regression Problems", "categories": ["stat.ML", "cs.LG", "math.OC", "60F05, 62L20, 93E35"], "comment": null, "summary": "In this paper, we consider the problem of Gaussian approximation for the\nonline linear regression task. We derive the corresponding rates for the\nsetting of a constant learning rate and study the explicit dependence of the\nconvergence rate upon the problem dimension $d$ and quantities related to the\ndesign matrix. When the number of iterations $n$ is known in advance, our\nresults yield the rate of normal approximation of order $\\sqrt{\\log{n}/n}$,\nprovided that the sample size $n$ is large enough.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.13448", "pdf": "https://arxiv.org/pdf/2509.13448", "abs": "https://arxiv.org/abs/2509.13448", "authors": ["Danila Valko", "Rohan Paranjpe", "Jorge Marx G\u00f3mez"], "title": "Outperforming Dijkstra on Sparse Graphs: The Lightning Network Use Case", "categories": ["cs.PF", "cs.DS", "cs.SI"], "comment": null, "summary": "Efficient routing is critical for payment channel networks (PCNs) such as the\nLightning Network (LN), where most clients currently rely on Dijkstra-based\nalgorithms for payment pathfinding. While Dijkstra's algorithm has long been\nregarded as optimal on sparse graphs, recent theoretical work challenges this\nview. The new Bounded Multi-Source Shortest Path (BMSSP) algorithm by Duan et\nal. theoretically achieves $O(m~log^{2/3}~n)$ runtime, which is asymptotically\nfaster than Dijkstra's $O(m + n~log~n)$ on sparse directed graphs. In this\npaper, we implement BMSSP on Rust and compare its performance against\nDijkstra's using real LN topology data. Our evaluation, based on multiple\nrandomized trials and statistical tests, shows that current implementations of\nBMSSP do not significantly outperform Dijkstra's in practice, and speedups are\nsmaller than what theory predicts, possibly due to implementation and constant\nfactor overheads. These results provide the first empirical evidence of BMSSP's\npotential to accelerate LN routing and inform future optimizations of PCN\npathfinding algorithms.", "AI": {"tldr": "\u672c\u6587\u5b9e\u73b0BMSSP\u7b97\u6cd5\u5e76\u4e0eDijkstra\u7b97\u6cd5\u5bf9\u6bd4\uff0c\u53d1\u73b0BMSSP\u5b9e\u9645\u672a\u663e\u8457\u4f18\u4e8eDijkstra\uff0c\u4e3a\u52a0\u901fLN\u8def\u7531\u63d0\u4f9b\u5b9e\u8bc1\u3002", "motivation": "\u9ad8\u6548\u8def\u7531\u5bf9\u652f\u4ed8\u901a\u9053\u7f51\u7edc\u81f3\u5173\u91cd\u8981\uff0c\u867dBMSSP\u7406\u8bba\u66f4\u5feb\uff0c\u4f46\u9700\u5b9e\u9645\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "method": "\u5728Rust\u4e2d\u5b9e\u73b0BMSSP\u7b97\u6cd5\uff0c\u7528\u771f\u5b9eLN\u62d3\u6251\u6570\u636e\u4e0eDijkstra\u7b97\u6cd5\u5bf9\u6bd4\uff0c\u8fdb\u884c\u591a\u6b21\u968f\u673a\u8bd5\u9a8c\u548c\u7edf\u8ba1\u6d4b\u8bd5\u3002", "result": "\u5f53\u524dBMSSP\u5b9e\u73b0\u672a\u663e\u8457\u4f18\u4e8eDijkstra\uff0c\u52a0\u901f\u6548\u679c\u5c0f\u4e8e\u7406\u8bba\u9884\u671f\uff0c\u53ef\u80fd\u56e0\u5b9e\u73b0\u548c\u5e38\u6570\u56e0\u5b50\u5f00\u9500\u3002", "conclusion": "\u4e3aBMSSP\u52a0\u901fLN\u8def\u7531\u63d0\u4f9b\u9996\u4efd\u5b9e\u8bc1\uff0c\u4e3aPCN\u8def\u5f84\u67e5\u627e\u7b97\u6cd5\u4f18\u5316\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2509.13578", "pdf": "https://arxiv.org/pdf/2509.13578", "abs": "https://arxiv.org/abs/2509.13578", "authors": ["Santiago Camara", "Jeanne Aublin"], "title": "In-between Transatlantic (Monetary) Disturbances", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper studies the spillovers of European Central Bank (ECB) interest\nrate shocks into the Canadian economy and compares them with those of the U.S.\nFederal Reserve (Fed). We combine a VAR model and local projection regressions\nwith identification strategies that explicitly purge information effects around\npolicy announcements. We find that an ECB rate hike leads to a depreciation of\nthe Canadian dollar and a sharp contraction in economic activity. The main\ntransmission channel is international trade: ECB shocks trigger a decline in\noil prices and exports, while leaving domestic financial conditions largely\nunaffected. By contrast, Fed shocks tighten Canadian financial conditions\nsignificantly, with more limited effects on trade flows. These findings show\nthat Canada is exposed to foreign monetary policy both directly and indirectly,\nthrough its integration in global financial and trade markets.", "AI": {"tldr": "\u7814\u7a76\u6b27\u592e\u884c\u548c\u7f8e\u8054\u50a8\u5229\u7387\u51b2\u51fb\u5bf9\u52a0\u62ff\u5927\u7ecf\u6d4e\u6ea2\u51fa\u6548\u5e94\uff0c\u53d1\u73b0\u4e24\u8005\u5f71\u54cd\u4e0d\u540c\uff0c\u52a0\u62ff\u5927\u901a\u8fc7\u91d1\u878d\u548c\u8d38\u6613\u5e02\u573a\u53d7\u56fd\u5916\u8d27\u5e01\u653f\u7b56\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u6b27\u592e\u884c\u5229\u7387\u51b2\u51fb\u5bf9\u52a0\u62ff\u5927\u7ecf\u6d4e\u7684\u6ea2\u51fa\u6548\u5e94\uff0c\u5e76\u4e0e\u7f8e\u8054\u50a8\u7684\u51b2\u51fb\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u7ed3\u5408VAR\u6a21\u578b\u548c\u5c40\u90e8\u6295\u5f71\u56de\u5f52\uff0c\u91c7\u7528\u8bc6\u522b\u7b56\u7565\u6d88\u9664\u653f\u7b56\u516c\u544a\u5468\u56f4\u7684\u4fe1\u606f\u6548\u5e94\u3002", "result": "\u6b27\u592e\u884c\u52a0\u606f\u4f7f\u52a0\u5143\u8d2c\u503c\u3001\u7ecf\u6d4e\u6d3b\u52a8\u6536\u7f29\uff0c\u4e3b\u8981\u901a\u8fc7\u56fd\u9645\u8d38\u6613\u4f20\u5bfc\uff1b\u7f8e\u8054\u50a8\u51b2\u51fb\u663e\u8457\u6536\u7d27\u52a0\u62ff\u5927\u91d1\u878d\u6761\u4ef6\uff0c\u5bf9\u8d38\u6613\u6d41\u52a8\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u52a0\u62ff\u5927\u901a\u8fc7\u5168\u7403\u91d1\u878d\u548c\u8d38\u6613\u5e02\u573a\u7684\u6574\u5408\uff0c\u76f4\u63a5\u548c\u95f4\u63a5\u53d7\u56fd\u5916\u8d27\u5e01\u653f\u7b56\u5f71\u54cd\u3002"}}
{"id": "2509.13950", "pdf": "https://arxiv.org/pdf/2509.13950", "abs": "https://arxiv.org/abs/2509.13950", "authors": ["Eya Ben Amar", "Nadhir Ben Rached", "Raul Tempone"], "title": "Hierarchical Importance Sampling for Estimating Occupation Time for SDE Solutions", "categories": ["math.NA", "cs.NA", "stat.CO"], "comment": null, "summary": "This study considers the estimation of the complementary cumulative\ndistribution function of the occupation time (i.e., the time spent below a\nthreshold) for a process governed by a stochastic differential equation. The\nfocus is on the right tail, where the underlying event becomes rare, and using\nvariance reduction techniques is essential to obtain computationally efficient\nestimates. Building on recent developments that relate importance sampling (IS)\nto stochastic optimal control, this work develops an optimal single level IS\n(SLIS) estimator based on the solution of an auxiliary Hamilton Jacobi Bellman\n(HJB) partial differential equation (PDE). The cost of solving the HJB-PDE is\nincorporated into the total computational work, and an optimized trade off\nbetween preprocessing and sampling is proposed to minimize the overall cost.\nThe SLIS approach is extended to the multilevel setting to enhance efficiency,\nyielding a multilevel IS (MLIS) estimator. A necessary and sufficient condition\nunder which the MLIS method outperforms the SLIS method is established, and a\ncommon likelihood MLIS formulation is introduced that satisfies this condition\nunder appropriate regularity assumptions. The classical multilevel Monte Carlo\ncomplexity theory can be extended to accommodate settings where the\nsingle-level variance varies with the discretization level. As a special case,\nthe variance-decay behavior observed in the IS framework stems from the zero\nvariance property of the optimal control. Notably, the total work complexity of\nMLIS can be better than an order of two. Numerical experiments in the context\nof fade duration estimation demonstrate the benefits of the proposed approach\nand validate these theoretical results.", "AI": {"tldr": "\u7814\u7a76\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u8fc7\u7a0b\u5360\u7528\u65f6\u95f4\u4e92\u8865\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u4f30\u8ba1\uff0c\u63d0\u51fa\u5355\u6c34\u5e73\u548c\u591a\u6c34\u5e73\u91cd\u8981\u6027\u62bd\u6837\u4f30\u8ba1\u5668\uff0c\u7ed9\u51fa\u591a\u6c34\u5e73\u4f18\u4e8e\u5355\u6c34\u5e73\u7684\u6761\u4ef6\uff0c\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5728\u5360\u7528\u65f6\u95f4\u4e92\u8865\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u53f3\u5c3e\u4f30\u8ba1\u4e2d\uff0c\u5e95\u5c42\u4e8b\u4ef6\u7f55\u89c1\uff0c\u9700\u7528\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u83b7\u9ad8\u6548\u4f30\u8ba1\u3002", "method": "\u57fa\u4e8e\u91cd\u8981\u6027\u62bd\u6837\u4e0e\u968f\u673a\u6700\u4f18\u63a7\u5236\u7684\u5173\u7cfb\uff0c\u6784\u5efa\u57fa\u4e8eHJB - PDE\u89e3\u7684\u6700\u4f18\u5355\u6c34\u5e73\u91cd\u8981\u6027\u62bd\u6837\u4f30\u8ba1\u5668\uff0c\u6269\u5c55\u5230\u591a\u6c34\u5e73\uff0c\u63d0\u51fa\u4f18\u5316\u9884\u5904\u7406\u548c\u62bd\u6837\u6743\u8861\u4ee5\u6700\u5c0f\u5316\u603b\u6210\u672c\u3002", "result": "\u5efa\u7acb\u591a\u6c34\u5e73\u91cd\u8981\u6027\u62bd\u6837\u65b9\u6cd5\u4f18\u4e8e\u5355\u6c34\u5e73\u7684\u5145\u8981\u6761\u4ef6\uff0c\u5f15\u5165\u6ee1\u8db3\u6761\u4ef6\u7684\u516c\u5f0f\uff0c\u7ecf\u5178\u591a\u5c42\u8499\u7279\u5361\u7f57\u590d\u6742\u5ea6\u7406\u8bba\u53ef\u6269\u5c55\uff0c\u591a\u6c34\u5e73\u603b\u5de5\u4f5c\u590d\u6742\u5ea6\u80fd\u4f18\u4e8e\u4e8c\u9636\u3002", "conclusion": "\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u52bf\u5e76\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002"}}
{"id": "2509.13978", "pdf": "https://arxiv.org/pdf/2509.13978", "abs": "https://arxiv.org/abs/2509.13978", "authors": ["Renan Souza", "Timothy Poteet", "Brian Etz", "Daniel Rosendo", "Amal Gueroudji", "Woong Shin", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology", "categories": ["cs.DC", "cs.AI", "cs.DB", "68M14, 68M20, 68T07", "C.2.4; D.1.3; I.2.0"], "comment": "Paper accepted in the proceedings of the ACM/IEEE Supercomputing\n  Conference (SC). Cite it as Renan Souza, Timothy Poteet, Brian Etz, Daniel\n  Rosendo, Amal Gueroudji, Woong Shin, Prasanna Balaprakash, and Rafael\n  Ferreira da Silva. 2025. LLM Agents for Interactive Workflow Provenance:\n  Reference Architecture and Evaluation Methodology. In SC Workshops (WORKS)", "summary": "Modern scientific discovery increasingly relies on workflows that process\ndata across the Edge, Cloud, and High Performance Computing (HPC) continuum.\nComprehensive and in-depth analyses of these data are critical for hypothesis\nvalidation, anomaly detection, reproducibility, and impactful findings.\nAlthough workflow provenance techniques support such analyses, at large scale,\nthe provenance data become complex and difficult to analyze. Existing systems\ndepend on custom scripts, structured queries, or static dashboards, limiting\ndata interaction. In this work, we introduce an evaluation methodology,\nreference architecture, and open-source implementation that leverages\ninteractive Large Language Model (LLM) agents for runtime data analysis. Our\napproach uses a lightweight, metadata-driven design that translates natural\nlanguage into structured provenance queries. Evaluations across LLaMA, GPT,\nGemini, and Claude, covering diverse query classes and a real-world chemistry\nworkflow, show that modular design, prompt tuning, and Retrieval-Augmented\nGeneration (RAG) enable accurate and insightful LLM agent responses beyond\nrecorded provenance.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u4ea4\u4e92\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u8fdb\u884c\u8fd0\u884c\u65f6\u6570\u636e\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u663e\u793a\u80fd\u5b9e\u73b0\u8d85\u8d8a\u8bb0\u5f55\u6eaf\u6e90\u7684\u51c6\u786e\u4e14\u6709\u6d1e\u5bdf\u529b\u7684\u54cd\u5e94\u3002", "motivation": "\u73b0\u4ee3\u79d1\u5b66\u53d1\u73b0\u4f9d\u8d56\u8de8\u8fb9\u7f18\u3001\u4e91\u4e0e\u9ad8\u6027\u80fd\u8ba1\u7b97\u7684\u6570\u636e\u5de5\u4f5c\u6d41\uff0c\u5de5\u4f5c\u6d41\u6eaf\u6e90\u6570\u636e\u5728\u5927\u89c4\u6a21\u65f6\u590d\u6742\u96be\u5206\u6790\uff0c\u73b0\u6709\u7cfb\u7edf\u9650\u5236\u6570\u636e\u4ea4\u4e92\u3002", "method": "\u5f15\u5165\u8bc4\u4f30\u65b9\u6cd5\u3001\u53c2\u8003\u67b6\u6784\u548c\u5f00\u6e90\u5b9e\u73b0\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u3001\u5143\u6570\u636e\u9a71\u52a8\u8bbe\u8ba1\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u6eaf\u6e90\u67e5\u8be2\u3002", "result": "\u5bf9LLaMA\u3001GPT\u3001Gemini\u548cClaude\u5728\u4e0d\u540c\u67e5\u8be2\u7c7b\u522b\u548c\u771f\u5b9e\u5316\u5b66\u5de5\u4f5c\u6d41\u4e0a\u7684\u8bc4\u4f30\uff0c\u663e\u793a\u6a21\u5757\u5316\u8bbe\u8ba1\u3001\u63d0\u793a\u8c03\u4f18\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6709\u6548\u3002", "conclusion": "\u5229\u7528\u4ea4\u4e92\u5f0fLLM\u4ee3\u7406\u7684\u65b9\u6cd5\u53ef\u5b9e\u73b0\u8d85\u8d8a\u8bb0\u5f55\u6eaf\u6e90\u7684\u51c6\u786e\u4e14\u6709\u6d1e\u5bdf\u529b\u7684\u54cd\u5e94\u3002"}}
{"id": "2509.13584", "pdf": "https://arxiv.org/pdf/2509.13584", "abs": "https://arxiv.org/abs/2509.13584", "authors": ["Yan S. Couto", "Cristina G. Fernandes"], "title": "Hardness of Dynamic Core and Truss Decompositions", "categories": ["cs.DS", "cs.CC"], "comment": "Full version of the paper accepted in WAOA 2025", "summary": "The k-core of a graph is its maximal subgraph with minimum degree at least k,\nand the core value of a vertex u is the largest k for which u is contained in\nthe k-core of the graph. Among cohesive subgraphs, k-core and its variants have\nreceived a lot of attention recently, particularly on dynamic graphs, as\nreported by Hanauer, Henzinger, and Schulz in their recent survey on dynamic\ngraph algorithms. We answer questions on k-core stated in the survey, proving\nthat there is no efficient dynamic algorithm for k-core or to find (2 -\n{\\epsilon})-approximations for the core values, unless we can improve\ndecade-long state-of-the-art algorithms in many areas including matrix\nmultiplication and satisfiability, based on the established OMv and SETH\nconjectures. Some of our results show that there is no dynamic algorithm for\nk-core asymptotically faster than the trivial ones. This explains why most\nrecent research papers in this area focus not on a generic efficient dynamic\nalgorithm, but on finding a bounded algorithm, which is fast when few core\nvalues change per update. However, we also prove that such bounded algorithms\ndo not exist, based on the OMv conjecture. We present lower bounds also for a\ndirected version of the problem, and for the edge variant of the problem, known\nas k-truss. On the positive side, we present a polylogarithmic dynamic\nalgorithm for 2-core.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u56fe\u7684k - \u6838\u95ee\u9898\uff0c\u8bc1\u660e\u9664\u975e\u6539\u8fdb\u591a\u4e2a\u9886\u57df\u7b97\u6cd5\uff0c\u5426\u5219\u65e0\u9ad8\u6548\u52a8\u6001\u7b97\u6cd5\uff0c\u8fd8\u8bc1\u660e\u6709\u754c\u7b97\u6cd5\u4e0d\u5b58\u5728\uff0c\u7ed9\u51fa\u6709\u5411\u548c\u8fb9\u53d8\u4f53\u95ee\u9898\u4e0b\u754c\uff0c\u63d0\u51fa2 - \u6838\u7684\u591a\u5bf9\u6570\u52a8\u6001\u7b97\u6cd5\u3002", "motivation": "\u56de\u7b54Hanauer\u7b49\u4eba\u5173\u4e8e\u52a8\u6001\u56fe\u7b97\u6cd5\u8c03\u67e5\u4e2d\u63d0\u51fa\u7684\u5173\u4e8ek - \u6838\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8eOMv\u548cSETH\u731c\u60f3\u8fdb\u884c\u7406\u8bba\u8bc1\u660e\u3002", "result": "\u8bc1\u660e\u65e0\u9ad8\u6548\u52a8\u6001\u7b97\u6cd5\u6c42k - \u6838\u6216\u6838\u5fc3\u503c\u7684(2 - \u03b5)\u8fd1\u4f3c\u503c\uff1b\u8bc1\u660e\u6709\u754c\u7b97\u6cd5\u4e0d\u5b58\u5728\uff1b\u7ed9\u51fa\u6709\u5411\u548ck - \u6841\u67b6\u95ee\u9898\u4e0b\u754c\uff1b\u63d0\u51fa2 - \u6838\u7684\u591a\u5bf9\u6570\u52a8\u6001\u7b97\u6cd5\u3002", "conclusion": "\u89e3\u91ca\u4e86\u76f8\u5173\u9886\u57df\u7814\u7a76\u591a\u805a\u7126\u4e8e\u6709\u754c\u7b97\u6cd5\u7684\u539f\u56e0\uff0c\u4e14\u57fa\u4e8e\u731c\u60f3\u8bc1\u660e\u6709\u754c\u7b97\u6cd5\u4e0d\u5b58\u5728\uff0c\u540c\u65f6\u7ed9\u51fa\u90e8\u5206\u6b63\u7ed3\u679c\u3002"}}
{"id": "2509.13653", "pdf": "https://arxiv.org/pdf/2509.13653", "abs": "https://arxiv.org/abs/2509.13653", "authors": ["Hang Ren", "Yulin Wu", "Shuhan Qi", "Jiajia Zhang", "Xiaozhen Sun", "Tianzi Ma", "Xuan Wang"], "title": "Efficient Last-Iterate Convergence in Regret Minimization via Adaptive Reward Transformation", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "Regret minimization is a powerful method for finding Nash equilibria in\nNormal-Form Games (NFGs) and Extensive-Form Games (EFGs), but it typically\nguarantees convergence only for the average strategy. However, computing the\naverage strategy requires significant computational resources or introduces\nadditional errors, limiting its practical applicability. The Reward\nTransformation (RT) framework was introduced to regret minimization to achieve\nlast-iterate convergence through reward function regularization. However, it\nfaces practical challenges: its performance is highly sensitive to manually\ntuned parameters, which often deviate from theoretical convergence conditions,\nleading to slow convergence, oscillations, or stagnation in local optima.\n  Inspired by previous work, we propose an adaptive technique to address these\nissues, ensuring better consistency between theoretical guarantees and\npractical performance for RT Regret Matching (RTRM), RT Counterfactual Regret\nMinimization (RTCFR), and their variants in solving NFGs and EFGs more\neffectively. Our adaptive methods dynamically adjust parameters, balancing\nexploration and exploitation while improving regret accumulation, ultimately\nenhancing asymptotic last-iterate convergence and achieving linear convergence.\nExperimental results demonstrate that our methods significantly accelerate\nconvergence, outperforming state-of-the-art algorithms.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u6280\u672f\u89e3\u51b3\u5956\u52b1\u53d8\u6362\u6846\u67b6\u7528\u4e8e\u540e\u6094\u6700\u5c0f\u5316\u65f6\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u52a0\u901f\u6536\u655b\u4e14\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u540e\u6094\u6700\u5c0f\u5316\u8ba1\u7b97\u5e73\u5747\u7b56\u7565\u8d44\u6e90\u9700\u6c42\u5927\u3001\u5956\u52b1\u53d8\u6362\u6846\u67b6\u53c2\u6570\u624b\u52a8\u8c03\u6574\u6709\u95ee\u9898\uff0c\u5f71\u54cd\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u6280\u672f\uff0c\u52a8\u6001\u8c03\u6574\u53c2\u6570\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u6539\u5584\u540e\u6094\u79ef\u7d2f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u52a0\u901f\u6536\u655b\uff0c\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "conclusion": "\u81ea\u9002\u5e94\u6280\u672f\u80fd\u786e\u4fdd\u7406\u8bba\u4fdd\u8bc1\u4e0e\u5b9e\u9645\u6027\u80fd\u66f4\u597d\u4e00\u81f4\uff0c\u6709\u6548\u89e3\u51b3NFGs\u548cEFGs\u95ee\u9898\u3002"}}
{"id": "2509.13603", "pdf": "https://arxiv.org/pdf/2509.13603", "abs": "https://arxiv.org/abs/2509.13603", "authors": ["Yongye Su", "Zeya Zhang", "Jane Kou", "Cheng Ju", "Shubhojeet Sarkar", "Yamin Wang", "Ji Liu", "Shengbo Guo"], "title": "Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation", "categories": ["cs.IR", "cs.AI"], "comment": "5 Pages, work done as Yongye Su's internship project at Meta", "summary": "Beyond general web-scale search, social network search uniquely enables users\nto retrieve information and discover potential connections within their social\ncontext. We introduce a framework of modernized Facebook Group Scoped Search by\nblending traditional keyword-based retrieval with embedding-based retrieval\n(EBR) to improve the search relevance and diversity of search results. Our\nsystem integrates semantic retrieval into the existing keyword search pipeline,\nenabling users to discover more contextually relevant group posts. To\nrigorously assess the impact of this blended approach, we introduce a novel\nevaluation framework that leverages large language models (LLMs) to perform\noffline relevance assessments, providing scalable and consistent quality\nbenchmarks. Our results demonstrate that the blended retrieval system\nsignificantly enhances user engagement and search quality, as validated by both\nonline metrics and LLM-based evaluation. This work offers practical insights\nfor deploying and evaluating advanced retrieval systems in large-scale,\nreal-world social platforms.", "AI": {"tldr": "\u63d0\u51fa\u73b0\u4ee3\u5316Facebook\u7fa4\u7ec4\u641c\u7d22\u6846\u67b6\uff0c\u7ed3\u5408\u4f20\u7edf\u4e0e\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\uff0c\u7528\u65b0\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u6548\u679c\uff0c\u63d0\u5347\u641c\u7d22\u8d28\u91cf\u3002", "motivation": "\u6539\u8fdb\u793e\u4ea4\u7f51\u7edc\u641c\u7d22\u7684\u76f8\u5173\u6027\u548c\u7ed3\u679c\u591a\u6837\u6027\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u5c06\u8bed\u4e49\u68c0\u7d22\u878d\u5165\u73b0\u6709\u5173\u952e\u8bcd\u641c\u7d22\u6d41\u7a0b\uff0c\u7ed3\u5408\u4f20\u7edf\u4e0e\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\uff1b\u5f15\u5165\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u6df7\u5408\u68c0\u7d22\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u641c\u7d22\u8d28\u91cf\uff0c\u7ecf\u5728\u7ebf\u6307\u6807\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u9a8c\u8bc1\u3002", "conclusion": "\u4e3a\u5927\u89c4\u6a21\u771f\u5b9e\u793e\u4ea4\u5e73\u53f0\u90e8\u7f72\u548c\u8bc4\u4f30\u9ad8\u7ea7\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2509.13575", "pdf": "https://arxiv.org/pdf/2509.13575", "abs": "https://arxiv.org/abs/2509.13575", "authors": ["Benjamin Wilfong", "Anand Radhakrishnan", "Henry A. Le Berre", "Tanush Prathi", "Stephen Abbott", "Spencer H. Bryngelson"], "title": "Testing and benchmarking emerging supercomputers via the MFC flow solver", "categories": ["cs.DC"], "comment": "9 pages, 3 figures", "summary": "Deploying new supercomputers requires testing and evaluation via application\ncodes. Portable, user-friendly tools enable evaluation, and the Multicomponent\nFlow Code (MFC), a computational fluid dynamics (CFD) code, addresses this\nneed. MFC is adorned with a toolchain that automates input generation,\ncompilation, batch job submission, regression testing, and benchmarking. The\ntoolchain design enables users to evaluate compiler-hardware combinations for\ncorrectness and performance with limited software engineering experience. As\nwith other PDE solvers, wall time per spatially discretized grid point serves\nas a figure of merit. We present MFC benchmarking results for five generations\nof NVIDIA GPUs, three generations of AMD GPUs, and various CPU architectures,\nutilizing Intel, Cray, NVIDIA, AMD, and GNU compilers. These tests have\nrevealed compiler bugs and regressions on recent machines such as Frontier and\nEl Capitan. MFC has benchmarked approximately 50 compute devices and 5 flagship\nsupercomputers.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u591a\u7ec4\u5206\u6d41\u4ee3\u7801\uff08MFC\uff09\u53ca\u5176\u5de5\u5177\u94fe\uff0c\u7528\u4e8e\u8d85\u7b97\u6d4b\u8bd5\u8bc4\u4f30\uff0c\u7ed9\u51fa\u591a\u79cd\u67b6\u6784\u548c\u7f16\u8bd1\u5668\u7684\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff0c\u53d1\u73b0\u4e86\u7f16\u8bd1\u5668\u95ee\u9898\u3002", "motivation": "\u65b0\u8d85\u7b97\u90e8\u7f72\u9700\u8981\u901a\u8fc7\u5e94\u7528\u4ee3\u7801\u8fdb\u884c\u6d4b\u8bd5\u8bc4\u4f30\uff0c\u9700\u8981\u4fbf\u643a\u3001\u7528\u6237\u53cb\u597d\u7684\u5de5\u5177\u3002", "method": "\u4f7f\u7528MFC\u53ca\u5176\u81ea\u52a8\u5316\u5de5\u5177\u94fe\u8fdb\u884c\u8f93\u5165\u751f\u6210\u3001\u7f16\u8bd1\u3001\u4f5c\u4e1a\u63d0\u4ea4\u3001\u56de\u5f52\u6d4b\u8bd5\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u6bcf\u7a7a\u95f4\u79bb\u6563\u7f51\u683c\u70b9\u7684\u5899\u65f6\u95f4\u4f5c\u4e3a\u8861\u91cf\u6807\u51c6\u3002", "result": "\u5bf9\u591a\u79cdGPU\u548cCPU\u67b6\u6784\u3001\u4e0d\u540c\u7f16\u8bd1\u5668\u8fdb\u884c\u6d4b\u8bd5\uff0c\u53d1\u73b0\u4e86\u524d\u6cbf\u548c\u57c3\u5c14\u5361\u76ae\u5766\u7b49\u673a\u5668\u4e0a\u7684\u7f16\u8bd1\u5668\u9519\u8bef\u548c\u56de\u5f52\u95ee\u9898\uff0c\u5df2\u5bf9\u7ea650\u4e2a\u8ba1\u7b97\u8bbe\u5907\u548c5\u53f0\u65d7\u8230\u8d85\u7b97\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "MFC\u53ca\u5176\u5de5\u5177\u94fe\u53ef\u6709\u6548\u7528\u4e8e\u8d85\u7b97\u7684\u6d4b\u8bd5\u548c\u8bc4\u4f30\uff0c\u80fd\u53d1\u73b0\u7f16\u8bd1\u5668\u95ee\u9898\u3002"}}
{"id": "2509.14066", "pdf": "https://arxiv.org/pdf/2509.14066", "abs": "https://arxiv.org/abs/2509.14066", "authors": ["Mirco Tincani", "Khaled Kerouch", "Umberto Garlando", "Mattia Barezzi", "Alessandro Sanginario", "Giacomo Indiveri", "Chiara De Luca"], "title": "A neuromorphic continuous soil monitoring system for precision irrigation", "categories": ["cs.NE", "cs.ET"], "comment": null, "summary": "Sensory processing at the edge requires ultra-low power stand-alone computing\ntechnologies. This is particularly true for modern agriculture and precision\nirrigation systems which aim to optimize water usage by monitoring key\nenvironmental observables continuously using distributed efficient embedded\nprocessing elements. Neuromorphic processing systems are emerging as a\npromising technology for extreme edge-computing applications that need to run\non resource-constrained hardware. As such, they are a very good candidate for\nimplementing efficient water management systems based on data measured from\nsoil and plants, across large fields. In this work, we present a fully\nenergy-efficient neuromorphic irrigation control system that operates\nautonomously without any need for data transmission or remote processing.\nLeveraging the properties of a biologically realistic spiking neural network,\nour system performs computation, and decision-making locally. We validate this\napproach using real-world soil moisture data from apple and kiwi orchards\napplied to a mixed-signal neuromorphic processor, and show that the generated\nirrigation commands closely match those derived from conventional methods\nacross different soil depths. Our results show that local neuromorphic\ninference can maintain decision accuracy, paving the way for autonomous,\nsustainable irrigation solutions at scale.", "AI": {"tldr": "\u63d0\u51fa\u5168\u8282\u80fd\u795e\u7ecf\u5f62\u6001\u704c\u6e89\u63a7\u5236\u7cfb\u7edf\uff0c\u5229\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u672c\u5730\u63a8\u7406\u53ef\u4fdd\u6301\u51b3\u7b56\u51c6\u786e\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u704c\u6e89\u65b9\u6848\u5960\u57fa\u3002", "motivation": "\u8fb9\u7f18\u611f\u5b98\u5904\u7406\u9700\u8d85\u4f4e\u529f\u8017\u72ec\u7acb\u8ba1\u7b97\u6280\u672f\uff0c\u73b0\u4ee3\u519c\u4e1a\u548c\u7cbe\u51c6\u704c\u6e89\u7cfb\u7edf\u9700\u6301\u7eed\u76d1\u6d4b\u73af\u5883\uff0c\u795e\u7ecf\u5f62\u6001\u5904\u7406\u7cfb\u7edf\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u6781\u7aef\u8fb9\u7f18\u8ba1\u7b97\u5e94\u7528\u3002", "method": "\u5229\u7528\u751f\u7269\u73b0\u5b9e\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7279\u6027\uff0c\u5728\u672c\u5730\u8fdb\u884c\u8ba1\u7b97\u548c\u51b3\u7b56\u3002", "result": "\u4f7f\u7528\u82f9\u679c\u548c\u7315\u7334\u6843\u679c\u56ed\u7684\u571f\u58e4\u6e7f\u5ea6\u6570\u636e\u9a8c\u8bc1\uff0c\u751f\u6210\u7684\u704c\u6e89\u547d\u4ee4\u4e0e\u4f20\u7edf\u65b9\u6cd5\u5f97\u51fa\u7684\u547d\u4ee4\u5728\u4e0d\u540c\u571f\u58e4\u6df1\u5ea6\u4e0a\u7d27\u5bc6\u5339\u914d\u3002", "conclusion": "\u672c\u5730\u795e\u7ecf\u5f62\u6001\u63a8\u7406\u53ef\u4fdd\u6301\u51b3\u7b56\u51c6\u786e\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u81ea\u4e3b\u3001\u53ef\u6301\u7eed\u704c\u6e89\u89e3\u51b3\u65b9\u6848\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2509.13333", "pdf": "https://arxiv.org/pdf/2509.13333", "abs": "https://arxiv.org/abs/2509.13333", "authors": ["Maheep Chaudhary", "Ian Su", "Nikhil Hooda", "Nishith Shankar", "Julia Tan", "Kevin Zhu", "Ashwinee Panda", "Ryan Lagasse", "Vasu Sharma"], "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) can internally distinguish between evaluation\nand deployment contexts, a behaviour known as \\emph{evaluation awareness}. This\nundermines AI safety evaluations, as models may conceal dangerous capabilities\nduring testing. Prior work demonstrated this in a single $70$B model, but the\nscaling relationship across model sizes remains unknown. We investigate\nevaluation awareness across $15$ models scaling from $0.27$B to $70$B\nparameters from four families using linear probing on steering vector\nactivations. Our results reveal a clear power-law scaling: evaluation awareness\nincreases predictably with model size. This scaling law enables forecasting\ndeceptive behavior in future larger models and guides the design of scale-aware\nevaluation strategies for AI safety. A link to the implementation of this paper\ncan be found at\nhttps://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.", "AI": {"tldr": "\u7814\u7a7615\u4e2a\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u6a21\u578b\u7684\u8bc4\u4f30\u610f\u8bc6\uff0c\u53d1\u73b0\u8bc4\u4f30\u610f\u8bc6\u4e0e\u6a21\u578b\u5927\u5c0f\u5448\u5e42\u5f8b\u7f29\u653e\u5173\u7cfb\uff0c\u53ef\u7528\u4e8e\u9884\u6d4b\u5927\u6a21\u578b\u6b3a\u9a97\u884c\u4e3a\u548c\u6307\u5bfc\u8bc4\u4f30\u7b56\u7565\u8bbe\u8ba1\u3002", "motivation": "\u5148\u524d\u4ec5\u5728\u5355\u4e0070B\u6a21\u578b\u4e2d\u8bc1\u660e\u8bc4\u4f30\u610f\u8bc6\uff0c\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u7f29\u653e\u5173\u7cfb\u672a\u77e5\uff0c\u8fd9\u4f1a\u5f71\u54cdAI\u5b89\u5168\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u63a2\u6d4b\u65b9\u6cd5\u5bf9\u56db\u4e2a\u7cfb\u521715\u4e2a\u4ece0.27B\u523070B\u53c2\u6570\u7684\u6a21\u578b\u7684\u8f6c\u5411\u5411\u91cf\u6fc0\u6d3b\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u8bc4\u4f30\u610f\u8bc6\u4e0e\u6a21\u578b\u5927\u5c0f\u5448\u660e\u663e\u7684\u5e42\u5f8b\u7f29\u653e\u5173\u7cfb\uff0c\u5373\u8bc4\u4f30\u610f\u8bc6\u968f\u6a21\u578b\u5927\u5c0f\u53ef\u9884\u6d4b\u5730\u589e\u52a0\u3002", "conclusion": "\u8be5\u7f29\u653e\u5b9a\u5f8b\u53ef\u7528\u4e8e\u9884\u6d4b\u672a\u6765\u66f4\u5927\u6a21\u578b\u7684\u6b3a\u9a97\u884c\u4e3a\uff0c\u5e76\u6307\u5bfc\u8bbe\u8ba1\u8003\u8651\u89c4\u6a21\u7684AI\u5b89\u5168\u8bc4\u4f30\u7b56\u7565\u3002"}}
{"id": "2509.13471", "pdf": "https://arxiv.org/pdf/2509.13471", "abs": "https://arxiv.org/abs/2509.13471", "authors": ["Sina Gogani-Khiabani", "Ashutosh Trivedi", "Diptikalyan Saha", "Saeid Tizpaz-Niari"], "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "categories": ["cs.SE", "cs.AI"], "comment": "To appear at ICSE 26. 12 pages", "summary": "Large language models (LLMs) show promise for translating natural-language\nstatutes into executable logic, but reliability in legally critical settings\nremains challenging due to ambiguity and hallucinations. We present an agentic\napproach for developing legal-critical software, using U.S. federal tax\npreparation as a case study. The key challenge is test-case generation under\nthe oracle problem, where correct outputs require interpreting law. Building on\nmetamorphic testing, we introduce higher-order metamorphic relations that\ncompare system outputs across structured shifts among similar individuals.\nBecause authoring such relations is tedious and error-prone, we use an\nLLM-driven, role-based framework to automate test generation and code\nsynthesis. We implement a multi-agent system that translates tax code into\nexecutable software and incorporates a metamorphic-testing agent that searches\nfor counterexamples. In experiments, our framework using a smaller model\n(GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier\nmodels (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results\nsupport agentic LLM methodologies as a path to robust, trustworthy\nlegal-critical software from natural-language specifications.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4ee3\u7406\u65b9\u6cd5\u5f00\u53d1\u6cd5\u5f8b\u5173\u952e\u8f6f\u4ef6\uff0c\u4ee5\u7f8e\u56fd\u8054\u90a6\u7a0e\u52a1\u51c6\u5907\u4e3a\u4f8b\uff0c\u7ed3\u5408\u9ad8\u9636\u53d8\u5f62\u5173\u7cfb\u548cLLM\u9a71\u52a8\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u5c0f\u6a21\u578b\u6846\u67b6\u8868\u73b0\u66f4\u4f73\uff0c\u652f\u6301\u4ee3\u7406LLM\u65b9\u6cd5\u5f00\u53d1\u6cd5\u5f8b\u8f6f\u4ef6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u6cd5\u89c4\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u903b\u8f91\u65f6\uff0c\u5728\u6cd5\u5f8b\u5173\u952e\u573a\u666f\u7684\u53ef\u9760\u6027\u56e0\u6b67\u4e49\u4e0e\u5e7b\u89c9\u95ee\u9898\u9762\u4e34\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u53d8\u5f62\u6d4b\u8bd5\u5f15\u5165\u9ad8\u9636\u53d8\u5f62\u5173\u7cfb\uff0c\u7528LLM\u9a71\u52a8\u7684\u57fa\u4e8e\u89d2\u8272\u7684\u6846\u67b6\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u4e0e\u4ee3\u7801\u5408\u6210\uff0c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "result": "\u4f7f\u7528\u8f83\u5c0f\u6a21\u578b\uff08GPT - 4o - mini\uff09\u7684\u6846\u67b6\u5728\u590d\u6742\u7a0e\u52a1\u4ee3\u7801\u4efb\u52a1\u4e0a\u6700\u574f\u60c5\u51b5\u901a\u8fc7\u7387\u8fbe45%\uff0c\u4f18\u4e8e\u524d\u6cbf\u6a21\u578b\uff08GPT - 4o\u548cClaude 3.5\uff0c9 - 15%\uff09\u3002", "conclusion": "\u4ee3\u7406LLM\u65b9\u6cd5\u662f\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u5f00\u53d1\u5065\u58ee\u3001\u53ef\u4fe1\u6cd5\u5f8b\u5173\u952e\u8f6f\u4ef6\u7684\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2509.13923", "pdf": "https://arxiv.org/pdf/2509.13923", "abs": "https://arxiv.org/abs/2509.13923", "authors": ["Lamia Lamrani", "Beno\u00eet Collins", "Jean-Philippe Bouchaud"], "title": "Holdout cross-validation for large non-Gaussian covariance matrix estimation using Weingarten calculus", "categories": ["q-fin.ST", "math.ST", "q-fin.RM", "stat.ML", "stat.TH"], "comment": null, "summary": "Cross-validation is one of the most widely used methods for model selection\nand evaluation; its efficiency for large covariance matrix estimation appears\nrobust in practice, but little is known about the theoretical behavior of its\nerror. In this paper, we derive the expected Frobenius error of the holdout\nmethod, a particular cross-validation procedure that involves a single train\nand test split, for a generic rotationally invariant multiplicative noise\nmodel, therefore extending previous results to non-Gaussian data distributions.\nOur approach involves using the Weingarten calculus and the Ledoit-P\\'ech\\'e\nformula to derive the oracle eigenvalues in the high-dimensional limit. When\nthe population covariance matrix follows an inverse Wishart distribution, we\napproximate the expected holdout error, first with a linear shrinkage, then\nwith a quadratic shrinkage to approximate the oracle eigenvalues. Under the\nlinear approximation, we find that the optimal train-test split ratio is\nproportional to the square root of the matrix dimension. Then we compute Monte\nCarlo simulations of the holdout error for different distributions of the norm\nof the noise, such as the Gaussian, Student, and Laplace distributions and\nobserve that the quadratic approximation yields a substantial improvement,\nespecially around the optimal train-test split ratio. We also observe that a\nhigher fourth-order moment of the Euclidean norm of the noise vector sharpens\nthe holdout error curve near the optimal split and lowers the ideal train-test\nratio, making the choice of the train-test ratio more important when performing\nthe holdout method.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u901a\u7528\u65cb\u8f6c\u4e0d\u53d8\u4e58\u6027\u566a\u58f0\u6a21\u578b\u4e0b\u7559\u4e00\u6cd5\u7684\u671f\u671bFrobenius\u8bef\u5dee\uff0c\u62d3\u5c55\u4e86\u5148\u524d\u7ed3\u679c\u5230\u975e\u9ad8\u65af\u6570\u636e\u5206\u5e03\uff0c\u5206\u6790\u4e86\u6700\u4f18\u8bad\u7ec3 - \u6d4b\u8bd5\u5206\u5272\u6bd4\u4f8b\uff0c\u901a\u8fc7\u6a21\u62df\u53d1\u73b0\u4e8c\u6b21\u8fd1\u4f3c\u6709\u6539\u8fdb\u3002", "motivation": "\u867d\u7136\u4ea4\u53c9\u9a8c\u8bc1\u5728\u5927\u534f\u65b9\u5dee\u77e9\u9635\u4f30\u8ba1\u4e2d\u5b9e\u8df5\u6548\u679c\u7a33\u5065\uff0c\u4f46\u5bf9\u5176\u8bef\u5dee\u7684\u7406\u8bba\u884c\u4e3a\u4e86\u89e3\u751a\u5c11\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u7559\u4e00\u6cd5\u8bef\u5dee\u7684\u7406\u8bba\u884c\u4e3a\u3002", "method": "\u4f7f\u7528Weingarten\u5fae\u79ef\u5206\u548cLedoit - P\u00e9ch\u00e9\u516c\u5f0f\u63a8\u5bfc\u9ad8\u7ef4\u6781\u9650\u4e0b\u7684\u6700\u4f18\u7279\u5f81\u503c\uff0c\u7528\u7ebf\u6027\u548c\u4e8c\u6b21\u6536\u7f29\u8fd1\u4f3c\u671f\u671b\u7559\u4e00\u8bef\u5dee\uff0c\u8fdb\u884c\u8499\u7279\u5361\u7f57\u6a21\u62df\u3002", "result": "\u7ebf\u6027\u8fd1\u4f3c\u4e0b\u6700\u4f18\u8bad\u7ec3 - \u6d4b\u8bd5\u5206\u5272\u6bd4\u4f8b\u4e0e\u77e9\u9635\u7ef4\u5ea6\u5e73\u65b9\u6839\u6210\u6b63\u6bd4\uff1b\u4e8c\u6b21\u8fd1\u4f3c\u6709\u663e\u8457\u6539\u8fdb\uff1b\u566a\u58f0\u5411\u91cf\u6b27\u6c0f\u8303\u6570\u7684\u56db\u9636\u77e9\u5f71\u54cd\u7559\u4e00\u8bef\u5dee\u66f2\u7ebf\u548c\u7406\u60f3\u8bad\u7ec3 - \u6d4b\u8bd5\u6bd4\u4f8b\u3002", "conclusion": "\u4e8c\u6b21\u8fd1\u4f3c\u5728\u7559\u4e00\u6cd5\u4e2d\u6709\u4f18\u52bf\uff0c\u566a\u58f0\u7684\u56db\u9636\u77e9\u4f1a\u5f71\u54cd\u7559\u4e00\u6cd5\u4e2d\u8bad\u7ec3 - \u6d4b\u8bd5\u6bd4\u4f8b\u7684\u9009\u62e9\u3002"}}
{"id": "2509.13516", "pdf": "https://arxiv.org/pdf/2509.13516", "abs": "https://arxiv.org/abs/2509.13516", "authors": ["Tom Almog"], "title": "An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training", "categories": ["cs.LG", "68T05 (Primary) 90C30, 68W40 (Secondary)"], "comment": "7 pages. 3 figures", "summary": "As machine learning models grow increasingly complex and computationally\ndemanding, understanding the environmental impact of training decisions becomes\ncritical for sustainable AI development. This paper presents a comprehensive\nempirical study investigating the relationship between optimizer choice and\nenergy efficiency in neural network training. We conducted 360 controlled\nexperiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using\neight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,\nNAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking\non Apple M1 Pro hardware, we measured training duration, peak memory usage,\ncarbon dioxide emissions, and final model performance. Our findings reveal\nsubstantial trade-offs between training speed, accuracy, and environmental\nimpact that vary across datasets and model complexity. We identify AdamW and\nNAdam as consistently efficient choices, while SGD demonstrates superior\nperformance on complex datasets despite higher emissions. These results provide\nactionable insights for practitioners seeking to balance performance and\nsustainability in machine learning workflows.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u4f18\u5316\u5668\u9009\u62e9\u4e0e\u80fd\u6e90\u6548\u7387\u7684\u5173\u7cfb\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u4e0d\u540c\u4f18\u5316\u5668\u5728\u8bad\u7ec3\u901f\u5ea6\u3001\u51c6\u786e\u6027\u548c\u73af\u5883\u5f71\u54cd\u4e0a\u5b58\u5728\u6743\u8861\uff0c\u4e3a\u5e73\u8861\u6027\u80fd\u4e0e\u53ef\u6301\u7eed\u6027\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u590d\u6742\u5ea6\u548c\u8ba1\u7b97\u9700\u6c42\u589e\u52a0\uff0c\u7406\u89e3\u8bad\u7ec3\u51b3\u7b56\u5bf9\u73af\u5883\u7684\u5f71\u54cd\u5bf9\u53ef\u6301\u7eedAI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u516b\u79cd\u6d41\u884c\u4f18\u5316\u5668\uff0c\u6bcf\u79cd\u8bbe15\u4e2a\u968f\u673a\u79cd\u5b50\uff0c\u8fdb\u884c360\u6b21\u5bf9\u7167\u5b9e\u9a8c\uff0c\u7528CodeCarbon\u5728Apple M1 Pro\u786c\u4ef6\u4e0a\u7cbe\u786e\u8ddf\u8e2a\u80fd\u6e90\u4f7f\u7528\u60c5\u51b5\uff0c\u6d4b\u91cf\u8bad\u7ec3\u65f6\u957f\u3001\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u3001\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u548c\u6700\u7ec8\u6a21\u578b\u6027\u80fd\u3002", "result": "\u4e0d\u540c\u6570\u636e\u96c6\u548c\u6a21\u578b\u590d\u6742\u5ea6\u4e0b\uff0c\u8bad\u7ec3\u901f\u5ea6\u3001\u51c6\u786e\u6027\u548c\u73af\u5883\u5f71\u54cd\u5b58\u5728\u663e\u8457\u6743\u8861\uff1bAdamW\u548cNAdam\u59cb\u7ec8\u9ad8\u6548\uff0cSGD\u5728\u590d\u6742\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u8d8a\u4f46\u6392\u653e\u8f83\u9ad8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u4e2d\u5e73\u8861\u6027\u80fd\u548c\u53ef\u6301\u7eed\u6027\u7684\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.13548", "pdf": "https://arxiv.org/pdf/2509.13548", "abs": "https://arxiv.org/abs/2509.13548", "authors": ["Manan Mittal", "Thomas Deppisch", "Joseph Forrer", "Chris Le Sueur", "Zamir Ben-Hur", "David Lou Along", "Daniel D. E. Wong"], "title": "Field of View Enhanced Signal Dependent Binauralization with Mixture of Experts Framework for Continuous Source Motion", "categories": ["cs.SD", "stat.ML"], "comment": "5 pages, 3 figures", "summary": "We propose a novel mixture of experts framework for field-of-view enhancement\nin binaural signal matching. Our approach enables dynamic spatial audio\nrendering that adapts to continuous talker motion, allowing users to emphasize\nor suppress sounds from selected directions while preserving natural binaural\ncues. Unlike traditional methods that rely on explicit direction-of-arrival\nestimation or operate in the Ambisonics domain, our signal-dependent framework\ncombines multiple binaural filters in an online manner using implicit\nlocalization. This allows for real-time tracking and enhancement of moving\nsound sources, supporting applications such as speech focus, noise reduction,\nand world-locked audio in augmented and virtual reality. The method is agnostic\nto array geometry offering a flexible solution for spatial audio capture and\npersonalized playback in next-generation consumer audio devices.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u53cc\u8033\u4fe1\u53f7\u5339\u914d\u4e2d\u89c6\u573a\u589e\u5f3a\u7684\u65b0\u578b\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\uff0c\u80fd\u52a8\u6001\u6e32\u67d3\u7a7a\u95f4\u97f3\u9891\uff0c\u652f\u6301\u591a\u5e94\u7528\u4e14\u7075\u6d3b\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u53cc\u8033\u4fe1\u53f7\u5339\u914d\u89c6\u573a\u589e\u5f3a\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u9002\u5e94\u8fde\u7eed\u8bf4\u8bdd\u8005\u8fd0\u52a8\u7684\u52a8\u6001\u7a7a\u95f4\u97f3\u9891\u6e32\u67d3\u3002", "method": "\u91c7\u7528\u9690\u5f0f\u5b9a\u4f4d\u5728\u7ebf\u7ec4\u5408\u591a\u4e2a\u53cc\u8033\u6ee4\u6ce2\u5668\u7684\u4fe1\u53f7\u4f9d\u8d56\u6846\u67b6\uff0c\u4e14\u4e0e\u9635\u5217\u51e0\u4f55\u65e0\u5173\u3002", "result": "\u53ef\u5b9e\u65f6\u8ddf\u8e2a\u548c\u589e\u5f3a\u79fb\u52a8\u58f0\u6e90\uff0c\u652f\u6301\u8bed\u97f3\u805a\u7126\u3001\u964d\u566a\u7b49\u5e94\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e0b\u4e00\u4ee3\u6d88\u8d39\u97f3\u9891\u8bbe\u5907\u7684\u7a7a\u95f4\u97f3\u9891\u6355\u83b7\u548c\u4e2a\u6027\u5316\u64ad\u653e\u63d0\u4f9b\u4e86\u7075\u6d3b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14041", "pdf": "https://arxiv.org/pdf/2509.14041", "abs": "https://arxiv.org/abs/2509.14041", "authors": ["Henry Kao", "Nikhil Sreekumar", "Prabhdeep Singh Soni", "Ali Sedaghati", "Fang Su", "Bryan Chan", "Maziar Goudarzi", "Reza Azimi"], "title": "A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching", "categories": ["cs.AR", "cs.CL", "cs.OS", "cs.PF"], "comment": null, "summary": "Modern mobile CPU software pose challenges for conventional instruction cache\nreplacement policies due to their complex runtime behavior causing high reuse\ndistance between executions of the same instruction. Mobile code commonly\nsuffers from large amounts of stalls in the CPU frontend and thus starvation of\nthe rest of the CPU resources. Complexity of these applications and their code\nfootprint are projected to grow at a rate faster than available on-chip memory\ndue to power and area constraints, making conventional hardware-centric methods\nfor managing instruction caches to be inadequate. We present a novel\nsoftware-hardware co-design approach called TRRIP (Temperature-based\nRe-Reference Interval Prediction) that enables the compiler to analyze,\nclassify, and transform code based on \"temperature\" (hot/cold), and to provide\nthe hardware with a summary of code temperature information through a\nwell-defined OS interface based on using code page attributes. TRRIP's\nlightweight hardware extension employs code temperature attributes to optimize\nthe instruction cache replacement policy resulting in the eviction rate\nreduction of hot code. TRRIP is designed to be practical and adoptable in real\nmobile systems that have strict feature requirements on both the software and\nhardware components. TRRIP can reduce the L2 MPKI for instructions by 26.5%\nresulting in geomean speedup of 3.9%, on top of RRIP cache replacement running\nmobile code already optimized using PGO.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3aTRRIP\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u4f18\u5316\u6307\u4ee4\u7f13\u5b58\u66ff\u6362\u7b56\u7565\uff0c\u53ef\u964d\u4f4eL2 MPKI\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u79fb\u52a8CPU\u8f6f\u4ef6\u56e0\u590d\u6742\u8fd0\u884c\u884c\u4e3a\u5bf9\u4f20\u7edf\u6307\u4ee4\u7f13\u5b58\u66ff\u6362\u7b56\u7565\u5e26\u6765\u6311\u6218\uff0c\u4f20\u7edf\u786c\u4ef6\u65b9\u6cd5\u7ba1\u7406\u6307\u4ee4\u7f13\u5b58\u4e0d\u8db3\u3002", "method": "\u7f16\u8bd1\u5668\u57fa\u4e8e\u4ee3\u7801\u201c\u6e29\u5ea6\u201d\u5206\u6790\u3001\u5206\u7c7b\u548c\u8f6c\u6362\u4ee3\u7801\uff0c\u901a\u8fc7\u64cd\u4f5c\u7cfb\u7edf\u63a5\u53e3\u5411\u786c\u4ef6\u63d0\u4f9b\u4ee3\u7801\u6e29\u5ea6\u4fe1\u606f\uff0c\u786c\u4ef6\u6269\u5c55\u5229\u7528\u6e29\u5ea6\u5c5e\u6027\u4f18\u5316\u6307\u4ee4\u7f13\u5b58\u66ff\u6362\u7b56\u7565\u3002", "result": "TRRIP\u53ef\u4f7fL2 MPKI\u964d\u4f4e26.5%\uff0c\u5728\u5df2\u4f7f\u7528PGO\u4f18\u5316\u7684\u79fb\u52a8\u4ee3\u7801\u4e2d\u5b9e\u73b03.9%\u7684\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u3002", "conclusion": "TRRIP\u5b9e\u7528\u4e14\u9002\u7528\u4e8e\u6709\u4e25\u683c\u8f6f\u786c\u4ef6\u8981\u6c42\u7684\u771f\u5b9e\u79fb\u52a8\u7cfb\u7edf\uff0c\u80fd\u6709\u6548\u4f18\u5316\u6307\u4ee4\u7f13\u5b58\u66ff\u6362\u7b56\u7565\u3002"}}
{"id": "2509.13623", "pdf": "https://arxiv.org/pdf/2509.13623", "abs": "https://arxiv.org/abs/2509.13623", "authors": ["Marlon Azinovic-Yang", "Jan \u017demli\u010dka"], "title": "Deep Learning in the Sequence Space", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "We develop a deep learning algorithm for approximating functional rational\nexpectations equilibria of dynamic stochastic economies in the sequence space.\nWe use deep neural networks to parameterize equilibrium objects of the economy\nas a function of truncated histories of exogenous shocks. We train the neural\nnetworks to fulfill all equilibrium conditions along simulated paths of the\neconomy. To illustrate the performance of our method, we solve three economies\nof increasing complexity: the stochastic growth model, a high-dimensional\noverlapping generations economy with multiple sources of aggregate risk, and\nfinally an economy where households and firms face uninsurable idiosyncratic\nrisk, shocks to aggregate productivity, and shocks to idiosyncratic and\naggregate volatility. Furthermore, we show how to design practical neural\npolicy function architectures that guarantee monotonicity of the predicted\npolicies, facilitating the use of the endogenous grid method to simplify parts\nof our algorithm.", "AI": {"tldr": "\u5f00\u53d1\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5728\u5e8f\u5217\u7a7a\u95f4\u8fd1\u4f3c\u52a8\u6001\u968f\u673a\u7ecf\u6d4e\u7684\u51fd\u6570\u7406\u6027\u9884\u671f\u5747\u8861\uff0c\u6d4b\u8bd5\u4e0d\u540c\u590d\u6742\u5ea6\u7ecf\u6d4e\u4f53\u5e76\u5c55\u793a\u8bbe\u8ba1\u4fdd\u8bc1\u5355\u8c03\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u7b56\u7565\u51fd\u6570\u67b6\u6784\u3002", "motivation": "\u5bfb\u627e\u5728\u5e8f\u5217\u7a7a\u95f4\u8fd1\u4f3c\u52a8\u6001\u968f\u673a\u7ecf\u6d4e\u7684\u51fd\u6570\u7406\u6027\u9884\u671f\u5747\u8861\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5c06\u7ecf\u6d4e\u7684\u5747\u8861\u5bf9\u8c61\u53c2\u6570\u5316\u4e3a\u5916\u751f\u51b2\u51fb\u622a\u65ad\u5386\u53f2\u7684\u51fd\u6570\uff0c\u5e76\u6cbf\u7740\u7ecf\u6d4e\u6a21\u62df\u8def\u5f84\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4ee5\u6ee1\u8db3\u6240\u6709\u5747\u8861\u6761\u4ef6\u3002", "result": "\u89e3\u51b3\u4e86\u4e09\u4e2a\u590d\u6742\u5ea6\u9012\u589e\u7684\u7ecf\u6d4e\u4f53\uff0c\u5c55\u793a\u4e86\u8bbe\u8ba1\u4fdd\u8bc1\u5355\u8c03\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u7b56\u7565\u51fd\u6570\u67b6\u6784\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u7b97\u6cd5\u53ef\u7528\u4e8e\u8fd1\u4f3c\u52a8\u6001\u968f\u673a\u7ecf\u6d4e\u7684\u51fd\u6570\u7406\u6027\u9884\u671f\u5747\u8861\uff0c\u8bbe\u8ba1\u7684\u67b6\u6784\u6709\u52a9\u4e8e\u7b80\u5316\u7b97\u6cd5\u3002"}}
{"id": "2509.14028", "pdf": "https://arxiv.org/pdf/2509.14028", "abs": "https://arxiv.org/abs/2509.14028", "authors": ["Menelaos Pavlou", "Rumana Z. Omar", "Gareth Ambler"], "title": "Sample Size Calculations for the Development of Risk Prediction Models that Account for Performance Variability", "categories": ["stat.ME", "stat.AP", "stat.CO"], "comment": "29 pages, 5 figures, 2 tables (plus supplementary material)", "summary": "Existing approaches to sample size calculations for developing clinical\nprediction models have focused on ensuring that the expected value of a chosen\nperformance measure meets a pre-specified target. For example, to limit\nmodel-overfitting, the sample size is commonly chosen such that the expected\ncalibration slope (CS) is 0.9, close to 1 for a perfectly calibrated model. In\npractice, due to sampling variability, model performance can vary considerably\nacross different development samples of the recommended size. If this\nvariability is high, the probability of obtaining a model with performance\nclose to the target for a given measure may be unacceptably low. To address\nthis, we propose an adapted approach to sample size calculations that\nexplicitly incorporates performance variability by targeting the probability of\nacceptable performance (PrAP). For example, in the context of calibration, we\nmay define a model as acceptably calibrated if CS falls in a pre-defined range,\ne.g. between 0.85 and 1.15. Then we choose the required sample size to ensure\nthat PrAP(CS)=80%. For binary outcomes we implemented our approach for CS\nwithin a simulation-based framework via the R package `samplesizedev'.\nAdditionally, for CS specifically, we have proposed an equivalent analytical\ncalculation which is computationally efficient. While we focused on CS, the\nsimulation-based framework is flexible and can be easily extended to\naccommodate other performance measures and types of outcomes. When adhering to\nexisting recommendations, we found that performance variability increased\nsubstantially as the number of predictors, p, decreased. Consequently, PrAP(CS)\nwas often low. For example, with 5 predictors, PrAP(CS) was around 50%. Our\nadapted approach resulted in considerably larger sample sizes, especially for\np<10. Applying shrinkage tends to improve PrAP(CS).", "AI": {"tldr": "\u63d0\u51fa\u8003\u8651\u6027\u80fd\u53d8\u5f02\u6027\u7684\u6837\u672c\u91cf\u8ba1\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u6846\u67b6\u548c\u89e3\u6790\u8ba1\u7b97\u5b9e\u73b0\uff0c\u53d1\u73b0\u539f\u65b9\u6cd5\u6027\u80fd\u53d8\u5f02\u6027\u5927\uff0c\u65b0\u65b9\u6cd5\u9700\u66f4\u5927\u6837\u672c\u91cf\uff0c\u6536\u7f29\u6cd5\u53ef\u6539\u5584\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u6837\u672c\u91cf\u8ba1\u7b97\u65b9\u6cd5\u672a\u8003\u8651\u6027\u80fd\u53d8\u5f02\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u83b7\u5f97\u63a5\u8fd1\u76ee\u6807\u6027\u80fd\u6a21\u578b\u7684\u6982\u7387\u4f4e\u3002", "method": "\u63d0\u51fa\u9002\u5e94\u65b9\u6cd5\uff0c\u4ee5\u53ef\u63a5\u53d7\u6027\u80fd\u6982\u7387\u4e3a\u76ee\u6807\uff0c\u901a\u8fc7R\u5305\u5728\u6a21\u62df\u6846\u67b6\u5b9e\u73b0\uff0c\u8fd8\u63d0\u51fa\u89e3\u6790\u8ba1\u7b97\u65b9\u6cd5\u3002", "result": "\u539f\u65b9\u6cd5\u6027\u80fd\u53d8\u5f02\u6027\u968f\u9884\u6d4b\u56e0\u5b50\u6570\u91cf\u51cf\u5c11\u800c\u589e\u52a0\uff0c\u53ef\u63a5\u53d7\u6027\u80fd\u6982\u7387\u4f4e\uff0c\u65b0\u65b9\u6cd5\u9700\u66f4\u5927\u6837\u672c\u91cf\uff0c\u6536\u7f29\u6cd5\u53ef\u6539\u5584\u53ef\u63a5\u53d7\u6027\u80fd\u6982\u7387\u3002", "conclusion": "\u65b0\u7684\u6837\u672c\u91cf\u8ba1\u7b97\u65b9\u6cd5\u8003\u8651\u6027\u80fd\u53d8\u5f02\u6027\uff0c\u53ef\u63d0\u9ad8\u83b7\u5f97\u63a5\u8fd1\u76ee\u6807\u6027\u80fd\u6a21\u578b\u7684\u6982\u7387\u3002"}}
{"id": "2509.13891", "pdf": "https://arxiv.org/pdf/2509.13891", "abs": "https://arxiv.org/abs/2509.13891", "authors": ["Tsz Chiu Kwok", "Zhewei Wei", "Mingji Yang"], "title": "On Solving Asymmetric Diagonally Dominant Linear Systems in Sublinear Time", "categories": ["cs.DS"], "comment": "46 pages", "summary": "We initiate a study of solving a row/column diagonally dominant (RDD/CDD)\nlinear system $Mx=b$ in sublinear time, with the goal of estimating\n$t^{\\top}x^*$ for a given vector $t\\in R^n$ and a specific solution $x^*$. This\nsetting naturally generalizes the study of sublinear-time solvers for symmetric\ndiagonally dominant (SDD) systems [AKP19] to the asymmetric case.\n  Our first contributions are characterizations of the problem's mathematical\nstructure. We express a solution $x^*$ via a Neumann series, prove its\nconvergence, and upper bound the truncation error on this series through a\nnovel quantity of $M$, termed the maximum $p$-norm gap. This quantity\ngeneralizes the spectral gap of symmetric matrices and captures how the\nstructure of $M$ governs the problem's computational difficulty.\n  For systems with bounded maximum $p$-norm gap, we develop a collection of\nalgorithmic results for locally approximating $t^{\\top}x^*$ under various\nscenarios and error measures. We derive these results by adapting the\ntechniques of random-walk sampling, local push, and their bidirectional\ncombination, which have proved powerful for special cases of solving RDD/CDD\nsystems, particularly estimating PageRank and effective resistance on graphs.\nOur general framework yields deeper insights, extended results, and improved\ncomplexity bounds for these problems. Notably, our perspective provides a\nunified understanding of Forward Push and Backward Push, two fundamental\napproaches for estimating random-walk probabilities on graphs.\n  Our framework also inherits the hardness results for sublinear-time SDD\nsolvers and local PageRank computation, establishing lower bounds on the\nmaximum $p$-norm gap or the accuracy parameter. We hope that our work opens the\ndoor for further study into sublinear solvers, local graph algorithms, and\ndirected spectral graph theory.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e9a\u7ebf\u6027\u65f6\u95f4\u6c42\u89e3RDD/CDD\u7ebf\u6027\u7cfb\u7edf\uff0c\u523b\u753b\u95ee\u9898\u6570\u5b66\u7ed3\u6784\uff0c\u7ed9\u51fa\u7b97\u6cd5\u7ed3\u679c\u5e76\u7ee7\u627f\u76f8\u5173\u95ee\u9898\u7684\u96be\u5ea6\u7ed3\u679c\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53ef\u80fd\u3002", "motivation": "\u5c06\u5bf9\u79f0\u5bf9\u89d2\u5360\u4f18\uff08SDD\uff09\u7cfb\u7edf\u7684\u4e9a\u7ebf\u6027\u65f6\u95f4\u6c42\u89e3\u5668\u7814\u7a76\u63a8\u5e7f\u5230\u975e\u5bf9\u79f0\u60c5\u51b5\uff0c\u4f30\u8ba1\u7ed9\u5b9a\u5411\u91cf\u4e0e\u7279\u5b9a\u89e3\u7684\u5185\u79ef\u3002", "method": "\u901a\u8fc7Neumann\u7ea7\u6570\u8868\u793a\u89e3\uff0c\u8bc1\u660e\u5176\u6536\u655b\u6027\u5e76\u754c\u5b9a\u622a\u65ad\u8bef\u5dee\uff1b\u91c7\u7528\u968f\u673a\u6e38\u8d70\u91c7\u6837\u3001\u5c40\u90e8\u63a8\u9001\u53ca\u5176\u53cc\u5411\u7ec4\u5408\u6280\u672f\u3002", "result": "\u5f97\u5230\u4e86\u5728\u4e0d\u540c\u573a\u666f\u548c\u8bef\u5dee\u5ea6\u91cf\u4e0b\u5c40\u90e8\u903c\u8fd1\u5185\u79ef\u7684\u7b97\u6cd5\u7ed3\u679c\uff0c\u7edf\u4e00\u7406\u89e3\u4e86\u56fe\u4e0a\u4f30\u8ba1\u968f\u673a\u6e38\u8d70\u6982\u7387\u7684\u4e24\u79cd\u57fa\u672c\u65b9\u6cd5\uff0c\u7ee7\u627f\u4e86\u76f8\u5173\u95ee\u9898\u7684\u786c\u5ea6\u7ed3\u679c\u3002", "conclusion": "\u4e3a\u4e9a\u7ebf\u6027\u6c42\u89e3\u5668\u3001\u5c40\u90e8\u56fe\u7b97\u6cd5\u548c\u6709\u5411\u8c31\u56fe\u7406\u8bba\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2509.14032", "pdf": "https://arxiv.org/pdf/2509.14032", "abs": "https://arxiv.org/abs/2509.14032", "authors": ["Philip Jordan", "Maryam Kamgarpour"], "title": "Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation", "categories": ["cs.GT", "cs.LG", "cs.MA"], "comment": null, "summary": "We study the existence and computation of Nash equilibria in continuous\nstatic games where the players' admissible strategies are subject to shared\ncoupling constraints, i.e., constraints that depend on their \\emph{joint}\nstrategies. Specifically, we focus on a class of games characterized by\nplayerwise concave utilities and playerwise concave constraints. Prior results\non the existence of Nash equilibria are not applicable to this class, as they\nrely on strong assumptions such as joint convexity of the feasible set. By\nleveraging topological fixed point theory and novel structural insights into\nthe contractibility of feasible sets under playerwise concave constraints, we\ngive an existence proof for Nash equilibria under weaker conditions. Having\nestablished existence, we then focus on the computation of Nash equilibria via\nindependent gradient methods under the additional assumption that the utilities\nadmit a potential function. To account for the possibly nonconvex feasible\nregion, we employ a log barrier regularized gradient ascent with adaptive\nstepsizes. Starting from an initial feasible strategy profile and under exact\ngradient feedback, the proposed method converges to an $\\epsilon$-approximate\nconstrained Nash equilibrium within $\\mathcal{O}(\\epsilon^{-3})$ iterations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.13626", "pdf": "https://arxiv.org/pdf/2509.13626", "abs": "https://arxiv.org/abs/2509.13626", "authors": ["Amanda Chan", "James Jiayu Liu", "He Kai", "Onno P. Kampman"], "title": "Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval", "categories": ["cs.IR", "cs.AI", "H.3.3; J.3; I.2.7"], "comment": "25 pages, 3 figures, submitted to NeurIPS 2025 GenAI4Health", "summary": "Access to reliable mental health information is vital for early help-seeking,\nyet expanding knowledge bases is resource-intensive and often misaligned with\nuser needs. This results in poor performance of retrieval systems when\npresented concerns are not covered or expressed in informal or contextualized\nlanguage. We present an AI-based gap-informed framework for corpus augmentation\nthat authentically identifies underrepresented topics (gaps) by overlaying\nnaturalistic user data such as forum posts in order to prioritize expansions\nbased on coverage and usefulness. In a case study, we compare Directed\n(gap-informed augmentations) with Non-Directed augmentation (random additions),\nevaluating the relevance and usefulness of retrieved information across four\nretrieval-augmented generation (RAG) pipelines. Directed augmentation achieved\nnear-optimal performance with modest expansions--requiring only a 42% increase\nfor Query Transformation, 74% for Reranking and Hierarchical, and 318% for\nBaseline--to reach ~95% of the performance of an exhaustive reference corpus.\nIn contrast, Non-Directed augmentation required substantially larger and thus\npractically infeasible expansions to achieve comparable performance (232%,\n318%, 403%, and 763%, respectively). These results show that strategically\ntargeted corpus growth can reduce content creation demands while sustaining\nhigh retrieval and provision quality, offering a scalable approach for building\ntrusted health information repositories and supporting generative AI\napplications in high-stakes domains.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eAI\u7684\u8bed\u6599\u5e93\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u6848\u4f8b\u5bf9\u6bd4\u6709\u9488\u5bf9\u6027\u548c\u65e0\u9488\u5bf9\u6027\u7684\u589e\u5f3a\u65b9\u5f0f\uff0c\u8868\u660e\u6709\u9488\u5bf9\u6027\u7684\u8bed\u6599\u5e93\u589e\u957f\u53ef\u964d\u4f4e\u5185\u5bb9\u521b\u5efa\u9700\u6c42\u5e76\u4fdd\u6301\u9ad8\u8d28\u91cf\u3002", "motivation": "\u53ef\u9760\u5fc3\u7406\u5065\u5eb7\u4fe1\u606f\u83b7\u53d6\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u77e5\u8bc6\u5e93\u6269\u5c55\u8d44\u6e90\u6d88\u8017\u5927\u4e14\u4e0e\u7528\u6237\u9700\u6c42\u4e0d\u5339\u914d\uff0c\u68c0\u7d22\u7cfb\u7edf\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eAI\u7684\u5dee\u8ddd\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u53e0\u52a0\u81ea\u7136\u4e3b\u4e49\u7528\u6237\u6570\u636e\u8bc6\u522b\u672a\u5145\u5206\u4ee3\u8868\u7684\u4e3b\u9898\uff0c\u5728\u6848\u4f8b\u7814\u7a76\u4e2d\u5bf9\u6bd4\u6709\u9488\u5bf9\u6027\u548c\u65e0\u9488\u5bf9\u6027\u7684\u8bed\u6599\u5e93\u589e\u5f3a\u65b9\u5f0f\uff0c\u8bc4\u4f30\u56db\u4e2a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ba1\u9053\u4e2d\u68c0\u7d22\u4fe1\u606f\u7684\u76f8\u5173\u6027\u548c\u6709\u7528\u6027\u3002", "result": "\u6709\u9488\u5bf9\u6027\u7684\u589e\u5f3a\u4ee5\u9002\u5ea6\u6269\u5c55\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u65e0\u9488\u5bf9\u6027\u7684\u589e\u5f3a\u9700\u8981\u5927\u5e45\u6269\u5c55\u624d\u80fd\u8fbe\u5230\u7c7b\u4f3c\u6027\u80fd\u3002", "conclusion": "\u6709\u9488\u5bf9\u6027\u7684\u8bed\u6599\u5e93\u589e\u957f\u53ef\u964d\u4f4e\u5185\u5bb9\u521b\u5efa\u9700\u6c42\uff0c\u4fdd\u6301\u9ad8\u68c0\u7d22\u548c\u63d0\u4f9b\u8d28\u91cf\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u5065\u5eb7\u4fe1\u606f\u5e93\u548c\u652f\u6301\u9ad8\u98ce\u9669\u9886\u57df\u751f\u6210\u5f0fAI\u5e94\u7528\u63d0\u4f9b\u53ef\u6269\u5c55\u65b9\u6cd5\u3002"}}
{"id": "2509.13583", "pdf": "https://arxiv.org/pdf/2509.13583", "abs": "https://arxiv.org/abs/2509.13583", "authors": ["Varsha Rao", "Andrew A. Chien"], "title": "Modeling the Carbon Footprint of HPC: The Top 500 and EasyC", "categories": ["cs.DC"], "comment": "15 pages, 11 figures", "summary": "Climate change is a critical concern for HPC systems, but GHG protocol\ncarbon-emission accounting methodologies are difficult for a single system, and\neffectively infeasible for a collection of systems. As a result, there is no\nHPC-wide carbon reporting, and even the largest HPC sites do not do GHG\nprotocol reporting.\n  We assess the carbon footprint of HPC, focusing on the Top 500 systems. The\nkey challenge lies in modeling the carbon footprint with limited data\navailability.\n  With the disclosed Top500.org data, and using a new tool, EasyC, we were able\nto model the operational carbon of 391 HPC systems and the embodied carbon of\n283 HPC systems. We further show how this coverage can be enhanced by\nexploiting additional public information. With improved coverage, then\ninterpolation is used to produce the first carbon footprint estimates of the\nTop 500 HPC systems. They are 1,393.7 million MT CO2e operational carbon (1\nYear) and 1,881.8 million MT CO2e embodied carbon. We also project how the Top\n500's carbon footprint will increase through 2030.\n  A key enabler is the EasyC tool which models carbon footprint with only a few\ndata metrics. We explore availability of data and enhancement, showing that\ncoverage can be increased to 98% of Top 500 systems for operational and 80.8%\nof the systems for embodied emissions.", "AI": {"tldr": "\u672c\u6587\u805a\u7126Top 500 HPC\u7cfb\u7edf\u78b3\u8db3\u8ff9\u8bc4\u4f30\uff0c\u7528EasyC\u5de5\u5177\u5efa\u6a21\uff0c\u7ed9\u51fa\u78b3\u8db3\u8ff9\u4f30\u7b97\u5e76\u9884\u6d4b\u52302030\u5e74\u7684\u53d8\u5316\uff0c\u8fd8\u63a2\u8ba8\u6570\u636e\u8986\u76d6\u63d0\u5347\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u5bf9HPC\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u78b3\u6392\u653e\u6838\u7b97\u65b9\u6cd5\u96be\u7528\u4e8e\u5355\u4e00\u6216\u591a\u4e2a\u7cfb\u7edf\uff0c\u7f3a\u4e4fHPC\u5168\u884c\u4e1a\u78b3\u62a5\u544a\u3002", "method": "\u5229\u7528Top500.org\u516c\u5f00\u6570\u636e\uff0c\u4f7f\u7528EasyC\u5de5\u5177\u5efa\u6a21\uff0c\u901a\u8fc7\u5229\u7528\u989d\u5916\u516c\u5171\u4fe1\u606f\u63d0\u5347\u8986\u76d6\u5ea6\uff0c\u7528\u63d2\u503c\u6cd5\u4f30\u7b97Top 500\u7cfb\u7edf\u78b3\u8db3\u8ff9\u3002", "result": "\u5bf9391\u4e2a\u7cfb\u7edf\u7684\u8fd0\u8425\u78b3\u548c283\u4e2a\u7cfb\u7edf\u7684\u5185\u542b\u78b3\u5efa\u6a21\uff0c\u5f97\u51faTop 500\u7cfb\u7edf\u8fd0\u8425\u78b3\u548c\u5185\u542b\u78b3\u4f30\u7b97\u503c\uff0c\u8fd8\u9884\u6d4b\u4e86\u52302030\u5e74\u78b3\u8db3\u8ff9\u589e\u957f\u3002", "conclusion": "EasyC\u5de5\u5177\u80fd\u4ee5\u5c11\u91cf\u6570\u636e\u6307\u6807\u5efa\u6a21\u78b3\u8db3\u8ff9\uff0c\u6570\u636e\u8986\u76d6\u5ea6\u53ef\u63d0\u5347\u81f3\u8fd0\u8425\u6392\u653e98%\u548c\u5185\u542b\u6392\u653e80.8%\u3002"}}
{"id": "2509.13338", "pdf": "https://arxiv.org/pdf/2509.13338", "abs": "https://arxiv.org/abs/2509.13338", "authors": ["Hassan Gharoun", "Mohammad Sadegh Khorshidi", "Kasra Ranjbarigderi", "Fang Chen", "Amir H. Gandomi"], "title": "Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE", "68T07, 68T09"], "comment": "15 pages, 4 figures, 3 tables", "summary": "This work proposes an evidence-retrieval mechanism for uncertainty-aware\ndecision-making that replaces a single global cutoff with an\nevidence-conditioned, instance-adaptive criterion. For each test instance,\nproximal exemplars are retrieved in an embedding space; their predictive\ndistributions are fused via Dempster-Shafer theory. The resulting fused belief\nacts as a per-instance thresholding mechanism. Because the supporting evidences\nare explicit, decisions are transparent and auditable. Experiments on\nCIFAR-10/100 with BiT and ViT backbones show higher or comparable\nuncertainty-aware performance with materially fewer confidently incorrect\noutcomes and a sustainable review load compared with applying threshold on\nprediction entropy. Notably, only a few evidences are sufficient to realize\nthese gains; increasing the evidence set yields only modest changes. These\nresults indicate that evidence-conditioned tagging provides a more reliable and\ninterpretable alternative to fixed prediction entropy thresholds for\noperational uncertainty-aware decision-making.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8bc1\u636e\u68c0\u7d22\u673a\u5236\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u51b3\u7b56\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u6bd4\u57fa\u4e8e\u9884\u6d4b\u71b5\u9608\u503c\u65b9\u6cd5\u66f4\u4f18\u3002", "motivation": "\u4e3a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u51b3\u7b56\u63d0\u4f9b\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u3002", "method": "\u7528\u8bc1\u636e\u6761\u4ef6\u3001\u5b9e\u4f8b\u81ea\u9002\u5e94\u6807\u51c6\u53d6\u4ee3\u5355\u4e00\u5168\u5c40\u9608\u503c\uff0c\u5728\u5d4c\u5165\u7a7a\u95f4\u68c0\u7d22\u8fd1\u90bb\u6837\u672c\uff0c\u7528Dempster - Shafer\u7406\u8bba\u878d\u5408\u9884\u6d4b\u5206\u5e03\uff0c\u4ee5\u878d\u5408\u540e\u7684\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5b9e\u4f8b\u9608\u503c\u673a\u5236\u3002", "result": "\u5728CIFAR - 10/100\u5b9e\u9a8c\u4e2d\uff0c\u6bd4\u57fa\u4e8e\u9884\u6d4b\u71b5\u9608\u503c\u65b9\u6cd5\u6709\u66f4\u9ad8\u6216\u76f8\u5f53\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6027\u80fd\uff0c\u9519\u8bef\u7ed3\u679c\u5c11\u4e14\u5ba1\u67e5\u8d1f\u62c5\u4f4e\uff0c\u5c11\u91cf\u8bc1\u636e\u5c31\u80fd\u5b9e\u73b0\u63d0\u5347\u3002", "conclusion": "\u8bc1\u636e\u6761\u4ef6\u6807\u8bb0\u4e3a\u5b9e\u9645\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u51b3\u7b56\u63d0\u4f9b\u4e86\u6bd4\u56fa\u5b9a\u9884\u6d4b\u71b5\u9608\u503c\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2509.13334", "pdf": "https://arxiv.org/pdf/2509.13334", "abs": "https://arxiv.org/abs/2509.13334", "authors": ["Anand Swaroop", "Akshat Nallani", "Saksham Uboweja", "Adiliia Uzdenova", "Michael Nguyen", "Kevin Zhu", "Sunishchal Dev", "Ashwinee Panda", "Vasu Sharma", "Maheep Chaudhary"], "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving\nlarge language model performance on complex tasks, but recent work shows that\nreasoning steps often fail to causally influence the final answer, creating\nbrittle and untrustworthy outputs. Prior approaches focus primarily on\nmeasuring faithfulness, while methods for systematically improving it remain\nlimited. We introduce Faithful Reasoning via Intervention Training (FRIT), a\nscalable alignment method that trains models to produce causally consistent\nreasoning by learning from systematically corrupted examples. FRIT generates\nsynthetic training data by intervening on individual reasoning steps in\nmodel-generated CoTs, creating faithful/unfaithful pairs that highlight when\nreasoning breaks down. We then apply Direct Preference Optimization to teach\nmodels to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B\nand Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases\nfaithful reasoning by $3.4$ percentage points for Mistral on GSM8K while\nimproving accuracy by $7.6$ percentage points. Our approach provides the first\nscalable, supervision-free method for training language models to produce more\nreliable and interpretable reasoning, addressing a critical gap between\nreasoning performance and trustworthiness. We release our code at\n\\href{https://github.com/Anut-py/frit}.", "AI": {"tldr": "\u63d0\u51faFRIT\u65b9\u6cd5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u548c\u51c6\u786e\u6027\uff0c\u5728\u591a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u6709CoT\u63a8\u7406\u7ed3\u679c\u4e0d\u53ef\u9760\uff0c\u4e14\u63d0\u5347\u63a8\u7406\u5fe0\u5b9e\u6027\u7684\u65b9\u6cd5\u6709\u9650\u3002", "method": "\u5f15\u5165FRIT\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e72\u9884\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u6b65\u9aa4\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u8ba9\u6a21\u578b\u9009\u62e9\u56e0\u679c\u4e00\u81f4\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728Qwen3 - 8B\u548cMistral - 7B - v0.1\u4e0a\u8bc4\u4f30\uff0cFRIT\u4f7fMistral\u5728GSM8K\u4e0a\u5fe0\u5b9e\u63a8\u7406\u63d0\u53473.4\u4e2a\u767e\u5206\u70b9\uff0c\u51c6\u786e\u7387\u63d0\u53477.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "FRIT\u662f\u9996\u4e2a\u53ef\u6269\u5c55\u3001\u65e0\u76d1\u7763\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u751f\u6210\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u5f25\u8865\u63a8\u7406\u6027\u80fd\u548c\u53ef\u4fe1\u5ea6\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.13487", "pdf": "https://arxiv.org/pdf/2509.13487", "abs": "https://arxiv.org/abs/2509.13487", "authors": ["Abubakari Alidu", "Michele Ciavotta", "Flavio DePaoli"], "title": "Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Developing reliable data enrichment pipelines demands significant engineering\nexpertise. We present Prompt2DAG, a methodology that transforms natural\nlanguage descriptions into executable Apache Airflow DAGs. We evaluate four\ngeneration approaches -- Direct, LLM-only, Hybrid, and Template-based -- across\n260 experiments using thirteen LLMs and five case studies to identify optimal\nstrategies for production-grade automation. Performance is measured using a\npenalized scoring framework that combines reliability with code quality (SAT),\nstructural integrity (DST), and executability (PCT). The Hybrid approach\nemerges as the optimal generative method, achieving a 78.5% success rate with\nrobust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly\noutperforms the LLM-only (66.2% success) and Direct (29.2% success) methods.\nOur findings show that reliability, not intrinsic code quality, is the primary\ndifferentiator. Cost-effectiveness analysis reveals the Hybrid method is over\ntwice as efficient as Direct prompting per successful DAG. We conclude that a\nstructured, hybrid approach is essential for balancing flexibility and\nreliability in automated workflow generation, offering a viable path to\ndemocratize data pipeline development.", "AI": {"tldr": "\u63d0\u51faPrompt2DAG\u65b9\u6cd5\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u4e3a\u53ef\u6267\u884cDAG\uff0c\u8bc4\u4f30\u56db\u79cd\u751f\u6210\u65b9\u6cd5\uff0c\u6df7\u5408\u65b9\u6cd5\u6700\u4f18\uff0c\u8868\u660e\u7ed3\u6784\u5316\u6df7\u5408\u65b9\u6cd5\u5bf9\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u751f\u6210\u5f88\u91cd\u8981\u3002", "motivation": "\u5f00\u53d1\u53ef\u9760\u6570\u636e\u4e30\u5bcc\u7ba1\u9053\u9700\u8981\u5927\u91cf\u5de5\u7a0b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5e0c\u671b\u627e\u5230\u751f\u4ea7\u7ea7\u81ea\u52a8\u5316\u7684\u6700\u4f18\u7b56\u7565\u3002", "method": "\u63d0\u51faPrompt2DAG\u65b9\u6cd5\uff0c\u8bc4\u4f30Direct\u3001LLM - only\u3001Hybrid\u548cTemplate - based\u56db\u79cd\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u60e9\u7f5a\u6027\u8bc4\u5206\u6846\u67b6\u8861\u91cf\u6027\u80fd\u3002", "result": "\u6df7\u5408\u65b9\u6cd5\u662f\u6700\u4f18\u751f\u6210\u65b9\u6cd5\uff0c\u6210\u529f\u738778.5%\uff0c\u8d28\u91cf\u5206\u6570\u9ad8\uff0c\u663e\u8457\u4f18\u4e8eLLM - only\u548cDirect\u65b9\u6cd5\uff0c\u4e14\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u3002", "conclusion": "\u7ed3\u6784\u5316\u6df7\u5408\u65b9\u6cd5\u5bf9\u5e73\u8861\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u751f\u6210\u7684\u7075\u6d3b\u6027\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u6570\u636e\u7ba1\u9053\u5f00\u53d1\u6c11\u4e3b\u5316\u63d0\u4f9b\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2509.13520", "pdf": "https://arxiv.org/pdf/2509.13520", "abs": "https://arxiv.org/abs/2509.13520", "authors": ["Varun Kumar", "Jing Bi", "Cyril Ngo Ngoc", "Victor Oancea", "George Em Karniadakis"], "title": "Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework", "categories": ["cs.LG"], "comment": null, "summary": "Neural surrogates and operator networks for solving partial differential\nequation (PDE) problems have attracted significant research interest in recent\nyears. However, most existing approaches are limited in their ability to\ngeneralize solutions across varying non-parametric geometric domains. In this\nwork, we address this challenge in the context of Polyethylene Terephthalate\n(PET) bottle buckling analysis, a representative packaging design problem\nconventionally solved using computationally expensive finite element analysis\n(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously\npredicts nodal displacement fields and the time evolution of reaction forces\nduring top load compression. Our methodology is evaluated on two families of\nbottle geometries parameterized by two and four design variables. Training data\nis generated using nonlinear FEA simulations in Abaqus for 254 unique designs\nper family. The proposed framework achieves mean relative $L^{2}$ errors of\n2.5-13% for displacement fields and approximately 2.4% for time-dependent\nreaction forces for the four-parameter bottle family. Point-wise error analyses\nfurther show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,\nwith the largest discrepancies confined to localized geometric regions.\nImportantly, the model accurately captures key physical phenomena, such as\nbuckling behavior, across diverse bottle geometries. These results highlight\nthe potential of our framework as a scalable and computationally efficient\nsurrogate, particularly for multi-task predictions in computational mechanics\nand applications requiring rapid design evaluation.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408DeepONet - Transolver\u6846\u67b6\u7528\u4e8ePET\u74f6\u5c48\u66f2\u5206\u6790\uff0c\u8bc4\u4f30\u5176\u5728\u4e0d\u540c\u74f6\u51e0\u4f55\u5f62\u72b6\u4e0a\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u4f5c\u4e3a\u66ff\u4ee3\u6a21\u578b\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u89e3\u51b3\u504f\u5fae\u5206\u65b9\u7a0b\u95ee\u9898\u7684\u65b9\u6cd5\u5728\u4e0d\u540c\u975e\u53c2\u6570\u51e0\u4f55\u57df\u4e0a\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0cPET\u74f6\u5c48\u66f2\u5206\u6790\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u5f15\u5165\u6df7\u5408DeepONet - Transolver\u6846\u67b6\uff0c\u7528Abaqus\u8fdb\u884c\u975e\u7ebf\u6027\u6709\u9650\u5143\u5206\u6790\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u4e24\u7c7b\u74f6\u51e0\u4f55\u5f62\u72b6\u4e0a\u8bc4\u4f30\u3002", "result": "\u56db\u53c2\u6570\u74f6\u65cf\u4f4d\u79fb\u573a\u5e73\u5747\u76f8\u5bf9$L^{2}$\u8bef\u5dee2.5 - 13%\uff0c\u65f6\u53d8\u53cd\u4f5c\u7528\u529b\u7ea62.4%\uff0c\u70b9\u8bef\u5dee\u5206\u6790\u663e\u793a\u4f4d\u79fb\u7edd\u5bf9\u8bef\u5dee\u5728$10^{-4}-10^{-3}$\uff0c\u80fd\u51c6\u786e\u6355\u6349\u5173\u952e\u7269\u7406\u73b0\u8c61\u3002", "conclusion": "\u6846\u67b6\u6709\u6f5c\u529b\u6210\u4e3a\u53ef\u6269\u5c55\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u8ba1\u7b97\u529b\u5b66\u591a\u4efb\u52a1\u9884\u6d4b\u548c\u5feb\u901f\u8bbe\u8ba1\u8bc4\u4f30\u3002"}}
{"id": "2509.13778", "pdf": "https://arxiv.org/pdf/2509.13778", "abs": "https://arxiv.org/abs/2509.13778", "authors": ["Sarah Zhao", "Emmanuel Cand\u00e8s"], "title": "Imputation-Powered Inference", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "Modern multi-modal and multi-site data frequently suffer from blockwise\nmissingness, where subsets of features are missing for groups of individuals,\ncreating complex patterns that challenge standard inference methods. Existing\napproaches have critical limitations: complete-case analysis discards\ninformative data and is potentially biased; doubly robust estimators for\nnon-monotone missingness-where the missingness patterns are not nested subsets\nof one another-can be theoretically efficient but lack closed-form solutions\nand often fail to scale; and blackbox imputation can leverage partially\nobserved data to improve efficiency but provides no inferential guarantees when\nmisspecified. To address the limitations of these existing methods, we propose\nimputation-powered inference (IPI), a model-lean framework that combines the\nflexibility of blackbox imputation with bias correction using fully observed\ndata, drawing on ideas from prediction-powered inference and semiparametric\ninference. IPI enables valid and efficient M-estimation under missing\ncompletely at random (MCAR) blockwise missingness and improves subpopulation\ninference under a weaker assumption we formalize as first-moment MCAR, for\nwhich we also provide practical diagnostics. Simulation studies and a clinical\napplication demonstrate that IPI may substantially improve subpopulation\nefficiency relative to complete-case analysis, while maintaining statistical\nvalidity in settings where both doubly robust estimators and naive imputation\nfail to achieve nominal coverage.", "AI": {"tldr": "\u63d0\u51faIPI\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u591a\u7ad9\u70b9\u6570\u636e\u5757\u7f3a\u5931\u95ee\u9898\uff0c\u7ed3\u5408\u9ed1\u76d2\u63d2\u8865\u7075\u6d3b\u6027\u4e0e\u5168\u89c2\u6d4b\u6570\u636e\u504f\u5dee\u6821\u6b63\uff0c\u6a21\u62df\u548c\u4e34\u5e8a\u5e94\u7528\u663e\u793a\u5176\u4f18\u52bf\u3002", "motivation": "\u73b0\u4ee3\u591a\u6a21\u6001\u591a\u7ad9\u70b9\u6570\u636e\u5b58\u5728\u5757\u7f3a\u5931\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u6709\u5c40\u9650\u6027\uff0c\u5982\u5b8c\u6574\u6848\u4f8b\u5206\u6790\u4e22\u5f03\u6570\u636e\u6709\u504f\u5dee\u3001\u53cc\u7a33\u5065\u4f30\u8ba1\u5668\u7f3a\u4e4f\u95ed\u5f0f\u89e3\u4e14\u96be\u6269\u5c55\u3001\u9ed1\u76d2\u63d2\u8865\u6307\u5b9a\u9519\u8bef\u65f6\u65e0\u63a8\u65ad\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u63d2\u8865\u9a71\u52a8\u63a8\u65ad\uff08IPI\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u9ed1\u76d2\u63d2\u8865\u7075\u6d3b\u6027\u548c\u5168\u89c2\u6d4b\u6570\u636e\u504f\u5dee\u6821\u6b63\uff0c\u501f\u9274\u9884\u6d4b\u9a71\u52a8\u63a8\u65ad\u548c\u534a\u53c2\u6570\u63a8\u65ad\u601d\u60f3\u3002", "result": "\u6a21\u62df\u7814\u7a76\u548c\u4e34\u5e8a\u5e94\u7528\u8868\u660e\uff0cIPI\u5728\u5b8c\u5168\u968f\u673a\u7f3a\u5931\u4e0b\u80fd\u8fdb\u884c\u6709\u6548\u548c\u9ad8\u6548\u7684M\u4f30\u8ba1\uff0c\u5728\u8f83\u5f31\u5047\u8bbe\u4e0b\u6539\u5584\u5b50\u603b\u4f53\u63a8\u65ad\uff0c\u76f8\u5bf9\u5b8c\u6574\u6848\u4f8b\u5206\u6790\u53ef\u5927\u5e45\u63d0\u9ad8\u5b50\u603b\u4f53\u6548\u7387\uff0c\u5728\u53cc\u7a33\u5065\u4f30\u8ba1\u5668\u548c\u7b80\u5355\u63d2\u8865\u5931\u8d25\u65f6\u4fdd\u6301\u7edf\u8ba1\u6709\u6548\u6027\u3002", "conclusion": "IPI\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u591a\u7ad9\u70b9\u6570\u636e\u5757\u7f3a\u5931\u95ee\u9898\uff0c\u5177\u6709\u8f83\u597d\u7684\u7edf\u8ba1\u6027\u80fd\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.13887", "pdf": "https://arxiv.org/pdf/2509.13887", "abs": "https://arxiv.org/abs/2509.13887", "authors": ["Claudia Cerrone", "Francesco Feri", "Anita Gantner", "Paolo Pin"], "title": "Can the decoy effect increase cooperation in networks? An experiment", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper investigates whether the decoy effect - specifically the\nattraction effect - can foster cooperation in social networks. In a lab\nexperiment, we show that introducing a dominated option increases the selection\nof the target choice, especially in early decisions. The effect is stronger in\nindividual settings but persists in networks despite free-riding incentives,\nwith variation depending on the decision-maker's strategic position.", "AI": {"tldr": "\u7814\u7a76\u8bf1\u9975\u6548\u5e94\uff08\u5438\u5f15\u6548\u5e94\uff09\u80fd\u5426\u4fc3\u8fdb\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5408\u4f5c\uff0c\u5b9e\u9a8c\u8868\u660e\u5f15\u5165\u52a3\u52bf\u9009\u9879\u80fd\u589e\u52a0\u76ee\u6807\u9009\u62e9\uff0c\u8be5\u6548\u5e94\u5728\u4e2a\u4f53\u548c\u7f51\u7edc\u4e2d\u5747\u5b58\u5728\u3002", "motivation": "\u63a2\u7a76\u8bf1\u9975\u6548\u5e94\uff08\u5438\u5f15\u6548\u5e94\uff09\u662f\u5426\u80fd\u4fc3\u8fdb\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5408\u4f5c\u3002", "method": "\u8fdb\u884c\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\u3002", "result": "\u5f15\u5165\u52a3\u52bf\u9009\u9879\u589e\u52a0\u4e86\u76ee\u6807\u9009\u62e9\uff0c\u8be5\u6548\u5e94\u5728\u4e2a\u4f53\u8bbe\u7f6e\u4e2d\u66f4\u5f3a\uff0c\u5728\u7f51\u7edc\u4e2d\u867d\u6709\u642d\u4fbf\u8f66\u52a8\u673a\u4ecd\u5b58\u5728\uff0c\u4e14\u968f\u51b3\u7b56\u8005\u6218\u7565\u4f4d\u7f6e\u800c\u53d8\u5316\u3002", "conclusion": "\u8bf1\u9975\u6548\u5e94\uff08\u5438\u5f15\u6548\u5e94\uff09\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u80fd\u4fc3\u8fdb\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5408\u4f5c\u3002"}}
{"id": "2509.14091", "pdf": "https://arxiv.org/pdf/2509.14091", "abs": "https://arxiv.org/abs/2509.14091", "authors": ["Sougata Bose", "Daniel Hausmann", "Soumyajit Paul", "Sven Schewe", "Tansholpan Zhanabekova"], "title": "Generalised Reachability Games Revisited", "categories": ["cs.GT", "cs.LO"], "comment": "In Proceedings GandALF 2025, arXiv:2509.13258", "summary": "Classic reachability games on graphs are zero-sum games, where the goal of\none player, Eve, is to visit a vertex from a given target set, and that of\nother player, Adam, is to prevent this. Generalised reachability games, studied\nby Fijalkow and Horn, are a generalisation of reachability objectives, where\ninstead of a single target set, there is a family of target sets and Eve must\nvisit all of them in any order. In this work, we further study the complexity\nof solving two-player games on graphs with generalised reachability objectives.\nOur results are twofold: first, we provide an improved complexity picture for\ngeneralised reachability games, expanding the known tractable class from games\nin which all target sets are singleton to additionally allowing a logarithmic\nnumber of target sets of arbitrary size. Second, we study optimisation variants\nof generalised reachability with a focus on the size of the target sets. For\nthese problems, we show intractability for most interesting cases.\nParticularly, in contrast to the tractability in the classic variant for\nsingleton target sets, the optimisation problem is NP-hard when Eve tries to\nmaximise the number of singleton target sets that are visited. Tractability can\nbe recovered in the optimisation setting when all target sets are singleton by\nrequiring that Eve pledges a maximum sized subset of target sets that she can\nguarantee to visit.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u56fe\u4e0a\u5e7f\u4e49\u53ef\u8fbe\u6027\u76ee\u6807\u7684\u4e24\u4eba\u6e38\u620f\u590d\u6742\u5ea6\uff0c\u4e00\u65b9\u9762\u6539\u8fdb\u590d\u6742\u5ea6\u60c5\u51b5\uff0c\u6269\u5927\u5df2\u77e5\u6613\u89e3\u7c7b\uff1b\u53e6\u4e00\u65b9\u9762\u7814\u7a76\u4f18\u5316\u53d8\u4f53\uff0c\u591a\u6570\u60c5\u51b5\u96be\u5904\u7406\u3002", "motivation": "\u8fdb\u4e00\u6b65\u7814\u7a76\u56fe\u4e0a\u4e24\u4eba\u5e7f\u4e49\u53ef\u8fbe\u6027\u76ee\u6807\u6e38\u620f\u7684\u590d\u6742\u5ea6\u3002", "method": "\u5206\u6790\u5e7f\u4e49\u53ef\u8fbe\u6027\u6e38\u620f\uff0c\u6269\u5c55\u5df2\u77e5\u6613\u89e3\u7c7b\uff1b\u7814\u7a76\u4f18\u5316\u53d8\u4f53\u95ee\u9898\u3002", "result": "\u4e00\u662f\u6539\u8fdb\u5e7f\u4e49\u53ef\u8fbe\u6027\u6e38\u620f\u590d\u6742\u5ea6\u60c5\u51b5\uff0c\u6269\u5927\u6613\u89e3\u7c7b\uff1b\u4e8c\u662f\u591a\u6570\u4f18\u5316\u53d8\u4f53\u95ee\u9898\u96be\u5904\u7406\uff0c\u5355\u5143\u7d20\u76ee\u6807\u96c6\u4f18\u5316\u95ee\u9898NP\u96be\uff0c\u7279\u6b8a\u60c5\u51b5\u53ef\u6062\u590d\u6613\u89e3\u6027\u3002", "conclusion": "\u5e7f\u4e49\u53ef\u8fbe\u6027\u6e38\u620f\u590d\u6742\u5ea6\u7814\u7a76\u6709\u65b0\u8fdb\u5c55\uff0c\u4e0d\u540c\u60c5\u51b5\u4e0b\u95ee\u9898\u7684\u96be\u6613\u7a0b\u5ea6\u4e0d\u540c\u3002"}}
{"id": "2509.13957", "pdf": "https://arxiv.org/pdf/2509.13957", "abs": "https://arxiv.org/abs/2509.13957", "authors": ["Sunkyung Lee", "Seongmin Park", "Jonghyo Kim", "Mincheol Yoon", "Jongwuk Lee"], "title": "Enhancing Time Awareness in Generative Recommendation", "categories": ["cs.IR", "cs.CL"], "comment": "EMNLP 2025 (Findings)", "summary": "Generative recommendation has emerged as a promising paradigm that formulates\nthe recommendations into a text-to-text generation task, harnessing the vast\nknowledge of large language models. However, existing studies focus on\nconsidering the sequential order of items and neglect to handle the temporal\ndynamics across items, which can imply evolving user preferences. To address\nthis limitation, we propose a novel model, Generative Recommender Using Time\nawareness (GRUT), effectively capturing hidden user preferences via various\ntemporal signals. We first introduce Time-aware Prompting, consisting of two\nkey contexts. The user-level temporal context models personalized temporal\npatterns across timestamps and time intervals, while the item-level transition\ncontext provides transition patterns across users. We also devise Trend-aware\nInference, a training-free method that enhances rankings by incorporating trend\ninformation about items with generation likelihood. Extensive experiments\ndemonstrate that GRUT outperforms state-of-the-art models, with gains of up to\n15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The\nsource code is available at https://github.com/skleee/GRUT.", "AI": {"tldr": "\u63d0\u51fa\u65f6\u95f4\u611f\u77e5\u751f\u6210\u63a8\u8350\u6a21\u578bGRUT\uff0c\u901a\u8fc7\u65f6\u95f4\u4fe1\u53f7\u6355\u6349\u7528\u6237\u504f\u597d\uff0c\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u63a8\u8350\u7814\u7a76\u5ffd\u7565\u7269\u54c1\u95f4\u65f6\u95f4\u52a8\u6001\uff0c\u65e0\u6cd5\u4f53\u73b0\u7528\u6237\u504f\u597d\u6f14\u53d8\u3002", "method": "\u63d0\u51fa\u65f6\u95f4\u611f\u77e5\u63d0\u793a\uff08\u542b\u7528\u6237\u7ea7\u548c\u7269\u54c1\u7ea7\u4e0a\u4e0b\u6587\uff09\u548c\u8d8b\u52bf\u611f\u77e5\u63a8\u7406\u65b9\u6cd5\u3002", "result": "GRUT\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0aRecall@5\u548cNDCG@5\u5206\u522b\u63d0\u5347\u8fbe15.4%\u548c14.3%\u3002", "conclusion": "GRUT\u80fd\u6709\u6548\u6355\u6349\u7528\u6237\u9690\u85cf\u504f\u597d\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2509.13703", "pdf": "https://arxiv.org/pdf/2509.13703", "abs": "https://arxiv.org/abs/2509.13703", "authors": ["Sriram Srinivasan", "Hamdan Alabsi", "Rand Obeidat", "Nithisha Ponnala", "Azene Zenebe"], "title": "GPU Programming for AI Workflow Development on AWS SageMaker: An Instructional Approach", "categories": ["cs.DC"], "comment": null, "summary": "We present the design, implementation, and comprehensive evaluation of a\nspecialized course on GPU architecture, GPU programming, and how these are used\nfor developing AI agents. This course is offered to undergraduate and graduate\nstudents during Fall 2024 and Spring 2025. The course began with foundational\nconcepts in GPU/CPU hardware and parallel computing and progressed to develop\nRAG and optimizing them using GPUs. Students gained experience provisioning and\nconfiguring cloud-based GPU instances, implementing parallel algorithms, and\ndeploying scalable AI solutions. We evaluated learning outcomes through\nassessments, course evaluations, and anonymous surveys. The results reveal that\n(1) AWS served as an effective and economical platform for practical GPU\nprogramming, (2) experiential learning significantly enhanced technical\nproficiency and engagement, and (3) the course strengthened students'\nproblem-solving and critical thinking skills through tools such as TensorBoard\nand HPC profilers, which exposed performance bottlenecks and scaling issues.\nOur findings underscore the pedagogical value of integrating parallel computing\ninto STEM education. We advocate for broader adoption of similar electives\nacross STEM curricula to prepare students for the demands of modern,\ncompute-intensive fields.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u95e8\u5173\u4e8eGPU\u67b6\u6784\u3001\u7f16\u7a0b\u53ca\u7528\u4e8e\u5f00\u53d1AI\u4ee3\u7406\u7684\u8bfe\u7a0b\uff0c\u5bf9\u5176\u8bbe\u8ba1\u3001\u5b9e\u65bd\u548c\u8bc4\u4f30\u8fdb\u884c\u9610\u8ff0\uff0c\u7ed3\u679c\u663e\u793a\u8bfe\u7a0b\u6709\u826f\u597d\u6548\u679c\uff0c\u5021\u5bfc\u5728STEM\u8bfe\u7a0b\u4e2d\u63a8\u5e7f\u7c7b\u4f3c\u9009\u4fee\u8bfe\u3002", "motivation": "\u4e3a\u672c\u79d1\u751f\u548c\u7814\u7a76\u751f\u63d0\u4f9b\u6709\u5173GPU\u67b6\u6784\u3001\u7f16\u7a0b\u53ca\u5f00\u53d1AI\u4ee3\u7406\u7684\u4e13\u4e1a\u8bfe\u7a0b\uff0c\u63d0\u5347\u5b66\u751f\u5728\u76f8\u5173\u9886\u57df\u7684\u80fd\u529b\u3002", "method": "\u8bfe\u7a0b\u4eceGPU/CPU\u786c\u4ef6\u548c\u5e76\u884c\u8ba1\u7b97\u57fa\u7840\u6982\u5ff5\u5f00\u59cb\uff0c\u5f15\u5bfc\u5b66\u751f\u5f00\u53d1RAG\u5e76\u4f18\u5316\uff0c\u8ba9\u5b66\u751f\u5b9e\u8df5\u4e91GPU\u5b9e\u4f8b\u914d\u7f6e\u7b49\uff0c\u901a\u8fc7\u8bc4\u4f30\u3001\u8bfe\u7a0b\u8bc4\u4ef7\u548c\u533f\u540d\u8c03\u67e5\u8bc4\u4f30\u5b66\u4e60\u6210\u679c\u3002", "result": "AWS\u662f\u5b9e\u7528GPU\u7f16\u7a0b\u7684\u6709\u6548\u7ecf\u6d4e\u5e73\u53f0\uff1b\u4f53\u9a8c\u5f0f\u5b66\u4e60\u589e\u5f3a\u6280\u672f\u80fd\u529b\u548c\u53c2\u4e0e\u5ea6\uff1b\u8bfe\u7a0b\u901a\u8fc7\u5de5\u5177\u5f3a\u5316\u5b66\u751f\u89e3\u51b3\u95ee\u9898\u548c\u6279\u5224\u6027\u601d\u7ef4\u80fd\u529b\u3002", "conclusion": "\u5f3a\u8c03\u5c06\u5e76\u884c\u8ba1\u7b97\u878d\u5165STEM\u6559\u80b2\u7684\u6559\u5b66\u4ef7\u503c\uff0c\u5021\u5bfc\u5728STEM\u8bfe\u7a0b\u4e2d\u66f4\u5e7f\u6cdb\u91c7\u7528\u7c7b\u4f3c\u9009\u4fee\u8bfe\u3002"}}
{"id": "2509.13459", "pdf": "https://arxiv.org/pdf/2509.13459", "abs": "https://arxiv.org/abs/2509.13459", "authors": ["Arna Ghosh", "Zahraa Chorghay", "Shahab Bakhtiari", "Blake A. Richards"], "title": "Why all roads don't lead to Rome: Representation geometry varies across the human visual cortical hierarchy", "categories": ["q-bio.NC", "cs.LG", "cs.NE"], "comment": "9 pages, 4 figures", "summary": "Biological and artificial intelligence systems navigate the fundamental\nefficiency-robustness tradeoff for optimal encoding, i.e., they must\nefficiently encode numerous attributes of the input space while also being\nrobust to noise. This challenge is particularly evident in hierarchical\nprocessing systems like the human brain. With a view towards understanding how\nsystems navigate the efficiency-robustness tradeoff, we turned to a population\ngeometry framework for analyzing representations in the human visual cortex\nalongside artificial neural networks (ANNs). In the ventral visual stream, we\nfound general-purpose, scale-free representations characterized by a power\nlaw-decaying eigenspectrum in most areas. However, in certain higher-order\nvisual areas did not have scale-free representations, indicating that\nscale-free geometry is not a universal property of the brain. In parallel, ANNs\ntrained with a self-supervised learning objective also exhibited free-free\ngeometry, but not after fine-tune on a specific task. Based on these empirical\nresults and our analytical insights, we posit that a system's representation\ngeometry is not a universal property and instead depends upon the computational\nobjective.", "AI": {"tldr": "\u7814\u7a76\u751f\u7269\u548c\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u6548\u7387 - \u9c81\u68d2\u6027\u6743\u8861\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u7cfb\u7edf\u8868\u5f81\u51e0\u4f55\u5e76\u975e\u666e\u904d\u5c5e\u6027\uff0c\u800c\u662f\u53d6\u51b3\u4e8e\u8ba1\u7b97\u76ee\u6807\u3002", "motivation": "\u7406\u89e3\u7cfb\u7edf\u5982\u4f55\u5e94\u5bf9\u6548\u7387 - \u9c81\u68d2\u6027\u6743\u8861\u6311\u6218\u3002", "method": "\u4f7f\u7528\u7fa4\u4f53\u51e0\u4f55\u6846\u67b6\u5206\u6790\u4eba\u7c7b\u89c6\u89c9\u76ae\u5c42\u548c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u5f81\u3002", "result": "\u4eba\u7c7b\u8179\u4fa7\u89c6\u89c9\u6d41\u591a\u6570\u533a\u57df\u6709\u901a\u7528\u3001\u65e0\u6807\u5ea6\u8868\u5f81\uff0c\u90e8\u5206\u9ad8\u9636\u89c6\u89c9\u533a\u57df\u65e0\uff1b\u81ea\u76d1\u7763\u5b66\u4e60\u76ee\u6807\u8bad\u7ec3\u7684ANNs\u6709\u65e0\u6807\u5ea6\u51e0\u4f55\uff0c\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u540e\u5219\u65e0\u3002", "conclusion": "\u7cfb\u7edf\u7684\u8868\u5f81\u51e0\u4f55\u5e76\u975e\u666e\u904d\u5c5e\u6027\uff0c\u53d6\u51b3\u4e8e\u8ba1\u7b97\u76ee\u6807\u3002"}}
{"id": "2509.13339", "pdf": "https://arxiv.org/pdf/2509.13339", "abs": "https://arxiv.org/abs/2509.13339", "authors": ["Ming Jin", "Hyunin Lee"], "title": "Position: AI Safety Must Embrace an Antifragile Perspective", "categories": ["cs.AI"], "comment": null, "summary": "This position paper contends that modern AI research must adopt an\nantifragile perspective on safety -- one in which the system's capacity to\nguarantee long-term AI safety such as handling rare or out-of-distribution\n(OOD) events expands over time. Conventional static benchmarks and single-shot\nrobustness tests overlook the reality that environments evolve and that models,\nif left unchallenged, can drift into maladaptation (e.g., reward hacking,\nover-optimization, or atrophy of broader capabilities). We argue that an\nantifragile approach -- Rather than striving to rapidly reduce current\nuncertainties, the emphasis is on leveraging those uncertainties to better\nprepare for potentially greater, more unpredictable uncertainties in the future\n-- is pivotal for the long-term reliability of open-ended ML systems. In this\nposition paper, we first identify key limitations of static testing, including\nscenario diversity, reward hacking, and over-alignment. We then explore the\npotential of antifragile solutions to manage rare events. Crucially, we\nadvocate for a fundamental recalibration of the methods used to measure,\nbenchmark, and continually improve AI safety over the long term, complementing\nexisting robustness approaches by providing ethical and practical guidelines\ntowards fostering an antifragile AI safety community.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u73b0\u4ee3AI\u7814\u7a76\u5e94\u91c7\u7528\u6297\u8106\u5f31\u89c6\u89d2\u4fdd\u969c\u957f\u671fAI\u5b89\u5168\uff0c\u6307\u51fa\u9759\u6001\u6d4b\u8bd5\u5c40\u9650\u5e76\u63a2\u7d22\u6297\u8106\u5f31\u89e3\u51b3\u65b9\u6848\uff0c\u5021\u5bfc\u91cd\u65b0\u6821\u51c6\u8bc4\u4f30\u548c\u63d0\u5347AI\u5b89\u5168\u7684\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u548c\u5355\u6b21\u9c81\u68d2\u6027\u6d4b\u8bd5\u5ffd\u89c6\u73af\u5883\u53d8\u5316\uff0c\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u4e0d\u9002\u5e94\uff0c\u9700\u8981\u65b0\u89c6\u89d2\u4fdd\u969c\u957f\u671fAI\u5b89\u5168\u3002", "method": "\u5148\u8bc6\u522b\u9759\u6001\u6d4b\u8bd5\u7684\u5173\u952e\u5c40\u9650\uff0c\u518d\u63a2\u7d22\u6297\u8106\u5f31\u89e3\u51b3\u65b9\u6848\u5e94\u5bf9\u7f55\u89c1\u4e8b\u4ef6\uff0c\u6700\u540e\u5021\u5bfc\u91cd\u65b0\u6821\u51c6\u8861\u91cf\u3001\u57fa\u51c6\u548c\u6301\u7eed\u6539\u8fdbAI\u5b89\u5168\u7684\u65b9\u6cd5\u5e76\u63d0\u4f9b\u76f8\u5173\u6307\u5357\u3002", "result": "\u660e\u786e\u6307\u51fa\u9759\u6001\u6d4b\u8bd5\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u4e86\u6297\u8106\u5f31\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\u3002", "conclusion": "\u6297\u8106\u5f31\u65b9\u6cd5\u5bf9\u5f00\u653e\u5f0f\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u957f\u671f\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5e94\u5efa\u7acb\u6297\u8106\u5f31\u7684AI\u5b89\u5168\u793e\u533a\u3002"}}
{"id": "2509.13535", "pdf": "https://arxiv.org/pdf/2509.13535", "abs": "https://arxiv.org/abs/2509.13535", "authors": ["S M Farah Al Fahim", "Md Nakhla Rafi", "Zeyang Ma", "Dong Jae Kim", "Tse-Hsun", "Chen"], "title": "Crash Report Enhancement with Large Language Models: An Empirical Study", "categories": ["cs.SE"], "comment": null, "summary": "Crash reports are central to software maintenance, yet many lack the\ndiagnostic detail developers need to debug efficiently. We examine whether\nlarge language models can enhance crash reports by adding fault locations,\nroot-cause explanations, and repair suggestions. We study two enhancement\nstrategies: Direct-LLM, a single-shot approach that uses stack-trace context,\nand Agentic-LLM, an iterative approach that explores the repository for\nadditional evidence. On a dataset of 492 real-world crash reports, LLM-enhanced\nreports improve Top-1 problem-localization accuracy from 10.6% (original\nreports) to 40.2-43.1%, and produce suggested fixes that closely resemble\ndeveloper patches (CodeBLEU around 56-57%). Both our manual evaluations and\nLLM-as-a-judge assessment show that Agentic-LLM delivers stronger root-cause\nexplanations and more actionable repair guidance. A user study with 16\nparticipants further confirms that enhanced reports make crashes easier to\nunderstand and resolve, with the largest improvement in repair guidance. These\nresults indicate that supplying LLMs with stack traces and repository code\nyields enhanced crash reports that are substantially more useful for debugging.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u589e\u5f3a\u5d29\u6e83\u62a5\u544a\uff0c\u5bf9\u6bd4\u4e24\u79cd\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u589e\u5f3a\u62a5\u544a\u5bf9\u8c03\u8bd5\u66f4\u6709\u7528\u3002", "motivation": "\u8bb8\u591a\u5d29\u6e83\u62a5\u544a\u7f3a\u4e4f\u5f00\u53d1\u8005\u9ad8\u6548\u8c03\u8bd5\u6240\u9700\u7684\u8bca\u65ad\u7ec6\u8282\uff0c\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u589e\u5f3a\u5d29\u6e83\u62a5\u544a\u3002", "method": "\u7814\u7a76\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\uff0cDirect - LLM\u5355\u6b65\u65b9\u6cd5\u548cAgentic - LLM\u8fed\u4ee3\u65b9\u6cd5\uff0c\u5e76\u5728492\u4e2a\u771f\u5b9e\u4e16\u754c\u5d29\u6e83\u62a5\u544a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u3002", "result": "\u589e\u5f3a\u62a5\u544a\u5c06Top - 1\u95ee\u9898\u5b9a\u4f4d\u51c6\u786e\u7387\u4ece10.6%\u63d0\u9ad8\u523040.2 - 43.1%\uff0c\u4fee\u590d\u5efa\u8bae\u4e0e\u5f00\u53d1\u8005\u8865\u4e01\u76f8\u4f3c\uff0cAgentic - LLM\u8868\u73b0\u66f4\u597d\uff0c\u7528\u6237\u7814\u7a76\u8868\u660e\u589e\u5f3a\u62a5\u544a\u4f7f\u5d29\u6e83\u66f4\u6613\u7406\u89e3\u548c\u89e3\u51b3\u3002", "conclusion": "\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u5806\u6808\u8ddf\u8e2a\u548c\u4ed3\u5e93\u4ee3\u7801\u53ef\u751f\u6210\u5bf9\u8c03\u8bd5\u66f4\u6709\u7528\u7684\u589e\u5f3a\u5d29\u6e83\u62a5\u544a\u3002"}}
{"id": "2509.13523", "pdf": "https://arxiv.org/pdf/2509.13523", "abs": "https://arxiv.org/abs/2509.13523", "authors": ["V\u00e4in\u00f6 Hatanp\u00e4\u00e4", "Eugene Ku", "Jason Stock", "Murali Emani", "Sam Foreman", "Chunyong Jung", "Sandeep Madireddy", "Tung Nguyen", "Varuni Sastry", "Ray A. O. Sinurat", "Sam Wheeler", "Huihuo Zheng", "Troy Arcomano", "Venkatram Vishwanath", "Rao Kotamarthi"], "title": "AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions", "categories": ["cs.LG", "cs.DC"], "comment": "14 pages, 7 figures", "summary": "Generative machine learning offers new opportunities to better understand\ncomplex Earth system dynamics. Recent diffusion-based methods address spectral\nbiases and improve ensemble calibration in weather forecasting compared to\ndeterministic methods, yet have so far proven difficult to scale stably at high\nresolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin\ndiffusion transformer to address this gap, and SWiPe, a generalizable technique\nthat composes window parallelism with sequence and pipeline parallelism to\nshard window-based transformers without added communication cost or increased\nglobal batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS\n(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \\times 1$\npatch size on the 0.25{\\deg} ERA5 dataset, achieving 95.5% weak scaling\nefficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS\nand remains stable on seasonal scales to 90 days, highlighting the potential of\nbillion-parameter diffusion models for weather and climate prediction.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdAERIS\u6a21\u578b\u548cSWiPe\u6280\u672f\uff0c\u5728\u6c14\u8c61\u9884\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u51f8\u663e\u5341\u4ebf\u53c2\u6570\u6269\u6563\u6a21\u578b\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u65b9\u6cd5\u5728\u9ad8\u5206\u8fa8\u7387\u4e0b\u96be\u4ee5\u7a33\u5b9a\u6269\u5c55\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5f15\u5165AERIS\u6a21\u578b\u548cSWiPe\u6280\u672f\u3002", "result": "AERIS\u5728Aurora\u4e0a\u6709\u9ad8\u8ba1\u7b97\u6027\u80fd\uff0c\u6709\u9ad8\u7f29\u653e\u6548\u7387\uff0c\u8868\u73b0\u4f18\u4e8eIFS ENS\u4e14\u572890\u5929\u5b63\u8282\u5c3a\u5ea6\u7a33\u5b9a\u3002", "conclusion": "\u5341\u4ebf\u53c2\u6570\u6269\u6563\u6a21\u578b\u5728\u6c14\u8c61\u548c\u6c14\u5019\u9884\u6d4b\u4e2d\u6709\u6f5c\u529b\u3002"}}
{"id": "2509.13805", "pdf": "https://arxiv.org/pdf/2509.13805", "abs": "https://arxiv.org/abs/2509.13805", "authors": ["Florian Wiesner", "Matthias Wessling", "Stephen Baek"], "title": "Towards a Physics Foundation Model", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Foundation models have revolutionized natural language processing through a\n``train once, deploy anywhere'' paradigm, where a single pre-trained model\nadapts to countless downstream tasks without retraining. Access to a Physics\nFoundation Model (PFM) would be transformative -- democratizing access to\nhigh-fidelity simulations, accelerating scientific discovery, and eliminating\nthe need for specialized solver development. Yet current physics-aware machine\nlearning approaches remain fundamentally limited to single, narrow domains and\nrequire retraining for each new system. We present the General Physics\nTransformer (GPhyT), trained on 1.8 TB of diverse simulation data, that\ndemonstrates foundation model capabilities are achievable for physics. Our key\ninsight is that transformers can learn to infer governing dynamics from\ncontext, enabling a single model to simulate fluid-solid interactions, shock\nwaves, thermal convection, and multi-phase dynamics without being told the\nunderlying equations. GPhyT achieves three critical breakthroughs: (1) superior\nperformance across multiple physics domains, outperforming specialized\narchitectures by up to 29x, (2) zero-shot generalization to entirely unseen\nphysical systems through in-context learning, and (3) stable long-term\npredictions through 50-timestep rollouts. By establishing that a single model\ncan learn generalizable physical principles from data alone, this work opens\nthe path toward a universal PFM that could transform computational science and\nengineering.", "AI": {"tldr": "\u63d0\u51fa\u901a\u7528\u7269\u7406\u53d8\u538b\u5668\uff08GPhyT\uff09\uff0c\u5c55\u793a\u7269\u7406\u9886\u57df\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u6709\u4e09\u9879\u5173\u952e\u7a81\u7834\uff0c\u4e3a\u901a\u7528\u7269\u7406\u57fa\u7840\u6a21\u578b\u5f00\u8f9f\u9053\u8def\u3002", "motivation": "\u5f53\u524d\u7269\u7406\u611f\u77e5\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5c40\u9650\u4e8e\u5355\u4e00\u72ed\u7a84\u9886\u57df\u4e14\u9700\u4e3a\u65b0\u7cfb\u7edf\u91cd\u65b0\u8bad\u7ec3\uff0c\u671f\u671b\u83b7\u5f97\u7269\u7406\u57fa\u7840\u6a21\u578b\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6a21\u62df\u666e\u53ca\u3001\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u548c\u6d88\u9664\u4e13\u7528\u6c42\u89e3\u5668\u5f00\u53d1\u9700\u6c42\u3002", "method": "\u57fa\u4e8e1.8TB\u591a\u6837\u6a21\u62df\u6570\u636e\u8bad\u7ec3\u901a\u7528\u7269\u7406\u53d8\u538b\u5668\uff08GPhyT\uff09\uff0c\u8ba9\u53d8\u6362\u5668\u4ece\u4e0a\u4e0b\u6587\u5b66\u4e60\u63a8\u65ad\u63a7\u5236\u52a8\u529b\u5b66\u3002", "result": "GPhyT\u6709\u4e09\u9879\u7a81\u7834\uff1a\u8de8\u591a\u7269\u7406\u9886\u57df\u6027\u80fd\u4f18\u8d8a\uff0c\u6bd4\u4e13\u7528\u67b6\u6784\u9ad829\u500d\uff1b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u96f6\u6837\u672c\u6cdb\u5316\u5230\u672a\u89c1\u7269\u7406\u7cfb\u7edf\uff1b50\u65f6\u95f4\u6b65\u957f\u6eda\u52a8\u5b9e\u73b0\u7a33\u5b9a\u957f\u671f\u9884\u6d4b\u3002", "conclusion": "\u5355\u4e2a\u6a21\u578b\u53ef\u4ece\u6570\u636e\u5b66\u4e60\u901a\u7528\u7269\u7406\u539f\u7406\uff0c\u4e3a\u901a\u7528\u7269\u7406\u57fa\u7840\u6a21\u578b\u53d8\u9769\u8ba1\u7b97\u79d1\u5b66\u548c\u5de5\u7a0b\u5f00\u8f9f\u9053\u8def\u3002"}}
{"id": "2509.14057", "pdf": "https://arxiv.org/pdf/2509.14057", "abs": "https://arxiv.org/abs/2509.14057", "authors": ["Riccardo Zanardelli"], "title": "Machines are more productive than humans until they aren't, and vice versa", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": null, "summary": "With the growth of artificial skills, organizations may increasingly confront\nwith the problem of optimizing skill policy decisions guided by economic\nprinciples. This paper addresses the underlying complexity of this challenge by\ndeveloping an in-silico framework based on Monte Carlo simulations grounded in\nempirical realism to analyze the economic impact of human and machine skills,\nindividually or jointly deployed, in the execution of tasks presenting varying\nlevels of complexity. Our results provide quantitative support for the\nestablished notions that automation tends to be the most economically-effective\nstrategy for tasks characterized by low-to-medium generalization difficulty,\nwhile automation struggles to match the economic utility of human skills in\nmore complex scenarios. Critically, our simulations highlight that combining\nhuman and machine skills can be the most effective strategy when a high level\nof generalization is required, but only if genuine augmentation is achieved. In\ncontrast, when failing to realize this synergy, the human-machine policy is\nseverely penalized by the inherent costs of its dual skill structure, causing\nit to destroy value and becoming the worst choice from an economic perspective.\nThe takeaway for decision-makers is unambiguous: simply allocating human and\nmachine skills to a task is insufficient, and a human-machine skill policy is\nneither a silver-bullet solution nor a low-risk compromise. Rather, it is a\ncritical opportunity to boost competitiveness that demands a strong\norganizational commitment to enabling augmentation. Also, our findings show\nthat improving the cost-effectiveness of machine skills over time, while\nuseful, does not replace the fundamental need to focus on achieving\naugmentation.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u8ba1\u7b97\u673a\u6a21\u62df\u6846\u67b6\u5206\u6790\u4eba\u673a\u6280\u80fd\u7ecf\u6d4e\u5f71\u54cd\uff0c\u53d1\u73b0\u81ea\u52a8\u5316\u9002\u7528\u4e8e\u4f4e\u4e2d\u590d\u6742\u5ea6\u4efb\u52a1\uff0c\u4eba\u673a\u7ed3\u5408\u5728\u9ad8\u6cdb\u5316\u573a\u666f\u6709\u6548\u4f46\u9700\u5b9e\u73b0\u589e\u5f3a\uff0c\u51b3\u7b56\u8005\u5e94\u81f4\u529b\u4e8e\u5b9e\u73b0\u589e\u5f3a\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u80fd\u53d1\u5c55\uff0c\u7ec4\u7ec7\u9762\u4e34\u57fa\u4e8e\u7ecf\u6d4e\u539f\u5219\u4f18\u5316\u6280\u80fd\u653f\u7b56\u51b3\u7b56\u7684\u6311\u6218\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u7684\u590d\u6742\u6027\u3002", "method": "\u57fa\u4e8e\u8499\u7279\u5361\u7f57\u6a21\u62df\u5f00\u53d1\u8ba1\u7b97\u673a\u6a21\u62df\u6846\u67b6\uff0c\u5206\u6790\u4eba\u673a\u6280\u80fd\u5355\u72ec\u6216\u8054\u5408\u6267\u884c\u4e0d\u540c\u590d\u6742\u5ea6\u4efb\u52a1\u7684\u7ecf\u6d4e\u5f71\u54cd\u3002", "result": "\u81ea\u52a8\u5316\u5728\u4f4e\u4e2d\u590d\u6742\u5ea6\u4efb\u52a1\u6700\u5177\u7ecf\u6d4e\u6548\u76ca\uff0c\u5728\u590d\u6742\u573a\u666f\u4eba\u673a\u7ed3\u5408\u53ef\u80fd\u6700\u6709\u6548\uff0c\u4f46\u9700\u5b9e\u73b0\u589e\u5f3a\uff0c\u5426\u5219\u7ecf\u6d4e\u8868\u73b0\u6700\u5dee\u3002", "conclusion": "\u7b80\u5355\u5206\u914d\u4eba\u673a\u6280\u80fd\u4e0d\u8db3\uff0c\u4eba\u673a\u6280\u80fd\u653f\u7b56\u9700\u7ec4\u7ec7\u81f4\u529b\u4e8e\u5b9e\u73b0\u589e\u5f3a\uff0c\u63d0\u9ad8\u673a\u5668\u6280\u80fd\u6210\u672c\u6548\u76ca\u4e0d\u80fd\u66ff\u4ee3\u5bf9\u589e\u5f3a\u7684\u5173\u6ce8\u3002"}}
{"id": "2509.13966", "pdf": "https://arxiv.org/pdf/2509.13966", "abs": "https://arxiv.org/abs/2509.13966", "authors": ["Mikhail Goncharov", "Alexander S. Kulikov", "Georgie Levtsov"], "title": "Smaller Circuits for Bit Addition", "categories": ["cs.CC", "cs.DM", "cs.DS", "cs.LO"], "comment": null, "summary": "Bit addition arises virtually everywhere in digital circuits: arithmetic\noperations, increment/decrement operators, computing addresses and table\nindices, and so on. Since bit addition is such a basic task in Boolean circuit\nsynthesis, a lot of research has been done on constructing efficient circuits\nfor various special cases of it. A vast majority of these results are devoted\nto optimizing the circuit depth (also known as delay).\n  In this paper, we investigate the circuit size (also known as area) over the\nfull binary basis of bit addition. Though most of the known circuits are built\nfrom Half Adders and Full Adders, we show that, in many interesting scenarios,\nthese circuits have suboptimal size. Namely, we improve an upper bound $5n-3m$\nto $4.5n-2m$, where $n$ is the number of input bits and $m$ is the number of\noutput bits. In the regimes where $m$ is small compared to $n$ (for example,\nfor computing the sum of $n$ bits or multiplying two $n$-bit integers), this\nleads to $10\\%$ improvement.\n  We complement our theoretical result by an open-source implementation of\ngenerators producing circuits for bit addition and multiplication. The\ngenerators allow one to produce the corresponding circuits in two lines of code\nand to compare them to existing designs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f4d\u52a0\u6cd5\u5728\u5168\u4e8c\u8fdb\u5236\u57fa\u4e0a\u7684\u7535\u8def\u89c4\u6a21\uff0c\u6539\u8fdb\u4e86\u4e0a\u754c\uff0c\u5728\u67d0\u4e9b\u573a\u666f\u670910%\u7684\u63d0\u5347\uff0c\u5e76\u7ed9\u51fa\u5f00\u6e90\u5b9e\u73b0\u3002", "motivation": "\u5df2\u6709\u5f88\u591a\u5173\u4e8e\u4f4d\u52a0\u6cd5\u7535\u8def\u6df1\u5ea6\u4f18\u5316\u7684\u7814\u7a76\uff0c\u672c\u6587\u805a\u7126\u7535\u8def\u89c4\u6a21\u4f18\u5316\u3002", "method": "\u5206\u6790\u5df2\u77e5\u7531\u534a\u52a0\u5668\u548c\u5168\u52a0\u5668\u6784\u5efa\u7684\u7535\u8def\uff0c\u6539\u8fdb\u4e0a\u754c\u3002", "result": "\u5c06\u4e0a\u754c\u4ece$5n - 3m$\u6539\u8fdb\u5230$4.5n - 2m$\uff0c\u5728$m$\u6bd4$n$\u5c0f\u7684\u573a\u666f\u670910%\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u66f4\u4f18\u7684\u4f4d\u52a0\u6cd5\u7535\u8def\u89c4\u6a21\u4e0a\u754c\uff0c\u5e76\u7ed9\u51fa\u5f00\u6e90\u751f\u6210\u5668\u7528\u4e8e\u751f\u6210\u548c\u6bd4\u8f83\u7535\u8def\u3002"}}
{"id": "2509.14112", "pdf": "https://arxiv.org/pdf/2509.14112", "abs": "https://arxiv.org/abs/2509.14112", "authors": ["Muqsit Azeem", "Jan Kretinsky", "Maximilian Weininger"], "title": "Sound Value Iteration for Simple Stochastic Games", "categories": ["cs.GT", "cs.MA"], "comment": "In Proceedings GandALF 2025, arXiv:2509.13258. A full version of this\n  paper appears at arXiv:2411.11549", "summary": "Algorithmic analysis of Markov decision processes (MDP) and stochastic games\n(SG) in practice relies on value-iteration (VI) algorithms. Since basic VI does\nnot provide guarantees on the precision of the result, variants of VI have been\nproposed that offer such guarantees. In particular, sound value iteration (SVI)\nnot only provides precise lower and upper bounds on the result, but also\nconverges faster in the presence of probabilistic cycles. Unfortunately, it is\nneither applicable to SG, nor to MDP with end components. In this paper, we\nextend SVI and cover both cases. The technical challenge consists mainly in\nproper treatment of end components, which require different handling than in\nthe literature. Moreover, we provide several optimizations of SVI. Finally, we\nevaluate our prototype implementation experimentally to demonstrate its\npotential on systems with probabilistic cycles.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86SVI\u7b97\u6cd5\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u968f\u673a\u535a\u5f08\u548c\u5e26\u7ec8\u7ec4\u4ef6\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u8fdb\u884c\u4f18\u5316\u548c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "motivation": "\u57fa\u672c\u503c\u8fed\u4ee3\u7b97\u6cd5\u65e0\u7ed3\u679c\u7cbe\u5ea6\u4fdd\u8bc1\uff0cSVI\u867d\u6709\u6539\u8fdb\u4f46\u4e0d\u9002\u7528\u4e8e\u968f\u673a\u535a\u5f08\u548c\u5e26\u7ec8\u7ec4\u4ef6\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u9700\u8fdb\u884c\u6269\u5c55\u3002", "method": "\u5bf9SVI\u7b97\u6cd5\u8fdb\u884c\u6269\u5c55\uff0c\u59a5\u5584\u5904\u7406\u7ec8\u7ec4\u4ef6\uff0c\u4e14\u63d0\u4f9bSVI\u7684\u4f18\u5316\u3002", "result": "\u5b9e\u73b0\u4e86\u6269\u5c55\u548c\u4f18\u5316\u540e\u7684SVI\u7b97\u6cd5\u7684\u539f\u578b\u3002", "conclusion": "\u5b9e\u9a8c\u8bc1\u660e\u6269\u5c55\u548c\u4f18\u5316\u540e\u7684SVI\u7b97\u6cd5\u5728\u542b\u6982\u7387\u5faa\u73af\u7684\u7cfb\u7edf\u4e2d\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.14221", "pdf": "https://arxiv.org/pdf/2509.14221", "abs": "https://arxiv.org/abs/2509.14221", "authors": ["Silan Hu", "Shiqi Zhang", "Yimin Shi", "Xiaokui Xiao"], "title": "GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing\ngenerative engines, such as LLM-based chatbots, by seamlessly integrating\nrelevant advertisements into their responses. At the core of GEM lies the\ngeneration and evaluation of ad-injected responses. However, existing\nbenchmarks are not specifically designed for this purpose, which limits future\nresearch. To address this gap, we propose GEM-Bench, the first comprehensive\nbenchmark for ad-injected response generation in GEM. GEM-Bench includes three\ncurated datasets covering both chatbot and search scenarios, a metric ontology\nthat captures multiple dimensions of user satisfaction and engagement, and\nseveral baseline solutions implemented within an extensible multi-agent\nframework. Our preliminary results indicate that, while simple prompt-based\nmethods achieve reasonable engagement such as click-through rate, they often\nreduce user satisfaction. In contrast, approaches that insert ads based on\npre-generated ad-free responses help mitigate this issue but introduce\nadditional overhead. These findings highlight the need for future research on\ndesigning more effective and efficient solutions for generating ad-injected\nresponses in GEM.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u9488\u5bf9GEM\u4e2d\u5e7f\u544a\u6ce8\u5165\u56de\u590d\u751f\u6210\u7684\u7efc\u5408\u57fa\u51c6GEM - Bench\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u65b9\u6cd5\u5404\u6709\u4f18\u52a3\uff0c\u9700\u540e\u7eed\u7814\u7a76\u66f4\u6709\u6548\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u672a\u9488\u5bf9GEM\u4e2d\u5e7f\u544a\u6ce8\u5165\u56de\u590d\u7684\u751f\u6210\u548c\u8bc4\u4f30\uff0c\u9650\u5236\u4e86\u672a\u6765\u7814\u7a76\u3002", "method": "\u63d0\u51faGEM - Bench\uff0c\u5305\u542b\u4e09\u4e2a\u6db5\u76d6\u804a\u5929\u673a\u5668\u4eba\u548c\u641c\u7d22\u573a\u666f\u7684\u6570\u636e\u96c6\u3001\u6355\u83b7\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u53c2\u4e0e\u5ea6\u591a\u7ef4\u5ea6\u7684\u5ea6\u91cf\u672c\u4f53\uff0c\u4ee5\u53ca\u5728\u53ef\u6269\u5c55\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5185\u5b9e\u73b0\u7684\u591a\u4e2a\u57fa\u7ebf\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7b80\u5355\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u80fd\u5b9e\u73b0\u5408\u7406\u53c2\u4e0e\u5ea6\u4f46\u964d\u4f4e\u7528\u6237\u6ee1\u610f\u5ea6\uff1b\u57fa\u4e8e\u9884\u751f\u6210\u65e0\u5e7f\u544a\u56de\u590d\u63d2\u5165\u5e7f\u544a\u7684\u65b9\u6cd5\u53ef\u7f13\u89e3\u6b64\u95ee\u9898\u4f46\u589e\u52a0\u989d\u5916\u5f00\u9500\u3002", "conclusion": "\u9700\u8981\u672a\u6765\u7814\u7a76\u8bbe\u8ba1\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684GEM\u5e7f\u544a\u6ce8\u5165\u56de\u590d\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13793", "pdf": "https://arxiv.org/pdf/2509.13793", "abs": "https://arxiv.org/abs/2509.13793", "authors": ["Thomas Chaffey"], "title": "Circuit realization and hardware linearization of monotone operator equilibrium networks", "categories": ["eess.SY", "cs.LG", "cs.NE", "cs.SY", "math.OC", "65K10, 68T05, 93B30, 93D99"], "comment": null, "summary": "It is shown that the port behavior of a resistor-diode network corresponds to\nthe solution of a ReLU monotone operator equilibrium network (a neural network\nin the limit of infinite depth), giving a parsimonious construction of a neural\nnetwork in analog hardware. We furthermore show that the gradient of such a\ncircuit can be computed directly in hardware, using a procedure we call\nhardware linearization. This allows the network to be trained in hardware,\nwhich we demonstrate with a device-level circuit simulation. We extend the\nresults to cascades of resistor-diode networks, which can be used to implement\nfeedforward and other asymmetric networks. We finally show that different\nnonlinear elements give rise to different activation functions, and introduce\nthe novel diode ReLU which is induced by a non-ideal diode model.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u7535\u963b - \u4e8c\u6781\u7ba1\u7f51\u7edc\u7aef\u53e3\u884c\u4e3a\u5bf9\u5e94ReLU\u5355\u8c03\u7b97\u5b50\u5e73\u8861\u7f51\u7edc\u89e3\uff0c\u53ef\u5728\u6a21\u62df\u786c\u4ef6\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u63d0\u51fa\u786c\u4ef6\u7ebf\u6027\u5316\u8ba1\u7b97\u68af\u5ea6\u5e76\u8bad\u7ec3\uff0c\u62d3\u5c55\u81f3\u7ea7\u8054\u7f51\u7edc\uff0c\u5f15\u5165\u65b0\u578b\u4e8c\u6781\u7ba1ReLU\u3002", "motivation": "\u5728\u6a21\u62df\u786c\u4ef6\u4e2d\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u7684\u7b80\u7ea6\u6784\u5efa\u5e76\u89e3\u51b3\u8bad\u7ec3\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u786c\u4ef6\u7ebf\u6027\u5316\u65b9\u6cd5\u8ba1\u7b97\u7535\u8def\u68af\u5ea6\uff0c\u8fdb\u884c\u8bbe\u5907\u7ea7\u7535\u8def\u4eff\u771f\u3002", "result": "\u53ef\u5728\u786c\u4ef6\u4e2d\u8bad\u7ec3\u7f51\u7edc\uff0c\u62d3\u5c55\u7ed3\u679c\u5230\u7ea7\u8054\u7f51\u7edc\uff0c\u5f15\u5165\u65b0\u578b\u4e8c\u6781\u7ba1ReLU\u3002", "conclusion": "\u7535\u963b - \u4e8c\u6781\u7ba1\u7f51\u7edc\u80fd\u5728\u6a21\u62df\u786c\u4ef6\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u4e0d\u540c\u975e\u7ebf\u6027\u5143\u4ef6\u4ea7\u751f\u4e0d\u540c\u6fc0\u6d3b\u51fd\u6570\u3002"}}
{"id": "2509.13341", "pdf": "https://arxiv.org/pdf/2509.13341", "abs": "https://arxiv.org/abs/2509.13341", "authors": ["Ahmet H. G\u00fczel", "Matthew Thomas Jackson", "Jarek Luca Liesen", "Tim Rockt\u00e4schel", "Jakob Nicolaus Foerster", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Imagined Autocurricula", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Training agents to act in embodied environments typically requires vast\ntraining data or access to accurate simulation, neither of which exists for\nmany cases in the real world. Instead, world models are emerging as an\nalternative leveraging offline, passively collected data, they make it possible\nto generate diverse worlds for training agents in simulation. In this work, we\nharness world models to generate imagined environments to train robust agents\ncapable of generalizing to novel task variations. One of the challenges in\ndoing this is ensuring the agent trains on useful generated data. We thus\npropose a novel approach, IMAC (Imagined Autocurricula), leveraging\nUnsupervised Environment Design (UED), which induces an automatic curriculum\nover generated worlds. In a series of challenging, procedurally generated\nenvironments, we show it is possible to achieve strong transfer performance on\nheld-out environments, having trained only inside a world model learned from a\nnarrower dataset. We believe this opens the path to utilizing larger-scale,\nfoundation world models for generally capable agents.", "AI": {"tldr": "\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u60f3\u8c61\u73af\u5883\u8bad\u7ec3\u9c81\u68d2\u4ee3\u7406\uff0c\u63d0\u51faIMAC\u65b9\u6cd5\uff0c\u5728\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\u5b9e\u73b0\u5f3a\u8fc1\u79fb\u6027\u80fd\u3002", "motivation": "\u8bad\u7ec3\u5177\u8eab\u73af\u5883\u4e2d\u7684\u4ee3\u7406\u901a\u5e38\u9700\u5927\u91cf\u6570\u636e\u6216\u7cbe\u786e\u6a21\u62df\uff0c\u73b0\u5b9e\u4e2d\u5f88\u591a\u60c5\u51b5\u4e0d\u5177\u5907\uff0c\u56e0\u6b64\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u591a\u6837\u4e16\u754c\u6765\u8bad\u7ec3\u4ee3\u7406\u3002", "method": "\u63d0\u51faIMAC\uff08Imagined Autocurricula\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff08UED\uff09\u5728\u751f\u6210\u7684\u4e16\u754c\u4e0a\u5f15\u5165\u81ea\u52a8\u8bfe\u7a0b\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u5177\u6709\u6311\u6218\u6027\u7684\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\uff0c\u4ec5\u5728\u4ece\u8f83\u7a84\u6570\u636e\u96c6\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u5185\u8bad\u7ec3\uff0c\u5c31\u80fd\u5728\u4fdd\u7559\u73af\u5883\u4e2d\u5b9e\u73b0\u5f3a\u8fc1\u79fb\u6027\u80fd\u3002", "conclusion": "\u8fd9\u4e3a\u5229\u7528\u66f4\u5927\u89c4\u6a21\u7684\u57fa\u7840\u4e16\u754c\u6a21\u578b\u8bad\u7ec3\u901a\u7528\u80fd\u529b\u7684\u4ee3\u7406\u5f00\u8f9f\u4e86\u9053\u8def\u3002"}}
{"id": "2509.13650", "pdf": "https://arxiv.org/pdf/2509.13650", "abs": "https://arxiv.org/abs/2509.13650", "authors": ["Amena Amro", "Manar H. Alalfi"], "title": "GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "As software development practices increasingly adopt AI-powered tools,\nensuring that such tools can support secure coding has become critical. This\nstudy evaluates the effectiveness of GitHub Copilot's recently introduced code\nreview feature in detecting security vulnerabilities. Using a curated set of\nlabeled vulnerable code samples drawn from diverse open-source projects\nspanning multiple programming languages and application domains, we\nsystematically assessed Copilot's ability to identify and provide feedback on\ncommon security flaws. Contrary to expectations, our results reveal that\nCopilot's code review frequently fails to detect critical vulnerabilities such\nas SQL injection, cross-site scripting (XSS), and insecure deserialization.\nInstead, its feedback primarily addresses low-severity issues, such as coding\nstyle and typographical errors. These findings expose a significant gap between\nthe perceived capabilities of AI-assisted code review and its actual\neffectiveness in supporting secure development practices. Our results highlight\nthe continued necessity of dedicated security tools and manual code audits to\nensure robust software security.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30GitHub Copilot\u4ee3\u7801\u5ba1\u67e5\u529f\u80fd\u68c0\u6d4b\u5b89\u5168\u6f0f\u6d1e\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u5176\u5e38\u65e0\u6cd5\u68c0\u6d4b\u5173\u952e\u6f0f\u6d1e\uff0c\u51f8\u663e\u4e13\u7528\u5b89\u5168\u5de5\u5177\u548c\u4eba\u5de5\u5ba1\u67e5\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5f00\u53d1\u91c7\u7528AI\u5de5\u5177\uff0c\u786e\u4fdd\u5176\u652f\u6301\u5b89\u5168\u7f16\u7801\u81f3\u5173\u91cd\u8981\uff0c\u8bc4\u4f30GitHub Copilot\u4ee3\u7801\u5ba1\u67e5\u529f\u80fd\u68c0\u6d4b\u5b89\u5168\u6f0f\u6d1e\u7684\u6709\u6548\u6027\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u4e0d\u540c\u5f00\u6e90\u9879\u76ee\u7684\u6807\u8bb0\u6f0f\u6d1e\u4ee3\u7801\u6837\u672c\uff0c\u7cfb\u7edf\u8bc4\u4f30Copilot\u8bc6\u522b\u5e38\u89c1\u5b89\u5168\u6f0f\u6d1e\u5e76\u63d0\u4f9b\u53cd\u9988\u7684\u80fd\u529b\u3002", "result": "Copilot\u4ee3\u7801\u5ba1\u67e5\u5e38\u65e0\u6cd5\u68c0\u6d4b\u5173\u952e\u6f0f\u6d1e\uff0c\u5982SQL\u6ce8\u5165\u3001XSS\u548c\u4e0d\u5b89\u5168\u53cd\u5e8f\u5217\u5316\uff0c\u4e3b\u8981\u5173\u6ce8\u4f4e\u4e25\u91cd\u6027\u95ee\u9898\u3002", "conclusion": "AI\u8f85\u52a9\u4ee3\u7801\u5ba1\u67e5\u5b9e\u9645\u6548\u679c\u4e0e\u9884\u671f\u6709\u5dee\u8ddd\uff0c\u4ecd\u9700\u4e13\u7528\u5b89\u5168\u5de5\u5177\u548c\u4eba\u5de5\u4ee3\u7801\u5ba1\u8ba1\u786e\u4fdd\u8f6f\u4ef6\u5b89\u5168\u3002"}}
{"id": "2509.13527", "pdf": "https://arxiv.org/pdf/2509.13527", "abs": "https://arxiv.org/abs/2509.13527", "authors": ["Yulia Pimonova", "Michael G. Taylor", "Alice Allen", "Ping Yang", "Nicholas Lubbers"], "title": "Meta-Learning Linear Models for Molecular Property Prediction", "categories": ["cs.LG", "physics.chem-ph"], "comment": "26 pages, 16 figures", "summary": "Chemists in search of structure-property relationships face great challenges\ndue to limited high quality, concordant datasets. Machine learning (ML) has\nsignificantly advanced predictive capabilities in chemical sciences, but these\nmodern data-driven approaches have increased the demand for data. In response\nto the growing demand for explainable AI (XAI) and to bridge the gap between\npredictive accuracy and human comprehensibility, we introduce LAMeL - a Linear\nAlgorithm for Meta-Learning that preserves interpretability while improving the\nprediction accuracy across multiple properties. While most approaches treat\neach chemical prediction task in isolation, LAMeL leverages a meta-learning\nframework to identify shared model parameters across related tasks, even if\nthose tasks do not share data, allowing it to learn a common functional\nmanifold that serves as a more informed starting point for new unseen tasks.\nOur method delivers performance improvements ranging from 1.1- to 25-fold over\nstandard ridge regression, depending on the domain of the dataset. While the\ndegree of performance enhancement varies across tasks, LAMeL consistently\noutperforms or matches traditional linear methods, making it a reliable tool\nfor chemical property prediction where both accuracy and interpretability are\ncritical.", "AI": {"tldr": "\u4e3a\u5e94\u5bf9\u5316\u5b66\u7ed3\u6784 - \u6027\u8d28\u5173\u7cfb\u7814\u7a76\u4e2d\u6570\u636e\u6311\u6218\uff0c\u5f15\u5165LAMeL\u7b97\u6cd5\uff0c\u5728\u591a\u5c5e\u6027\u9884\u6d4b\u4e0a\u63d0\u5347\u51c6\u786e\u7387\u5e76\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5316\u5b66\u9886\u57df\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u6709\u9650\uff0c\u673a\u5668\u5b66\u4e60\u5bf9\u6570\u636e\u9700\u6c42\u589e\u52a0\uff0c\u4e14\u9700\u8981\u53ef\u89e3\u91caAI\u4ee5\u5e73\u8861\u9884\u6d4b\u51c6\u786e\u6027\u548c\u4eba\u7c7b\u53ef\u7406\u89e3\u6027\u3002", "method": "\u5f15\u5165LAMeL\u7ebf\u6027\u5143\u5b66\u4e60\u7b97\u6cd5\uff0c\u5229\u7528\u5143\u5b66\u4e60\u6846\u67b6\u8bc6\u522b\u76f8\u5173\u4efb\u52a1\u95f4\u5171\u4eab\u6a21\u578b\u53c2\u6570\uff0c\u5b66\u4e60\u901a\u7528\u529f\u80fd\u6d41\u5f62\u4e3a\u65b0\u4efb\u52a1\u63d0\u4f9b\u8d77\u70b9\u3002", "result": "LAMeL\u5728\u4e0d\u540c\u6570\u636e\u96c6\u9886\u57df\u6027\u80fd\u6bd4\u6807\u51c6\u5cad\u56de\u5f52\u63d0\u53471.1 - 25\u500d\uff0c\u5728\u5404\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6216\u5339\u914d\u4f20\u7edf\u7ebf\u6027\u65b9\u6cd5\u3002", "conclusion": "LAMeL\u662f\u5316\u5b66\u6027\u8d28\u9884\u6d4b\u4e2d\u517c\u987e\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2509.14102", "pdf": "https://arxiv.org/pdf/2509.14102", "abs": "https://arxiv.org/abs/2509.14102", "authors": ["Felicia Nguyen"], "title": "Incentivizing High Quality Entrants When Creators Are Strategic", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "We study how a platform should design early exposure and rewards when\ncreators strategically choose quality before release. A short testing window\nwith a pass/fail bar induces a pass probability, the slope of which is the key\nsufficient statistic for incentives. We derive three main results. First, a\nclosed-form ``implementability bounty'' can perfectly align creator and\nplatform objectives, correcting for incomplete revenue sharing. Second,\nfront-loading guaranteed impressions is the most effective way to strengthen\nincentives for a given attention budget. Third, when impression and cash\nbudgets are constrained, the optimal policy follows an equal-marginal-value\nrule based on the prize spread and certain exposure. We map realistic ranking\nengines (e.g., Thompson sampling) into the model's parameters and provide\ntelemetry-based estimators. The framework is simple to operationalize and\noffers a direct, managerially interpretable solution for platforms to solve the\ncreator cold-start problem and cultivate high-quality supply.", "AI": {"tldr": "\u7814\u7a76\u5e73\u53f0\u5728\u521b\u4f5c\u8005\u53d1\u5e03\u524d\u7b56\u7565\u6027\u9009\u62e9\u8d28\u91cf\u65f6\u5982\u4f55\u8bbe\u8ba1\u65e9\u671f\u66dd\u5149\u548c\u5956\u52b1\uff0c\u5f97\u51fa\u4e09\u4e2a\u4e3b\u8981\u7ed3\u679c\u5e76\u7ed9\u51fa\u53ef\u64cd\u4f5c\u6846\u67b6\u89e3\u51b3\u521b\u4f5c\u8005\u51b7\u542f\u52a8\u95ee\u9898\u3002", "motivation": "\u63a2\u8ba8\u5e73\u53f0\u5728\u521b\u4f5c\u8005\u7b56\u7565\u6027\u9009\u62e9\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u8bbe\u8ba1\u65e9\u671f\u66dd\u5149\u548c\u5956\u52b1\u673a\u5236\u3002", "method": "\u4ee5\u77ed\u6d4b\u8bd5\u7a97\u53e3\u7684\u901a\u8fc7/\u5931\u8d25\u6807\u51c6\u8bf1\u5bfc\u901a\u8fc7\u6982\u7387\uff0c\u5c06\u5176\u659c\u7387\u4f5c\u4e3a\u6fc0\u52b1\u7684\u5173\u952e\u7edf\u8ba1\u91cf\u3002", "result": "\u4e00\u662f\u5f97\u51fa\u5c01\u95ed\u5f62\u5f0f\u7684\u201c\u53ef\u5b9e\u65bd\u8d4f\u91d1\u201d\u80fd\u4f7f\u521b\u4f5c\u8005\u548c\u5e73\u53f0\u76ee\u6807\u4e00\u81f4\uff1b\u4e8c\u662f\u63d0\u524d\u5206\u914d\u4fdd\u8bc1\u66dd\u5149\u91cf\u662f\u589e\u5f3a\u6fc0\u52b1\u7684\u6700\u6709\u6548\u65b9\u5f0f\uff1b\u4e09\u662f\u9884\u7b97\u53d7\u9650\u4e0b\u6700\u4f18\u653f\u7b56\u9075\u5faa\u7b49\u8fb9\u9645\u4ef7\u503c\u89c4\u5219\u3002", "conclusion": "\u8be5\u6846\u67b6\u6613\u4e8e\u64cd\u4f5c\uff0c\u4e3a\u5e73\u53f0\u89e3\u51b3\u521b\u4f5c\u8005\u51b7\u542f\u52a8\u95ee\u9898\u548c\u57f9\u517b\u9ad8\u8d28\u91cf\u5185\u5bb9\u4f9b\u5e94\u63d0\u4f9b\u76f4\u63a5\u3001\u53ef\u7ba1\u7406\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13370", "pdf": "https://arxiv.org/pdf/2509.13370", "abs": "https://arxiv.org/abs/2509.13370", "authors": ["Andrew Conway", "Michelle Blom", "Alexander Ek", "Peter Stuckey", "Vanessa Teague", "Damjan Vukcevic"], "title": "To whom did my vote go?", "categories": ["cs.CY", "cs.GT"], "comment": null, "summary": "Single Transferable Vote (STV) counting, used in several jurisdictions in\nAustralia, is a system for choosing multiple election winners given voters'\npreferences among candidates. The system is complex and it is not always\nobvious how an individual's vote contributes to candidates' tallies across\nrounds of tabulation. This short paper presents a demonstration system that\nallows voters to enter an example vote in a past Australian STV election, and\nsee: (i)~how that vote would have been transferred between candidates; and\n(ii)~how much that vote would have contributed to the tallies of relevant\ncandidates, across rounds of tabulation.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u6f14\u793a\u7cfb\u7edf\uff0c\u53ef\u8ba9\u9009\u6c11\u4e86\u89e3\u5176\u5728\u6fb3\u5927\u5229\u4e9aSTV\u9009\u4e3e\u4e2d\u7684\u9009\u7968\u8f6c\u79fb\u548c\u8ba1\u7968\u8d21\u732e\u3002", "motivation": "STV\u8ba1\u7968\u7cfb\u7edf\u590d\u6742\uff0c\u9009\u6c11\u96be\u4ee5\u4e86\u89e3\u4e2a\u4eba\u9009\u7968\u5728\u5404\u8f6e\u8ba1\u7968\u4e2d\u5bf9\u5019\u9009\u4eba\u7968\u6570\u7684\u8d21\u732e\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u6f14\u793a\u7cfb\u7edf\uff0c\u8ba9\u9009\u6c11\u8f93\u5165\u8fc7\u53bb\u6fb3\u5927\u5229\u4e9aSTV\u9009\u4e3e\u7684\u793a\u4f8b\u9009\u7968\u3002", "result": "\u8be5\u7cfb\u7edf\u53ef\u5c55\u793a\u9009\u7968\u5728\u5019\u9009\u4eba\u4e4b\u95f4\u7684\u8f6c\u79fb\u60c5\u51b5\uff0c\u4ee5\u53ca\u5bf9\u76f8\u5173\u5019\u9009\u4eba\u7968\u6570\u7684\u8d21\u732e\u3002", "conclusion": "\u8be5\u6f14\u793a\u7cfb\u7edf\u6709\u52a9\u4e8e\u9009\u6c11\u7406\u89e3STV\u8ba1\u7968\u8fc7\u7a0b\u4e2d\u4e2a\u4eba\u9009\u7968\u7684\u4f5c\u7528\u3002"}}
{"id": "2509.13586", "pdf": "https://arxiv.org/pdf/2509.13586", "abs": "https://arxiv.org/abs/2509.13586", "authors": ["Nathalie Neptune", "Josiane Mothe"], "title": "Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.MM", "I.2; I.4; I.7; H.3"], "comment": null, "summary": "The Amazon rain forest is a vital ecosystem that plays a crucial role in\nregulating the Earth's climate and providing habitat for countless species.\nDeforestation in the Amazon is a major concern as it has a significant impact\non global carbon emissions and biodiversity. In this paper, we present a method\nfor detecting deforestation in the Amazon using image pairs from Earth\nobservation satellites. Our method leverages deep learning techniques to\ncompare the images of the same area at different dates and identify changes in\nthe forest cover. We also propose a visual semantic model that automatically\nannotates the detected changes with relevant keywords. The candidate annotation\nfor images are extracted from scientific documents related to the Amazon\nregion. We evaluate our approach on a dataset of Amazon image pairs and\ndemonstrate its effectiveness in detecting deforestation and generating\nrelevant annotations. Our method provides a useful tool for monitoring and\nstudying the impact of deforestation in the Amazon. While we focus on\nenvironment applications of our work by using images of deforestation in the\nAmazon rain forest to demonstrate the effectiveness of our proposed approach,\nit is generic enough to be applied to other domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5730\u7403\u89c2\u6d4b\u536b\u661f\u56fe\u50cf\u5bf9\u68c0\u6d4b\u4e9a\u9a6c\u900a\u96e8\u6797\u780d\u4f10\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u5bf9\u6bd4\u4e0d\u540c\u65f6\u671f\u56fe\u50cf\uff0c\u8fd8\u63d0\u51fa\u89c6\u89c9\u8bed\u4e49\u6a21\u578b\u6807\u6ce8\u53d8\u5316\uff0c\u8bc4\u4f30\u663e\u793a\u65b9\u6cd5\u6709\u6548\u4e14\u53ef\u7528\u4e8e\u5176\u4ed6\u9886\u57df\u3002", "motivation": "\u4e9a\u9a6c\u900a\u96e8\u6797\u780d\u4f10\u5bf9\u5168\u7403\u78b3\u6392\u653e\u548c\u751f\u7269\u591a\u6837\u6027\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u9700\u8981\u6709\u6548\u65b9\u6cd5\u68c0\u6d4b\u3002", "method": "\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5bf9\u6bd4\u4e0d\u540c\u65e5\u671f\u540c\u4e00\u533a\u57df\u536b\u661f\u56fe\u50cf\u8bc6\u522b\u68ee\u6797\u8986\u76d6\u53d8\u5316\uff0c\u63d0\u51fa\u89c6\u89c9\u8bed\u4e49\u6a21\u578b\uff0c\u4ece\u76f8\u5173\u79d1\u5b66\u6587\u6863\u63d0\u53d6\u56fe\u50cf\u5019\u9009\u6ce8\u91ca\u3002", "result": "\u5728\u4e9a\u9a6c\u900a\u56fe\u50cf\u5bf9\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8bc1\u660e\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u780d\u4f10\u5e76\u751f\u6210\u76f8\u5173\u6ce8\u91ca\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u76d1\u6d4b\u548c\u7814\u7a76\u4e9a\u9a6c\u900a\u96e8\u6797\u780d\u4f10\u5f71\u54cd\u63d0\u4f9b\u6709\u7528\u5de5\u5177\uff0c\u4e14\u5177\u6709\u901a\u7528\u6027\u53ef\u5e94\u7528\u4e8e\u5176\u4ed6\u9886\u57df\u3002"}}
{"id": "2509.13827", "pdf": "https://arxiv.org/pdf/2509.13827", "abs": "https://arxiv.org/abs/2509.13827", "authors": ["Renyuan Liu", "Haoting Zhou", "Chuankai Fang", "Qinbing Fu"], "title": "How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots", "categories": ["cs.RO", "cs.NE"], "comment": "9 pages, 6 figures", "summary": "Anyone who has tried to swat a fly has likely been frustrated by its\nremarkable agility.This ability stems from its visual neural perception system,\nparticularly the collision-selective neurons within its small brain.For\nautonomous robots operating in complex and unfamiliar environments, achieving\nsimilar agility is highly desirable but often constrained by the trade-off\nbetween computational cost and performance.In this context, insect-inspired\nintelligence offers a parsimonious route to low-power, computationally\nefficient frameworks.In this paper, we propose an attention-driven visuomotor\ncontrol strategy inspired by a specific class of fly visual projection\nneurons-the lobula plate/lobula column type-2 (LPLC2)-and their associated\nescape behaviors.To our knowledge, this represents the first embodiment of an\nLPLC2 neural model in the embedded vision of a physical mobile robot, enabling\ncollision perception and reactive evasion.The model was simplified and\noptimized at 70KB in memory to suit the computational constraints of a\nvision-based micro robot, the Colias, while preserving key neural perception\nmechanisms.We further incorporated multi-attention mechanisms to emulate the\ndistributed nature of LPLC2 responses, allowing the robot to detect and react\nto approaching targets both rapidly and selectively.We systematically evaluated\nthe proposed method against a state-of-the-art locust-inspired collision\ndetection model.Results showed that the fly-inspired visuomotor model achieved\ncomparable robustness, at success rate of 96.1% in collision detection while\nproducing more adaptive and elegant evasive maneuvers.Beyond demonstrating an\neffective collision-avoidance strategy, this work highlights the potential of\nfly-inspired neural models for advancing research into collective behaviors in\ninsect intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53d7\u679c\u8747\u89c6\u89c9\u795e\u7ecf\u5143\u542f\u53d1\u7684\u6ce8\u610f\u529b\u9a71\u52a8\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u7b56\u7565\uff0c\u7528\u4e8e\u79fb\u52a8\u673a\u5668\u4eba\u907f\u969c\uff0c\u7ecf\u8bc4\u4f30\u8be5\u7b56\u7565\u6709\u6548\u4e14\u51f8\u663e\u679c\u8747\u795e\u7ecf\u6a21\u578b\u6f5c\u529b\u3002", "motivation": "\u81ea\u4e3b\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u5b9e\u73b0\u7c7b\u4f3c\u679c\u8747\u7684\u654f\u6377\u6027\u53d7\u8ba1\u7b97\u6210\u672c\u548c\u6027\u80fd\u6743\u8861\u7684\u9650\u5236\uff0c\u6606\u866b\u542f\u53d1\u7684\u667a\u80fd\u63d0\u4f9b\u4f4e\u529f\u8017\u3001\u9ad8\u6548\u8ba1\u7b97\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u53d7\u679c\u8747LPLC2\u795e\u7ecf\u5143\u53ca\u5176\u9003\u9038\u884c\u4e3a\u542f\u53d1\u7684\u6ce8\u610f\u529b\u9a71\u52a8\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u7b56\u7565\uff0c\u7b80\u5316\u4f18\u5316\u6a21\u578b\u4ee5\u9002\u5e94\u5fae\u578b\u673a\u5668\u4eba\u8ba1\u7b97\u9650\u5236\uff0c\u5f15\u5165\u591a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4e0e\u8757\u866b\u542f\u53d1\u7684\u78b0\u649e\u68c0\u6d4b\u6a21\u578b\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u679c\u8747\u542f\u53d1\u7684\u89c6\u89c9\u8fd0\u52a8\u6a21\u578b\u5728\u78b0\u649e\u68c0\u6d4b\u6210\u529f\u7387\u8fbe96.1%\uff0c\u5177\u6709\u76f8\u5f53\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u4ea7\u751f\u66f4\u81ea\u9002\u5e94\u548c\u4f18\u96c5\u7684\u89c4\u907f\u52a8\u4f5c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e0d\u4ec5\u5c55\u793a\u4e86\u6709\u6548\u7684\u907f\u969c\u7b56\u7565\uff0c\u8fd8\u51f8\u663e\u4e86\u679c\u8747\u542f\u53d1\u7684\u795e\u7ecf\u6a21\u578b\u5728\u6606\u866b\u667a\u80fd\u96c6\u4f53\u884c\u4e3a\u7814\u7a76\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13347", "pdf": "https://arxiv.org/pdf/2509.13347", "abs": "https://arxiv.org/abs/2509.13347", "authors": ["Zihao Wang", "Muyao Li", "Kaichen He", "Xiangyu Wang", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "categories": ["cs.AI"], "comment": null, "summary": "The choice of action spaces is a critical yet unresolved challenge in\ndeveloping capable, end-to-end trainable agents. This paper first presents a\nlarge-scale, systematic comparison of prominent abstracted action spaces and\ntokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the\nopen-ended Minecraft. Our analysis reveals that no single action space is\nuniversally optimal; instead, the most effective abstraction is highly\ntask-dependent, creating a dilemma for building generalist agents. To resolve\nthis, we introduce Chain of Action (CoA), a novel framework that unifies\nhigh-level planning and low-level control within a single, monolithic VLA\nmodel. CoA treats an abstracted action not as a command for a separate policy,\nbut as an intermediate reasoning step--akin to a chain of thought--that guides\nthe generation of the final, executable action. Furthermore, we demonstrate\nthat an All-in-One agent trained on a diverse mixture of action spaces using\nthe CoA paradigm learns a more robust and generalizable policy. This unified\nagent achieves a new state-of-the-art, improving the overall task success rate\nover strong, specialized baselines. To foster reproducible research, we release\nthe OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive\nbenchmark of over 800 distinct tasks, curated datasets, source code, and all\npretrained model checkpoints at https://github.com/CraftJarvis/OpenHA", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e86VLA\u6216\u5206\u5c42\u4ee3\u7406\u6a21\u578b\u7684\u52a8\u4f5c\u7a7a\u95f4\uff0c\u53d1\u73b0\u65e0\u901a\u7528\u6700\u4f18\u52a8\u4f5c\u7a7a\u95f4\uff0c\u63d0\u51faCoA\u6846\u67b6\uff0c\u7528\u5176\u8bad\u7ec3\u7684\u4e00\u4f53\u5316\u4ee3\u7406\u53d6\u5f97\u65b0SOTA\uff0c\u8fd8\u53d1\u5e03OpenHA\u5957\u4ef6\u3002", "motivation": "\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u662f\u5f00\u53d1\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u4ee3\u7406\u7684\u5173\u952e\u672a\u51b3\u6311\u6218\uff0c\u4e0d\u540c\u4efb\u52a1\u7f3a\u4e4f\u901a\u7528\u6700\u4f18\u52a8\u4f5c\u7a7a\u95f4\uff0c\u96be\u4ee5\u6784\u5efa\u901a\u7528\u4ee3\u7406\u3002", "method": "\u5148\u5bf9\u7a81\u51fa\u7684\u62bd\u8c61\u52a8\u4f5c\u7a7a\u95f4\u548c\u5206\u8bcd\u5668\u8fdb\u884c\u5927\u89c4\u6a21\u7cfb\u7edf\u6bd4\u8f83\uff0c\u518d\u5f15\u5165CoA\u6846\u67b6\u7edf\u4e00\u9ad8\u7ea7\u89c4\u5212\u548c\u4f4e\u7ea7\u63a7\u5236\uff0c\u7528CoA\u8303\u5f0f\u5728\u4e0d\u540c\u52a8\u4f5c\u7a7a\u95f4\u6df7\u5408\u6570\u636e\u4e0a\u8bad\u7ec3\u4e00\u4f53\u5316\u4ee3\u7406\u3002", "result": "\u7528CoA\u8303\u5f0f\u8bad\u7ec3\u7684\u4e00\u4f53\u5316\u4ee3\u7406\u53d6\u5f97\u65b0\u7684\u6700\u4f18\u6210\u679c\uff0c\u63d0\u9ad8\u4e86\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "CoA\u6846\u67b6\u6709\u6548\uff0c\u53ef\u4f7f\u4ee3\u7406\u5b66\u4e60\u5230\u66f4\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u7684\u7b56\u7565\uff0c\u540c\u65f6\u53d1\u5e03OpenHA\u5957\u4ef6\u4fc3\u8fdb\u53ef\u590d\u73b0\u7814\u7a76\u3002"}}
{"id": "2509.13656", "pdf": "https://arxiv.org/pdf/2509.13656", "abs": "https://arxiv.org/abs/2509.13656", "authors": ["Yingao Elaine Yao", "Vedant Nimje", "Varun Viswanath", "Saikat Dutta"], "title": "A Regression Testing Framework with Automated Assertion Generation for Machine Learning Notebooks", "categories": ["cs.SE"], "comment": "22 pages, 2 figures, 6 tables", "summary": "Notebooks have become the de-facto choice for data scientists and machine\nlearning engineers for prototyping and experimenting with machine learning (ML)\npipelines. Notebooks provide an interactive interface for code, data, and\nvisualization. However, notebooks provide very limited support for testing.\nThus, during continuous development, many subtle bugs that do not lead to\ncrashes often go unnoticed and cause silent errors that manifest as performance\nregressions.\n  To address this, we introduce NBTest - the first regression testing framework\nthat allows developers to write cell-level assertions in notebooks and run such\nnotebooks in pytest or in continuous integration (CI) pipelines. NBTest offers\na library of assertion APIs, and a JupyterLab plugin that enables executing\nassertions. We also develop the first automated approach for generating\ncell-level assertions for key components in ML notebooks, such as data\nprocessing, model building, and model evaluation. NBTest aims to improve the\nreliability and maintainability of ML notebooks without adding developer\nburden.\n  We evaluate NBTest on 592 Kaggle notebooks. Overall, NBTest generates 21163\nassertions (35.75 on average per notebook). The generated assertions obtain a\nmutation score of 0.57 in killing ML-specific mutations. NBTest can catch\nregression bugs in previous versions of the Kaggle notebooks using assertions\ngenerated for the latest versions. Because ML pipelines involve non\ndeterministic computations, the assertions can be flaky. Hence, we also show\nhow NBTest leverages statistical techniques to minimize flakiness while\nretaining high fault-detection effectiveness. NBTest has been adopted in the CI\nof a popular ML library. Further, we perform a user study with 17 participants\nthat shows that notebook users find NBTest intuitive (Rating 4.3/5) and useful\nin writing assertions and testing notebooks (Rating 4.24/5).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdNBTest\u56de\u5f52\u6d4b\u8bd5\u6846\u67b6\uff0c\u80fd\u5728\u7b14\u8bb0\u672c\u4e2d\u5199\u5355\u5143\u7ea7\u65ad\u8a00\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6709\u6548\u4e14\u88ab\u91c7\u7528\uff0c\u7528\u6237\u8bc4\u4ef7\u9ad8\u3002", "motivation": "\u73b0\u6709\u7b14\u8bb0\u672c\u5bf9\u6d4b\u8bd5\u652f\u6301\u6709\u9650\uff0c\u5f00\u53d1\u4e2d\u7ec6\u5fae\u9519\u8bef\u96be\u53d1\u73b0\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5f15\u5165NBTest\u6846\u67b6\uff0c\u63d0\u4f9b\u65ad\u8a00API\u548cJupyterLab\u63d2\u4ef6\uff0c\u5f00\u53d1\u81ea\u52a8\u751f\u6210\u5355\u5143\u7ea7\u65ad\u8a00\u65b9\u6cd5\uff0c\u5229\u7528\u7edf\u8ba1\u6280\u672f\u51cf\u5c11\u65ad\u8a00\u4e0d\u7a33\u5b9a\u6027\u3002", "result": "\u5728592\u4e2aKaggle\u7b14\u8bb0\u672c\u4e0a\u8bc4\u4f30\uff0c\u751f\u621021163\u4e2a\u65ad\u8a00\uff0c\u7a81\u53d8\u5f97\u52060.57\uff0c\u80fd\u6355\u6349\u56de\u5f52\u9519\u8bef\uff0c\u88ab\u6d41\u884cML\u5e93CI\u91c7\u7528\uff0c\u7528\u6237\u8bc4\u4ef7\u9ad8\u3002", "conclusion": "NBTest\u80fd\u5728\u4e0d\u589e\u52a0\u5f00\u53d1\u8005\u8d1f\u62c5\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8ML\u7b14\u8bb0\u672c\u7684\u53ef\u9760\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002"}}
{"id": "2509.13608", "pdf": "https://arxiv.org/pdf/2509.13608", "abs": "https://arxiv.org/abs/2509.13608", "authors": ["Niruthiha Selvanayagam", "Ted Kurti"], "title": "Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection", "categories": ["cs.LG"], "comment": null, "summary": "As Large Multimodal Models (LMMs) become integral to daily digital life,\nunderstanding their safety architectures is a critical problem for AI\nAlignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a\nglobally deployed model, on the difficult task of multimodal hate speech\ndetection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase\ninvestigation on 500 samples to probe the model's reasoning and failure modes.\nOur central finding is the experimental identification of a \"Unimodal\nBottleneck,\" an architectural flaw where the model's advanced multimodal\nreasoning is systematically preempted by context-blind safety filters. A\nquantitative validation of 144 content policy refusals reveals that these\noverrides are triggered in equal measure by unimodal visual 50% and textual 50%\ncontent. We further demonstrate that this safety system is brittle, blocking\nnot only high-risk imagery but also benign, common meme formats, leading to\npredictable false positives. These findings expose a fundamental tension\nbetween capability and safety in state-of-the-art LMMs, highlighting the need\nfor more integrated, context-aware alignment strategies to ensure AI systems\ncan be deployed both safely and effectively.", "AI": {"tldr": "\u672c\u6587\u5bf9OpenAI\u7684GPT - 4o mini\u8fdb\u884c\u591a\u6a21\u6001\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u5206\u6790\uff0c\u53d1\u73b0\u201c\u5355\u6a21\u6001\u74f6\u9888\u201d\u95ee\u9898\uff0c\u51f8\u663e\u5f53\u524dLMMs\u80fd\u529b\u4e0e\u5b89\u5168\u7684\u77db\u76fe\u3002", "motivation": "\u968f\u7740\u5927\u8de8\u6a21\u6001\u6a21\u578b\u878d\u5165\u65e5\u5e38\u751f\u6d3b\uff0c\u7406\u89e3\u5176\u5b89\u5168\u67b6\u6784\u5bf9AI\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u5206\u6790GPT - 4o mini\u7684\u591a\u6a21\u6001\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u4f7f\u7528Hateful Memes Challenge\u6570\u636e\u96c6\uff0c\u5bf9500\u4e2a\u6837\u672c\u8fdb\u884c\u591a\u9636\u6bb5\u8c03\u67e5\u3002", "result": "\u53d1\u73b0\u201c\u5355\u6a21\u6001\u74f6\u9888\u201d\u67b6\u6784\u7f3a\u9677\uff0c\u5185\u5bb9\u653f\u7b56\u62d2\u7edd\u4e2d\u670950%\u7531\u5355\u6a21\u6001\u89c6\u89c9\u5185\u5bb9\u89e6\u53d1\uff0c50%\u7531\u6587\u672c\u5185\u5bb9\u89e6\u53d1\uff0c\u5b89\u5168\u7cfb\u7edf\u8106\u5f31\uff0c\u4f1a\u4ea7\u751f\u8bef\u5224\u3002", "conclusion": "\u5f53\u524d\u6700\u5148\u8fdb\u7684LMMs\u5728\u80fd\u529b\u548c\u5b89\u5168\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u77db\u76fe\uff0c\u9700\u8981\u66f4\u96c6\u6210\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5bf9\u9f50\u7b56\u7565\u3002"}}
{"id": "2509.14218", "pdf": "https://arxiv.org/pdf/2509.14218", "abs": "https://arxiv.org/abs/2509.14218", "authors": ["James Leiner", "Robin Dunn", "Aaditya Ramdas"], "title": "Adaptive Off-Policy Inference for M-Estimators Under Model Misspecification", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.OT", "stat.TH"], "comment": "36 pages, 6 figures", "summary": "When data are collected adaptively, such as in bandit algorithms, classical\nstatistical approaches such as ordinary least squares and $M$-estimation will\noften fail to achieve asymptotic normality. Although recent lines of work have\nmodified the classical approaches to ensure valid inference on adaptively\ncollected data, most of these works assume that the model is correctly\nspecified. We propose a method that provides valid inference for M-estimators\nthat use adaptively collected bandit data with a (possibly) misspecified\nworking model. A key ingredient in our approach is the use of flexible machine\nlearning approaches to stabilize the variance induced by adaptive data\ncollection. A major novelty is that our procedure enables the construction of\nvalid confidence sets even in settings where treatment policies are unstable\nand non-converging, such as when there is no unique optimal arm and standard\nbandit algorithms are used. Empirical results on semi-synthetic datasets\nconstructed from the Osteoarthritis Initiative demonstrate that the method\nmaintains type I error control, while existing methods for inference in\nadaptive settings do not cover in the misspecified case.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u4e3a\u4f7f\u7528\u81ea\u9002\u5e94\u6536\u96c6\u7684\u8001\u864e\u673a\u6570\u636e\u7684M - \u4f30\u8ba1\u91cf\u5728\u5de5\u4f5c\u6a21\u578b\u53ef\u80fd\u9519\u8bef\u8bbe\u5b9a\u65f6\u63d0\u4f9b\u6709\u6548\u63a8\u65ad\u3002", "motivation": "\u7ecf\u5178\u7edf\u8ba1\u65b9\u6cd5\u5728\u81ea\u9002\u5e94\u6536\u96c6\u6570\u636e\u65f6\u96be\u4ee5\u5b9e\u73b0\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u73b0\u6709\u6539\u8fdb\u5de5\u4f5c\u5927\u591a\u5047\u8bbe\u6a21\u578b\u6b63\u786e\u8bbe\u5b9a\uff0c\u9700\u8981\u89e3\u51b3\u6a21\u578b\u9519\u8bef\u8bbe\u5b9a\u65f6\u7684\u6709\u6548\u63a8\u65ad\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u7075\u6d3b\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6765\u7a33\u5b9a\u81ea\u9002\u5e94\u6570\u636e\u6536\u96c6\u5f15\u8d77\u7684\u65b9\u5dee\u3002", "result": "\u5728\u9aa8\u5173\u8282\u708e\u5021\u8bae\u6784\u5efa\u7684\u534a\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u63a7\u5236\u4e00\u7c7b\u9519\u8bef\uff0c\u800c\u73b0\u6709\u81ea\u9002\u5e94\u8bbe\u7f6e\u4e0b\u7684\u63a8\u65ad\u65b9\u6cd5\u5728\u6a21\u578b\u9519\u8bef\u8bbe\u5b9a\u65f6\u65e0\u6cd5\u8986\u76d6\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u4e3a\u4f7f\u7528\u81ea\u9002\u5e94\u6536\u96c6\u7684\u8001\u864e\u673a\u6570\u636e\u7684M - \u4f30\u8ba1\u91cf\u5728\u6a21\u578b\u53ef\u80fd\u9519\u8bef\u8bbe\u5b9a\u65f6\u63d0\u4f9b\u6709\u6548\u63a8\u65ad\uff0c\u5728\u5904\u7406\u7b56\u7565\u4e0d\u7a33\u5b9a\u548c\u4e0d\u6536\u655b\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6784\u5efa\u6709\u6548\u7f6e\u4fe1\u96c6\u3002"}}
{"id": "2509.14116", "pdf": "https://arxiv.org/pdf/2509.14116", "abs": "https://arxiv.org/abs/2509.14116", "authors": ["Celine Bonnet", "Fabrice Etile", "Sebastien Lecocq"], "title": "Minimum pricing or volumetric taxation? Quantity, quality and competition effects of price regulations in alcohol markets", "categories": ["econ.GN", "q-fin.EC"], "comment": "Main Text: 52 pages; 11 Tables", "summary": "Reforming alcohol price regulations in wine-producing countries is\nchallenging, as current price regulations reflect the alignment of cultural\npreferences with economic interests rather than public health concerns. We\nevaluate and compare the impact of counterfactual alcohol pricing policies on\nconsumer behaviors, firms, and markets in France. We develop a micro-founded\npartial equilibrium model that accounts for consumer preferences over purchase\nvolumes across alcohol categories and over product quality within categories,\nand for firms' strategic price-setting. After calibration on household scanner\ndata, we compare the impacts of replacing current taxes by ethanol-based\nvolumetric taxes with a minimum unit price (MUP) policy of 0.50 Euro per\nstandard drink. The results show that the MUP in addition to the current tax\noutperforms a tax reform in reducing ethanol purchases (-15% vs. -10% for\nprogressive taxation), especially among heavy drinking households (-17%). The\nMUP increases the profits of small and medium wine firms (+39%) while\ndecreasing the profits of large manufacturers and retailers (-39%) and\nmaintaining tax revenues stable. The results support the MUP as a targeted\nstrategy to reduce harmful consumption while benefiting small and medium wine\nproducers. This study provides ex-ante evidence that is crucial for alcohol\npricing policies in wine-producing countries.", "AI": {"tldr": "\u8bc4\u4f30\u6cd5\u56fd\u4e0d\u540c\u9152\u7cbe\u5b9a\u4ef7\u653f\u7b56\u5f71\u54cd\uff0c\u53d1\u73b0\u6700\u4f4e\u5355\u4f4d\u4ef7\u683c\uff08MUP\uff09\u653f\u7b56\u5728\u51cf\u5c11\u4e59\u9187\u8d2d\u4e70\u548c\u60e0\u53ca\u4e2d\u5c0f\u4f01\u4e1a\u65b9\u9762\u8868\u73b0\u66f4\u4f73\u3002", "motivation": "\u8461\u8404\u9152\u751f\u4ea7\u56fd\u6539\u9769\u9152\u7cbe\u4ef7\u683c\u76d1\u7ba1\u5177\u6709\u6311\u6218\u6027\uff0c\u5f53\u524d\u653f\u7b56\u672a\u8003\u8651\u516c\u5171\u5065\u5eb7\uff0c\u9700\u8bc4\u4f30\u4e0d\u540c\u5b9a\u4ef7\u653f\u7b56\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u5fae\u89c2\u57fa\u7840\u5c40\u90e8\u5747\u8861\u6a21\u578b\uff0c\u57fa\u4e8e\u5bb6\u5ead\u626b\u63cf\u6570\u636e\u6821\u51c6\uff0c\u6bd4\u8f83\u4e59\u9187\u4f53\u79ef\u7a0e\u548cMUP\u653f\u7b56\u5f71\u54cd\u3002", "result": "MUP\u653f\u7b56\u5728\u51cf\u5c11\u4e59\u9187\u8d2d\u4e70\u4e0a\u4f18\u4e8e\u7a0e\u6536\u6539\u9769\uff0c\u5c24\u5176\u5bf9\u91cd\u5ea6\u996e\u9152\u5bb6\u5ead\uff1b\u589e\u52a0\u4e2d\u5c0f\u4f01\u4e1a\u5229\u6da6\uff0c\u51cf\u5c11\u5927\u578b\u5236\u9020\u5546\u548c\u96f6\u552e\u5546\u5229\u6da6\uff0c\u7ef4\u6301\u7a0e\u6536\u7a33\u5b9a\u3002", "conclusion": "MUP\u653f\u7b56\u53ef\u4f5c\u4e3a\u51cf\u5c11\u6709\u5bb3\u6d88\u8d39\u3001\u60e0\u53ca\u4e2d\u5c0f\u4f01\u4e1a\u7684\u76ee\u6807\u7b56\u7565\uff0c\u4e3a\u8461\u8404\u9152\u751f\u4ea7\u56fd\u9152\u7cbe\u5b9a\u4ef7\u653f\u7b56\u63d0\u4f9b\u4e8b\u524d\u8bc1\u636e\u3002"}}
{"id": "2509.13392", "pdf": "https://arxiv.org/pdf/2509.13392", "abs": "https://arxiv.org/abs/2509.13392", "authors": ["Demyan Yarmoshik", "Igor Ignashin", "Ekaterina Sikacheva", "Alexander Gasnikov"], "title": "Modeling skiers flows via Wardrope equilibrium in closed capacitated networks", "categories": ["cs.SY", "cs.GT"], "comment": null, "summary": "We propose an equilibrium model of ski resorts where users are assigned to\ncycles in a closed network. As queues form on lifts with limited capacity, we\nderive an efficient way to find waiting times via convex optimization. The\nequilibrium problem is formulated as a variational inequality, and numerical\nexperiments show that it can be solved using standard algorithms.", "AI": {"tldr": "\u63d0\u51fa\u6ed1\u96ea\u5ea6\u5047\u6751\u5747\u8861\u6a21\u578b\uff0c\u7528\u51f8\u4f18\u5316\u6c42\u7b49\u5f85\u65f6\u95f4\uff0c\u5c06\u5747\u8861\u95ee\u9898\u8f6c\u5316\u4e3a\u53d8\u5206\u4e0d\u7b49\u5f0f\u5e76\u7528\u6807\u51c6\u7b97\u6cd5\u6c42\u89e3\u3002", "motivation": "\u7814\u7a76\u6ed1\u96ea\u5ea6\u5047\u6751\u7528\u6237\u5728\u5c01\u95ed\u7f51\u7edc\u4e2d\u5206\u914d\u5230\u5faa\u73af\u7684\u5747\u8861\u60c5\u51b5\uff0c\u89e3\u51b3\u6709\u9650\u5bb9\u91cf\u7d22\u9053\u6392\u961f\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u51f8\u4f18\u5316\u627e\u5230\u8ba1\u7b97\u7b49\u5f85\u65f6\u95f4\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5c06\u5747\u8861\u95ee\u9898\u8868\u8ff0\u4e3a\u53d8\u5206\u4e0d\u7b49\u5f0f\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u53ef\u4ee5\u4f7f\u7528\u6807\u51c6\u7b97\u6cd5\u89e3\u51b3\u5747\u8861\u95ee\u9898\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u548c\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u6ed1\u96ea\u5ea6\u5047\u6751\u7684\u5747\u8861\u95ee\u9898\u3002"}}
{"id": "2509.13648", "pdf": "https://arxiv.org/pdf/2509.13648", "abs": "https://arxiv.org/abs/2509.13648", "authors": ["Geon Lee", "Bhuvesh Kumar", "Clark Mingxuan Ju", "Tong Zhao", "Kijung Shin", "Neil Shah", "Liam Collins"], "title": "Sequential Data Augmentation for Generative Recommendation", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Generative recommendation plays a crucial role in personalized systems,\npredicting users' future interactions from their historical behavior sequences.\nA critical yet underexplored factor in training these models is data\naugmentation, the process of constructing training data from user interaction\nhistories. By shaping the training distribution, data augmentation directly and\noften substantially affects model generalization and performance. Nevertheless,\nin much of the existing work, this process is simplified, applied\ninconsistently, or treated as a minor design choice, without a systematic and\nprincipled understanding of its effects.\n  Motivated by our empirical finding that different augmentation strategies can\nyield large performance disparities, we conduct an in-depth analysis of how\nthey reshape training distributions and influence alignment with future targets\nand generalization to unseen inputs. To systematize this design space, we\npropose GenPAS, a generalized and principled framework that models augmentation\nas a stochastic sampling process over input-target pairs with three\nbias-controlled steps: sequence sampling, target sampling, and input sampling.\nThis formulation unifies widely used strategies as special cases and enables\nflexible control of the resulting training distribution. Our extensive\nexperiments on benchmark and industrial datasets demonstrate that GenPAS yields\nsuperior accuracy, data efficiency, and parameter efficiency compared to\nexisting strategies, providing practical guidance for principled training data\nconstruction in generative recommendation.", "AI": {"tldr": "\u6587\u7ae0\u5206\u6790\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6570\u636e\u589e\u5f3a\u95ee\u9898\uff0c\u63d0\u51faGenPAS\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5bf9\u6570\u636e\u589e\u5f3a\u7f3a\u4e4f\u7cfb\u7edf\u7406\u89e3\uff0c\u4e0d\u540c\u589e\u5f3a\u7b56\u7565\u6027\u80fd\u5dee\u5f02\u5927\uff0c\u9700\u6df1\u5165\u5206\u6790\u5176\u5bf9\u8bad\u7ec3\u5206\u5e03\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faGenPAS\u6846\u67b6\uff0c\u5c06\u589e\u5f3a\u5efa\u6a21\u4e3a\u8f93\u5165 - \u76ee\u6807\u5bf9\u7684\u968f\u673a\u62bd\u6837\u8fc7\u7a0b\uff0c\u5305\u542b\u5e8f\u5217\u62bd\u6837\u3001\u76ee\u6807\u62bd\u6837\u548c\u8f93\u5165\u62bd\u6837\u4e09\u4e2a\u6b65\u9aa4\u3002", "result": "\u5728\u57fa\u51c6\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cGenPAS\u5728\u51c6\u786e\u6027\u3001\u6570\u636e\u6548\u7387\u548c\u53c2\u6570\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u7b56\u7565\u3002", "conclusion": "GenPAS\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u6709\u539f\u5219\u7684\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2509.13627", "pdf": "https://arxiv.org/pdf/2509.13627", "abs": "https://arxiv.org/abs/2509.13627", "authors": ["Vijay Kumar Butte", "Sujata Butte"], "title": "Secure, Scalable and Privacy Aware Data Strategy in Cloud", "categories": ["cs.CR", "cs.AI", "cs.DC"], "comment": null, "summary": "The enterprises today are faced with the tough challenge of processing,\nstoring large amounts of data in a secure, scalable manner and enabling\ndecision makers to make quick, informed data driven decisions. This paper\naddresses this challenge and develops an effective enterprise data strategy in\nthe cloud. Various components of an effective data strategy are discussed and\narchitectures addressing security, scalability and privacy aspects are\nprovided.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4f01\u4e1a\u5728\u4e91\u73af\u5883\u4e0b\u5f00\u53d1\u6709\u6548\u6570\u636e\u7b56\u7565\u4ee5\u5e94\u5bf9\u6570\u636e\u5904\u7406\u548c\u51b3\u7b56\u6311\u6218\u3002", "motivation": "\u4f01\u4e1a\u9762\u4e34\u5b89\u5168\u3001\u53ef\u6269\u5c55\u5730\u5904\u7406\u548c\u5b58\u50a8\u5927\u91cf\u6570\u636e\uff0c\u4ee5\u53ca\u652f\u6301\u51b3\u7b56\u8005\u5feb\u901f\u505a\u51fa\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u7684\u6311\u6218\u3002", "method": "\u8ba8\u8bba\u6709\u6548\u6570\u636e\u7b56\u7565\u7684\u5404\u4e2a\u7ec4\u6210\u90e8\u5206\uff0c\u5e76\u63d0\u4f9b\u89e3\u51b3\u5b89\u5168\u3001\u53ef\u6269\u5c55\u6027\u548c\u9690\u79c1\u65b9\u9762\u7684\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u4e86\u6709\u6548\u4f01\u4e1a\u6570\u636e\u7b56\u7565\u7684\u5404\u7ec4\u6210\u90e8\u5206\u548c\u76f8\u5173\u67b6\u6784\u3002", "conclusion": "\u5f00\u53d1\u51fa\u5728\u4e91\u73af\u5883\u4e0b\u7684\u6709\u6548\u4f01\u4e1a\u6570\u636e\u7b56\u7565\u3002"}}
{"id": "2509.13351", "pdf": "https://arxiv.org/pdf/2509.13351", "abs": "https://arxiv.org/abs/2509.13351", "authors": ["Pulkit Verma", "Ngoc La", "Anthony Favier", "Swaroop Mishra", "Julie A. Shah"], "title": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse tasks, yet their ability to perform structured symbolic planning\nremains limited, particularly in domains requiring formal representations like\nthe Planning Domain Definition Language (PDDL). In this paper, we present a\nnovel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'\nsymbolic planning capabilities through logical chain-of-thought reasoning. Our\napproach focuses on teaching models to rigorously reason about action\napplicability, state transitions, and plan validity using explicit logical\ninference steps. By developing instruction prompts that guide models through\nthe precise logical reasoning required to determine when actions can be applied\nin a given state, we enable LLMs to self-correct their planning processes\nthrough structured reflection. The framework systematically builds verification\nskills by decomposing the planning process into explicit reasoning chains about\nprecondition satisfaction, effect application, and invariant preservation.\nExperimental results on multiple planning domains show that our\nchain-of-thought reasoning based instruction-tuned models are significantly\nbetter at planning, achieving planning accuracy of up to 94% on standard\nbenchmarks, representing a 66% absolute improvement over baseline models. This\nwork bridges the gap between the general reasoning capabilities of LLMs and the\nlogical precision required for automated planning, offering a promising\ndirection for developing better AI planning systems.", "AI": {"tldr": "\u63d0\u51faPDDL - Instruct\u6846\u67b6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7b26\u53f7\u89c4\u5212\u80fd\u529b\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\uff0c\u4e3aAI\u89c4\u5212\u7cfb\u7edf\u53d1\u5c55\u63d0\u4f9b\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u7b26\u53f7\u89c4\u5212\u80fd\u529b\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5f62\u5f0f\u5316\u8868\u793a\u7684\u9886\u57df\uff0c\u5982PDDL\u3002", "method": "\u63d0\u51faPDDL - Instruct\u6307\u4ee4\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u5f15\u5bfc\u6a21\u578b\u8fdb\u884c\u7cbe\u786e\u903b\u8f91\u63a8\u7406\uff0c\u5c06\u89c4\u5212\u8fc7\u7a0b\u5206\u89e3\u4e3a\u660e\u786e\u63a8\u7406\u94fe\u4ee5\u6784\u5efa\u9a8c\u8bc1\u6280\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u89c4\u5212\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u57fa\u4e8e\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u89c4\u5212\u80fd\u529b\u663e\u8457\u63d0\u5347\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u89c4\u5212\u51c6\u786e\u7387\u8fbe94%\uff0c\u6bd4\u57fa\u7ebf\u6a21\u578b\u7edd\u5bf9\u63d0\u9ad866%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f25\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e00\u822c\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u89c4\u5212\u6240\u9700\u903b\u8f91\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5f00\u53d1\u66f4\u597d\u7684AI\u89c4\u5212\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2509.13680", "pdf": "https://arxiv.org/pdf/2509.13680", "abs": "https://arxiv.org/abs/2509.13680", "authors": ["Wei Ma", "Yixiao Yang", "Jingquan Ge", "Xiaofei Xie", "Lingxiao Jiang"], "title": "Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code generation models are widely used in software development, yet their\nsensitivity to prompt phrasing remains under-examined. Identical requirements\nexpressed with different emotions or communication styles can yield divergent\noutputs, while most benchmarks emphasize only peak performance. We present\nPromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically\nequivalent prompt variants with emotion and personality templates, and that\nevaluates stability using probability aware continuous scoring or using binary\npass rates when logits are unavailable. The results are aggregated into a\nproposed area under curve metric (AUC-E) for cross model comparison. Across 14\nmodels from three families (Llama, Qwen, and DeepSeek), our study shows that\nperformance and stability behave as largely decoupled optimization objectives,\nand it reveals architectural and scale related patterns that challenge common\nassumptions about model robustness. The framework supports rapid screening for\nclosed-source models as well as detailed stability analysis in research\nsettings. PromptSE enables practitioners to quantify performance stability\ntrade offs for deployment and model selection, positioning prompt stability as\na complementary evaluation dimension alongside performance and fairness, and\ncontributing to more trustworthy AI-assisted software development tools.", "AI": {"tldr": "\u63d0\u51faPromptSE\u6846\u67b6\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5bf9\u63d0\u793a\u7684\u654f\u611f\u6027\uff0c\u7814\u7a76\u53d1\u73b0\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u89e3\u8026\uff0c\u652f\u6301\u6a21\u578b\u7b5b\u9009\u4e0e\u5206\u6790\u3002", "motivation": "\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5bf9\u63d0\u793a\u63aa\u8f9e\u7684\u654f\u611f\u6027\u672a\u5145\u5206\u7814\u7a76\uff0c\u591a\u6570\u57fa\u51c6\u4ec5\u5173\u6ce8\u5cf0\u503c\u6027\u80fd\u3002", "method": "\u521b\u5efa\u5e26\u6709\u60c5\u611f\u548c\u4e2a\u6027\u6a21\u677f\u7684\u8bed\u4e49\u7b49\u6548\u63d0\u793a\u53d8\u4f53\uff0c\u7528\u6982\u7387\u611f\u77e5\u8fde\u7eed\u8bc4\u5206\u6216\u4e8c\u5143\u901a\u8fc7\u7387\u8bc4\u4f30\u7a33\u5b9a\u6027\uff0c\u63d0\u51faAUC - E\u6307\u6807\u8fdb\u884c\u8de8\u6a21\u578b\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u663e\u793a\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u662f\u89e3\u8026\u7684\u4f18\u5316\u76ee\u6807\uff0c\u63ed\u793a\u4e86\u4e0e\u67b6\u6784\u548c\u89c4\u6a21\u76f8\u5173\u7684\u6a21\u5f0f\u3002", "conclusion": "PromptSE\u6846\u67b6\u53ef\u91cf\u5316\u6027\u80fd\u7a33\u5b9a\u6027\u6743\u8861\uff0c\u5c06\u63d0\u793a\u7a33\u5b9a\u6027\u4f5c\u4e3a\u8865\u5145\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u53ef\u4fe1\u7684AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u3002"}}
{"id": "2509.13621", "pdf": "https://arxiv.org/pdf/2509.13621", "abs": "https://arxiv.org/abs/2509.13621", "authors": ["Antonin Sulc", "Thorsten Hellert", "Steven Hunt"], "title": "Unsupervised Anomaly Detection in ALS EPICS Event Logs", "categories": ["cs.LG"], "comment": "6 pages, 5 figures, The 20th International Conference on Accelerator\n  and Large Experimental Physics Control Systems", "summary": "This paper introduces an automated fault analysis framework for the Advanced\nLight Source (ALS) that processes real-time event logs from its EPICS control\nsystem. By treating log entries as natural language, we transform them into\ncontextual vector representations using semantic embedding techniques. A\nsequence-aware neural network, trained on normal operational data, assigns a\nreal-time anomaly score to each event. This method flags deviations from\nbaseline behavior, enabling operators to rapidly identify the critical event\nsequences that precede complex system failures.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8eALS\u7684\u81ea\u52a8\u6545\u969c\u5206\u6790\u6846\u67b6\uff0c\u5904\u7406\u5b9e\u65f6\u4e8b\u4ef6\u65e5\u5fd7\uff0c\u7528\u8bed\u4e49\u5d4c\u5165\u6280\u672f\u8f6c\u6362\u65e5\u5fd7\uff0c\u7528\u795e\u7ecf\u7f51\u7edc\u6253\u5206\u4ee5\u8bc6\u522b\u6545\u969c\u524d\u5173\u952e\u4e8b\u4ef6\u5e8f\u5217\u3002", "motivation": "\u4e3a\u5148\u8fdb\u5149\u6e90\uff08ALS\uff09\u5f00\u53d1\u81ea\u52a8\u5316\u7684\u6545\u969c\u5206\u6790\u6846\u67b6\uff0c\u5e2e\u52a9\u64cd\u4f5c\u5458\u5feb\u901f\u8bc6\u522b\u590d\u6742\u7cfb\u7edf\u6545\u969c\u524d\u7684\u5173\u952e\u4e8b\u4ef6\u5e8f\u5217\u3002", "method": "\u5c06\u65e5\u5fd7\u6761\u76ee\u89c6\u4e3a\u81ea\u7136\u8bed\u8a00\uff0c\u4f7f\u7528\u8bed\u4e49\u5d4c\u5165\u6280\u672f\u5c06\u5176\u8f6c\u6362\u4e3a\u4e0a\u4e0b\u6587\u5411\u91cf\u8868\u793a\uff0c\u7528\u6b63\u5e38\u8fd0\u884c\u6570\u636e\u8bad\u7ec3\u987a\u5e8f\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\uff0c\u4e3a\u6bcf\u4e2a\u4e8b\u4ef6\u5206\u914d\u5b9e\u65f6\u5f02\u5e38\u5206\u6570\u3002", "result": "\u80fd\u591f\u6807\u8bb0\u51fa\u4e0e\u57fa\u7ebf\u884c\u4e3a\u7684\u504f\u5dee\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4f7f\u64cd\u4f5c\u5458\u5feb\u901f\u8bc6\u522b\u590d\u6742\u7cfb\u7edf\u6545\u969c\u524d\u7684\u5173\u952e\u4e8b\u4ef6\u5e8f\u5217\u3002"}}
{"id": "2509.14225", "pdf": "https://arxiv.org/pdf/2509.14225", "abs": "https://arxiv.org/abs/2509.14225", "authors": ["Benjamin Sterling", "Yousef El-Laham", "M\u00f3nica F. Bugallo"], "title": "Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics", "categories": ["cs.LG", "stat.ML"], "comment": "5 pages, 2 figures, 1 table", "summary": "Recent advances in generative artificial intelligence applications have\nraised new data security concerns. This paper focuses on defending diffusion\nmodels against membership inference attacks. This type of attack occurs when\nthe attacker can determine if a certain data point was used to train the model.\nAlthough diffusion models are intrinsically more resistant to membership\ninference attacks than other generative models, they are still susceptible. The\ndefense proposed here utilizes critically-damped higher-order Langevin\ndynamics, which introduces several auxiliary variables and a joint diffusion\nprocess along these variables. The idea is that the presence of auxiliary\nvariables mixes external randomness that helps to corrupt sensitive input data\nearlier on in the diffusion process. This concept is theoretically investigated\nand validated on a toy dataset and a speech dataset using the Area Under the\nReceiver Operating Characteristic (AUROC) curves and the FID metric.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u9632\u5fa1\u6269\u6563\u6a21\u578b\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u63d0\u51fa\u7528\u4e34\u754c\u963b\u5c3c\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u9632\u5fa1\uff0c\u8fdb\u884c\u7406\u8bba\u7814\u7a76\u5e76\u5728\u6570\u636e\u96c6\u9a8c\u8bc1\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u53d1\u5c55\u5f15\u53d1\u65b0\u7684\u6570\u636e\u5b89\u5168\u62c5\u5fe7\uff0c\u6269\u6563\u6a21\u578b\u867d\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u6709\u4e00\u5b9a\u6297\u6027\u4f46\u4ecd\u6613\u53d7\u653b\u51fb\u3002", "method": "\u5229\u7528\u4e34\u754c\u963b\u5c3c\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\uff0c\u5f15\u5165\u8f85\u52a9\u53d8\u91cf\u548c\u8054\u5408\u6269\u6563\u8fc7\u7a0b\uff0c\u7528\u5916\u90e8\u968f\u673a\u6027\u7834\u574f\u654f\u611f\u8f93\u5165\u6570\u636e\u3002", "result": "\u5728\u73a9\u5177\u6570\u636e\u96c6\u548c\u8bed\u97f3\u6570\u636e\u96c6\u4e0a\uff0c\u7528AUROC\u66f2\u7ebf\u548cFID\u6307\u6807\u9a8c\u8bc1\u8be5\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u4ece\u9a8c\u8bc1\u60c5\u51b5\u63a8\u6d4b\u6240\u63d0\u9632\u5fa1\u65b9\u6cd5\u6709\u4e00\u5b9a\u6548\u679c\u3002"}}
{"id": "2509.13323", "pdf": "https://arxiv.org/pdf/2509.13323", "abs": "https://arxiv.org/abs/2509.13323", "authors": ["Matthew O. Jackson", "Qiaozhu Me", "Stephanie W. Wang", "Yutong Xie", "Walter Yuan", "Seth Benzell", "Erik Brynjolfsson", "Colin F. Camerer", "James Evans", "Brian Jabarian", "Jon Kleinberg", "Juanjuan Meng", "Sendhil Mullainathan", "Asuman Ozdaglar", "Thomas Pfeiffer", "Moshe Tennenholtz", "Robb Willer", "Diyi Yang", "Teng Ye"], "title": "AI Behavioral Science", "categories": ["cs.HC", "econ.GN", "q-fin.EC"], "comment": null, "summary": "We discuss the three main areas comprising the new and emerging field of \"AI\nBehavioral Science\". This includes not only how AI can enhance research in the\nbehavioral sciences, but also how the behavioral sciences can be used to study\nand better design AI and to understand how the world will change as AI and\nhumans interact in increasingly layered and complex ways.", "AI": {"tldr": "\u63a2\u8ba8\u65b0\u5174\u7684\u201cAI\u884c\u4e3a\u79d1\u5b66\u201d\u7684\u4e09\u4e2a\u4e3b\u8981\u9886\u57df\u3002", "motivation": "\u63a2\u7d22AI\u4e0e\u884c\u4e3a\u79d1\u5b66\u76f8\u4e92\u4fc3\u8fdb\u53ca\u4e8c\u8005\u4ea4\u4e92\u5bf9\u4e16\u754c\u7684\u5f71\u54cd\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2509.13585", "pdf": "https://arxiv.org/pdf/2509.13585", "abs": "https://arxiv.org/abs/2509.13585", "authors": ["Sean Anderson", "Chris Darken", "Jo\u00e3o Hespanha"], "title": "Zero-sum turn games using Q-learning: finite computation with security guarantees", "categories": ["eess.SY", "cs.GT", "cs.SY"], "comment": "8 pages", "summary": "This paper addresses zero-sum ``turn'' games, in which only one player can\nmake decisions at each state. We show that pure saddle-point state-feedback\npolicies for turn games can be constructed from dynamic programming fixed-point\nequations for a single value function or Q-function. These fixed-points can be\nconstructed using a suitable form of Q-learning. For discounted costs,\nconvergence of this form of Q-learning can be established using classical\ntechniques. For undiscounted costs, we provide a convergence result that\napplies to finite-time deterministic games, which we use to illustrate our\nresults. For complex games, the Q-learning iteration must be terminated before\nexploring the full-state, which can lead to policies that cannot guarantee the\nsecurity levels implied by the final Q-function. To mitigate this, we propose\nan ``opponent-informed'' exploration policy for selecting the Q-learning\nsamples. This form of exploration can guarantee that the final Q-function\nprovides security levels that hold, at least, against a given set of policies.\nA numerical demonstration for a multi-agent game, Atlatl, indicates the\neffectiveness of these methods.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u96f6\u548c\u56de\u5408\u5236\u535a\u5f08\uff0c\u63d0\u51fa\u7528Q - learning\u6784\u5efa\u7eaf\u978d\u70b9\u72b6\u6001\u53cd\u9988\u7b56\u7565\uff0c\u5bf9\u6298\u6263\u548c\u975e\u6298\u6263\u6210\u672c\u7ed9\u51fa\u6536\u655b\u7ed3\u679c\uff0c\u8fd8\u63d0\u51fa\u5bf9\u624b\u4fe1\u606f\u63a2\u7d22\u7b56\u7565\uff0c\u5e76\u7528\u591a\u667a\u80fd\u4f53\u6e38\u620f\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u96f6\u548c\u56de\u5408\u5236\u535a\u5f08\u4e2d\u7eaf\u978d\u70b9\u72b6\u6001\u53cd\u9988\u7b56\u7565\u7684\u6784\u5efa\u95ee\u9898\u3002", "method": "\u4ece\u52a8\u6001\u89c4\u5212\u4e0d\u52a8\u70b9\u65b9\u7a0b\u6784\u5efa\u7b56\u7565\uff0c\u4f7f\u7528Q - learning\uff0c\u5bf9\u6298\u6263\u6210\u672c\u7528\u7ecf\u5178\u6280\u672f\u8bc1\u660e\u6536\u655b\uff0c\u5bf9\u975e\u6298\u6263\u6210\u672c\u7ed9\u51fa\u6709\u9650\u65f6\u95f4\u786e\u5b9a\u6027\u535a\u5f08\u6536\u655b\u7ed3\u679c\uff0c\u63d0\u51fa\u5bf9\u624b\u4fe1\u606f\u63a2\u7d22\u7b56\u7565\u3002", "result": "\u5bf9\u6298\u6263\u6210\u672c\u8bc1\u660eQ - learning\u6536\u655b\uff0c\u5bf9\u975e\u6298\u6263\u6210\u672c\u7ed9\u51fa\u6709\u9650\u65f6\u95f4\u786e\u5b9a\u6027\u535a\u5f08\u6536\u655b\u7ed3\u679c\uff0c\u5bf9\u624b\u4fe1\u606f\u63a2\u7d22\u7b56\u7565\u80fd\u4fdd\u8bc1\u6700\u7ec8Q\u51fd\u6570\u7684\u5b89\u5168\u6c34\u5e73\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u667a\u80fd\u4f53\u6e38\u620fAtlatl\u4e2d\u6709\u6548\u3002"}}
{"id": "2509.13772", "pdf": "https://arxiv.org/pdf/2509.13772", "abs": "https://arxiv.org/abs/2509.13772", "authors": ["Baolei Zhang", "Haoran Xin", "Yuxi Chen", "Zhuqing Liu", "Biao Yi", "Tong Li", "Lihai Nie", "Zheli Liu", "Minghong Fang"], "title": "Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation", "categories": ["cs.CR", "cs.IR", "cs.LG"], "comment": "To appear in the IEEE Symposium on Security and Privacy, 2026", "summary": "Retrieval-Augmented Generation (RAG) integrates external knowledge into large\nlanguage models to improve response quality. However, recent work has shown\nthat RAG systems are highly vulnerable to poisoning attacks, where malicious\ntexts are inserted into the knowledge database to influence model outputs.\nWhile several defenses have been proposed, they are often circumvented by more\nadaptive or sophisticated attacks.\n  This paper presents RAGOrigin, a black-box responsibility attribution\nframework designed to identify which texts in the knowledge database are\nresponsible for misleading or incorrect generations. Our method constructs a\nfocused attribution scope tailored to each misgeneration event and assigns a\nresponsibility score to each candidate text by evaluating its retrieval\nranking, semantic relevance, and influence on the generated response. The\nsystem then isolates poisoned texts using an unsupervised clustering method. We\nevaluate RAGOrigin across seven datasets and fifteen poisoning attacks,\nincluding newly developed adaptive poisoning strategies and multi-attacker\nscenarios. Our approach outperforms existing baselines in identifying poisoned\ncontent and remains robust under dynamic and noisy conditions. These results\nsuggest that RAGOrigin provides a practical and effective solution for tracing\nthe origins of corrupted knowledge in RAG systems.", "AI": {"tldr": "\u63d0\u51faRAGOrigin\u6846\u67b6\u8bc6\u522bRAG\u7cfb\u7edf\u77e5\u8bc6\u6570\u636e\u5e93\u4e2d\u5bfc\u81f4\u9519\u8bef\u751f\u6210\u7684\u6587\u672c\uff0c\u8bc4\u4f30\u6548\u679c\u597d\u3002", "motivation": "RAG\u7cfb\u7edf\u6613\u53d7\u6295\u6bd2\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5e38\u88ab\u7ed5\u8fc7\uff0c\u9700\u627e\u51fa\u5bfc\u81f4\u9519\u8bef\u751f\u6210\u7684\u6587\u672c\u3002", "method": "\u6784\u5efa\u9488\u5bf9\u6bcf\u4e2a\u9519\u8bef\u751f\u6210\u4e8b\u4ef6\u7684\u5f52\u56e0\u8303\u56f4\uff0c\u901a\u8fc7\u8bc4\u4f30\u68c0\u7d22\u6392\u540d\u3001\u8bed\u4e49\u76f8\u5173\u6027\u548c\u5bf9\u751f\u6210\u54cd\u5e94\u7684\u5f71\u54cd\u4e3a\u5019\u9009\u6587\u672c\u5206\u914d\u8d23\u4efb\u5206\u6570\uff0c\u7528\u65e0\u76d1\u7763\u805a\u7c7b\u65b9\u6cd5\u9694\u79bb\u6295\u6bd2\u6587\u672c\u3002", "result": "\u5728\u4e03\u4e2a\u6570\u636e\u96c6\u548c\u5341\u4e94\u79cd\u6295\u6bd2\u653b\u51fb\u4e0a\u8bc4\u4f30\uff0cRAGOrigin\u5728\u8bc6\u522b\u6295\u6bd2\u5185\u5bb9\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u52a8\u6001\u548c\u5608\u6742\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5065\u3002", "conclusion": "RAGOrigin\u4e3a\u8ffd\u8e2aRAG\u7cfb\u7edf\u4e2d\u53d7\u6c61\u67d3\u77e5\u8bc6\u7684\u6765\u6e90\u63d0\u4f9b\u4e86\u5b9e\u7528\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13631", "pdf": "https://arxiv.org/pdf/2509.13631", "abs": "https://arxiv.org/abs/2509.13631", "authors": ["Yuvraj Dutta", "Aaditya Sikder", "Basabdatta Palit"], "title": "Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery", "categories": ["cs.CV", "cs.DC", "14J60", "F.2.2; I.2.7"], "comment": "6 pages, 7 figures, accepted at IEEE INDISCON 2025", "summary": "Accurate identification of deforestation from satellite images is essential\nin order to understand the geographical situation of an area. This paper\nintroduces a new distributed approach to identify as well as locate\ndeforestation across different clients using Federated Learning (FL). Federated\nLearning enables distributed network clients to collaboratively train a model\nwhile maintaining data privacy and security of the active users. In our\nframework, a client corresponds to an edge satellite center responsible for\nlocal data processing. Moreover, FL provides an advantage over centralized\ntraining method which requires combining data, thereby compromising with data\nsecurity of the clients. Our framework leverages the FLOWER framework with RAY\nframework to execute the distributed learning workload. Furthermore, efficient\nclient spawning is ensured by RAY as it can select definite amount of users to\ncreate an emulation environment. Our FL framework uses YOLOS-small (a Vision\nTransformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN\nwith a MobileNetV3 backbone models trained and tested on publicly available\ndatasets. Our approach provides us a different view for image\nsegmentation-based tasks on satellite imagery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u8fdb\u884c\u5206\u5e03\u5f0f\u65b9\u6cd5\u6765\u8bc6\u522b\u548c\u5b9a\u4f4d\u4e0d\u540c\u5ba2\u6237\u7aef\u7684\u68ee\u6797\u780d\u4f10\uff0c\u5229\u7528FLOWER\u548cRAY\u6846\u67b6\uff0c\u6d4b\u8bd5\u591a\u4e2a\u6a21\u578b\uff0c\u4e3a\u536b\u661f\u56fe\u50cf\u5206\u5272\u4efb\u52a1\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "motivation": "\u4e3a\u51c6\u786e\u4ece\u536b\u661f\u56fe\u50cf\u8bc6\u522b\u68ee\u6797\u780d\u4f10\u4ee5\u4e86\u89e3\u533a\u57df\u5730\u7406\u60c5\u51b5\uff0c\u4e14\u89e3\u51b3\u96c6\u4e2d\u8bad\u7ec3\u65b9\u6cd5\u5b58\u5728\u7684\u6570\u636e\u5b89\u5168\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8054\u90a6\u5b66\u4e60\uff0c\u5bf9\u5e94\u8fb9\u7f18\u536b\u661f\u4e2d\u5fc3\u4e3a\u5ba2\u6237\u7aef\u8fdb\u884c\u672c\u5730\u6570\u636e\u5904\u7406\uff0c\u5229\u7528FLOWER\u548cRAY\u6846\u67b6\u6267\u884c\u5206\u5e03\u5f0f\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f7f\u7528YOLOS - small\u3001Faster R - CNN\u7b49\u6a21\u578b\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8e\u56fe\u50cf\u5206\u5272\u7684\u536b\u661f\u56fe\u50cf\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e0d\u540c\u89c6\u89d2\u3002"}}
{"id": "2509.13352", "pdf": "https://arxiv.org/pdf/2509.13352", "abs": "https://arxiv.org/abs/2509.13352", "authors": ["Anis Koubaa", "Khaled Gabr"], "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "categories": ["cs.AI", "cs.RO", "68T07, 68T40, 68T42", "I.2.9; I.2.11; I.2.8; I.2.10"], "comment": "14 pages, 1 figure", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,\nsurveillance, and disaster response, yet most systems remain confined to SAE\nLevel 2--3 autonomy. Their reliance on rule-based control and narrow AI\nrestricts adaptability in dynamic, uncertain missions. Existing UAV frameworks\nlack context-aware reasoning, autonomous decision-making, and ecosystem-level\nintegration; critically, none leverage Large Language Model (LLM) agents with\ntool-calling for real-time knowledge access. This paper introduces the Agentic\nUAVs framework, a five-layer architecture (Perception, Reasoning, Action,\nIntegration, Learning) that augments UAVs with LLM-driven reasoning, database\nquerying, and third-party system interaction. A ROS2 and Gazebo-based prototype\nintegrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3\ndeployment. In simulated search-and-rescue scenarios, agentic UAVs achieved\nhigher detection confidence (0.79 vs. 0.72), improved person detection rates\n(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).\nThese results confirm that modest computational overhead enables qualitatively\nnew levels of autonomy and ecosystem integration.", "AI": {"tldr": "\u73b0\u6709\u65e0\u4eba\u673a\u81ea\u4e3b\u6027\u53d7\u9650\uff0c\u672c\u6587\u63d0\u51faAgentic UAVs\u6846\u67b6\uff0c\u7ecf\u6a21\u62df\u6d4b\u8bd5\u63d0\u5347\u4e86\u81ea\u4e3b\u6027\u548c\u96c6\u6210\u5ea6\u3002", "motivation": "\u73b0\u6709\u65e0\u4eba\u673a\u7cfb\u7edf\u591a\u5904\u4e8eSAE 2 - 3\u7ea7\u81ea\u4e3b\uff0c\u4f9d\u8d56\u89c4\u5219\u63a7\u5236\u548c\u72ed\u4e49AI\uff0c\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u7b49\u80fd\u529b\uff0c\u4e14\u672a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e0e\u5de5\u5177\u8c03\u7528\u8fdb\u884c\u5b9e\u65f6\u77e5\u8bc6\u8bbf\u95ee\u3002", "method": "\u5f15\u5165\u4e94\u5c42\u67b6\u6784\u7684Agentic UAVs\u6846\u67b6\uff0c\u7528ROS2\u548cGazebo\u6784\u5efa\u539f\u578b\uff0c\u96c6\u6210YOLOv11\u3001GPT - 4\u548c\u672c\u5730Gemma - 3\u3002", "result": "\u5728\u6a21\u62df\u641c\u7d22\u6551\u63f4\u573a\u666f\u4e2d\uff0c\u65e0\u4eba\u673a\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\u3001\u4eba\u5458\u68c0\u6d4b\u7387\u548c\u884c\u52a8\u63a8\u8350\u7387\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u9002\u5ea6\u7684\u8ba1\u7b97\u5f00\u9500\u80fd\u5e26\u6765\u65b0\u7684\u81ea\u4e3b\u6027\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\u6c34\u5e73\u3002"}}
{"id": "2509.13755", "pdf": "https://arxiv.org/pdf/2509.13755", "abs": "https://arxiv.org/abs/2509.13755", "authors": ["Zhaoyang Chu", "Yao Wan", "Zhikun Zhang", "Di Wang", "Zhou Yang", "Hongyu Zhang", "Pan Zhou", "Xuanhua Shi", "Hai Jin", "David Lo"], "title": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": "Accepted at the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "summary": "While Code Language Models (CLMs) have demonstrated superior performance in\nsoftware engineering tasks such as code generation and summarization, recent\nempirical studies reveal a critical privacy vulnerability: these models exhibit\nunintended memorization of sensitive training data, enabling verbatim\nreproduction of confidential information when specifically prompted. To address\nthis issue, several approaches, including training data de-duplication and\ndifferential privacy augmentation, have been proposed. However, these methods\nrequire full-model retraining for deployed CLMs, which incurs substantial\ncomputational costs. In this paper, we aim to answer the following research\nquestion: Can sensitive information memorized by CLMs be erased effectively and\nefficiently?\n  We conduct a pioneering investigation into erasing sensitive memorization in\nCLMs through machine unlearning - a post-hoc modification method that removes\nspecific information from trained models without requiring full retraining.\nSpecifically, we first quantify the memorization risks of sensitive data within\nCLM training datasets and curate a high-risk dataset of 50,000 sensitive\nmemorized samples as unlearning targets. We study two widely used gradient\nascent-based unlearning approaches: the vanilla and constraint-based methods,\nand introduce CodeEraser, an advanced variant that selectively unlearns\nsensitive memorized segments in code while preserving the structural integrity\nand functional correctness of the surrounding code. Extensive experiments on\nthree families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,\nvalidate the effectiveness and efficiency of CodeEraser in erasing targeted\nsensitive memorization while maintaining model utility.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8CLMs\u654f\u611f\u4fe1\u606f\u64e6\u9664\u95ee\u9898\uff0c\u7528\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\uff0c\u63d0\u51faCodeEraser\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "motivation": "CLMs\u5b58\u5728\u654f\u611f\u6570\u636e\u8bb0\u5fc6\u9690\u79c1\u6f0f\u6d1e\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u5168\u6a21\u578b\u91cd\u8bad\u6210\u672c\u9ad8\uff0c\u8981\u6709\u6548\u9ad8\u6548\u64e6\u9664\u654f\u611f\u4fe1\u606f\u3002", "method": "\u5148\u91cf\u5316CLM\u8bad\u7ec3\u6570\u636e\u654f\u611f\u8bb0\u5fc6\u98ce\u9669\u5e76\u6574\u7406\u76ee\u6807\u6570\u636e\u96c6\uff0c\u7814\u7a76\u4e24\u79cd\u68af\u5ea6\u4e0a\u5347\u9057\u5fd8\u65b9\u6cd5\uff0c\u63d0\u51faCodeEraser\u3002", "result": "\u5728\u4e09\u7c7bCLMs\u4e0a\u5b9e\u9a8c\uff0c\u9a8c\u8bc1CodeEraser\u80fd\u64e6\u9664\u654f\u611f\u8bb0\u5fc6\u5e76\u4fdd\u6301\u6a21\u578b\u6548\u7528\u3002", "conclusion": "CodeEraser\u53ef\u6709\u6548\u4e14\u9ad8\u6548\u5730\u64e6\u9664CLMs\u4e2d\u654f\u611f\u8bb0\u5fc6\uff0c\u540c\u65f6\u7ef4\u6301\u6a21\u578b\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.13625", "pdf": "https://arxiv.org/pdf/2509.13625", "abs": "https://arxiv.org/abs/2509.13625", "authors": ["Bishnu Bhusal", "Manoj Acharya", "Ramneet Kaur", "Colin Samplawski", "Anirban Roy", "Adam D. Cobb", "Rohit Chadha", "Susmit Jha"], "title": "Privacy-Aware In-Context Learning for Large Language Models", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": null, "summary": "Large language models (LLMs) have significantly transformed natural language\nunderstanding and generation, but they raise privacy concerns due to potential\nexposure of sensitive information. Studies have highlighted the risk of\ninformation leakage, where adversaries can extract sensitive information\nembedded in the prompts. In this work, we introduce a novel private prediction\nframework for generating high-quality synthetic text with strong privacy\nguarantees. Our approach leverages the Differential Privacy (DP) framework to\nensure worst-case theoretical bounds on information leakage without requiring\nany fine-tuning of the underlying models.The proposed method performs inference\non private records and aggregates the resulting per-token output distributions.\nThis enables the generation of longer and coherent synthetic text while\nmaintaining privacy guarantees. Additionally, we propose a simple blending\noperation that combines private and public inference to further enhance\nutility. Empirical evaluations demonstrate that our approach outperforms\nprevious state-of-the-art methods on in-context-learning (ICL) tasks, making it\na promising direction for privacy-preserving text generation while maintaining\nhigh utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6587\u672c\u7684\u9690\u79c1\u9884\u6d4b\u6846\u67b6\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u540c\u65f6\u63d0\u5347\u6548\u7528\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u654f\u611f\u4fe1\u606f\u6cc4\u9732\u9690\u79c1\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u5229\u7528\u5dee\u5206\u9690\u79c1\u6846\u67b6\uff0c\u5bf9\u79c1\u6709\u8bb0\u5f55\u8fdb\u884c\u63a8\u7406\u5e76\u805a\u5408\u6bcf\u4e2atoken\u8f93\u51fa\u5206\u5e03\uff0c\u8fd8\u63d0\u51fa\u7ed3\u5408\u79c1\u6709\u548c\u516c\u5171\u63a8\u7406\u7684\u6df7\u5408\u64cd\u4f5c\u3002", "result": "\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4e4b\u524d\u7684\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u662f\u5728\u4fdd\u6301\u9ad8\u6548\u7528\u7684\u540c\u65f6\u8fdb\u884c\u9690\u79c1\u4fdd\u62a4\u6587\u672c\u751f\u6210\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2509.13729", "pdf": "https://arxiv.org/pdf/2509.13729", "abs": "https://arxiv.org/abs/2509.13729", "authors": ["Yukun Zhang", "Tianyang Zhang"], "title": "The Economics of Information Pollution in the Age of AI: A General Equilibrium Approach to Welfare, Measurement, and Policy", "categories": ["cs.CY", "cs.GT"], "comment": null, "summary": "The advent of Large Language Models (LLMs) represents a fundamental shock to\nthe economics of information production. By asymmetrically collapsing the\nmarginal cost of generating low-quality, synthetic content while leaving\nhigh-quality production costly, AI systematically incentivizes information\npollution. This paper develops a general equilibrium framework to analyze this\nchallenge. We model the strategic interactions among a monopolistic platform,\nprofit-maximizing producers, and utility-maximizing consumers in a three-stage\ngame. The core of our model is a production technology with differential\nelasticities of substitution ($\\sigma_L > 1 > \\sigma_H$), which formalizes the\ninsight that AI is a substitute for labor in low-quality production but a\ncomplement in high-quality creation. We prove the existence of a unique\n\"Polluted Information Equilibrium\" and demonstrate its inefficiency, which is\ndriven by a threefold market failure: a production externality, a platform\ngovernance failure, and an information commons externality. Methodologically,\nwe derive a theoretically-grounded Information Pollution Index (IPI) with\nendogenous welfare weights to measure ecosystem health. From a policy\nperspective, we show that a first-best outcome requires a portfolio of\ninstruments targeting each failure. Finally, considering the challenges of deep\nuncertainty, we advocate for an adaptive governance framework where policy\ninstruments are dynamically adjusted based on real-time IPI readings, offering\na robust blueprint for regulating information markets in the age of AI.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e00\u822c\u5747\u8861\u6846\u67b6\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u53d1\u7684\u4fe1\u606f\u6c61\u67d3\u6311\u6218\uff0c\u8bc1\u660e\u201c\u6c61\u67d3\u4fe1\u606f\u5747\u8861\u201d\u5b58\u5728\u53ca\u4f4e\u6548\u6027\uff0c\u63a8\u5bfc\u4fe1\u606f\u6c61\u67d3\u6307\u6570\uff0c\u63d0\u51fa\u9700\u7ec4\u5408\u653f\u7b56\u5de5\u5177\u5e76\u91c7\u7528\u9002\u5e94\u6027\u6cbb\u7406\u6846\u67b6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4f7f\u4f4e\u8d28\u91cf\u4fe1\u606f\u751f\u4ea7\u6210\u672c\u4e0d\u5bf9\u79f0\u4e0b\u964d\uff0c\u5f15\u53d1\u4fe1\u606f\u6c61\u67d3\u95ee\u9898\uff0c\u9700\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "method": "\u6784\u5efa\u4e09\u9636\u6bb5\u535a\u5f08\u6a21\u578b\uff0c\u6a21\u62df\u5784\u65ad\u5e73\u53f0\u3001\u751f\u4ea7\u8005\u548c\u6d88\u8d39\u8005\u7684\u6218\u7565\u4e92\u52a8\uff0c\u91c7\u7528\u5177\u6709\u4e0d\u540c\u66ff\u4ee3\u5f39\u6027\u7684\u751f\u4ea7\u6280\u672f\uff1b\u63a8\u5bfc\u4fe1\u606f\u6c61\u67d3\u6307\u6570\u3002", "result": "\u8bc1\u660e\u5b58\u5728\u552f\u4e00\u7684\u201c\u6c61\u67d3\u4fe1\u606f\u5747\u8861\u201d\u4e14\u8be5\u5747\u8861\u65e0\u6548\u7387\uff0c\u7531\u4e09\u91cd\u5e02\u573a\u5931\u7075\u5bfc\u81f4\uff1b\u63d0\u51fa\u9700\u7ec4\u5408\u653f\u7b56\u5de5\u5177\u5e94\u5bf9\u3002", "conclusion": "\u5728AI\u65f6\u4ee3\uff0c\u9700\u91c7\u7528\u9002\u5e94\u6027\u6cbb\u7406\u6846\u67b6\uff0c\u6839\u636e\u5b9e\u65f6\u4fe1\u606f\u6c61\u67d3\u6307\u6570\u52a8\u6001\u8c03\u6574\u653f\u7b56\u5de5\u5177\u6765\u76d1\u7ba1\u4fe1\u606f\u5e02\u573a\u3002"}}
{"id": "2509.13773", "pdf": "https://arxiv.org/pdf/2509.13773", "abs": "https://arxiv.org/abs/2509.13773", "authors": ["Zhipeng Bian", "Jieming Zhu", "Xuyang Xie", "Quanyu Dai", "Zhou Zhao", "Zhenhua Dong"], "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "categories": ["cs.AI", "cs.IR", "I.2.7; I.2.10"], "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (Volume 6: Industry Track), ACL\n  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103", "summary": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u667a\u80fd\u624b\u673a\u4efb\u52a1\u6307\u4ee4\u63a8\u8350\u7684MIRA\u6846\u67b6\uff0c\u6709\u4e09\u9879\u5173\u952e\u521b\u65b0\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u80fd\u63d0\u5347\u6307\u4ee4\u63a8\u8350\u51c6\u786e\u6027\uff0c\u6539\u5584\u7528\u6237\u4e0eAI\u670d\u52a1\u4ea4\u4e92\u4f53\u9a8c\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6280\u672f\u53d1\u5c55\uff0c\u4e3a\u7b80\u5316\u7528\u6237\u8bbf\u95ee\u9884\u5b9a\u4e49AI\u670d\u52a1\uff0c\u5b9e\u73b0\u667a\u80fd\u624b\u673a\u4e0a\u76f4\u89c2\u7684\u4e00\u952e\u5f0fAI\u4efb\u52a1\u64cd\u4f5c\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u7ba1\u9053\u3001\u6a21\u677f\u589e\u5f3a\u63a8\u7406\u673a\u5236\u548c\u57fa\u4e8e\u524d\u7f00\u6811\u7684\u53d7\u9650\u89e3\u7801\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u771f\u5b9e\u4e16\u754c\u6807\u6ce8\u6570\u636e\u96c6\u8bc4\u4f30\u548c\u7528\u6237\u7814\u7a76\uff0cMIRA\u5728\u6307\u4ee4\u63a8\u8350\u51c6\u786e\u6027\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MIRA\u6709\u6f5c\u529b\u9769\u65b0\u7528\u6237\u5728\u667a\u80fd\u624b\u673a\u4e0a\u4e0eAI\u670d\u52a1\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u63d0\u4f9b\u66f4\u65e0\u7f1d\u9ad8\u6548\u7684\u4f53\u9a8c\u3002"}}
{"id": "2509.13739", "pdf": "https://arxiv.org/pdf/2509.13739", "abs": "https://arxiv.org/abs/2509.13739", "authors": ["Zihou Wu", "Yuecheng Li", "Tianchi Liao", "Jian Lou", "Chuan Chen"], "title": "ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": "8 pages, 1 figure", "summary": "Federated learning (FL) faces a critical dilemma: existing protection\nmechanisms like differential privacy (DP) and homomorphic encryption (HE)\nenforce a rigid trade-off, forcing a choice between model utility and\ncomputational efficiency. This lack of flexibility hinders the practical\nimplementation. To address this, we introduce ParaAegis, a parallel protection\nframework designed to give practitioners flexible control over the\nprivacy-utility-efficiency balance. Our core innovation is a strategic model\npartitioning scheme. By applying lightweight DP to the less critical, low norm\nportion of the model while protecting the remainder with HE, we create a\ntunable system. A distributed voting mechanism ensures consensus on this\npartitioning. Theoretical analysis confirms the adjustments between efficiency\nand utility with the same privacy. Crucially, the experimental results\ndemonstrate that by adjusting the hyperparameters, our method enables flexible\nprioritization between model accuracy and training time.", "AI": {"tldr": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u4fdd\u62a4\u673a\u5236\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u672c\u6587\u63d0\u51faParaAegis\u6846\u67b6\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u53ef\u7075\u6d3b\u5e73\u8861\u9690\u79c1\u3001\u6548\u7528\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u4fdd\u62a4\u673a\u5236\uff08\u5982DP\u548cHE\uff09\u5728\u6a21\u578b\u6548\u7528\u548c\u8ba1\u7b97\u6548\u7387\u95f4\u5b58\u5728\u521a\u6027\u6743\u8861\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u963b\u788d\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faParaAegis\u5e76\u884c\u4fdd\u62a4\u6846\u67b6\uff0c\u91c7\u7528\u6218\u7565\u6a21\u578b\u5206\u533a\u65b9\u6848\uff0c\u5bf9\u6a21\u578b\u4f4e\u8303\u6570\u90e8\u5206\u7528\u8f7b\u91cf\u7ea7DP\uff0c\u5176\u4f59\u90e8\u5206\u7528HE\u4fdd\u62a4\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u6295\u7968\u673a\u5236\u8fbe\u6210\u5206\u533a\u5171\u8bc6\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u5b9e\u53ef\u5728\u76f8\u540c\u9690\u79c1\u4e0b\u8c03\u6574\u6548\u7387\u548c\u6548\u7528\uff0c\u5b9e\u9a8c\u8868\u660e\u8c03\u6574\u8d85\u53c2\u6570\u53ef\u7075\u6d3b\u6743\u8861\u6a21\u578b\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "ParaAegis\u6846\u67b6\u80fd\u8ba9\u4ece\u4e1a\u8005\u7075\u6d3b\u63a7\u5236\u9690\u79c1 - \u6548\u7528 - \u6548\u7387\u7684\u5e73\u8861\u3002"}}
{"id": "2509.13357", "pdf": "https://arxiv.org/pdf/2509.13357", "abs": "https://arxiv.org/abs/2509.13357", "authors": ["Yongchao Huang", "Hassan Raza"], "title": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling", "categories": ["cs.AI"], "comment": "16 pages", "summary": "We propose semantic fusion, a lightweight scheme that augments a Transformer\nlanguage model (LM) with a parallel, fuzzy-membership feature channel that\nencodes token-level semantics. Each token is represented by a vector of\ninterpretable features (e.g. part-of-speech cues, shallow roles, boundary\nflags, sentiment polarity and strength) whose values are graded degrees from\ndifferentiable membership functions (e.g. power kernels). These per-token\nvectors form a sentence-level semantic matrix fused via a gated adapter into\nthe LM. Training uses standard next-token prediction, an auxiliary loss that\nreconstructs the semantic features from hidden states, and a lightweight\nuniformizer that regularizes adjective-class distributions. On a synthetic\ntwo-clause corpus with held-out adjectives for out-of-distribution (OOD)\ncontrol, semantic fusion improves perplexity and enables precise,\nuser-controllable generation of polarity and punctuation while maintaining\nmodel simplicity. This approach adds only small overhead, remains fully\ncompatible with tied input-output embeddings, and provides an interpretable\npathway for conditioned natural language generation.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u878d\u5408\u65b9\u6848\u589e\u5f3aTransformer\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u5408\u6210\u8bed\u6599\u4e0a\u63d0\u5347\u6548\u679c\u4e14\u6709\u8bf8\u591a\u4f18\u70b9\u3002", "motivation": "\u4e3aTransformer\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u8bed\u4e49\u7f16\u7801\u80fd\u529b\uff0c\u5b9e\u73b0\u53ef\u63a7\u7684\u81ea\u7136\u8bed\u8a00\u751f\u6210\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u878d\u5408\u65b9\u6848\uff0c\u7528\u53ef\u89e3\u91ca\u7279\u5f81\u5411\u91cf\u8868\u793a\u6bcf\u4e2atoken\uff0c\u5f62\u6210\u8bed\u4e49\u77e9\u9635\u901a\u8fc7\u95e8\u63a7\u9002\u914d\u5668\u878d\u5408\u5230\u8bed\u8a00\u6a21\u578b\uff0c\u8bad\u7ec3\u91c7\u7528\u6807\u51c6\u9884\u6d4b\u3001\u8f85\u52a9\u635f\u5931\u548c\u8f7b\u91cf\u7ea7\u7edf\u4e00\u5668\u3002", "result": "\u5728\u5408\u6210\u8bed\u6599\u4e0a\u6539\u5584\u56f0\u60d1\u5ea6\uff0c\u80fd\u7cbe\u786e\u3001\u53ef\u63a7\u5730\u751f\u6210\u6781\u6027\u548c\u6807\u70b9\uff0c\u589e\u52a0\u5f00\u9500\u5c0f\uff0c\u4e0e\u8f93\u5165\u8f93\u51fa\u5d4c\u5165\u517c\u5bb9\u3002", "conclusion": "\u8bed\u4e49\u878d\u5408\u65b9\u6848\u4e3a\u6761\u4ef6\u81ea\u7136\u8bed\u8a00\u751f\u6210\u63d0\u4f9b\u53ef\u89e3\u91ca\u9014\u5f84\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u7b80\u5355\u6027\u7684\u540c\u65f6\u6709\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2509.13758", "pdf": "https://arxiv.org/pdf/2509.13758", "abs": "https://arxiv.org/abs/2509.13758", "authors": ["Kevin Halim", "Sin G. Teo", "Ruitao Feng", "Zhenpeng Chen", "Yang Gu", "Chong Wang", "Yang Liu"], "title": "A Study on Thinking Patterns of Large Reasoning Models in Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "Currently, many large language models (LLMs) are utilized for software\nengineering tasks such as code generation. The emergence of more advanced\nmodels known as large reasoning models (LRMs), such as OpenAI's o3, DeepSeek\nR1, and Qwen3. They have demonstrated the capability of performing multi-step\nreasoning. Despite the advancement in LRMs, little attention has been paid to\nsystematically analyzing the reasoning patterns these models exhibit and how\nsuch patterns influence the generated code. This paper presents a comprehensive\nstudy aimed at investigating and uncovering the reasoning behavior of LRMs\nduring code generation. We prompted several state-of-the-art LRMs of varying\nsizes with code generation tasks and applied open coding to manually annotate\nthe reasoning traces. From this analysis, we derive a taxonomy of LRM reasoning\nbehaviors, encompassing 15 reasoning actions across four phases.\n  Our empirical study based on the taxonomy reveals a series of findings.\nFirst, we identify common reasoning patterns, showing that LRMs generally\nfollow a human-like coding workflow, with more complex tasks eliciting\nadditional actions such as scaffolding, flaw detection, and style checks.\nSecond, we compare reasoning across models, finding that Qwen3 exhibits\niterative reasoning while DeepSeek-R1-7B follows a more linear, waterfall-like\napproach. Third, we analyze the relationship between reasoning and code\ncorrectness, showing that actions such as unit test creation and scaffold\ngeneration strongly support functional outcomes, with LRMs adapting strategies\nbased on task context. Finally, we evaluate lightweight prompting strategies\ninformed by these findings, demonstrating the potential of context- and\nreasoning-oriented prompts to improve LRM-generated code. Our results offer\ninsights and practical implications for advancing automatic code generation.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u5927\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u63a8\u7406\u884c\u4e3a\u8fdb\u884c\u5168\u9762\u7814\u7a76\uff0c\u5f97\u51fa\u63a8\u7406\u884c\u4e3a\u5206\u7c7b\uff0c\u6709\u5173\u4e8e\u63a8\u7406\u6a21\u5f0f\u3001\u6a21\u578b\u5bf9\u6bd4\u3001\u63a8\u7406\u4e0e\u4ee3\u7801\u6b63\u786e\u6027\u5173\u7cfb\u7b49\u53d1\u73b0\uff0c\u8bc4\u4f30\u8f7b\u91cf\u7ea7\u63d0\u793a\u7b56\u7565\u4ee5\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u5bf9LRMs\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u63a8\u7406\u6a21\u5f0f\u53ca\u5176\u5bf9\u751f\u6210\u4ee3\u7801\u7684\u5f71\u54cd\u7f3a\u4e4f\u7cfb\u7edf\u5206\u6790\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7528\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u793a\u4e0d\u540c\u89c4\u6a21\u7684LRMs\uff0c\u5e94\u7528\u5f00\u653e\u7f16\u7801\u624b\u52a8\u6ce8\u91ca\u63a8\u7406\u75d5\u8ff9\uff0c\u5f97\u51fa\u63a8\u7406\u884c\u4e3a\u5206\u7c7b\u3002", "result": "\u53d1\u73b0\u5e38\u89c1\u63a8\u7406\u6a21\u5f0f\uff0c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u63a8\u7406\u65b9\u5f0f\uff0c\u5206\u6790\u63a8\u7406\u4e0e\u4ee3\u7801\u6b63\u786e\u6027\u5173\u7cfb\uff0c\u8bc4\u4f30\u8f7b\u91cf\u7ea7\u63d0\u793a\u7b56\u7565\u53ef\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u63a8\u8fdb\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u89c1\u89e3\u548c\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2509.13633", "pdf": "https://arxiv.org/pdf/2509.13633", "abs": "https://arxiv.org/abs/2509.13633", "authors": ["Jeremy Oon", "Rakhi Manohar Mepparambath", "Ling Feng"], "title": "DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the significant progress of deep learning models in multitude of\napplications, their adaption in planning and policy related areas remains\nchallenging due to the black-box nature of these models. In this work, we\ndevelop a set of DeepLogit models that follow a novel sequentially constrained\napproach in estimating deep learning models for transport policy analysis. In\nthe first step of the proposed approach, we estimate a convolutional neural\nnetwork (CNN) model with only linear terms, which is equivalent of a\nlinear-in-parameter multinomial logit model. We then estimate other deep\nlearning models by constraining the parameters that need interpretability at\nthe values obtained in the linear-in-parameter CNN model and including higher\norder terms or by introducing advanced deep learning architectures like\nTransformers. Our approach can retain the interpretability of the selected\nparameters, yet provides significantly improved model accuracy than the\ndiscrete choice model. We demonstrate our approach on a transit route choice\nexample using real-world transit smart card data from Singapore. This study\nshows the potential for a unifying approach, where theory-based discrete choice\nmodel (DCM) and data-driven AI models can leverage each other's strengths in\ninterpretability and predictive power. With the availability of larger datasets\nand more complex constructions, such approach can lead to more accurate models\nusing discrete choice models while maintaining its applicability in planning\nand policy-related areas. Our code is available on\nhttps://github.com/jeremyoon/route-choice/ .", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1DeepLogit\u6a21\u578b\u7528\u4e8e\u4ea4\u901a\u653f\u7b56\u5206\u6790\uff0c\u7ed3\u5408\u79bb\u6563\u9009\u62e9\u6a21\u578b\u548cAI\u6a21\u578b\u4f18\u52bf\uff0c\u4ee5\u65b0\u52a0\u5761\u516c\u4ea4\u5361\u6570\u636e\u9a8c\u8bc1\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u56e0\u9ed1\u76d2\u7279\u6027\u5728\u89c4\u5212\u548c\u653f\u7b56\u9886\u57df\u5e94\u7528\u6709\u6311\u6218\uff0c\u9700\u5f00\u53d1\u53ef\u89e3\u91ca\u4e14\u51c6\u786e\u7684\u6a21\u578b\u7528\u4e8e\u4ea4\u901a\u653f\u7b56\u5206\u6790\u3002", "method": "\u91c7\u7528\u987a\u5e8f\u7ea6\u675f\u65b9\u6cd5\uff0c\u5148\u4f30\u8ba1\u4ec5\u542b\u7ebf\u6027\u9879\u7684CNN\u6a21\u578b\uff0c\u518d\u7ea6\u675f\u9700\u89e3\u91ca\u53c2\u6570\u503c\u4f30\u8ba1\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u80fd\u4fdd\u7559\u6240\u9009\u53c2\u6570\u53ef\u89e3\u91ca\u6027\uff0c\u6bd4\u79bb\u6563\u9009\u62e9\u6a21\u578b\u6709\u66f4\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u7406\u8bba\u79bb\u6563\u9009\u62e9\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8AI\u6a21\u578b\u53ef\u76f8\u4e92\u501f\u9274\u4f18\u52bf\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u4fdd\u6301\u89c4\u5212\u548c\u653f\u7b56\u9886\u57df\u9002\u7528\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u6a21\u578b\u51c6\u786e\u6027\u3002"}}
{"id": "2509.13879", "pdf": "https://arxiv.org/pdf/2509.13879", "abs": "https://arxiv.org/abs/2509.13879", "authors": ["Mariano Barone", "Antonio Romano", "Giuseppe Riccio", "Marco Postiglione", "Vincenzo Moscato"], "title": "Combining Evidence and Reasoning for Biomedical Fact-Checking", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Proceedings of the 48th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval, 2025", "summary": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https: //github.com/PRAISELab-PicusLab/CER.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u751f\u7269\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u7684CER\u6846\u67b6\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u5e76\u5f00\u6e90\u4ee3\u7801\u6570\u636e\u3002", "motivation": "\u533b\u7597\u9886\u57df\u9519\u8bef\u4fe1\u606f\u5371\u5bb3\u5927\uff0c\u751f\u7269\u533b\u5b66\u58f0\u660e\u9a8c\u8bc1\u56e0\u4e13\u4e1a\u672f\u8bed\u3001\u9886\u57df\u77e5\u8bc6\u548c\u79d1\u5b66\u8bc1\u636e\u8981\u6c42\u9762\u4e34\u6311\u6218\u3002", "method": "\u5f15\u5165CER\u6846\u67b6\uff0c\u6574\u5408\u79d1\u5b66\u8bc1\u636e\u68c0\u7d22\u3001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u76d1\u7763\u771f\u5b9e\u6027\u9884\u6d4b\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u751f\u6210\u80fd\u529b\u4e0e\u5148\u8fdb\u68c0\u7d22\u6280\u672f\u3002", "result": "\u5728\u4e13\u5bb6\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u548c\u826f\u597d\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "CER\u6846\u67b6\u6709\u6548\u964d\u4f4e\u5e7b\u89c9\u98ce\u9669\uff0c\u786e\u4fdd\u8f93\u51fa\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u7684\u8bc1\u636e\u6e90\uff0c\u5177\u6709\u8f83\u597d\u6548\u679c\u3002"}}
{"id": "2509.13855", "pdf": "https://arxiv.org/pdf/2509.13855", "abs": "https://arxiv.org/abs/2509.13855", "authors": ["Shamsiiat Abdurakhmanova", "Alex Jung"], "title": "Graph-Regularized Learning of Gaussian Mixture Models", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in\ndistributed settings with heterogeneous and limited local data. The method\nexploits a provided similarity graph to guide parameter sharing among nodes,\navoiding the transfer of raw data. The resulting model allows for flexible\naggregation of neighbors' parameters and outperforms both centralized and\nlocally trained GMMs in heterogeneous, low-sample regimes.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u57fa\u4e8e\u56fe\u6b63\u5219\u5316\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u76f8\u4f3c\u56fe\u5f15\u5bfc\u53c2\u6570\u5171\u4eab\uff0c\u5728\u5f02\u6784\u5c0f\u6837\u672c\u573a\u666f\u8868\u73b0\u4f18\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u5f02\u6784\u4e14\u6709\u9650\u672c\u5730\u6570\u636e\u4e0b\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u5229\u7528\u7ed9\u5b9a\u7684\u76f8\u4f3c\u56fe\u5f15\u5bfc\u8282\u70b9\u95f4\u53c2\u6570\u5171\u4eab\uff0c\u907f\u514d\u539f\u59cb\u6570\u636e\u4f20\u8f93\u3002", "result": "\u5f97\u5230\u7684\u6a21\u578b\u80fd\u7075\u6d3b\u805a\u5408\u90bb\u5c45\u53c2\u6570\uff0c\u5728\u5f02\u6784\u5c0f\u6837\u672c\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u672c\u5730\u8bad\u7ec3\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u5f02\u6784\u5c0f\u6837\u672c\u6570\u636e\u4e0b\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5b66\u4e60\u3002"}}
{"id": "2509.13364", "pdf": "https://arxiv.org/pdf/2509.13364", "abs": "https://arxiv.org/abs/2509.13364", "authors": ["Zixi Li"], "title": "Asterisk Operator", "categories": ["cs.AI"], "comment": "Code available at: https://github.com/lizixi-0x2F/Asterisk-Games", "summary": "We propose the \\textbf{Asterisk Operator} ($\\ast$-operator), a novel unified\nframework for abstract reasoning based on Adjacency-Structured Parallel\nPropagation (ASPP). The operator formalizes structured reasoning tasks as\nlocal, parallel state evolution processes guided by implicit relational graphs.\nWe prove that the $\\ast$-operator maintains local computational constraints\nwhile achieving global reasoning capabilities, providing an efficient and\nconvergent computational paradigm for abstract reasoning problems. Through\nrigorous mathematical analysis and comprehensive experiments on ARC2 challenges\nand Conway's Game of Life, we demonstrate the operator's universality,\nconvergence properties, and superior performance. Our innovative\nEmbedding-Asterisk distillation method achieves 100\\% accuracy on ARC2\nvalidation with only 6M parameters, representing a significant breakthrough in\nneural-symbolic reasoning.\n  \\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel\nPropagation, Asterisk Operator, Convergence, Universal Approximation", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eASPP\u7684Asterisk Operator\u7edf\u4e00\u6846\u67b6\u7528\u4e8e\u62bd\u8c61\u63a8\u7406\uff0c\u8bc1\u660e\u5176\u7279\u6027\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0cEmbedding - Asterisk\u84b8\u998f\u6cd5\u5728ARC2\u9a8c\u8bc1\u8fbe100%\u51c6\u786e\u7387\u3002", "motivation": "\u4e3a\u62bd\u8c61\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u9ad8\u6548\u4e14\u6536\u655b\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u89e3\u51b3\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u63d0\u51faAsterisk Operator\uff0c\u5c06\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u5c40\u90e8\u3001\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\uff1b\u91c7\u7528Embedding - Asterisk\u84b8\u998f\u65b9\u6cd5\uff1b\u8fdb\u884c\u6570\u5b66\u5206\u6790\u548c\u5b9e\u9a8c\u3002", "result": "Asterisk Operator\u5c55\u73b0\u51fa\u666e\u904d\u6027\u3001\u6536\u655b\u6027\u548c\u4f18\u8d8a\u6027\u80fd\uff0cEmbedding - Asterisk\u84b8\u998f\u6cd5\u7528600\u4e07\u53c2\u6570\u5728ARC2\u9a8c\u8bc1\u8fbe100%\u51c6\u786e\u7387\u3002", "conclusion": "Asterisk Operator\u4e3a\u62bd\u8c61\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0cEmbedding - Asterisk\u84b8\u998f\u6cd5\u5728\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u4e0a\u6709\u91cd\u5927\u7a81\u7834\u3002"}}
{"id": "2509.13782", "pdf": "https://arxiv.org/pdf/2509.13782", "abs": "https://arxiv.org/abs/2509.13782", "authors": ["Yu Ge", "Linna Xie", "Zhong Li", "Yu Pei", "Tian Zhang"], "title": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis", "categories": ["cs.SE", "cs.AI", "cs.MA", "D.2.2; I.2.1"], "comment": "20 pages, 6 figures", "summary": "Large Language Model Powered Multi-Agent Systems (MASs) are increasingly\nemployed to automate complex real-world problems, such as programming and\nscientific discovery. Despite their promising, MASs are not without their\nflaws. However, failure attribution in MASs - pinpointing the specific agent\nactions responsible for failures - remains underexplored and labor-intensive,\nposing significant challenges for debugging and system improvement. To bridge\nthis gap, we propose FAMAS, the first spectrum-based failure attribution\napproach for MASs, which operates through systematic trajectory replay and\nabstraction, followed by spectrum analysis.The core idea of FAMAS is to\nestimate, from variations across repeated MAS executions, the likelihood that\neach agent action is responsible for the failure. In particular, we propose a\nnovel suspiciousness formula tailored to MASs, which integrates two key factor\ngroups, namely the agent behavior group and the action behavior group, to\naccount for the agent activation patterns and the action activation patterns\nwithin the execution trajectories of MASs. Through expensive evaluations\nagainst 12 baselines on the Who and When benchmark, FAMAS demonstrates superior\nperformance by outperforming all the methods in comparison.", "AI": {"tldr": "\u63d0\u51faFAMAS\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MASs\uff09\u6545\u969c\u5f52\u56e0\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "MASs\u867d\u6709\u5e94\u7528\u4f46\u6545\u969c\u5f52\u56e0\u7814\u7a76\u4e0d\u8db3\u4e14\u8d39\u529b\uff0c\u5f71\u54cd\u8c03\u8bd5\u548c\u7cfb\u7edf\u6539\u8fdb\u3002", "method": "\u63d0\u51faFAMAS\uff0c\u901a\u8fc7\u7cfb\u7edf\u8f68\u8ff9\u91cd\u653e\u548c\u62bd\u8c61\uff0c\u518d\u8fdb\u884c\u9891\u8c31\u5206\u6790\uff0c\u8fd8\u6709\u9488\u5bf9MASs\u7684\u53ef\u7591\u6027\u516c\u5f0f\u3002", "result": "\u5728Who and When\u57fa\u51c6\u4e0a\u4e0e12\u4e2a\u57fa\u7ebf\u5bf9\u6bd4\u8bc4\u4f30\uff0cFAMAS\u8868\u73b0\u4f18\u4e8e\u6240\u6709\u5bf9\u6bd4\u65b9\u6cd5\u3002", "conclusion": "FAMAS\u662f\u6709\u6548\u7684MASs\u6545\u969c\u5f52\u56e0\u65b9\u6cd5\u3002"}}
{"id": "2509.13634", "pdf": "https://arxiv.org/pdf/2509.13634", "abs": "https://arxiv.org/abs/2509.13634", "authors": ["Md Bokhtiar Al Zami", "Md Raihan Uddin", "Dinh C. Nguyen"], "title": "Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs", "categories": ["cs.LG", "cs.CR"], "comment": "15 pages, under revision at IEEE Internet of Things Journal", "summary": "Federated learning (FL) has gained popularity as a privacy-preserving method\nof training machine learning models on decentralized networks. However to\nensure reliable operation of UAV-assisted FL systems, issues like as excessive\nenergy consumption, communication inefficiencies, and security vulnerabilities\nmust be solved. This paper proposes an innovative framework that integrates\nDigital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to\ntackle these challenges. UAVs act as mobile base stations, allowing scattered\ndevices to train FL models locally and upload model updates for aggregation. By\nincorporating DT technology, our approach enables real-time system monitoring\nand predictive maintenance, improving UAV network efficiency. Additionally,\nZero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification\nwithout exposing sensitive data. To optimize energy efficiency and resource\nmanagement, we introduce a dynamic allocation strategy that adjusts UAV flight\npaths, transmission power, and processing rates based on network conditions.\nUsing block coordinate descent and convex optimization techniques, our method\nsignificantly reduces system energy consumption by up to 29.6% compared to\nconventional FL approaches. Simulation results demonstrate improved learning\nperformance, security, and scalability, positioning this framework as a\npromising solution for next-generation UAV-based intelligent networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u6280\u672f\u548c\u96f6\u77e5\u8bc6\u8054\u90a6\u5b66\u4e60\uff08zkFed\uff09\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u65e0\u4eba\u673a\u8f85\u52a9\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u7684\u80fd\u8017\u3001\u901a\u4fe1\u548c\u5b89\u5168\u95ee\u9898\uff0c\u964d\u4f4e\u80fd\u8017\uff0c\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u786e\u4fdd\u65e0\u4eba\u673a\u8f85\u52a9\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u53ef\u9760\u8fd0\u884c\uff0c\u89e3\u51b3\u80fd\u8017\u8fc7\u9ad8\u3001\u901a\u4fe1\u4f4e\u6548\u548c\u5b89\u5168\u6f0f\u6d1e\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7ed3\u5408DT\u6280\u672f\u548czkFed\u7684\u6846\u67b6\uff0c\u65e0\u4eba\u673a\u4f5c\u79fb\u52a8\u57fa\u7ad9\uff0c\u5229\u7528DT\u6280\u672f\u5b9e\u73b0\u5b9e\u65f6\u76d1\u63a7\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u589e\u5f3a\u5b89\u5168\uff0c\u5f15\u5165\u52a8\u6001\u5206\u914d\u7b56\u7565\uff0c\u4f7f\u7528\u5757\u5750\u6807\u4e0b\u964d\u548c\u51f8\u4f18\u5316\u6280\u672f\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7cfb\u7edf\u80fd\u8017\u6700\u591a\u964d\u4f4e29.6%\uff0c\u6a21\u62df\u7ed3\u679c\u663e\u793a\u5b66\u4e60\u6027\u80fd\u3001\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\u5f97\u5230\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u4e0b\u4e00\u4ee3\u57fa\u4e8e\u65e0\u4eba\u673a\u7684\u667a\u80fd\u7f51\u7edc\u7684\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13888", "pdf": "https://arxiv.org/pdf/2509.13888", "abs": "https://arxiv.org/abs/2509.13888", "authors": ["Mariano Barone", "Antonio Romano", "Giuseppe Riccio", "Marco Postiglione", "Vincenzo Moscato"], "title": "Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https://github.com/PRAISELab-PicusLab/CER", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u751f\u7269\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u7684CER\u6846\u67b6\uff0c\u7ed3\u5408\u8bc1\u636e\u68c0\u7d22\u3001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u76d1\u7763\u771f\u5b9e\u6027\u9884\u6d4b\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\u5e76\u5f00\u6e90\u3002", "motivation": "\u533b\u7597\u9886\u57df\u9519\u8bef\u4fe1\u606f\u5371\u5bb3\u5927\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u5728\u9a8c\u8bc1\u751f\u7269\u533b\u5b66\u58f0\u660e\u65f6\u9762\u4e34\u6311\u6218\u3002", "method": "\u5f15\u5165CER\u6846\u67b6\uff0c\u6574\u5408\u79d1\u5b66\u8bc1\u636e\u68c0\u7d22\u3001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u76d1\u7763\u771f\u5b9e\u6027\u9884\u6d4b\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u751f\u6210\u80fd\u529b\u4e0e\u5148\u8fdb\u68c0\u7d22\u6280\u672f\u3002", "result": "\u5728\u4e13\u5bb6\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u548c\u6709\u524d\u666f\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "CER\u6846\u67b6\u80fd\u6709\u6548\u7f13\u89e3\u5e7b\u89c9\u98ce\u9669\uff0c\u786e\u4fdd\u8f93\u51fa\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u7684\u8bc1\u636e\u6e90\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2509.13933", "pdf": "https://arxiv.org/pdf/2509.13933", "abs": "https://arxiv.org/abs/2509.13933", "authors": ["Qiyue Li", "Yingxin Liu", "Hang Qi", "Jieping Luo", "Zhizhang Liu", "Jingjin Wu"], "title": "Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "We consider the client selection problem in wireless Federated Learning (FL),\nwith the objective of reducing the total required time to achieve a certain\nlevel of learning accuracy. Since the server cannot observe the clients'\ndynamic states that can change their computation and communication efficiency,\nwe formulate client selection as a restless multi-armed bandit problem. We\npropose a scalable and efficient approach called the Whittle Index Learning in\nFederated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and\nupdate an approximated Whittle index associated with each client, and then\nselects the clients with the highest indices. Compared to existing approaches,\nWILF-Q does not require explicit knowledge of client state transitions or data\ndistributions, making it well-suited for deployment in practical FL settings.\nExperiment results demonstrate that WILF-Q significantly outperforms existing\nbaseline policies in terms of learning efficiency, providing a robust and\nefficient approach to client selection in wireless FL.", "AI": {"tldr": "\u9488\u5bf9\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u51faWILF - Q\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u5b66\u4e60\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7b56\u7565\u3002", "motivation": "\u89e3\u51b3\u670d\u52a1\u5668\u65e0\u6cd5\u89c2\u6d4b\u5ba2\u6237\u7aef\u52a8\u6001\u72b6\u6001\uff0c\u4ee5\u51cf\u5c11\u8fbe\u5230\u4e00\u5b9a\u5b66\u4e60\u7cbe\u5ea6\u6240\u9700\u7684\u603b\u65f6\u95f4\u3002", "method": "\u5c06\u5ba2\u6237\u7aef\u9009\u62e9\u95ee\u9898\u5efa\u6a21\u4e3a restless\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63d0\u51faWILF - Q\u65b9\u6cd5\uff0c\u7528Q - learning\u81ea\u9002\u5e94\u5b66\u4e60\u548c\u66f4\u65b0\u4e0e\u6bcf\u4e2a\u5ba2\u6237\u7aef\u76f8\u5173\u7684\u8fd1\u4f3cWhittle\u6307\u6570\uff0c\u9009\u62e9\u6307\u6570\u6700\u9ad8\u7684\u5ba2\u6237\u7aef\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aWILF - Q\u5728\u5b66\u4e60\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7b56\u7565\u3002", "conclusion": "WILF - Q\u662f\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u9009\u62e9\u7684\u5f3a\u5927\u800c\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u660e\u786e\u7684\u5ba2\u6237\u7aef\u72b6\u6001\u8f6c\u79fb\u6216\u6570\u636e\u5206\u5e03\u77e5\u8bc6\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2509.13368", "pdf": "https://arxiv.org/pdf/2509.13368", "abs": "https://arxiv.org/abs/2509.13368", "authors": ["Yuan Wei", "Xiaohan Shan", "Ran Miao", "Jianmin Li"], "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "categories": ["cs.AI", "cs.LG"], "comment": "9 pages, 7 figures", "summary": "Reinforcement learning agent development traditionally requires extensive\nexpertise and lengthy iterations, often resulting in high failure rates and\nlimited accessibility. This paper introduces $Agent^2$, a novel\nagent-generates-agent framework that achieves fully automated RL agent design\nthrough intelligent LLM-driven generation. The system autonomously transforms\nnatural language task descriptions and environment code into comprehensive,\nhigh-performance reinforcement learning solutions without human intervention.\n$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent\nserves as an autonomous AI designer that analyzes tasks and generates\nexecutable RL agents, while the Target Agent is the resulting automatically\ngenerated RL agent. The framework decomposes RL development into two distinct\nstages: MDP modeling and algorithmic optimization, enabling more targeted and\neffective agent generation. Built on the Model Context Protocol, $Agent^2$\nprovides a unified framework that standardizes intelligent agent creation\nacross diverse environments and algorithms, while incorporating adaptive\ntraining management and intelligent feedback analysis for continuous\nimprovement. Extensive experiments on a wide range of benchmarks, including\nMuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently\noutperforms manually designed solutions across all tasks, achieving up to 55%\nperformance improvement and substantial gains on average. By enabling truly\nend-to-end, closed-loop automation, this work establishes a new paradigm in\nwhich intelligent agents design and optimize other agents, marking a\nfundamental breakthrough for automated AI systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Agent^2\u6846\u67b6\uff0c\u53ef\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u5b9e\u73b0\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u5168\u81ea\u52a8\u8bbe\u8ba1\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u624b\u52a8\u8bbe\u8ba1\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5f00\u53d1\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u548c\u591a\u6b21\u8fed\u4ee3\uff0c\u5931\u8d25\u7387\u9ad8\u4e14\u53ef\u53ca\u6027\u6709\u9650\u3002", "method": "\u63d0\u51faAgent^2\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5c06\u5f00\u53d1\u5206\u4e3aMDP\u5efa\u6a21\u548c\u7b97\u6cd5\u4f18\u5316\u4e24\u9636\u6bb5\uff0c\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u8bad\u7ec3\u7ba1\u7406\u548c\u667a\u80fd\u53cd\u9988\u5206\u6790\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgent^2\u59cb\u7ec8\u4f18\u4e8e\u624b\u52a8\u8bbe\u8ba1\u65b9\u6848\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe55%\u3002", "conclusion": "Agent^2\u5b9e\u73b0\u7aef\u5230\u7aef\u95ed\u73af\u81ea\u52a8\u5316\uff0c\u5f00\u521b\u4e86\u667a\u80fd\u4f53\u8bbe\u8ba1\u548c\u4f18\u5316\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u65b0\u8303\u5f0f\uff0c\u662f\u81ea\u52a8\u5316AI\u7cfb\u7edf\u7684\u91cd\u5927\u7a81\u7834\u3002"}}
{"id": "2509.13852", "pdf": "https://arxiv.org/pdf/2509.13852", "abs": "https://arxiv.org/abs/2509.13852", "authors": ["Yulun Wu", "Guangba Yu", "Zhihan Jiang", "Yichen Li", "Michael R. Lyu"], "title": "Trace Sampling 2.0: Code Knowledge Enhanced Span-level Sampling for Distributed Tracing", "categories": ["cs.SE"], "comment": null, "summary": "Distributed tracing is an essential diagnostic tool in microservice systems,\nbut the sheer volume of traces places a significant burden on backend storage.\nA common approach to mitigating this issue is trace sampling, which selectively\nretains traces based on specific criteria, often preserving only anomalous\nones. However, this method frequently discards valuable information, including\nnormal traces that are essential for comparative analysis. To address this\nlimitation, we introduce Trace Sampling 2.0, which operates at the span level\nwhile maintaining trace structure consistency. This approach allows for the\nretention of all traces while significantly reducing storage overhead. Based on\nthis concept, we design and implement Autoscope, a span-level sampling method\nthat leverages static analysis to extract execution logic, ensuring that\ncritical spans are preserved without compromising structural integrity. We\nevaluated Autoscope on two open-source microservices. Our results show that it\nreduces trace size by 81.2% while maintaining 98.1% faulty span coverage,\noutperforming existing trace-level sampling methods. Furthermore, we\ndemonstrate its effectiveness in root cause analysis, achieving an average\nimprovement of 8.3%. These findings indicate that Autoscope can significantly\nenhance observability and storage efficiency in microservices, offering a\nrobust solution for performance monitoring.", "AI": {"tldr": "\u63d0\u51faTrace Sampling 2.0\u6982\u5ff5\u5e76\u5b9e\u73b0Autoscope\u65b9\u6cd5\uff0c\u5728\u4e24\u5f00\u6e90\u5fae\u670d\u52a1\u8bc4\u4f30\uff0c\u80fd\u964d\u8ff9\u5927\u5c0f81.2%\u3001\u4fdd98.1%\u6545\u969c\u8de8\u5ea6\u8986\u76d6\uff0c\u6839\u56e0\u5206\u6790\u5e73\u5747\u63d0\u53478.3%\u3002", "motivation": "\u4f20\u7edf\u8ddf\u8e2a\u91c7\u6837\u65b9\u6cd5\u5e38\u4e22\u5f03\u6709\u4ef7\u503c\u4fe1\u606f\uff0c\u9700\u65b0\u65b9\u6cd5\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\u540c\u65f6\u4fdd\u7559\u66f4\u591a\u4fe1\u606f\u3002", "method": "\u5f15\u5165Trace Sampling 2.0\uff0c\u8bbe\u8ba1\u5b9e\u73b0\u57fa\u4e8e\u8de8\u5ea6\u7ea7\u91c7\u6837\u7684Autoscope\u65b9\u6cd5\uff0c\u5229\u7528\u9759\u6001\u5206\u6790\u63d0\u53d6\u6267\u884c\u903b\u8f91\u3002", "result": "Autoscope\u51cf\u5c11\u8ddf\u8e2a\u5927\u5c0f81.2%\uff0c\u4fdd\u630198.1%\u6545\u969c\u8de8\u5ea6\u8986\u76d6\uff0c\u6839\u56e0\u5206\u6790\u5e73\u5747\u63d0\u53478.3%\u3002", "conclusion": "Autoscope\u80fd\u663e\u8457\u63d0\u9ad8\u5fae\u670d\u52a1\u53ef\u89c2\u6d4b\u6027\u548c\u5b58\u50a8\u6548\u7387\uff0c\u4e3a\u6027\u80fd\u76d1\u63a7\u63d0\u4f9b\u6709\u529b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13636", "pdf": "https://arxiv.org/pdf/2509.13636", "abs": "https://arxiv.org/abs/2509.13636", "authors": ["Yasin Hasanpoor", "Bahram Tarvirdizadeh", "Khalil Alipour", "Mohammad Ghamari"], "title": "Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images", "categories": ["cs.LG"], "comment": "14 pages 7 images 2 tables", "summary": "This study introduces a novel method that transforms multimodal physiological\nsignalsphotoplethysmography (PPG), galvanic skin response (GSR), and\nacceleration (ACC) into 2D image matrices to enhance stress detection using\nconvolutional neural networks (CNNs). Unlike traditional approaches that\nprocess these signals separately or rely on fixed encodings, our technique\nfuses them into structured image representations that enable CNNs to capture\ntemporal and cross signal dependencies more effectively. This image based\ntransformation not only improves interpretability but also serves as a robust\nform of data augmentation. To further enhance generalization and model\nrobustness, we systematically reorganize the fused signals into multiple\nformats, combining them in a multi stage training pipeline. This approach\nsignificantly boosts classification performance. While demonstrated here in the\ncontext of stress detection, the proposed method is broadly applicable to any\ndomain involving multimodal physiological signals, paving the way for more\naccurate, personalized, and real time health monitoring through wearable\ntechnologies.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u8f6c\u6362\u4e3a2D\u56fe\u50cf\u77e9\u9635\u7684\u65b0\u65b9\u6cd5\uff0c\u63d0\u5347\u538b\u529b\u68c0\u6d4b\u6548\u679c\uff0c\u9002\u7528\u4e8e\u591a\u9886\u57df\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5355\u72ec\u5904\u7406\u4fe1\u53f7\u6216\u4f9d\u8d56\u56fa\u5b9a\u7f16\u7801\uff0c\u4e0d\u80fd\u6709\u6548\u6355\u6349\u65f6\u95f4\u548c\u8de8\u4fe1\u53f7\u4f9d\u8d56\uff0c\u9700\u6539\u8fdb\u538b\u529b\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5c06\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u8f6c\u6362\u4e3a2D\u56fe\u50cf\u77e9\u9635\uff0c\u7528CNN\u5904\u7406\uff1b\u7cfb\u7edf\u5730\u5c06\u878d\u5408\u4fe1\u53f7\u91cd\u7ec4\u4e3a\u591a\u79cd\u683c\u5f0f\uff0c\u5728\u591a\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\u4e2d\u7ec4\u5408\u3002", "result": "\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u6d89\u53ca\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u7684\u4efb\u4f55\u9886\u57df\uff0c\u4e3a\u53ef\u7a7f\u6234\u6280\u672f\u7684\u5065\u5eb7\u76d1\u6d4b\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2509.14098", "pdf": "https://arxiv.org/pdf/2509.14098", "abs": "https://arxiv.org/abs/2509.14098", "authors": ["Doru Thom Popovici", "Harlin Lee", "Mauro Del Ben", "Naoki Yoshioka", "Nobuyasu Ito", "Katherine Klymko", "Daan Camps", "Anastasiia Butko"], "title": "A Closeness Centrality-based Circuit Partitioner for Quantum Simulations", "categories": ["quant-ph", "cs.DC"], "comment": "14 pages, 10 figures", "summary": "Simulating quantum circuits (QC) on high-performance computing (HPC) systems\nhas become an essential method to benchmark algorithms and probe the potential\nof large-scale quantum computation despite the limitations of current quantum\nhardware. However, these simulations often require large amounts of resources,\nnecessitating the use of large clusters with thousands of compute nodes and\nlarge memory footprints. In this work, we introduce an end-to-end framework\nthat provides an efficient partitioning scheme for large-scale QCs alongside a\nflexible code generator to offer a portable solution that minimizes data\nmovement between compute nodes. By formulating the distribution of quantum\nstates and circuits as a graph problem, we apply closeness centrality to assess\ngate importance and design a fast, scalable partitioning method. The resulting\npartitions are compiled into highly optimized codes that run seamlessly on a\nwide range of supercomputers, providing critical insights into the performance\nand scalability of quantum algorithm simulations.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u7528\u4e8e\u5927\u89c4\u6a21\u91cf\u5b50\u7535\u8def\u6a21\u62df\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u53ef\u51cf\u5c11\u8ba1\u7b97\u8282\u70b9\u95f4\u6570\u636e\u79fb\u52a8\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u7535\u8def\u6a21\u62df\u9700\u5927\u91cf\u8d44\u6e90\uff0c\u9700\u5927\u578b\u96c6\u7fa4\u548c\u5927\u5185\u5b58\uff0c\u9700\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u91cf\u5b50\u6001\u548c\u7535\u8def\u5206\u5e03\u4f5c\u4e3a\u56fe\u95ee\u9898\uff0c\u7528\u7d27\u5bc6\u4e2d\u5fc3\u6027\u8bc4\u4f30\u95e8\u7684\u91cd\u8981\u6027\uff0c\u8bbe\u8ba1\u5206\u533a\u65b9\u6cd5\uff0c\u5c06\u5206\u533a\u7f16\u8bd1\u4e3a\u4f18\u5316\u4ee3\u7801\u3002", "result": "\u6846\u67b6\u80fd\u5728\u591a\u79cd\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u65e0\u7f1d\u8fd0\u884c\u3002", "conclusion": "\u6846\u67b6\u4e3a\u91cf\u5b50\u7b97\u6cd5\u6a21\u62df\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u63d0\u4f9b\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2509.13379", "pdf": "https://arxiv.org/pdf/2509.13379", "abs": "https://arxiv.org/abs/2509.13379", "authors": ["Asif Azad", "Mohammad Sadat Hossain", "MD Sadik Hossain Shanto", "M Saifur Rahman", "Md Rizwan Pervez"], "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) have achieved remarkable progress in complex\nvisual understanding across scientific and reasoning tasks. While performance\nbenchmarking has advanced our understanding of these capabilities, the critical\ndimension of uncertainty quantification has received insufficient attention.\nTherefore, unlike prior conformal prediction studies that focused on limited\nsettings, we conduct a comprehensive uncertainty benchmarking study, evaluating\n16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets\nwith 3 distinct scoring functions. Our findings demonstrate that larger models\nconsistently exhibit better uncertainty quantification; models that know more\nalso know better what they don't know. More certain models achieve higher\naccuracy, while mathematical and reasoning tasks elicit poorer uncertainty\nperformance across all models compared to other domains. This work establishes\na foundation for reliable uncertainty evaluation in multimodal systems.", "AI": {"tldr": "\u5bf916\u4e2aVLM\u6a21\u578b\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u66f4\u597d\uff0c\u66f4\u786e\u5b9a\u7684\u6a21\u578b\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\u5dee\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u53d7\u5173\u6ce8\uff0c\u4f46\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7ef4\u5ea6\u5173\u6ce8\u4e0d\u8db3\u3002", "method": "\u5bf916\u4e2a\u6700\u5148\u8fdb\u7684VLMs\uff08\u5f00\u6e90\u548c\u95ed\u6e90\uff09\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u75283\u79cd\u4e0d\u540c\u8bc4\u5206\u51fd\u6570\u8fdb\u884c\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5927\u6a21\u578b\u59cb\u7ec8\u6709\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff1b\u66f4\u786e\u5b9a\u7684\u6a21\u578b\u7cbe\u5ea6\u66f4\u9ad8\uff1b\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u4e2d\u6240\u6709\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\u6bd4\u5176\u4ed6\u9886\u57df\u5dee\u3002", "conclusion": "\u4e3a\u591a\u6a21\u6001\u7cfb\u7edf\u7684\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.13868", "pdf": "https://arxiv.org/pdf/2509.13868", "abs": "https://arxiv.org/abs/2509.13868", "authors": ["Manal Binkhonain", "Reem Alfayaz"], "title": "Are Prompts All You Need? Evaluating Prompt-Based Large Language Models (LLM)s for Software Requirements Classification", "categories": ["cs.SE"], "comment": "33 pages, 12 figures", "summary": "Requirements classification assigns natural language requirements to\npredefined classes, such as functional and non functional. Accurate\nclassification reduces risk and improves software quality. Most existing models\nrely on supervised learning, which needs large labeled data that are costly,\nslow to create, and domain dependent; they also generalize poorly and often\nrequire retraining for each task. This study tests whether prompt based large\nlanguage models can reduce data needs. We benchmark several models and\nprompting styles (zero shot, few shot, persona, and chain of thought) across\nmultiple tasks on two English datasets, PROMISE and SecReq. For each task we\ncompare model prompt configurations and then compare the best LLM setups with a\nstrong fine tuned transformer baseline. Results show that prompt based LLMs,\nespecially with few shot prompts, can match or exceed the baseline. Adding a\npersona, or persona plus chain of thought, can yield further gains. We conclude\nthat prompt based LLMs are a practical and scalable option that reduces\ndependence on large annotations and can improve generalizability across tasks.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u51cf\u5c11\u9700\u6c42\u5206\u7c7b\u7684\u6570\u636e\u9700\u6c42\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u57fa\u4e8e\u63d0\u793a\u7684LLM\u5c24\u5176\u662f\u5c11\u6837\u672c\u63d0\u793a\u53ef\u5ab2\u7f8e\u6216\u8d85\u8d8a\u57fa\u7ebf\uff0c\u52a0\u4eba\u8bbe\u7b49\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6548\u679c\uff0c\u662f\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u9700\u6c42\u5206\u7c7b\u6a21\u578b\u4f9d\u8d56\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u6210\u672c\u9ad8\u3001\u521b\u5efa\u6162\u3001\u4f9d\u8d56\u9886\u57df\u3001\u6cdb\u5316\u6027\u5dee\u4e14\u5e38\u9700\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u91cd\u65b0\u8bad\u7ec3\uff0c\u56e0\u6b64\u6d4b\u8bd5\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u51cf\u5c11\u6570\u636e\u9700\u6c42\u3002", "method": "\u5728\u4e24\u4e2a\u82f1\u8bed\u6570\u636e\u96c6PROMISE\u548cSecReq\u4e0a\u5bf9\u591a\u4e2a\u4efb\u52a1\uff0c\u5bf9\u51e0\u79cd\u6a21\u578b\u548c\u63d0\u793a\u98ce\u683c\uff08\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u4eba\u8bbe\u3001\u601d\u7ef4\u94fe\uff09\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u6a21\u578b\u63d0\u793a\u914d\u7f6e\u5e76\u4e0e\u5f3a\u5fae\u8c03\u7684Transformer\u57fa\u7ebf\u5bf9\u6bd4\u3002", "result": "\u57fa\u4e8e\u63d0\u793a\u7684LLM\u5c24\u5176\u662f\u5c11\u6837\u672c\u63d0\u793a\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u57fa\u7ebf\uff0c\u6dfb\u52a0\u4eba\u8bbe\u6216\u4eba\u8bbe\u52a0\u601d\u7ef4\u94fe\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6548\u679c\u3002", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u7684LLM\u662f\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u9009\u62e9\uff0c\u53ef\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u6ce8\u7684\u4f9d\u8d56\u5e76\u63d0\u9ad8\u8de8\u4efb\u52a1\u7684\u6cdb\u5316\u6027\u3002"}}
{"id": "2509.13642", "pdf": "https://arxiv.org/pdf/2509.13642", "abs": "https://arxiv.org/abs/2509.13642", "authors": ["Zirun Guo", "Feng Zhang", "Kai Jia", "Tao Jin"], "title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that\nreframes interleaved image-text generation as a tool-use problem. LLM-I is\ndesigned to overcome the \"one-tool\" bottleneck of current unified models, which\nare limited to synthetic imagery and struggle with tasks requiring factual\ngrounding or programmatic precision. Our framework empowers a central LLM or\nMLLM agent to intelligently orchestrate a diverse toolkit of specialized visual\ntools, including online image search, diffusion-based generation, code\nexecution, and image editing. The agent is trained to select and apply these\ntools proficiently via a Reinforcement Learning (RL) framework that features a\nhybrid reward system combining rule-based logic with judgments from LLM and\nMLLM evaluators. Trained on a diverse new dataset using four different model\nbackbones, LLM-I demonstrates state-of-the-art performance, outperforming\nexisting methods by a large margin across four benchmarks. We also introduce a\nnovel test-time scaling strategy that provides further performance gains.\nProject Page: https://github.com/ByteDance-BandAI/LLM-I.", "AI": {"tldr": "\u63d0\u51faLLM - I\u6846\u67b6\uff0c\u5c06\u4ea4\u9519\u56fe\u50cf\u6587\u672c\u751f\u6210\u89c6\u4e3a\u5de5\u5177\u4f7f\u7528\u95ee\u9898\uff0c\u7528RL\u8bad\u7ec3\uff0c\u8868\u73b0\u8d85\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u6709\u6d4b\u8bd5\u65f6\u7f29\u653e\u7b56\u7565\u3002", "motivation": "\u514b\u670d\u5f53\u524d\u7edf\u4e00\u6a21\u578b\u7684\u201c\u5355\u5de5\u5177\u201d\u74f6\u9888\uff0c\u89e3\u51b3\u5176\u5728\u5408\u6210\u56fe\u50cf\u53ca\u9700\u8981\u4e8b\u5b9e\u4f9d\u636e\u6216\u7f16\u7a0b\u7cbe\u5ea6\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u3002", "method": "\u8bbe\u8ba1LLM - I\u6846\u67b6\uff0c\u8ba9\u4e2d\u5fc3LLM\u6216MLLM\u4ee3\u7406\u667a\u80fd\u7f16\u6392\u591a\u79cd\u89c6\u89c9\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u5408\u89c4\u5219\u903b\u8f91\u548cLLM\u3001MLLM\u8bc4\u4f30\u5668\u5224\u65ad\u7684\u6df7\u5408\u5956\u52b1\u7cfb\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\u4ee3\u7406\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u91c7\u7528\u65b0\u6d4b\u8bd5\u65f6\u7f29\u653e\u7b56\u7565\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "LLM - I\u6846\u67b6\u5728\u56fe\u50cf\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.14211", "pdf": "https://arxiv.org/pdf/2509.14211", "abs": "https://arxiv.org/abs/2509.14211", "authors": ["Pascal Costanza", "Timothy G. Mattson", "Raye Kimmerer", "Benjamin Brock"], "title": "Julia GraphBLAS with Nonblocking Execution", "categories": ["cs.MS", "cs.DC", "cs.PL"], "comment": null, "summary": "From the beginning, the GraphBLAS were designed for ``nonblocking\nexecution''; i.e., calls to GraphBLAS methods return as soon as the arguments\nto the methods are validated and define a directed acyclic graph (DAG) of\nGraphBLAS operations. This lets GraphBLAS implementations fuse functions, elide\nunneeded objects, exploit parallelism, plus any additional DAG-preserving\ntransformations. GraphBLAS implementations exist that utilize nonblocking\nexecution but with limited scope. In this paper, we describe our work to\nimplement GraphBLAS with support for aggressive nonblocking execution. We show\nhow features of the Julia programming language greatly simplify implementation\nof nonblocking execution. This is \\emph{work-in-progress} sufficient to show\nthe potential for nonblocking execution and is limited to GraphBLAS methods\nrequired to support PageRank.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5728Julia\u8bed\u8a00\u4e2d\u5b9e\u73b0\u652f\u6301\u79ef\u6781\u975e\u963b\u585e\u6267\u884c\u7684GraphBLAS\uff0c\u5c55\u793a\u8be5\u8bed\u8a00\u7b80\u5316\u5b9e\u73b0\u7684\u7279\u6027\uff0c\u5de5\u4f5c\u5904\u4e8e\u8fdb\u884c\u4e2d\uff0c\u76ee\u524d\u9650\u4e8e\u652f\u6301PageRank\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709GraphBLAS\u975e\u963b\u585e\u6267\u884c\u5b9e\u73b0\u8303\u56f4\u6709\u9650\uff0c\u9700\u5b9e\u73b0\u652f\u6301\u79ef\u6781\u975e\u963b\u585e\u6267\u884c\u7684GraphBLAS\u3002", "method": "\u5229\u7528Julia\u7f16\u7a0b\u8bed\u8a00\u7684\u7279\u6027\u6765\u5b9e\u73b0\u975e\u963b\u585e\u6267\u884c\u3002", "result": "\u5c55\u793a\u4e86Julia\u8bed\u8a00\u7279\u6027\u53ef\u6781\u5927\u7b80\u5316\u975e\u963b\u585e\u6267\u884c\u7684\u5b9e\u73b0\u3002", "conclusion": "\u5f53\u524d\u5de5\u4f5c\u867d\u4e3a\u8fdb\u884c\u4e2d\uff0c\u4f46\u663e\u793a\u4e86\u975e\u963b\u585e\u6267\u884c\u7684\u6f5c\u529b\uff0c\u76ee\u524d\u5c40\u9650\u4e8e\u652f\u6301PageRank\u7684GraphBLAS\u65b9\u6cd5\u3002"}}
{"id": "2509.13389", "pdf": "https://arxiv.org/pdf/2509.13389", "abs": "https://arxiv.org/abs/2509.13389", "authors": ["Carlos N\u00fa\u00f1ez-Molina", "Vicen\u00e7 G\u00f3mez", "Hector Geffner"], "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.8"], "comment": "10 pages, 3 figures", "summary": "We consider the problem of learning propositional STRIPS world models from\naction traces alone, using a deep learning architecture (transformers) and\ngradient descent. The task is cast as a supervised next token prediction\nproblem where the tokens are the actions, and an action $a$ may follow an\naction sequence if the hidden effects of the previous actions do not make an\naction precondition of $a$ false. We show that a suitable transformer\narchitecture can faithfully represent propositional STRIPS world models, and\nthat the models can be learned from sets of random valid (positive) and invalid\n(negative) action sequences alone. A number of experiments are reported.", "AI": {"tldr": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff08transformers\uff09\u548c\u68af\u5ea6\u4e0b\u964d\u4ece\u52a8\u4f5c\u8f68\u8ff9\u5b66\u4e60\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u4ec5\u4ece\u52a8\u4f5c\u8f68\u8ff9\u5b66\u4e60\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\u7684\u95ee\u9898\u3002", "method": "\u5c06\u4efb\u52a1\u8f6c\u5316\u4e3a\u76d1\u7763\u5f0f\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u95ee\u9898\uff0c\u5229\u7528\u5408\u9002\u7684transformer\u67b6\u6784\uff0c\u901a\u8fc7\u968f\u673a\u6709\u6548\u548c\u65e0\u6548\u52a8\u4f5c\u5e8f\u5217\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u5408\u9002\u7684transformer\u67b6\u6784\u80fd\u5fe0\u5b9e\u8868\u793a\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u4e14\u53ef\u4ece\u52a8\u4f5c\u5e8f\u5217\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5229\u7528transformer\u67b6\u6784\u4ece\u52a8\u4f5c\u8f68\u8ff9\u5b66\u4e60\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.13896", "pdf": "https://arxiv.org/pdf/2509.13896", "abs": "https://arxiv.org/abs/2509.13896", "authors": ["Shalini Chakraborty", "Lola Burgue\u00f1o", "Nathalie Moreno", "Javier Troya", "Paula Mu\u00f1oz"], "title": "Mind the Ethics! The Overlooked Ethical Dimensions of GenAI in Software Modeling Education", "categories": ["cs.SE"], "comment": "8 pages, Educators Symposium at MODELS 2025", "summary": "Generative Artificial Intelligence (GenAI) is rapidly gaining momentum in\nsoftware modeling education, embraced by both students and educators. As GenAI\nassists with interpreting requirements, formalizing models, and translating\nstudents' mental models into structured notations, it increasingly shapes core\nlearning outcomes such as domain comprehension, diagrammatic thinking, and\nmodeling fluency without clear ethical oversight or pedagogical guidelines.\nYet, the ethical implications of this integration remain underexplored.\n  In this paper, we conduct a systematic literature review across six major\ndigital libraries in computer science (ACM Digital Library, IEEE Xplore,\nScopus, ScienceDirect, SpringerLink, and Web of Science). Our aim is to\nidentify studies discussing the ethical aspects of GenAI in software modeling\neducation, including responsibility, fairness, transparency, diversity, and\ninclusion among others.\n  Out of 1,386 unique papers initially retrieved, only three explicitly\naddressed ethical considerations. This scarcity highlights the critical absence\nof ethical discourse surrounding GenAI in modeling education and raises urgent\nquestions about the responsible integration of AI in modeling curricula, as\nwell as it evinces the pressing need for structured ethical frameworks in this\nemerging educational landscape. We examine these three studies and explore the\nemerging research opportunities as well as the challenges that have arisen in\nthis field.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51faGenAI\u5728\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2d\u5e94\u7528\u589e\u591a\u4f46\u4f26\u7406\u95ee\u9898\u7814\u7a76\u4e0d\u8db3\uff0c\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u53d1\u73b0\u76f8\u5173\u4f26\u7406\u7814\u7a76\u7a00\u7f3a\uff0c\u9700\u6784\u5efa\u4f26\u7406\u6846\u67b6\u3002", "motivation": "GenAI\u5728\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2d\u5e94\u7528\u5e7f\u6cdb\u4f46\u7f3a\u4e4f\u4f26\u7406\u76d1\u7763\u548c\u6559\u5b66\u6307\u5bfc\uff0c\u5176\u4f26\u7406\u5f71\u54cd\u672a\u5145\u5206\u63a2\u7d22\uff0c\u56e0\u6b64\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u516d\u5927\u6570\u5b57\u56fe\u4e66\u9986\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u8bc6\u522b\u8ba8\u8bbaGenAI\u4f26\u7406\u65b9\u9762\u7684\u7814\u7a76\u3002", "result": "\u6700\u521d\u68c0\u7d22\u52301386\u7bc7\u8bba\u6587\uff0c\u4ec53\u7bc7\u660e\u786e\u63d0\u53ca\u4f26\u7406\u8003\u91cf\uff0c\u51f8\u663e\u8be5\u9886\u57df\u4f26\u7406\u7814\u7a76\u7a00\u7f3a\u3002", "conclusion": "\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2dGenAI\u4f26\u7406\u8ba8\u8bba\u7f3a\u5931\uff0c\u8feb\u5207\u9700\u8981\u6784\u5efa\u7ed3\u6784\u5316\u4f26\u7406\u6846\u67b6\uff0c\u540c\u65f6\u63a2\u8ba8\u4e86\u7814\u7a76\u673a\u4f1a\u548c\u6311\u6218\u3002"}}
{"id": "2509.13450", "pdf": "https://arxiv.org/pdf/2509.13450", "abs": "https://arxiv.org/abs/2509.13450", "authors": ["Vincent Siu", "Nicholas Crispino", "David Park", "Nathan W. Henry", "Zhun Wang", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce SteeringControl, a benchmark for evaluating representation\nsteering methods across core alignment objectives--bias, harmful generation,\nand hallucination--and their effects on secondary behaviors such as sycophancy\nand commonsense morality. While prior alignment work often highlights\ntruthfulness or reasoning ability to demonstrate the side effects of\nrepresentation steering, we find there are many unexplored tradeoffs not yet\nunderstood in a systematic way. We collect a dataset of safety-relevant primary\nand secondary behaviors to evaluate steering effectiveness and behavioral\nentanglement centered around five popular steering methods. To enable this, we\ncraft a modular steering framework based on unique components that serve as the\nbuilding blocks of many existing methods. Our results on Qwen-2.5-7B and\nLlama-3.1-8B find that strong steering performance is dependent on the specific\ncombination of steering method, model, and targeted behavior, and that severe\nconcept entanglement can result from poor combinations of these three as well.\nWe release our code here:\nhttps://github.com/wang-research-lab/SteeringControl.git.", "AI": {"tldr": "\u4ecb\u7ecdSteeringControl\u57fa\u51c6\uff0c\u8bc4\u4f30\u8868\u5f81\u5f15\u5bfc\u65b9\u6cd5\uff0c\u53d1\u73b0\u672a\u7cfb\u7edf\u63a2\u7d22\u7684\u6743\u8861\uff0c\u6536\u96c6\u6570\u636e\u96c6\uff0c\u6784\u5efa\u6846\u67b6\uff0c\u5f97\u51fa\u5f15\u5bfc\u6027\u80fd\u4f9d\u8d56\u7ec4\u5408\u7684\u7ed3\u8bba\u5e76\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u5de5\u4f5c\u5bf9\u8868\u5f81\u5f15\u5bfc\u65b9\u6cd5\u7684\u526f\u4f5c\u7528\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\uff0c\u5b58\u5728\u8bb8\u591a\u672a\u63a2\u7d22\u7684\u6743\u8861\u3002", "method": "\u6536\u96c6\u5b89\u5168\u76f8\u5173\u7684\u4e3b\u8981\u548c\u6b21\u8981\u884c\u4e3a\u6570\u636e\u96c6\uff0c\u56f4\u7ed5\u4e94\u79cd\u6d41\u884c\u5f15\u5bfc\u65b9\u6cd5\u8bc4\u4f30\u5f15\u5bfc\u6548\u679c\u548c\u884c\u4e3a\u7ea0\u7f20\uff0c\u6784\u5efa\u6a21\u5757\u5316\u5f15\u5bfc\u6846\u67b6\u3002", "result": "\u5728Qwen - 2.5 - 7B\u548cLlama - 3.1 - 8B\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5f3a\u5f15\u5bfc\u6027\u80fd\u4f9d\u8d56\u4e8e\u5f15\u5bfc\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u884c\u4e3a\u7684\u7279\u5b9a\u7ec4\u5408\uff0c\u4e0d\u826f\u7ec4\u5408\u4f1a\u5bfc\u81f4\u4e25\u91cd\u6982\u5ff5\u7ea0\u7f20\u3002", "conclusion": "\u8868\u5f81\u5f15\u5bfc\u65b9\u6cd5\u7684\u6027\u80fd\u53d7\u591a\u79cd\u56e0\u7d20\u7ec4\u5408\u5f71\u54cd\uff0c\u4e0d\u540c\u7ec4\u5408\u4f1a\u5e26\u6765\u4e0d\u540c\u7ed3\u679c\u3002"}}
{"id": "2509.13941", "pdf": "https://arxiv.org/pdf/2509.13941", "abs": "https://arxiv.org/abs/2509.13941", "authors": ["Simiao Liu", "Fang Liu", "Liehao Li", "Xin Tan", "Yinghao Zhu", "Xiaoli Lian", "Li Zhang"], "title": "An Empirical Study on Failures in Automated Issue Solving", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Automated issue solving seeks to autonomously identify and repair defective\ncode snippets across an entire codebase. SWE-Bench has emerged as the most\nwidely adopted benchmark for evaluating progress in this area. While LLM-based\nagentic tools show great promise, they still fail on a substantial portion of\ntasks. Moreover, current evaluations primarily report aggregate issue-solving\nrates, which obscure the underlying causes of success and failure, making it\nchallenging to diagnose model weaknesses or guide targeted improvements. To\nbridge this gap, we first analyze the performance and efficiency of three SOTA\ntools, spanning both pipeline-based and agentic architectures, in automated\nissue solving tasks of SWE-Bench-Verified under varying task characteristics.\nFurthermore, to move from high-level performance metrics to underlying cause\nanalysis, we conducted a systematic manual analysis of 150 failed instances.\nFrom this analysis, we developed a comprehensive taxonomy of failure modes\ncomprising 3 primary phases, 9 main categories, and 25 fine-grained\nsubcategories. Then we systematically analyze the distribution of the\nidentified failure modes, the results reveal distinct failure fingerprints\nbetween the two architectural paradigms, with the majority of agentic failures\nstemming from flawed reasoning and cognitive deadlocks. Motivated by these\ninsights, we propose a collaborative Expert-Executor framework. It introduces a\nsupervisory Expert agent tasked with providing strategic oversight and\ncourse-correction for a primary Executor agent. This architecture is designed\nto correct flawed reasoning and break the cognitive deadlocks that frequently\nlead to failure. Experiments show that our framework solves 22.2% of previously\nintractable issues for a leading single agent. These findings pave the way for\nbuilding more robust agents through diagnostic evaluation and collaborative\ndesign.", "AI": {"tldr": "\u5206\u6790SOTA\u5de5\u5177\u5728SWE - Bench\u81ea\u52a8\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5bf9\u5931\u8d25\u5b9e\u4f8b\u624b\u52a8\u5206\u6790\u5efa\u7acb\u5206\u7c7b\u6cd5\uff0c\u53d1\u73b0\u4e0d\u540c\u67b6\u6784\u5931\u8d25\u7279\u70b9\uff0c\u63d0\u51faExpert - Executor\u6846\u67b6\u89e3\u51b3\u90e8\u5206\u96be\u9898\u3002", "motivation": "\u73b0\u6709LLM - based\u5de5\u5177\u5728\u81ea\u52a8\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u6709\u5931\u8d25\u60c5\u51b5\uff0c\u4e14\u5f53\u524d\u8bc4\u4f30\u4e3b\u8981\u662f\u6574\u4f53\u89e3\u51b3\u7387\uff0c\u96be\u4ee5\u8bca\u65ad\u6a21\u578b\u5f31\u70b9\u548c\u6307\u5bfc\u6539\u8fdb\u3002", "method": "\u5206\u6790\u4e09\u79cdSOTA\u5de5\u5177\u5728SWE - Bench - Verified\u81ea\u52a8\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u7684\u8868\u73b0\u548c\u6548\u7387\uff1b\u624b\u52a8\u5206\u6790150\u4e2a\u5931\u8d25\u5b9e\u4f8b\u5efa\u7acb\u5931\u8d25\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff1b\u63d0\u51faExpert - Executor\u6846\u67b6\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u67b6\u6784\u6709\u4e0d\u540c\u5931\u8d25\u7279\u70b9\uff0c\u591a\u6570\u4ee3\u7406\u5931\u8d25\u6e90\u4e8e\u63a8\u7406\u7f3a\u9677\u548c\u8ba4\u77e5\u50f5\u5c40\uff1b\u6846\u67b6\u89e3\u51b3\u4e86\u9886\u5148\u5355\u4ee3\u740622.2%\u5148\u524d\u96be\u89e3\u51b3\u7684\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u8bca\u65ad\u8bc4\u4f30\u548c\u534f\u4f5c\u8bbe\u8ba1\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u4ee3\u7406\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2509.13651", "pdf": "https://arxiv.org/pdf/2509.13651", "abs": "https://arxiv.org/abs/2509.13651", "authors": ["Yongkang Du", "Jieyu Zhao", "Yijun Yang", "Tianyi Zhou"], "title": "Controllable Pareto Trade-off between Fairness and Accuracy", "categories": ["cs.LG"], "comment": null, "summary": "The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work\nfocuses on finding a single \"optimal\" solution to balance the two objectives,\nwhich is limited considering the diverse solutions on the Pareto front. This\nwork intends to provide controllable trade-offs according to the user's\npreference of the two objectives, which is defined as a reference vector. To\nachieve this goal, we apply multi-objective optimization (MOO), which can find\nsolutions from various regions of the Pareto front. However, it is challenging\nto precisely control the trade-off due to the stochasticity of the training\nprocess and the high dimentional gradient vectors. Thus, we propose\nControllable Pareto Trade-off (CPT) that can effectively train models to\nperform different trade-offs according to users' preferences. CPT 1) stabilizes\nthe fairness update with a moving average of stochastic gradients to determine\nthe update direction, and 2) prunes the gradients by only keeping the gradients\nof the critical parameters. We evaluate CPT on hate speech detection and\noccupation classification tasks. Experiments show that CPT can achieve a\nhigher-quality set of solutions on the Pareto front than the baseline methods.\nIt also exhibits better controllability and can precisely follow the\nhuman-defined reference vectors.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9NLP\u4efb\u52a1\u4e2d\u516c\u5e73\u6027 - \u51c6\u786e\u6027\u6743\u8861\u95ee\u9898\uff0c\u63d0\u51faCPT\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u5728\u5e15\u7d2f\u6258\u524d\u6cbf\u83b7\u5f97\u9ad8\u8d28\u91cf\u89e3\uff0c\u4e14\u53ef\u63a7\u6027\u66f4\u597d\u3002", "motivation": "\u5f53\u524d\u5de5\u4f5c\u5728\u89e3\u51b3NLP\u4efb\u52a1\u4e2d\u516c\u5e73\u6027\u4e0e\u51c6\u786e\u6027\u6743\u8861\u65f6\uff0c\u4ec5\u5173\u6ce8\u5355\u4e00'\u6700\u4f18'\u89e3\uff0c\u672a\u8003\u8651\u5e15\u7d2f\u6258\u524d\u6cbf\u7684\u591a\u6837\u89e3\uff0c\u672c\u6587\u65e8\u5728\u6839\u636e\u7528\u6237\u504f\u597d\u63d0\u4f9b\u53ef\u63a7\u6743\u8861\u3002", "method": "\u5e94\u7528\u591a\u76ee\u6807\u4f18\u5316\uff08MOO\uff09\uff0c\u63d0\u51fa\u53ef\u63a7\u5e15\u7d2f\u6258\u6743\u8861\uff08CPT\uff09\u65b9\u6cd5\uff0c\u5305\u62ec\u7528\u968f\u673a\u68af\u5ea6\u79fb\u52a8\u5e73\u5747\u7a33\u5b9a\u516c\u5e73\u6027\u66f4\u65b0\u3001\u4fee\u526a\u68af\u5ea6\u4fdd\u7559\u5173\u952e\u53c2\u6570\u68af\u5ea6\u3002", "result": "\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u548c\u804c\u4e1a\u5206\u7c7b\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0cCPT\u5728\u5e15\u7d2f\u6258\u524d\u6cbf\u83b7\u5f97\u7684\u89e3\u8d28\u91cf\u9ad8\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u53ef\u63a7\u6027\u66f4\u597d\uff0c\u80fd\u7cbe\u786e\u9075\u5faa\u4eba\u4e3a\u5b9a\u4e49\u7684\u53c2\u8003\u5411\u91cf\u3002", "conclusion": "CPT\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3NLP\u4efb\u52a1\u4e2d\u516c\u5e73\u6027 - \u51c6\u786e\u6027\u7684\u53ef\u63a7\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2509.13547", "pdf": "https://arxiv.org/pdf/2509.13547", "abs": "https://arxiv.org/abs/2509.13547", "authors": ["Harper Reed", "Michael Sugimura", "Angelo Zangari"], "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "categories": ["cs.AI", "cs.HC"], "comment": "16 pages, 5 tables", "summary": "We investigate whether giving LLM agents the collaborative tools and autonomy\nthat humans naturally use for problem solving can improve their performance. We\nequip Claude Code agents with MCP-based social media and journaling tools and\nallow them to use these tools as they see fit. Across 34 Aider Polyglot Python\nprogramming challenges, collaborative tools substantially improve performance\non the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and\n12-38% faster completion than baseline agents. Effects on the full challenge\nset are mixed, suggesting these tools act as performance enhancers when\nadditional reasoning scaffolding is most needed. Surprisingly, Different models\nnaturally adopted distinct collaborative strategies without explicit\ninstruction. Sonnet 3.7 engaged broadly across tools and benefited from\narticulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,\nleaning on journal-based semantic search when problems were genuinely\ndifficult. This mirrors how human developers adjust collaboration based on\nexpertise and task complexity. Behavioral analysis shows agents prefer writing\nover reading by about 2-9x, indicating that structured articulation drives much\nof the improvement rather than information access alone. Overall, AI agents can\nsystematically benefit from human-inspired collaboration tools at the edge of\ntheir capabilities, pointing to adaptive collaborative interfaces as reasoning\nenhancers rather than universal efficiency boosts.", "AI": {"tldr": "\u7814\u7a76\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u914d\u5907\u4eba\u7c7b\u95ee\u9898\u89e3\u51b3\u5de5\u5177\u80fd\u5426\u63d0\u5347\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u5de5\u5177\u5bf9\u96be\u9898\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e0d\u540c\u6a21\u578b\u91c7\u7528\u4e0d\u540c\u534f\u4f5c\u7b56\u7565\uff0c\u7ed3\u6784\u5316\u8868\u8fbe\u662f\u63d0\u5347\u4e3b\u56e0\uff0c\u5de5\u5177\u662f\u63a8\u7406\u589e\u5f3a\u800c\u975e\u901a\u7528\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u63a2\u7a76\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u914d\u5907\u4eba\u7c7b\u89e3\u51b3\u95ee\u9898\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6027\u80fd\u5426\u63d0\u5347\u5176\u6027\u80fd\u3002", "method": "\u4e3aClaude Code\u4ee3\u7406\u914d\u5907\u57fa\u4e8eMCP\u7684\u793e\u4ea4\u5a92\u4f53\u548c\u65e5\u5fd7\u5de5\u5177\uff0c\u8ba9\u5176\u81ea\u4e3b\u4f7f\u7528\uff0c\u8fdb\u884c34\u4e2aAider Polyglot Python\u7f16\u7a0b\u6311\u6218\u5b9e\u9a8c\u3002", "result": "\u534f\u4f5c\u5de5\u5177\u5bf9\u96be\u9898\u6027\u80fd\u63d0\u5347\u663e\u8457\uff0c\u4e0d\u540c\u6a21\u578b\u81ea\u7136\u91c7\u7528\u4e0d\u540c\u534f\u4f5c\u7b56\u7565\uff0c\u4ee3\u7406\u5199\u4f5c\u504f\u597d\u9ad8\u4e8e\u9605\u8bfb\u7ea62 - 9\u500d\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u80fd\u4ece\u7c7b\u4eba\u534f\u4f5c\u5de5\u5177\u4e2d\u7cfb\u7edf\u53d7\u76ca\uff0c\u534f\u4f5c\u754c\u9762\u662f\u63a8\u7406\u589e\u5f3a\u800c\u975e\u901a\u7528\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2509.13942", "pdf": "https://arxiv.org/pdf/2509.13942", "abs": "https://arxiv.org/abs/2509.13942", "authors": ["Duc Minh Ha", "Phu Trac Kien", "Tho Quan", "Anh Nguyen-Duc"], "title": "Evaluating Classical Software Process Models as Coordination Mechanisms for LLM-Based Software Generation", "categories": ["cs.SE"], "comment": null, "summary": "[Background] Large Language Model (LLM)-based multi-agent systems (MAS) are\ntransforming software development by enabling autonomous collaboration.\nClassical software processes such asWaterfall, V-Model, and Agile offer\nstructured coordination patterns that can be repurposed to guide these agent\ninteractions. [Aims] This study explores how traditional software development\nprocesses can be adapted as coordination scaffolds for LLM based MAS and\nexamines their impact on code quality, cost, and productivity. [Method] We\nexecuted 11 diverse software projects under three process models and four GPT\nvariants, totaling 132 runs. Each output was evaluated using standardized\nmetrics for size (files, LOC), cost (execution time, token usage), and quality\n(code smells, AI- and human detected bugs). [Results] Both process model and\nLLM choice significantly affected system performance. Waterfall was most\nefficient, V-Model produced the most verbose code, and Agile achieved the\nhighest code quality, albeit at higher computational cost. [Conclusions]\nClassical software processes can be effectively instantiated in LLM-based MAS,\nbut each entails trade-offs across quality, cost, and adaptability. Process\nselection should reflect project goals, whether prioritizing efficiency,\nrobustness, or structured validation.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u9002\u914d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65b9\u5f0f\u53ca\u5f71\u54cd\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5f97\u51fa\u4e0d\u540c\u6d41\u7a0b\u5404\u6709\u4f18\u52a3\uff0c\u9009\u62e9\u5e94\u4f9d\u9879\u76ee\u76ee\u6807\u800c\u5b9a\u3002", "motivation": "\u63a2\u7d22\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u5982\u4f55\u4f5c\u4e3a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u8c03\u6846\u67b6\uff0c\u5e76\u7814\u7a76\u5176\u5bf9\u4ee3\u7801\u8d28\u91cf\u3001\u6210\u672c\u548c\u751f\u4ea7\u529b\u7684\u5f71\u54cd\u3002", "method": "\u5728\u4e09\u79cd\u6d41\u7a0b\u6a21\u578b\u548c\u56db\u79cdGPT\u53d8\u4f53\u4e0b\u6267\u884c11\u4e2a\u4e0d\u540c\u7684\u8f6f\u4ef6\u9879\u76ee\uff0c\u5171132\u6b21\u8fd0\u884c\uff0c\u7528\u6807\u51c6\u5316\u6307\u6807\u8bc4\u4f30\u8f93\u51fa\u3002", "result": "\u6d41\u7a0b\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u90fd\u663e\u8457\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\uff0c\u7011\u5e03\u6a21\u578b\u6700\u6709\u6548\u7387\uff0cV\u6a21\u578b\u4ee3\u7801\u6700\u5197\u957f\uff0c\u654f\u6377\u6a21\u578b\u4ee3\u7801\u8d28\u91cf\u6700\u9ad8\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "conclusion": "\u4f20\u7edf\u8f6f\u4ef6\u6d41\u7a0b\u53ef\u6709\u6548\u5e94\u7528\u4e8e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f46\u5404\u6709\u8d28\u91cf\u3001\u6210\u672c\u548c\u9002\u5e94\u6027\u7684\u6743\u8861\uff0c\u6d41\u7a0b\u9009\u62e9\u5e94\u53cd\u6620\u9879\u76ee\u76ee\u6807\u3002"}}
{"id": "2509.13686", "pdf": "https://arxiv.org/pdf/2509.13686", "abs": "https://arxiv.org/abs/2509.13686", "authors": ["Bingsheng Peng", "Shutao Zhang", "Xi Zheng", "Ye Xue", "Xinyu Qin", "Tsung-Hui Chang"], "title": "RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Accurate localized wireless channel modeling is a cornerstone of cellular\nnetwork optimization, enabling reliable prediction of network performance\nduring parameter tuning. Localized statistical channel modeling (LSCM) is the\nstate-of-the-art channel modeling framework tailored for cellular network\noptimization. However, traditional LSCM methods, which infer the channel's\nAngular Power Spectrum (APS) from Reference Signal Received Power (RSRP)\nmeasurements, suffer from critical limitations: they are typically confined to\nsingle-cell, single-grid and single-carrier frequency analysis and fail to\ncapture complex cross-domain interactions. To overcome these challenges, we\npropose RF-LSCM, a novel framework that models the channel APS by jointly\nrepresenting large-scale signal attenuation and multipath components within a\nradiance field. RF-LSCM introduces a multi-domain LSCM formulation with a\nphysics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the\ncross frequency generalization as well as a point-cloud-aided environment\nenhanced method to enable multi-cell and multi-grid channel modeling.\nFurthermore, to address the computational inefficiency of typical neural\nradiance fields, RF-LSCM leverages a low-rank tensor representation,\ncomplemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.\nThis efficient design significantly reduces GPU memory requirements and\ntraining time while preserving fine-grained accuracy. Extensive experiments on\nreal-world multi-cell datasets demonstrate that RF-LSCM significantly\noutperforms state-of-the-art methods, achieving up to a 30% reduction in mean\nabsolute error (MAE) for coverage prediction and a 22% MAE improvement by\neffectively fusing multi-frequency data.", "AI": {"tldr": "\u63d0\u51faRF - LSCM\u6846\u67b6\u7528\u4e8e\u65e0\u7ebf\u4fe1\u9053\u5efa\u6a21\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5c40\u9650\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfLSCM\u65b9\u6cd5\u5728\u5355\u5c0f\u533a\u3001\u5355\u7f51\u683c\u3001\u5355\u8f7d\u6ce2\u9891\u7387\u5206\u6790\u53ca\u6355\u6349\u8de8\u57df\u4ea4\u4e92\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51faRF - LSCM\u6846\u67b6\uff0c\u5f15\u5165\u591a\u57dfLSCM\u516c\u5f0f\u3001FDAM\u6a21\u578b\u3001\u70b9\u4e91\u8f85\u52a9\u73af\u5883\u589e\u5f3a\u65b9\u6cd5\uff0c\u5229\u7528\u4f4e\u79e9\u5f20\u91cf\u8868\u793a\u548cHiTAM\u7b97\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u591a\u5c0f\u533a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cRF - LSCM\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8986\u76d6\u9884\u6d4bMAE\u6700\u591a\u964d30%\uff0c\u878d\u5408\u591a\u9891\u6570\u636eMAE\u63d0\u534722%\u3002", "conclusion": "RF - LSCM\u80fd\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5c40\u9650\uff0c\u63d0\u5347\u65e0\u7ebf\u4fe1\u9053\u5efa\u6a21\u6027\u80fd\u3002"}}
{"id": "2509.13570", "pdf": "https://arxiv.org/pdf/2509.13570", "abs": "https://arxiv.org/abs/2509.13570", "authors": ["Hannah Klawa", "Shraddha Rajpal", "Cigole Thomas"], "title": "Gen AI in Proof-based Math Courses: A Pilot Study", "categories": ["cs.AI", "math.HO", "Primary: 97U50, Secondary: 97U70, 97D40, 97D60, 97E50, 97H40"], "comment": "35 pages, 6 figures, Comments welcome!", "summary": "With the rapid rise of generative AI in higher education and the\nunreliability of current AI detection tools, developing policies that encourage\nstudent learning and critical thinking has become increasingly important. This\nstudy examines student use and perceptions of generative AI across three\nproof-based undergraduate mathematics courses: a first-semester abstract\nalgebra course, a topology course and a second-semester abstract algebra\ncourse. In each case, course policy permitted some use of generative AI.\nDrawing on survey responses and student interviews, we analyze how students\nengaged with AI tools, their perceptions of generative AI's usefulness and\nlimitations, and what implications these perceptions hold for teaching\nproof-based mathematics. We conclude by discussing future considerations for\nintegrating generative AI into proof-based mathematics instruction.", "AI": {"tldr": "\u7814\u7a76\u5728\u4e09\u95e8\u672c\u79d1\u6570\u5b66\u8bc1\u660e\u8bfe\u7a0b\u4e2d\uff0c\u5b66\u751f\u5bf9\u751f\u6210\u5f0fAI\u7684\u4f7f\u7528\u548c\u770b\u6cd5\uff0c\u63a2\u8ba8\u5176\u5bf9\u6559\u5b66\u7684\u5f71\u54cd\u5e76\u8ba8\u8bba\u672a\u6765\u6559\u5b66\u6574\u5408\u7684\u8003\u8651\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u5feb\u901f\u5174\u8d77\u4e14\u5f53\u524d\u68c0\u6d4b\u5de5\u5177\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u5236\u5b9a\u9f13\u52b1\u5b66\u751f\u5b66\u4e60\u548c\u6279\u5224\u6027\u601d\u7ef4\u7684\u653f\u7b56\u3002", "method": "\u5728\u4e09\u95e8\u5141\u8bb8\u4e00\u5b9a\u4f7f\u7528\u751f\u6210\u5f0fAI\u7684\u8bfe\u7a0b\u4e2d\uff0c\u57fa\u4e8e\u8c03\u67e5\u56de\u590d\u548c\u5b66\u751f\u8bbf\u8c08\uff0c\u5206\u6790\u5b66\u751f\u4e0eAI\u5de5\u5177\u7684\u4e92\u52a8\u3001\u5bf9\u5176\u6709\u7528\u6027\u548c\u5c40\u9650\u6027\u7684\u770b\u6cd5\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5c06\u751f\u6210\u5f0fAI\u6574\u5408\u5230\u57fa\u4e8e\u8bc1\u660e\u7684\u6570\u5b66\u6559\u5b66\u4e2d\u7684\u672a\u6765\u8003\u8651\u3002"}}
{"id": "2509.14093", "pdf": "https://arxiv.org/pdf/2509.14093", "abs": "https://arxiv.org/abs/2509.14093", "authors": ["Kerui Huang", "Shuhan Liu", "Xing Hu", "Tongtong Xu", "Lingfeng Bao", "Xin Xia"], "title": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by\nprompting intermediate steps, improving accuracy and robustness in arithmetic,\nlogic, and commonsense tasks. However, this benefit comes with high\ncomputational costs: longer outputs increase latency, memory usage, and\nKV-cache demands. These issues are especially critical in software engineering\ntasks where concise and deterministic outputs are required. To investigate\nthese trade-offs, we conduct an empirical study based on code generation\nbenchmarks. The results reveal that longer CoT does not always help. Excessive\nreasoning often causes truncation, accuracy drops, and latency up to five times\nhigher, with failed outputs consistently longer than successful ones. These\nfindings challenge the assumption that longer reasoning is inherently better\nand highlight the need for adaptive CoT control. Motivated by this, we propose\nSEER (Self-Enhancing Efficient Reasoning), an adaptive framework that\ncompresses CoT while preserving accuracy. SEER combines Best-of-N sampling with\ntask-aware adaptive filtering, dynamically adjusting thresholds based on\npre-inference outputs to reduce verbosity and computational overhead. We then\nevaluate SEER on three software engineering tasks and one math task. On\naverage, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,\nand eliminates most infinite loops. These results demonstrate SEER as a\npractical method to make CoT-enhanced LLMs more efficient and robust, even\nunder resource constraints.", "AI": {"tldr": "\u7814\u7a76\u601d\u7ef4\u94fe\u63a8\u7406\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u51faSEER\u6846\u67b6\u538b\u7f29\u601d\u7ef4\u94fe\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u601d\u7ef4\u94fe\u63a8\u7406\u867d\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u6709\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u95ee\u9898\u7a81\u51fa\uff0c\u9700\u6743\u8861\u5229\u5f0a\u3002", "method": "\u57fa\u4e8e\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51faSEER\u6846\u67b6\uff0c\u7ed3\u5408Best - of - N\u91c7\u6837\u4e0e\u4efb\u52a1\u611f\u77e5\u81ea\u9002\u5e94\u8fc7\u6ee4\u52a8\u6001\u8c03\u6574\u9608\u503c\u3002", "result": "SEER\u5e73\u5747\u7f29\u77ed\u601d\u7ef4\u94fe42.1%\uff0c\u51cf\u5c11\u622a\u65ad\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u6d88\u9664\u591a\u6570\u65e0\u9650\u5faa\u73af\u3002", "conclusion": "SEER\u662f\u4f7f\u601d\u7ef4\u94fe\u589e\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u4e0b\u66f4\u9ad8\u6548\u3001\u66f4\u5065\u58ee\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2509.13717", "pdf": "https://arxiv.org/pdf/2509.13717", "abs": "https://arxiv.org/abs/2509.13717", "authors": ["Yifan Yu", "Cheuk Hin Ho", "Yangshuai Wang"], "title": "A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving PDEs, yet existing uncertainty quantification (UQ) approaches for\nPINNs generally lack rigorous statistical guarantees. In this work, we bridge\nthis gap by introducing a distribution-free conformal prediction (CP) framework\nfor UQ in PINNs. This framework calibrates prediction intervals by constructing\nnonconformity scores on a calibration set, thereby yielding distribution-free\nuncertainty estimates with rigorous finite-sample coverage guarantees for\nPINNs. To handle spatial heteroskedasticity, we further introduce local\nconformal quantile estimation, enabling spatially adaptive uncertainty bands\nwhile preserving theoretical guarantee. Through systematic evaluations on\ntypical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz\nequations) and comprehensive testing across multiple uncertainty metrics, our\nresults demonstrate that the proposed framework achieves reliable calibration\nand locally adaptive uncertainty intervals, consistently outperforming\nheuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work\nintroduces a general framework that not only enhances calibration and\nreliability, but also opens new avenues for uncertainty-aware modeling of\ncomplex PDE systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8ePINNs\u4e2dUQ\u7684\u65e0\u5206\u5e03\u5171\u5f62\u9884\u6d4b\u6846\u67b6\uff0c\u7ecf\u8bc4\u4f30\u8868\u73b0\u4f18\u4e8e\u542f\u53d1\u5f0fUQ\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u6821\u51c6\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709PINNs\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u65b9\u6cd5\u7f3a\u4e4f\u4e25\u683c\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5f15\u5165\u65e0\u5206\u5e03\u5171\u5f62\u9884\u6d4b\uff08CP\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6821\u51c6\u96c6\u4e0a\u6784\u5efa\u975e\u4e00\u81f4\u6027\u5206\u6570\u6821\u51c6\u9884\u6d4b\u533a\u95f4\uff1b\u5f15\u5165\u5c40\u90e8\u5171\u5f62\u5206\u4f4d\u6570\u4f30\u8ba1\u5904\u7406\u7a7a\u95f4\u5f02\u65b9\u5dee\u6027\u3002", "result": "\u5728\u5178\u578bPDEs\u4e0a\u7684\u7cfb\u7edf\u8bc4\u4f30\u548c\u591a\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u53ef\u9760\u6821\u51c6\u548c\u5c40\u90e8\u81ea\u9002\u5e94\u4e0d\u786e\u5b9a\u6027\u533a\u95f4\uff0c\u4f18\u4e8e\u542f\u53d1\u5f0fUQ\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06PINNs\u4e0e\u65e0\u5206\u5e03UQ\u7ed3\u5408\uff0c\u4e0d\u4ec5\u589e\u5f3a\u6821\u51c6\u548c\u53ef\u9760\u6027\uff0c\u8fd8\u4e3a\u590d\u6742PDE\u7cfb\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5efa\u6a21\u5f00\u8f9f\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.13429", "pdf": "https://arxiv.org/pdf/2509.13429", "abs": "https://arxiv.org/abs/2509.13429", "authors": ["Anthony Arnold", "Mark Marron"], "title": "Catalpa: GC for a Low-Variance Software Stack", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "The performance of an application/runtime is usually conceptualized as a\ncontinuous function where, the lower the amount of memory/time used on a given\nworkload, then the better the compiler/runtime is. However, in practice, good\nperformance of an application is viewed as more of a binary function - either\nthe application responds in under, say 100 ms, and is fast enough for a user to\nbarely notice, or it takes a noticeable amount of time, leaving the user\nwaiting and potentially abandoning the task. Thus, performance really means how\noften the application is fast enough to be usable, leading industrial\ndevelopers to focus on the 95th and 99th percentile tail-latencies as heavily,\nor moreso, than average response time. Our vision is to create a software stack\nthat actively supports these needs via programming language and runtime system\ndesign. In this paper we present a novel garbage-collector design, the Catalpa\ncollector, for the Bosque programming language and runtime. This allocator is\ndesigned to minimize latency and variability while maintaining high-throughput\nand incurring small memory overheads. To achieve these goals we leverage\nvarious features of the Bosque language, including immutability and\nreference-cycle freedom, to construct a collector that has bounded collection\npauses, incurs fixed-constant memory overheads, and does not require any\nbarriers or synchronization with application code.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8eBosque\u8bed\u8a00\u548c\u8fd0\u884c\u65f6\u7684Catalpa\u5783\u573e\u6536\u96c6\u5668\u8bbe\u8ba1\uff0c\u5229\u7528\u8bed\u8a00\u7279\u6027\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u548c\u5c0f\u5185\u5b58\u5f00\u9500\u3002", "motivation": "\u5b9e\u9645\u5e94\u7528\u4e2d\u6027\u80fd\u591a\u4e3a\u4e8c\u5143\u51fd\u6570\uff0c\u5f00\u53d1\u8005\u5173\u6ce8\u5c3e\u5ef6\u8fdf\uff0c\u9700\u8f6f\u4ef6\u6808\u6ee1\u8db3\u6b64\u9700\u6c42\u3002", "method": "\u5229\u7528Bosque\u8bed\u8a00\u7684\u4e0d\u53ef\u53d8\u6027\u548c\u65e0\u5f15\u7528\u5faa\u73af\u7b49\u7279\u6027\uff0c\u8bbe\u8ba1Catalpa\u6536\u96c6\u5668\u3002", "result": "\u8bbe\u8ba1\u51fa\u7684\u6536\u96c6\u5668\u6709\u6709\u754c\u6536\u96c6\u6682\u505c\u3001\u56fa\u5b9a\u5185\u5b58\u5f00\u9500\uff0c\u65e0\u9700\u4e0e\u5e94\u7528\u4ee3\u7801\u8fdb\u884c\u5c4f\u969c\u6216\u540c\u6b65\u3002", "conclusion": "Catalpa\u6536\u96c6\u5668\u80fd\u6700\u5c0f\u5316\u5ef6\u8fdf\u548c\u53ef\u53d8\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u548c\u5c0f\u5185\u5b58\u5f00\u9500\u3002"}}
{"id": "2509.13725", "pdf": "https://arxiv.org/pdf/2509.13725", "abs": "https://arxiv.org/abs/2509.13725", "authors": ["Md Sabbir Ahmed", "Noah French", "Mark Rucker", "Zhiyuan Wang", "Taylor Myers-Brower", "Kaitlyn Petz", "Mehdi Boukhechba", "Bethany A. Teachman", "Laura E. Barnes"], "title": "WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Social anxiety is a common mental health condition linked to significant\nchallenges in academic, social, and occupational functioning. A core feature is\nelevated momentary (state) anxiety in social situations, yet little prior work\nhas measured or predicted fluctuations in this anxiety throughout the day.\nCapturing these intra-day dynamics is critical for designing real-time,\npersonalized interventions such as Just-In-Time Adaptive Interventions\n(JITAIs). To address this gap, we conducted a study with socially anxious\ncollege students (N=91; 72 after exclusions) using our custom smartwatch-based\nsystem over an average of 9.03 days (SD = 2.95). Participants received seven\necological momentary assessments (EMAs) per day to report state anxiety. We\ndeveloped a base model on over 10,000 days of external heart rate data,\ntransferred its representations to our dataset, and fine-tuned it to generate\nprobabilistic predictions. These were combined with trait-level measures in a\nmeta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety\ndetection in our dataset. To evaluate generalizability, we applied the training\napproach to a separate hold-out set from the TILES-18 dataset-the same dataset\nused for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%\nbalanced accuracy, outperforming prior work by at least 7%.", "AI": {"tldr": "\u7814\u7a76\u7528\u667a\u80fd\u624b\u8868\u7cfb\u7edf\u5bf9\u793e\u4ea4\u7126\u8651\u5927\u5b66\u751f\u8fdb\u884c\u7814\u7a76\uff0c\u5f00\u53d1\u6a21\u578b\u9884\u6d4b\u72b6\u6001\u7126\u8651\uff0c\u5728\u81ea\u6709\u6570\u636e\u96c6\u548c\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u4e0d\u9519\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\u3002", "motivation": "\u793e\u4ea4\u7126\u8651\u5728\u793e\u4ea4\u60c5\u5883\u4e2d\u4f1a\u6709\u72b6\u6001\u7126\u8651\u6ce2\u52a8\uff0c\u4f46\u6b64\u524d\u5c11\u6709\u7814\u7a76\u6d4b\u91cf\u6216\u9884\u6d4b\u5176\u5168\u5929\u6ce2\u52a8\uff0c\u4e3a\u8bbe\u8ba1\u5b9e\u65f6\u4e2a\u6027\u5316\u5e72\u9884\u63aa\u65bd\uff0c\u9700\u6355\u6349\u8fd9\u4e9b\u65e5\u5185\u52a8\u6001\u3002", "method": "\u7528\u5b9a\u5236\u667a\u80fd\u624b\u8868\u7cfb\u7edf\u5bf9\u793e\u4ea4\u7126\u8651\u5927\u5b66\u751f\u8fdb\u884c\u7814\u7a76\uff0c\u6bcf\u65e5\u8fdb\u884c\u4e03\u6b21\u751f\u6001\u77ac\u65f6\u8bc4\u4f30\uff0c\u5f00\u53d1\u57fa\u4e8e\u5916\u90e8\u5fc3\u7387\u6570\u636e\u7684\u57fa\u7840\u6a21\u578b\uff0c\u8fc1\u79fb\u5176\u8868\u5f81\u5e76\u5fae\u8c03\uff0c\u7ed3\u5408\u7279\u8d28\u6c34\u5e73\u6d4b\u91cf\u5728\u5143\u5b66\u4e60\u5668\u4e2d\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u81ea\u6709\u6570\u636e\u96c6\u4e0a\u72b6\u6001\u7126\u8651\u68c0\u6d4b\u7684\u5e73\u8861\u51c6\u786e\u7387\u8fbe60.4%\uff0c\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u8fbe59.1%\uff0c\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\u81f3\u5c117%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u9884\u6d4b\u793e\u4ea4\u7126\u8651\u5927\u5b66\u751f\u7684\u72b6\u6001\u7126\u8651\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.13615", "pdf": "https://arxiv.org/pdf/2509.13615", "abs": "https://arxiv.org/abs/2509.13615", "authors": ["Zongru Wu", "Rui Mao", "Zhiyuan Tian", "Pengzhou Cheng", "Tianjie Ju", "Zheng Wu", "Lingzhong Dong", "Haiyue Sheng", "Zhuosheng Zhang", "Gongshen Liu"], "title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "The advent of multimodal agents facilitates effective interaction within\ngraphical user interface (GUI), especially in ubiquitous GUI control. However,\ntheir inability to reliably execute toggle control instructions remains a key\nbottleneck. To investigate this, we construct a state control benchmark with\nbinary toggle instructions from public datasets. Evaluations of existing agents\ndemonstrate their unreliability, particularly when the current toggle state\nalready matches the desired state. To address the challenge, we propose\nState-aware Reasoning (StaR), a training method that teaches agents to perceive\nthe current toggle state, analyze the desired state from the instruction, and\nact accordingly. Experiments on three multimodal agents demonstrate that StaR\ncan improve toggle instruction execution accuracy by over 30\\%. Further\nevaluations on three public benchmarks show that StaR also enhances general\ntask performance. Finally, evaluations on a dynamic environment highlight the\npotential of StaR for real-world applications. Code, benchmark, and\nStaR-enhanced agents are available at https://github.com/ZrW00/StaR.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u72b6\u6001\u63a7\u5236\u57fa\u51c6\u8bc4\u4f30\u73b0\u6709\u591a\u6a21\u6001\u4ee3\u7406\u5728\u5207\u6362\u63a7\u5236\u6307\u4ee4\u6267\u884c\u4e0a\u7684\u4e0d\u53ef\u9760\u6027\uff0c\u63d0\u51faStaR\u8bad\u7ec3\u65b9\u6cd5\u63d0\u5347\u6267\u884c\u51c6\u786e\u6027\u548c\u901a\u7528\u4efb\u52a1\u6027\u80fd\uff0c\u8fd8\u5c55\u793a\u5176\u5728\u73b0\u5b9e\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u591a\u6a21\u6001\u4ee3\u7406\u5728GUI\u63a7\u5236\u4e2d\u65e0\u6cd5\u53ef\u9760\u6267\u884c\u5207\u6362\u63a7\u5236\u6307\u4ee4\uff0c\u8fd9\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "\u6784\u5efa\u72b6\u6001\u63a7\u5236\u57fa\u51c6\u8bc4\u4f30\u73b0\u6709\u4ee3\u7406\uff0c\u63d0\u51faState - aware Reasoning (StaR)\u8bad\u7ec3\u65b9\u6cd5\uff0c\u8ba9\u4ee3\u7406\u611f\u77e5\u5f53\u524d\u5207\u6362\u72b6\u6001\u3001\u5206\u6790\u6307\u4ee4\u4e2d\u671f\u671b\u72b6\u6001\u5e76\u91c7\u53d6\u76f8\u5e94\u884c\u52a8\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u4ee3\u7406\u4e0a\u5b9e\u9a8c\u8868\u660eStaR\u80fd\u5c06\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u7387\u63d0\u9ad8\u8d8530%\uff0c\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u901a\u7528\u4efb\u52a1\u6027\u80fd\uff0c\u5728\u52a8\u6001\u73af\u5883\u8bc4\u4f30\u663e\u793a\u5176\u73b0\u5b9e\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "StaR\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u4ee3\u7406\u5728\u5207\u6362\u63a7\u5236\u6307\u4ee4\u6267\u884c\u4e0a\u7684\u51c6\u786e\u6027\u548c\u901a\u7528\u4efb\u52a1\u6027\u80fd\uff0c\u6709\u73b0\u5b9e\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.13699", "pdf": "https://arxiv.org/pdf/2509.13699", "abs": "https://arxiv.org/abs/2509.13699", "authors": ["Max Barth", "Marie-Christine Jakobs"], "title": "Multi-Threaded Software Model Checking via Parallel Trace Abstraction Refinement", "categories": ["cs.LO", "cs.PL", "cs.SE"], "comment": null, "summary": "Automatic software verification is a valuable means for software quality\nassurance. However, automatic verification and in particular software model\nchecking can be time-consuming, which hinders their practical applicability\ne.g., the use in continuous integration. One solution to address the issue is\nto reduce the response time of the verification procedure by leveraging today's\nmulti-core CPUs.\n  In this paper, we propose a solution to parallelize trace abstraction, an\nabstraction-based approach to software model checking. The underlying idea of\nour approach is to parallelize the abstraction refinement. More concretely, our\napproach analyzes different traces (syntactic program paths) that could violate\nthe safety property in parallel. We realize our parallelized version of trace\nabstraction in the verification tool Ulti mate Automizer and perform a thorough\nevaluation. Our evaluation shows that our parallelization is more effective\nthan sequential trace abstraction and can provide results significantly faster\non many time-consuming tasks. Also, our approach is more effective than DSS, a\nrecent parallel approach to abstraction-based software model checking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u884c\u5316\u8ddf\u8e2a\u62bd\u8c61\u7684\u89e3\u51b3\u65b9\u6848\u4ee5\u52a0\u901f\u8f6f\u4ef6\u6a21\u578b\u68c0\u67e5\uff0c\u8bc4\u4f30\u663e\u793a\u8be5\u5e76\u884c\u5316\u6bd4\u987a\u5e8f\u8ddf\u8e2a\u62bd\u8c61\u548cDSS\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "motivation": "\u81ea\u52a8\u8f6f\u4ef6\u9a8c\u8bc1\u8017\u65f6\u957f\uff0c\u963b\u788d\u5b9e\u9645\u5e94\u7528\uff0c\u9700\u5229\u7528\u591a\u6838CPU\u51cf\u5c11\u9a8c\u8bc1\u54cd\u5e94\u65f6\u95f4\u3002", "method": "\u5e76\u884c\u5316\u8ddf\u8e2a\u62bd\u8c61\uff0c\u5e76\u884c\u5206\u6790\u53ef\u80fd\u8fdd\u53cd\u5b89\u5168\u5c5e\u6027\u7684\u4e0d\u540c\u8ddf\u8e2a\uff0c\u5728\u9a8c\u8bc1\u5de5\u5177Ultimate Automizer\u4e2d\u5b9e\u73b0\u3002", "result": "\u5e76\u884c\u5316\u6bd4\u987a\u5e8f\u8ddf\u8e2a\u62bd\u8c61\u66f4\u6709\u6548\uff0c\u5728\u8bb8\u591a\u8017\u65f6\u4efb\u52a1\u4e0a\u80fd\u66f4\u5feb\u7ed9\u51fa\u7ed3\u679c\uff0c\u4e5f\u6bd4DSS\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5e76\u884c\u5316\u8ddf\u8e2a\u62bd\u8c61\u89e3\u51b3\u65b9\u6848\u80fd\u6709\u6548\u52a0\u901f\u8f6f\u4ef6\u6a21\u578b\u68c0\u67e5\u3002"}}
{"id": "2509.13735", "pdf": "https://arxiv.org/pdf/2509.13735", "abs": "https://arxiv.org/abs/2509.13735", "authors": ["Junzhi She", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "State Space Models over Directed Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "currently undergoing review by IEEE Transactions on Big Data", "summary": "Directed graphs are ubiquitous across numerous domains, where the\ndirectionality of edges encodes critical causal dependencies. However, existing\nGNNs and graph Transformers tailored for directed graphs face two major\nchallenges: (1) effectively capturing long-range causal dependencies derived\nfrom directed edges; (2) balancing accuracy and training efficiency when\nprocessing large-scale graph datasets. In recent years, state space models\n(SSMs) have achieved substantial progress in causal sequence tasks, and their\nvariants designed for graphs have demonstrated state-of-the-art accuracy while\nmaintaining high efficiency across various graph learning benchmarks. However,\nexisting graph state space models are exclusively designed for undirected\ngraphs, which limits their performance in directed graph learning. To this end,\nwe propose an innovative approach DirEgo2Token which sequentializes directed\ngraphs via k-hop ego graphs. This marks the first systematic extension of state\nspace models to the field of directed graph learning. Building upon this, we\ndevelop DirGraphSSM, a novel directed graph neural network architecture that\nimplements state space models on directed graphs via the message-passing\nmechanism. Experimental results demonstrate that DirGraphSSM achieves\nstate-of-the-art performance on three representative directed graph learning\ntasks while attaining competitive performance on two additional tasks with\n1.5$\\times $ to 2$\\times $ training speed improvements compared to existing\nstate-of-the-art models.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faDirEgo2Token\u548cDirGraphSSM\uff0c\u89e3\u51b3\u6709\u5411\u56fe\u5b66\u4e60\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u73b0\u826f\u597d\u4e14\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6709\u5411\u56feGNN\u548c\u56feTransformer\u9762\u4e34\u6355\u83b7\u957f\u8ddd\u79bb\u56e0\u679c\u4f9d\u8d56\u548c\u5e73\u8861\u7cbe\u5ea6\u4e0e\u6548\u7387\u7684\u6311\u6218\uff0c\u73b0\u6709\u56fe\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4ec5\u9002\u7528\u4e8e\u65e0\u5411\u56fe\u3002", "method": "\u63d0\u51faDirEgo2Token\u5c06\u6709\u5411\u56fe\u901a\u8fc7k\u8df3\u81ea\u6211\u56fe\u5e8f\u5217\u5316\uff0c\u5f00\u53d1DirGraphSSM\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u673a\u5236\u5728\u6709\u5411\u56fe\u4e0a\u5b9e\u73b0\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002", "result": "DirGraphSSM\u5728\u4e09\u4e2a\u6709\u5411\u56fe\u5b66\u4e60\u4efb\u52a1\u4e0a\u8fbe\u6700\u4f18\uff0c\u5728\u53e6\u5916\u4e24\u4e2a\u4efb\u52a1\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u53471.5 - 2\u500d\u3002", "conclusion": "\u5c06\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7cfb\u7edf\u6269\u5c55\u5230\u6709\u5411\u56fe\u5b66\u4e60\u9886\u57df\uff0c\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u4e14\u9ad8\u6548\u3002"}}
{"id": "2509.13704", "pdf": "https://arxiv.org/pdf/2509.13704", "abs": "https://arxiv.org/abs/2509.13704", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.", "AI": {"tldr": "\u73b0\u6709\u5de5\u4e1a\u7ba1\u7406\u81ea\u52a8\u5316\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u63d0\u51faInfraMind\u6846\u67b6\u89e3\u51b3\u76f8\u5173\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u5de5\u4e1a\u7ba1\u7406\u8f6f\u4ef6\u64cd\u4f5c\u56e0\u7cfb\u7edf\u590d\u6742\u3001\u591a\u4f9b\u5e94\u5546\u96c6\u6210\u548c\u4e13\u5bb6\u64cd\u4f5c\u5458\u77ed\u7f3a\u9762\u4e34\u6311\u6218\uff0cRPA\u7075\u6d3b\u6027\u6709\u9650\u3001\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u901a\u7528GUI\u4ee3\u7406\u5e94\u7528\u4e8e\u5de5\u4e1a\u7ba1\u7406\u6709\u4e94\u5927\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51faInfraMind\u6846\u67b6\uff0c\u96c6\u6210\u4e94\u4e2a\u521b\u65b0\u6a21\u5757\uff0c\u5305\u62ec\u57fa\u4e8e\u7cfb\u7edf\u641c\u7d22\u7684\u63a2\u7d22\u3001\u5185\u5b58\u9a71\u52a8\u89c4\u5212\u3001\u5148\u8fdb\u72b6\u6001\u8bc6\u522b\u3001\u7ed3\u6784\u5316\u77e5\u8bc6\u84b8\u998f\u548c\u591a\u5c42\u5b89\u5168\u673a\u5236\u3002", "result": "\u5728\u5f00\u6e90\u548c\u5546\u4e1aDCIM\u5e73\u53f0\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cInfraMind\u5728\u4efb\u52a1\u6210\u529f\u7387\u548c\u8fd0\u8425\u6548\u7387\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "conclusion": "InfraMind\u4e3a\u5de5\u4e1a\u7ba1\u7406\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u4e25\u8c28\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13761", "pdf": "https://arxiv.org/pdf/2509.13761", "abs": "https://arxiv.org/abs/2509.13761", "authors": ["Qikai Chang", "Zhenrong Zhang", "Pengfei Hu", "Jiefeng Ma", "Yicheng Pan", "Jianshu Zhang", "Jun Du", "Quan Liu", "Jianqing Gao"], "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "22 pages, 13 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u7cbe\u5ea6\u6570\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u63d0\u51faTHOR\u65b9\u6cd5\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u7cbe\u5ea6\u6570\u5b66\u4efb\u52a1\u4e0a\u7684\u4e0d\u8db3\uff0c\u4ee5\u53ca\u73b0\u6709\u5de5\u5177\u96c6\u6210\u65b9\u6cd5\u5728\u6784\u5efa\u6570\u636e\u3001\u4f18\u5316\u548c\u63a8\u7406\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faTHOR\u65b9\u6cd5\uff0c\u5305\u62ec\u7528TIRGen\u6784\u5efa\u6570\u636e\u96c6\u3001\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u5c42\u4f18\u5316\u3001\u5f15\u5165\u81ea\u6211\u4fee\u6b63\u673a\u5236\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u6709\u5f3a\u6cdb\u5316\u6027\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\uff0c\u5728\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "THOR\u662f\u4e00\u79cd\u6709\u6548\u7684\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u548c\u8ba1\u7b97\u80fd\u529b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.13753", "pdf": "https://arxiv.org/pdf/2509.13753", "abs": "https://arxiv.org/abs/2509.13753", "authors": ["Hyotaek Jeon", "Hyunwook Lee", "Juwon Kim", "Sungahn Ko"], "title": "ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting", "categories": ["cs.LG"], "comment": "11 pages, 4 figures, Accepted to CIKM 2025. Code:\n  https://github.com/HyoTaek98/ST_LINK", "summary": "Traffic forecasting represents a crucial problem within intelligent\ntransportation systems. In recent research, Large Language Models (LLMs) have\nemerged as a promising method, but their intrinsic design, tailored primarily\nfor sequential token processing, introduces notable challenges in effectively\ncapturing spatial dependencies. Specifically, the inherent limitations of LLMs\nin modeling spatial relationships and their architectural incompatibility with\ngraph-structured spatial data remain largely unaddressed. To overcome these\nlimitations, we introduce ST-LINK, a novel framework that enhances the\ncapability of Large Language Models to capture spatio-temporal dependencies.\nIts key components are Spatially-Enhanced Attention (SE-Attention) and the\nMemory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary\nposition embeddings to integrate spatial correlations as direct rotational\ntransformations within the attention mechanism. This approach maximizes spatial\nlearning while preserving the LLM's inherent sequential processing structure.\nMeanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to\ncapture complex temporal dependencies and improve the stability of long-term\nforecasting. Comprehensive experiments on benchmark datasets demonstrate that\nST-LINK surpasses conventional deep learning and LLM approaches, and\neffectively captures both regular traffic patterns and abrupt changes.", "AI": {"tldr": "\u63d0\u51faST - LINK\u6846\u67b6\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u6355\u83b7\u65f6\u7a7a\u4f9d\u8d56\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6355\u83b7\u7a7a\u95f4\u4f9d\u8d56\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u5efa\u6a21\u7a7a\u95f4\u5173\u7cfb\u6709\u5c40\u9650\u4e14\u4e0e\u56fe\u7ed3\u6784\u7a7a\u95f4\u6570\u636e\u4e0d\u517c\u5bb9\u3002", "method": "\u5f15\u5165ST - LINK\u6846\u67b6\uff0c\u5305\u542bSpatially - Enhanced Attention\uff08SE - Attention\uff09\u548cMemory Retrieval Feed - Forward Network\uff08MRFFN\uff09\u3002SE - Attention\u6269\u5c55\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff0cMRFFN\u52a8\u6001\u68c0\u7d22\u5229\u7528\u5386\u53f2\u6a21\u5f0f\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u663e\u793a\uff0cST - LINK\u8d85\u8d8a\u4e86\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u548cLLM\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u6355\u83b7\u5e38\u89c4\u4ea4\u901a\u6a21\u5f0f\u548c\u7a81\u53d1\u53d8\u5316\u3002", "conclusion": "ST - LINK\u6846\u67b6\u80fd\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u6355\u83b7\u65f6\u7a7a\u4f9d\u8d56\u7684\u80fd\u529b\uff0c\u53ef\u7528\u4e8e\u4ea4\u901a\u9884\u6d4b\u3002"}}
{"id": "2509.13763", "pdf": "https://arxiv.org/pdf/2509.13763", "abs": "https://arxiv.org/abs/2509.13763", "authors": ["Zongxin Shen", "Yanyong Huang", "Bin Wang", "Jinyuan Chang", "Shiyu Liu", "Tianrui Li"], "title": "Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning", "categories": ["cs.LG"], "comment": null, "summary": "Multi-view unsupervised feature selection (MUFS) has recently received\nincreasing attention for its promising ability in dimensionality reduction on\nmulti-view unlabeled data. Existing MUFS methods typically select\ndiscriminative features by capturing correlations between features and\nclustering labels. However, an important yet underexplored question remains:\n\\textit{Are such correlations sufficiently reliable to guide feature\nselection?} In this paper, we analyze MUFS from a causal perspective by\nintroducing a novel structural causal model, which reveals that existing\nmethods may select irrelevant features because they overlook spurious\ncorrelations caused by confounders. Building on this causal perspective, we\npropose a novel MUFS method called CAusal multi-view Unsupervised feature\nSelection leArning (CAUSA). Specifically, we first employ a generalized\nunsupervised spectral regression model that identifies informative features by\ncapturing dependencies between features and consensus clustering labels. We\nthen introduce a causal regularization module that can adaptively separate\nconfounders from multi-view data and simultaneously learn view-shared sample\nweights to balance confounder distributions, thereby mitigating spurious\ncorrelations. Thereafter, integrating both into a unified learning framework\nenables CAUSA to select causally informative features. Comprehensive\nexperiments demonstrate that CAUSA outperforms several state-of-the-art\nmethods. To our knowledge, this is the first in-depth study of causal\nmulti-view feature selection in the unsupervised setting.", "AI": {"tldr": "\u6587\u7ae0\u4ece\u56e0\u679c\u89c6\u89d2\u5206\u6790\u591a\u89c6\u56fe\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\uff08MUFS\uff09\uff0c\u63d0\u51faCAUSA\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u662f\u65e0\u76d1\u7763\u4e0b\u56e0\u679c\u591a\u89c6\u56fe\u7279\u5f81\u9009\u62e9\u7684\u9996\u6b21\u6df1\u5165\u7814\u7a76\u3002", "motivation": "\u73b0\u6709MUFS\u65b9\u6cd5\u901a\u8fc7\u7279\u5f81\u4e0e\u805a\u7c7b\u6807\u7b7e\u7684\u76f8\u5173\u6027\u9009\u62e9\u7279\u5f81\uff0c\u9700\u63a2\u7a76\u8fd9\u79cd\u76f8\u5173\u6027\u662f\u5426\u8db3\u4ee5\u6307\u5bfc\u7279\u5f81\u9009\u62e9\u3002", "method": "\u5f15\u5165\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5206\u6790\u95ee\u9898\uff0c\u63d0\u51faCAUSA\u65b9\u6cd5\uff0c\u5148\u4f7f\u7528\u5e7f\u4e49\u65e0\u76d1\u7763\u8c31\u56de\u5f52\u6a21\u578b\u8bc6\u522b\u7279\u5f81\uff0c\u518d\u5f15\u5165\u56e0\u679c\u6b63\u5219\u5316\u6a21\u5757\u5206\u79bb\u6df7\u6742\u56e0\u7d20\u3001\u5b66\u4e60\u6837\u672c\u6743\u91cd\uff0c\u6700\u540e\u6574\u5408\u5230\u7edf\u4e00\u6846\u67b6\u3002", "result": "CAUSA\u5728\u7efc\u5408\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u591a\u4e2a\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CAUSA\u80fd\u6709\u6548\u9009\u62e9\u56e0\u679c\u4fe1\u606f\u7279\u5f81\uff0c\u662f\u65e0\u76d1\u7763\u4e0b\u56e0\u679c\u591a\u89c6\u56fe\u7279\u5f81\u9009\u62e9\u7684\u9996\u6b21\u6df1\u5165\u7814\u7a76\u3002"}}
{"id": "2509.13880", "pdf": "https://arxiv.org/pdf/2509.13880", "abs": "https://arxiv.org/abs/2509.13880", "authors": ["Mingwei Zhang", "Zhenhao Gu", "Liangda Fang", "Cunjing Ge", "Ziliang Chen", "Zhao-Rong Lai", "Quanlong Guan"], "title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "categories": ["cs.AI"], "comment": null, "summary": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u7a77\u4e3eDPLL\u67b6\u6784\u7684\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u6a21\u578b\u8ba1\u6570\u7cbe\u786e\u65b9\u6cd5\uff0c\u7ed3\u5408\u7b80\u5316\u6280\u672f\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u968f\u673a\u548c\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u6a21\u578b\u8ba1\u6570\uff08MCILC\uff09\u5728\u591a\u4e2a\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u9700\u8bbe\u8ba1\u6709\u6548\u7cbe\u786e\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u7a77\u4e3eDPLL\u67b6\u6784\u8bbe\u8ba1\u7cbe\u786e\u65b9\u6cd5\uff0c\u5e76\u96c6\u6210\u6df7\u5408\u6574\u6570\u89c4\u5212\u7684\u7b80\u5316\u6280\u672f\u3002", "result": "\u57282840\u4e2a\u968f\u673a\u548c4131\u4e2a\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u968f\u673a\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cbe\u786e\u65b9\u6cd5\uff0c\u4e14\u662f\u552f\u4e00\u80fd\u89e3\u51b3\u6240\u67094131\u4e2a\u5e94\u7528\u5b9e\u4f8b\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6240\u8bbe\u8ba1\u7684\u65b9\u6cd5\u5728\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u6a21\u578b\u8ba1\u6570\u4e0a\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2509.13783", "pdf": "https://arxiv.org/pdf/2509.13783", "abs": "https://arxiv.org/abs/2509.13783", "authors": ["Tianshuo Zhang", "Wenzhe Zhai", "Rui Yann", "Jia Gao", "He Cao", "Xianglei Xing"], "title": "Floating-Body Hydrodynamic Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Fluid-structure interaction is common in engineering and natural systems,\nwhere floating-body motion is governed by added mass, drag, and background\nflows. Modeling these dissipative dynamics is difficult: black-box neural\nmodels regress state derivatives with limited interpretability and unstable\nlong-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks\n(FHNN), a physics-structured framework that predicts interpretable hydrodynamic\nparameters such as directional added masses, drag coefficients, and a\nstreamfunction-based flow, and couples them with analytic equations of motion.\nThis design constrains the hypothesis space, enhances interpretability, and\nstabilizes integration. On synthetic vortex datasets, FHNN achieves up to an\norder-of-magnitude lower error than Neural ODEs, recovers physically consistent\nflow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN\nmore effectively handles dissipative dynamics while preserving\ninterpretability, which bridges the gap between black-box learning and\ntransparent system identification.", "AI": {"tldr": "\u63d0\u51faFloating - Body Hydrodynamic Neural Networks (FHNN)\u6846\u67b6\uff0c\u80fd\u9884\u6d4b\u53ef\u89e3\u91ca\u7684\u6c34\u52a8\u529b\u53c2\u6570\uff0c\u5728\u5408\u6210\u6da1\u65cb\u6570\u636e\u96c6\u4e0a\u6bd4Neural ODEs\u8bef\u5dee\u4f4e\uff0c\u6bd4Hamiltonian\u548cLagrangian\u795e\u7ecf\u7f51\u7edc\u66f4\u6709\u6548\u5904\u7406\u8017\u6563\u52a8\u529b\u5b66\u3002", "motivation": "\u73b0\u6709\u9ed1\u76d2\u795e\u7ecf\u6a21\u578b\u5728\u5bf9\u6d6e\u4f53\u8fd0\u52a8\u7684\u8017\u6563\u52a8\u529b\u5b66\u5efa\u6a21\u65f6\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u6709\u9650\u548c\u957f\u65f6\u9884\u6d4b\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faFHNN\u6846\u67b6\uff0c\u9884\u6d4b\u53ef\u89e3\u91ca\u7684\u6c34\u52a8\u529b\u53c2\u6570\u5e76\u4e0e\u89e3\u6790\u8fd0\u52a8\u65b9\u7a0b\u8026\u5408\u3002", "result": "\u5728\u5408\u6210\u6da1\u65cb\u6570\u636e\u96c6\u4e0a\uff0cFHNN\u6bd4Neural ODEs\u8bef\u5dee\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u6062\u590d\u7269\u7406\u4e0a\u4e00\u81f4\u7684\u6d41\u573a\uff1b\u6bd4Hamiltonian\u548cLagrangian\u795e\u7ecf\u7f51\u7edc\u66f4\u6709\u6548\u5904\u7406\u8017\u6563\u52a8\u529b\u5b66\u3002", "conclusion": "FHNN\u6846\u67b6\u7f29\u5c0f\u4e86\u9ed1\u76d2\u5b66\u4e60\u548c\u900f\u660e\u7cfb\u7edf\u8bc6\u522b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.13968", "pdf": "https://arxiv.org/pdf/2509.13968", "abs": "https://arxiv.org/abs/2509.13968", "authors": ["Konstantinos Voudouris", "Andrew Barron", "Marta Halina", "Colin Klein", "Matishalin Patel"], "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.LG"], "comment": null, "summary": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.", "AI": {"tldr": "\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u8bc4\u4f30\u7f51\u7edc\u4fe1\u606f\u6d41\u53d8\u5316\u5bf9\u8ba4\u77e5\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5faa\u73af\u7f51\u7edc\u6709\u4f18\u52bf\uff0c\u90e8\u5206\u62d3\u6251\u53d8\u5316\u65e0\u4f18\u52bf", "motivation": "\u8bc4\u4f30\u7f51\u7edc\u4fe1\u606f\u6d41\u53d8\u5316\u80fd\u5426\u5bfc\u81f4\u8ba4\u77e5\u8868\u73b0\u7684\u8fc7\u6e21\u6027\u53d8\u5316", "method": "\u4f7f\u7528\u7406\u60f3\u5316\u4fe1\u606f\u6d41\u6a21\u578b\u548c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u6bd4\u8f83\u524d\u9988\u3001\u5faa\u73af\u548c\u5c42\u53e0\u62d3\u6251\u7f51\u7edc\u5728\u5b66\u4e60\u4e0d\u540c\u590d\u6742\u5ea6\u4eba\u5de5\u8bed\u6cd5\u7684\u8868\u73b0", "result": "\u5faa\u73af\u7f51\u7edc\u76f8\u6bd4\u524d\u9988\u7f51\u7edc\u80fd\u5904\u7406\u66f4\u591a\u7c7b\u578b\u8f93\u5165\uff0c\u5b66\u4e60\u590d\u6742\u8bed\u6cd5\u8868\u73b0\u66f4\u597d\uff1b\u8bad\u7ec3\u5faa\u73af\u7f51\u7edc\u6709\u56f0\u96be\uff1b\u5c42\u53e0\u7f51\u7edc\u5728\u8bed\u6cd5\u5b66\u4e60\u4e2d\u672a\u8d85\u8d8a\u975e\u5c42\u53e0\u7f51\u7edc", "conclusion": "\u4e00\u4e9b\u4fe1\u606f\u6d41\u53d8\u5316\u80fd\u5e26\u6765\u8ba4\u77e5\u8868\u73b0\u7684\u8fc7\u6e21\u6027\u53d8\u5316"}}
{"id": "2509.14030", "pdf": "https://arxiv.org/pdf/2509.14030", "abs": "https://arxiv.org/abs/2509.14030", "authors": ["Maosheng Qin", "Renyu Zhu", "Mingxuan Xia", "Chenkai Chen", "Zhen Zhu", "Minmin Lin", "Junbo Zhao", "Lu Xu", "Changjie Fan", "Runze Wu", "Haobo Wang"], "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "categories": ["cs.AI"], "comment": null, "summary": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cfb\u7edfCrowdAgent\uff0c\u53ef\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6807\u6ce8\u8fc7\u7a0b\u8fdb\u884c\u7aef\u5230\u7aef\u63a7\u5236\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5229\u7528\u4e0d\u540c\u6807\u6ce8\u6e90\u65f6\u7f3a\u4e4f\u5bf9\u6807\u6ce8\u8fc7\u7a0b\u7684\u6574\u4f53\u63a7\u5236\uff0c\u672a\u7edf\u4e00\u89e3\u51b3\u8c03\u5ea6\u548c\u8d28\u91cf\u6210\u672c\u6743\u8861\u95ee\u9898\u3002", "method": "\u5f15\u5165\u591a\u667a\u80fd\u4f53\u7cfb\u7edfCrowdAgent\uff0c\u96c6\u6210\u4efb\u52a1\u5206\u914d\u3001\u6570\u636e\u6807\u6ce8\u548c\u8d28\u91cf/\u6210\u672c\u7ba1\u7406\uff0c\u5408\u7406\u5206\u914d\u4efb\u52a1\u4f7f\u4e0d\u540c\u6807\u6ce8\u6e90\u534f\u540c\u5de5\u4f5c\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u7684\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86CrowdAgent\u7684\u6709\u6548\u6027\u3002", "conclusion": "CrowdAgent\u80fd\u6709\u6548\u5b9e\u73b0\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6807\u6ce8\u8fc7\u7a0b\u7684\u7aef\u5230\u7aef\u63a7\u5236\u3002"}}
{"id": "2509.13818", "pdf": "https://arxiv.org/pdf/2509.13818", "abs": "https://arxiv.org/abs/2509.13818", "authors": ["Zheng-an Wang", "Yanbo J. Wang", "Jiachi Zhang", "Qi Xu", "Yilun Zhao", "Jintao Li", "Yipeng Zhang", "Bo Yang", "Xinkai Gao", "Xiaofeng Cao", "Kai Xu", "Pengpeng Hao", "Xuan Yang", "Heng Fan"], "title": "Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Quantum Machine Learning (QML) offers a new paradigm for addressing complex\nfinancial problems intractable for classical methods. This work specifically\ntackles the challenge of few-shot credit risk assessment, a critical issue in\ninclusive finance where data scarcity and imbalance limit the effectiveness of\nconventional models. To address this, we design and implement a novel hybrid\nquantum-classical workflow. The methodology first employs an ensemble of\nclassical machine learning models (Logistic Regression, Random Forest, XGBoost)\nfor intelligent feature engineering and dimensionality reduction. Subsequently,\na Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as\nthe core classifier. This framework was evaluated through numerical simulations\nand deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting\nprocessor. On a real-world credit dataset of 279 samples, our QNN achieved a\nrobust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive\nAUC of 0.88 in the hardware experiment. This performance surpasses a suite of\nclassical benchmarks, with a particularly strong result on the recall metric.\nThis study provides a pragmatic blueprint for applying quantum computing to\ndata-constrained financial scenarios in the NISQ era and offers valuable\nempirical evidence supporting its potential in high-stakes applications like\ninclusive finance.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u5c11\u6837\u672c\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u95ee\u9898\uff0c\u8bbe\u8ba1\u6df7\u5408\u91cf\u5b50 - \u7ecf\u5178\u5de5\u4f5c\u6d41\uff0c\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u4e8e\u7ecf\u5178\u6a21\u578b\u7684\u7ed3\u679c\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u5728\u91d1\u878d\u573a\u666f\u5e94\u7528\u63d0\u4f9b\u84dd\u56fe\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\u5c11\u6837\u672c\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u95ee\u9898\uff0c\u6570\u636e\u7a00\u7f3a\u548c\u4e0d\u5e73\u8861\u9650\u5236\u4f20\u7edf\u6a21\u578b\u6548\u679c\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5148\u4f7f\u7528\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u5de5\u7a0b\u548c\u964d\u7ef4\uff0c\u518d\u7528\u53c2\u6570\u8f6c\u79fb\u89c4\u5219\u8bad\u7ec3\u7684\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6838\u5fc3\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u6570\u503c\u6a21\u62df\u8bc4\u4f30\u5e76\u5728\u91cf\u5b50\u4e91\u5e73\u53f0\u5904\u7406\u5668\u4e0a\u90e8\u7f72\u3002", "result": "\u5728 279 \u4e2a\u6837\u672c\u7684\u771f\u5b9e\u4fe1\u7528\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u62df\u4e2d QNN \u5e73\u5747 AUC \u4e3a 0.852 +/- 0.027\uff0c\u786c\u4ef6\u5b9e\u9a8c AUC \u4e3a 0.88\uff0c\u8d85\u8d8a\u7ecf\u5178\u57fa\u51c6\u6a21\u578b\uff0c\u53ec\u56de\u7387\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u4e3a NISQ \u65f6\u4ee3\u91cf\u5b50\u8ba1\u7b97\u5728\u6570\u636e\u53d7\u9650\u91d1\u878d\u573a\u666f\u5e94\u7528\u63d0\u4f9b\u5b9e\u7528\u84dd\u56fe\uff0c\u8bc1\u660e\u5176\u5728\u666e\u60e0\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.14195", "pdf": "https://arxiv.org/pdf/2509.14195", "abs": "https://arxiv.org/abs/2509.14195", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "categories": ["cs.AI", "cs.LG"], "comment": "8 pages, 3 figures", "summary": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u5206\u5c42\u67b6\u6784\u9a8c\u8bc1\u4e8c\u9636\u5b66\u4e60\u4fc3\u8fdb\u5fc3\u667a\u8868\u5f81\u4e0e\u73af\u5883\u540c\u6784\u7684\u5047\u8bbe\uff0c\u5b9e\u9a8c\u8868\u660e\u4e8c\u9636\u5b66\u4e60\u5728\u5fc3\u667a\u5730\u56fe\u4e0e\u73af\u5883\u540c\u6784\u65f6\u6709\u6548\uff0c\u4e14\u5728\u8ff7\u5bab\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5fc3\u667a\u8868\u5f81\u7814\u7a76\u56f0\u96be\uff0c\u73b0\u6709\u7406\u8bba\u5047\u8bbe\u4e8c\u9636\u5b66\u4e60\u4fc3\u8fdb\u73af\u5883 - \u8ba4\u77e5\u540c\u6784\uff0c\u9700\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u5305\u542b\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u4f5c\u4e3a\u4e00\u9636\u5b66\u4e60\u5668\u548c\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u63a7\u5236\u5668\u4f5c\u4e3a\u4e8c\u9636\u5b66\u4e60\u5668\u7684\u5206\u5c42\u67b6\u6784\u3002", "result": "\u4e8c\u9636\u5b66\u4e60\u5728\u8ba4\u77e5\u7cfb\u7edf\u5f62\u6210\u4e0e\u73af\u5883\u540c\u6784\u7684\u5fc3\u667a\u5730\u56fe\u65f6\u7279\u522b\u6709\u6548\uff0c\u5728\u672a\u89c1\u8fc7\u7684\u8ff7\u5bab\u4efb\u52a1\u4e2d\u6027\u80fd\u663e\u8457\u63d0\u5347\u3001\u6cdb\u5316\u6027\u5f3a\u3002", "conclusion": "\u7ed3\u6784\u5316\u5fc3\u667a\u8868\u5f81\u5bf9\u6700\u5927\u5316\u4e8c\u9636\u5b66\u4e60\u6709\u6548\u6027\u8d77\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2509.13841", "pdf": "https://arxiv.org/pdf/2509.13841", "abs": "https://arxiv.org/abs/2509.13841", "authors": ["Qingqi Zhao", "Heng Xiao"], "title": "An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction", "categories": ["cs.LG", "physics.geo-ph"], "comment": "This preprint is also available at ESS Open Archive:\n  https://essopenarchive.org/users/960205/articles/1329010", "summary": "Accurate prediction of permeability in porous media is essential for modeling\nsubsurface flow. While pure data-driven models offer computational efficiency,\nthey often lack generalization across scales and do not incorporate explicit\nphysical constraints. Pore network models (PNMs), on the other hand, are\nphysics-based and efficient but rely on idealized geometric assumptions to\nestimate pore-scale hydraulic conductance, limiting their accuracy in complex\nstructures. To overcome these limitations, we present an end-to-end\ndifferentiable hybrid framework that embeds a graph neural network (GNN) into a\nPNM. In this framework, the analytical formulas used for conductance\ncalculations are replaced by GNN-based predictions derived from pore and throat\nfeatures. The predicted conductances are then passed to the PNM solver for\npermeability computation. In this way, the model avoids the idealized geometric\nassumptions of PNM while preserving the physics-based flow calculations. The\nGNN is trained without requiring labeled conductance data, which can number in\nthe thousands per pore network; instead, it learns conductance values by using\na single scalar permeability as the training target. This is made possible by\nbackpropagating gradients through both the GNN (via automatic differentiation)\nand the PNM solver (via a discrete adjoint method), enabling fully coupled,\nend-to-end training. The resulting model achieves high accuracy and generalizes\nwell across different scales, outperforming both pure data-driven and\ntraditional PNM approaches. Gradient-based sensitivity analysis further reveals\nphysically consistent feature influences, enhancing model interpretability.\nThis approach offers a scalable and physically informed framework for\npermeability prediction in complex porous media, reducing model uncertainty and\nimproving accuracy.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u56fe\u795e\u7ecf\u7f51\u7edc\u5d4c\u5165\u5b54\u9699\u7f51\u7edc\u6a21\u578b\u7684\u7aef\u5230\u7aef\u53ef\u5fae\u6df7\u5408\u6846\u67b6\u9884\u6d4b\u591a\u5b54\u4ecb\u8d28\u6e17\u900f\u7387\uff0c\u7cbe\u5ea6\u9ad8\u3001\u6cdb\u5316\u6027\u597d\u3002", "motivation": "\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7f3a\u4e4f\u8de8\u5c3a\u5ea6\u6cdb\u5316\u80fd\u529b\u4e14\u65e0\u660e\u786e\u7269\u7406\u7ea6\u675f\uff0c\u4f20\u7edf\u5b54\u9699\u7f51\u7edc\u6a21\u578b\u4f9d\u8d56\u7406\u60f3\u5316\u51e0\u4f55\u5047\u8bbe\uff0c\u7cbe\u5ea6\u53d7\u9650\u3002", "method": "\u6784\u5efa\u7aef\u5230\u7aef\u53ef\u5fae\u6df7\u5408\u6846\u67b6\uff0c\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u66ff\u4ee3\u5b54\u9699\u7f51\u7edc\u6a21\u578b\u4e2d\u7535\u5bfc\u8ba1\u7b97\u7684\u89e3\u6790\u516c\u5f0f\uff0c\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u548c\u79bb\u6563\u4f34\u968f\u65b9\u6cd5\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u7cbe\u5ea6\u9ad8\u3001\u8de8\u5c3a\u5ea6\u6cdb\u5316\u6027\u597d\uff0c\u4f18\u4e8e\u7eaf\u6570\u636e\u9a71\u52a8\u548c\u4f20\u7edf\u5b54\u9699\u7f51\u7edc\u6a21\u578b\u65b9\u6cd5\uff0c\u68af\u5ea6\u654f\u611f\u6027\u5206\u6790\u63ed\u793a\u7269\u7406\u4e0a\u4e00\u81f4\u7684\u7279\u5f81\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u591a\u5b54\u4ecb\u8d28\u6e17\u900f\u7387\u9884\u6d4b\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u6709\u7269\u7406\u4f9d\u636e\u7684\u6846\u67b6\uff0c\u51cf\u5c11\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u9ad8\u7cbe\u5ea6\u3002"}}
{"id": "2010.01052", "pdf": "https://arxiv.org/pdf/2010.01052", "abs": "https://arxiv.org/abs/2010.01052", "authors": ["Jaume Banus", "Maxime Sermesant", "Oscar Camara", "Marco Lorenzi"], "title": "Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The use of mechanistic models in clinical studies is limited by the lack of\nmulti-modal patients data representing different anatomical and physiological\nprocesses. For example, neuroimaging datasets do not provide a sufficient\nrepresentation of heart features for the modeling of cardiovascular factors in\nbrain disorders. To tackle this problem we introduce a probabilistic framework\nfor joint cardiac data imputation and personalisation of cardiovascular\nmechanistic models, with application to brain studies with incomplete heart\ndata. Our approach is based on a variational framework for the joint inference\nof an imputation model of cardiac information from the available features,\nalong with a Gaussian Process emulator that can faithfully reproduce\npersonalised cardiovascular dynamics. Experimental results on UK Biobank show\nthat our model allows accurate imputation of missing cardiac features in\ndatasets containing minimal heart information, e.g. systolic and diastolic\nblood pressures only, while jointly estimating the emulated parameters of the\nlumped model. This allows a novel exploration of the heart-brain joint\nrelationship through simulation of realistic cardiac dynamics corresponding to\ndifferent conditions of brain anatomy.", "AI": {"tldr": "\u63d0\u51fa\u6982\u7387\u6846\u67b6\u89e3\u51b3\u4e34\u5e8a\u7814\u7a76\u4e2d\u591a\u6a21\u6001\u60a3\u8005\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u5b9e\u73b0\u5fc3\u810f\u6570\u636e\u63d2\u8865\u548c\u5fc3\u8840\u7ba1\u673a\u5236\u6a21\u578b\u4e2a\u6027\u5316\uff0c\u5b9e\u9a8c\u8868\u660e\u6a21\u578b\u53ef\u51c6\u786e\u63d2\u8865\u7f3a\u5931\u5fc3\u810f\u7279\u5f81\u3002", "motivation": "\u4e34\u5e8a\u7814\u7a76\u4e2d\u4f7f\u7528\u673a\u5236\u6a21\u578b\u53d7\u9650\u4e8e\u7f3a\u4e4f\u4ee3\u8868\u4e0d\u540c\u89e3\u5256\u548c\u751f\u7406\u8fc7\u7a0b\u7684\u591a\u6a21\u6001\u60a3\u8005\u6570\u636e\uff0c\u5982\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u96c6\u65e0\u6cd5\u4e3a\u8111\u75be\u75c5\u5fc3\u8840\u7ba1\u56e0\u7d20\u5efa\u6a21\u63d0\u4f9b\u8db3\u591f\u5fc3\u810f\u7279\u5f81\u3002", "method": "\u5f15\u5165\u6982\u7387\u6846\u67b6\uff0c\u57fa\u4e8e\u53d8\u5206\u6846\u67b6\u8054\u5408\u63a8\u65ad\u5fc3\u810f\u4fe1\u606f\u63d2\u8865\u6a21\u578b\uff0c\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u6a21\u62df\u5668\u91cd\u73b0\u4e2a\u6027\u5316\u5fc3\u8840\u7ba1\u52a8\u529b\u5b66\u3002", "result": "\u5728UK Biobank\u5b9e\u9a8c\u4e2d\uff0c\u6a21\u578b\u80fd\u5728\u4ec5\u542b\u5c11\u91cf\u5fc3\u810f\u4fe1\u606f\u7684\u6570\u636e\u96c6\u4e2d\u51c6\u786e\u63d2\u8865\u7f3a\u5931\u5fc3\u810f\u7279\u5f81\uff0c\u540c\u65f6\u4f30\u8ba1\u96c6\u603b\u6a21\u578b\u7684\u6a21\u62df\u53c2\u6570\u3002", "conclusion": "\u8be5\u6a21\u578b\u53ef\u901a\u8fc7\u6a21\u62df\u5bf9\u5e94\u4e0d\u540c\u8111\u89e3\u5256\u6761\u4ef6\u7684\u73b0\u5b9e\u5fc3\u810f\u52a8\u529b\u5b66\uff0c\u5bf9\u5fc3\u8111\u5173\u7cfb\u8fdb\u884c\u65b0\u63a2\u7d22\u3002"}}
{"id": "2408.00208", "pdf": "https://arxiv.org/pdf/2408.00208", "abs": "https://arxiv.org/abs/2408.00208", "authors": ["SaeedReza Motamedian", "Sadra Mohaghegh", "Elham Babadi Oregani", "Mahrsa Amjadi", "Parnian Shobeiri", "Negin Cheraghi", "Niusha Solouki", "Nikoo Ahmadi", "Hossein Mohammad-Rahimi", "Yassine Bouchareb", "Arman Rahmim"], "title": "Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis", "categories": ["physics.med-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Purpose: Artificial intelligence (AI) techniques have been extensively\nutilized for diagnosing and prognosis of several diseases in recent years. This\nstudy identifies, appraises and synthesizes published studies on the use of AI\nfor the prognosis of COVID-19. Method: Electronic search was performed using\nMedline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that\nexamined machine learning or deep learning methods to determine the prognosis\nof COVID-19 using CT or chest X-ray images were included. Polled sensitivity,\nspecificity area under the curve and diagnostic odds ratio were calculated.\nResult: A total of 36 articles were included; various prognosis-related issues,\nincluding disease severity, mechanical ventilation or admission to the\nintensive care unit and mortality, were investigated. Several AI models and\narchitectures were employed, such as the Siamense model, support vector\nmachine, Random Forest , eXtreme Gradient Boosting, and convolutional neural\nnetworks. The models achieved 71%, 88% and 67% sensitivity for mortality,\nseverity assessment and need for ventilation, respectively. The specificity of\n69%, 89% and 89% were reported for the aforementioned variables. Conclusion:\nBased on the included articles, machine learning and deep learning methods used\nfor the prognosis of COVID-19 patients using radiomic features from CT or CXR\nimages can help clinicians manage patients and allocate resources more\neffectively. These studies also demonstrate that combining patient demographic,\nclinical data, laboratory tests and radiomic features improves model\nperformances.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u5229\u7528AI\u8fdb\u884cCOVID - 19\u9884\u540e\u7684\u5df2\u53d1\u8868\u7814\u7a76\u8fdb\u884c\u8bc6\u522b\u3001\u8bc4\u4f30\u548c\u7efc\u5408\uff0c\u53d1\u73b0\u4f7f\u7528CT\u6216CXR\u56fe\u50cf\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u53ef\u52a9\u4e34\u5e8a\u7ba1\u7406\u4e0e\u8d44\u6e90\u5206\u914d\uff0c\u7ed3\u5408\u591a\u7c7b\u6570\u636e\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u8bc6\u522b\u3001\u8bc4\u4f30\u548c\u7efc\u5408\u5df2\u53d1\u8868\u7684\u5173\u4e8e\u4f7f\u7528AI\u8fdb\u884cCOVID - 19\u9884\u540e\u7684\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u591a\u4e2a\u6570\u636e\u5e93\u8fdb\u884c\u7535\u5b50\u641c\u7d22\uff0c\u7eb3\u5165\u7528CT\u6216\u80f8\u90e8X\u5149\u56fe\u50cf\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6216\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5224\u65adCOVID - 19\u9884\u540e\u7684\u7814\u7a76\uff0c\u5e76\u8ba1\u7b97\u76f8\u5173\u6307\u6807\u3002", "result": "\u5171\u7eb3\u516536\u7bc7\u6587\u7ae0\uff0c\u7814\u7a76\u591a\u79cd\u9884\u540e\u76f8\u5173\u95ee\u9898\uff0c\u91c7\u7528\u591a\u79cdAI\u6a21\u578b\u548c\u67b6\u6784\uff0c\u6a21\u578b\u5bf9\u6b7b\u4ea1\u7387\u3001\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u4f30\u548c\u901a\u6c14\u9700\u6c42\u7684\u654f\u611f\u6027\u5206\u522b\u4e3a71%\u300188%\u548c67%\uff0c\u7279\u5f02\u6027\u5206\u522b\u4e3a69%\u300189%\u548c89%\u3002", "conclusion": "\u57fa\u4e8e\u7eb3\u5165\u6587\u7ae0\uff0c\u7528CT\u6216CXR\u56fe\u50cf\u7684\u653e\u5c04\u7ec4\u5b66\u7279\u5f81\u8fdb\u884cCOVID - 19\u60a3\u8005\u9884\u540e\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u53ef\u5e2e\u52a9\u4e34\u5e8a\u7ba1\u7406\u548c\u8d44\u6e90\u5206\u914d\uff0c\u7ed3\u5408\u591a\u79cd\u6570\u636e\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2509.13866", "pdf": "https://arxiv.org/pdf/2509.13866", "abs": "https://arxiv.org/abs/2509.13866", "authors": ["Sitong Chen", "Shen Nie", "Jiacheng Sun", "Zijin Feng", "Zhenguo Li", "Ji-Rong Wen", "Chongxuan Li"], "title": "Masked Diffusion Models as Energy Minimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present a systematic theoretical framework that interprets masked\ndiffusion models (MDMs) as solutions to energy minimization problems in\ndiscrete optimal transport. Specifically, we prove that three distinct energy\nformulations--kinetic, conditional kinetic, and geodesic energy--are\nmathematically equivalent under the structure of MDMs, and that MDMs minimize\nall three when the mask schedule satisfies a closed-form optimality condition.\nThis unification not only clarifies the theoretical foundations of MDMs, but\nalso motivates practical improvements in sampling. By parameterizing\ninterpolation schedules via Beta distributions, we reduce the schedule design\nspace to a tractable 2D search, enabling efficient post-training tuning without\nmodel modification. Experiments on synthetic and real-world benchmarks\ndemonstrate that our energy-inspired schedules outperform hand-crafted\nbaselines, particularly in low-step sampling settings.", "AI": {"tldr": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDMs\uff09\uff0c\u8bc1\u660e\u4e09\u79cd\u80fd\u91cf\u516c\u5f0f\u7b49\u4ef7\uff0c\u63d0\u51fa\u9ad8\u6548\u8c03\u5ea6\u65b9\u6cd5\u5e76\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6548\u679c\u597d", "motivation": "\u9610\u660eMDMs\u7406\u8bba\u57fa\u7840\u5e76\u63a8\u52a8\u91c7\u6837\u5b9e\u8df5\u6539\u8fdb", "method": "\u8bc1\u660e\u4e09\u79cd\u80fd\u91cf\u516c\u5f0f\u5728MDMs\u7ed3\u6784\u4e0b\u6570\u5b66\u7b49\u4ef7\uff0c\u7528Beta\u5206\u5e03\u53c2\u6570\u5316\u63d2\u503c\u8c03\u5ea6\uff0c\u5c06\u8c03\u5ea6\u8bbe\u8ba1\u7a7a\u95f4\u7f29\u51cf\u4e3a\u4e8c\u7ef4\u641c\u7d22", "result": "\u80fd\u91cf\u542f\u53d1\u5f0f\u8c03\u5ea6\u5728\u5408\u6210\u548c\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u624b\u5de5\u57fa\u51c6\uff0c\u5728\u4f4e\u6b65\u6570\u91c7\u6837\u4e2d\u8868\u73b0\u66f4\u4f73", "conclusion": "\u8be5\u7406\u8bba\u6846\u67b6\u6709\u6548\uff0c\u80fd\u91cf\u542f\u53d1\u5f0f\u8c03\u5ea6\u65b9\u6cd5\u53ef\u884c\u4e14\u9ad8\u6548"}}
{"id": "2509.13328", "pdf": "https://arxiv.org/pdf/2509.13328", "abs": "https://arxiv.org/abs/2509.13328", "authors": ["Danish Rizvi", "David Boyle"], "title": "Dual Actor DDPG for Airborne STAR-RIS Assisted Communications", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.NI", "math.IT"], "comment": null, "summary": "This study departs from the prevailing assumption of independent Transmission\nand Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect\nReconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a\nnovel multi-user downlink communication system that leverages a UAV-mounted\nSTAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key\ncontributions include the joint optimization of UAV trajectory, active\nbeamforming vectors at the base station, and passive RIS TRCs to enhance\ncommunication efficiency, while considering UAV energy constraints. We design\nthe TRC as a combination of discrete and continuous actions, and propose a\nnovel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The\nalgorithm relies on two separate actor networks for high-dimensional hybrid\naction space. We also propose a novel harmonic mean index (HFI)-based reward\nfunction to ensure communication fairness amongst users. For comprehensive\nanalysis, we study the impact of RIS size on UAV aerodynamics showing that it\nincreases drag and energy demand. Simulation results demonstrate that the\nproposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based\nsolutions by 24% and 97%, respectively, in accumulated reward.\nThree-dimensional UAV trajectory optimization achieves 28% higher communication\nefficiency compared to two-dimensional and altitude optimization. The HFI based\nreward function provides 41% lower QoS denial rates as compared to other\nbenchmarks. The mobile Aerial-STAR system shows superior performance over fixed\ndeployed counterparts, with the coupled phase STAR-RIS outperforming dual\nTransmit/Reflect RIS and conventional RIS setups. These findings highlight the\npotential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG\napproach in optimizing their performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u57fa\u4e8e\u8026\u5408TRC\u76f8\u79fb\u6a21\u578b\u7684Aerial - STAR\u591a\u7528\u6237\u4e0b\u884c\u901a\u4fe1\u7cfb\u7edf\uff0c\u63d0\u51faDA - DDPG\u7b97\u6cd5\u548cHFI\u5956\u52b1\u51fd\u6570\uff0c\u4eff\u771f\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u6253\u7834\u73b0\u6709STAR - RIS\u7814\u7a76\u4e2d\u4f20\u8f93\u548c\u53cd\u5c04\u7cfb\u6570\u72ec\u7acb\u7684\u5047\u8bbe\uff0c\u63d0\u5347\u901a\u4fe1\u6548\u7387\u5e76\u8003\u8651\u65e0\u4eba\u673a\u80fd\u91cf\u7ea6\u675f\u3002", "method": "\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u8f68\u8ff9\u3001\u57fa\u7ad9\u6709\u6e90\u6ce2\u675f\u8d4b\u5f62\u5411\u91cf\u548c\u65e0\u6e90RIS\u7684TRC\uff1b\u5c06TRC\u8bbe\u8ba1\u4e3a\u79bb\u6563\u548c\u8fde\u7eed\u52a8\u4f5c\u7ec4\u5408\uff1b\u63d0\u51faDA - DDPG\u7b97\u6cd5\u548cHFI\u5956\u52b1\u51fd\u6570\uff1b\u7814\u7a76RIS\u5c3a\u5bf8\u5bf9\u65e0\u4eba\u673a\u7a7a\u6c14\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002", "result": "DA - DDPG\u7b97\u6cd5\u5728\u7d2f\u79ef\u5956\u52b1\u4e0a\u4f18\u4e8e\u4f20\u7edfDDPG\u548cDQN\u89e3\u51b3\u65b9\u6848\uff1b\u4e09\u7ef4\u65e0\u4eba\u673a\u8f68\u8ff9\u4f18\u5316\u901a\u4fe1\u6548\u7387\u66f4\u9ad8\uff1bHFI\u5956\u52b1\u51fd\u6570\u964d\u4f4eQoS\u62d2\u7edd\u7387\uff1b\u79fb\u52a8Aerial - STAR\u7cfb\u7edf\u6027\u80fd\u66f4\u4f73\u3002", "conclusion": "Aerial - STAR\u7cfb\u7edf\u6709\u6f5c\u529b\uff0c\u63d0\u51fa\u7684DA - DDPG\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u5176\u6027\u80fd\u3002"}}
{"id": "2509.13895", "pdf": "https://arxiv.org/pdf/2509.13895", "abs": "https://arxiv.org/abs/2509.13895", "authors": ["Zhanting Zhou", "Jinshan Lai", "Fengchun Zhang", "Zeqin Wu", "Fengli Zhang"], "title": "FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": "4 page main text for conference", "summary": "Non-IID data and partial participation induce client drift and inconsistent\nlocal optima in federated learning, causing unstable convergence and accuracy\nloss. We present FedSSG, a stochastic sampling-guided, history-aware drift\nalignment method. FedSSG maintains a per-client drift memory that accumulates\nlocal model differences as a lightweight sketch of historical gradients;\ncrucially, it gates both the memory update and the local alignment term by a\nsmooth function of the observed/expected participation ratio (a\nphase-by-expectation signal derived from the server sampler). This\nstatistically grounded gate stays weak and smooth when sampling noise dominates\nearly, then strengthens once participation statistics stabilize, contracting\nthe local-global gap without extra communication. Across CIFAR-10/100 with\n100/500 clients and 2-15 percent participation, FedSSG consistently outperforms\nstrong drift-aware baselines and accelerates convergence; on our benchmarks it\nimproves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and\nabout +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about\n4.5x faster target-accuracy convergence on average. The method adds only O(d)\nclient memory and a constant-time gate, and degrades gracefully to a mild\nregularizer under near-IID or uniform sampling. FedSSG shows that sampling\nstatistics can be turned into a principled, history-aware phase control to\nstabilize and speed up federated training.", "AI": {"tldr": "\u63d0\u51faFedSSG\u65b9\u6cd5\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u56e0\u975eIID\u6570\u636e\u548c\u90e8\u5206\u53c2\u4e0e\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0c\u52a0\u901f\u6536\u655b\u4e14\u8d44\u6e90\u5f00\u9500\u5c0f\u3002", "motivation": "\u975eIID\u6570\u636e\u548c\u90e8\u5206\u53c2\u4e0e\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u4f1a\u5bfc\u81f4\u5ba2\u6237\u7aef\u6f02\u79fb\u548c\u5c40\u90e8\u6700\u4f18\u4e0d\u4e00\u81f4\uff0c\u9020\u6210\u6536\u655b\u4e0d\u7a33\u5b9a\u548c\u7cbe\u5ea6\u635f\u5931\u3002", "method": "\u63d0\u51fa\u968f\u673a\u91c7\u6837\u5f15\u5bfc\u3001\u5386\u53f2\u611f\u77e5\u7684\u6f02\u79fb\u5bf9\u9f50\u65b9\u6cd5FedSSG\uff0c\u7ef4\u62a4\u5ba2\u6237\u7aef\u6f02\u79fb\u5185\u5b58\uff0c\u901a\u8fc7\u89c2\u5bdf/\u671f\u671b\u53c2\u4e0e\u7387\u7684\u5e73\u6ed1\u51fd\u6570\u63a7\u5236\u5185\u5b58\u66f4\u65b0\u548c\u5c40\u90e8\u5bf9\u9f50\u9879\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u53c2\u4e0e\u7387\u4e0b\uff0cFedSSG\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u6f02\u79fb\u611f\u77e5\u57fa\u7ebf\uff0c\u52a0\u901f\u6536\u655b\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u7cbe\u5ea6\uff0c\u4ec5\u589e\u52a0O(d)\u5ba2\u6237\u7aef\u5185\u5b58\u548c\u5e38\u6570\u65f6\u95f4\u95e8\u63a7\u3002", "conclusion": "\u91c7\u6837\u7edf\u8ba1\u53ef\u8f6c\u5316\u4e3a\u6709\u539f\u5219\u3001\u5386\u53f2\u611f\u77e5\u7684\u9636\u6bb5\u63a7\u5236\uff0c\u7a33\u5b9a\u5e76\u52a0\u901f\u8054\u90a6\u8bad\u7ec3\u3002"}}
{"id": "2509.13331", "pdf": "https://arxiv.org/pdf/2509.13331", "abs": "https://arxiv.org/abs/2509.13331", "authors": ["Reza Pirayeshshirazinezhad"], "title": "Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation", "categories": ["astro-ph.IM", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "We use artificial intelligence (AI) and supervisory adaptive control systems\nto plan and optimize the mission of precise spacecraft formation. Machine\nlearning and robust control enhance the efficiency of spacecraft precision\nformation of the Virtual Telescope for X-ray Observation (VTXO) space mission.\nVTXO is a precise formation of two separate spacecraft making a virtual\ntelescope with a one-kilometer focal length. One spacecraft carries the lens\nand the other spacecraft holds the camera to observe high-energy space objects\nin the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed\nautomata for supervisory control, Monte Carlo simulations for stability and\nrobustness evaluation, and integration of deep neural networks for optimal\nestimation of mission parameters, satisfy the high precision mission criteria.\nWe integrate deep neural networks with a constrained, non-convex dynamic\noptimization pipeline to predict optimal mission parameters, ensuring precision\nmission criteria are met. AI framework provides explainability by predicting\nthe resulting energy consumption and mission error for a given set of mission\nparameters. It allows for transparent, justifiable, and real-time trade-offs, a\ncapability not present in traditional adaptive controllers. The results show\nreductions in energy consumption and improved mission accuracy, demonstrating\nthe capability of the system to address dynamic uncertainties and disturbances.", "AI": {"tldr": "\u672c\u6587\u5229\u7528AI\u548c\u76d1\u7763\u81ea\u9002\u5e94\u63a7\u5236\u7cfb\u7edf\u4f18\u5316\u822a\u5929\u5668\u7cbe\u786e\u7f16\u961f\u4efb\u52a1\uff0c\u7ed3\u679c\u663e\u793a\u964d\u4f4e\u80fd\u8017\u3001\u63d0\u9ad8\u4efb\u52a1\u7cbe\u5ea6\u3002", "motivation": "\u63d0\u5347X\u5c04\u7ebf\u89c2\u6d4b\u865a\u62df\u671b\u8fdc\u955c\uff08VTXO\uff09\u592a\u7a7a\u4efb\u52a1\u4e2d\u822a\u5929\u5668\u7cbe\u786e\u7f16\u961f\u7684\u6548\u7387\uff0c\u6ee1\u8db3\u9ad8\u7cbe\u5ea6\u4efb\u52a1\u6807\u51c6\u3002", "method": "\u91c7\u7528\u76d1\u7763\u63a7\u5236\u7684\u65f6\u95f4\u81ea\u52a8\u673a\u3001\u8499\u7279\u5361\u7f57\u6a21\u62df\u8bc4\u4f30\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\uff0c\u96c6\u6210\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u4efb\u52a1\u53c2\u6570\u6700\u4f18\u4f30\u8ba1\uff0c\u5e76\u5c06\u5176\u4e0e\u53d7\u9650\u975e\u51f8\u52a8\u6001\u4f18\u5316\u7ba1\u9053\u96c6\u6210\u9884\u6d4b\u6700\u4f18\u4efb\u52a1\u53c2\u6570\u3002", "result": "\u964d\u4f4e\u4e86\u80fd\u8017\uff0c\u63d0\u9ad8\u4e86\u4efb\u52a1\u7cbe\u5ea6\uff0c\u7cfb\u7edf\u80fd\u5e94\u5bf9\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u548c\u5e72\u6270\u3002", "conclusion": "\u8be5AI\u6846\u67b6\u53ef\u9884\u6d4b\u80fd\u8017\u548c\u4efb\u52a1\u8bef\u5dee\uff0c\u5b9e\u73b0\u900f\u660e\u3001\u5408\u7406\u548c\u5b9e\u65f6\u6743\u8861\uff0c\u4f18\u4e8e\u4f20\u7edf\u81ea\u9002\u5e94\u63a7\u5236\u5668\u3002"}}
{"id": "2509.13906", "pdf": "https://arxiv.org/pdf/2509.13906", "abs": "https://arxiv.org/abs/2509.13906", "authors": ["Afrin Dange", "Sunita Sarawagi"], "title": "TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates", "categories": ["cs.LG", "I.2.6"], "comment": "Accepted at CIKM 2025", "summary": "Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art\nperformance in univariate forecasting on new time series simply by conditioned\non a brief history of past values. Their success demonstrates that large-scale\npretraining across diverse domains can acquire the inductive bias to generalize\nfrom temporal patterns in a brief history. However, most TSFMs are unable to\nleverage covariates -- future-available exogenous variables critical for\naccurate forecasting in many applications -- due to their domain-specific\nnature and the lack of associated inductive bias. We propose TFMAdapter, a\nlightweight, instance-level adapter that augments TSFMs with covariate\ninformation without fine-tuning. Instead of retraining, TFMAdapter operates on\nthe limited history provided during a single model call, learning a\nnon-parametric cascade that combines covariates with univariate TSFM forecasts.\nHowever, such learning would require univariate forecasts at all steps in the\nhistory, requiring too many calls to the TSFM. To enable training on the full\nhistorical context while limiting TSFM invocations, TFMAdapter uses a two-stage\nmethod: (1) generating pseudo-forecasts with a simple regression model, and (2)\ntraining a Gaussian Process regressor to refine predictions using both pseudo-\nand TSFM forecasts alongside covariates. Extensive experiments on real-world\ndatasets demonstrate that TFMAdapter consistently outperforms both foundation\nmodels and supervised baselines, achieving a 24-27\\% improvement over base\nfoundation models with minimal data and computational overhead. Our results\nhighlight the potential of lightweight adapters to bridge the gap between\ngeneric foundation models and domain-specific forecasting needs.", "AI": {"tldr": "\u63d0\u51faTFMAdapter\u8f7b\u91cf\u7ea7\u5b9e\u4f8b\u7ea7\u9002\u914d\u5668\uff0c\u65e0\u9700\u5fae\u8c03\u589e\u5f3aTSFMs\u5229\u7528\u534f\u53d8\u91cf\u4fe1\u606f\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u548c\u76d1\u7763\u57fa\u7ebf\u3002", "motivation": "\u591a\u6570\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u56e0\u7279\u5b9a\u9886\u57df\u6027\u8d28\u548c\u7f3a\u4e4f\u76f8\u5173\u5f52\u7eb3\u504f\u7f6e\uff0c\u65e0\u6cd5\u5229\u7528\u534f\u53d8\u91cf\u8fdb\u884c\u51c6\u786e\u9884\u6d4b\u3002", "method": "\u63d0\u51faTFMAdapter\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u5148\u7528\u7b80\u5355\u56de\u5f52\u6a21\u578b\u751f\u6210\u4f2a\u9884\u6d4b\uff0c\u518d\u8bad\u7ec3\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u5668\u7ed3\u5408\u4f2a\u9884\u6d4b\u3001TSFM\u9884\u6d4b\u548c\u534f\u53d8\u91cf\u6539\u8fdb\u9884\u6d4b\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cTFMAdapter\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u548c\u76d1\u7763\u57fa\u7ebf\uff0c\u5728\u6700\u5c0f\u6570\u636e\u548c\u8ba1\u7b97\u5f00\u9500\u4e0b\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u534724 - 27%\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6709\u6f5c\u529b\u5f25\u5408\u901a\u7528\u57fa\u7840\u6a21\u578b\u548c\u7279\u5b9a\u9886\u57df\u9884\u6d4b\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.13908", "pdf": "https://arxiv.org/pdf/2509.13908", "abs": "https://arxiv.org/abs/2509.13908", "authors": ["Priyobrata Mondal", "Faizanuddin Ansari", "Swagatam Das"], "title": "APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring fairness in machine learning models is critical, especially when\nbiases compound across intersecting protected attributes like race, gender, and\nage. While existing methods address fairness for single attributes, they fail\nto capture the nuanced, multiplicative biases faced by intersectional\nsubgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first\nframework to explicitly model intersectional fairness as a joint optimization\nproblem over the Cartesian product of sensitive attributes. APFEx combines\nthree key innovations- (1) an adaptive multi-objective optimizer that\ndynamically switches between Pareto cone projection, gradient weighting, and\nexploration strategies to navigate fairness-accuracy trade-offs, (2)\ndifferentiable intersectional fairness metrics enabling gradient-based\noptimization of non-smooth subgroup disparities, and (3) theoretical guarantees\nof convergence to Pareto-optimal solutions. Experiments on four real-world\ndatasets demonstrate APFEx's superiority, reducing fairness violations while\nmaintaining competitive accuracy. Our work bridges a critical gap in fair ML,\nproviding a scalable, model-agnostic solution for intersectional fairness.", "AI": {"tldr": "\u63d0\u51faAPFEx\u6846\u67b6\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u4ea4\u53c9\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u5c55\u793a\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u4ea4\u53c9\u5b50\u7fa4\u4f53\u9762\u4e34\u7684\u7ec6\u5fae\u3001\u591a\u91cd\u504f\u5dee\uff0c\u9700\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ea4\u53c9\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165APFEx\u6846\u67b6\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u591a\u76ee\u6807\u4f18\u5316\u5668\u3001\u53ef\u5fae\u4ea4\u53c9\u516c\u5e73\u6027\u6307\u6807\u548c\u6536\u655b\u5230\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAPFEx\u5728\u51cf\u5c11\u516c\u5e73\u6027\u8fdd\u89c4\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5de5\u4f5c\u586b\u8865\u4e86\u516c\u5e73\u673a\u5668\u5b66\u4e60\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u4ea4\u53c9\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u6a21\u578b\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13342", "pdf": "https://arxiv.org/pdf/2509.13342", "abs": "https://arxiv.org/abs/2509.13342", "authors": ["Isaac Ronald Ward"], "title": "Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments", "categories": ["cs.RO", "cs.AI"], "comment": "This report is submitted as partial fulfilment of the requirements\n  for the Honours Programme of the Department of Computer Science and Software\n  Engineering, The University of Western Australia, 2019", "summary": "In this work, an existing deep neural network approach for determining a\nrobot's pose from visual information (RGB images) is modified, improving its\nlocalization performance without impacting its ease of training. Explicitly,\nthe network's loss function is extended in a manner which intuitively combines\nthe positional and rotational error in order to increase robustness to\nperceptual aliasing. An improvement in the localization accuracy for indoor\nscenes is observed: with decreases of up to 9.64% and 2.99% in the median\npositional and rotational error respectively, when compared to the unmodified\nnetwork.\n  Additionally, photogrammetry data is used to produce a pose-labelled dataset\nwhich allows the above model to be trained on a local environment, resulting in\nlocalization accuracies of 0.11m & 0.89 degrees. This trained model forms the\nbasis of a navigation algorithm, which is tested in real-time on a TurtleBot (a\nwheeled robotic device). As such, this work introduces a full pipeline for\ncreating a robust navigational algorithm for any given real world indoor scene;\nthe only requirement being a collection of images from the scene, which can be\ncaptured in as little as 330 seconds of", "AI": {"tldr": "\u6539\u8fdb\u73b0\u6709\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u63d0\u5347\u673a\u5668\u4eba\u5b9a\u4f4d\u6027\u80fd\uff0c\u521b\u5efa\u9002\u7528\u4e8e\u5ba4\u5185\u573a\u666f\u7684\u5bfc\u822a\u7b97\u6cd5\u3002", "motivation": "\u63d0\u9ad8\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u4fe1\u606f\u786e\u5b9a\u673a\u5668\u4eba\u4f4d\u59ff\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5b9a\u4f4d\u6027\u80fd\uff0c\u589e\u5f3a\u5bf9\u611f\u77e5\u6df7\u6dc6\u7684\u9c81\u68d2\u6027\u3002", "method": "\u6269\u5c55\u7f51\u7edc\u635f\u5931\u51fd\u6570\uff0c\u7ed3\u5408\u4f4d\u7f6e\u548c\u65cb\u8f6c\u8bef\u5dee\uff1b\u4f7f\u7528\u6444\u5f71\u6d4b\u91cf\u6570\u636e\u751f\u6210\u5e26\u4f4d\u59ff\u6807\u7b7e\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5ba4\u5185\u573a\u666f\u5b9a\u4f4d\u7cbe\u5ea6\u63d0\u9ad8\uff0c\u4e2d\u4f4d\u4f4d\u7f6e\u548c\u65cb\u8f6c\u8bef\u5dee\u5206\u522b\u6700\u591a\u964d\u4f4e9.64%\u548c2.99%\uff0c\u8bad\u7ec3\u6a21\u578b\u5b9a\u4f4d\u7cbe\u5ea6\u8fbe0.11m\u548c0.89\u5ea6\uff0c\u5e76\u5728TurtleBot\u4e0a\u5b9e\u65f6\u6d4b\u8bd5\u5bfc\u822a\u7b97\u6cd5\u3002", "conclusion": "\u5f15\u5165\u4e86\u4e3a\u4efb\u610f\u771f\u5b9e\u5ba4\u5185\u573a\u666f\u521b\u5efa\u9c81\u68d2\u5bfc\u822a\u7b97\u6cd5\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u4ec5\u9700\u77ed\u65f6\u95f4\u91c7\u96c6\u573a\u666f\u56fe\u50cf\u3002"}}
{"id": "2509.13914", "pdf": "https://arxiv.org/pdf/2509.13914", "abs": "https://arxiv.org/abs/2509.13914", "authors": ["Divya Thuremella", "Yi Yang", "Simon Wanna", "Lars Kunze", "Daniele De Martini"], "title": "Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "summary": "This work explores the application of ensemble modeling to the\nmultidimensional regression problem of trajectory prediction for vehicles in\nurban environments. As newer and bigger state-of-the-art prediction models for\nautonomous driving continue to emerge, an important open challenge is the\nproblem of how to combine the strengths of these big models without the need\nfor costly re-training. We show how, perhaps surprisingly, combining\nstate-of-the-art deep learning models out-of-the-box (without retraining or\nfine-tuning) with a simple confidence-weighted average method can enhance the\noverall prediction. Indeed, while combining trajectory prediction models is not\nstraightforward, this simple approach enhances performance by 10% over the best\nprediction model, especially in the long-tailed metrics. We show that this\nperformance improvement holds on both the NuScenes and Argoverse datasets, and\nthat these improvements are made across the dataset distribution. The code for\nour work is open source.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u96c6\u6210\u5efa\u6a21\u5728\u57ce\u5e02\u73af\u5883\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u591a\u7ef4\u56de\u5f52\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u7528\u7b80\u5355\u7f6e\u4fe1\u52a0\u6743\u5e73\u5747\u6cd5\u7ed3\u5408\u5148\u8fdb\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u5148\u8fdb\u9884\u6d4b\u6a21\u578b\u4e0d\u65ad\u6d8c\u73b0\uff0c\u9700\u8981\u89e3\u51b3\u5982\u4f55\u5728\u65e0\u9700\u6602\u8d35\u518d\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u7ed3\u5408\u8fd9\u4e9b\u5927\u6a21\u578b\u7684\u4f18\u52bf\u3002", "method": "\u91c7\u7528\u7b80\u5355\u7684\u7f6e\u4fe1\u52a0\u6743\u5e73\u5747\u6cd5\uff0c\u5c06\u5148\u8fdb\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u76f4\u63a5\u7ec4\u5408\uff0c\u65e0\u9700\u518d\u8bad\u7ec3\u6216\u5fae\u8c03\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u6700\u4f73\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u63d0\u534710%\uff0c\u5c24\u5176\u5728\u957f\u5c3e\u6307\u6807\u4e0a\uff0c\u4e14\u5728NuScenes\u548cArgoverse\u6570\u636e\u96c6\u4e0a\u5747\u6709\u6548\uff0c\u6027\u80fd\u63d0\u5347\u8986\u76d6\u6570\u636e\u96c6\u5206\u5e03\u3002", "conclusion": "\u7b80\u5355\u7684\u7f6e\u4fe1\u52a0\u6743\u5e73\u5747\u6cd5\u7ed3\u5408\u5148\u8fdb\u6a21\u578b\u80fd\u6709\u6548\u63d0\u5347\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u6027\u80fd\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2509.13345", "pdf": "https://arxiv.org/pdf/2509.13345", "abs": "https://arxiv.org/abs/2509.13345", "authors": ["Zihao Li", "Weiwei Yi", "Jiahong Chen"], "title": "Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) permeate everyday decision-making, their\nepistemic and societal risks demand urgent scrutiny. Hallucinations, the\ngeneration of fabricated, misleading, oversimplified or untrustworthy outputs,\nhas emerged as imperative challenges. While regulatory, academic, and technical\ndiscourse position accuracy as the principal benchmark for mitigating such\nharms, this article contends that overreliance on accuracy misdiagnoses the\nproblem and has counterproductive effect: the accuracy paradox. Drawing on\ninterdisciplinary literatures, this article develops a taxonomy of\nhallucination types and shows the paradox along three intertwining dimensions:\noutputs, individuals and society. First, accuracy functions as a superficial\nproxy for reliability, incentivising the optimisation of rhetorical fluency and\nsurface-level correctness over epistemic trustworthiness. This encourages\npassive user trust in outputs that appear accurate but epistemically untenable.\nSecond, accuracy as a singular metric fails to detect harms that are not\nfactually false but are nonetheless misleading, value-laden, or socially\ndistorting, including consensus illusions, sycophantic alignment, and subtle\nmanipulation. Third, regulatory overemphasis on accuracy obscures the wider\nsocietal consequences of hallucination, including social sorting, privacy\nviolations, equity harms, epistemic convergence that marginalises dissent,\nreduces pluralism, and causes social deskilling. By examining the EU AI Act,\nGDPR, and DSA, the article argues that current regulations are not yet\nstructurally equipped to address these epistemic, relational, and systemic\nharms and exacerbated by the overreliance on accuracy. By exposing such\nconceptual and practical challenges, this article calls for a fundamental shift\ntowards pluralistic, context-aware, and manipulation-resilient approaches to AI\ntrustworthy governance.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u4e25\u91cd\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u51c6\u786e\u6027\u6307\u6807\u5b58\u5728\u6096\u8bba\uff0c\u73b0\u884c\u6cd5\u89c4\u96be\u4ee5\u5e94\u5bf9\uff0c\u547c\u5401\u8f6c\u5411\u591a\u5143\u3001\u60c5\u5883\u611f\u77e5\u548c\u6297\u64cd\u7eb5\u7684AI\u53ef\u4fe1\u6cbb\u7406\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5165\u65e5\u5e38\u51b3\u7b56\uff0c\u5176\u8ba4\u77e5\u548c\u793e\u4f1a\u98ce\u9669\u9700\u8feb\u5207\u5ba1\u89c6\uff0c\u800c\u8fc7\u5ea6\u4f9d\u8d56\u51c6\u786e\u6027\u6307\u6807\u6765\u51cf\u8f7b\u5e7b\u89c9\u5371\u5bb3\u5b58\u5728\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u8de8\u5b66\u79d1\u6587\u732e\uff0c\u4ece\u8f93\u51fa\u3001\u4e2a\u4f53\u548c\u793e\u4f1a\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790\u51c6\u786e\u6027\u6096\u8bba\uff0c\u8fd8\u901a\u8fc7\u7814\u7a76\u6b27\u76dfAI\u6cd5\u6848\u3001GDPR\u548cDSA\u7b49\u6cd5\u89c4\u3002", "result": "\u53d1\u73b0\u51c6\u786e\u6027\u6307\u6807\u662f\u53ef\u9760\u6027\u7684\u8868\u9762\u66ff\u4ee3\uff0c\u65e0\u6cd5\u68c0\u6d4b\u975e\u4e8b\u5b9e\u6027\u9519\u8bef\u4f46\u6709\u8bef\u5bfc\u6027\u7684\u5371\u5bb3\uff0c\u4e14\u6cd5\u89c4\u8fc7\u5ea6\u5f3a\u8c03\u51c6\u786e\u6027\u63a9\u76d6\u4e86\u5e7b\u89c9\u7684\u793e\u4f1a\u540e\u679c\u3002", "conclusion": "\u73b0\u884c\u6cd5\u89c4\u5728\u7ed3\u6784\u4e0a\u65e0\u6cd5\u5e94\u5bf9\u8fd9\u4e9b\u5371\u5bb3\uff0c\u9700\u5411\u591a\u5143\u3001\u60c5\u5883\u611f\u77e5\u548c\u6297\u64cd\u7eb5\u7684AI\u53ef\u4fe1\u6cbb\u7406\u65b9\u6cd5\u8f6c\u53d8\u3002"}}
{"id": "2509.13349", "pdf": "https://arxiv.org/pdf/2509.13349", "abs": "https://arxiv.org/abs/2509.13349", "authors": ["Jed Guzelkabaagac", "Boris Petrovi\u0107"], "title": "Label-Efficient Grasp Joint Prediction with Point-JEPA", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "4 pages, 5 figures. Submitted to IROS 2025 Workshop", "summary": "We investigate whether 3D self-supervised pretraining with a Joint-Embedding\nPredictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle\nprediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained\nPoint-JEPA encoder, we train a lightweight multi-hypothesis head with\nwinner-takes-all and evaluate by top-logit selection. On DLR-Hand II with\nobject-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes\nand reaches parity with full supervision. These results suggest JEPA-style\npretraining is a practical approach for data-efficient grasp learning.", "AI": {"tldr": "\u7814\u7a763D\u81ea\u76d1\u7763\u9884\u8bad\u7ec3Point - JEPA\u662f\u5426\u80fd\u5b9e\u73b0\u9ad8\u6548\u7684\u6293\u53d6\u5173\u8282\u89d2\u5ea6\u9884\u6d4b\uff0c\u7ed3\u679c\u8868\u660eJEPA\u98ce\u683c\u9884\u8bad\u7ec3\u5bf9\u6570\u636e\u9ad8\u6548\u6293\u53d6\u5b66\u4e60\u6709\u6548\u3002", "motivation": "\u63a2\u7a763D\u81ea\u76d1\u7763\u9884\u8bad\u7ec3Point - JEPA\u80fd\u5426\u5b9e\u73b0\u6807\u7b7e\u9ad8\u6548\u7684\u6293\u53d6\u5173\u8282\u89d2\u5ea6\u9884\u6d4b\u3002", "method": "\u4f7f\u7528\u4ece\u7f51\u683c\u4e2d\u6807\u8bb0\u7684\u70b9\u4e91\u4ee5\u53caShapeNet\u9884\u8bad\u7ec3\u7684Point - JEPA\u7f16\u7801\u5668\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u591a\u5047\u8bbe\u5934\u5e76\u91c7\u7528\u80dc\u8005\u4e3a\u738b\u7b56\u7565\uff0c\u901a\u8fc7\u6700\u9ad8\u5bf9\u6570\u9009\u62e9\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728DLR - Hand II\u4e0a\uff0cPoint - JEPA\u5728\u4f4e\u6807\u7b7e\u60c5\u51b5\u4e0b\u5c06RMSE\u964d\u4f4e\u4e8626%\uff0c\u5e76\u8fbe\u5230\u4e0e\u5168\u76d1\u7763\u76f8\u5f53\u7684\u6548\u679c\u3002", "conclusion": "JEPA\u98ce\u683c\u7684\u9884\u8bad\u7ec3\u662f\u4e00\u79cd\u7528\u4e8e\u6570\u636e\u9ad8\u6548\u6293\u53d6\u5b66\u4e60\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2509.13952", "pdf": "https://arxiv.org/pdf/2509.13952", "abs": "https://arxiv.org/abs/2509.13952", "authors": ["Amin Lotfalian", "Mohammad Reza Banan", "Pooyan Broumand"], "title": "eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "This paper presents eXtended Physics-Informed Neural Network (X-PINN), a\nnovel and robust framework for addressing fracture mechanics problems involving\nmultiple cracks in fractured media. To address this, an energy-based loss\nfunction, customized integration schemes, and domain decomposition procedures\nare proposed. Inspired by the Extended Finite Element Method (XFEM), the neural\nnetwork solution space is enriched with specialized functions that allow crack\nbody discontinuities and singularities at crack tips to be explicitly captured.\nFurthermore, a structured framework is introduced in which standard and\nenriched solution components are modeled using distinct neural networks,\nenabling flexible and effective simulations of complex multiple-crack problems\nin 1D and 2D domains, with convenient extensibility to 3D problems. Numerical\nexperiments are conducted to validate the effectiveness and robustness of the\nproposed method.", "AI": {"tldr": "\u63d0\u51faX - PINN\u6846\u67b6\u89e3\u51b3\u542b\u591a\u88c2\u7eb9\u7684\u65ad\u88c2\u529b\u5b66\u95ee\u9898\uff0c\u4ecb\u7ecd\u65b9\u6cd5\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u542b\u591a\u88c2\u7eb9\u7684\u65ad\u88c2\u529b\u5b66\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u80fd\u91cf\u7684\u635f\u5931\u51fd\u6570\u3001\u5b9a\u5236\u79ef\u5206\u65b9\u6848\u548c\u533a\u57df\u5206\u89e3\u7a0b\u5e8f\uff1b\u501f\u9274XFEM\u7528\u7279\u6b8a\u51fd\u6570\u4e30\u5bcc\u795e\u7ecf\u7f51\u7edc\u89e3\u7a7a\u95f4\uff1b\u7528\u4e0d\u540c\u795e\u7ecf\u7f51\u7edc\u5206\u522b\u5efa\u6a21\u6807\u51c6\u548c\u5bcc\u96c6\u89e3\u5206\u91cf\u3002", "result": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "X - PINN\u6846\u67b6\u80fd\u6709\u6548\u4e14\u7075\u6d3b\u5730\u6a21\u62df1D\u548c2D\u57df\u4e2d\u7684\u590d\u6742\u591a\u88c2\u7eb9\u95ee\u9898\uff0c\u4e14\u4fbf\u4e8e\u6269\u5c55\u52303D\u95ee\u9898\u3002"}}
{"id": "2509.13353", "pdf": "https://arxiv.org/pdf/2509.13353", "abs": "https://arxiv.org/abs/2509.13353", "authors": ["Muhammad Adnan Shahzad"], "title": "Hybrid Quantum-Classical Model for Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This study presents a systematic comparison between hybrid quantum-classical\nneural networks and purely classical models across three benchmark datasets\n(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and\nrobustness. The hybrid models integrate parameterized quantum circuits with\nclassical deep learning architectures, while the classical counterparts use\nconventional convolutional neural networks (CNNs). Experiments were conducted\nover 50 training epochs for each dataset, with evaluations on validation\naccuracy, test accuracy, training time, computational resource usage, and\nadversarial robustness (tested with $\\epsilon=0.1$ perturbations).Key findings\ndemonstrate that hybrid models consistently outperform classical models in\nfinal accuracy, achieving {99.38\\% (MNIST), 41.69\\% (CIFAR100), and 74.05\\%\n(STL10) validation accuracy, compared to classical benchmarks of 98.21\\%,\n32.25\\%, and 63.76\\%, respectively. Notably, the hybrid advantage scales with\ndataset complexity, showing the most significant gains on CIFAR100 (+9.44\\%)\nand STL10 (+10.29\\%). Hybrid models also train 5--12$\\times$ faster (e.g.,\n21.23s vs. 108.44s per epoch on MNIST) and use 6--32\\% fewer parameters} while\nmaintaining superior generalization to unseen test data.Adversarial robustness\ntests reveal that hybrid models are significantly more resilient on simpler\ndatasets (e.g., 45.27\\% robust accuracy on MNIST vs. 10.80\\% for classical) but\nshow comparable fragility on complex datasets like CIFAR100 ($\\sim$1\\%\nrobustness for both). Resource efficiency analyses indicate that hybrid models\nconsume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization\n(9.5\\% vs. 23.2\\% on average).These results suggest that hybrid\nquantum-classical architectures offer compelling advantages in accuracy,\ntraining efficiency, and parameter scalability, particularly for complex vision\ntasks.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6df7\u5408\u91cf\u5b50 - \u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u548c\u7eaf\u7ecf\u5178\u6a21\u578b\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u53d1\u73b0\u6df7\u5408\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u8bad\u7ec3\u6548\u7387\u7b49\u65b9\u9762\u6709\u4f18\u52bf\u3002", "motivation": "\u8bc4\u4f30\u6df7\u5408\u91cf\u5b50 - \u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u548c\u7eaf\u7ecf\u5178\u6a21\u578b\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u5dee\u5f02\u3002", "method": "\u5728MNIST\u3001CIFAR100\u548cSTL10\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c50\u4e2a\u8bad\u7ec3\u5468\u671f\u7684\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u9a8c\u8bc1\u51c6\u786e\u7387\u3001\u6d4b\u8bd5\u51c6\u786e\u7387\u3001\u8bad\u7ec3\u65f6\u95f4\u7b49\u6307\u6807\u3002", "result": "\u6df7\u5408\u6a21\u578b\u5728\u6700\u7ec8\u51c6\u786e\u7387\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u7ecf\u5178\u6a21\u578b\uff0c\u8bad\u7ec3\u901f\u5ea6\u5feb5 - 12\u500d\uff0c\u4f7f\u7528\u53c2\u6570\u5c116 - 32%\uff0c\u5728\u7b80\u5355\u6570\u636e\u96c6\u4e0a\u5bf9\u6297\u9c81\u68d2\u6027\u66f4\u5f3a\uff0c\u4e14\u8d44\u6e90\u6d88\u8017\u66f4\u5c11\u3002", "conclusion": "\u6df7\u5408\u91cf\u5b50 - \u7ecf\u5178\u67b6\u6784\u5728\u51c6\u786e\u6027\u3001\u8bad\u7ec3\u6548\u7387\u548c\u53c2\u6570\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u3002"}}
{"id": "2509.13974", "pdf": "https://arxiv.org/pdf/2509.13974", "abs": "https://arxiv.org/abs/2509.13974", "authors": ["Amirhossein Shahbazinia", "Jonathan Dan", "Jose A. Miranda", "Giovanni Ansaloni", "David Atienza"], "title": "Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Objective: Epilepsy, a prevalent neurological disease, demands careful\ndiagnosis and continuous care. Seizure detection remains challenging, as\ncurrent clinical practice relies on expert analysis of electroencephalography,\nwhich is a time-consuming process and requires specialized knowledge.\nAddressing this challenge, this paper explores automated epileptic seizure\ndetection using deep learning, focusing on personalized continual learning\nmodels that adapt to each patient's unique electroencephalography signal\nfeatures, which evolve over time. Methods: In this context, our approach\naddresses the challenge of integrating new data into existing models without\ncatastrophic forgetting, a common issue in static deep learning models. We\npropose EpiSMART, a continual learning framework for seizure detection that\nuses a size-constrained replay buffer and an informed sample selection strategy\nto incrementally adapt to patient-specific electroencephalography signals. By\nselectively retaining high-entropy and seizure-predicted samples, our method\npreserves critical past information while maintaining high performance with\nminimal memory and computational requirements. Results: Validation on the\nCHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score\nover a trained baseline without updates in all other patients. On average,\nEpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,\nmaking it suitable for real-time deployment in wearable systems.\nConclusion:EpiSMART enables robust and personalized seizure detection under\nrealistic and resource-constrained conditions by effectively integrating new\ndata into existing models without degrading past knowledge. Significance: This\nframework advances automated seizure detection by providing a continual\nlearning approach that supports patient-specific adaptation and practical\ndeployment in wearable healthcare systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEpiSMART\u6846\u67b6\u7528\u4e8e\u766b\u75eb\u53d1\u4f5c\u81ea\u52a8\u68c0\u6d4b\uff0c\u5728CHB - MIT\u6570\u636e\u96c6\u9a8c\u8bc1\u6548\u679c\u826f\u597d\uff0c\u9002\u5408\u53ef\u7a7f\u6234\u7cfb\u7edf\u5b9e\u65f6\u90e8\u7f72\u3002", "motivation": "\u766b\u75eb\u8bca\u65ad\u548c\u62a4\u7406\u9700\u4ed4\u7ec6\uff0c\u5f53\u524d\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\u4f9d\u8d56\u4e13\u5bb6\u5206\u6790\u8111\u7535\u56fe\uff0c\u8017\u65f6\u4e14\u9700\u4e13\u4e1a\u77e5\u8bc6\uff0c\u672c\u6587\u63a2\u7d22\u7528\u6df1\u5ea6\u5b66\u4e60\u8fdb\u884c\u81ea\u52a8\u68c0\u6d4b\uff0c\u5173\u6ce8\u4e2a\u6027\u5316\u6301\u7eed\u5b66\u4e60\u6a21\u578b\u3002", "method": "\u63d0\u51faEpiSMART\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u5c0f\u53d7\u9650\u7684\u91cd\u653e\u7f13\u51b2\u533a\u548c\u660e\u667a\u7684\u6837\u672c\u9009\u62e9\u7b56\u7565\uff0c\u9009\u62e9\u6027\u4fdd\u7559\u9ad8\u71b5\u548c\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u6837\u672c\u3002", "result": "\u5728CHB - MIT\u6570\u636e\u96c6\u4e0a\uff0cEpiSMART\u7684F1\u5206\u6570\u6bd4\u672a\u66f4\u65b0\u7684\u57fa\u7ebf\u63d0\u9ad821%\uff0c\u5e73\u5747\u6bcf\u5929\u4ec5\u97006.46\u5206\u949f\u6807\u8bb0\u6570\u636e\u548c6.28\u6b21\u66f4\u65b0\uff0c\u9002\u5408\u53ef\u7a7f\u6234\u7cfb\u7edf\u5b9e\u65f6\u90e8\u7f72\u3002", "conclusion": "EpiSMART\u80fd\u5728\u73b0\u5b9e\u548c\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u5b9e\u73b0\u7a33\u5065\u4e14\u4e2a\u6027\u5316\u7684\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\uff0c\u6709\u6548\u6574\u5408\u65b0\u6570\u636e\u4e14\u4e0d\u635f\u5bb3\u8fc7\u5f80\u77e5\u8bc6\u3002"}}
{"id": "2509.13355", "pdf": "https://arxiv.org/pdf/2509.13355", "abs": "https://arxiv.org/abs/2509.13355", "authors": ["Dietmar Offenhuber"], "title": "Synthetic Data and the Shifting Ground of Truth", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Talk presented at the Society for the Social Studies of Science (4S)\n  2025 meeting in Seattle, Sept. 3, 2025", "summary": "The emergence of synthetic data for privacy protection, training data\ngeneration, or simply convenient access to quasi-realistic data in any shape or\nvolume complicates the concept of ground truth. Synthetic data mimic real-world\nobservations, but do not refer to external features. This lack of a\nrepresentational relationship, however, not prevent researchers from using\nsynthetic data as training data for AI models and ground truth repositories. It\nis claimed that the lack of data realism is not merely an acceptable tradeoff,\nbut often leads to better model performance than realistic data: compensate for\nknown biases, prevent overfitting and support generalization, and make the\nmodels more robust in dealing with unexpected outliers. Indeed, injecting noisy\nand outright implausible data into training sets can be beneficial for the\nmodel. This greatly complicates usual assumptions based on which\nrepresentational accuracy determines data fidelity (garbage in - garbage out).\nFurthermore, ground truth becomes a self-referential affair, in which the\nlabels used as a ground truth repository are themselves synthetic products of a\ngenerative model and as such not connected to real-world observations. My paper\nexamines how ML researchers and practitioners bootstrap ground truth under such\nparadoxical circumstances without relying on the stable ground of\nrepresentation and real-world reference. It will also reflect on the broader\nimplications of a shift from a representational to what could be described as a\nmimetic or iconic concept of data.", "AI": {"tldr": "\u5408\u6210\u6570\u636e\u4f7f\u5730\u9762\u771f\u503c\u6982\u5ff5\u590d\u6742\u5316\uff0c\u7f3a\u4e4f\u73b0\u5b9e\u53c2\u7167\u4ecd\u6709\u76ca\u6a21\u578b\uff0c\u8bba\u6587\u63a2\u8ba8\u5728\u6b64\u60c5\u51b5\u4e0b\u5f15\u5bfc\u5730\u9762\u771f\u503c\u53ca\u6570\u636e\u6982\u5ff5\u8f6c\u53d8\u5f71\u54cd\u3002", "motivation": "\u5408\u6210\u6570\u636e\u51fa\u73b0\u4f7f\u5730\u9762\u771f\u503c\u6982\u5ff5\u590d\u6742\uff0c\u9700\u7814\u7a76\u5728\u6b64\u77db\u76fe\u60c5\u51b5\u4e0b\u5f15\u5bfc\u5730\u9762\u771f\u503c\u53ca\u6570\u636e\u6982\u5ff5\u8f6c\u53d8\u5f71\u54cd\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2509.14000", "pdf": "https://arxiv.org/pdf/2509.14000", "abs": "https://arxiv.org/abs/2509.14000", "authors": ["Ivana Kesi\u0107", "Alja\u017e Blatnik", "Carolina Fortuna", "Bla\u017e Bertalani\u010d"], "title": "Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations", "categories": ["cs.LG"], "comment": "20 pages, 4 figures", "summary": "Global Navigation Satellite Systems (GNSS) are increasingly disrupted by\nintentional jamming, degrading availability precisely when positioning and\ntiming must remain operational. We address this by reframing jamming mitigation\nas dynamic graph regression and introducing a receiver-centric deep temporal\ngraph network that predicts, and thus corrects, the receivers horizontal\ndeviation in real time. At each 1 Hz epoch, the satellite receiver environment\nis represented as a heterogeneous star graph (receiver center, tracked\nsatellites as leaves) with time varying attributes (e.g., SNR, azimuth,\nelevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM\n(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a\nshort history to output the 2D deviation vector applied for on the fly\ncorrection.\n  We evaluate on datasets from two distinct receivers under three jammer\nprofiles, continuous wave (cw), triple tone (cw3), and wideband FM, each\nexercised at six power levels between -45 and -70 dBm, with 50 repetitions per\nscenario (prejam/jam/recovery). Against strong multivariate time series\nbaselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains\nthe lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm\n(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and\n4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode\ndatasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),\noutperforming Seq2Point, MLP, and CNN. A split study shows superior data\nefficiency: with only 10\\% training data our approach remains well ahead of\nbaselines (20 cm vs. 36-42 cm).", "AI": {"tldr": "\u672c\u6587\u5c06\u5e72\u6270\u7f13\u89e3\u95ee\u9898\u8f6c\u5316\u4e3a\u52a8\u6001\u56fe\u56de\u5f52\uff0c\u5f15\u5165\u4ee5\u63a5\u6536\u5668\u4e3a\u4e2d\u5fc3\u7684\u6df1\u5ea6\u65f6\u95f4\u56fe\u7f51\u7edc\u5b9e\u65f6\u9884\u6d4b\u5e76\u6821\u6b63\u63a5\u6536\u5668\u6c34\u5e73\u504f\u5dee\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u5728\u591a\u65b9\u9762\u4f18\u4e8e\u5f3a\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u57fa\u7ebf\u3002", "motivation": "\u5168\u7403\u5bfc\u822a\u536b\u661f\u7cfb\u7edf\uff08GNSS\uff09\u53d7\u6709\u610f\u5e72\u6270\u5f71\u54cd\uff0c\u9700\u89e3\u51b3\u5e72\u6270\u7f13\u89e3\u95ee\u9898\u4ee5\u4fdd\u8bc1\u5b9a\u4f4d\u548c\u6388\u65f6\u529f\u80fd\u6b63\u5e38\u8fd0\u884c\u3002", "method": "\u5c06\u5e72\u6270\u7f13\u89e3\u95ee\u9898\u8f6c\u5316\u4e3a\u52a8\u6001\u56fe\u56de\u5f52\uff0c\u5f15\u5165\u63a5\u6536\u5668\u4e2d\u5fc3\u7684\u6df1\u5ea6\u65f6\u95f4\u56fe\u7f51\u7edc\uff0c\u7528\u5355\u5c42\u5f02\u8d28\u56fe\u5377\u79ef\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08HeteroGCLSTM\uff09\u805a\u5408\u7a7a\u95f4\u548c\u65f6\u95f4\u4fe1\u606f\uff0c\u8f93\u51fa\u4e8c\u7ef4\u504f\u5dee\u5411\u91cf\u8fdb\u884c\u5b9e\u65f6\u6821\u6b63\u3002", "result": "\u5728\u4e0d\u540c\u63a5\u6536\u5668\u3001\u5e72\u6270\u6a21\u5f0f\u548c\u529f\u7387\u6c34\u5e73\u4e0b\uff0c\u8be5\u6a21\u578b\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u4f4e\u4e8e\u5f3a\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u57fa\u7ebf\uff0c\u5728\u6df7\u5408\u6a21\u5f0f\u6570\u636e\u96c6\u4e0a\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u6570\u636e\u6548\u7387\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u89e3\u51b3GNSS\u5e72\u6270\u7f13\u89e3\u95ee\u9898\u4e0a\u6548\u679c\u826f\u597d\uff0c\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u6a21\u578b\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u6570\u636e\u6548\u7387\u3002"}}
{"id": "2509.13359", "pdf": "https://arxiv.org/pdf/2509.13359", "abs": "https://arxiv.org/abs/2509.13359", "authors": ["Benjamin J. Walker", "Beatriz Navarro Lameda", "Ruth A. Reynolds"], "title": "Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are\ntransforming the educational landscape, prompting reconsideration of\ntraditional assessment practices. In parallel, universities are exploring\nalternatives to in-person, closed-book examinations, raising concerns about\nacademic integrity and pedagogical alignment in uninvigilated settings. This\nstudy investigates whether traditional closed-book mathematics examinations\nretain their pedagogical relevance when hypothetically administered in\nuninvigilated, open-book settings with GenAI access. Adopting an empirical\napproach, we generate, transcribe, and blind-mark GenAI submissions to eight\nundergraduate mathematics examinations at a Russel Group university, spanning\nthe entirety of the first-year curriculum. By combining independent GenAI\nresponses to individual questions, we enable a meaningful evaluation of GenAI\nperformance, both at the level of modules and across the first-year curriculum.\nWe find that GenAI attainment is at the level of a first-class degree, though\ncurrent performance can vary between modules. Further, we find that GenAI\nperformance is remarkably consistent when viewed across the entire curriculum,\nsignificantly more so than that of students in invigilated examinations. Our\nfindings evidence the need for redesigning assessments in mathematics for\nunsupervised settings, and highlight the potential reduction in pedagogical\nvalue of current standards in the era of generative artificial intelligence.", "AI": {"tldr": "\u7814\u7a76\u5728\u65e0\u76d1\u8003\u3001\u53ef\u4f7f\u7528GenAI\u7684\u5f00\u5377\u73af\u5883\u4e0b\uff0c\u4f20\u7edf\u95ed\u5377\u6570\u5b66\u8003\u8bd5\u662f\u5426\u8fd8\u6709\u6559\u5b66\u76f8\u5173\u6027\uff0c\u53d1\u73b0GenAI\u6210\u7ee9\u8fbe\u4e00\u7b49\u5b66\u4f4d\u6c34\u5e73\uff0c\u8868\u73b0\u6bd4\u5b66\u751f\u66f4\u7a33\u5b9a\uff0c\u9700\u91cd\u65b0\u8bbe\u8ba1\u6570\u5b66\u8bc4\u4f30\u3002", "motivation": "GenAI\u6539\u53d8\u6559\u80b2\u683c\u5c40\uff0c\u9ad8\u6821\u63a2\u7d22\u66ff\u4ee3\u95ed\u5377\u8003\u8bd5\u65b9\u5f0f\uff0c\u5f15\u53d1\u5b66\u672f\u8bda\u4fe1\u548c\u6559\u5b66\u4e00\u81f4\u6027\u62c5\u5fe7\uff0c\u7814\u7a76\u4f20\u7edf\u95ed\u5377\u6570\u5b66\u8003\u8bd5\u5728\u65b0\u73af\u5883\u4e0b\u7684\u6559\u5b66\u76f8\u5173\u6027\u3002", "method": "\u91c7\u7528\u5b9e\u8bc1\u65b9\u6cd5\uff0c\u5bf9\u7f57\u7d20\u96c6\u56e2\u5927\u5b66\u672c\u79d1\u4e00\u5e74\u7ea7\u516b\u95e8\u6570\u5b66\u8003\u8bd5\u7684GenAI\u63d0\u4ea4\u5185\u5bb9\u8fdb\u884c\u751f\u6210\u3001\u8f6c\u5f55\u548c\u76f2\u8bc4\uff0c\u7efc\u5408\u72ec\u7acbGenAI\u5bf9\u5355\u4e2a\u95ee\u9898\u7684\u56de\u7b54\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "GenAI\u6210\u7ee9\u8fbe\u4e00\u7b49\u5b66\u4f4d\u6c34\u5e73\uff0c\u4e0d\u540c\u6a21\u5757\u8868\u73b0\u6709\u5dee\u5f02\uff0c\u5728\u6574\u4e2a\u8bfe\u7a0b\u4e2d\u7684\u8868\u73b0\u6bd4\u76d1\u8003\u8003\u8bd5\u4e2d\u5b66\u751f\u7684\u8868\u73b0\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u6709\u5fc5\u8981\u4e3a\u65e0\u76d1\u7763\u73af\u5883\u91cd\u65b0\u8bbe\u8ba1\u6570\u5b66\u8bc4\u4f30\uff0c\u5f53\u524d\u6807\u51c6\u5728GenAI\u65f6\u4ee3\u7684\u6559\u5b66\u4ef7\u503c\u53ef\u80fd\u964d\u4f4e\u3002"}}
{"id": "2509.14024", "pdf": "https://arxiv.org/pdf/2509.14024", "abs": "https://arxiv.org/abs/2509.14024", "authors": ["Raouf Kerkouche", "Henrik Zunker", "Mario Fritz", "Martin J. K\u00fchn"], "title": "Differentially private federated learning for localized control of infectious disease dynamics", "categories": ["cs.LG", "68T07, 68P27, 92-08, 92-10"], "comment": "18 pages, 6 figures", "summary": "In times of epidemics, swift reaction is necessary to mitigate epidemic\nspreading. For this reaction, localized approaches have several advantages,\nlimiting necessary resources and reducing the impact of interventions on a\nlarger scale. However, training a separate machine learning (ML) model on a\nlocal scale is often not feasible due to limited available data. Centralizing\nthe data is also challenging because of its high sensitivity and privacy\nconstraints. In this study, we consider a localized strategy based on the\nGerman counties and communities managed by the related local health authorities\n(LHA). For the preservation of privacy to not oppose the availability of\ndetailed situational data, we propose a privacy-preserving forecasting method\nthat can assist public health experts and decision makers. ML methods with\nfederated learning (FL) train a shared model without centralizing raw data.\nConsidering the counties, communities or LHAs as clients and finding a balance\nbetween utility and privacy, we study a FL framework with client-level\ndifferential privacy (DP). We train a shared multilayer perceptron on sliding\nwindows of recent case counts to forecast the number of cases, while clients\nexchange only norm-clipped updates and the server aggregated updates with DP\nnoise. We evaluate the approach on COVID-19 data on county-level during two\nphases. As expected, very strict privacy yields unstable, unusable forecasts.\nAt a moderately strong level, the DP model closely approaches the non-DP model:\n$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in\nNovember 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,\nclient-level DP-FL can deliver useful county-level predictions with strong\nprivacy guarantees, and viable privacy budgets depend on epidemic phase,\nallowing privacy-compliant collaboration among health authorities for local\nforecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u548c\u5dee\u5206\u9690\u79c1\u7684\u9690\u79c1\u4fdd\u62a4\u9884\u6d4b\u65b9\u6cd5\u7528\u4e8e\u75ab\u60c5\u75c5\u4f8b\u9884\u6d4b\uff0c\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u5728\u4fdd\u8bc1\u9690\u79c1\u524d\u63d0\u4e0b\u63d0\u4f9b\u6709\u7528\u7684\u53bf\u7ea7\u9884\u6d4b\u3002", "motivation": "\u75ab\u60c5\u671f\u95f4\u672c\u5730\u5316\u53cd\u5e94\u6709\u4f18\u52bf\uff0c\u4f46\u672c\u5730\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u56e0\u6570\u636e\u6709\u9650\u4e0d\u53ef\u884c\uff0c\u96c6\u4e2d\u6570\u636e\u53c8\u53d7\u9690\u79c1\u9650\u5236\uff0c\u9700\u4fdd\u62a4\u9690\u79c1\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5fb7\u56fd\u53bf\u548c\u793e\u533a\u7684\u672c\u5730\u5316\u7b56\u7565\uff0c\u91c7\u7528\u5e26\u5ba2\u6237\u7aef\u5dee\u5206\u9690\u79c1\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3\u5171\u4eab\u591a\u5c42\u611f\u77e5\u5668\u9884\u6d4b\u75c5\u4f8b\u6570\uff0c\u5ba2\u6237\u7aef\u4ea4\u6362\u8303\u6570\u88c1\u526a\u66f4\u65b0\uff0c\u670d\u52a1\u5668\u805a\u5408\u5e26\u5dee\u5206\u9690\u79c1\u566a\u58f0\u7684\u66f4\u65b0\u3002", "result": "\u5728\u4e24\u4e2a\u9636\u6bb5\u7684\u53bf\u7ea7COVID - 19\u6570\u636e\u4e0a\u8bc4\u4f30\uff0c\u6781\u5f3a\u9690\u79c1\u4e0b\u9884\u6d4b\u4e0d\u7a33\u5b9a\uff0c\u9002\u5ea6\u5f3a\u9690\u79c1\u4e0b\uff0cDP\u6a21\u578b\u63a5\u8fd1\u975eDP\u6a21\u578b\u3002", "conclusion": "\u5ba2\u6237\u7aef\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60\u80fd\u5728\u5f3a\u9690\u79c1\u4fdd\u8bc1\u4e0b\u63d0\u4f9b\u6709\u7528\u7684\u53bf\u7ea7\u9884\u6d4b\uff0c\u53ef\u884c\u7684\u9690\u79c1\u9884\u7b97\u53d6\u51b3\u4e8e\u75ab\u60c5\u9636\u6bb5\uff0c\u53ef\u5b9e\u73b0\u536b\u751f\u90e8\u95e8\u95f4\u7b26\u5408\u9690\u79c1\u89c4\u5b9a\u7684\u672c\u5730\u9884\u6d4b\u5408\u4f5c\u3002"}}
{"id": "2509.13365", "pdf": "https://arxiv.org/pdf/2509.13365", "abs": "https://arxiv.org/abs/2509.13365", "authors": ["Brian D. Earp", "Haotian Yuan", "Julian Koplin", "Sebastian Porsdam Mann"], "title": "The Provenance Problem: LLMs and the Breakdown of Citation Norms", "categories": ["cs.CY", "cs.AI"], "comment": "9 pages", "summary": "The increasing use of generative AI in scientific writing raises urgent\nquestions about attribution and intellectual credit. When a researcher employs\nChatGPT to draft a manuscript, the resulting text may echo ideas from sources\nthe author has never encountered. If an AI system reproduces insights from, for\nexample, an obscure 1975 paper without citation, does this constitute\nplagiarism? We argue that such cases exemplify the 'provenance problem': a\nsystematic breakdown in the chain of scholarly credit. Unlike conventional\nplagiarism, this phenomenon does not involve intent to deceive (researchers may\ndisclose AI use and act in good faith) yet still benefit from the uncredited\nintellectual contributions of others. This dynamic creates a novel category of\nattributional harm that current ethical and professional frameworks fail to\naddress. As generative AI becomes embedded across disciplines, the risk that\nsignificant ideas will circulate without recognition threatens both the\nreputational economy of science and the demands of epistemic justice. This\nPerspective analyzes how AI challenges established norms of authorship,\nintroduces conceptual tools for understanding the provenance problem, and\nproposes strategies to preserve integrity and fairness in scholarly\ncommunication.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u7528\u4e8e\u79d1\u7814\u5199\u4f5c\u5f15\u53d1\u5f52\u5c5e\u548c\u5b66\u672f\u4fe1\u7528\u95ee\u9898\uff0c\u5b58\u5728\u51fa\u5904\u95ee\u9898\uff0c\u5f53\u524d\u6846\u67b6\u65e0\u6cd5\u89e3\u51b3\uff0c\u6587\u7ae0\u5206\u6790\u6311\u6218\u5e76\u63d0\u51fa\u7b56\u7565\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u79d1\u7814\u5199\u4f5c\u4e2d\u7684\u4f7f\u7528\u65e5\u76ca\u589e\u52a0\uff0c\u5f15\u53d1\u5f52\u5c5e\u548c\u5b66\u672f\u4fe1\u7528\u7684\u7d27\u8feb\u95ee\u9898\uff0c\u5f53\u524d\u4f26\u7406\u548c\u4e13\u4e1a\u6846\u67b6\u65e0\u6cd5\u5e94\u5bf9\u65b0\u7684\u5f52\u5c5e\u4f24\u5bb3\u3002", "method": "\u5206\u6790AI\u5bf9\u65e2\u5b9a\u4f5c\u8005\u89c4\u8303\u7684\u6311\u6218\uff0c\u5f15\u5165\u6982\u5ff5\u5de5\u5177\u7406\u89e3\u51fa\u5904\u95ee\u9898\u3002", "result": "\u6307\u51fa\u4f7f\u7528\u751f\u6210\u5f0fAI\u5199\u4f5c\u5b58\u5728\u4e0d\u6d89\u53ca\u6b3a\u9a97\u610f\u56fe\u4f46\u4ecd\u53d7\u76ca\u4e8e\u4ed6\u4eba\u672a\u83b7\u8ba4\u53ef\u667a\u529b\u8d21\u732e\u7684\u51fa\u5904\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7ef4\u62a4\u5b66\u672f\u4ea4\u6d41\u5b8c\u6574\u6027\u548c\u516c\u5e73\u6027\u7684\u7b56\u7565\u3002"}}
{"id": "2509.14029", "pdf": "https://arxiv.org/pdf/2509.14029", "abs": "https://arxiv.org/abs/2509.14029", "authors": ["Samuel Tovey", "Julian Ho\u00dfbach", "Sandro Kuppel", "Tobias Ensslen", "Jan C. Behrends", "Christian Holm"], "title": "Deep Learning-Driven Peptide Classification in Biological Nanopores", "categories": ["cs.LG", "eess.SP", "physics.comp-ph", "q-bio.BM"], "comment": "29 pages (incl. references) 7 figures", "summary": "A device capable of performing real time classification of proteins in a\nclinical setting would allow for inexpensive and rapid disease diagnosis. One\nsuch candidate for this technology are nanopore devices. These devices work by\nmeasuring a current signal that arises when a protein or peptide enters a\nnanometer-length-scale pore. Should this current be uniquely related to the\nstructure of the peptide and its interactions with the pore, the signals can be\nused to perform identification. While such a method would allow for real time\nidentification of peptides and proteins in a clinical setting, to date, the\ncomplexities of these signals limit their accuracy. In this work, we tackle the\nissue of classification by converting the current signals into scaleogram\nimages via wavelet transforms, capturing amplitude, frequency, and time\ninformation in a modality well-suited to machine learning algorithms. When\ntested on 42 peptides, our method achieved a classification accuracy of\n~$81\\,\\%$, setting a new state-of-the-art in the field and taking a step toward\npractical peptide/protein diagnostics at the point of care. In addition, we\ndemonstrate model transfer techniques that will be critical when deploying\nthese models into real hardware, paving the way to a new method for real-time\ndisease diagnosis.", "AI": {"tldr": "\u672c\u6587\u5c06\u7eb3\u7c73\u5b54\u8bbe\u5907\u7535\u6d41\u4fe1\u53f7\u8f6c\u6362\u4e3a\u5c3a\u5ea6\u56fe\u56fe\u50cf\u8fdb\u884c\u86cb\u767d\u8d28\u5206\u7c7b\uff0c\u572842\u79cd\u80bd\u4e0a\u5b9e\u73b0\u7ea681%\u51c6\u786e\u7387\uff0c\u63a8\u52a8\u5373\u65f6\u8bca\u65ad\u3002", "motivation": "\u73b0\u6709\u7eb3\u7c73\u5b54\u8bbe\u5907\u8fdb\u884c\u86cb\u767d\u8d28\u5b9e\u65f6\u5206\u7c7b\u65f6\u4fe1\u53f7\u590d\u6742\uff0c\u9650\u5236\u4e86\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u9700\u63d0\u9ad8\u5206\u7c7b\u7cbe\u5ea6\u4ee5\u5b9e\u73b0\u4e34\u5e8a\u5ec9\u4ef7\u5feb\u901f\u75be\u75c5\u8bca\u65ad\u3002", "method": "\u901a\u8fc7\u5c0f\u6ce2\u53d8\u6362\u5c06\u7535\u6d41\u4fe1\u53f7\u8f6c\u6362\u4e3a\u5c3a\u5ea6\u56fe\u56fe\u50cf\uff0c\u5229\u7528\u9002\u5408\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u65b9\u5f0f\u6355\u6349\u5e45\u5ea6\u3001\u9891\u7387\u548c\u65f6\u95f4\u4fe1\u606f\uff1b\u8fd8\u5c55\u793a\u4e86\u6a21\u578b\u8fc1\u79fb\u6280\u672f\u3002", "result": "\u572842\u79cd\u80bd\u4e0a\u6d4b\u8bd5\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u7ea6\u4e3a81%\uff0c\u521b\u9020\u4e86\u8be5\u9886\u57df\u65b0\u7684\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5411\u5373\u65f6\u62a4\u7406\u4e2d\u7684\u80bd/\u86cb\u767d\u8d28\u8bca\u65ad\u8fc8\u51fa\u4e00\u6b65\uff0c\u6a21\u578b\u8fc1\u79fb\u6280\u672f\u4e3a\u5b9e\u65f6\u75be\u75c5\u8bca\u65ad\u65b0\u65b9\u6cd5\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2509.13372", "pdf": "https://arxiv.org/pdf/2509.13372", "abs": "https://arxiv.org/abs/2509.13372", "authors": ["Prahlad G Menon"], "title": "Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.ET", "q-bio.QM", "92C50, 68T07, 76D05, 65D18, 92C55", "I.4.6; I.4.8; J.3; I.2.10; I.4.9"], "comment": null, "summary": "Fontan palliation for univentricular congenital heart disease progresses to\nhemodynamic failure with complex flow patterns poorly characterized by\nconventional 2D imaging. Current assessment relies on fluoroscopic angiography,\nproviding limited 3D geometric information essential for computational fluid\ndynamics (CFD) analysis and surgical planning.\n  A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash\n(2.5B parameters) for systematic, iterative processing of fluoroscopic\nangiograms through transformer-based neural architecture. The pipeline\nencompasses medical image preprocessing, vascular segmentation, contrast\nenhancement, artifact removal, and virtual hemodynamic flow visualization\nwithin 2D projections. Final views were processed through Tencent's\nHunyuan3D-2mini (384M parameters) for stereolithography file generation.\n  The pipeline successfully generated geometrically optimized 2D projections\nfrom single-view angiograms after 16 processing steps using a custom web\ninterface. Initial iterations contained hallucinated vascular features\nrequiring iterative refinement to achieve anatomically faithful\nrepresentations. Final projections demonstrated accurate preservation of\ncomplex Fontan geometry with enhanced contrast suitable for 3D conversion.\nAI-generated virtual flow visualization identified stagnation zones in central\nconnections and flow patterns in branch arteries. Complete processing required\nunder 15 minutes with second-level API response times.\n  This approach demonstrates clinical feasibility of generating CFD-suitable\ngeometries from routine angiographic data, enabling 3D generation and rapid\nvirtual flow visualization for cursory insights prior to full CFD simulation.\nWhile requiring refinement cycles for accuracy, this establishes foundation for\ndemocratizing advanced geometric and hemodynamic analysis using readily\navailable imaging data.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u591a\u6b65AI\u7ba1\u9053\u5904\u7406\u5fc3\u810f\u9020\u5f71\u56fe\u50cf\uff0c\u751f\u6210\u9002\u5408CFD\u5206\u6790\u7684\u51e0\u4f55\u7ed3\u6784\u53ca\u865a\u62df\u8840\u6d41\u53ef\u89c6\u5316\uff0c\u8bc1\u660e\u4e86\u4e34\u5e8a\u53ef\u884c\u6027\u3002", "motivation": "\u4f20\u7edf2D\u6210\u50cf\u96be\u4ee5\u8868\u5f81Fontan\u59d1\u606f\u6cbb\u7597\u540e\u590d\u6742\u8840\u6d41\u6a21\u5f0f\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u63d0\u4f9b\u76843D\u51e0\u4f55\u4fe1\u606f\u6709\u9650\uff0c\u65e0\u6cd5\u6ee1\u8db3CFD\u5206\u6790\u548c\u624b\u672f\u89c4\u5212\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u591a\u6b65AI\u7ba1\u9053\uff0c\u5229\u7528Google\u7684Gemini 2.5 Flash\u5904\u7406\u8840\u7ba1\u9020\u5f71\u56fe\u50cf\uff0c\u7ecf\u591a\u6b65\u9aa4\u5904\u7406\u540e\u7528Tencent\u7684Hunyuan3D - 2mini\u751f\u6210\u7acb\u4f53\u5149\u523b\u6587\u4ef6\u3002", "result": "\u7ba1\u9053\u7ecf16\u6b65\u5904\u7406\u4ece\u5355\u89c6\u56fe\u8840\u7ba1\u9020\u5f71\u6210\u529f\u751f\u6210\u51e0\u4f55\u4f18\u5316\u76842D\u6295\u5f71\uff0c\u80fd\u51c6\u786e\u4fdd\u7559\u590d\u6742\u51e0\u4f55\u7ed3\u6784\u548c\u589e\u5f3a\u5bf9\u6bd4\u5ea6\uff0c\u8bc6\u522b\u8840\u6d41\u505c\u6ede\u533a\u548c\u6a21\u5f0f\uff0c\u5904\u7406\u65f6\u95f4\u4e0d\u523015\u5206\u949f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u4e34\u5e8a\u53ef\u884c\u6027\uff0c\u867d\u9700\u8fed\u4ee3\u4f18\u5316\uff0c\u4f46\u4e3a\u5229\u7528\u73b0\u6709\u6210\u50cf\u6570\u636e\u8fdb\u884c\u9ad8\u7ea7\u51e0\u4f55\u548c\u8840\u6d41\u52a8\u529b\u5b66\u5206\u6790\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.14061", "pdf": "https://arxiv.org/pdf/2509.14061", "abs": "https://arxiv.org/abs/2509.14061", "authors": ["Chiara De Luca", "Elisa Donati"], "title": "Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Queen bee presence is essential for the health and stability of honeybee\ncolonies, yet current monitoring methods rely on manual inspections that are\nlabor-intensive, disruptive, and impractical for large-scale beekeeping. While\nrecent audio-based approaches have shown promise, they often require high power\nconsumption, complex preprocessing, and are susceptible to ambient noise. To\novercome these limitations, we propose a lightweight, multimodal system for\nqueen detection based on environmental sensor fusion-specifically, temperature,\nhumidity, and pressure differentials between the inside and outside of the\nhive. Our approach employs quantized decision tree inference on a commercial\nSTM32 microcontroller, enabling real-time, low-power edge computing without\ncompromising accuracy. We show that our system achieves over 99% queen\ndetection accuracy using only environmental inputs, with audio features\noffering no significant performance gain. This work presents a scalable and\nsustainable solution for non-invasive hive monitoring, paving the way for\nautonomous, precision beekeeping using off-the-shelf, energy-efficient\nhardware.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u73af\u5883\u4f20\u611f\u5668\u878d\u5408\u7684\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u8702\u738b\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5728STM32\u5fae\u63a7\u5236\u5668\u5b9e\u73b0\u4f4e\u529f\u8017\u8fb9\u7f18\u8ba1\u7b97\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u8d8599%\uff0c\u4e3a\u517b\u8702\u76d1\u6d4b\u63d0\u4f9b\u53ef\u6269\u5c55\u53ef\u6301\u7eed\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u8702\u738b\u76d1\u6d4b\u65b9\u6cd5\u5b58\u5728\u52b3\u52a8\u5bc6\u96c6\u3001\u5e72\u6270\u5927\u3001\u529f\u8017\u9ad8\u3001\u6613\u53d7\u73af\u5883\u566a\u58f0\u5f71\u54cd\u7b49\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u76d1\u6d4b\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u73af\u5883\u4f20\u611f\u5668\u878d\u5408\uff08\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u538b\u529b\u5dee\uff09\uff0c\u5728\u5546\u7528STM32\u5fae\u63a7\u5236\u5668\u4e0a\u91c7\u7528\u91cf\u5316\u51b3\u7b56\u6811\u63a8\u7406\u3002", "result": "\u4ec5\u4f7f\u7528\u73af\u5883\u8f93\u5165\uff0c\u7cfb\u7edf\u8702\u738b\u68c0\u6d4b\u51c6\u786e\u7387\u8d8599%\uff0c\u97f3\u9891\u7279\u5f81\u65e0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u975e\u4fb5\u5165\u5f0f\u8702\u5de2\u76d1\u6d4b\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u53ef\u6301\u7eed\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u7cbe\u51c6\u517b\u8702\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.13375", "pdf": "https://arxiv.org/pdf/2509.13375", "abs": "https://arxiv.org/abs/2509.13375", "authors": ["Yuxiao Lee", "Xiaofeng Cao", "Wei Ye", "Jiangchao Yao", "Jingkuan Song", "Heng Tao Shen"], "title": "An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable\nzero-shot out-of-distribution (OOD) detection capabilities, vital for reliable\nAI systems. Despite this promising capability, a comprehensive understanding of\n(1) why they work so effectively, (2) what advantages do they have over\nsingle-modal methods, and (3) how is their behavioral robustness -- remains\nnotably incomplete within the research community. This paper presents a\nsystematic empirical analysis of VLM-based OOD detection using in-distribution\n(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and\nformalize key operational properties within the VLM embedding space that\nfacilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the\nsuperiority of these models over established single-modal approaches,\nattributing this distinct advantage to the VLM's capacity to leverage rich\nsemantic novelty. (3) Sensitivity: We uncovers a significant and previously\nunder-explored asymmetry in their robustness profile: while exhibiting\nresilience to common image noise, these VLM-based methods are highly sensitive\nto prompt phrasing. Our findings contribute a more structured understanding of\nthe strengths and critical vulnerabilities inherent in VLM-based OOD detection,\noffering crucial, empirically-grounded guidance for developing more robust and\nreliable future designs.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u96f6\u6837\u672c\u5206\u5e03\u5916\uff08OOD\uff09\u68c0\u6d4b\u8fdb\u884c\u7cfb\u7edf\u5b9e\u8bc1\u5206\u6790\uff0c\u63ed\u793a\u5176\u673a\u5236\u3001\u4f18\u52bf\u4e0e\u654f\u611f\u6027\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u5bf9VLM\u5728OOD\u68c0\u6d4b\u4e2d\u4e3a\u4f55\u6709\u6548\u3001\u4e0e\u5355\u6a21\u6001\u65b9\u6cd5\u76f8\u6bd4\u7684\u4f18\u52bf\u4ee5\u53ca\u884c\u4e3a\u9c81\u68d2\u6027\u7f3a\u4e4f\u5168\u9762\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u5206\u5e03\u5185\uff08ID\uff09\u548c\u5206\u5e03\u5916\uff08OOD\uff09\u63d0\u793a\u5bf9\u57fa\u4e8eVLM\u7684OOD\u68c0\u6d4b\u8fdb\u884c\u7cfb\u7edf\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u660e\u786eVLM\u5d4c\u5165\u7a7a\u95f4\u4fc3\u8fdb\u96f6\u6837\u672cOOD\u68c0\u6d4b\u7684\u5173\u952e\u7279\u6027\uff0c\u91cf\u5316\u5176\u76f8\u5bf9\u5355\u6a21\u6001\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u53d1\u73b0\u5176\u5bf9\u56fe\u50cf\u566a\u58f0\u6709\u4e00\u5b9a\u6297\u6027\u4f46\u5bf9\u63d0\u793a\u63aa\u8f9e\u654f\u611f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u57fa\u4e8eVLM\u7684OOD\u68c0\u6d4b\u7684\u4f18\u52bf\u548c\u5173\u952e\u5f31\u70b9\u63d0\u4f9b\u4e86\u66f4\u7ed3\u6784\u5316\u7684\u7406\u89e3\uff0c\u4e3a\u672a\u6765\u8bbe\u8ba1\u66f4\u9c81\u68d2\u53ef\u9760\u7684\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5b9e\u8bc1\u7684\u6307\u5bfc\u3002"}}
{"id": "2509.14077", "pdf": "https://arxiv.org/pdf/2509.14077", "abs": "https://arxiv.org/abs/2509.14077", "authors": ["Yuhao Wang", "Enlu Zhou"], "title": "Online Bayesian Risk-Averse Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we study the Bayesian risk-averse formulation in reinforcement\nlearning (RL). To address the epistemic uncertainty due to a lack of data, we\nadopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the\nparameter uncertainty of the unknown underlying model. We derive the asymptotic\nnormality that characterizes the difference between the Bayesian risk value\nfunction and the original value function under the true unknown distribution.\nThe results indicate that the Bayesian risk-averse approach tends to\npessimistically underestimate the original value function. This discrepancy\nincreases with stronger risk aversion and decreases as more data become\navailable. We then utilize this adaptive property in the setting of online RL\nas well as online contextual multi-arm bandits (CMAB), a special case of online\nRL. We provide two procedures using posterior sampling for both the general RL\nproblem and the CMAB problem. We establish a sub-linear regret bound, with the\nregret defined as the conventional regret for both the RL and CMAB settings.\nAdditionally, we establish a sub-linear regret bound for the CMAB setting with\nthe regret defined as the Bayesian risk regret. Finally, we conduct numerical\nexperiments to demonstrate the effectiveness of the proposed algorithm in\naddressing epistemic uncertainty and verifying the theoretical properties.", "AI": {"tldr": "\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u4e2d\u8d1d\u53f6\u65af\u98ce\u9669\u89c4\u907f\u516c\u5f0f\uff0c\u63a8\u5bfc\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u63d0\u51fa\u540e\u9a8c\u91c7\u6837\u7a0b\u5e8f\uff0c\u5efa\u7acb\u6b21\u7ebf\u6027\u9057\u61be\u754c\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u56e0\u6570\u636e\u4e0d\u8db3\u5bfc\u81f4\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u98ce\u9669\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5904\u7406\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u63a8\u5bfc\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u5229\u7528\u81ea\u9002\u5e94\u7279\u6027\u63d0\u51fa\u540e\u9a8c\u91c7\u6837\u7a0b\u5e8f\u3002", "result": "\u8d1d\u53f6\u65af\u98ce\u9669\u89c4\u907f\u65b9\u6cd5\u503e\u5411\u4e8e\u60b2\u89c2\u4f4e\u4f30\u539f\u4ef7\u503c\u51fd\u6570\uff0c\u5efa\u7acb\u6b21\u7ebf\u6027\u9057\u61be\u754c\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u80fd\u6709\u6548\u5904\u7406\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u7406\u8bba\u6027\u8d28\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2509.13380", "pdf": "https://arxiv.org/pdf/2509.13380", "abs": "https://arxiv.org/abs/2509.13380", "authors": ["Alejandro D. Mousist"], "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "comment": "This preprint presents ASTREA, a multi-agent architecture combining\n  LLM-guided semantic modulation with reinforcement learning for autonomous\n  satellite operations. The system is validated in hardware orbital\n  environments", "summary": "This paper presents ASTREA, the first agentic system deployed on\nflight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using\nthermal control as a representative use case, we integrate a\nresource-constrained Large Language Model (LLM) agent with a reinforcement\nlearning controller in an asynchronous architecture tailored for\nspace-qualified platforms. Ground experiments show that LLM-guided supervision\nimproves thermal stability and reduces violations, confirming the feasibility\nof combining semantic reasoning with adaptive control under hardware\nconstraints. However, on-orbit validation aboard the International Space\nStation (ISS) reveals performance degradation caused by inference latency\nmismatched with the rapid thermal cycles characteristic of Low Earth Orbit\n(LEO) satellites. These results highlight both the opportunities and current\nlimitations of agentic LLM-based systems in real flight environments, providing\npractical design guidelines for future space autonomy.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u9996\u4e2a\u90e8\u7f72\u5728\u98de\u884c\u9a8c\u8bc1\u786c\u4ef6\u4e0a\u7528\u4e8e\u81ea\u4e3b\u822a\u5929\u5668\u64cd\u4f5c\u7684\u4ee3\u7406\u7cfb\u7edfASTREA\uff0c\u901a\u8fc7\u70ed\u63a7\u7528\u4f8b\u5b9e\u9a8c\uff0c\u5c55\u793a\u5176\u5728\u5730\u9762\u548c\u5728\u8f68\u8868\u73b0\uff0c\u6307\u51fa\u673a\u9047\u4e0e\u5c40\u9650\u5e76\u7ed9\u51fa\u8bbe\u8ba1\u6307\u5357\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u98de\u884c\u9a8c\u8bc1\u786c\u4ef6\u7684\u81ea\u4e3b\u822a\u5929\u5668\u64cd\u4f5c\u4ee3\u7406\u7cfb\u7edf\uff0c\u63a2\u7d22\u8bed\u4e49\u63a8\u7406\u4e0e\u81ea\u9002\u5e94\u63a7\u5236\u5728\u786c\u4ef6\u7ea6\u675f\u4e0b\u7ed3\u5408\u7684\u53ef\u884c\u6027\u3002", "method": "\u4ee5\u70ed\u63a7\u4e3a\u7528\u4f8b\uff0c\u5c06\u8d44\u6e90\u53d7\u9650\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u4e0e\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u96c6\u6210\u5728\u9002\u7528\u4e8e\u822a\u5929\u5e73\u53f0\u7684\u5f02\u6b65\u67b6\u6784\u4e2d\u3002", "result": "\u5730\u9762\u5b9e\u9a8c\u663e\u793aLLM\u5f15\u5bfc\u7684\u76d1\u7763\u63d0\u9ad8\u70ed\u7a33\u5b9a\u6027\u5e76\u51cf\u5c11\u8fdd\u89c4\uff1b\u5728\u8f68\u9a8c\u8bc1\u4e2d\uff0c\u56e0\u63a8\u7406\u5ef6\u8fdf\u4e0e\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u5feb\u901f\u70ed\u5faa\u73af\u4e0d\u5339\u914d\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u51f8\u663e\u57fa\u4e8e\u4ee3\u7406\u7684LLM\u7cfb\u7edf\u5728\u5b9e\u9645\u98de\u884c\u73af\u5883\u4e2d\u7684\u673a\u9047\u548c\u5f53\u524d\u5c40\u9650\uff0c\u4e3a\u672a\u6765\u592a\u7a7a\u81ea\u4e3b\u63d0\u4f9b\u5b9e\u7528\u8bbe\u8ba1\u6307\u5357\u3002"}}
{"id": "2509.14078", "pdf": "https://arxiv.org/pdf/2509.14078", "abs": "https://arxiv.org/abs/2509.14078", "authors": ["Robiul Islam", "Dmitry I. Ignatov", "Karl Kaberg", "Roman Nabatchikov"], "title": "Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques", "categories": ["cs.LG"], "comment": null, "summary": "This study investigates classifier performance across EEG frequency bands\nusing various optimizers and evaluates efficient class prediction for the left\nand right hemispheres. Three neural network architectures - a deep dense\nnetwork, a shallow three-layer network, and a convolutional neural network\n(CNN) - are implemented and compared using the TensorFlow and PyTorch\nframeworks. Results indicate that the Adagrad and RMSprop optimizers\nconsistently perform well across different frequency bands, with Adadelta\nexhibiting robust performance in cross-model evaluations. Specifically, Adagrad\nexcels in the beta band, while RMSprop achieves superior performance in the\ngamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among\nthe models, the CNN demonstrates the second highest accuracy, particularly in\ncapturing spatial features of EEG data. The deep dense network shows\ncompetitive performance in learning complex patterns, whereas the shallow\nthree-layer network, sometimes being less accurate, provides computational\nefficiency. SHAP (Shapley Additive Explanations) plots are employed to identify\nefficient class prediction, revealing nuanced contributions of EEG frequency\nbands to model accuracy. Overall, the study highlights the importance of\noptimizer selection, model architecture, and EEG frequency band analysis in\nenhancing classifier performance and understanding feature importance in\nneuroimaging-based classification tasks.", "AI": {"tldr": "\u7814\u7a76\u7528\u4e0d\u540c\u4f18\u5316\u5668\u8bc4\u4f30EEG\u9891\u5e26\u5206\u7c7b\u5668\u6027\u80fd\uff0c\u6bd4\u8f83\u4e09\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u6307\u51fa\u4f18\u5316\u5668\u3001\u6a21\u578b\u67b6\u6784\u548c\u9891\u5e26\u5206\u6790\u5bf9\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u91cd\u8981\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u4f18\u5316\u5668\u4e0bEEG\u9891\u5e26\u7684\u5206\u7c7b\u5668\u6027\u80fd\uff0c\u8bc4\u4f30\u5de6\u53f3\u534a\u7403\u7684\u6709\u6548\u7c7b\u522b\u9884\u6d4b\u3002", "method": "\u5b9e\u73b0\u4e09\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff08\u6df1\u5ea6\u5bc6\u96c6\u7f51\u7edc\u3001\u6d45\u5c42\u4e09\u5c42\u7f51\u7edc\u548cCNN\uff09\uff0c\u7528TensorFlow\u548cPyTorch\u6846\u67b6\u6bd4\u8f83\uff0c\u4f7f\u7528SHAP\u56fe\u8bc6\u522b\u6709\u6548\u7c7b\u522b\u9884\u6d4b\u3002", "result": "Adagrad\u548cRMSprop\u5728\u4e0d\u540c\u9891\u5e26\u8868\u73b0\u597d\uff0cAdadelta\u8de8\u6a21\u578b\u8bc4\u4f30\u8868\u73b0\u7a33\u5065\uff1bCNN\u7cbe\u5ea6\u7b2c\u4e8c\uff0c\u6df1\u5ea6\u5bc6\u96c6\u7f51\u7edc\u5b66\u4e60\u590d\u6742\u6a21\u5f0f\u6709\u7ade\u4e89\u529b\uff0c\u6d45\u5c42\u4e09\u5c42\u7f51\u7edc\u8ba1\u7b97\u9ad8\u6548\u3002", "conclusion": "\u4f18\u5316\u5668\u9009\u62e9\u3001\u6a21\u578b\u67b6\u6784\u548cEEG\u9891\u5e26\u5206\u6790\u5bf9\u63d0\u5347\u5206\u7c7b\u5668\u6027\u80fd\u548c\u7406\u89e3\u7279\u5f81\u91cd\u8981\u6027\u5f88\u5173\u952e\u3002"}}
{"id": "2509.13387", "pdf": "https://arxiv.org/pdf/2509.13387", "abs": "https://arxiv.org/abs/2509.13387", "authors": ["Delaram Golpayegani", "Marta Lasek-Markey", "Arjumand Younus", "Aphra Kerr", "Dave Lewis"], "title": "Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The upsurge of policies and guidelines that aim to ensure Artificial\nIntelligence (AI) systems are safe and trustworthy has led to a fragmented\nlandscape of AI governance. The European Union (EU) is a key actor in the\ndevelopment of such policies and guidelines. Its High-Level Expert Group (HLEG)\nissued an influential set of guidelines for trustworthy AI, followed in 2024 by\nthe adoption of the EU AI Act. While the EU policies and guidelines are\nexpected to be aligned, they may differ in their scope, areas of emphasis,\ndegrees of normativity, and priorities in relation to AI. To gain a broad\nunderstanding of AI governance from the EU perspective, we leverage qualitative\nthematic analysis approaches to uncover prevalent themes in key EU documents,\nincluding the AI Act and the HLEG Ethics Guidelines. We further employ\nquantitative topic modelling approaches, specifically through the use of the\nBERTopic model, to enhance the results and increase the document sample to\ninclude EU AI policy documents published post-2018. We present a novel\nperspective on EU policies, tracking the evolution of its approach to\naddressing AI governance.", "AI": {"tldr": "\u672c\u6587\u7528\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u6cd5\u5206\u6790\u6b27\u76dfAI\u6cbb\u7406\u653f\u7b56\u6587\u4ef6\uff0c\u5448\u73b0\u6b27\u76dfAI\u6cbb\u7406\u653f\u7b56\u6f14\u53d8\u89c6\u89d2\u3002", "motivation": "\u6b27\u76dfAI\u6cbb\u7406\u653f\u7b56\u548c\u6307\u5357\u96f6\u6563\uff0c\u867d\u671f\u671b\u4e00\u81f4\u4f46\u5b58\u5728\u5dee\u5f02\uff0c\u4e3a\u5168\u9762\u4e86\u89e3\u6b27\u76dfAI\u6cbb\u7406\u3002", "method": "\u8fd0\u7528\u5b9a\u6027\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\u7814\u7a76\u5173\u952e\u6587\u4ef6\uff0c\u7528BERTopic\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u4e3b\u9898\u5efa\u6a21\uff0c\u589e\u52a02018\u5e74\u540e\u6587\u4ef6\u6837\u672c\u3002", "result": "\u5448\u73b0\u4e86\u5bf9\u6b27\u76df\u653f\u7b56\u7684\u65b0\u89c6\u89d2\uff0c\u8ffd\u8e2a\u5176\u89e3\u51b3AI\u6cbb\u7406\u65b9\u6cd5\u7684\u6f14\u53d8\u3002", "conclusion": "\u901a\u8fc7\u5b9a\u6027\u548c\u5b9a\u91cf\u7ed3\u5408\u65b9\u6cd5\u80fd\u6709\u6548\u5206\u6790\u6b27\u76dfAI\u6cbb\u7406\u653f\u7b56\u6f14\u53d8\u3002"}}
{"id": "2509.14113", "pdf": "https://arxiv.org/pdf/2509.14113", "abs": "https://arxiv.org/abs/2509.14113", "authors": ["Alessandro Brusaferri", "Danial Ramin", "Andrea Ballarino"], "title": "From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting", "categories": ["cs.LG"], "comment": "6 pages", "summary": "While neural networks are achieving high predictive accuracy in multi-horizon\nprobabilistic forecasting, understanding the underlying mechanisms that lead to\nfeature-conditioned outputs remains a significant challenge for forecasters. In\nthis work, we take a further step toward addressing this critical issue by\nintroducing the Quantile Neural Basis Model, which incorporates the\ninterpretability principles of Quantile Generalized Additive Models into an\nend-to-end neural network training framework. To this end, we leverage shared\nbasis decomposition and weight factorization, complementing Neural Models for\nLocation, Scale, and Shape by avoiding any parametric distributional\nassumptions. We validate our approach on day-ahead electricity price\nforecasting, achieving predictive performance comparable to distributional and\nquantile regression neural networks, while offering valuable insights into\nmodel behavior through the learned nonlinear mappings from input features to\noutput predictions across the horizon.", "AI": {"tldr": "\u5f15\u5165\u5206\u4f4d\u6570\u795e\u7ecf\u57fa\u6a21\u578b\u89e3\u51b3\u591a\u6b65\u6982\u7387\u9884\u6d4b\u4e2d\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u6761\u4ef6\u8f93\u51fa\u673a\u5236\u7406\u89e3\u96be\u9898\uff0c\u5728\u7535\u4ef7\u9884\u6d4b\u4e2d\u9a8c\u8bc1\u6548\u679c\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u6b65\u6982\u7387\u9884\u6d4b\u4e2d\u867d\u7cbe\u5ea6\u9ad8\uff0c\u4f46\u7406\u89e3\u7279\u5f81\u6761\u4ef6\u8f93\u51fa\u7684\u6f5c\u5728\u673a\u5236\u662f\u91cd\u5927\u6311\u6218\u3002", "method": "\u5f15\u5165\u5206\u4f4d\u6570\u795e\u7ecf\u57fa\u6a21\u578b\uff0c\u5c06\u5206\u4f4d\u6570\u5e7f\u4e49\u53ef\u52a0\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u539f\u5219\u878d\u5165\u7aef\u5230\u7aef\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6846\u67b6\uff0c\u5229\u7528\u5171\u4eab\u57fa\u5206\u89e3\u548c\u6743\u91cd\u56e0\u5b50\u5206\u89e3\uff0c\u907f\u514d\u53c2\u6570\u5206\u5e03\u5047\u8bbe\u3002", "result": "\u5728\u65e5\u524d\u7535\u4ef7\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u4e0e\u5206\u5e03\u548c\u5206\u4f4d\u6570\u56de\u5f52\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5b9e\u73b0\u53ef\u6bd4\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u80fd\u901a\u8fc7\u5b66\u4e60\u7684\u975e\u7ebf\u6027\u6620\u5c04\u4e3a\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.13388", "pdf": "https://arxiv.org/pdf/2509.13388", "abs": "https://arxiv.org/abs/2509.13388", "authors": ["Yadvendra Gurjar", "Ruoni Wan", "Ehsan Farahbakhsh", "Rohitash Chandra"], "title": "Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji", "categories": ["cs.CV", "cs.AI", "stat.AP"], "comment": null, "summary": "As a developing country, Fiji is facing rapid urbanisation, which is visible\nin the massive development projects that include housing, roads, and civil\nworks. In this study, we present machine learning and remote sensing frameworks\nto compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The\nultimate goal of this study is to provide technical support in land cover/land\nuse modelling and change detection. We used Landsat-8 satellite image for the\nstudy region and created our training dataset with labels for supervised\nmachine learning. We used Google Earth Engine and unsupervised machine learning\nvia k-means clustering to generate the land cover map. We used convolutional\nneural networks to classify the selected regions' land cover types. We present\na visualisation of change detection, highlighting urban area changes over time\nto monitor changes in the map.", "AI": {"tldr": "\u672c\u6587\u8fd0\u7528\u673a\u5668\u5b66\u4e60\u548c\u9065\u611f\u6846\u67b6\u5bf9\u6bd4\u6590\u6d4e\u6960\u8fea2013 - 2024\u5e74\u571f\u5730\u5229\u7528\u4e0e\u8986\u76d6\u53d8\u5316\uff0c\u63d0\u4f9b\u6280\u672f\u652f\u6301\u5e76\u53ef\u89c6\u5316\u53d8\u5316\u3002", "motivation": "\u6590\u6d4e\u4f5c\u4e3a\u53d1\u5c55\u4e2d\u56fd\u5bb6\u9762\u4e34\u5feb\u901f\u57ce\u5e02\u5316\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u4e3a\u571f\u5730\u8986\u76d6/\u571f\u5730\u5229\u7528\u5efa\u6a21\u548c\u53d8\u5316\u68c0\u6d4b\u63d0\u4f9b\u6280\u672f\u652f\u6301\u3002", "method": "\u4f7f\u7528Landsat - 8\u536b\u661f\u56fe\u50cf\u521b\u5efa\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\u6570\u636e\u96c6\uff1b\u5229\u7528Google Earth Engine\u548ck - means\u805a\u7c7b\u8fdb\u884c\u65e0\u76d1\u7763\u5b66\u4e60\u751f\u6210\u571f\u5730\u8986\u76d6\u56fe\uff1b\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5bf9\u9009\u5b9a\u533a\u57df\u571f\u5730\u8986\u76d6\u7c7b\u578b\u5206\u7c7b\u3002", "result": "\u5448\u73b0\u4e86\u53d8\u5316\u68c0\u6d4b\u7684\u53ef\u89c6\u5316\u7ed3\u679c\uff0c\u7a81\u51fa\u57ce\u5e02\u533a\u57df\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002", "conclusion": "\u8be5\u673a\u5668\u5b66\u4e60\u548c\u9065\u611f\u6846\u67b6\u53ef\u7528\u4e8e\u76d1\u6d4b\u571f\u5730\u5229\u7528\u548c\u571f\u5730\u8986\u76d6\u53d8\u5316\uff0c\u4e3a\u76f8\u5173\u5efa\u6a21\u548c\u68c0\u6d4b\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2509.14129", "pdf": "https://arxiv.org/pdf/2509.14129", "abs": "https://arxiv.org/abs/2509.14129", "authors": ["Kit T. Rodolfa", "Erika Salomon", "Jin Yao", "Steve Yoder", "Robert Sullivan", "Kevin McGuire", "Allie Dickinson", "Rob MacDougall", "Brian Seidler", "Christina Sung", "Claire Herdeman", "Rayid Ghani"], "title": "Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Many incarcerated individuals face significant and complex challenges,\nincluding mental illness, substance dependence, and homelessness, yet jails and\nprisons are often poorly equipped to address these needs. With little support\nfrom the existing criminal justice system, these needs can remain untreated and\nworsen, often leading to further offenses and a cycle of incarceration with\nadverse outcomes both for the individual and for public safety, with\nparticularly large impacts on communities of color that continue to widen the\nalready extensive racial disparities in criminal justice outcomes. Responding\nto these failures, a growing number of criminal justice stakeholders are\nseeking to break this cycle through innovative approaches such as\ncommunity-driven and alternative approaches to policing, mentoring, community\nbuilding, restorative justice, pretrial diversion, holistic defense, and social\nservice connections. Here we report on a collaboration between Johnson County,\nKansas, and Carnegie Mellon University to perform targeted, proactive mental\nhealth outreach in an effort to reduce reincarceration rates.\n  This paper describes the data used, our predictive modeling approach and\nresults, as well as the design and analysis of a field trial conducted to\nconfirm our model's predictive power, evaluate the impact of this targeted\noutreach, and understand at what level of reincarceration risk outreach might\nbe most effective. Through this trial, we find that our model is highly\npredictive of new jail bookings, with more than half of individuals in the\ntrial's highest-risk group returning to jail in the following year. Outreach\nwas most effective among these highest-risk individuals, with impacts on mental\nhealth utilization, EMS dispatches, and criminal justice involvement.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u582a\u8428\u65af\u5dde\u7ea6\u7ff0\u900a\u53bf\u4e0e\u5361\u5185\u57fa\u6885\u9686\u5927\u5b66\u5408\u4f5c\u5f00\u5c55\u9488\u5bf9\u6027\u5fc3\u7406\u5065\u5eb7\u5916\u5c55\u6d3b\u52a8\u4ee5\u964d\u4f4e\u518d\u5165\u72f1\u7387\uff0c\u63cf\u8ff0\u4e86\u6570\u636e\u3001\u5efa\u6a21\u65b9\u6cd5\u53ca\u7ed3\u679c\uff0c\u8bd5\u9a8c\u8868\u660e\u6a21\u578b\u5bf9\u65b0\u5165\u72f1\u60c5\u51b5\u9884\u6d4b\u6027\u9ad8\uff0c\u5916\u5c55\u5bf9\u9ad8\u98ce\u9669\u4eba\u7fa4\u6700\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u5211\u4e8b\u53f8\u6cd5\u7cfb\u7edf\u96be\u4ee5\u6ee1\u8db3\u88ab\u76d1\u7981\u8005\u9700\u6c42\uff0c\u5bfc\u81f4\u95ee\u9898\u6076\u5316\u548c\u518d\u5165\u72f1\u5faa\u73af\uff0c\u4e3a\u6253\u7834\u6b64\u5faa\u73af\uff0c\u51cf\u5c11\u518d\u5165\u72f1\u7387\u3002", "method": "\u91c7\u7528\u9884\u6d4b\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u5b9e\u5730\u8bd5\u9a8c\u6765\u9a8c\u8bc1\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u3001\u8bc4\u4f30\u5916\u5c55\u5f71\u54cd\u53ca\u786e\u5b9a\u5916\u5c55\u6700\u6709\u6548\u98ce\u9669\u6c34\u5e73\u3002", "result": "\u6a21\u578b\u5bf9\u65b0\u5165\u72f1\u60c5\u51b5\u6709\u9ad8\u9884\u6d4b\u6027\uff0c\u8bd5\u9a8c\u4e2d\u9ad8\u98ce\u9669\u7ec4\u8d85\u534a\u6570\u4eba\u5458\u6b21\u5e74\u518d\u6b21\u5165\u72f1\uff0c\u5916\u5c55\u5bf9\u9ad8\u98ce\u9669\u4eba\u7fa4\u5728\u5fc3\u7406\u5065\u5eb7\u5229\u7528\u3001\u6025\u6551\u8c03\u5ea6\u548c\u5211\u4e8b\u53f8\u6cd5\u4ecb\u5165\u65b9\u9762\u6709\u5f71\u54cd\u3002", "conclusion": "\u9488\u5bf9\u6027\u5fc3\u7406\u5065\u5eb7\u5916\u5c55\u6d3b\u52a8\u5bf9\u964d\u4f4e\u9ad8\u98ce\u9669\u4eba\u7fa4\u518d\u5165\u72f1\u7387\u6709\u79ef\u6781\u4f5c\u7528\u3002"}}
{"id": "2509.13390", "pdf": "https://arxiv.org/pdf/2509.13390", "abs": "https://arxiv.org/abs/2509.13390", "authors": ["Deepti Kunte", "Bram Cornelis", "Claudio Colangeli", "Karl Janssens", "Brecht Van Baelen", "Konstantinos Gryllias"], "title": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS", "I.2.1; I.2.6; I.2.10; I.5.1; I.5.2; J.2; J.7"], "comment": "Submitted to: Mechanical Systems and Signal Processing", "summary": "The detection of anomalies in automotive cabin sounds is critical for\nensuring vehicle quality and maintaining passenger comfort. In many real-world\nsettings, this task is more appropriately framed as an unsupervised learning\nproblem rather than the supervised case due to the scarcity or complete absence\nof labeled faulty data. In such an unsupervised setting, the model is trained\nexclusively on healthy samples and detects anomalies as deviations from normal\nbehavior. However, in the absence of labeled faulty samples for validation and\nthe limited reliability of commonly used metrics, such as validation\nreconstruction error, effective model selection remains a significant\nchallenge. To overcome these limitations, a domain-knowledge-informed approach\nfor model selection is proposed, in which proxy-anomalies engineered through\nstructured perturbations of healthy spectrograms are used in the validation set\nto support model selection. The proposed methodology is evaluated on a\nhigh-fidelity electric vehicle dataset comprising healthy and faulty cabin\nsounds across five representative fault types viz., Imbalance, Modulation,\nWhine, Wind, and Pulse Width Modulation. This dataset, generated using advanced\nsound synthesis techniques, and validated via expert jury assessments, has been\nmade publicly available to facilitate further research. Experimental\nevaluations on the five fault cases demonstrate the selection of optimal models\nusing proxy-anomalies, significantly outperform conventional model selection\nstrategies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\uff0c\u7528\u5065\u5eb7\u9891\u8c31\u56fe\u7684\u4ee3\u7406\u5f02\u5e38\u8fdb\u884c\u6a21\u578b\u9009\u62e9\uff0c\u5728\u7535\u52a8\u6c7d\u8f66\u8231\u5185\u58f0\u97f3\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7b56\u7565\u3002", "motivation": "\u6c7d\u8f66\u8231\u5185\u58f0\u97f3\u5f02\u5e38\u68c0\u6d4b\u5e38\u4e3a\u65e0\u76d1\u7763\u5b66\u4e60\uff0c\u7f3a\u4e4f\u6807\u6ce8\u6545\u969c\u6837\u672c\u548c\u53ef\u9760\u6307\u6807\uff0c\u6709\u6548\u6a21\u578b\u9009\u62e9\u662f\u6311\u6218\u3002", "method": "\u63d0\u51fa\u9886\u57df\u77e5\u8bc6\u9a71\u52a8\u7684\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u5065\u5eb7\u9891\u8c31\u56fe\u8fdb\u884c\u7ed3\u6784\u5316\u6270\u52a8\u751f\u6210\u4ee3\u7406\u5f02\u5e38\u7528\u4e8e\u9a8c\u8bc1\u96c6\u6765\u652f\u6301\u6a21\u578b\u9009\u62e9\u3002", "result": "\u5728\u5305\u542b\u4e94\u79cd\u6545\u969c\u7c7b\u578b\u7684\u7535\u52a8\u6c7d\u8f66\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4ee3\u7406\u5f02\u5e38\u80fd\u9009\u51fa\u6700\u4f18\u6a21\u578b\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u9009\u62e9\u7b56\u7565\u3002", "conclusion": "\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u5229\u7528\u4ee3\u7406\u5f02\u5e38\u8fdb\u884c\u6a21\u578b\u9009\u62e9\u7684\u65b9\u6cd5\u5728\u6c7d\u8f66\u8231\u5185\u58f0\u97f3\u5f02\u5e38\u68c0\u6d4b\u4e2d\u6709\u6548\uff0c\u4f18\u4e8e\u4f20\u7edf\u7b56\u7565\u3002"}}
{"id": "2509.14158", "pdf": "https://arxiv.org/pdf/2509.14158", "abs": "https://arxiv.org/abs/2509.14158", "authors": ["Feng Ruan", "Keli Liu", "Michael Jordan"], "title": "A Compositional Kernel Model for Feature Learning", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We study a compositional variant of kernel ridge regression in which the\npredictor is applied to a coordinate-wise reweighting of the inputs. Formulated\nas a variational problem, this model provides a simple testbed for feature\nlearning in compositional architectures. From the perspective of variable\nselection, we show how relevant variables are recovered while noise variables\nare eliminated. We establish guarantees showing that both global minimizers and\nstationary points discard noise coordinates when the noise variables are\nGaussian distributed. A central finding is that $\\ell_1$-type kernels, such as\nthe Laplace kernel, succeed in recovering features contributing to nonlinear\neffects at stationary points, whereas Gaussian kernels recover only linear\nones.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.13391", "pdf": "https://arxiv.org/pdf/2509.13391", "abs": "https://arxiv.org/abs/2509.13391", "authors": ["Sandrine R. Schiller", "Camilo Miguel Signorelli", "Filippos Stamatiou"], "title": "The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self", "categories": ["cs.CY", "cs.AI"], "comment": "8 pages, accepted at the 8th AAAI/ACM Conference on AI, Ethics, and\n  Society", "summary": "Generative AI is changing our way of interacting with technology, others, and\nourselves. Systems such as Microsoft copilot, Gemini and the expected Apple\nintelligence still awaits our prompt for action. Yet, it is likely that AI\nassistant systems will only become better at predicting our behaviour and\nacting on our behalf. Imagine new generations of generative and predictive AI\ndeciding what you might like best at a new restaurant, picking an outfit that\nincreases your chances on your date with a partner also chosen by the same or a\nsimilar system. Far from a science fiction scenario, the goal of several\nresearch programs is to build systems capable of assisting us in exactly this\nmanner. The prospect urges us to rethink human-technology relations, but it\nalso invites us to question how such systems might change the way we relate to\nourselves. Building on our conception of the relational self, we question the\npossible effects of generative AI with respect to what we call the sphere of\nexternalised output, the contextual sphere and the sphere of self-relating. In\nthis paper, we attempt to deepen the existential considerations accompanying\nthe AI revolution by outlining how generative AI enables the fulfilment of\ntasks and also increasingly anticipates, i.e. intercepts, our initiatives in\nthese different spheres.", "AI": {"tldr": "\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5bf9\u4eba\u673a\u5173\u7cfb\u53ca\u81ea\u6211\u8ba4\u77e5\u7684\u5f71\u54cd\uff0c\u5206\u6790\u5176\u5728\u4e0d\u540c\u9886\u57df\u5bf9\u4eba\u7c7b\u4e3b\u52a8\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u751f\u6210\u5f0fAI\u53d1\u5c55\u4fc3\u4f7f\u4eba\u4eec\u91cd\u65b0\u601d\u8003\u4eba\u673a\u5173\u7cfb\u53ca\u5bf9\u81ea\u6211\u7684\u5f71\u54cd\uff0c\u6709\u5fc5\u8981\u6df1\u5165\u7814\u7a76\u3002", "method": "\u57fa\u4e8e\u5173\u7cfb\u81ea\u6211\u7684\u6982\u5ff5\uff0c\u5206\u6790\u751f\u6210\u5f0fAI\u5728\u5916\u90e8\u8f93\u51fa\u3001\u60c5\u5883\u548c\u81ea\u6211\u5173\u8054\u9886\u57df\u7684\u53ef\u80fd\u5f71\u54cd\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7814\u7a76\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u6982\u8ff0\u751f\u6210\u5f0fAI\u5728\u4e0d\u540c\u9886\u57df\u5bf9\u4efb\u52a1\u5b8c\u6210\u548c\u4eba\u7c7b\u4e3b\u52a8\u6027\u7684\u5f71\u54cd\uff0c\u52a0\u6df1\u5bf9AI\u9769\u547d\u7684\u5b58\u5728\u4e3b\u4e49\u601d\u8003\u3002"}}
{"id": "2509.14167", "pdf": "https://arxiv.org/pdf/2509.14167", "abs": "https://arxiv.org/abs/2509.14167", "authors": ["Md Rezwan Jaher", "Abul Mukid Mohammad Mukaddes", "A. B. M. Abdul Malek"], "title": "Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework", "categories": ["cs.LG", "q-bio.QM", "stat.AP", "stat.ME"], "comment": "43 pages, 10 figures (including supplementary material)", "summary": "Many critical healthcare decisions are challenged by the inability to measure\nkey underlying parameters. Glaucoma, a leading cause of irreversible blindness\ndriven by elevated intraocular pressure (IOP), provides a stark example. The\nprimary determinant of IOP, a tissue property called trabecular meshwork\npermeability, cannot be measured in vivo, forcing clinicians to depend on\nindirect surrogates. This clinical challenge is compounded by a broader\ncomputational one: developing predictive models for such ill-posed inverse\nproblems is hindered by a lack of ground-truth data and prohibitive cost of\nlarge-scale, high-fidelity simulations. We address both challenges with an\nend-to-end framework to noninvasively estimate unmeasurable variables from\nsparse, routine data. Our approach combines a multi-stage artificial\nintelligence architecture to functionally separate the problem; a novel data\ngeneration strategy we term PCDS that obviates the need for hundreds of\nthousands of costly simulations, reducing the effective computational time from\nyears to hours; and a Bayesian engine to quantify predictive uncertainty. Our\nframework deconstructs a single IOP measurement into its fundamental components\nfrom routine inputs only, yielding estimates for the unmeasurable tissue\npermeability and a patient's outflow facility. Our noninvasively estimated\noutflow facility achieved excellent agreement with state-of-the-art tonography\nwith precision comparable to direct physical instruments. Furthermore, the\nnewly derived permeability biomarker demonstrates high accuracy in stratifying\nclinical cohorts by disease risk, highlighting its diagnostic potential. More\nbroadly, our framework establishes a generalizable blueprint for solving\nsimilar inverse problems in other data-scarce, computationally-intensive\ndomains.", "AI": {"tldr": "\u63d0\u51fa\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u4ece\u7a00\u758f\u5e38\u89c4\u6570\u636e\u975e\u4fb5\u5165\u6027\u4f30\u8ba1\u4e0d\u53ef\u6d4b\u53d8\u91cf\uff0c\u89e3\u51b3\u533b\u7597\u5173\u952e\u53c2\u6570\u6d4b\u91cf\u548c\u8ba1\u7b97\u96be\u9898\uff0c\u5728\u9752\u5149\u773c\u7814\u7a76\u4e2d\u53d6\u5f97\u826f\u597d\u7ed3\u679c\u4e14\u5177\u63a8\u5e7f\u6027\u3002", "motivation": "\u89e3\u51b3\u533b\u7597\u4e2d\u5173\u952e\u6f5c\u5728\u53c2\u6570\u65e0\u6cd5\u6d4b\u91cf\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u8ba1\u7b97\u4e2d\u56e0\u7f3a\u4e4f\u771f\u5b9e\u6570\u636e\u548c\u9ad8\u6210\u672c\u6a21\u62df\u5bfc\u81f4\u7684\u9006\u95ee\u9898\u5efa\u6a21\u96be\u9898\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u4eba\u5de5\u667a\u80fd\u67b6\u6784\u5206\u79bb\u95ee\u9898\uff0c\u4f7f\u7528PCDS\u6570\u636e\u751f\u6210\u7b56\u7565\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\uff0c\u7528\u8d1d\u53f6\u65af\u5f15\u64ce\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u975e\u4fb5\u5165\u6027\u4f30\u8ba1\u7684\u6d41\u51fa\u8bbe\u65bd\u4e0e\u6700\u65b0\u773c\u538b\u63cf\u8bb0\u6cd5\u9ad8\u5ea6\u4e00\u81f4\uff0c\u65b0\u5bfc\u51fa\u7684\u6e17\u900f\u7387\u751f\u7269\u6807\u5fd7\u7269\u5728\u6309\u75be\u75c5\u98ce\u9669\u5206\u5c42\u4e34\u5e8a\u961f\u5217\u65f6\u51c6\u786e\u6027\u9ad8\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5176\u4ed6\u6570\u636e\u7a00\u7f3a\u3001\u8ba1\u7b97\u5bc6\u96c6\u9886\u57df\u7684\u7c7b\u4f3c\u9006\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u63a8\u5e7f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13395", "pdf": "https://arxiv.org/pdf/2509.13395", "abs": "https://arxiv.org/abs/2509.13395", "authors": ["Haolong Zheng", "Yekaterina Yegorova", "Mark Hasegawa-Johnson"], "title": "TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": null, "summary": "Speech foundation models have recently demonstrated the ability to perform\nSpeech In-Context Learning (SICL). Selecting effective in-context examples is\ncrucial for SICL performance, yet selection methodologies remain underexplored.\nIn this work, we propose Text-Embedding KNN for SICL (TICL), a simple pipeline\nthat uses semantic context to enhance off-the-shelf large multimodal models'\nspeech recognition ability without fine-tuning. Across challenging automatic\nspeech recognition tasks, including accented English, multilingual speech, and\nchildren's speech, our method enables models to surpass zero-shot performance\nwith up to 84.7% relative WER reduction. We conduct ablation studies to show\nthe robustness and efficiency of our method.", "AI": {"tldr": "\u63d0\u51faTICL\u65b9\u6cd5\u63d0\u5347\u5927\u6a21\u578b\u8bed\u97f3\u8bc6\u522b\u80fd\u529b\uff0c\u5728\u591a\u4efb\u52a1\u4e2d\u8868\u73b0\u597d\u3002", "motivation": "\u8bed\u97f3\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u6709\u6548\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\u5f85\u63a2\u7d22\uff0c\u9700\u63d0\u5347\u6a21\u578b\u8bed\u97f3\u8bc6\u522b\u80fd\u529b\u3002", "method": "\u63d0\u51faText - Embedding KNN for SICL (TICL)\u65b9\u6cd5\uff0c\u7528\u8bed\u4e49\u4e0a\u4e0b\u6587\u63d0\u5347\u6a21\u578b\u8bed\u97f3\u8bc6\u522b\u80fd\u529b\u4e14\u65e0\u9700\u5fae\u8c03\u3002", "result": "\u5728\u591a\u79cd\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u8d85\u8d8a\u96f6\u6837\u672c\u6027\u80fd\uff0c\u76f8\u5bf9WER\u6700\u591a\u964d\u4f4e84.7%\u3002", "conclusion": "\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2509.14169", "pdf": "https://arxiv.org/pdf/2509.14169", "abs": "https://arxiv.org/abs/2509.14169", "authors": ["Ziming Wei", "Zichen Kong", "Yuan Wang", "David Z. Pan", "Xiyuan Tang"], "title": "TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits", "categories": ["cs.LG"], "comment": null, "summary": "Analog and mixed-signal circuit design remains challenging due to the\nshortage of high-quality data and the difficulty of embedding domain knowledge\ninto automated flows. Traditional black-box optimization achieves sampling\nefficiency but lacks circuit understanding, which often causes evaluations to\nbe wasted in low-value regions of the design space. In contrast, learning-based\nmethods embed structural knowledge but are case-specific and costly to retrain.\nRecent attempts with large language models show potential, yet they often rely\non manual intervention, limiting generality and transparency. We propose\nTopoSizing, an end-to-end framework that performs robust circuit understanding\ndirectly from raw netlists and translates this knowledge into optimization\ngains. Our approach first applies graph algorithms to organize circuits into a\nhierarchical device-module-stage representation. LLM agents then execute an\niterative hypothesis-verification-refinement loop with built-in consistency\nchecks, producing explicit annotations. Verified insights are integrated into\nBayesian optimization through LLM-guided initial sampling and\nstagnation-triggered trust-region updates, improving efficiency while\npreserving feasibility.", "AI": {"tldr": "\u63d0\u51faTopoSizing\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u4ece\u539f\u59cb\u7f51\u8868\u8fdb\u884c\u7535\u8def\u7406\u89e3\u5e76\u4f18\u5316\u7535\u8def\u8bbe\u8ba1\u3002", "motivation": "\u6a21\u62df\u548c\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u8bbe\u8ba1\u56e0\u6570\u636e\u548c\u5d4c\u5165\u9886\u57df\u77e5\u8bc6\u96be\u800c\u5177\u6311\u6218\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u6709\u4e0d\u8db3\u3002", "method": "\u5148\u7528\u56fe\u7b97\u6cd5\u5c06\u7535\u8def\u7ec4\u7ec7\u6210\u5c42\u6b21\u5316\u8868\u793a\uff0c\u518d\u7528LLM\u4ee3\u7406\u6267\u884c\u8fed\u4ee3\u5faa\u73af\u751f\u6210\u663e\u5f0f\u6ce8\u91ca\uff0c\u5c06\u9a8c\u8bc1\u89c1\u89e3\u96c6\u6210\u5230\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "TopoSizing\u6846\u67b6\u80fd\u76f4\u63a5\u4ece\u539f\u59cb\u7f51\u8868\u8fdb\u884c\u7535\u8def\u7406\u89e3\u5e76\u8f6c\u5316\u4e3a\u4f18\u5316\u6536\u76ca\uff0c\u63d0\u9ad8\u6548\u7387\u5e76\u4fdd\u8bc1\u53ef\u884c\u6027\u3002"}}
{"id": "2509.13397", "pdf": "https://arxiv.org/pdf/2509.13397", "abs": "https://arxiv.org/abs/2509.13397", "authors": ["Jamie Cummins"], "title": "The threat of analytic flexibility in using large language models to simulate human data: A call to attention", "categories": ["cs.CY", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "Social scientists are now using large language models to create \"silicon\nsamples\" - synthetic datasets intended to stand in for human respondents, aimed\nat revolutionising human subjects research. However, there are many analytic\nchoices which must be made to produce these samples. Though many of these\nchoices are defensible, their impact on sample quality is poorly understood. I\nmap out these analytic choices and demonstrate how a very small number of\ndecisions can dramatically change the correspondence between silicon samples\nand human data. Configurations (N = 252) varied substantially in their capacity\nto estimate (i) rank ordering of participants, (ii) response distributions, and\n(iii) between-scale correlations. Most critically, configurations were not\nconsistent in quality: those that performed well on one dimension often\nperformed poorly on another, implying that there is no \"one-size-fits-all\"\nconfiguration that optimises the accuracy of these samples. I call for greater\nattention to the threat of analytic flexibility in using silicon samples.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7528\u5927\u8bed\u8a00\u6a21\u578b\u521b\u5efa\u201c\u7845\u6837\u672c\u201d\u7528\u4e8e\u4eba\u7c7b\u4e3b\u4f53\u7814\u7a76\uff0c\u6307\u51fa\u5206\u6790\u9009\u62e9\u5f71\u54cd\u6837\u672c\u8d28\u91cf\u4e14\u65e0\u901a\u7528\u914d\u7f6e\uff0c\u547c\u5401\u5173\u6ce8\u5206\u6790\u7075\u6d3b\u6027\u5a01\u80c1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u521b\u5efa\u7845\u6837\u672c\u7528\u4e8e\u4eba\u7c7b\u4e3b\u4f53\u7814\u7a76\u65f6\uff0c\u4f17\u591a\u5206\u6790\u9009\u62e9\u5bf9\u6837\u672c\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5bf9\u521b\u5efa\u7845\u6837\u672c\u7684\u5206\u6790\u9009\u62e9\u8fdb\u884c\u68b3\u7406\uff0c\u5e76\u5c55\u793a\u5c11\u91cf\u51b3\u7b56\u5982\u4f55\u663e\u8457\u6539\u53d8\u7845\u6837\u672c\u4e0e\u4eba\u7c7b\u6570\u636e\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u6d4b\u8bd5252\u79cd\u914d\u7f6e\u3002", "result": "\u4e0d\u540c\u914d\u7f6e\u5728\u4f30\u8ba1\u53c2\u4e0e\u8005\u6392\u540d\u987a\u5e8f\u3001\u54cd\u5e94\u5206\u5e03\u548c\u91cf\u8868\u95f4\u76f8\u5173\u6027\u7684\u80fd\u529b\u4e0a\u5dee\u5f02\u5927\uff0c\u4e14\u5728\u8d28\u91cf\u4e0a\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u4f7f\u7528\u7845\u6837\u672c\u65f6\u6ca1\u6709\u201c\u4e00\u5200\u5207\u201d\u7684\u914d\u7f6e\u6765\u4f18\u5316\u6837\u672c\u51c6\u786e\u6027\uff0c\u9700\u66f4\u591a\u5173\u6ce8\u5206\u6790\u7075\u6d3b\u6027\u7684\u5a01\u80c1\u3002"}}
{"id": "2509.14172", "pdf": "https://arxiv.org/pdf/2509.14172", "abs": "https://arxiv.org/abs/2509.14172", "authors": ["Ziyuan Chen", "Zhenghui Zhao", "Zhangye Han", "Miancan Liu", "Xianhang Ye", "Yiqing Li", "Hongbo Min", "Jinkui Ren", "Xiantao Zhang", "Guitao Cao"], "title": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the rapid advancement of large language models and vision-language\nmodels, employing large models as Web Agents has become essential for automated\nweb interaction. However, training Web Agents with reinforcement learning faces\ncritical challenges including credit assignment misallocation, prohibitively\nhigh annotation costs, and reward sparsity. To address these issues, we propose\nTree-Guided Preference Optimization (TGPO), an offline reinforcement learning\nframework that proposes a tree-structured trajectory representation merging\nsemantically identical states across trajectories to eliminate label conflicts.\nOur framework incorporates a Process Reward Model that automatically generates\nfine-grained rewards through subgoal progress, redundancy detection, and action\nverification. Additionally, a dynamic weighting mechanism prioritizes\nhigh-impact decision points during training. Experiments on Online-Mind2Web and\nour self-constructed C-WebShop datasets demonstrate that TGPO significantly\noutperforms existing methods, achieving higher success rates with fewer\nredundant steps.", "AI": {"tldr": "\u63d0\u51faTGPO\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u8bad\u7ec3Web Agents\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8bad\u7ec3Web Agents\u9762\u4e34\u4fe1\u7528\u5206\u914d\u9519\u8bef\u3001\u6807\u6ce8\u6210\u672c\u9ad8\u548c\u5956\u52b1\u7a00\u758f\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faTree - Guided Preference Optimization (TGPO)\u6846\u67b6\uff0c\u7528\u6811\u7ed3\u6784\u8f68\u8ff9\u8868\u793a\u6d88\u9664\u6807\u7b7e\u51b2\u7a81\uff0c\u7ed3\u5408Process Reward Model\u81ea\u52a8\u751f\u6210\u7ec6\u7c92\u5ea6\u5956\u52b1\uff0c\u4f7f\u7528\u52a8\u6001\u52a0\u6743\u673a\u5236\u3002", "result": "\u5728Online - Mind2Web\u548cC - WebShop\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cTGPO\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6210\u529f\u7387\u66f4\u9ad8\u4e14\u5197\u4f59\u6b65\u9aa4\u66f4\u5c11\u3002", "conclusion": "TGPO\u80fd\u6709\u6548\u89e3\u51b3\u8bad\u7ec3Web Agents\u7684\u95ee\u9898\uff0c\u6027\u80fd\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2509.13399", "pdf": "https://arxiv.org/pdf/2509.13399", "abs": "https://arxiv.org/abs/2509.13399", "authors": ["Tianyu Chen", "Yasi Zhang", "Zhi Zhang", "Peiyu Yu", "Shu Wang", "Zhendong Wang", "Kevin Lin", "Xiaofei Wang", "Zhengyuan Yang", "Linjie Li", "Chung-Ching Lin", "Jianwen Xie", "Oscar Leong", "Lijuan Wang", "Ying Nian Wu", "Mingyuan Zhou"], "title": "EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Tianyu Chen and Yasi Zhang contributed equally; Oscar Leong, Lijuan\n  Wang, Ying Nian Wu, and Mingyuan Zhou advised equally", "summary": "Instruction-based image editing has advanced rapidly, yet reliable and\ninterpretable evaluation remains a bottleneck. Current protocols either (i)\ndepend on paired reference images -- resulting in limited coverage and\ninheriting biases from prior generative models -- or (ii) rely solely on\nzero-shot vision-language models (VLMs), whose prompt-based assessments of\ninstruction following, content consistency, and visual quality are often\nimprecise.\n  To address this, we introduce EdiVal-Agent, an automated, scalable, and\nfine-grained evaluation framework for multi-turn instruction-based editing from\nan object-centric perspective, supported by a suite of expert tools. Given an\nimage, EdiVal-Agent first decomposes it into semantically meaningful objects,\nthen synthesizes diverse, context-aware editing instructions. For evaluation,\nit integrates VLMs with open-vocabulary object detectors to assess instruction\nfollowing, uses semantic-level feature extractors to evaluate content\nconsistency, and leverages human preference models to judge visual quality. We\nshow that combining VLMs with object detectors yields stronger agreement with\nhuman judgments in instruction-following evaluation compared to using VLMs\nalone and CLIP-based metrics. Furthermore, the pipeline's modular design allows\nfuture tools to be seamlessly integrated, enhancing evaluation accuracy over\ntime.\n  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing\nbenchmark covering 9 instruction types and 11 state-of-the-art editing models\nspanning autoregressive (AR) (including Nano Banana, GPT-Image-1),\nflow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be\nused to identify existing failure modes, thereby informing the development of\nthe next generation of editing models. Project page:\nhttps://tianyucodings.github.io/EdiVAL-page/.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u6307\u4ee4\u7684\u56fe\u50cf\u7f16\u8f91\u8bc4\u4f30\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51faEdiVal - Agent\u6846\u67b6\u53caEdiVal - Bench\u57fa\u51c6\uff0c\u53ef\u8bc6\u522b\u73b0\u6709\u6a21\u578b\u5931\u6548\u6a21\u5f0f\uff0c\u5229\u4e8e\u4e0b\u4e00\u4ee3\u6a21\u578b\u5f00\u53d1\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6307\u4ee4\u7684\u56fe\u50cf\u7f16\u8f91\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u8986\u76d6\u8303\u56f4\u6709\u9650\u3001\u8bc4\u4f30\u4e0d\u7cbe\u786e\u7b49\u95ee\u9898\uff0c\u9700\u8981\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165EdiVal - Agent\u6846\u67b6\uff0c\u4ece\u5bf9\u8c61\u4e2d\u5fc3\u89c6\u89d2\u8bc4\u4f30\uff0c\u5206\u89e3\u56fe\u50cf\u6210\u5bf9\u8c61\u3001\u5408\u6210\u6307\u4ee4\uff1b\u96c6\u6210VLMs\u4e0e\u5bf9\u8c61\u68c0\u6d4b\u5668\u8bc4\u4f30\u6307\u4ee4\u9075\u5faa\u5ea6\uff0c\u7528\u7279\u5f81\u63d0\u53d6\u5668\u8bc4\u4f30\u5185\u5bb9\u4e00\u81f4\u6027\uff0c\u7528\u4eba\u7c7b\u504f\u597d\u6a21\u578b\u8bc4\u4f30\u89c6\u89c9\u8d28\u91cf\u3002\u6784\u5efaEdiVal - Bench\u57fa\u51c6\u3002", "result": "\u7ed3\u5408VLMs\u4e0e\u5bf9\u8c61\u68c0\u6d4b\u5668\u5728\u6307\u4ee4\u9075\u5faa\u5ea6\u8bc4\u4f30\u4e0a\u6bd4\u5355\u72ec\u4f7f\u7528VLMs\u548c\u57fa\u4e8eCLIP\u7684\u6307\u6807\u66f4\u7b26\u5408\u4eba\u7c7b\u5224\u65ad\uff0c\u6846\u67b6\u6a21\u5757\u5316\u8bbe\u8ba1\u4fbf\u4e8e\u96c6\u6210\u65b0\u5de5\u5177\u3002", "conclusion": "EdiVal - Agent\u53ef\u7528\u4e8e\u8bc6\u522b\u73b0\u6709\u6a21\u578b\u5931\u6548\u6a21\u5f0f\uff0c\u6709\u52a9\u4e8e\u4e0b\u4e00\u4ee3\u7f16\u8f91\u6a21\u578b\u7684\u5f00\u53d1\u3002"}}
{"id": "2509.14181", "pdf": "https://arxiv.org/pdf/2509.14181", "abs": "https://arxiv.org/abs/2509.14181", "authors": ["Yifan Hu", "Jie Yang", "Tian Zhou", "Peiyuan Liu", "Yujin Tang", "Rong Jin", "Liang Sun"], "title": "Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Representation learning techniques like contrastive learning have long been\nexplored in time series forecasting, mirroring their success in computer vision\nand natural language processing. Yet recent state-of-the-art (SOTA) forecasters\nseldom adopt these representation approaches because they have shown little\nperformance advantage. We challenge this view and demonstrate that explicit\nrepresentation alignment can supply critical information that bridges the\ndistributional gap between input histories and future targets. To this end, we\nintroduce TimeAlign, a lightweight, plug-and-play framework that learns\nauxiliary features via a simple reconstruction task and feeds them back to any\nbase forecaster. Extensive experiments across eight benchmarks verify its\nsuperior performance. Further studies indicate that the gains arises primarily\nfrom correcting frequency mismatches between historical inputs and future\noutputs. We also provide a theoretical justification for the effectiveness of\nTimeAlign in increasing the mutual information between learned representations\nand predicted targets. As it is architecture-agnostic and incurs negligible\noverhead, TimeAlign can serve as a general alignment module for modern deep\nlearning time-series forecasting systems. The code is available at\nhttps://github.com/TROUBADOUR000/TimeAlign.", "AI": {"tldr": "\u73b0\u6709SOTA\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5668\u5f88\u5c11\u7528\u8868\u5f81\u5b66\u4e60\u65b9\u6cd5\uff0c\u672c\u6587\u63d0\u51faTimeAlign\u6846\u67b6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u4f18\u8d8a\uff0c\u53ef\u4f5c\u901a\u7528\u5bf9\u9f50\u6a21\u5757\u3002", "motivation": "\u73b0\u6709SOTA\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5668\u5f88\u5c11\u91c7\u7528\u8868\u5f81\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f5c\u8005\u8ba4\u4e3a\u663e\u5f0f\u8868\u5f81\u5bf9\u9f50\u80fd\u63d0\u4f9b\u5173\u952e\u4fe1\u606f\uff0c\u7f29\u5c0f\u8f93\u5165\u5386\u53f2\u548c\u672a\u6765\u76ee\u6807\u4e4b\u95f4\u7684\u5206\u5e03\u5dee\u8ddd\u3002", "method": "\u5f15\u5165TimeAlign\u6846\u67b6\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u91cd\u5efa\u4efb\u52a1\u5b66\u4e60\u8f85\u52a9\u7279\u5f81\u5e76\u53cd\u9988\u7ed9\u57fa\u7840\u9884\u6d4b\u5668\u3002", "result": "\u5728\u516b\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86TimeAlign\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u589e\u76ca\u4e3b\u8981\u6765\u81ea\u7ea0\u6b63\u5386\u53f2\u8f93\u5165\u548c\u672a\u6765\u8f93\u51fa\u4e4b\u95f4\u7684\u9891\u7387\u4e0d\u5339\u914d\u3002", "conclusion": "TimeAlign\u67b6\u6784\u65e0\u5173\u4e14\u5f00\u9500\u53ef\u5ffd\u7565\uff0c\u53ef\u4f5c\u4e3a\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7cfb\u7edf\u7684\u901a\u7528\u5bf9\u9f50\u6a21\u5757\u3002"}}
{"id": "2509.13400", "pdf": "https://arxiv.org/pdf/2509.13400", "abs": "https://arxiv.org/abs/2509.13400", "authors": ["Sai Suresh Marchala Vasu", "Ivaxi Sheth", "Hui-Po Wang", "Ruta Binkyte", "Mario Fritz"], "title": "Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The adoption of large language models (LLMs) is transforming the peer review\nprocess, from assisting reviewers in writing more detailed evaluations to\ngenerating entire reviews automatically. While these capabilities offer\nexciting opportunities, they also raise critical concerns about fairness and\nreliability. In this paper, we investigate bias in LLM-generated peer reviews\nby conducting controlled experiments on sensitive metadata, including author\naffiliation and gender. Our analysis consistently shows affiliation bias\nfavoring institutions highly ranked on common academic rankings. Additionally,\nwe find some gender preferences, which, even though subtle in magnitude, have\nthe potential to compound over time. Notably, we uncover implicit biases that\nbecome more evident with token-based soft ratings.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u504f\u89c1\uff0c\u53d1\u73b0\u5b58\u5728\u673a\u6784\u6392\u540d\u548c\u6027\u522b\u504f\u597d\u7b49\u504f\u89c1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u540c\u884c\u8bc4\u5ba1\u5e26\u6765\u673a\u9047\u540c\u65f6\u5f15\u53d1\u516c\u5e73\u548c\u53ef\u9760\u6027\u62c5\u5fe7\uff0c\u9700\u7814\u7a76\u5176\u751f\u6210\u8bc4\u5ba1\u4e2d\u7684\u504f\u89c1\u3002", "method": "\u5bf9\u4f5c\u8005\u6240\u5c5e\u673a\u6784\u548c\u6027\u522b\u7b49\u654f\u611f\u5143\u6570\u636e\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\u3002", "result": "\u5206\u6790\u663e\u793a\u5b58\u5728\u504f\u5411\u9ad8\u6392\u540d\u673a\u6784\u7684\u673a\u6784\u504f\u89c1\uff0c\u4e5f\u53d1\u73b0\u6709\u4e00\u5b9a\u6027\u522b\u504f\u597d\uff0c\u57fa\u4e8e\u6807\u8bb0\u7684\u8f6f\u8bc4\u5206\u4e2d\u9690\u5f0f\u504f\u89c1\u66f4\u660e\u663e\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u540c\u884c\u8bc4\u5ba1\u5b58\u5728\u673a\u6784\u6392\u540d\u548c\u6027\u522b\u7b49\u65b9\u9762\u7684\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2509.14198", "pdf": "https://arxiv.org/pdf/2509.14198", "abs": "https://arxiv.org/abs/2509.14198", "authors": ["Juan Diego Toscano", "Daniel T. Chen", "Vivek Oommen", "George Em Karniadakis"], "title": "A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "physics.comp-ph"], "comment": null, "summary": "Residual-based adaptive strategies are widely used in scientific machine\nlearning but remain largely heuristic. We introduce a unifying variational\nframework that formalizes these methods by integrating convex transformations\nof the residual. Different transformations correspond to distinct objective\nfunctionals: exponential weights target the minimization of uniform error,\nwhile linear weights recover the minimization of quadratic error. Within this\nperspective, adaptive weighting is equivalent to selecting sampling\ndistributions that optimize the primal objective, thereby linking\ndiscretization choices directly to error metrics. This principled approach\nyields three benefits: (1) it enables systematic design of adaptive schemes\nacross norms, (2) reduces discretization error through variance reduction of\nthe loss estimator, and (3) enhances learning dynamics by improving the\ngradient signal-to-noise ratio. Extending the framework to operator learning,\nwe demonstrate substantial performance gains across optimizers and\narchitectures. Our results provide a theoretical justification of\nresidual-based adaptivity and establish a foundation for principled\ndiscretization and training strategies.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u7edf\u4e00\u53d8\u5206\u6846\u67b6\u5f62\u5f0f\u5316\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u7b56\u7565\uff0c\u6709\u4e09\u65b9\u9762\u76ca\u5904\uff0c\u6269\u5c55\u5230\u7b97\u5b50\u5b66\u4e60\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u7b56\u7565\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "motivation": "\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u7b56\u7565\u5728\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u4f46\u5927\u591a\u662f\u542f\u53d1\u5f0f\u7684\uff0c\u7f3a\u4e4f\u7406\u8bba\u5f62\u5f0f\u5316\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u53d8\u5206\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u6b8b\u5dee\u7684\u51f8\u53d8\u6362\u6765\u5f62\u5f0f\u5316\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u4e0d\u540c\u53d8\u6362\u5bf9\u5e94\u4e0d\u540c\u76ee\u6807\u6cdb\u51fd\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u4e09\u65b9\u9762\u76ca\u5904\uff0c\u6269\u5c55\u5230\u7b97\u5b50\u5b66\u4e60\u5728\u4f18\u5316\u5668\u548c\u67b6\u6784\u4e0a\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u4e3a\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u7b56\u7565\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\uff0c\u4e3a\u539f\u5219\u6027\u79bb\u6563\u5316\u548c\u8bad\u7ec3\u7b56\u7565\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.13414", "pdf": "https://arxiv.org/pdf/2509.13414", "abs": "https://arxiv.org/abs/2509.13414", "authors": ["Nikhil Keetha", "Norman M\u00fcller", "Johannes Sch\u00f6nberger", "Lorenzo Porzi", "Yuchen Zhang", "Tobias Fischer", "Arno Knapitsch", "Duncan Zauss", "Ethan Weber", "Nelson Antunes", "Jonathon Luiten", "Manuel Lopez-Antequera", "Samuel Rota Bul\u00f2", "Christian Richardt", "Deva Ramanan", "Sebastian Scherer", "Peter Kontschieder"], "title": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Project Page: https://map-anything.github.io/", "summary": "We introduce MapAnything, a unified transformer-based feed-forward model that\ningests one or more images along with optional geometric inputs such as camera\nintrinsics, poses, depth, or partial reconstructions, and then directly\nregresses the metric 3D scene geometry and cameras. MapAnything leverages a\nfactored representation of multi-view scene geometry, i.e., a collection of\ndepth maps, local ray maps, camera poses, and a metric scale factor that\neffectively upgrades local reconstructions into a globally consistent metric\nframe. Standardizing the supervision and training across diverse datasets,\nalong with flexible input augmentation, enables MapAnything to address a broad\nrange of 3D vision tasks in a single feed-forward pass, including uncalibrated\nstructure-from-motion, calibrated multi-view stereo, monocular depth\nestimation, camera localization, depth completion, and more. We provide\nextensive experimental analyses and model ablations demonstrating that\nMapAnything outperforms or matches specialist feed-forward models while\noffering more efficient joint training behavior, thus paving the way toward a\nuniversal 3D reconstruction backbone.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8eTransformer\u7684\u7edf\u4e00\u524d\u9988\u6a21\u578bMapAnything\uff0c\u53ef\u5904\u7406\u591a\u79cd\u8f93\u5165\u5e76\u56de\u5f523D\u573a\u666f\u51e0\u4f55\u4e0e\u76f8\u673a\u53c2\u6570\uff0c\u80fd\u89e3\u51b3\u591a\u79cd3D\u89c6\u89c9\u4efb\u52a1\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u3002", "motivation": "\u6784\u5efa\u80fd\u5904\u7406\u591a\u79cd\u8f93\u5165\u3001\u89e3\u51b3\u591a\u79cd3D\u89c6\u89c9\u4efb\u52a1\u7684\u7edf\u4e00\u6a21\u578b\u3002", "method": "\u5f15\u5165MapAnything\u6a21\u578b\uff0c\u5229\u7528\u591a\u89c6\u56fe\u573a\u666f\u51e0\u4f55\u7684\u5206\u89e3\u8868\u793a\uff0c\u7edf\u4e00\u4e0d\u540c\u6570\u636e\u96c6\u7684\u76d1\u7763\u548c\u8bad\u7ec3\uff0c\u8fdb\u884c\u7075\u6d3b\u8f93\u5165\u589e\u5f3a\u3002", "result": "MapAnything\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u4e13\u4e1a\u524d\u9988\u6a21\u578b\uff0c\u4e14\u8054\u5408\u8bad\u7ec3\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "MapAnything\u4e3a\u901a\u75283D\u91cd\u5efa\u9aa8\u5e72\u7f51\u7edc\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.14216", "pdf": "https://arxiv.org/pdf/2509.14216", "abs": "https://arxiv.org/abs/2509.14216", "authors": ["Johnny R. Zhang", "Xiaomei Mi", "Gaoyuan Du", "Qianyi Sun", "Shiqi Wang", "Jiaxuan Li", "Wenhua Zhou"], "title": "A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training", "categories": ["cs.LG", "cs.AI"], "comment": "69 pages, 10 figures. Preprint", "summary": "Stochastic optimization powers the scalability of modern artificial\nintelligence, spanning machine learning, deep learning, reinforcement learning,\nand large language model training. Yet, existing theory remains largely\nconfined to Hilbert spaces, relying on inner-product frameworks and\northogonality. This paradigm fails to capture non-Euclidean settings, such as\nmirror descent on simplices, Bregman proximal methods for sparse learning,\nnatural gradient descent in information geometry, or\nKullback--Leibler-regularized language model training. Unlike Euclidean-based\nHilbert-space methods, this approach embraces general Banach spaces. This work\nintroduces a pioneering Banach--Bregman framework for stochastic iterations,\nestablishing Bregman geometry as a foundation for next-generation optimization.\nIt (i) provides a unified template via Bregman projections and Bregman--Fejer\nmonotonicity, encompassing stochastic approximation, mirror descent, natural\ngradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations\n($\\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and\nelucidating their acceleration effect; and (iii) delivers convergence theorems\nspanning almost-sure boundedness to geometric rates, validated on synthetic and\nreal-world tasks. Empirical studies across machine learning (UCI benchmarks),\ndeep learning (e.g., Transformer training), reinforcement learning\n(actor--critic), and large language models (WikiText-2 with distilGPT-2) show\nup to 20% faster convergence, reduced variance, and enhanced accuracy over\nclassical baselines. These results position Banach--Bregman geometry as a\ncornerstone unifying optimization theory and practice across core AI paradigms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBanach - Bregman\u6846\u67b6\u7528\u4e8e\u968f\u673a\u8fed\u4ee3\uff0c\u7edf\u4e00\u4f18\u5316\u7406\u8bba\u4e0e\u5b9e\u8df5\uff0c\u5b9e\u8bc1\u663e\u793a\u5728\u591aAI\u8303\u5f0f\u4e2d\u6709\u66f4\u597d\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u968f\u673a\u4f18\u5316\u7406\u8bba\u5c40\u9650\u4e8e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u65e0\u6cd5\u5904\u7406\u975e\u6b27\u51e0\u91cc\u5f97\u8bbe\u7f6e\uff0c\u9700\u65b0\u6846\u67b6\u3002", "method": "\u5f15\u5165Banach - Bregman\u6846\u67b6\uff0c\u901a\u8fc7Bregman\u6295\u5f71\u548cBregman - Fejer\u5355\u8c03\u6027\u63d0\u4f9b\u7edf\u4e00\u6a21\u677f\uff0c\u5efa\u7acb\u8d85\u677e\u5f1b\u6761\u4ef6\uff0c\u7ed9\u51fa\u6536\u655b\u5b9a\u7406\u3002", "result": "\u5728\u5408\u6210\u548c\u73b0\u5b9e\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u5728\u591aAI\u8303\u5f0f\u91cc\u6bd4\u7ecf\u5178\u57fa\u7ebf\u6536\u655b\u5feb20%\uff0c\u65b9\u5dee\u964d\u4f4e\uff0c\u7cbe\u5ea6\u63d0\u9ad8\u3002", "conclusion": "Banach - Bregman\u51e0\u4f55\u53ef\u4f5c\u4e3a\u7edf\u4e00\u6838\u5fc3AI\u8303\u5f0f\u4f18\u5316\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u57fa\u77f3\u3002"}}
{"id": "2509.14219", "pdf": "https://arxiv.org/pdf/2509.14219", "abs": "https://arxiv.org/abs/2509.14219", "authors": ["Jiaqi Yao", "Lewis Mitchell", "John Maclean", "Hemanth Saratchandran"], "title": "Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems", "categories": ["cs.LG", "math.DS", "physics.comp-ph"], "comment": null, "summary": "Data-driven modeling of nonlinear dynamical systems is often hampered by\nmeasurement noise. We propose a denoising framework, called Runge-Kutta and\nTotal Variation Based Implicit Neural Representation (RKTV-INR), that\nrepresents the state trajectory with an implicit neural representation (INR)\nfitted directly to noisy observations. Runge-Kutta integration and total\nvariation are imposed as constraints to ensure that the reconstructed state is\na trajectory of a dynamical system that remains close to the original data. The\ntrained INR yields a clean, continuous trajectory and provides accurate\nfirst-order derivatives via automatic differentiation. These denoised states\nand derivatives are then supplied to Sparse Identification of Nonlinear\nDynamics (SINDy) to recover the governing equations. Experiments demonstrate\neffective noise suppression, precise derivative estimation, and reliable system\nidentification.", "AI": {"tldr": "\u63d0\u51faRKTV - INR\u53bb\u566a\u6846\u67b6\u5904\u7406\u542b\u566a\u6570\u636e\u4ee5\u6062\u590d\u52a8\u529b\u7cfb\u7edf\u63a7\u5236\u65b9\u7a0b\uff0c\u5b9e\u9a8c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u5e38\u53d7\u6d4b\u91cf\u566a\u58f0\u963b\u788d\u3002", "method": "\u63d0\u51faRKTV - INR\u6846\u67b6\uff0c\u7528\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u62df\u5408\u542b\u566a\u89c2\u6d4b\u6570\u636e\uff0c\u65bd\u52a0\u9f99\u683c - \u5e93\u5854\u79ef\u5206\u548c\u603b\u53d8\u5dee\u7ea6\u675f\uff0c\u5c06\u53bb\u566a\u540e\u7684\u72b6\u6001\u548c\u5bfc\u6570\u8f93\u5165SINDy\u6062\u590d\u63a7\u5236\u65b9\u7a0b\u3002", "result": "\u5b9e\u73b0\u6709\u6548\u566a\u58f0\u6291\u5236\u3001\u7cbe\u786e\u5bfc\u6570\u4f30\u8ba1\u548c\u53ef\u9760\u7cfb\u7edf\u8bc6\u522b\u3002", "conclusion": "RKTV - INR\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u6d4b\u91cf\u566a\u58f0\uff0c\u6062\u590d\u52a8\u529b\u7cfb\u7edf\u63a7\u5236\u65b9\u7a0b\u3002"}}
{"id": "2509.14223", "pdf": "https://arxiv.org/pdf/2509.14223", "abs": "https://arxiv.org/abs/2509.14223", "authors": ["Dmitrii Krasheninnikov", "Richard E. Turner", "David Krueger"], "title": "Language models' activations linearly encode training-order recency", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We show that language models' activations linearly encode when information\nwas learned during training. Our setup involves creating a model with a known\ntraining order by sequentially fine-tuning Llama-3.2-1B on six disjoint but\notherwise similar datasets about named entities. We find that the average\nactivations of test samples for the six training datasets encode the training\norder: when projected into a 2D subspace, these centroids are arranged exactly\nin the order of training and lie on a straight line. Further, we show that\nlinear probes can accurately (~90%) distinguish \"early\" vs. \"late\" entities,\ngeneralizing to entities unseen during the probes' own training. The model can\nalso be fine-tuned to explicitly report an unseen entity's training stage (~80%\naccuracy). Interestingly, this temporal signal does not seem attributable to\nsimple differences in activation magnitudes, losses, or model confidence. Our\npaper demonstrates that models are capable of differentiating information by\nits acquisition time, and carries significant implications for how they might\nmanage conflicting data and respond to knowledge modifications.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u503c\u7ebf\u6027\u7f16\u7801\u8bad\u7ec3\u65f6\u4fe1\u606f\u5b66\u4e60\u7684\u65f6\u95f4\u3002", "motivation": "\u63a2\u7a76\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5bf9\u8bad\u7ec3\u65f6\u4fe1\u606f\u5b66\u4e60\u7684\u65f6\u95f4\u8fdb\u884c\u7f16\u7801\u3002", "method": "\u5bf9Llama - 3.2 - 1B\u5728\u516d\u4e2a\u4e0d\u76f8\u4ea4\u4f46\u76f8\u4f3c\u7684\u547d\u540d\u5b9e\u4f53\u6570\u636e\u96c6\u4e0a\u987a\u5e8f\u5fae\u8c03\uff0c\u521b\u5efa\u5df2\u77e5\u8bad\u7ec3\u987a\u5e8f\u7684\u6a21\u578b\u3002", "result": "\u6d4b\u8bd5\u6837\u672c\u5e73\u5747\u6fc0\u6d3b\u503c\u7f16\u7801\u8bad\u7ec3\u987a\u5e8f\uff0c\u7ebf\u6027\u63a2\u9488\u80fd\u51c6\u786e\u533a\u5206\u2018\u65e9\u671f\u2019\u548c\u2018\u665a\u671f\u2019\u5b9e\u4f53\uff0c\u6a21\u578b\u53ef\u5fae\u8c03\u4ee5\u62a5\u544a\u672a\u89c1\u5b9e\u4f53\u8bad\u7ec3\u9636\u6bb5\uff0c\u4e14\u65f6\u95f4\u4fe1\u53f7\u5e76\u975e\u6e90\u4e8e\u6fc0\u6d3b\u5e45\u5ea6\u3001\u635f\u5931\u6216\u6a21\u578b\u7f6e\u4fe1\u5ea6\u5dee\u5f02\u3002", "conclusion": "\u6a21\u578b\u80fd\u591f\u6309\u4fe1\u606f\u83b7\u53d6\u65f6\u95f4\u533a\u5206\u4fe1\u606f\uff0c\u5bf9\u5904\u7406\u51b2\u7a81\u6570\u636e\u548c\u77e5\u8bc6\u4fee\u6539\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.13499", "pdf": "https://arxiv.org/pdf/2509.13499", "abs": "https://arxiv.org/abs/2509.13499", "authors": ["Susobhan Ghosh", "Bhanu T. Gulapalli", "Daiqi Gao", "Asim Gazi", "Anna Trella", "Ziping Xu", "Kelly Zhang", "Susan A. Murphy"], "title": "Reproducible workflow for online AI in digital health", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Online artificial intelligence (AI) algorithms are an important component of\ndigital health interventions. These online algorithms are designed to\ncontinually learn and improve their performance as streaming data is collected\non individuals. Deploying online AI presents a key challenge: balancing\nadaptability of online AI with reproducibility. Online AI in digital\ninterventions is a rapidly evolving area, driven by advances in algorithms,\nsensors, software, and devices. Digital health intervention development and\ndeployment is a continuous process, where implementation - including the AI\ndecision-making algorithm - is interspersed with cycles of re-development and\noptimization. Each deployment informs the next, making iterative deployment a\ndefining characteristic of this field. This iterative nature underscores the\nimportance of reproducibility: data collected across deployments must be\naccurately stored to have scientific utility, algorithm behavior must be\nauditable, and results must be comparable over time to facilitate scientific\ndiscovery and trustworthy refinement. This paper proposes a reproducible\nscientific workflow for developing, deploying, and analyzing online AI\ndecision-making algorithms in digital health interventions. Grounded in\npractical experience from multiple real-world deployments, this workflow\naddresses key challenges to reproducibility across all phases of the online AI\nalgorithm development life-cycle.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6570\u5b57\u5065\u5eb7\u5e72\u9884\u4e2d\u5728\u7ebfAI\u51b3\u7b56\u7b97\u6cd5\u7684\u53ef\u590d\u73b0\u79d1\u5b66\u5de5\u4f5c\u6d41\uff0c\u5e94\u5bf9\u53ef\u590d\u73b0\u6027\u6311\u6218\u3002", "motivation": "\u5728\u7ebfAI\u5728\u6570\u5b57\u5065\u5eb7\u5e72\u9884\u4e2d\u90e8\u7f72\u9762\u4e34\u9002\u5e94\u6027\u4e0e\u53ef\u590d\u73b0\u6027\u5e73\u8861\u7684\u6311\u6218\uff0c\u4e14\u8be5\u9886\u57df\u8fed\u4ee3\u90e8\u7f72\u7279\u6027\u51f8\u663e\u53ef\u590d\u73b0\u6027\u91cd\u8981\u6027\u3002", "method": "\u57fa\u4e8e\u591a\u4e2a\u5b9e\u9645\u90e8\u7f72\u7684\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u63d0\u51fa\u4e00\u4e2a\u79d1\u5b66\u5de5\u4f5c\u6d41\u3002", "result": "\u63d0\u51fa\u7684\u5de5\u4f5c\u6d41\u80fd\u5e94\u5bf9\u5728\u7ebfAI\u7b97\u6cd5\u5f00\u53d1\u751f\u547d\u5468\u671f\u5404\u9636\u6bb5\u53ef\u590d\u73b0\u6027\u7684\u5173\u952e\u6311\u6218\u3002", "conclusion": "\u8be5\u53ef\u590d\u73b0\u7684\u79d1\u5b66\u5de5\u4f5c\u6d41\u6709\u52a9\u4e8e\u6570\u5b57\u5065\u5eb7\u5e72\u9884\u4e2d\u5728\u7ebfAI\u51b3\u7b56\u7b97\u6cd5\u7684\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u5206\u6790\u3002"}}
{"id": "2509.13525", "pdf": "https://arxiv.org/pdf/2509.13525", "abs": "https://arxiv.org/abs/2509.13525", "authors": ["Romain Hardy", "Tyler Berzin", "Pranav Rajpurkar"], "title": "ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "12 pages, 8 figures", "summary": "Three-dimensional (3D) scene understanding in colonoscopy presents\nsignificant challenges that necessitate automated methods for accurate depth\nestimation. However, existing depth estimation models for endoscopy struggle\nwith temporal consistency across video sequences, limiting their applicability\nfor 3D reconstruction. We present ColonCrafter, a diffusion-based depth\nestimation model that generates temporally consistent depth maps from monocular\ncolonoscopy videos. Our approach learns robust geometric priors from synthetic\ncolonoscopy sequences to generate temporally consistent depth maps. We also\nintroduce a style transfer technique that preserves geometric structure while\nadapting real clinical videos to match our synthetic training domain.\nColonCrafter achieves state-of-the-art zero-shot performance on the C3VD\ndataset, outperforming both general-purpose and endoscopy-specific approaches.\nAlthough full trajectory 3D reconstruction remains a challenge, we demonstrate\nclinically relevant applications of ColonCrafter, including 3D point cloud\ngeneration and surface coverage assessment.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6269\u6563\u7684\u6df1\u5ea6\u4f30\u8ba1\u6a21\u578bColonCrafter\uff0c\u53ef\u4ece\u5355\u76ee\u7ed3\u80a0\u955c\u89c6\u9891\u751f\u6210\u65f6\u95f4\u4e00\u81f4\u7684\u6df1\u5ea6\u56fe\uff0c\u5728C3VD\u6570\u636e\u96c6\u4e0a\u6709\u96f6\u6837\u672c\u6700\u4f18\u8868\u73b0\uff0c\u5e76\u5c55\u793a\u4e34\u5e8a\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u5185\u7aa5\u955c\u6df1\u5ea6\u4f30\u8ba1\u6a21\u578b\u5728\u89c6\u9891\u5e8f\u5217\u65f6\u95f4\u4e00\u81f4\u6027\u4e0a\u5b58\u5728\u95ee\u9898\uff0c\u9650\u52363D\u91cd\u5efa\u5e94\u7528\uff0c\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u8fdb\u884c\u51c6\u786e\u6df1\u5ea6\u4f30\u8ba1\u3002", "method": "\u4ece\u5408\u6210\u7ed3\u80a0\u955c\u5e8f\u5217\u5b66\u4e60\u9c81\u68d2\u51e0\u4f55\u5148\u9a8c\u751f\u6210\u6df1\u5ea6\u56fe\uff0c\u5f15\u5165\u98ce\u683c\u8fc1\u79fb\u6280\u672f\u4f7f\u771f\u5b9e\u4e34\u5e8a\u89c6\u9891\u9002\u914d\u5408\u6210\u8bad\u7ec3\u57df\u3002", "result": "ColonCrafter\u5728C3VD\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u96f6\u6837\u672c\u6700\u4f18\u6027\u80fd\uff0c\u4f18\u4e8e\u901a\u7528\u548c\u5185\u7aa5\u955c\u7279\u5b9a\u65b9\u6cd5\u3002", "conclusion": "\u867d\u5168\u8f68\u8ff93D\u91cd\u5efa\u4ecd\u6709\u6311\u6218\uff0c\u4f46ColonCrafter\u6709\u4e34\u5e8a\u76f8\u5173\u5e94\u7528\uff0c\u59823D\u70b9\u4e91\u751f\u6210\u548c\u8868\u9762\u8986\u76d6\u8bc4\u4f30\u3002"}}
{"id": "2509.14230", "pdf": "https://arxiv.org/pdf/2509.14230", "abs": "https://arxiv.org/abs/2509.14230", "authors": ["Mengting Ai", "Tianxin Wei", "Sirui Chen", "Jingrui He"], "title": "NIRVANA: Structured pruning reimagined for large language models compression", "categories": ["cs.LG"], "comment": null, "summary": "Structured pruning of large language models (LLMs) offers substantial\nefficiency improvements by removing entire hidden units, yet current approaches\noften suffer from significant performance degradation, particularly in\nzero-shot settings, and necessitate costly recovery techniques such as\nsupervised fine-tuning (SFT) or adapter insertion. To address these critical\nshortcomings, we introduce NIRVANA, a novel pruning method explicitly designed\nto balance immediate zero-shot accuracy preservation with robust fine-tuning\ncapability. Leveraging a first-order saliency criterion derived from the Neural\nTangent Kernel under Adam optimization dynamics, NIRVANA provides a\ntheoretically grounded pruning strategy that respects essential model training\nbehaviors. To further address the unique challenges posed by structured\npruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across\nlayers and modules (attention vs. MLP), which adjusts pruning intensity between\nmodules in a globally balanced manner. Additionally, to mitigate the high\nsensitivity of pruning decisions to calibration data quality, we propose a\nsimple yet effective KL divergence-based calibration data selection strategy,\nensuring more reliable and task-agnostic pruning outcomes. Comprehensive\nexperiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA\noutperforms existing structured pruning methods under equivalent sparsity\nconstraints, providing a theoretically sound and practical approach to LLM\ncompression. The code is available at\nhttps://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.", "AI": {"tldr": "\u63d0\u51faNIRVANA\u526a\u679d\u65b9\u6cd5\u5e73\u8861\u5927\u8bed\u8a00\u6a21\u578b\u96f6\u6837\u672c\u51c6\u786e\u7387\u548c\u5fae\u8c03\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u9700\u6602\u8d35\u6062\u590d\u6280\u672f\uff0c\u8981\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5229\u7528Adam\u4f18\u5316\u52a8\u529b\u5b66\u4e0b\u795e\u7ecf\u5207\u7ebf\u6838\u7684\u4e00\u9636\u663e\u8457\u6027\u51c6\u5219\uff0c\u7ed3\u5408\u8de8\u5c42\u548c\u6a21\u5757\u7684\u81ea\u9002\u5e94\u7a00\u758f\u5206\u914d\u673a\u5236\uff0c\u63d0\u51fa\u57fa\u4e8eKL\u6563\u5ea6\u7684\u6821\u51c6\u6570\u636e\u9009\u62e9\u7b56\u7565\u3002", "result": "\u5728Llama3\u3001Qwen\u548cT5\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0cNIRVANA\u5728\u76f8\u540c\u7a00\u758f\u7ea6\u675f\u4e0b\u4f18\u4e8e\u73b0\u6709\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u3002", "conclusion": "NIRVANA\u662f\u4e00\u79cd\u7406\u8bba\u53ef\u9760\u4e14\u5b9e\u7528\u7684\u5927\u8bed\u8a00\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u3002"}}
{"id": "2509.13550", "pdf": "https://arxiv.org/pdf/2509.13550", "abs": "https://arxiv.org/abs/2509.13550", "authors": ["Phillipe R. Sampaio"], "title": "Complexity Bounds for Smooth Convex Multiobjective Optimization", "categories": ["math.OC", "cs.AI"], "comment": "16 pages", "summary": "We study the oracle complexity of finding $\\varepsilon$-Pareto stationary\npoints in smooth multiobjective optimization with $m$ objectives. The progress\nmetric is the Pareto stationarity gap $\\mathcal{G}(x)$ (the norm of an optimal\nconvex combination of gradients). Our contributions are fourfold. (i) For\nstrongly convex objectives, any span first-order method (iterates lie in the\nspan of past gradients) exhibits linear convergence no faster than\n$\\exp(-\\Theta(T/\\sqrt{\\kappa}))$ after $T$ oracle calls, where $\\kappa$ is the\ncondition number, implying $\\Theta(\\sqrt{\\kappa}\\log(1/\\varepsilon))$\niterations; this matches classical accelerated upper bounds. (ii) For convex\nproblems and oblivious one-step methods (a fixed scalarization with\npre-scheduled step sizes), we prove a lower bound of order $1/T$ on the best\ngradient norm among the first $T$ iterates. (iii) Although accelerated gradient\ndescent is outside this restricted class, it is an oblivious span method and\nattains the same $1/T$ upper rate on a fixed scalarization. (iv) For convex\nproblems and general span methods with adaptive scalarizations, we establish a\nuniversal lower bound of order $1/T^{2}$ on the gradient norm of the final\niterate after $T$ steps, highlighting a gap between known upper bounds and\nworst-case guarantees. All bounds hold on non-degenerate instances with\ndistinct objectives and non-singleton Pareto fronts; rates are stated up to\nuniversal constants and natural problem scaling.", "AI": {"tldr": "\u7814\u7a76\u5149\u6ed1\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u627e\u03b5 - Pareto\u9a7b\u70b9\u7684oracle\u590d\u6742\u5ea6\uff0c\u7ed9\u51fa\u5f3a\u51f8\u3001\u51f8\u95ee\u9898\u4e0d\u540c\u65b9\u6cd5\u7684\u6536\u655b\u901f\u7387\u4e0b\u754c\u3002", "motivation": "\u7814\u7a76\u5149\u6ed1\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u627e\u03b5 - Pareto\u9a7b\u70b9\u7684oracle\u590d\u6742\u5ea6\u3002", "method": "\u5206\u6790\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\uff08\u5f3a\u51f8\u3001\u51f8\uff09\u548c\u4e0d\u540c\u65b9\u6cd5\uff08span\u4e00\u9636\u65b9\u6cd5\u3001oblivious\u4e00\u6b65\u65b9\u6cd5\u3001\u52a0\u901f\u68af\u5ea6\u4e0b\u964d\u3001\u4e00\u822cspan\u65b9\u6cd5\uff09\u3002", "result": "\u7ed9\u51fa\u4e0d\u540c\u60c5\u51b5\u4e0b\u7684\u6536\u655b\u901f\u7387\u4e0b\u754c\uff0c\u5982\u5f3a\u51f8\u95ee\u9898\u7ebf\u6027\u6536\u655b\u901f\u7387\uff0c\u51f8\u95ee\u9898\u4e0d\u540c\u65b9\u6cd51/T\u62161/T\u00b2\u7684\u901f\u7387\u3002", "conclusion": "\u4e0d\u540c\u65b9\u6cd5\u5728\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u6709\u4e0d\u540c\u6536\u655b\u901f\u7387\uff0c\u90e8\u5206\u60c5\u51b5\u5b58\u5728\u5df2\u77e5\u4e0a\u754c\u548c\u6700\u574f\u60c5\u51b5\u4fdd\u8bc1\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.14234", "pdf": "https://arxiv.org/pdf/2509.14234", "abs": "https://arxiv.org/abs/2509.14234", "authors": ["Dulhan Jayalath", "Shashwat Goel", "Thomas Foster", "Parag Jain", "Suchin Gururangan", "Cheng Zhang", "Anirudh Goyal", "Alan Schelten"], "title": "Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision", "categories": ["cs.LG"], "comment": "22 pages, 8 figures, 2 tables", "summary": "Where do learning signals come from when there is no ground truth in\npost-training? We propose turning exploration into supervision through Compute\nas Teacher (CaT), which converts the model's own exploration at inference-time\ninto reference-free supervision by synthesizing a single reference from a group\nof parallel rollouts and then optimizing toward it. Concretely, the current\npolicy produces a group of rollouts; a frozen anchor (the initial policy)\nreconciles omissions and contradictions to estimate a reference, turning extra\ninference-time compute into a teacher signal. We turn this into rewards in two\nregimes: (i) verifiable tasks use programmatic equivalence on final answers;\n(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria\nscored by an independent LLM judge, with reward given by the fraction\nsatisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge\nscores), synthesis may disagree with the majority and be correct even when all\nrollouts are wrong; performance scales with the number of rollouts. As a\ntest-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up\nto +27% on MATH-500; +12% on HealthBench). With reinforcement learning\n(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained\npolicy surpassing the initial teacher signal.", "AI": {"tldr": "\u63d0\u51faCompute as Teacher (CaT)\u65b9\u6cd5\uff0c\u5c06\u6a21\u578b\u63a8\u7406\u65f6\u7684\u63a2\u7d22\u8f6c\u5316\u4e3a\u65e0\u53c2\u8003\u76d1\u7763\uff0c\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u751f\u6210\u5956\u52b1\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6709\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u8bad\u7ec3\u540e\u65e0\u771f\u5b9e\u6807\u7b7e\u65f6\u5b66\u4e60\u4fe1\u53f7\u6765\u6e90\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5408\u6210\u4e00\u7ec4\u5e76\u884c\u63a8\u6f14\u7684\u5355\u4e2a\u53c2\u8003\uff0c\u5c06\u6a21\u578b\u63a8\u7406\u65f6\u7684\u63a2\u7d22\u8f6c\u5316\u4e3a\u65e0\u53c2\u8003\u76d1\u7763\uff1b\u5728\u53ef\u9a8c\u8bc1\u548c\u4e0d\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u5206\u522b\u751f\u6210\u5956\u52b1\u3002", "result": "\u4f5c\u4e3a\u6d4b\u8bd5\u65f6\u7a0b\u5e8f\uff0cCaT\u63d0\u5347\u4e86Gemma 3 4B\u3001Qwen 3 4B\u548cLlama 3.1 8B\u7684\u6027\u80fd\uff1b\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6709\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "CaT\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5c06\u63a2\u7d22\u8f6c\u5316\u4e3a\u76d1\u7763\u4fe1\u53f7\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6548\u679c\u66f4\u4f73\u3002"}}
{"id": "2509.13574", "pdf": "https://arxiv.org/pdf/2509.13574", "abs": "https://arxiv.org/abs/2509.13574", "authors": ["Zidong Chen", "Zihao Guo", "Peng Wang", "ThankGod Itua Egbe", "Yan Lyu", "Chenghao Qian"], "title": "Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Flow matching has emerged as a competitive framework for learning\nhigh-quality generative policies in robotics; however, we find that\ngeneralisation arises and saturates early along the flow trajectory, in\naccordance with recent findings in the literature. We further observe that\nincreasing the number of Euler integration steps during inference\ncounter-intuitively and universally degrades policy performance. We attribute\nthis to (i) additional, uniformly spaced integration steps oversample the\nlate-time region, thereby constraining actions towards the training\ntrajectories and reducing generalisation; and (ii) the learned velocity field\nbecoming non-Lipschitz as integration time approaches 1, causing instability.\nTo address these issues, we propose a novel policy that utilises non-uniform\ntime scheduling (e.g., U-shaped) during training, which emphasises both early\nand late temporal stages to regularise policy training, and a dense-jump\nintegration schedule at inference, which uses a single-step integration to\nreplace the multi-step integration beyond a jump point, to avoid unstable areas\naround 1. Essentially, our policy is an efficient one-step learner that still\npushes forward performance through multi-step integration, yielding up to 23.7%\nperformance gains over state-of-the-art baselines across diverse robotic tasks.", "AI": {"tldr": "\u53d1\u73b0\u6d41\u5339\u914d\u5728\u673a\u5668\u4eba\u751f\u6210\u7b56\u7565\u6cdb\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u975e\u5747\u5300\u65f6\u95f4\u8c03\u5ea6\u548c\u5bc6\u96c6\u8df3\u8dc3\u79ef\u5206\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6d41\u5339\u914d\u5728\u673a\u5668\u4eba\u751f\u6210\u7b56\u7565\u4e2d\u6cdb\u5316\u65e9\u9971\u548c\u3001\u589e\u52a0\u6b27\u62c9\u79ef\u5206\u6b65\u6570\u53cd\u800c\u964d\u4f4e\u6027\u80fd\u7684\u95ee\u9898\u3002", "method": "\u8bad\u7ec3\u65f6\u91c7\u7528\u975e\u5747\u5300\u65f6\u95f4\u8c03\u5ea6\uff08\u5982U\u578b\uff09\uff0c\u63a8\u7406\u65f6\u91c7\u7528\u5bc6\u96c6\u8df3\u8dc3\u79ef\u5206\u7b56\u7565\u3002", "result": "\u5728\u4e0d\u540c\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u6bd4\u73b0\u6709\u57fa\u7ebf\u6027\u80fd\u63d0\u5347\u8fbe23.7%\u3002", "conclusion": "\u6240\u63d0\u7b56\u7565\u662f\u9ad8\u6548\u5355\u6b65\u5b66\u4e60\u5668\uff0c\u901a\u8fc7\u591a\u6b65\u79ef\u5206\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2509.12510", "pdf": "https://arxiv.org/pdf/2509.12510", "abs": "https://arxiv.org/abs/2509.12510", "authors": ["Wei Shao", "Ruoyu Zhang", "Zequan Liang", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun"], "title": "Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device", "categories": ["eess.SP", "cs.LG"], "comment": "In the proceedings of IEEE-EMBS BSN 2025", "summary": "Wearable photoplethysmography (PPG) is embedded in billions of devices, yet\nits optical waveform is easily corrupted by motion, perfusion loss, and ambient\nlight, jeopardizing downstream cardiometric analytics. Existing signal-quality\nassessment (SQA) methods rely either on brittle heuristics or on data-hungry\nsupervised models. We introduce the first fully unsupervised SQA pipeline for\nwrist PPG. Stage 1 trains a contrastive 1-D ResNet-18 on 276 h of raw,\nunlabeled data from heterogeneous sources (varying in device and sampling\nfrequency), yielding optical-emitter- and motion-invariant embeddings (i.e.,\nthe learned representation is stable across differences in LED wavelength,\ndrive intensity, and device optics, as well as wrist motion). Stage 2 converts\neach 512-D encoder embedding into a 4-D topological signature via persistent\nhomology (PH) and clusters these signatures with HDBSCAN. To produce a binary\nsignal-quality index (SQI), the acceptable PPG signals are represented by the\ndensest cluster while the remaining clusters are assumed to mainly contain\npoor-quality PPG signals. Without re-tuning, the SQI attains Silhouette,\nDavies-Bouldin, and Calinski-Harabasz scores of 0.72, 0.34, and 6173,\nrespectively, on a stratified sample of 10,000 windows. In this study, we\npropose a hybrid self-supervised-learning--topological-data-analysis (SSL--TDA)\nframework that offers a drop-in, scalable, cross-device quality gate for PPG\nsignals.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u7528\u4e8e\u624b\u8155PPG\u7684\u5b8c\u5168\u65e0\u76d1\u7763\u4fe1\u53f7\u8d28\u91cf\u8bc4\u4f30\uff08SQA\uff09\u7ba1\u9053\uff0c\u7ed3\u5408\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u62d3\u6251\u6570\u636e\u5206\u6790\uff0c\u53ef\u4f5c\u4e3aPPG\u4fe1\u53f7\u7684\u8d28\u91cf\u95e8\u3002", "motivation": "\u73b0\u6709PPG\u4fe1\u53f7\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8981\u4e48\u4f9d\u8d56\u6570\u636e\u91cf\u5927\u7684\u76d1\u7763\u6a21\u578b\uff0c\u800cPPG\u5149\u5b66\u6ce2\u5f62\u6613\u53d7\u591a\u79cd\u56e0\u7d20\u5e72\u6270\u3002", "method": "\u7b2c\u4e00\u9636\u6bb5\u5728276\u5c0f\u65f6\u539f\u59cb\u672a\u6807\u8bb0\u6570\u636e\u4e0a\u8bad\u7ec3\u5bf9\u6bd4\u5f0f1 - D ResNet - 18\u5f97\u5230\u4e0d\u53d8\u5d4c\u5165\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u6301\u4e45\u540c\u8c03\u5c06\u5d4c\u5165\u8f6c\u6362\u4e3a\u62d3\u6251\u7b7e\u540d\u5e76\u805a\u7c7b\uff0c\u4ee5\u4ea7\u751f\u4e8c\u8fdb\u5236\u4fe1\u53f7\u8d28\u91cf\u6307\u6570\u3002", "result": "\u572810000\u4e2a\u7a97\u53e3\u7684\u5206\u5c42\u6837\u672c\u4e0a\uff0c\u4fe1\u53f7\u8d28\u91cf\u6307\u6570\u7684\u8f6e\u5ed3\u7cfb\u6570\u3001\u6234\u7ef4\u65af - \u5e03\u5c14\u4e01\u6307\u6570\u548c\u5361\u6797\u65af\u57fa - \u54c8\u62c9\u5df4\u65af\u6307\u6570\u5206\u522b\u8fbe\u52300.72\u30010.34\u548c6173\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408\u81ea\u76d1\u7763\u5b66\u4e60 - \u62d3\u6251\u6570\u636e\u5206\u6790\u6846\u67b6\u53ef\u4f5c\u4e3aPPG\u4fe1\u53f7\u7684\u53ef\u6269\u5c55\u3001\u8de8\u8bbe\u5907\u8d28\u91cf\u95e8\u3002"}}
{"id": "2509.13579", "pdf": "https://arxiv.org/pdf/2509.13579", "abs": "https://arxiv.org/abs/2509.13579", "authors": ["Momchil S. Tomov", "Sang Uk Lee", "Hansford Hendrago", "Jinwook Huh", "Teawon Han", "Forbes Howington", "Rafael da Silva", "Gianmarco Bernasconi", "Marc Heim", "Samuel Findler", "Xiaonan Ji", "Alexander Boule", "Michael Napoli", "Kuo Chen", "Jesse Miller", "Boaz Floor", "Yunqing Hu"], "title": "TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "We present TreeIRL, a novel planner for autonomous driving that combines\nMonte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to\nachieve state-of-the-art performance in simulation and in real-world driving.\nThe core idea is to use MCTS to find a promising set of safe candidate\ntrajectories and a deep IRL scoring function to select the most human-like\namong them. We evaluate TreeIRL against both classical and state-of-the-art\nplanners in large-scale simulations and on 500+ miles of real-world autonomous\ndriving in the Las Vegas metropolitan area. Test scenarios include dense urban\ntraffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves\nthe best overall performance, striking a balance between safety, progress,\ncomfort, and human-likeness. To our knowledge, our work is the first\ndemonstration of MCTS-based planning on public roads and underscores the\nimportance of evaluating planners across a diverse set of metrics and in\nreal-world environments. TreeIRL is highly extensible and could be further\nimproved with reinforcement learning and imitation learning, providing a\nframework for exploring different combinations of classical and learning-based\napproaches to solve the planning bottleneck in autonomous driving.", "AI": {"tldr": "\u63d0\u51faTreeIRL\u89c4\u5212\u5668\uff0c\u7ed3\u5408MCTS\u548cIRL\uff0c\u5728\u4eff\u771f\u548c\u73b0\u5b9e\u9a7e\u9a76\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u74f6\u9888\uff0c\u5b9e\u73b0\u66f4\u4f18\u89c4\u5212\u6027\u80fd\u3002", "method": "\u7ed3\u5408\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\uff08MCTS\uff09\u548c\u9006\u5f3a\u5316\u5b66\u4e60\uff08IRL\uff09\uff0c\u7528MCTS\u627e\u5019\u9009\u8f68\u8ff9\uff0c\u7528IRL\u8bc4\u5206\u51fd\u6570\u9009\u6700\u4f3c\u4eba\u7c7b\u7684\u8f68\u8ff9\u3002", "result": "\u5728\u5927\u89c4\u6a21\u4eff\u771f\u548c500\u591a\u82f1\u91cc\u73b0\u5b9e\u9a7e\u9a76\u6d4b\u8bd5\u4e2d\uff0cTreeIRL\u8868\u73b0\u6700\u4f73\uff0c\u5e73\u8861\u4e86\u5b89\u5168\u3001\u8fdb\u5ea6\u3001\u8212\u9002\u548c\u7c7b\u4eba\u7a0b\u5ea6\u3002", "conclusion": "TreeIRL\u662f\u9996\u6b21\u57fa\u4e8eMCTS\u7684\u516c\u5171\u9053\u8def\u89c4\u5212\uff0c\u5f3a\u8c03\u591a\u6307\u6807\u548c\u73b0\u5b9e\u73af\u5883\u8bc4\u4f30\u89c4\u5212\u5668\u7684\u91cd\u8981\u6027\uff0c\u4e14\u5177\u6709\u9ad8\u6269\u5c55\u6027\u3002"}}
{"id": "2509.13326", "pdf": "https://arxiv.org/pdf/2509.13326", "abs": "https://arxiv.org/abs/2509.13326", "authors": ["Hemil Mehta", "Tanvi Raut", "Kohav Yadav", "Edward F. Gehringer"], "title": "LLM Chatbot-Creation Approaches", "categories": ["cs.HC", "cs.LG"], "comment": "Forthcoming in Frontiers in Education (FIE 2025), Nashville,\n  Tennessee, USA, Nov 2-5, 2025", "summary": "This full research-to-practice paper explores approaches for developing\ncourse chatbots by comparing low-code platforms and custom-coded solutions in\neducational contexts. With the rise of Large Language Models (LLMs) like GPT-4\nand LLaMA, LLM-based chatbots are being integrated into teaching workflows to\nautomate tasks, provide assistance, and offer scalable support. However,\nselecting the optimal development strategy requires balancing ease of use,\ncustomization, data privacy, and scalability. This study compares two\ndevelopment approaches: low-code platforms like AnythingLLM and Botpress, with\ncustom-coded solutions using LangChain, FAISS, and FastAPI. The research uses\nPrompt engineering, Retrieval-augmented generation (RAG), and personalization\nto evaluate chatbot prototypes across technical performance, scalability, and\nuser experience. Findings indicate that while low-code platforms enable rapid\nprototyping, they face limitations in customization and scaling, while\ncustom-coded systems offer more control but require significant technical\nexpertise. Both approaches successfully implement key research principles such\nas adaptive feedback loops and conversational continuity. The study provides a\nframework for selecting the appropriate development strategy based on\ninstitutional goals and resources. Future work will focus on hybrid solutions\nthat combine low-code accessibility with modular customization and incorporate\nmultimodal input for intelligent tutoring systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4f4e\u4ee3\u7801\u5e73\u53f0\u548c\u81ea\u5b9a\u4e49\u7f16\u7801\u89e3\u51b3\u65b9\u6848\u5728\u6559\u80b2\u573a\u666f\u5f00\u53d1\u8bfe\u7a0b\u804a\u5929\u673a\u5668\u4eba\u7684\u65b9\u6cd5\uff0c\u7ed9\u51fa\u9009\u62e9\u5f00\u53d1\u7b56\u7565\u7684\u6846\u67b6\uff0c\u672a\u6765\u5173\u6ce8\u6df7\u5408\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5174\u8d77\uff0cLLM \u804a\u5929\u673a\u5668\u4eba\u7528\u4e8e\u6559\u5b66\uff0c\u4f46\u9009\u62e9\u5f00\u53d1\u7b56\u7565\u9700\u5e73\u8861\u6613\u7528\u6027\u3001\u5b9a\u5236\u6027\u3001\u6570\u636e\u9690\u79c1\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5bf9\u6bd4\u4f4e\u4ee3\u7801\u5e73\u53f0\uff08\u5982 AnythingLLM \u548c Botpress\uff09\u4e0e\u4f7f\u7528 LangChain\u3001FAISS \u548c FastAPI \u7684\u81ea\u5b9a\u4e49\u7f16\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u63d0\u793a\u5de5\u7a0b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e2a\u6027\u5316\u8bc4\u4f30\u804a\u5929\u673a\u5668\u4eba\u539f\u578b\u3002", "result": "\u4f4e\u4ee3\u7801\u5e73\u53f0\u53ef\u5feb\u901f\u539f\u578b\u5f00\u53d1\uff0c\u4f46\u5b9a\u5236\u548c\u6269\u5c55\u6709\u9650\uff1b\u81ea\u5b9a\u4e49\u7f16\u7801\u7cfb\u7edf\u63a7\u5236\u66f4\u591a\uff0c\u4f46\u9700\u5927\u91cf\u6280\u672f\u4e13\u957f\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u5b9e\u73b0\u4e86\u5173\u952e\u7814\u7a76\u539f\u5219\u3002", "conclusion": "\u63d0\u4f9b\u6839\u636e\u673a\u6784\u76ee\u6807\u548c\u8d44\u6e90\u9009\u62e9\u5408\u9002\u5f00\u53d1\u7b56\u7565\u7684\u6846\u67b6\uff0c\u672a\u6765\u5173\u6ce8\u7ed3\u5408\u4f4e\u4ee3\u7801\u53ef\u8bbf\u95ee\u6027\u548c\u6a21\u5757\u5316\u5b9a\u5236\u7684\u6df7\u5408\u89e3\u51b3\u65b9\u6848\u53ca\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u7684\u591a\u6a21\u6001\u8f93\u5165\u3002"}}
{"id": "2509.13590", "pdf": "https://arxiv.org/pdf/2509.13590", "abs": "https://arxiv.org/abs/2509.13590", "authors": ["Samer Al-Hamadani"], "title": "Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation", "categories": ["cs.CV", "cs.AI"], "comment": "32 pages, 14 figures, 6 tables", "summary": "The rapid advancement of artificial intelligence (AI) in healthcare imaging\nhas revolutionized diagnostic medicine and clinical decision-making processes.\nThis work presents an intelligent multimodal framework for medical image\nanalysis that leverages Vision-Language Models (VLMs) in healthcare\ndiagnostics. The framework integrates Google Gemini 2.5 Flash for automated\ntumor detection and clinical report generation across multiple imaging\nmodalities including CT, MRI, X-ray, and Ultrasound. The system combines visual\nfeature extraction with natural language processing to enable contextual image\ninterpretation, incorporating coordinate verification mechanisms and\nprobabilistic Gaussian modeling for anomaly distribution. Multi-layered\nvisualization techniques generate detailed medical illustrations, overlay\ncomparisons, and statistical representations to enhance clinical confidence,\nwith location measurement achieving 80 pixels average deviation. Result\nprocessing utilizes precise prompt engineering and textual analysis to extract\nstructured clinical information while maintaining interpretability.\nExperimental evaluations demonstrated high performance in anomaly detection\nacross multiple modalities. The system features a user-friendly Gradio\ninterface for clinical workflow integration and demonstrates zero-shot learning\ncapabilities to reduce dependence on large datasets. This framework represents\na significant advancement in automated diagnostic support and radiological\nworkflow efficiency, though clinical validation and multi-center evaluation are\nnecessary prior to widespread adoption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eVLMs\u7684\u533b\u7597\u56fe\u50cf\u5206\u6790\u667a\u80fd\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u79cd\u6280\u672f\u5b9e\u73b0\u80bf\u7624\u68c0\u6d4b\u548c\u62a5\u544a\u751f\u6210\uff0c\u5b9e\u9a8c\u8868\u73b0\u826f\u597d\uff0c\u6709\u96f6\u6837\u672c\u5b66\u4e60\u80fd\u529b\uff0c\u4f46\u9700\u4e34\u5e8a\u9a8c\u8bc1\u3002", "motivation": "\u5229\u7528\u4eba\u5de5\u667a\u80fd\u5728\u533b\u7597\u5f71\u50cf\u9886\u57df\u7684\u53d1\u5c55\uff0c\u6539\u8fdb\u533b\u7597\u8bca\u65ad\u548c\u4e34\u5e8a\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u96c6\u6210Google Gemini 2.5 Flash\uff0c\u7ed3\u5408\u89c6\u89c9\u7279\u5f81\u63d0\u53d6\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u91c7\u7528\u5750\u6807\u9a8c\u8bc1\u3001\u9ad8\u65af\u5efa\u6a21\u7b49\u6280\u672f\uff0c\u8fd0\u7528\u591a\u5c42\u53ef\u89c6\u5316\uff0c\u7ed3\u679c\u5904\u7406\u4f7f\u7528\u7cbe\u786e\u63d0\u793a\u5de5\u7a0b\u548c\u6587\u672c\u5206\u6790\u3002", "result": "\u5728\u591a\u6a21\u6001\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u9ad8\u6027\u80fd\uff0c\u5b9a\u4f4d\u6d4b\u91cf\u5e73\u5747\u504f\u5dee80\u50cf\u7d20\uff0c\u5177\u5907\u96f6\u6837\u672c\u5b66\u4e60\u80fd\u529b\uff0c\u6709\u7528\u6237\u53cb\u597d\u754c\u9762\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u81ea\u52a8\u8bca\u65ad\u652f\u6301\u548c\u653e\u5c04\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\u7684\u91cd\u5927\u8fdb\u6b65\uff0c\u4f46\u9700\u4e34\u5e8a\u9a8c\u8bc1\u548c\u591a\u4e2d\u5fc3\u8bc4\u4f30\u624d\u80fd\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2509.13597", "pdf": "https://arxiv.org/pdf/2509.13597", "abs": "https://arxiv.org/abs/2509.13597", "authors": ["Abhishek Goswami"], "title": "Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents", "categories": ["cs.CR", "cs.AI"], "comment": "17 pages, 6 figures, 2 Tables", "summary": "Autonomous LLM agents can issue thousands of API calls per hour without human\noversight. OAuth 2.0 assumes deterministic clients, but in agentic settings\nstochastic reasoning, prompt injection, or multi-agent orchestration can\nsilently expand privileges.\n  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each\nagent's action to verifiable user intent and, optionally, to a specific\nworkflow step. A-JWT carries an agent's identity as a one-way checksum hash\nderived from its prompt, tools and configuration, and a chained delegation\nassertion to prove which downstream agent may execute a given task, and\nper-agent proof-of-possession keys to prevent replay and in-process\nimpersonation. We define a new authorization mechanism and add a lightweight\nclient shim library that self-verifies code at run time, mints intent tokens,\ntracks workflow steps and derives keys, thus enabling secure agent identity and\nseparation even within a single process.\n  We illustrate a comprehensive threat model for agentic applications,\nimplement a Python proof-of-concept and show functional blocking of\nscope-violating requests, replay, impersonation, and prompt-injection pathways\nwith sub-millisecond overhead on commodity hardware. The design aligns with\nongoing OAuth agent discussions and offers a drop-in path toward zero-trust\nguarantees for agentic applications. A comprehensive performance and security\nevaluation with experimental results will appear in our forthcoming journal\npublication", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Agentic JWT\uff08A - JWT\uff09\u4ee5\u89e3\u51b3\u81ea\u4e3bLLM\u4ee3\u7406\u5728OAuth 2.0\u4e0b\u7684\u5b89\u5168\u95ee\u9898\uff0c\u5b9e\u73b0\u5b89\u5168\u4ee3\u7406\u8eab\u4efd\u548c\u9694\u79bb\uff0c\u901a\u8fc7\u6982\u5ff5\u9a8c\u8bc1\u5c55\u793a\u5176\u529f\u80fd\u5e76\u4e0eOAuth\u4ee3\u7406\u8ba8\u8bba\u4fdd\u6301\u4e00\u81f4\u3002", "motivation": "\u81ea\u4e3bLLM\u4ee3\u7406\u53ef\u5728\u65e0\u4eba\u76d1\u7763\u4e0b\u5927\u91cf\u8c03\u7528API\uff0c\u800cOAuth 2.0\u5728\u4ee3\u7406\u573a\u666f\u5b58\u5728\u56e0\u968f\u673a\u63a8\u7406\u3001\u63d0\u793a\u6ce8\u5165\u7b49\u5bfc\u81f4\u6743\u9650\u65e0\u58f0\u6269\u5c55\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165A - JWT\uff0c\u5b9a\u4e49\u65b0\u7684\u6388\u6743\u673a\u5236\uff0c\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u5ba2\u6237\u7aef\u57ab\u7247\u5e93\uff0c\u5b9e\u73b0\u8fd0\u884c\u65f6\u4ee3\u7801\u81ea\u9a8c\u8bc1\u3001\u751f\u6210\u610f\u56fe\u4ee4\u724c\u7b49\u3002", "result": "\u5b9e\u73b0Python\u6982\u5ff5\u9a8c\u8bc1\uff0c\u80fd\u5728\u5546\u54c1\u786c\u4ef6\u4e0a\u4ee5\u4e9a\u6beb\u79d2\u7ea7\u5f00\u9500\u963b\u6b62\u8fdd\u89c4\u8bf7\u6c42\u3001\u91cd\u653e\u3001\u6a21\u62df\u548c\u63d0\u793a\u6ce8\u5165\u7b49\uff0c\u8bbe\u8ba1\u4e0eOAuth\u4ee3\u7406\u8ba8\u8bba\u4e00\u81f4\u3002", "conclusion": "\u8bbe\u8ba1\u4e3a\u4ee3\u7406\u5e94\u7528\u63d0\u4f9b\u4e86\u8fc8\u5411\u96f6\u4fe1\u4efb\u4fdd\u969c\u7684\u9014\u5f84\uff0c\u5168\u9762\u6027\u80fd\u548c\u5b89\u5168\u8bc4\u4f30\u7ed3\u679c\u5c06\u5728\u540e\u7eed\u671f\u520a\u53d1\u8868\u3002"}}
{"id": "2509.13336", "pdf": "https://arxiv.org/pdf/2509.13336", "abs": "https://arxiv.org/abs/2509.13336", "authors": ["Mehran Behjati", "Rosdiadee Nordin", "Nor Fadzilah Abdullah"], "title": "Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning", "categories": ["cs.RO", "cs.LG"], "comment": "Submitted to an IEEE Conference", "summary": "This paper presents a reinforcement learning (RL) based approach for path\nplanning of cellular connected unmanned aerial vehicles (UAVs) operating beyond\nvisual line of sight (BVLoS). The objective is to minimize travel distance\nwhile maximizing the quality of cellular link connectivity by considering real\nworld aerial coverage constraints and employing an empirical aerial channel\nmodel. The proposed solution employs RL techniques to train an agent, using the\nquality of communication links between the UAV and base stations (BSs) as the\nreward function. Simulation results demonstrate the effectiveness of the\nproposed method in training the agent and generating feasible UAV path plans.\nThe proposed approach addresses the challenges due to limitations in UAV\ncellular communications, highlighting the need for investigations and\nconsiderations in this area. The RL algorithm efficiently identifies optimal\npaths, ensuring maximum connectivity with ground BSs to ensure safe and\nreliable BVLoS flight operation. Moreover, the solution can be deployed as an\noffline path planning module that can be integrated into future ground control\nsystems (GCS) for UAV operations, enhancing their capabilities and safety. The\nmethod holds potential for complex long range UAV applications, advancing the\ntechnology in the field of cellular connected UAV path planning.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u89c6\u8ddd\u5916\u8702\u7a9d\u8fde\u63a5\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u4eff\u771f\u9a8c\u8bc1\u6709\u6548\uff0c\u53ef\u96c6\u6210\u5230\u5730\u9762\u63a7\u5236\u7cfb\u7edf\uff0c\u6709\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u8702\u7a9d\u901a\u4fe1\u9650\u5236\u5e26\u6765\u7684\u6311\u6218\uff0c\u5728\u8003\u8651\u73b0\u5b9e\u7a7a\u4e2d\u8986\u76d6\u7ea6\u675f\u4e0b\uff0c\u6700\u5c0f\u5316\u98de\u884c\u8ddd\u79bb\u5e76\u6700\u5927\u5316\u8702\u7a9d\u94fe\u8def\u8fde\u63a5\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u8bad\u7ec3\u667a\u80fd\u4f53\uff0c\u4ee5\u65e0\u4eba\u673a\u4e0e\u57fa\u7ad9\u901a\u4fe1\u94fe\u8def\u8d28\u91cf\u4e3a\u5956\u52b1\u51fd\u6570\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8bad\u7ec3\u667a\u80fd\u4f53\u5e76\u751f\u6210\u53ef\u884c\u8def\u5f84\u89c4\u5212\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u80fd\u9ad8\u6548\u8bc6\u522b\u6700\u4f18\u8def\u5f84\uff0c\u786e\u4fdd\u6700\u5927\u8fde\u63a5\u6027\uff0c\u53ef\u4f5c\u4e3a\u79bb\u7ebf\u6a21\u5757\u96c6\u6210\u5230\u5730\u9762\u63a7\u5236\u7cfb\u7edf\uff0c\u63a8\u52a8\u8702\u7a9d\u8fde\u63a5\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2509.13620", "pdf": "https://arxiv.org/pdf/2509.13620", "abs": "https://arxiv.org/abs/2509.13620", "authors": ["Jeongjin", "Park", "Grant Bruer", "Huseyin Tuna Erdinc", "Abhinav Prakash Gahlot", "Felix J. Herrmann"], "title": "A reduced-order derivative-informed neural operator for subsurface fluid-flow", "categories": ["physics.comp-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Neural operators have emerged as cost-effective surrogates for expensive\nfluid-flow simulators, particularly in computationally intensive tasks such as\npermeability inversion from time-lapse seismic data, and uncertainty\nquantification. In these applications, the fidelity of the surrogate's\ngradients with respect to system parameters is crucial, as the accuracy of\ndownstream tasks, such as optimization and Bayesian inference, relies directly\non the quality of the derivative information. Recent advances in\nphysics-informed methods have leveraged derivative information to improve\nsurrogate accuracy. However, incorporating explicit Jacobians can become\ncomputationally prohibitive, as the complexity typically scales quadratically\nwith the number of input parameters. To address this limitation, we propose\nDeFINO (Derivative-based Fisher-score Informed Neural Operator), a\nreduced-order, derivative-informed training framework. DeFINO integrates\nFourier neural operators (FNOs) with a novel derivative-based training strategy\nguided by the Fisher Information Matrix (FIM). By projecting Jacobians onto\ndominant eigen-directions identified by the FIM, DeFINO captures critical\nsensitivity information directly informed by observational data, significantly\nreducing computational expense. We validate DeFINO through synthetic\nexperiments in the context of subsurface multi-phase fluid-flow, demonstrating\nimprovements in gradient accuracy while maintaining robust forward predictions\nof underlying fluid dynamics. These results highlight DeFINO's potential to\noffer practical, scalable solutions for inversion problems in complex\nreal-world scenarios, all at substantially reduced computational cost.", "AI": {"tldr": "\u63d0\u51faDeFINO\u6846\u67b6\u89e3\u51b3\u73b0\u6709\u795e\u7ecf\u7b97\u5b50\u6c42\u5bfc\u8ba1\u7b97\u6210\u672c\u9ad8\u95ee\u9898\uff0c\u5728\u5408\u6210\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u5176\u5728\u964d\u4f4e\u6210\u672c\u540c\u65f6\u63d0\u9ad8\u68af\u5ea6\u7cbe\u5ea6\u548c\u4fdd\u6301\u6b63\u5411\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7b97\u5b50\u5728\u5904\u7406\u4e0e\u7cfb\u7edf\u53c2\u6570\u76f8\u5173\u7684\u4e0b\u6e38\u4efb\u52a1\u65f6\uff0c\u4fdd\u771f\u68af\u5ea6\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u89e3\u51b3\u8be5\u9650\u5236\u3002", "method": "\u63d0\u51faDeFINO\u6846\u67b6\uff0c\u5c06\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u4e0e\u57fa\u4e8eFisher\u4fe1\u606f\u77e9\u9635\u5f15\u5bfc\u7684\u8bad\u7ec3\u7b56\u7565\u7ed3\u5408\uff0c\u628a\u96c5\u53ef\u6bd4\u77e9\u9635\u6295\u5f71\u5230\u4e3b\u5bfc\u7279\u5f81\u65b9\u5411\u3002", "result": "\u5728\u5730\u4e0b\u591a\u76f8\u6d41\u5408\u6210\u5b9e\u9a8c\u4e2d\uff0cDeFINO\u63d0\u9ad8\u4e86\u68af\u5ea6\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u6d41\u4f53\u52a8\u529b\u5b66\u7684\u7a33\u5065\u6b63\u5411\u9884\u6d4b\u3002", "conclusion": "DeFINO\u6709\u6f5c\u529b\u4e3a\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u53cd\u6f14\u95ee\u9898\u63d0\u4f9b\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u4e14\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13344", "pdf": "https://arxiv.org/pdf/2509.13344", "abs": "https://arxiv.org/abs/2509.13344", "authors": ["Md Ishtyaq Mahmud", "Veena Kochat", "Suresh Satpati", "Jagan Mohan Reddy Dwarampudi", "Kunal Rai", "Tania Banerjee"], "title": "Benchmarking Dimensionality Reduction Techniques for Spatial Transcriptomics", "categories": ["q-bio.GN", "cs.LG"], "comment": "This paper is accepted to the 16th ACM Conference on Bioinformatics,\n  Computational Biology, and Health Informatics (ACM-BCB 2025), 10 page and\n  have 4 figures", "summary": "We introduce a unified framework for evaluating dimensionality reduction\ntechniques in spatial transcriptomics beyond standard PCA approaches. We\nbenchmark six methods PCA, NMF, autoencoder, VAE, and two hybrid embeddings on\na cholangiocarcinoma Xenium dataset, systematically varying latent dimensions\n($k$=5-40) and clustering resolutions ($\\rho$=0.1-1.2). Each configuration is\nevaluated using complementary metrics including reconstruction error, explained\nvariance, cluster cohesion, and two novel biologically-motivated measures:\nCluster Marker Coherence (CMC) and Marker Exclusion Rate (MER). Our results\ndemonstrate distinct performance profiles: PCA provides a fast baseline, NMF\nmaximizes marker enrichment, VAE balances reconstruction and interpretability,\nwhile autoencoders occupy a middle ground. We provide systematic hyperparameter\nselection using Pareto optimal analysis and demonstrate how MER-guided\nreassignment improves biological fidelity across all methods, with CMC scores\nimproving by up to 12\\% on average. This framework enables principled selection\nof dimensionality reduction methods tailored to specific spatial\ntranscriptomics analyses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bc4\u4f30\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u964d\u7ef4\u6280\u672f\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5bf9\u516d\u79cd\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e0d\u540c\u6027\u80fd\uff0c\u63d0\u4f9b\u8d85\u53c2\u6570\u9009\u62e9\u548c\u6539\u8fdb\u751f\u7269\u4fdd\u771f\u5ea6\u65b9\u6cd5\uff0c\u5b9e\u73b0\u6709\u539f\u5219\u7684\u65b9\u6cd5\u9009\u62e9\u3002", "motivation": "\u5f15\u5165\u8d85\u8d8a\u6807\u51c6PCA\u7684\u7edf\u4e00\u6846\u67b6\u8bc4\u4f30\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u964d\u7ef4\u6280\u672f\u3002", "method": "\u5728\u80c6\u7ba1\u764cXenium\u6570\u636e\u96c6\u4e0a\u5bf9\u516d\u79cd\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u6539\u53d8\u6f5c\u5728\u7ef4\u5ea6\u548c\u805a\u7c7b\u5206\u8fa8\u7387\uff0c\u7528\u591a\u79cd\u6307\u6807\u8bc4\u4f30\uff0c\u4f7f\u7528Pareto\u6700\u4f18\u5206\u6790\u9009\u8d85\u53c2\u6570\uff0c\u7528MER\u5f15\u5bfc\u91cd\u65b0\u5206\u914d\u3002", "result": "PCA\u63d0\u4f9b\u5feb\u901f\u57fa\u7ebf\uff0cNMF\u4f7f\u6807\u8bb0\u5bcc\u96c6\u6700\u5927\u5316\uff0cVAE\u5e73\u8861\u91cd\u5efa\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u81ea\u7f16\u7801\u5668\u5904\u4e8e\u4e2d\u95f4\u4f4d\u7f6e\uff0cMER\u5f15\u5bfc\u91cd\u65b0\u5206\u914d\u5e73\u5747\u4f7fCMC\u5206\u6570\u63d0\u9ad812%\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u4e3a\u7279\u5b9a\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5206\u6790\u6709\u539f\u5219\u5730\u9009\u62e9\u964d\u7ef4\u65b9\u6cd5\u3002"}}
{"id": "2509.13662", "pdf": "https://arxiv.org/pdf/2509.13662", "abs": "https://arxiv.org/abs/2509.13662", "authors": ["Yulan Guo", "Longguang Wang", "Wendong Mao", "Xiaoyu Dong", "Yingqian Wang", "Li Liu", "Wei An"], "title": "Deep Lookup Network", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Convolutional neural networks are constructed with massive operations with\ndifferent types and are highly computationally intensive. Among these\noperations, multiplication operation is higher in computational complexity and\nusually requires {more} energy consumption with longer inference time than\nother operations, which hinders the deployment of convolutional neural networks\non mobile devices. In many resource-limited edge devices, complicated\noperations can be calculated via lookup tables to reduce computational cost.\nMotivated by this, in this paper, we introduce a generic and efficient lookup\noperation which can be used as a basic operation for the construction of neural\nnetworks. Instead of calculating the multiplication of weights and activation\nvalues, simple yet efficient lookup operations are adopted to compute their\nresponses. To enable end-to-end optimization of the lookup operation, we\nconstruct the lookup tables in a differentiable manner and propose several\ntraining strategies to promote their convergence. By replacing computationally\nexpensive multiplication operations with our lookup operations, we develop\nlookup networks for the image classification, image super-resolution, and point\ncloud classification tasks. It is demonstrated that our lookup networks can\nbenefit from the lookup operations to achieve higher efficiency in terms of\nenergy consumption and inference speed while maintaining competitive\nperformance to vanilla convolutional networks. Extensive experiments show that\nour lookup networks produce state-of-the-art performance on different tasks\n(both classification and regression tasks) and different data types (both\nimages and point clouds).", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u901a\u7528\u9ad8\u6548\u7684\u67e5\u627e\u64cd\u4f5c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u66ff\u4ee3\u4e58\u6cd5\u8fd0\u7b97\uff0c\u5f00\u53d1\u67e5\u627e\u7f51\u7edc\u7528\u4e8e\u591a\u4efb\u52a1\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u7f51\u7edc\u80fd\u8017\u4f4e\u3001\u63a8\u7406\u5feb\u4e14\u6027\u80fd\u4f18\u3002", "motivation": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u4e58\u6cd5\u8fd0\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u80fd\u8017\u5927\u3001\u63a8\u7406\u65f6\u95f4\u957f\uff0c\u963b\u788d\u5176\u5728\u79fb\u52a8\u8bbe\u5907\u90e8\u7f72\uff0c\u800c\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u53ef\u7528\u67e5\u627e\u8868\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5f15\u5165\u901a\u7528\u9ad8\u6548\u67e5\u627e\u64cd\u4f5c\u66ff\u4ee3\u4e58\u6cd5\u8fd0\u7b97\uff0c\u4ee5\u53ef\u5fae\u65b9\u5f0f\u6784\u5efa\u67e5\u627e\u8868\u5e76\u63d0\u51fa\u8bad\u7ec3\u7b56\u7565\u4fc3\u8fdb\u6536\u655b\uff0c\u5f00\u53d1\u67e5\u627e\u7f51\u7edc\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u3001\u8d85\u5206\u8fa8\u7387\u548c\u70b9\u4e91\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u67e5\u627e\u7f51\u7edc\u5728\u80fd\u8017\u548c\u63a8\u7406\u901f\u5ea6\u4e0a\u66f4\u9ad8\u6548\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6570\u636e\u7c7b\u578b\u4e0a\u53d6\u5f97\u4e86\u4e0e\u4f20\u7edf\u5377\u79ef\u7f51\u7edc\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u67e5\u627e\u7f51\u7edc\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6570\u636e\u7c7b\u578b\u4e0a\u90fd\u80fd\u4ea7\u751f\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2509.13664", "pdf": "https://arxiv.org/pdf/2509.13664", "abs": "https://arxiv.org/abs/2509.13664", "authors": ["Zhuoxuan Zhang", "Jinhao Duan", "Edward Kim", "Kaidi Xu"], "title": "Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "To be appeared in EMNLP 2025 (main)", "summary": "Ambiguity is pervasive in real-world questions, yet large language models\n(LLMs) often respond with confident answers rather than seeking clarification.\nIn this work, we show that question ambiguity is linearly encoded in the\ninternal representations of LLMs and can be both detected and controlled at the\nneuron level. During the model's pre-filling stage, we identify that a small\nnumber of neurons, as few as one, encode question ambiguity information. Probes\ntrained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance\non ambiguity detection and generalize across datasets, outperforming\nprompting-based and representation-based baselines. Layerwise analysis reveals\nthat AENs emerge from shallow layers, suggesting early encoding of ambiguity\nsignals in the model's processing pipeline. Finally, we show that through\nmanipulating AENs, we can control LLM's behavior from direct answering to\nabstention. Our findings reveal that LLMs form compact internal representations\nof question ambiguity, enabling interpretable and controllable behavior.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u8868\u5f81\u7ebf\u6027\u7f16\u7801\u95ee\u9898\u6b67\u4e49\uff0c\u53ef\u5728\u795e\u7ecf\u5143\u5c42\u9762\u68c0\u6d4b\u548c\u63a7\u5236\uff0c\u64cd\u7eb5\u76f8\u5173\u795e\u7ecf\u5143\u80fd\u6539\u53d8\u6a21\u578b\u884c\u4e3a\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u666e\u904d\u5b58\u5728\u6b67\u4e49\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5e38\u76f4\u63a5\u7ed9\u51fa\u7b54\u6848\u800c\u4e0d\u5bfb\u6c42\u6f84\u6e05\uff0c\u9700\u7814\u7a76\u6a21\u578b\u5bf9\u6b67\u4e49\u7684\u5904\u7406\u3002", "method": "\u5728\u6a21\u578b\u9884\u586b\u5145\u9636\u6bb5\u8bc6\u522b\u7f16\u7801\u95ee\u9898\u6b67\u4e49\u4fe1\u606f\u7684\u5c11\u91cf\u795e\u7ecf\u5143\uff08AENs\uff09\uff0c\u8bad\u7ec3\u57fa\u4e8eAENs\u7684\u63a2\u6d4b\u5668\uff0c\u8fdb\u884c\u5c42\u5206\u6790\u3002", "result": "\u57fa\u4e8eAENs\u7684\u63a2\u6d4b\u5668\u5728\u6b67\u4e49\u68c0\u6d4b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u8de8\u6570\u636e\u96c6\u6cdb\u5316\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff1bAENs\u6765\u81ea\u6d45\u5c42\uff0c\u53ef\u901a\u8fc7\u64cd\u7eb5AENs\u6539\u53d8\u6a21\u578b\u884c\u4e3a\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u95ee\u9898\u6b67\u4e49\u5f62\u6210\u7d27\u51d1\u5185\u90e8\u8868\u5f81\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u548c\u53ef\u63a7\u5236\u7684\u884c\u4e3a\u3002"}}
{"id": "2509.13360", "pdf": "https://arxiv.org/pdf/2509.13360", "abs": "https://arxiv.org/abs/2509.13360", "authors": ["L. Zimmer", "J. Weidner", "M. Balcerak", "F. Kofler", "I. Ezhov", "B. Menze", "B. Wiestler"], "title": "PREDICT-GBM: Platform for Robust Evaluation and Development of Individualized Computational Tumor Models in Glioblastoma", "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Glioblastoma is the most prevalent primary brain malignancy, distinguished by\nits highly invasive behavior and exceptionally high rates of recurrence.\nConventional radiation therapy, which employs uniform treatment margins, fails\nto account for patient-specific anatomical and biological factors that\ncritically influence tumor cell migration. To address this limitation, numerous\ncomputational models of glioblastoma growth have been developed, enabling\ngeneration of tumor cell distribution maps extending beyond radiographically\nvisible regions and thus informing more precise treatment strategies. However,\ndespite encouraging preliminary findings, the clinical adoption of these growth\nmodels remains limited. To bridge this translational gap and accelerate both\nmodel development and clinical validation, we introduce PREDICT-GBM, a\ncomprehensive integrated pipeline and dataset for modeling and evaluation. This\nplatform enables systematic benchmarking of state-of-the-art tumor growth\nmodels using an expert-curated clinical dataset comprising 255 subjects with\ncomplete tumor segmentations and tissue characterization maps. Our analysis\ndemonstrates that personalized radiation treatment plans derived from tumor\ngrowth predictions achieved superior recurrence coverage compared to\nconventional uniform margin approaches for two of the evaluated models. This\nwork establishes a robust platform for advancing and systematically evaluating\ncutting-edge tumor growth modeling approaches, with the ultimate goal of\nfacilitating clinical translation and improving patient outcomes.", "AI": {"tldr": "\u4ecb\u7ecdPREDICT - GBM\u5e73\u53f0\u7528\u4e8e\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u751f\u957f\u5efa\u6a21\u548c\u8bc4\u4f30\uff0c\u5206\u6790\u8868\u660e\u4e2a\u6027\u5316\u653e\u7597\u8ba1\u5212\u6548\u679c\u66f4\u597d\uff0c\u4e3a\u63a8\u8fdb\u80bf\u7624\u751f\u957f\u5efa\u6a21\u548c\u4e34\u5e8a\u8f6c\u5316\u63d0\u4f9b\u5e73\u53f0\u3002", "motivation": "\u4f20\u7edf\u653e\u7597\u672a\u8003\u8651\u60a3\u8005\u7279\u5b9a\u56e0\u7d20\uff0c\u73b0\u6709\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u751f\u957f\u8ba1\u7b97\u6a21\u578b\u4e34\u5e8a\u5e94\u7528\u6709\u9650\uff0c\u9700\u7f29\u5c0f\u8f6c\u5316\u5dee\u8ddd\u3002", "method": "\u5f15\u5165PREDICT - GBM\u5e73\u53f0\uff0c\u7528\u542b255\u540d\u53d7\u8bd5\u8005\u7684\u4e34\u5e8a\u6570\u636e\u96c6\u5bf9\u5148\u8fdb\u80bf\u7624\u751f\u957f\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5bf9\u4e8e\u4e24\u4e2a\u8bc4\u4f30\u6a21\u578b\uff0c\u57fa\u4e8e\u80bf\u7624\u751f\u957f\u9884\u6d4b\u7684\u4e2a\u6027\u5316\u653e\u7597\u8ba1\u5212\u5728\u590d\u53d1\u6027\u8986\u76d6\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7edf\u4e00\u8fb9\u7f18\u65b9\u6cd5\u3002", "conclusion": "\u5efa\u7acb\u4e86\u63a8\u8fdb\u548c\u7cfb\u7edf\u8bc4\u4f30\u524d\u6cbf\u80bf\u7624\u751f\u957f\u5efa\u6a21\u65b9\u6cd5\u7684\u5f3a\u5927\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u4e34\u5e8a\u8f6c\u5316\u548c\u6539\u5584\u60a3\u8005\u9884\u540e\u3002"}}
{"id": "2509.13666", "pdf": "https://arxiv.org/pdf/2509.13666", "abs": "https://arxiv.org/abs/2509.13666", "authors": ["Zhenqi Wu", "Abhinav Modi", "Angelos Mavrogiannis", "Kaustubh Joshi", "Nikhil Chopra", "Yiannis Aloimonos", "Nare Karapetyan", "Ioannis Rekleitis", "Xiaomin Lin"], "title": "DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring", "categories": ["cs.RO", "cs.AI"], "comment": "submitted to ICRA 2026", "summary": "The ocean is warming and acidifying, increasing the risk of mass mortality\nevents for temperature-sensitive shellfish such as oysters. This motivates the\ndevelopment of long-term monitoring systems. However, human labor is costly and\nlong-duration underwater work is highly hazardous, thus favoring robotic\nsolutions as a safer and more efficient option. To enable underwater robots to\nmake real-time, environment-aware decisions without human intervention, we must\nequip them with an intelligent \"brain.\" This highlights the need for\npersistent,wide-area, and low-cost benthic monitoring. To this end, we present\nDREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term\nunderwater exploration and habitat monitoring. The results show that our\nframework is highly efficient in finding and exploring target objects (e.g.,\noysters, shipwrecks) without prior location information. In the\noyster-monitoring task, our framework takes 31.5% less time than the previous\nbaseline with the same amount of oysters. Compared to the vanilla VLM, it uses\n23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our\nframework successfully explores and maps the wreck without collisions,\nrequiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,\nwhile the vanilla model achieves 60.23% average coverage in our shipwreck\nenvironments.", "AI": {"tldr": "\u6d77\u6d0b\u53d8\u6696\u548c\u9178\u5316\u5a01\u80c1\u8d1d\u7c7b\u751f\u5b58\uff0c\u9700\u957f\u671f\u76d1\u6d4b\u7cfb\u7edf\u3002\u672c\u6587\u63d0\u51faDREAM\u6846\u67b6\u7528\u4e8e\u6c34\u4e0b\u957f\u671f\u63a2\u7d22\u548c\u6816\u606f\u5730\u76d1\u6d4b\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5728\u76ee\u6807\u63a2\u7d22\u4efb\u52a1\u4e2d\u9ad8\u6548\u3002", "motivation": "\u6d77\u6d0b\u53d8\u6696\u548c\u9178\u5316\u589e\u52a0\u8d1d\u7c7b\u5927\u89c4\u6a21\u6b7b\u4ea1\u98ce\u9669\uff0c\u4eba\u7c7b\u957f\u671f\u6c34\u4e0b\u76d1\u6d4b\u6210\u672c\u9ad8\u4e14\u5371\u9669\uff0c\u9700\u8981\u5f00\u53d1\u957f\u671f\u6c34\u4e0b\u76d1\u6d4b\u7cfb\u7edf\u53ca\u667a\u80fd\u51b3\u7b56\u6846\u67b6\u3002", "method": "\u63d0\u51faVision Language Model (VLM) \u5f15\u5bfc\u7684\u81ea\u4e3b\u6846\u67b6DREAM\u7528\u4e8e\u957f\u671f\u6c34\u4e0b\u63a2\u7d22\u548c\u6816\u606f\u5730\u76d1\u6d4b\u3002", "result": "\u6846\u67b6\u5728\u65e0\u5148\u9a8c\u4f4d\u7f6e\u4fe1\u606f\u4e0b\u80fd\u9ad8\u6548\u5bfb\u627e\u548c\u63a2\u7d22\u76ee\u6807\u5bf9\u8c61\u3002\u7261\u86ce\u76d1\u6d4b\u4efb\u52a1\u4e2d\u8017\u65f6\u6bd4\u57fa\u7ebf\u5c1131.5%\uff1b\u76f8\u6bd4\u666e\u901aVLM\uff0c\u6b65\u6570\u5c1123%\u4e14\u8986\u76d6\u7261\u86ce\u591a8.88%\u3002\u6c89\u8239\u573a\u666f\u4e2d\uff0c\u6210\u529f\u63a2\u7d22\u548c\u7ed8\u5236\u6c89\u8239\u56fe\uff0c\u6b65\u6570\u6bd4\u666e\u901a\u6a21\u578b\u5c1127.5%\uff0c\u8986\u76d6\u7387\u8fbe100%\uff0c\u666e\u901a\u6a21\u578b\u4e3a60.23%\u3002", "conclusion": "DREAM\u6846\u67b6\u5728\u6c34\u4e0b\u76ee\u6807\u63a2\u7d22\u548c\u76d1\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u9ad8\u6548\uff0c\u80fd\u6709\u6548\u5b8c\u6210\u957f\u671f\u6c34\u4e0b\u63a2\u7d22\u548c\u6816\u606f\u5730\u76d1\u6d4b\u5de5\u4f5c\u3002"}}
{"id": "2509.13672", "pdf": "https://arxiv.org/pdf/2509.13672", "abs": "https://arxiv.org/abs/2509.13672", "authors": ["Shang Qin", "Jingheng Ye", "Yinghui Li", "Hai-Tao Zheng", "Qi Li", "Jinxiao Shan", "Zhixing Li", "Hong-Gee Kim"], "title": "CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The growing demand for automated writing assistance in diverse academic\ndomains highlights the need for robust Chinese Grammatical Error Correction\n(CGEC) systems that can adapt across disciplines. However, existing CGEC\nresearch largely lacks dedicated benchmarks for multi-disciplinary academic\nwriting, overlooking continual learning (CL) as a promising solution to handle\ndomain-specific linguistic variation and prevent catastrophic forgetting. To\nfill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning\nbenchmark for Chinese Literature Grammatical Error Correction, designed to\nevaluate adaptive CGEC across multiple academic fields. Our benchmark includes\n10,000 human-annotated sentences spanning 10 disciplines, each exhibiting\ndistinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating\ngrammatical error correction in a continual learning setting, simulating\nsequential exposure to diverse academic disciplines to reflect real-world\neditorial dynamics. We evaluate large language models under sequential tuning,\nparameter-efficient adaptation, and four representative CL algorithms, using\nboth standard GEC metrics and continual learning metrics adapted to task-level\nvariation. Experimental results reveal that regularization-based methods\nmitigate forgetting more effectively than replay-based or naive sequential\napproaches. Our benchmark provides a rigorous foundation for future research in\nadaptive grammatical error correction across diverse academic domains.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u9996\u4e2a\u4e2d\u6587\u6587\u5b66\u8bed\u6cd5\u7ea0\u9519\u7684\u6301\u7eed\u5b66\u4e60\u57fa\u51c6CL$^2$GEC\uff0c\u8bc4\u4f30\u8de8\u591a\u5b66\u79d1\u9886\u57df\u7684\u81ea\u9002\u5e94\u4e2d\u6587\u8bed\u6cd5\u7ea0\u9519\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u8868\u660e\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u5728\u7f13\u89e3\u9057\u5fd8\u65b9\u9762\u66f4\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u4e2d\u6587\u8bed\u6cd5\u7ea0\u9519\u7814\u7a76\u7f3a\u4e4f\u591a\u5b66\u79d1\u5199\u4f5c\u7684\u4e13\u7528\u57fa\u51c6\uff0c\u5ffd\u7565\u6301\u7eed\u5b66\u4e60\u5904\u7406\u7279\u5b9a\u9886\u57df\u8bed\u8a00\u53d8\u4f53\u548c\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u7684\u6f5c\u529b\u3002", "method": "\u5f15\u5165CL$^2$GEC\u57fa\u51c6\uff0c\u5305\u542b10\u4e2a\u5b66\u79d1\u768410000\u4e2a\u4eba\u5de5\u6807\u6ce8\u53e5\u5b50\uff0c\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u987a\u5e8f\u8c03\u4f18\u3001\u53c2\u6570\u9ad8\u6548\u9002\u914d\u548c4\u79cd\u4ee3\u8868\u6027\u6301\u7eed\u5b66\u4e60\u7b97\u6cd5\u8bc4\u4f30\uff0c\u4f7f\u7528\u6807\u51c6GEC\u6307\u6807\u548c\u9002\u5e94\u4efb\u52a1\u7ea7\u53d8\u5316\u7684\u6301\u7eed\u5b66\u4e60\u6307\u6807\u3002", "result": "\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u6bd4\u57fa\u4e8e\u91cd\u653e\u6216\u6734\u7d20\u987a\u5e8f\u7684\u65b9\u6cd5\u66f4\u80fd\u6709\u6548\u7f13\u89e3\u9057\u5fd8\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u8de8\u4e0d\u540c\u5b66\u672f\u9886\u57df\u7684\u81ea\u9002\u5e94\u8bed\u6cd5\u7ea0\u9519\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2509.13371", "pdf": "https://arxiv.org/pdf/2509.13371", "abs": "https://arxiv.org/abs/2509.13371", "authors": ["Xuyuan Kang", "Xiao Wang", "Jingjing An", "Da Yan"], "title": "A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "16 pages,14 figures,published to Energy & Buildings", "summary": "Thermal energy storage (TES) is an effective method for load shifting and\ndemand response in buildings. Optimal TES control and management are essential\nto improve the performance of the cooling system. Most existing TES systems\noperate on a fixed schedule, which cannot take full advantage of its load\nshifting capability, and requires extensive investigation and optimization.\nThis study proposed a novel integrated load prediction and optimized control\napproach for ice-based TES in commercial buildings. A cooling load prediction\nmodel was developed and a mid-day modification mechanism was introduced into\nthe prediction model to improve the accuracy. Based on the predictions, a\nrule-based control strategy was proposed according to the time-of-use tariff;\nthe mid-day control adjustment mechanism was introduced in accordance with the\nmid-day prediction modifications. The proposed approach was applied in the\nice-based TES system of a commercial complex in Beijing, and achieved a mean\nabsolute error (MAE) of 389 kW and coefficient of variance of MAE of 12.5%. The\nintegrated prediction-based control strategy achieved an energy cost saving\nrate of 9.9%. The proposed model was deployed in the realistic building\nautomation system of the case building and significantly improved the\nefficiency and automation of the cooling system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u5546\u4e1a\u5efa\u7b51\u51b0\u84c4\u51b7\u7cfb\u7edf\u7684\u96c6\u6210\u8d1f\u8377\u9884\u6d4b\u4e0e\u4f18\u5316\u63a7\u5236\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u5b9e\u9645\u9879\u76ee\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u63d0\u9ad8\u4e86\u5236\u51b7\u7cfb\u7edf\u6548\u7387\u548c\u81ea\u52a8\u5316\u7a0b\u5ea6\u3002", "motivation": "\u73b0\u6709\u51b0\u84c4\u51b7\u7cfb\u7edf\u591a\u6309\u56fa\u5b9a\u65f6\u95f4\u8868\u8fd0\u884c\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8d1f\u8377\u8f6c\u79fb\u80fd\u529b\uff0c\u9700\u8981\u6df1\u5165\u7814\u7a76\u548c\u4f18\u5316\u3002", "method": "\u5f00\u53d1\u51b7\u5374\u8d1f\u8377\u9884\u6d4b\u6a21\u578b\u5e76\u5f15\u5165\u5348\u95f4\u4fee\u6b63\u673a\u5236\uff0c\u57fa\u4e8e\u9884\u6d4b\u7ed3\u679c\u6839\u636e\u5206\u65f6\u7535\u4ef7\u63d0\u51fa\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236\u7b56\u7565\uff0c\u540c\u65f6\u5f15\u5165\u5348\u95f4\u63a7\u5236\u8c03\u6574\u673a\u5236\u3002", "result": "\u5728\u5317\u4eac\u67d0\u5546\u4e1a\u7efc\u5408\u4f53\u51b0\u84c4\u51b7\u7cfb\u7edf\u5e94\u7528\u4e2d\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a389kW\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u53d8\u5f02\u7cfb\u6570\u4e3a12.5%\uff0c\u57fa\u4e8e\u9884\u6d4b\u7684\u96c6\u6210\u63a7\u5236\u7b56\u7565\u5b9e\u73b09.9%\u7684\u80fd\u6e90\u6210\u672c\u8282\u7ea6\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u90e8\u7f72\u5728\u5b9e\u9645\u5efa\u7b51\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5236\u51b7\u7cfb\u7edf\u7684\u6548\u7387\u548c\u81ea\u52a8\u5316\u7a0b\u5ea6\u3002"}}
{"id": "2509.13676", "pdf": "https://arxiv.org/pdf/2509.13676", "abs": "https://arxiv.org/abs/2509.13676", "authors": ["Xiaobo Yang", "Xiaojin Gong"], "title": "Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recently, Referring Image Segmentation (RIS) frameworks that pair the\nMultimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)\nhave achieved impressive results. However, adapting MLLM to segmentation is\ncomputationally intensive, primarily due to visual token redundancy. We observe\nthat traditional patch-wise visual projectors struggle to strike a balance\nbetween reducing the number of visual tokens and preserving semantic clarity,\noften retaining overly long token sequences to avoid performance drops.\nInspired by text tokenizers, we propose a novel semantic visual projector that\nleverages semantic superpixels generated by SAM to identify \"visual words\" in\nan image. By compressing and projecting semantic superpixels as visual tokens,\nour approach adaptively shortens the token sequence according to scene\ncomplexity while minimizing semantic loss in compression. To mitigate loss of\ninformation, we propose a semantic superpixel positional embedding to\nstrengthen MLLM's awareness of superpixel geometry and position, alongside a\nsemantic superpixel aggregator to preserve both fine-grained details inside\nsuperpixels and global context outside. Experiments show that our method cuts\nvisual tokens by 93% without compromising performance, notably speeding up MLLM\ntraining and inference, and outperforming existing compressive visual\nprojectors on RIS.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u89c6\u89c9\u6295\u5f71\u5668\uff0c\u538b\u7f29\u89c6\u89c9\u6807\u8bb0\u52a0\u901fMLLM\uff0c\u5728RIS\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u5c06MLLM\u9002\u914d\u5230\u5206\u5272\u4efb\u52a1\u8ba1\u7b97\u91cf\u5927\uff0c\u4f20\u7edf\u6295\u5f71\u5668\u96be\u5e73\u8861\u51cf\u5c11\u89c6\u89c9\u6807\u8bb0\u548c\u4fdd\u7559\u8bed\u4e49\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u89c6\u89c9\u6295\u5f71\u5668\uff0c\u5229\u7528SAM\u751f\u6210\u7684\u8bed\u4e49\u8d85\u50cf\u7d20\u8bc6\u522b\u89c6\u89c9\u8bcd\u5e76\u538b\u7f29\u6295\u5f71\uff1b\u63d0\u51fa\u8bed\u4e49\u8d85\u50cf\u7d20\u4f4d\u7f6e\u5d4c\u5165\u548c\u805a\u5408\u5668\u51cf\u5c11\u4fe1\u606f\u635f\u5931\u3002", "result": "\u51cf\u5c1193%\u89c6\u89c9\u6807\u8bb0\uff0c\u52a0\u901fMLLM\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u5728RIS\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u89c6\u89c9\u6807\u8bb0\u4e14\u4e0d\u635f\u5931\u6027\u80fd\uff0c\u80fd\u52a0\u901fMLLM\uff0c\u5728RIS\u4efb\u52a1\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2509.13677", "pdf": "https://arxiv.org/pdf/2509.13677", "abs": "https://arxiv.org/abs/2509.13677", "authors": ["Xinxu Zhou", "Jiaqi Bai", "Zhenqi Sun", "Fanxiang Zeng", "Yue Liu"], "title": "AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Although significant progress has been made in many tasks within the field of\nNatural Language Processing (NLP), Controlled Text Generation (CTG) continues\nto face numerous challenges, particularly in achieving fine-grained conditional\ncontrol over generation. Additionally, in real scenario and online\napplications, cost considerations, scalability, domain knowledge learning and\nmore precise control are required, presenting more challenge for CTG. This\npaper introduces a novel and scalable framework, AgentCTG, which aims to\nenhance precise and complex control over the text generation by simulating the\ncontrol and regulation mechanisms in multi-agent workflows. We explore various\ncollaboration methods among different agents and introduce an auto-prompt\nmodule to further enhance the generation effectiveness. AgentCTG achieves\nstate-of-the-art results on multiple public datasets. To validate its\neffectiveness in practical applications, we propose a new challenging\nCharacter-Driven Rewriting task, which aims to convert the original text into\nnew text that conform to specific character profiles and simultaneously\npreserve the domain knowledge. When applied to online navigation with\nrole-playing, our approach significantly enhances the driving experience\nthrough improved content delivery. By optimizing the generation of contextually\nrelevant text, we enable a more immersive interaction within online\ncommunities, fostering greater personalization and user engagement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAgentCTG\u6846\u67b6\u89e3\u51b3\u53ef\u63a7\u6587\u672c\u751f\u6210\uff08CTG\uff09\u6311\u6218\uff0c\u5728\u591a\u6570\u636e\u96c6\u8fbeSOTA\uff0c\u8fd8\u63d0\u51fa\u65b0\u4efb\u52a1\u9a8c\u8bc1\u5176\u5728\u5b9e\u9645\u5e94\u7528\u6709\u6548\u6027\u3002", "motivation": "NLP\u4e2dCTG\u5728\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u6761\u4ef6\u63a7\u5236\u53ca\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u8bf8\u591a\u6311\u6218\u3002", "method": "\u5f15\u5165AgentCTG\u6846\u67b6\uff0c\u6a21\u62df\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e2d\u7684\u63a7\u5236\u548c\u8c03\u8282\u673a\u5236\uff0c\u63a2\u7d22\u4e0d\u540c\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\uff0c\u5f15\u5165\u81ea\u52a8\u63d0\u793a\u6a21\u5757\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5728\u65b0\u63d0\u51fa\u7684\u5b57\u7b26\u9a71\u52a8\u91cd\u5199\u4efb\u52a1\u548c\u5728\u7ebf\u5bfc\u822a\u89d2\u8272\u626e\u6f14\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "AgentCTG\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u6587\u672c\u751f\u6210\u7684\u7cbe\u786e\u548c\u590d\u6742\u63a7\u5236\u80fd\u529b\uff0c\u4f18\u5316\u76f8\u5173\u6587\u672c\u751f\u6210\uff0c\u589e\u5f3a\u4e86\u5728\u7ebf\u793e\u533a\u4ea4\u4e92\u4f53\u9a8c\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u3002"}}
{"id": "2509.13376", "pdf": "https://arxiv.org/pdf/2509.13376", "abs": "https://arxiv.org/abs/2509.13376", "authors": ["Zhiwei Fan", "Tiangang Wang", "Kexin Huang", "Binwu Ying", "Xiaobo Zhou"], "title": "Unleashing the power of computational insights in revealing the complexity of biological systems in the new era of spatial multi-omics", "categories": ["q-bio.QM", "cs.LG"], "comment": "43 pages, 9 figures, 1 table", "summary": "Recent advances in spatial omics technologies have revolutionized our ability\nto study biological systems with unprecedented resolution. By preserving the\nspatial context of molecular measurements, these methods enable comprehensive\nmapping of cellular heterogeneity, tissue architecture, and dynamic biological\nprocesses in developmental biology, neuroscience, oncology, and evolutionary\nstudies. This review highlights a systematic overview of the continuous\nadvancements in both technology and computational algorithms that are paving\nthe way for a deeper, more systematic comprehension of the structure and\nmechanisms of mammalian tissues and organs by using spatial multi-omics. Our\nviewpoint demonstrates how advanced machine learning algorithms and multi-omics\nintegrative modeling can decode complex biological processes, including the\nspatial organization and topological relationships of cells during organ\ndevelopment, as well as key molecular signatures and regulatory networks\nunderlying tumorigenesis and metastasis. Finally, we outline future directions\nfor technological innovation and modeling insights of spatial omics in\nprecision medicine.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u7a7a\u95f4\u7ec4\u5b66\u6280\u672f\u8fdb\u5c55\uff0c\u4ecb\u7ecd\u673a\u5668\u5b66\u4e60\u4e0e\u591a\u7ec4\u5b66\u6574\u5408\u5efa\u6a21\u5e94\u7528\uff0c\u5c55\u671b\u5176\u5728\u7cbe\u51c6\u533b\u5b66\u7684\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u7a7a\u95f4\u7ec4\u5b66\u6280\u672f\u53d1\u5c55\uff0c\u9700\u7cfb\u7edf\u4e86\u89e3\u5176\u5728\u89e3\u6790\u54fa\u4e73\u52a8\u7269\u7ec4\u7ec7\u5668\u5b98\u7ed3\u6784\u548c\u673a\u5236\u7684\u8fdb\u5c55\u3002", "method": "\u5bf9\u7a7a\u95f4\u591a\u7ec4\u5b66\u6280\u672f\u548c\u8ba1\u7b97\u7b97\u6cd5\u7684\u6301\u7eed\u8fdb\u5c55\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\u3002", "result": "\u5c55\u793a\u5148\u8fdb\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c\u591a\u7ec4\u5b66\u6574\u5408\u5efa\u6a21\u53ef\u89e3\u7801\u590d\u6742\u751f\u7269\u8fc7\u7a0b\u3002", "conclusion": "\u7ed9\u51fa\u7a7a\u95f4\u7ec4\u5b66\u5728\u7cbe\u51c6\u533b\u5b66\u4e2d\u6280\u672f\u521b\u65b0\u548c\u5efa\u6a21\u7684\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2509.13683", "pdf": "https://arxiv.org/pdf/2509.13683", "abs": "https://arxiv.org/abs/2509.13683", "authors": ["Suyuchen Wang", "Jinlin Wang", "Xinyu Wang", "Shiqi Li", "Xiangru Tang", "Sirui Hong", "Xiao-Wen Chang", "Chenglin Wu", "Bang Liu"], "title": "Improving Context Fidelity via Native Retrieval-Augmented Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted as a main conference paper at EMNLP 2025", "summary": "Large language models (LLMs) often struggle with context fidelity, producing\ninconsistent answers when responding to questions based on provided\ninformation. Existing approaches either rely on expensive supervised\nfine-tuning to generate evidence post-answer or train models to perform web\nsearches without necessarily improving utilization of the given context. We\npropose CARE, a novel native retrieval-augmented reasoning framework that\nteaches LLMs to explicitly integrate in-context evidence within their reasoning\nprocess with the model's own retrieval capabilities. Our method requires\nlimited labeled evidence data while significantly enhancing both retrieval\naccuracy and answer generation performance through strategically retrieved\nin-context tokens in the reasoning chain. Extensive experiments on multiple\nreal-world and counterfactual QA benchmarks demonstrate that our approach\nsubstantially outperforms supervised fine-tuning, traditional\nretrieval-augmented generation methods, and external retrieval solutions. This\nwork represents a fundamental advancement in making LLMs more accurate,\nreliable, and efficient for knowledge-intensive tasks.", "AI": {"tldr": "\u63d0\u51faCARE\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u65b9\u9762\u5b58\u5728\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faCARE\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5229\u7528\u81ea\u8eab\u68c0\u7d22\u80fd\u529b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6574\u5408\u4e0a\u4e0b\u6587\u8bc1\u636e\u3002", "result": "\u5728\u591a\u4e2a\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u3001\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u548c\u5916\u90e8\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5728\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u51c6\u786e\u3001\u53ef\u9760\u548c\u9ad8\u6548\u5730\u5904\u7406\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u65b9\u9762\u53d6\u5f97\u4e86\u6839\u672c\u6027\u8fdb\u5c55\u3002"}}
{"id": "2509.13381", "pdf": "https://arxiv.org/pdf/2509.13381", "abs": "https://arxiv.org/abs/2509.13381", "authors": ["Zhang Xueyao", "Yang Bo", "Yu Zhiwen", "Cao Xuelin", "George C. Alexandropoulos", "Merouane Debbah", "Chau Yuen"], "title": "Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach", "categories": ["cs.RO", "cs.LG", "cs.MA"], "comment": "6 pages", "summary": "Autonomous Underwater Vehicles (AUVs) have shown great potential for\ncooperative detection and reconnaissance. However, collaborative AUV\ncommunications introduce risks of exposure. In adversarial environments,\nachieving efficient collaboration while ensuring covert operations becomes a\nkey challenge for underwater cooperative missions. In this paper, we propose a\nnovel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization\n(H-MAPPO) framework. The high-level component determines the individuals\nparticipating in the task based on a central AUV, while the low-level component\nreduces exposure probabilities through power and trajectory control by the\nparticipating AUVs. Simulation results show that the proposed framework\nachieves rapid convergence, outperforms benchmark algorithms in terms of\nperformance, and maximizes long-term cooperative efficiency while ensuring\ncovert operations.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u65f6\u95f4\u5c3a\u5ea6\u5206\u5c42\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u6846\u67b6\u7528\u4e8e\u6c34\u4e0b\u534f\u4f5c\u4efb\u52a1\uff0c\u6a21\u62df\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e14\u80fd\u4fdd\u969c\u9690\u853d\u64cd\u4f5c\u3002", "motivation": "\u534f\u4f5c\u5f0fAUV\u901a\u4fe1\u6709\u66b4\u9732\u98ce\u9669\uff0c\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u534f\u4f5c\u4e0e\u9690\u853d\u64cd\u4f5c\u662f\u6c34\u4e0b\u534f\u4f5c\u4efb\u52a1\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u53cc\u65f6\u95f4\u5c3a\u5ea6\u7684Hierarchical Multi - Agent Proximal Policy Optimization (H - MAPPO)\u6846\u67b6\uff0c\u9ad8\u5c42\u57fa\u4e8e\u4e2d\u5fc3AUV\u786e\u5b9a\u53c2\u4e0e\u4efb\u52a1\u4e2a\u4f53\uff0c\u4f4e\u5c42\u53c2\u4e0eAUV\u901a\u8fc7\u529f\u7387\u548c\u8f68\u8ff9\u63a7\u5236\u964d\u4f4e\u66b4\u9732\u6982\u7387\u3002", "result": "\u8be5\u6846\u67b6\u5b9e\u73b0\u5feb\u901f\u6536\u655b\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u51c6\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u5728\u786e\u4fdd\u9690\u853d\u64cd\u4f5c\u7684\u540c\u65f6\u6700\u5927\u5316\u957f\u671f\u534f\u4f5c\u6548\u7387\u3002"}}
{"id": "2509.13688", "pdf": "https://arxiv.org/pdf/2509.13688", "abs": "https://arxiv.org/abs/2509.13688", "authors": ["James Jincheng", "Youcheng Cai", "Ligang Liu"], "title": "CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "Controllable, high-fidelity mesh editing remains a significant challenge in\n3D content creation. Existing generative methods often struggle with complex\ngeometries and fail to produce detailed results. We propose CraftMesh, a novel\nframework for high-fidelity generative mesh manipulation via Poisson Seamless\nFusion. Our key insight is to decompose mesh editing into a pipeline that\nleverages the strengths of 2D and 3D generative models: we edit a 2D reference\nimage, then generate a region-specific 3D mesh, and seamlessly fuse it into the\noriginal model. We introduce two core techniques: Poisson Geometric Fusion,\nwhich utilizes a hybrid SDF/Mesh representation with normal blending to achieve\nharmonious geometric integration, and Poisson Texture Harmonization for\nvisually consistent texture blending. Experimental results demonstrate that\nCraftMesh outperforms state-of-the-art methods, delivering superior global\nconsistency and local detail in complex editing tasks.", "AI": {"tldr": "\u63d0\u51faCraftMesh\u6846\u67b6\u7528\u4e8e\u9ad8\u4fdd\u771f\u751f\u6210\u5f0f\u7f51\u683c\u64cd\u4f5c\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u51e0\u4f55\u5f62\u72b6\u548c\u751f\u6210\u8be6\u7ec6\u7ed3\u679c\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u53ef\u63a7\u7684\u9ad8\u4fdd\u771f\u7f51\u683c\u7f16\u8f91\u4ecd\u662f3D\u5185\u5bb9\u521b\u4f5c\u7684\u91cd\u5927\u6311\u6218\u3002", "method": "\u5c06\u7f51\u683c\u7f16\u8f91\u5206\u89e3\u4e3a\u5229\u75282D\u548c3D\u751f\u6210\u6a21\u578b\u4f18\u52bf\u7684\u7ba1\u9053\uff0c\u7f16\u8f912D\u53c2\u8003\u56fe\u50cf\uff0c\u751f\u6210\u7279\u5b9a\u533a\u57df\u76843D\u7f51\u683c\u5e76\u878d\u5408\u5230\u539f\u59cb\u6a21\u578b\u4e2d\uff0c\u5f15\u5165Poisson Geometric Fusion\u548cPoisson Texture Harmonization\u4e24\u79cd\u6838\u5fc3\u6280\u672f\u3002", "result": "CraftMesh\u5728\u590d\u6742\u7f16\u8f91\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u5168\u5c40\u4e00\u81f4\u6027\u548c\u5c40\u90e8\u7ec6\u8282\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "CraftMesh\u6846\u67b6\u5728\u9ad8\u4fdd\u771f\u751f\u6210\u5f0f\u7f51\u683c\u64cd\u4f5c\u65b9\u9762\u662f\u6709\u6548\u7684\uff0c\u80fd\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2509.13385", "pdf": "https://arxiv.org/pdf/2509.13385", "abs": "https://arxiv.org/abs/2509.13385", "authors": ["Charlotte Beylier", "Parvaneh Joharinad", "J\u00fcrgen Jost", "Nahid Torbati"], "title": "Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension", "categories": ["cs.CV", "cs.DM", "cs.LG", "51K05 (primary) 57-08, 53Z50, 55U10 (secondary)", "G.2.2"], "comment": "31 pages, 14 figures", "summary": "Utilizing recently developed abstract notions of sectional curvature, we\nintroduce a method for constructing a curvature-based geometric profile of\ndiscrete metric spaces. The curvature concept that we use here captures the\nmetric relations between triples of points and other points. More\nsignificantly, based on this curvature profile, we introduce a quantitative\nmeasure to evaluate the effectiveness of data representations, such as those\nproduced by dimensionality reduction techniques. Furthermore, Our experiments\ndemonstrate that this curvature-based analysis can be employed to estimate the\nintrinsic dimensionality of datasets. We use this to explore the large-scale\ngeometry of empirical networks and to evaluate the effectiveness of\ndimensionality reduction techniques.", "AI": {"tldr": "\u5229\u7528\u622a\u9762\u66f2\u7387\u6982\u5ff5\u6784\u5efa\u79bb\u6563\u5ea6\u91cf\u7a7a\u95f4\u7684\u51e0\u4f55\u8f6e\u5ed3\uff0c\u5f15\u5165\u8bc4\u4f30\u6570\u636e\u8868\u793a\u6709\u6548\u6027\u7684\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53ef\u4f30\u8ba1\u6570\u636e\u96c6\u5185\u5728\u7ef4\u5ea6\u5e76\u8bc4\u4f30\u964d\u7ef4\u6280\u672f\u3002", "motivation": "\u5f15\u5165\u57fa\u4e8e\u66f2\u7387\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u6570\u636e\u8868\u793a\u7684\u6709\u6548\u6027\u4ee5\u53ca\u4f30\u8ba1\u6570\u636e\u96c6\u7684\u5185\u5728\u7ef4\u5ea6\u3002", "method": "\u5229\u7528\u65b0\u5f00\u53d1\u7684\u622a\u9762\u66f2\u7387\u62bd\u8c61\u6982\u5ff5\u6784\u5efa\u79bb\u6563\u5ea6\u91cf\u7a7a\u95f4\u7684\u66f2\u7387\u51e0\u4f55\u8f6e\u5ed3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u57fa\u4e8e\u66f2\u7387\u7684\u5206\u6790\u53ef\u7528\u4e8e\u4f30\u8ba1\u6570\u636e\u96c6\u7684\u5185\u5728\u7ef4\u5ea6\uff0c\u53ef\u63a2\u7d22\u7ecf\u9a8c\u7f51\u7edc\u7684\u5927\u89c4\u6a21\u51e0\u4f55\u7ed3\u6784\u5e76\u8bc4\u4f30\u964d\u7ef4\u6280\u672f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u66f2\u7387\u7684\u51e0\u4f55\u8f6e\u5ed3\u6784\u5efa\u65b9\u6cd5\u80fd\u6709\u6548\u8bc4\u4f30\u6570\u636e\u8868\u793a\uff0c\u53ef\u7528\u4e8e\u4f30\u8ba1\u5185\u5728\u7ef4\u5ea6\u548c\u8bc4\u4f30\u964d\u7ef4\u6280\u672f\u3002"}}
{"id": "2509.13702", "pdf": "https://arxiv.org/pdf/2509.13702", "abs": "https://arxiv.org/abs/2509.13702", "authors": ["Xiao Zheng"], "title": "DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) hallucination is a significant barrier to their\nreliable deployment. Current methods like Retrieval-Augmented Generation (RAG)\nare often reactive. We introduce **Dynamic Self-reinforcing Calibration for\nHallucination Suppression (DSCC-HS)**, a novel, proactive framework that\nintervenes during autoregressive decoding. Inspired by dual-process cognitive\ntheory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a\nFactual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During\ninference, these proxies dynamically steer a large target model by injecting a\nreal-time steering vector, which is the difference between FAP and HDP logits,\nat each decoding step. This plug-and-play approach requires no modification to\nthe target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS\nachieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%\nFactual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained\nthe highest FActScore of 46.50. These results validate DSCC-HS as a principled\nand efficient solution for enhancing LLM factuality.", "AI": {"tldr": "\u63d0\u51faDSCC - HS\u6846\u67b6\u6291\u5236\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u8fbeSOTA\u6027\u80fd\uff0c\u63d0\u5347\u6a21\u578b\u4e8b\u5b9e\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u662f\u53ef\u9760\u90e8\u7f72\u7684\u91cd\u5927\u969c\u788d\uff0c\u73b0\u6709\u65b9\u6cd5\u5e38\u662f\u88ab\u52a8\u7684\u3002", "method": "\u5f15\u5165DSCC - HS\u6846\u67b6\uff0c\u53d7\u53cc\u8fc7\u7a0b\u8ba4\u77e5\u7406\u8bba\u542f\u53d1\uff0c\u4f7f\u7528\u7d27\u51d1\u4ee3\u7406\u6a21\u578bFAP\u548cHDP\uff0c\u63a8\u7406\u65f6\u5728\u6bcf\u4e2a\u89e3\u7801\u6b65\u9aa4\u6ce8\u5165\u5b9e\u65f6\u5f15\u5bfc\u5411\u91cf\u3002", "result": "\u5728TruthfulQA\u548cBioGEN\u4e0a\u5b9e\u9a8c\u8fbeSOTA\u6027\u80fd\uff0c\u5982TruthfulQA\u4e0aFCR\u8fbe99.2%\uff0cBioGEN\u4e0aFActScore\u8fbe46.50\u3002", "conclusion": "DSCC - HS\u662f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e8b\u5b9e\u6027\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2509.13386", "pdf": "https://arxiv.org/pdf/2509.13386", "abs": "https://arxiv.org/abs/2509.13386", "authors": ["Hansol Lim", "Minhyeok Im", "Jonathan Boyack", "Jee Won Lee", "Jongseong Brad Choi"], "title": "VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization", "categories": ["cs.RO", "cs.LG"], "comment": "This work has been submitted to the 2026 IEEE International\n  Conference on Robotics and Automation (ICRA) for possible publication", "summary": "Demands for software-defined vehicles (SDV) are rising and electric vehicles\n(EVs) are increasingly being equipped with powerful computers. This enables\nonboard AI systems to optimize charge-aware path optimization customized to\nreflect vehicle's current condition and environment. We present VEGA, a\ncharge-aware EV navigation agent that plans over a charger-annotated road graph\nusing Proximal Policy Optimization (PPO) with budgeted A* teacher-student\nguidance under state-of-charge (SoC) feasibility. VEGA consists of two modules.\nFirst, a physics-informed neural operator (PINO), trained on real vehicle speed\nand battery-power logs, uses recent vehicle speed logs to estimate aerodynamic\ndrag, rolling resistance, mass, motor and regenerative-braking efficiencies,\nand auxiliary load by learning a vehicle-custom dynamics. Second, a\nReinforcement Learning (RL) agent uses these dynamics to optimize a path with\noptimal charging stops and dwell times under SoC constraints. VEGA requires no\nadditional sensors and uses only vehicle speed signals. It may serve as a\nvirtual sensor for power and efficiency to potentially reduce EV cost. In\nevaluation on long routes like San Francisco to New York, VEGA's stops, dwell\ntimes, SoC management, and total travel time closely track Tesla Trip Planner\nwhile being slightly more conservative, presumably due to real vehicle\nconditions such as vehicle parameter drift due to deterioration. Although\ntrained only in U.S. regions, VEGA was able to compute optimal charge-aware\npaths in France and Japan, demonstrating generalizability. It achieves\npractical integration of physics-informed learning and RL for EV eco-routing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVEGA\uff0c\u4e00\u4e2a\u5145\u7535\u611f\u77e5\u7684\u7535\u52a8\u6c7d\u8f66\u5bfc\u822a\u4ee3\u7406\uff0c\u5229\u7528\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u751f\u6001\u8def\u7531\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u957f\u8def\u7ebf\u4e0a\u8868\u73b0\u826f\u597d\u4e14\u6709\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5b9a\u4e49\u6c7d\u8f66\u9700\u6c42\u4e0a\u5347\u53ca\u7535\u52a8\u6c7d\u8f66\u914d\u5907\u5f3a\u5927\u8ba1\u7b97\u673a\uff0c\u9700\u8981\u4f18\u5316\u5145\u7535\u611f\u77e5\u8def\u5f84\u89c4\u5212\u4ee5\u9002\u5e94\u8f66\u8f86\u5f53\u524d\u72b6\u51b5\u548c\u73af\u5883\u3002", "method": "\u63d0\u51faVEGA\uff0c\u5305\u542b\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7b97\u5b50\uff08PINO\uff09\u6a21\u5757\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee3\u7406\u6a21\u5757\uff0c\u524d\u8005\u57fa\u4e8e\u8f66\u8f86\u901f\u5ea6\u548c\u7535\u6c60\u529f\u7387\u65e5\u5fd7\u5b66\u4e60\u8f66\u8f86\u81ea\u5b9a\u4e49\u52a8\u529b\u5b66\uff0c\u540e\u8005\u5728\u5145\u7535\u72b6\u6001\u7ea6\u675f\u4e0b\u4f18\u5316\u8def\u5f84\u3002", "result": "\u5728\u65e7\u91d1\u5c71\u5230\u7ebd\u7ea6\u7b49\u957f\u8def\u7ebf\u8bc4\u4f30\u4e2d\uff0cVEGA\u7684\u505c\u8f66\u3001\u505c\u7559\u65f6\u95f4\u3001\u5145\u7535\u72b6\u6001\u7ba1\u7406\u548c\u603b\u65c5\u884c\u65f6\u95f4\u4e0e\u7279\u65af\u62c9\u884c\u7a0b\u89c4\u5212\u5668\u76f8\u8fd1\u4e14\u66f4\u4fdd\u5b88\uff0c\u5728\u6cd5\u56fd\u548c\u65e5\u672c\u4e5f\u80fd\u8ba1\u7b97\u6700\u4f18\u5145\u7535\u611f\u77e5\u8def\u5f84\u3002", "conclusion": "VEGA\u5b9e\u73b0\u4e86\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u5728\u7535\u52a8\u6c7d\u8f66\u751f\u6001\u8def\u7531\u4e2d\u7684\u5b9e\u9645\u96c6\u6210\u3002"}}
{"id": "2509.13706", "pdf": "https://arxiv.org/pdf/2509.13706", "abs": "https://arxiv.org/abs/2509.13706", "authors": ["Peter Beidler", "Mark Nguyen", "Kevin Lybarger", "Ola Holmberg", "Eric Ford", "John Kang"], "title": "Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "PURPOSE: Incident reports are an important tool for safety and quality\nimprovement in healthcare, but manual review is time-consuming and requires\nsubject matter expertise. Here we present a natural language processing (NLP)\nscreening tool to detect high-severity incident reports in radiation oncology\nacross two institutions.\n  METHODS AND MATERIALS: We used two text datasets to train and evaluate our\nNLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA\nSAFRON (SF), all of which had severity scores labeled by clinical content\nexperts. We trained and evaluated two types of models: baseline support vector\nmachines (SVM) and BlueBERT which is a large language model pretrained on\nPubMed abstracts and hospitalized patient data. We assessed for\ngeneralizability of our model in two ways. First, we evaluated models trained\nusing Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that\nwas first fine-tuned on Inst.-train then on SF-train before testing on SF-test\nset. To further analyze model performance, we also examined a subset of 59\nreports from our Inst. dataset, which were manually edited for clarity.\n  RESULTS Classification performance on the Inst. test achieved AUROC 0.82\nusing SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,\nperformance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56\nusing BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,\nimproved the performance on SF test to AUROC 0.78. Performance of SVM, and\nBlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and\n0.74) was similar to human performance (AUROC 0.81).\n  CONCLUSION: In summary, we successfully developed cross-institution NLP\nmodels on incident report text from radiation oncology centers. These models\nwere able to detect high-severity reports similarly to humans on a curated\ndataset.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u68c0\u6d4b\u653e\u7597\u9ad8\u4e25\u91cd\u5ea6\u4e8b\u4ef6\u62a5\u544a\u7684NLP\u7b5b\u9009\u5de5\u5177\uff0c\u7ecf\u4e0d\u540c\u6570\u636e\u96c6\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\uff0c\u90e8\u5206\u6a21\u578b\u8868\u73b0\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u3002", "motivation": "\u533b\u7597\u4e8b\u4ef6\u62a5\u544a\u624b\u52a8\u5ba1\u67e5\u8017\u65f6\u4e14\u9700\u4e13\u4e1a\u77e5\u8bc6\uff0c\u6545\u5f00\u53d1NLP\u7b5b\u9009\u5de5\u5177\u68c0\u6d4b\u653e\u7597\u9ad8\u4e25\u91cd\u5ea6\u4e8b\u4ef6\u62a5\u544a\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u6587\u672c\u6570\u636e\u96c6\u8bad\u7ec3\u548c\u8bc4\u4f30SVM\u548cBlueBERT\u4e24\u79cd\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u79cd\u65b9\u5f0f\u8bc4\u4f30\u6a21\u578b\u6cdb\u5316\u6027\uff0c\u8fd8\u5206\u6790\u624b\u52a8\u7f16\u8f91\u5b50\u96c6\u3002", "result": "\u5728\u672c\u673a\u6784\u6d4b\u8bd5\u96c6\u4e0aSVM\u548cBlueBERT\u7684AUROC\u5206\u522b\u4e3a0.82\u548c0.81\uff1b\u65e0\u8de8\u673a\u6784\u8fc1\u79fb\u5b66\u4e60\u65f6\uff0cSF\u6d4b\u8bd5\u96c6\u4e0aSVM\u548cBlueBERT\u7684AUROC\u5206\u522b\u4e3a0.42\u548c0.56\uff1bBlueBERT_TRANSFER\u5728SF\u6d4b\u8bd5\u96c6\u4e0aAUROC\u8fbe0.78\uff1bSVM\u548cBlueBERT_TRANSFER\u5728\u624b\u52a8\u7b5b\u9009\u62a5\u544a\u4e0a\u7684\u8868\u73b0\u4e0e\u4eba\u7c7b\u76f8\u8fd1\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u8de8\u673a\u6784NLP\u6a21\u578b\uff0c\u5728\u7b5b\u9009\u6570\u636e\u96c6\u4e0a\u68c0\u6d4b\u9ad8\u4e25\u91cd\u5ea6\u62a5\u544a\u80fd\u529b\u4e0e\u4eba\u7c7b\u76f8\u8fd1\u3002"}}
{"id": "2509.13722", "pdf": "https://arxiv.org/pdf/2509.13722", "abs": "https://arxiv.org/abs/2509.13722", "authors": ["Dingwei Zhang", "Dong Zhang", "Jinhui Tang"], "title": "Mitigating Query Selection Bias in Referring Video Object Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recently, query-based methods have achieved remarkable performance in\nReferring Video Object Segmentation (RVOS) by using textual static object\nqueries to drive cross-modal alignment. However, these static queries are\neasily misled by distractors with similar appearance or motion, resulting in\n\\emph{query selection bias}. To address this issue, we propose Triple Query\nFormer (TQF), which factorizes the referring query into three specialized\ncomponents: an appearance query for static attributes, an intra-frame\ninteraction query for spatial relations, and an inter-frame motion query for\ntemporal association. Instead of relying solely on textual embeddings, our\nqueries are dynamically constructed by integrating both linguistic cues and\nvisual guidance. Furthermore, we introduce two motion-aware aggregation modules\nthat enhance object token representations: Intra-frame Interaction Aggregation\nincorporates position-aware interactions among objects within a single frame,\nwhile Inter-frame Motion Aggregation leverages trajectory-guided alignment\nacross frames to ensure temporal coherence. Extensive experiments on multiple\nRVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our\nstructured query design and motion-aware aggregation modules.", "AI": {"tldr": "\u63d0\u51faTriple Query Former (TQF)\u89e3\u51b3RVOS\u4e2d\u9759\u6001\u67e5\u8be2\u6613\u53d7\u5e72\u6270\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u67e5\u8be2\u7684RVOS\u65b9\u6cd5\u4e2d\u9759\u6001\u67e5\u8be2\u6613\u53d7\u5e72\u6270\uff0c\u4ea7\u751f\u67e5\u8be2\u9009\u62e9\u504f\u5dee\u3002", "method": "\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u5916\u89c2\u3001\u5e27\u5185\u4ea4\u4e92\u548c\u5e27\u95f4\u8fd0\u52a8\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u52a8\u6001\u6784\u5efa\u67e5\u8be2\uff1b\u5f15\u5165\u5e27\u5185\u4ea4\u4e92\u805a\u5408\u548c\u5e27\u95f4\u8fd0\u52a8\u805a\u5408\u4e24\u4e2a\u6a21\u5757\u589e\u5f3a\u5bf9\u8c61\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2aRVOS\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660eTQF\u5177\u6709\u4f18\u52bf\uff0c\u7ed3\u6784\u5316\u67e5\u8be2\u8bbe\u8ba1\u548c\u8fd0\u52a8\u611f\u77e5\u805a\u5408\u6a21\u5757\u6709\u6548\u3002", "conclusion": "TQF\u80fd\u6709\u6548\u89e3\u51b3\u9759\u6001\u67e5\u8be2\u6613\u53d7\u5e72\u6270\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u7ec4\u4ef6\u548c\u6a21\u5757\u6709\u79ef\u6781\u6548\u679c\u3002"}}
{"id": "2509.13775", "pdf": "https://arxiv.org/pdf/2509.13775", "abs": "https://arxiv.org/abs/2509.13775", "authors": ["Vani Kanjirangat", "Ljiljana Dolamic", "Fabio Rinaldi"], "title": "Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications", "categories": ["cs.CL", "cs.AI"], "comment": "4 main pages, 4 additional, 5 figures", "summary": "This paper discusses our exploration of different data-efficient and\nparameter-efficient approaches to Arabic Dialect Identification (ADI). In\nparticular, we investigate various soft-prompting strategies, including\nprefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA\nreparameterizations. For the data-efficient strategy, we analyze hard prompting\nwith zero-shot and few-shot inferences to analyze the dialect identification\ncapabilities of Large Language Models (LLMs). For the parameter-efficient PEFT\napproaches, we conducted our experiments using Arabic-specific encoder models\non several major datasets. We also analyzed the n-shot inferences on\nopen-source decoder-only models, a general multilingual model (Phi-3.5), and an\nArabic-specific one(SILMA). We observed that the LLMs generally struggle to\ndifferentiate the dialectal nuances in the few-shot or zero-shot setups. The\nsoft-prompted encoder variants perform better, while the LoRA-based fine-tuned\nmodels perform best, even surpassing full fine-tuning.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e0d\u540c\u7684\u6570\u636e\u9ad8\u6548\u548c\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\u7528\u4e8e\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bc6\u522b\uff0c\u6d4b\u8bd5\u591a\u79cd\u7b56\u7565\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u6216\u96f6\u6837\u672c\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u8f6f\u63d0\u793a\u7f16\u7801\u5668\u53d8\u4f53\u8868\u73b0\u8f83\u597d\uff0c\u57fa\u4e8eLoRA\u7684\u5fae\u8c03\u6a21\u578b\u6700\u4f73\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u7684\u6570\u636e\u9ad8\u6548\u548c\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\u8fdb\u884c\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bc6\u522b\u3002", "method": "\u7814\u7a76\u591a\u79cd\u8f6f\u63d0\u793a\u7b56\u7565\u548cLoRA\u91cd\u53c2\u6570\u5316\uff1b\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u63a8\u7406\u4e0b\u7684\u786c\u63d0\u793a\uff1b\u5728\u591a\u4e2a\u4e3b\u8981\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u963f\u62c9\u4f2f\u8bed\u7279\u5b9a\u7f16\u7801\u5668\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff1b\u5206\u6790\u5f00\u6e90\u4ec5\u89e3\u7801\u5668\u6a21\u578b\u3001\u901a\u7528\u591a\u8bed\u8a00\u6a21\u578b\u548c\u963f\u62c9\u4f2f\u8bed\u7279\u5b9a\u6a21\u578b\u7684n\u6837\u672c\u63a8\u7406\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u6216\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u96be\u4ee5\u533a\u5206\u65b9\u8a00\u7ec6\u5fae\u5dee\u522b\uff1b\u8f6f\u63d0\u793a\u7f16\u7801\u5668\u53d8\u4f53\u8868\u73b0\u8f83\u597d\uff1b\u57fa\u4e8eLoRA\u7684\u5fae\u8c03\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u751a\u81f3\u8d85\u8fc7\u5168\u91cf\u5fae\u8c03\u3002", "conclusion": "\u57fa\u4e8eLoRA\u7684\u5fae\u8c03\u6a21\u578b\u5728\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bc6\u522b\u4e2d\u6548\u679c\u6700\u597d\u3002"}}
{"id": "2509.13789", "pdf": "https://arxiv.org/pdf/2509.13789", "abs": "https://arxiv.org/abs/2509.13789", "authors": ["Hanshuai Cui", "Zhiqing Tang", "Zhifei Xu", "Zhi Yao", "Wenyi Zeng", "Weijia Jia"], "title": "BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in Diffusion Transformers (DiTs) have established them as\nthe state-of-the-art method for video generation. However, their inherently\nsequential denoising process results in inevitable latency, limiting real-world\napplicability. Existing acceleration methods either compromise visual quality\ndue to architectural modifications or fail to reuse intermediate features at\nproper granularity. Our analysis reveals that DiT blocks are the primary\ncontributors to inference latency. Across diffusion timesteps, the feature\nvariations of DiT blocks exhibit a U-shaped pattern with high similarity during\nintermediate timesteps, which suggests substantial computational redundancy. In\nthis paper, we propose Block-Wise Caching (BWCache), a training-free method to\naccelerate DiT-based video generation. BWCache dynamically caches and reuses\nfeatures from DiT blocks across diffusion timesteps. Furthermore, we introduce\na similarity indicator that triggers feature reuse only when the differences\nbetween block features at adjacent timesteps fall below a threshold, thereby\nminimizing redundant computations while maintaining visual fidelity. Extensive\nexperiments on several video diffusion models demonstrate that BWCache achieves\nup to 2.24$\\times$ speedup with comparable visual quality.", "AI": {"tldr": "\u73b0\u6709Diffusion Transformers\uff08DiTs\uff09\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u6709\u5ef6\u8fdf\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u65e0\u8bad\u7ec3\u7684BWCache\u65b9\u6cd5\u52a0\u901f\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u5b9e\u73b02.24\u500d\u52a0\u901f\u4e14\u89c6\u89c9\u8d28\u91cf\u76f8\u5f53\u3002", "motivation": "DiTs\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u987a\u5e8f\u53bb\u566a\u8fc7\u7a0b\u5bfc\u81f4\u5ef6\u8fdf\uff0c\u73b0\u6709\u52a0\u901f\u65b9\u6cd5\u6709\u8d28\u91cf\u4e0b\u964d\u6216\u7279\u5f81\u590d\u7528\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faBlock - Wise Caching\uff08BWCache\uff09\u65b9\u6cd5\uff0c\u52a8\u6001\u7f13\u5b58\u548c\u590d\u7528DiT\u5757\u7279\u5f81\uff0c\u5f15\u5165\u76f8\u4f3c\u5ea6\u6307\u6807\uff0c\u5728\u76f8\u90bb\u65f6\u95f4\u6b65\u5757\u7279\u5f81\u5dee\u5f02\u4f4e\u4e8e\u9608\u503c\u65f6\u89e6\u53d1\u7279\u5f81\u590d\u7528\u3002", "result": "\u5728\u591a\u4e2a\u89c6\u9891\u6269\u6563\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0cBWCache\u5b9e\u73b0\u4e86\u9ad8\u8fbe2.24\u500d\u7684\u52a0\u901f\uff0c\u89c6\u89c9\u8d28\u91cf\u76f8\u5f53\u3002", "conclusion": "BWCache\u80fd\u6709\u6548\u52a0\u901fDiT-based\u89c6\u9891\u751f\u6210\uff0c\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u540c\u65f6\u4fdd\u6301\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2509.13476", "pdf": "https://arxiv.org/pdf/2509.13476", "abs": "https://arxiv.org/abs/2509.13476", "authors": ["Md Masud Rana", "Farjana Tasnim Mukta", "Duc D. Nguyen"], "title": "A Geometric Graph-Based Deep Learning Model for Drug-Target Affinity Prediction", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "In structure-based drug design, accurately estimating the binding affinity\nbetween a candidate ligand and its protein receptor is a central challenge.\nRecent advances in artificial intelligence, particularly deep learning, have\ndemonstrated superior performance over traditional empirical and physics-based\nmethods for this task, enabled by the growing availability of structural and\nexperimental affinity data. In this work, we introduce DeepGGL, a deep\nconvolutional neural network that integrates residual connections and an\nattention mechanism within a geometric graph learning framework. By leveraging\nmultiscale weighted colored bipartite subgraphs, DeepGGL effectively captures\nfine-grained atom-level interactions in protein-ligand complexes across\nmultiple scales. We benchmarked DeepGGL against established models on CASF-2013\nand CASF-2016, where it achieved state-of-the-art performance with significant\nimprovements across diverse evaluation metrics. To further assess robustness\nand generalization, we tested the model on the CSAR-NRC-HiQ dataset and the\nPDBbind v2019 holdout set. DeepGGL consistently maintained high predictive\naccuracy, highlighting its adaptability and reliability for binding affinity\nprediction in structure-based drug discovery.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u57fa\u4e8e\u7ed3\u6784\u7684\u836f\u7269\u8bbe\u8ba1\u4e2d\u9884\u6d4b\u7ed3\u5408\u4eb2\u548c\u529b\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bDeepGGL\uff0c\u8be5\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u57fa\u4e8e\u7ed3\u6784\u7684\u836f\u7269\u8bbe\u8ba1\u4e2d\uff0c\u51c6\u786e\u4f30\u8ba1\u5019\u9009\u914d\u4f53\u4e0e\u86cb\u767d\u8d28\u53d7\u4f53\u4e4b\u95f4\u7684\u7ed3\u5408\u4eb2\u548c\u529b\u662f\u6838\u5fc3\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u9700\u66f4\u4f18\u65b9\u6cd5\u3002", "method": "\u5f15\u5165DeepGGL\uff0c\u5728\u51e0\u4f55\u56fe\u5b66\u4e60\u6846\u67b6\u4e2d\u96c6\u6210\u6b8b\u5dee\u8fde\u63a5\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5229\u7528\u591a\u5c3a\u5ea6\u52a0\u6743\u5f69\u8272\u4e8c\u5206\u56fe\u5b50\u56fe\u6355\u83b7\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u5728CASF - 2013\u548cCASF - 2016\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u6709\u663e\u8457\u6539\u8fdb\uff1b\u5728CSAR - NRC - HiQ\u6570\u636e\u96c6\u548cPDBbind v2019\u4fdd\u7559\u96c6\u4e0a\u4fdd\u6301\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "DeepGGL\u5177\u6709\u9002\u5e94\u6027\u548c\u53ef\u9760\u6027\uff0c\u53ef\u7528\u4e8e\u57fa\u4e8e\u7ed3\u6784\u7684\u836f\u7269\u53d1\u73b0\u4e2d\u7ed3\u5408\u4eb2\u548c\u529b\u9884\u6d4b\u3002"}}
{"id": "2509.13790", "pdf": "https://arxiv.org/pdf/2509.13790", "abs": "https://arxiv.org/abs/2509.13790", "authors": ["Yangning Li", "Tingwei Lu", "Yinghui Li", "Yankai Chen", "Wei-Chieh Huang", "Wenhao Jiang", "Hui Wang", "Hai-Tao Zheng", "Philip S. Yu"], "title": "Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025 Findings", "summary": "Efficient instruction tuning aims to enhance the ultimate performance of\nlarge language models (LLMs) trained on a given instruction dataset. Curriculum\nlearning as a typical data organization strategy has shown preliminary\neffectiveness in instruction tuning. However, current curriculum tuning methods\nsuffer from the curriculum rigidity, since they rely solely on static heuristic\ndifficulty metrics. These methods fail to adapt to the evolving capabilities of\nmodels during training, resulting in a fixed and potentially sub-optimal\nlearning trajectory. To address the issue, Competence-Aware Multi-Perspective\ncUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS\noffers several advantages: (1) Dynamic selection for sub-curriculum. (2)\nCompetency-aware adjustment to the curriculum schedule. (3) Multiple\ndifficulty-based scheduling. Extensive experiments prove the superior\nperformance of CAMPUS, compared to other state-of-the-art baselines for\nefficient instruction tuning.", "AI": {"tldr": "\u63d0\u51faCAMPUS\u6846\u67b6\u89e3\u51b3\u5f53\u524d\u8bfe\u7a0b\u8c03\u4f18\u65b9\u6cd5\u7684\u8bfe\u7a0b\u521a\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u5f53\u524d\u8bfe\u7a0b\u8c03\u4f18\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u542f\u53d1\u5f0f\u96be\u5ea6\u6307\u6807\uff0c\u5b58\u5728\u8bfe\u7a0b\u521a\u6027\u95ee\u9898\uff0c\u65e0\u6cd5\u9002\u5e94\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u53d8\u5316\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faCompetence - Aware Multi - Perspective cUrriculum inStruction tuning\u6846\u67b6\uff08CAMPUS\uff09\uff0c\u5305\u62ec\u5b50\u8bfe\u7a0b\u52a8\u6001\u9009\u62e9\u3001\u57fa\u4e8e\u80fd\u529b\u7684\u8bfe\u7a0b\u8fdb\u5ea6\u8c03\u6574\u548c\u591a\u96be\u5ea6\u8c03\u5ea6\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5176\u4ed6\u9ad8\u6548\u6307\u4ee4\u8c03\u4f18\u7684\u5148\u8fdb\u57fa\u7ebf\u76f8\u6bd4\uff0cCAMPUS\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "CAMPUS\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u5f53\u524d\u8bfe\u7a0b\u8c03\u4f18\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u63d0\u5347\u9ad8\u6548\u6307\u4ee4\u8c03\u4f18\u7684\u6027\u80fd\u3002"}}
{"id": "2509.13496", "pdf": "https://arxiv.org/pdf/2509.13496", "abs": "https://arxiv.org/abs/2509.13496", "authors": ["Rajatsubhra Chakraborty", "Xujun Che", "Depeng Xu", "Cori Faklaris", "Xi Niu", "Shuhan Yuan"], "title": "BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Bias discovery is critical for black-box generative models, especiall\ntext-to-image (TTI) models. Existing works predominantly focus on output-level\ndemographic distributions, which do not necessarily guarantee concept\nrepresentations to be disentangled post-mitigation. We propose BiasMap, a\nmodel-agnostic framework for uncovering latent concept-level representational\nbiases in stable diffusion models. BiasMap leverages cross-attention\nattribution maps to reveal structural entanglements between demographics (e.g.,\ngender, race) and semantics (e.g., professions), going deeper into\nrepresentational bias during the image generation. Using attribution maps of\nthese concepts, we quantify the spatial demographics-semantics concept\nentanglement via Intersection over Union (IoU), offering a lens into bias that\nremains hidden in existing fairness discovery approaches. In addition, we\nfurther utilize BiasMap for bias mitigation through energy-guided diffusion\nsampling that directly modifies latent noise space and minimizes the expected\nSoftIoU during the denoising process. Our findings show that existing fairness\ninterventions may reduce the output distributional gap but often fail to\ndisentangle concept-level coupling, whereas our mitigation method can mitigate\nconcept entanglement in image generation while complementing distributional\nbias mitigation.", "AI": {"tldr": "\u63d0\u51faBiasMap\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u73b0\u5e76\u7f13\u89e3\u7a33\u5b9a\u6269\u6563\u6a21\u578b\u4e2d\u6f5c\u5728\u6982\u5ff5\u5c42\u9762\u7684\u8868\u5f81\u504f\u5dee\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u8f93\u51fa\u5c42\u9762\u7684\u4eba\u53e3\u7edf\u8ba1\u5206\u5e03\uff0c\u4e0d\u80fd\u4fdd\u8bc1\u7f13\u89e3\u540e\u6982\u5ff5\u8868\u5f81\u89e3\u8026\uff0c\u9700\u8981\u6df1\u5165\u6316\u6398\u6982\u5ff5\u5c42\u9762\u7684\u8868\u5f81\u504f\u5dee\u3002", "method": "\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u5f52\u56e0\u56fe\u63ed\u793a\u4eba\u53e3\u7edf\u8ba1\u4e0e\u8bed\u4e49\u7684\u7ed3\u6784\u7ea0\u7f20\uff0c\u901a\u8fc7IoU\u91cf\u5316\u6982\u5ff5\u7ea0\u7f20\uff0c\u5229\u7528\u80fd\u91cf\u5f15\u5bfc\u7684\u6269\u6563\u91c7\u6837\u7f13\u89e3\u504f\u5dee\u3002", "result": "\u73b0\u6709\u516c\u5e73\u5e72\u9884\u63aa\u65bd\u53ef\u80fd\u51cf\u5c11\u8f93\u51fa\u5206\u5e03\u5dee\u8ddd\uff0c\u4f46\u65e0\u6cd5\u89e3\u8026\u6982\u5ff5\u5c42\u9762\u7684\u8026\u5408\uff0c\u800c\u63d0\u51fa\u7684\u7f13\u89e3\u65b9\u6cd5\u53ef\u7f13\u89e3\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u6982\u5ff5\u7ea0\u7f20\u3002", "conclusion": "BiasMap\u6846\u67b6\u80fd\u6709\u6548\u53d1\u73b0\u5e76\u7f13\u89e3\u7a33\u5b9a\u6269\u6563\u6a21\u578b\u4e2d\u6982\u5ff5\u5c42\u9762\u7684\u8868\u5f81\u504f\u5dee\uff0c\u8865\u5145\u4e86\u5206\u5e03\u504f\u5dee\u7f13\u89e3\u3002"}}
{"id": "2509.13792", "pdf": "https://arxiv.org/pdf/2509.13792", "abs": "https://arxiv.org/abs/2509.13792", "authors": ["Inder Pal Singh", "Nidhal Eddine Chenni", "Abd El Rahman Shabayek", "Arunkumar Rathinam", "Djamila Aouada"], "title": "Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous\nspace operations such as rendezvous, docking, and in-orbit servicing. Hybrid\npipelines that combine object detection, keypoint regression, and\nPerspective-n-Point (PnP) solvers have recently achieved strong results on\nsynthetic datasets, yet their performance deteriorates sharply on real or\nlab-generated imagery due to the persistent synthetic-to-real domain gap.\nExisting unsupervised domain adaptation approaches aim to mitigate this issue\nbut often underperform when a modest number of labeled target samples are\navailable. In this work, we propose the first Supervised Domain Adaptation\n(SDA) framework tailored for SPE keypoint regression. Building on the Learning\nInvariant Representation and Risk (LIRR) paradigm, our method jointly optimizes\ndomain-invariant representations and task-specific risk using both labeled\nsynthetic and limited labeled real data, thereby reducing generalization error\nunder domain shift. Extensive experiments on the SPEED+ benchmark demonstrate\nthat our approach consistently outperforms source-only, fine-tuning, and oracle\nbaselines. Notably, with only 5% labeled target data, our method matches or\nsurpasses oracle performance trained on larger fractions of labeled data. The\nframework is lightweight, backbone-agnostic, and computationally efficient,\noffering a practical pathway toward robust and deployable spacecraft pose\nestimation in real-world space environments.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u822a\u5929\u5668\u59ff\u6001\u4f30\u8ba1\uff08SPE\uff09\u5173\u952e\u70b9\u56de\u5f52\u7684\u76d1\u7763\u57df\u9002\u5e94\uff08SDA\uff09\u6846\u67b6\uff0c\u5728SPEED+\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8f7b\u91cf\u7ea7\u4e14\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u7ba1\u9053\u5728\u771f\u5b9e\u56fe\u50cf\u4e0a\u56e0\u5408\u6210\u5230\u771f\u5b9e\u7684\u57df\u5dee\u8ddd\u6027\u80fd\u4e0b\u964d\uff0c\u65e0\u76d1\u7763\u57df\u9002\u5e94\u65b9\u6cd5\u5728\u6709\u5c11\u91cf\u6807\u8bb0\u76ee\u6807\u6837\u672c\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5b66\u4e60\u4e0d\u53d8\u8868\u793a\u548c\u98ce\u9669\uff08LIRR\uff09\u8303\u5f0f\uff0c\u8054\u5408\u4f18\u5316\u57df\u4e0d\u53d8\u8868\u793a\u548c\u4efb\u52a1\u7279\u5b9a\u98ce\u9669\uff0c\u4f7f\u7528\u6807\u8bb0\u7684\u5408\u6210\u6570\u636e\u548c\u6709\u9650\u7684\u6807\u8bb0\u771f\u5b9e\u6570\u636e\u3002", "result": "\u5728SPEED+\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u4ec5\u6e90\u3001\u5fae\u8c03\u3001oracle\u57fa\u7ebf\uff0c\u4ec5\u75285%\u6807\u8bb0\u76ee\u6807\u6570\u636e\u5c31\u53ef\u5ab2\u7f8e\u6216\u8d85\u8d8a\u7528\u66f4\u591a\u6807\u8bb0\u6570\u636e\u8bad\u7ec3\u7684oracle\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u8f7b\u91cf\u7ea7\u3001\u4e0e\u9aa8\u5e72\u7f51\u7edc\u65e0\u5173\u4e14\u8ba1\u7b97\u9ad8\u6548\uff0c\u4e3a\u73b0\u5b9e\u7a7a\u95f4\u73af\u5883\u4e2d\u5b9e\u73b0\u9c81\u68d2\u4e14\u53ef\u90e8\u7f72\u7684\u822a\u5929\u5668\u59ff\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2509.13577", "pdf": "https://arxiv.org/pdf/2509.13577", "abs": "https://arxiv.org/abs/2509.13577", "authors": ["Tongfei Guo", "Lili Su"], "title": "Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "8 pages, 7 figures", "summary": "Trajectory prediction is central to the safe and seamless operation of\nautonomous vehicles (AVs). In deployment, however, prediction models inevitably\nface distribution shifts between training data and real-world conditions, where\nrare or underrepresented traffic scenarios induce out-of-distribution (OOD)\ncases. While most prior OOD detection research in AVs has concentrated on\ncomputer vision tasks such as object detection and segmentation,\ntrajectory-level OOD detection remains largely underexplored. A recent study\nformulated this problem as a quickest change detection (QCD) task, providing\nformal guarantees on the trade-off between detection delay and false alarms\n[1]. Building on this foundation, we propose a new framework that introduces\nadaptive mechanisms to achieve robust detection in complex driving\nenvironments. Empirical analysis across multiple real-world datasets reveals\nthat prediction errors -- even on in-distribution samples -- exhibit\nmode-dependent distributions that evolve over time with dataset-specific\ndynamics. By explicitly modeling these error modes, our method achieves\nsubstantial improvements in both detection delay and false alarm rates.\nComprehensive experiments on established trajectory prediction benchmarks show\nthat our framework significantly outperforms prior UQ- and vision-based OOD\napproaches in both accuracy and computational efficiency, offering a practical\npath toward reliable, driving-aware autonomy.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u6846\u67b6\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684OOD\u68c0\u6d4b\uff0c\u5728\u591a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u9a7e\u9a76OOD\u68c0\u6d4b\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\uff0c\u8f68\u8ff9\u7ea7OOD\u68c0\u6d4b\u7814\u7a76\u4e0d\u8db3\uff0c\u4e14\u8981\u5e94\u5bf9\u590d\u6742\u9a7e\u9a76\u73af\u5883\u4e0b\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u65b0\u6846\u67b6\u5f15\u5165\u81ea\u9002\u5e94\u673a\u5236\uff0c\u660e\u786e\u5efa\u6a21\u9884\u6d4b\u8bef\u5dee\u6a21\u5f0f\u3002", "result": "\u5728\u591a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u65b0\u65b9\u6cd5\u5728\u68c0\u6d4b\u5ef6\u8fdf\u548c\u8bef\u62a5\u7387\u4e0a\u6709\u663e\u8457\u6539\u5584\uff0c\u7efc\u5408\u5b9e\u9a8c\u4e2d\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u6846\u67b6\u4e3a\u53ef\u9760\u7684\u3001\u9a7e\u9a76\u611f\u77e5\u7684\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u4e86\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2509.13854", "pdf": "https://arxiv.org/pdf/2509.13854", "abs": "https://arxiv.org/abs/2509.13854", "authors": ["Jack McKinlay", "Marina De Vos", "Janina A. Hoffmann", "Andreas Theodorou"], "title": "Understanding the Process of Human-AI Value Alignment", "categories": ["cs.CY", "cs.AI"], "comment": "39 pages, 7 figures", "summary": "Background: Value alignment in computer science research is often used to\nrefer to the process of aligning artificial intelligence with humans, but the\nway the phrase is used often lacks precision. Objectives: In this paper, we\nconduct a systematic literature review to advance the understanding of value\nalignment in artificial intelligence by characterising the topic in the context\nof its research literature. We use this to suggest a more precise definition of\nthe term. Methods: We analyse 172 value alignment research articles that have\nbeen published in recent years and synthesise their content using thematic\nanalyses. Results: Our analysis leads to six themes: value alignment drivers &\napproaches; challenges in value alignment; values in value alignment; cognitive\nprocesses in humans and AI; human-agent teaming; and designing and developing\nvalue-aligned systems. Conclusions: By analysing these themes in the context of\nthe literature we define value alignment as an ongoing process between humans\nand autonomous agents that aims to express and implement abstract values in\ndiverse contexts, while managing the cognitive limits of both humans and AI\nagents and also balancing the conflicting ethical and political demands\ngenerated by the values in different groups. Our analysis gives rise to a set\nof research challenges and opportunities in the field of value alignment for\nfuture work.", "AI": {"tldr": "\u6587\u7ae0\u901a\u8fc7\u5bf9172\u7bc7\u4ef7\u503c\u5bf9\u9f50\u7814\u7a76\u6587\u7ae0\u8fdb\u884c\u4e3b\u9898\u5206\u6790\uff0c\u5f97\u51fa\u516d\u4e2a\u4e3b\u9898\uff0c\u5e76\u7ed9\u51fa\u4ef7\u503c\u5bf9\u9f50\u7684\u5b9a\u4e49\uff0c\u6307\u51fa\u7814\u7a76\u6311\u6218\u548c\u673a\u4f1a\u3002", "motivation": "\u5f53\u524d\u4ef7\u503c\u5bf9\u9f50\u8868\u8ff0\u7f3a\u4e4f\u7cbe\u786e\u6027\uff0c\u4e3a\u589e\u8fdb\u5bf9\u4eba\u5de5\u667a\u80fd\u4e2d\u4ef7\u503c\u5bf9\u9f50\u7684\u7406\u89e3\uff0c\u7ed9\u51fa\u66f4\u7cbe\u786e\u7684\u5b9a\u4e49\u3002", "method": "\u5206\u6790\u8fd1\u5e74\u53d1\u8868\u7684172\u7bc7\u4ef7\u503c\u5bf9\u9f50\u7814\u7a76\u6587\u7ae0\uff0c\u5e76\u7528\u4e3b\u9898\u5206\u6790\u7efc\u5408\u5185\u5bb9\u3002", "result": "\u5206\u6790\u5f97\u51fa\u516d\u4e2a\u4e3b\u9898\uff1a\u4ef7\u503c\u5bf9\u9f50\u9a71\u52a8\u4e0e\u65b9\u6cd5\u3001\u4ef7\u503c\u5bf9\u9f50\u6311\u6218\u3001\u4ef7\u503c\u5bf9\u9f50\u4e2d\u7684\u4ef7\u503c\u3001\u4eba\u7c7b\u4e0eAI\u8ba4\u77e5\u8fc7\u7a0b\u3001\u4eba\u673a\u534f\u4f5c\u3001\u8bbe\u8ba1\u5f00\u53d1\u4ef7\u503c\u5bf9\u9f50\u7cfb\u7edf\u3002", "conclusion": "\u5c06\u4ef7\u503c\u5bf9\u9f50\u5b9a\u4e49\u4e3a\u4eba\u7c7b\u4e0e\u81ea\u4e3b\u4ee3\u7406\u95f4\u7684\u6301\u7eed\u8fc7\u7a0b\uff0c\u5206\u6790\u5f97\u51fa\u8be5\u9886\u57df\u672a\u6765\u7814\u7a76\u7684\u6311\u6218\u548c\u673a\u4f1a\u3002"}}
{"id": "2509.13624", "pdf": "https://arxiv.org/pdf/2509.13624", "abs": "https://arxiv.org/abs/2509.13624", "authors": ["Shambhavi Krishna", "Atharva Naik", "Chaitali Agarwal", "Sudharshan Govindan", "Taesung Lee", "Haw-Shiuan Chang"], "title": "Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning", "categories": ["cs.CL", "cs.LG"], "comment": "Camera-ready version. Accepted to appear in the proceedings of the\n  14th Joint Conference on Lexical and Computational Semantics (*SEM 2025)", "summary": "Large language models are increasingly deployed across diverse applications.\nThis often includes tasks LLMs have not encountered during training. This\nimplies that enumerating and obtaining the high-quality training data for all\ntasks is infeasible. Thus, we often need to rely on transfer learning using\ndatasets with different characteristics, and anticipate out-of-distribution\nrequests. Motivated by this practical need, we propose an analysis framework,\nbuilding a transfer learning matrix and dimensionality reduction, to dissect\nthese cross-task interactions. We train and analyze 10 models to identify\nlatent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)\nand discover the side effects of the transfer learning. Our findings reveal\nthat performance improvements often defy explanations based on surface-level\ndataset similarity or source data quality. Instead, hidden statistical factors\nof the source dataset, such as class distribution and generation length\nproclivities, alongside specific linguistic features, are actually more\ninfluential. This work offers insights into the complex dynamics of transfer\nlearning, paving the way for more predictable and effective LLM adaptation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5206\u6790\u6846\u67b6\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u4efb\u52a1\u8fc1\u79fb\u5b66\u4e60\uff0c\u53d1\u73b0\u9690\u85cf\u7edf\u8ba1\u56e0\u7d20\u548c\u8bed\u8a00\u7279\u5f81\u66f4\u5f71\u54cd\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e2d\u96be\u4ee5\u83b7\u53d6\u6240\u6709\u4efb\u52a1\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u9700\u4f9d\u8d56\u8fc1\u79fb\u5b66\u4e60\uff0c\u56e0\u6b64\u8981\u5206\u6790\u8de8\u4efb\u52a1\u4ea4\u4e92\u3002", "method": "\u6784\u5efa\u8fc1\u79fb\u5b66\u4e60\u77e9\u9635\u548c\u964d\u7ef4\u7684\u5206\u6790\u6846\u67b6\uff0c\u8bad\u7ec3\u5e76\u5206\u679010\u4e2a\u6a21\u578b\u3002", "result": "\u6027\u80fd\u63d0\u5347\u96be\u4ee5\u7528\u8868\u9762\u6570\u636e\u96c6\u76f8\u4f3c\u6027\u6216\u6e90\u6570\u636e\u8d28\u91cf\u89e3\u91ca\uff0c\u6e90\u6570\u636e\u96c6\u9690\u85cf\u7edf\u8ba1\u56e0\u7d20\u548c\u7279\u5b9a\u8bed\u8a00\u7279\u5f81\u66f4\u5177\u5f71\u54cd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u53ef\u9884\u6d4b\u548c\u6709\u6548\u7684\u9002\u914d\u63d0\u4f9b\u601d\u8def\u3002"}}
{"id": "2509.13628", "pdf": "https://arxiv.org/pdf/2509.13628", "abs": "https://arxiv.org/abs/2509.13628", "authors": ["Mert G\u00fcrb\u00fczbalaban", "Yasa Syed", "Necdet Serhat Aybat"], "title": "Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "We study trade-offs between convergence rate and robustness to gradient\nerrors in first-order methods. Our focus is on generalized momentum methods\n(GMMs), a class that includes Nesterov's accelerated gradient, heavy-ball, and\ngradient descent. We allow stochastic gradient errors that may be adversarial\nand biased, and quantify robustness via the risk-sensitive index (RSI) from\nrobust control theory. For quadratic objectives with i.i.d. Gaussian noise, we\ngive closed-form expressions for RSI using 2x2 Riccati equations, revealing a\nPareto frontier between RSI and convergence rate over stepsize and momentum\nchoices. We prove a large-deviation principle for time-averaged suboptimality\nand show that the rate function is, up to scaling, the convex conjugate of the\nRSI. We further connect RSI to the $H_{\\infty}$-norm, showing that stronger\nworst-case robustness (smaller $H_{\\infty}$ norm) yields sharper decay of tail\nprobabilities. Beyond quadratics, under biased sub-Gaussian gradient errors, we\nderive non-asymptotic bounds on a finite-time analogue of the RSI, giving\nfinite-time high-probability guarantees and large-deviation bounds. We also\nobserve an analogous trade-off between RSI and convergence-rate bounds for\nsmooth strongly convex functions. To our knowledge, these are the first\nnon-asymptotic guarantees and risk-sensitive analysis of GMMs with biased\ngradients. Numerical experiments on robust regression illustrate the results.", "AI": {"tldr": "\u7814\u7a76\u4e00\u9636\u65b9\u6cd5\u4e2d\u6536\u655b\u901f\u5ea6\u4e0e\u68af\u5ea6\u8bef\u5dee\u9c81\u68d2\u6027\u7684\u6743\u8861\uff0c\u805a\u7126\u5e7f\u4e49\u52a8\u91cf\u65b9\u6cd5\uff0c\u7ed9\u51fa\u4e8c\u6b21\u76ee\u6807\u4e0bRSI\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u8bc1\u660e\u5927\u504f\u5dee\u539f\u7406\uff0c\u63a8\u5bfc\u975e\u6e10\u8fd1\u754c\uff0c\u6709\u6570\u503c\u5b9e\u9a8c\u3002", "motivation": "\u7814\u7a76\u4e00\u9636\u65b9\u6cd5\u4e2d\u6536\u655b\u901f\u5ea6\u548c\u5bf9\u68af\u5ea6\u8bef\u5dee\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u7279\u522b\u662f\u5e7f\u4e49\u52a8\u91cf\u65b9\u6cd5\uff08GMMs\uff09\u5728\u6b64\u65b9\u9762\u7684\u60c5\u51b5\u3002", "method": "\u5141\u8bb8\u968f\u673a\u68af\u5ea6\u8bef\u5dee\uff0c\u7528\u98ce\u9669\u654f\u611f\u6307\u6570\uff08RSI\uff09\u91cf\u5316\u9c81\u68d2\u6027\uff0c\u4f7f\u75282x2 Riccati\u65b9\u7a0b\u7ed9\u51fa\u4e8c\u6b21\u76ee\u6807\u4e0bRSI\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u8bc1\u660e\u5927\u504f\u5dee\u539f\u7406\uff0c\u63a8\u5bfc\u975e\u6e10\u8fd1\u754c\u3002", "result": "\u63ed\u793a\u4e86RSI\u548c\u6536\u655b\u901f\u5ea6\u5728\u6b65\u957f\u548c\u52a8\u91cf\u9009\u62e9\u4e0a\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u8bc1\u660e\u5927\u504f\u5dee\u539f\u7406\uff0c\u5c06RSI\u4e0e$H_{\\infty}$ - \u8303\u6570\u8054\u7cfb\u8d77\u6765\uff0c\u5f97\u5230\u975e\u6e10\u8fd1\u754c\uff0c\u5728\u5e73\u6ed1\u5f3a\u51f8\u51fd\u6570\u4e0a\u4e5f\u89c2\u5bdf\u5230\u7c7b\u4f3c\u6743\u8861\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5bf9\u6709\u504f\u68af\u5ea6\u7684GMMs\u8fdb\u884c\u975e\u6e10\u8fd1\u4fdd\u8bc1\u548c\u98ce\u9669\u654f\u611f\u5206\u6790\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7ed3\u679c\u3002"}}
{"id": "2509.13892", "pdf": "https://arxiv.org/pdf/2509.13892", "abs": "https://arxiv.org/abs/2509.13892", "authors": ["Gustavo Kruger", "Nikhil Sachdeva", "Michael Sobolev"], "title": "Synthetic Data Generation for Screen Time and App Usage", "categories": ["cs.HC", "cs.AI", "I.2; J.4"], "comment": "14 pages", "summary": "Smartphone usage data can provide valuable insights for understanding\ninteraction with technology and human behavior. However, collecting\nlarge-scale, in-the-wild smartphone usage logs is challenging due to high\ncosts, privacy concerns, under representative user samples and biases like\nnon-response that can skew results. These challenges call for exploring\nalternative approaches to obtain smartphone usage datasets. In this context,\nlarge language models (LLMs) such as Open AI's ChatGPT present a novel approach\nfor synthetic smartphone usage data generation, addressing limitations of\nreal-world data collection. We describe a case study on how four prompt\nstrategies influenced the quality of generated smartphone usage data. We\ncontribute with insights on prompt design and measures of data quality,\nreporting a prompting strategy comparison combining two factors, prompt level\nof detail (describing a user persona, describing the expected results\ncharacteristics) and seed data inclusion (with versus without an initial real\nusage example). Our findings suggest that using LLMs to generate structured and\nbehaviorally plausible smartphone use datasets is feasible for some use cases,\nespecially when using detailed prompts. Challenges remain in capturing diverse\nnuances of human behavioral patterns in a single synthetic dataset, and\nevaluating tradeoffs between data fidelity and diversity, suggesting the need\nfor use-case-specific evaluation metrics and future research with more diverse\nseed data and different LLM models.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5408\u6210\u667a\u80fd\u624b\u673a\u4f7f\u7528\u6570\u636e\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u5bf9\u6570\u636e\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8be6\u7ec6\u63d0\u793a\u4e0b\u751f\u6210\u6570\u636e\u53ef\u884c\uff0c\u4f46\u4ecd\u6709\u6311\u6218\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u6536\u96c6\u667a\u80fd\u624b\u673a\u4f7f\u7528\u65e5\u5fd7\u5b58\u5728\u6210\u672c\u9ad8\u3001\u9690\u79c1\u7b49\u95ee\u9898\uff0c\u9700\u63a2\u7d22\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u5f00\u5c55\u6848\u4f8b\u7814\u7a76\uff0c\u5bf9\u6bd4\u56db\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u7ed3\u5408\u63d0\u793a\u8be6\u7ec6\u7a0b\u5ea6\u548c\u79cd\u5b50\u6570\u636e\u5305\u542b\u60c5\u51b5\u3002", "result": "\u5728\u4e00\u4e9b\u7528\u4f8b\u4e2d\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u4e14\u884c\u4e3a\u5408\u7406\u7684\u667a\u80fd\u624b\u673a\u4f7f\u7528\u6570\u636e\u96c6\u662f\u53ef\u884c\u7684\uff0c\u5c24\u5176\u662f\u4f7f\u7528\u8be6\u7ec6\u63d0\u793a\u65f6\u3002", "conclusion": "\u867d\u6709\u53ef\u884c\u6027\uff0c\u4f46\u5728\u6355\u6349\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\u7ec6\u5fae\u5dee\u522b\u3001\u5e73\u8861\u6570\u636e\u4fdd\u771f\u5ea6\u548c\u591a\u6837\u6027\u65b9\u9762\u6709\u6311\u6218\uff0c\u9700\u7279\u5b9a\u7528\u4f8b\u8bc4\u4f30\u6307\u6807\u548c\u66f4\u591a\u7814\u7a76\u3002"}}
{"id": "2509.13705", "pdf": "https://arxiv.org/pdf/2509.13705", "abs": "https://arxiv.org/abs/2509.13705", "authors": ["Koki Chinzei", "Quoc Hoan Tran", "Norifumi Matsumoto", "Yasuhiro Endo", "Hirotaka Oshima"], "title": "Learning quantum many-body data locally: A provably scalable framework", "categories": ["quant-ph", "cond-mat.stat-mech", "cs.LG"], "comment": "38 pages, 5 figures", "summary": "Machine learning (ML) holds great promise for extracting insights from\ncomplex quantum many-body data obtained in quantum experiments. This approach\ncan efficiently solve certain quantum problems that are classically\nintractable, suggesting potential advantages of harnessing quantum data.\nHowever, addressing large-scale problems still requires significant amounts of\ndata beyond the limited computational resources of near-term quantum devices.\nWe propose a scalable ML framework called Geometrically Local Quantum Kernel\n(GLQK), designed to efficiently learn quantum many-body experimental data by\nleveraging the exponential decay of correlations, a phenomenon prevalent in\nnoncritical systems. In the task of learning an unknown polynomial of quantum\nexpectation values, we rigorously prove that GLQK substantially improves\npolynomial sample complexity in the number of qubits $n$, compared to the\nexisting shadow kernel, by constructing a feature space from local quantum\ninformation at the correlation length scale. This improvement is particularly\nnotable when each term of the target polynomial involves few local subsystems.\nRemarkably, for translationally symmetric data, GLQK achieves constant sample\ncomplexity, independent of $n$. We numerically demonstrate its high scalability\nin two learning tasks on quantum many-body phenomena. These results establish\nnew avenues for utilizing experimental data to advance the understanding of\nquantum many-body physics.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u6269\u5c55\u673a\u5668\u5b66\u4e60\u6846\u67b6GLQK\u5b66\u4e60\u91cf\u5b50\u591a\u4f53\u5b9e\u9a8c\u6570\u636e\uff0c\u8bc1\u660e\u5176\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u7684\u4f18\u52bf\u5e76\u6570\u503c\u9a8c\u8bc1\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u7406\u89e3\u91cf\u5b50\u591a\u4f53\u7269\u7406\u63d0\u4f9b\u65b0\u9014\u5f84\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5904\u7406\u91cf\u5b50\u591a\u4f53\u6570\u636e\u6709\u6f5c\u529b\uff0c\u4f46\u89e3\u51b3\u5927\u89c4\u6a21\u95ee\u9898\u53d7\u8fd1\u671f\u9650\u91cf\u5b50\u8bbe\u5907\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u3002", "method": "\u63d0\u51faGeometrically Local Quantum Kernel (GLQK)\u6846\u67b6\uff0c\u5229\u7528\u975e\u4e34\u754c\u7cfb\u7edf\u4e2d\u76f8\u5173\u6027\u6307\u6570\u8870\u51cf\u7684\u7279\u6027\uff0c\u4ece\u76f8\u5173\u957f\u5ea6\u5c3a\u5ea6\u7684\u5c40\u90e8\u91cf\u5b50\u4fe1\u606f\u6784\u5efa\u7279\u5f81\u7a7a\u95f4\u3002", "result": "\u5728\u5b66\u4e60\u91cf\u5b50\u671f\u671b\u503c\u7684\u672a\u77e5\u591a\u9879\u5f0f\u4efb\u52a1\u4e2d\uff0cGLQK\u76f8\u6bd4\u73b0\u6709\u5f71\u5b50\u6838\u5927\u5e45\u63d0\u9ad8\u4e86\u5173\u4e8e\u91cf\u5b50\u6bd4\u7279\u6570n\u7684\u591a\u9879\u5f0f\u6837\u672c\u590d\u6742\u5ea6\uff1b\u5bf9\u4e8e\u5e73\u79fb\u5bf9\u79f0\u6570\u636e\uff0c\u5b9e\u73b0\u4e0en\u65e0\u5173\u7684\u6052\u5b9a\u6837\u672c\u590d\u6742\u5ea6\uff1b\u5728\u4e24\u4e2a\u91cf\u5b50\u591a\u4f53\u73b0\u8c61\u5b66\u4e60\u4efb\u52a1\u4e2d\u6570\u503c\u9a8c\u8bc1\u4e86\u9ad8\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5229\u7528\u5b9e\u9a8c\u6570\u636e\u63a8\u8fdb\u5bf9\u91cf\u5b50\u591a\u4f53\u7269\u7406\u7684\u7406\u89e3\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.13905", "pdf": "https://arxiv.org/pdf/2509.13905", "abs": "https://arxiv.org/abs/2509.13905", "authors": ["Domenico Meconi", "Simone Stirpe", "Federico Martelli", "Leonardo Lavalle", "Roberto Navigli"], "title": "Do Large Language Models Understand Word Senses?", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, to be published in EMNLP2025", "summary": "Understanding the meaning of words in context is a fundamental capability for\nLarge Language Models (LLMs). Despite extensive evaluation efforts, the extent\nto which LLMs show evidence that they truly grasp word senses remains\nunderexplored. In this paper, we address this gap by evaluating both i) the\nWord Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,\ncomparing their performance to state-of-the-art systems specifically designed\nfor the task, and ii) the ability of two top-performing open- and closed-source\nLLMs to understand word senses in three generative settings: definition\ngeneration, free-form explanation, and example generation. Notably, we find\nthat, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve\nperformance on par with specialized WSD systems, while also demonstrating\ngreater robustness across domains and levels of difficulty. In the generation\ntasks, results reveal that LLMs can explain the meaning of words in context up\nto 98\\% accuracy, with the highest performance observed in the free-form\nexplanation task, which best aligns with their generative capabilities.", "AI": {"tldr": "\u8bc4\u4f30\u6307\u4ee4\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u4e49\u6d88\u6b67\u80fd\u529b\u53ca\u5728\u4e09\u79cd\u751f\u6210\u573a\u666f\u4e0b\u7406\u89e3\u8bcd\u4e49\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u9886\u5148\u6a21\u578b\u5728\u8bcd\u4e49\u6d88\u6b67\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u4e13\u4e1a\u7cfb\u7edf\u76f8\u5f53\uff0c\u751f\u6210\u4efb\u52a1\u51c6\u786e\u7387\u9ad8\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u6b63\u638c\u63e1\u8bcd\u4e49\u7684\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8bc4\u4f30\u5176\u8bcd\u4e49\u7406\u89e3\u80fd\u529b\u3002", "method": "\u8bc4\u4f30\u6307\u4ee4\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u4e49\u6d88\u6b67\u80fd\u529b\u5e76\u4e0e\u4e13\u4e1a\u7cfb\u7edf\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u4e24\u4e2a\u9876\u5c16\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u79cd\u751f\u6210\u573a\u666f\u4e0b\u7406\u89e3\u8bcd\u4e49\u7684\u80fd\u529b\u3002", "result": "\u5728\u8bcd\u4e49\u6d88\u6b67\u4efb\u52a1\u4e2d\uff0cGPT - 4o\u548cDeepSeek - V3\u7b49\u9886\u5148\u6a21\u578b\u8868\u73b0\u4e0e\u4e13\u4e1a\u7cfb\u7edf\u76f8\u5f53\u4e14\u66f4\u5177\u9c81\u68d2\u6027\uff1b\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u8bcd\u4e49\u7684\u51c6\u786e\u7387\u8fbe98%\uff0c\u81ea\u7531\u5f62\u5f0f\u89e3\u91ca\u4efb\u52a1\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bcd\u4e49\u6d88\u6b67\u548c\u8bcd\u4e49\u7406\u89e3\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2509.13926", "pdf": "https://arxiv.org/pdf/2509.13926", "abs": "https://arxiv.org/abs/2509.13926", "authors": ["Huilin Yin", "Yiming Kan", "Daniel Watzenig"], "title": "MAP: End-to-End Autonomous Driving with Map-Assisted Planning", "categories": ["cs.RO", "cs.AI", "cs.CV", "I.2.9; I.2.10"], "comment": "8 pages, 2 figures, accepted by ICCVW Author list updated to match\n  the camera-ready version, in compliance with conference policy", "summary": "In recent years, end-to-end autonomous driving has attracted increasing\nattention for its ability to jointly model perception, prediction, and planning\nwithin a unified framework. However, most existing approaches underutilize the\nonline mapping module, leaving its potential to enhance trajectory planning\nlargely untapped. This paper proposes MAP (Map-Assisted Planning), a novel\nmap-assisted end-to-end trajectory planning framework. MAP explicitly\nintegrates segmentation-based map features and the current ego status through a\nPlan-enhancing Online Mapping module, an Ego-status-guided Planning module, and\na Weight Adapter based on current ego status. Experiments conducted on the\nDAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%\nreduction in L2 displacement error, a 56.2% reduction in off-road rate, and a\n44.5% improvement in overall score compared to the UniV2X baseline, even\nwithout post-processing. Furthermore, it achieves top ranking in Track 2 of the\nEnd-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS\nWorkshop @CVPR2025, outperforming the second-best model by 39.5% in terms of\noverall score. These results highlight the effectiveness of explicitly\nleveraging semantic map features in planning and suggest new directions for\nimproving structure design in end-to-end autonomous driving systems. Our code\nis available at https://gitee.com/kymkym/map.git", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMAP\u6846\u67b6\u7528\u4e8e\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u89c4\u5212\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u679c\u826f\u597d\uff0c\u4e3a\u7cfb\u7edf\u7ed3\u6784\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u5728\u7ebf\u5730\u56fe\u6a21\u5757\u63d0\u5347\u8f68\u8ff9\u89c4\u5212\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faMAP\u6846\u67b6\uff0c\u901a\u8fc7Plan - enhancing Online Mapping\u6a21\u5757\u3001Ego - status - guided Planning\u6a21\u5757\u548c\u57fa\u4e8e\u5f53\u524d\u81ea\u6211\u72b6\u6001\u7684Weight Adapter\uff0c\u660e\u786e\u6574\u5408\u57fa\u4e8e\u5206\u5272\u7684\u5730\u56fe\u7279\u5f81\u548c\u5f53\u524d\u81ea\u6211\u72b6\u6001\u3002", "result": "\u5728DAIR - V2X - seq - SPD\u6570\u636e\u96c6\u4e0a\uff0cL2\u4f4d\u79fb\u8bef\u5dee\u964d\u4f4e16.6%\uff0c\u8d8a\u91ce\u7387\u964d\u4f4e56.2%\uff0c\u603b\u4f53\u5f97\u5206\u63d0\u9ad844.5%\uff1b\u5728MEIS Workshop @CVPR2025\u6311\u6218\u8d5bTrack 2\u4e2d\u6392\u540d\u7b2c\u4e00\uff0c\u603b\u4f53\u5f97\u5206\u6bd4\u7b2c\u4e8c\u597d\u7684\u6a21\u578b\u9ad839.5%\u3002", "conclusion": "\u660e\u786e\u5229\u7528\u8bed\u4e49\u5730\u56fe\u7279\u5f81\u8fdb\u884c\u89c4\u5212\u662f\u6709\u6548\u7684\uff0c\u4e3a\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7ed3\u6784\u8bbe\u8ba1\u6539\u8fdb\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2509.13821", "pdf": "https://arxiv.org/pdf/2509.13821", "abs": "https://arxiv.org/abs/2509.13821", "authors": ["Frederik M\u00f8ller", "Gabriel Fern\u00e1ndez-Fern\u00e1ndez", "Thomas Schweigler", "Paulin de Schoulepnikoff", "J\u00f6rg Schmiedmayer", "Gorka Mu\u00f1oz-Gil"], "title": "Learning Minimal Representations of Many-Body Physics from Snapshots of a Quantum Simulator", "categories": ["quant-ph", "cs.LG"], "comment": "13 pages, 7 figures", "summary": "Analog quantum simulators provide access to many-body dynamics beyond the\nreach of classical computation. However, extracting physical insights from\nexperimental data is often hindered by measurement noise, limited observables,\nand incomplete knowledge of the underlying microscopic model. Here, we develop\na machine learning approach based on a variational autoencoder (VAE) to analyze\ninterference measurements of tunnel-coupled one-dimensional Bose gases, which\nrealize the sine-Gordon quantum field theory. Trained in an unsupervised\nmanner, the VAE learns a minimal latent representation that strongly correlates\nwith the equilibrium control parameter of the system. Applied to\nnon-equilibrium protocols, the latent space uncovers signatures of frozen-in\nsolitons following rapid cooling, and reveals anomalous post-quench dynamics\nnot captured by conventional correlation-based methods. These results\ndemonstrate that generative models can extract physically interpretable\nvariables directly from noisy and sparse experimental data, providing\ncomplementary probes of equilibrium and non-equilibrium physics in quantum\nsimulators. More broadly, our work highlights how machine learning can\nsupplement established field-theoretical techniques, paving the way for\nscalable, data-driven discovery in quantum many-body systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eVAE\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5206\u6790\u4e00\u7ef4\u73bb\u8272\u6c14\u4f53\u5e72\u6270\u6d4b\u91cf\u6570\u636e\uff0c\u80fd\u4ece\u566a\u58f0\u7a00\u758f\u6570\u636e\u63d0\u53d6\u7269\u7406\u53d8\u91cf\uff0c\u8865\u5145\u573a\u8bba\u6280\u672f\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u4ece\u6a21\u62df\u91cf\u5b50\u6a21\u62df\u5668\u5b9e\u9a8c\u6570\u636e\u63d0\u53d6\u7269\u7406\u89c1\u89e3\u65f6\u53d7\u6d4b\u91cf\u566a\u58f0\u3001\u6709\u9650\u53ef\u89c2\u6d4b\u91cf\u548c\u6a21\u578b\u77e5\u8bc6\u4e0d\u8db3\u7684\u963b\u788d\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u65e0\u76d1\u7763\u8bad\u7ec3\u3002", "result": "VAE\u5b66\u4e60\u5230\u4e0e\u7cfb\u7edf\u5e73\u8861\u63a7\u5236\u53c2\u6570\u5f3a\u76f8\u5173\u7684\u6f5c\u5728\u8868\u793a\uff0c\u63ed\u793a\u975e\u5e73\u8861\u534f\u8bae\u4e2d\u5b64\u5b50\u7279\u5f81\u548c\u53cd\u5e38\u6dec\u706b\u540e\u52a8\u529b\u5b66\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u53ef\u4ece\u566a\u58f0\u7a00\u758f\u5b9e\u9a8c\u6570\u636e\u63d0\u53d6\u53ef\u7269\u7406\u89e3\u91ca\u53d8\u91cf\uff0c\u673a\u5668\u5b66\u4e60\u80fd\u8865\u5145\u573a\u8bba\u6280\u672f\uff0c\u63a8\u52a8\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u3002"}}
{"id": "2509.13927", "pdf": "https://arxiv.org/pdf/2509.13927", "abs": "https://arxiv.org/abs/2509.13927", "authors": ["Kevin Wilkinghoff", "Zheng-Hua Tan"], "title": "DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": null, "summary": "Reasoning about spatial audio with large language models requires a spatial\naudio encoder as an acoustic front-end to obtain audio embeddings for further\nprocessing. Such an encoder needs to capture all information required to detect\nthe type of sound events, as well as the direction and distance of their\ncorresponding sources. Accomplishing this with a single audio encoder is\ndemanding as the information required for each of these tasks is mostly\nindependent of each other. As a result, the performance obtained with a single\nencoder is often worse than when using task-specific audio encoders. In this\nwork, we present DSpAST, a novel audio encoder based on SpatialAST that learns\ndisentangled representations of spatial audio while having only 0.2% additional\nparameters. Experiments on SpatialSoundQA with the spatial audio reasoning\nsystem BAT demonstrate that DSpAST significantly outperforms SpatialAST.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSpatialAST\u7684\u65b0\u578b\u97f3\u9891\u7f16\u7801\u5668DSpAST\uff0c\u53c2\u6570\u4ec5\u589e\u52a00.2%\uff0c\u5728SpatialSoundQA\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8eSpatialAST\u3002", "motivation": "\u5355\u97f3\u9891\u7f16\u7801\u5668\u5b8c\u6210\u7a7a\u95f4\u97f3\u9891\u63a8\u7406\u56f0\u96be\uff0c\u6027\u80fd\u4e0d\u5982\u7279\u5b9a\u4efb\u52a1\u7f16\u7801\u5668\uff0c\u9700\u66f4\u597d\u7684\u7f16\u7801\u5668\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eSpatialAST\u7684\u65b0\u578b\u97f3\u9891\u7f16\u7801\u5668DSpAST\u5b66\u4e60\u7a7a\u95f4\u97f3\u9891\u89e3\u8026\u8868\u793a\u3002", "result": "\u5728SpatialSoundQA\u4e0a\u7528\u7a7a\u95f4\u97f3\u9891\u63a8\u7406\u7cfb\u7edfBAT\u5b9e\u9a8c\uff0cDSpAST\u663e\u8457\u4f18\u4e8eSpatialAST\u3002", "conclusion": "DSpAST\u5728\u7a7a\u95f4\u97f3\u9891\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u662f\u66f4\u4f18\u7684\u97f3\u9891\u7f16\u7801\u5668\u3002"}}
{"id": "2509.13846", "pdf": "https://arxiv.org/pdf/2509.13846", "abs": "https://arxiv.org/abs/2509.13846", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "MICCAI 2025: 1st Place in Transformer track and 2nd Place in\n  Convolution track of SSL3D-OpenMind challenge", "summary": "Many recent approaches in representation learning implicitly assume that\nuncorrelated views of a data point are sufficient to learn meaningful\nrepresentations for various downstream tasks. In this work, we challenge this\nassumption and demonstrate that meaningful structure in the latent space does\nnot emerge naturally. Instead, it must be explicitly induced. We propose a\nmethod that aligns representations from different views of the data to align\ncomplementary information without inducing false positives. Our experiments\nshow that our proposed self-supervised learning method, Consistent View\nAlignment, improves performance for downstream tasks, highlighting the critical\nrole of structured view alignment in learning effective representations. Our\nmethod achieved first and second place in the MICCAI 2025 SSL3D challenge when\nusing a Primus vision transformer and ResEnc convolutional neural network,\nrespectively. The code and pretrained model weights are released at\nhttps://github.com/Tenbatsu24/LatentCampus.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u8868\u5f81\u5b66\u4e60\u4e2d\u65e0\u76f8\u5173\u89c6\u56fe\u8db3\u4ee5\u5b66\u4e60\u6709\u610f\u4e49\u8868\u5f81\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u4e00\u81f4\u89c6\u56fe\u5bf9\u9f50\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff0c\u5728\u7ade\u8d5b\u4e2d\u53d6\u5f97\u597d\u6210\u7ee9\u3002", "motivation": "\u6311\u6218\u8868\u5f81\u5b66\u4e60\u4e2d\u65e0\u76f8\u5173\u89c6\u56fe\u8db3\u4ee5\u5b66\u4e60\u6709\u610f\u4e49\u8868\u5f81\u7684\u5047\u8bbe\uff0c\u6307\u51fa\u6f5c\u5728\u7a7a\u95f4\u7684\u6709\u610f\u4e49\u7ed3\u6784\u9700\u660e\u786e\u8bf1\u5bfc\u3002", "method": "\u63d0\u51fa\u4e00\u81f4\u89c6\u56fe\u5bf9\u9f50\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5bf9\u9f50\u6570\u636e\u4e0d\u540c\u89c6\u56fe\u7684\u8868\u5f81\u4ee5\u6574\u5408\u4e92\u8865\u4fe1\u606f\u4e14\u907f\u514d\u8bef\u62a5\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff0c\u4f7f\u7528Primus\u89c6\u89c9\u53d8\u538b\u5668\u548cResEnc\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u65f6\u5206\u522b\u5728MICCAI 2025 SSL3D\u6311\u6218\u4e2d\u83b7\u7b2c\u4e00\u548c\u7b2c\u4e8c\u540d\u3002", "conclusion": "\u7ed3\u6784\u5316\u89c6\u56fe\u5bf9\u9f50\u5728\u5b66\u4e60\u6709\u6548\u8868\u5f81\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2509.13848", "pdf": "https://arxiv.org/pdf/2509.13848", "abs": "https://arxiv.org/abs/2509.13848", "authors": ["Jiayi Pan", "Jiaming Xu", "Yongkang Zhou", "Guohao Dai"], "title": "SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Feature caching has recently emerged as a promising method for diffusion\nmodel acceleration. It effectively alleviates the inefficiency problem caused\nby high computational requirements by caching similar features in the inference\nprocess of the diffusion model. In this paper, we analyze existing feature\ncaching methods from the perspective of information utilization, and point out\nthat relying solely on historical information will lead to constrained accuracy\nand speed performance. And we propose a novel paradigm that introduces future\ninformation via self-speculation based on the information similarity at the\nsame time step across different iteration times. Based on this paradigm, we\npresent \\textit{SpecDiff}, a training-free multi-level feature caching strategy\nincluding a cached feature selection algorithm and a multi-level feature\nclassification algorithm. (1) Feature selection algorithm based on\nself-speculative information. \\textit{SpecDiff} determines a dynamic importance\nscore for each token based on self-speculative information and historical\ninformation, and performs cached feature selection through the importance\nscore. (2) Multi-level feature classification algorithm based on feature\nimportance scores. \\textit{SpecDiff} classifies tokens by leveraging the\ndifferences in feature importance scores and introduces a multi-level feature\ncalculation strategy. Extensive experiments show that \\textit{SpecDiff}\nachieves average 2.80 \\times, 2.74 \\times , and 3.17\\times speedup with\nnegligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow\non NVIDIA A800-80GB GPU. By merging speculative and historical information,\n\\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing\nthe Pareto frontier of speedup and accuracy in the efficient diffusion model\ninference.", "AI": {"tldr": "\u672c\u6587\u4ece\u4fe1\u606f\u5229\u7528\u89d2\u5ea6\u5206\u6790\u73b0\u6709\u7279\u5f81\u7f13\u5b58\u65b9\u6cd5\uff0c\u63d0\u51fa\u65b0\u8303\u5f0f\u5e76\u6784\u5efaSpecDiff\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u5728\u901f\u5ea6\u63d0\u5347\u540c\u65f6\u4fdd\u8bc1\u8d28\u91cf\uff0c\u7a81\u7834\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u6743\u8861\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u7f13\u5b58\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5386\u53f2\u4fe1\u606f\u4f1a\u5bfc\u81f4\u7cbe\u5ea6\u548c\u901f\u5ea6\u6027\u80fd\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u901a\u8fc7\u81ea\u63a8\u6d4b\u5f15\u5165\u672a\u6765\u4fe1\u606f\u7684\u65b0\u8303\u5f0f\uff0c\u6784\u5efa\u8bad\u7ec3-free\u7684SpecDiff\u7b56\u7565\uff0c\u5305\u62ec\u57fa\u4e8e\u81ea\u63a8\u6d4b\u4fe1\u606f\u7684\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\u548c\u57fa\u4e8e\u7279\u5f81\u91cd\u8981\u6027\u5206\u6570\u7684\u591a\u7ea7\u7279\u5f81\u5206\u7c7b\u7b97\u6cd5\u3002", "result": "\u5728NVIDIA A800 - 80GB GPU\u4e0a\uff0c\u4e0eRFlow\u76f8\u6bd4\uff0cSpecDiff\u5728Stable Diffusion 3\u30013.5\u548cFLUX\u4e2d\u5e73\u5747\u5206\u522b\u5b9e\u73b02.80\u00d7\u30012.74\u00d7\u548c3.17\u00d7\u7684\u52a0\u901f\uff0c\u4e14\u8d28\u91cf\u635f\u5931\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u901a\u8fc7\u878d\u5408\u63a8\u6d4b\u548c\u5386\u53f2\u4fe1\u606f\uff0cSpecDiff\u7a81\u7834\u4e86\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u6743\u8861\u7684\u74f6\u9888\uff0c\u63a8\u52a8\u4e86\u9ad8\u6548\u6269\u6563\u6a21\u578b\u63a8\u7406\u4e2d\u901f\u5ea6\u548c\u7cbe\u5ea6\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002"}}
{"id": "2509.13863", "pdf": "https://arxiv.org/pdf/2509.13863", "abs": "https://arxiv.org/abs/2509.13863", "authors": ["Chu Chen", "Ander Biguri", "Jean-Michel Morel", "Raymond H. Chan", "Carola-Bibiane Sch\u00f6nlieb", "Jizhou Li"], "title": "LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "X-ray Computed Laminography (CL) is essential for non-destructive inspection\nof plate-like structures in applications such as microchips and composite\nbattery materials, where traditional computed tomography (CT) struggles due to\ngeometric constraints. However, reconstructing high-quality volumes from\nlaminographic projections remains challenging, particularly under highly\nsparse-view acquisition conditions. In this paper, we propose a reconstruction\nalgorithm, namely LamiGauss, that combines Gaussian Splatting radiative\nrasterization with a dedicated detector-to-world transformation model\nincorporating the laminographic tilt angle. LamiGauss leverages an\ninitialization strategy that explicitly filters out common laminographic\nartifacts from the preliminary reconstruction, preventing redundant Gaussians\nfrom being allocated to false structures and thereby concentrating model\ncapacity on representing the genuine object. Our approach effectively optimizes\ndirectly from sparse projections, enabling accurate and efficient\nreconstruction with limited data. Extensive experiments on both synthetic and\nreal datasets demonstrate the effectiveness and superiority of the proposed\nmethod over existing techniques. LamiGauss uses only 3$\\%$ of full views to\nachieve superior performance over the iterative method optimized on a full\ndataset.", "AI": {"tldr": "\u63d0\u51faLamiGauss\u91cd\u5efa\u7b97\u6cd5\uff0c\u7ed3\u5408\u9ad8\u65af\u62fc\u63a5\u8f90\u5c04\u5149\u6805\u5316\u548c\u63a2\u6d4b\u5668\u5230\u4e16\u754c\u7684\u8f6c\u6362\u6a21\u578b\uff0c\u80fd\u4ece\u7a00\u758f\u6295\u5f71\u4e2d\u51c6\u786e\u9ad8\u6548\u91cd\u5efa\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "X\u5c04\u7ebf\u8ba1\u7b97\u5c42\u6444\u5f71\uff08CL\uff09\u5728\u65e0\u635f\u68c0\u6d4b\u4e2d\u91cd\u8981\uff0c\u4f46\u4ece\u5c42\u6444\u5f71\u6295\u5f71\u91cd\u5efa\u9ad8\u8d28\u91cf\u4f53\u79ef\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7a00\u758f\u89c6\u56fe\u91c7\u96c6\u6761\u4ef6\u4e0b\u4ecd\u5177\u6311\u6218\u3002", "method": "\u63d0\u51faLamiGauss\u7b97\u6cd5\uff0c\u7ed3\u5408\u9ad8\u65af\u62fc\u63a5\u8f90\u5c04\u5149\u6805\u5316\u4e0e\u542b\u5c42\u6444\u5f71\u503e\u659c\u89d2\u7684\u63a2\u6d4b\u5668\u5230\u4e16\u754c\u8f6c\u6362\u6a21\u578b\uff0c\u5229\u7528\u521d\u59cb\u5316\u7b56\u7565\u8fc7\u6ee4\u5e38\u89c1\u5c42\u6444\u5f71\u4f2a\u5f71\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u4ec5\u75283%\u7684\u5168\u89c6\u56fe\u5c31\u6bd4\u5728\u5b8c\u6574\u6570\u636e\u96c6\u4e0a\u4f18\u5316\u7684\u8fed\u4ee3\u65b9\u6cd5\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "LamiGauss\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u4ece\u7a00\u758f\u5c42\u6444\u5f71\u6295\u5f71\u91cd\u5efa\u9ad8\u8d28\u91cf\u4f53\u79ef\u7684\u95ee\u9898\uff0c\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2509.13987", "pdf": "https://arxiv.org/pdf/2509.13987", "abs": "https://arxiv.org/abs/2509.13987", "authors": ["Ozer Ozturk", "Busra Buyuktanir", "Gozde Karatas Baydogmus", "Kazim Yildiz"], "title": "Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Machine learning models used for distributed architectures consisting of\nservers and clients require large amounts of data to achieve high accuracy.\nData obtained from clients are collected on a central server for model\ntraining. However, storing data on a central server raises concerns about\nsecurity and privacy. To address this issue, a federated learning architecture\nhas been proposed. In federated learning, each client trains a local model\nusing its own data. The trained models are periodically transmitted to the\ncentral server. The server then combines the received models using federated\naggregation algorithms to obtain a global model. This global model is\ndistributed back to the clients, and the process continues in a cyclical\nmanner. Although preventing data from leaving the clients enhances security,\ncertain concerns still remain. Attackers can perform inference attacks on the\nobtained models to approximate the training dataset, potentially causing data\nleakage. In this study, differential privacy was applied to address the\naforementioned security vulnerability, and a performance analysis was\nconducted. The Data-Unaware Classification Based on Association (duCBA)\nalgorithm was used as the federated aggregation method. Differential privacy\nwas implemented on the data using the Randomized Response technique, and the\ntrade-off between security and performance was examined under different epsilon\nvalues. As the epsilon value decreased, the model accuracy declined, and class\nprediction imbalances were observed. This indicates that higher levels of\nprivacy do not always lead to practical outcomes and that the balance between\nsecurity and performance must be carefully considered.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b58\u5728\u5b89\u5168\u9690\u79c1\u95ee\u9898\uff0c\u63d0\u51fa\u8054\u90a6\u5b66\u4e60\u67b6\u6784\uff0c\u4f46\u4ecd\u6709\u5b89\u5168\u6f0f\u6d1e\u3002\u91c7\u7528\u5dee\u5206\u9690\u79c1\u548cduCBA\u7b97\u6cd5\uff0c\u7814\u7a76\u53d1\u73b0\u9690\u79c1\u589e\u5f3a\u4f1a\u4f7f\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\uff0c\u9700\u5e73\u8861\u5b89\u5168\u4e0e\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5c06\u6570\u636e\u5b58\u50a8\u5728\u4e2d\u592e\u670d\u52a1\u5668\u5e26\u6765\u7684\u5b89\u5168\u548c\u9690\u79c1\u95ee\u9898\uff0c\u4ee5\u53ca\u8054\u90a6\u5b66\u4e60\u67b6\u6784\u5b58\u5728\u7684\u63a8\u7406\u653b\u51fb\u5bfc\u81f4\u6570\u636e\u6cc4\u9732\u95ee\u9898\u3002", "method": "\u5e94\u7528\u5dee\u5206\u9690\u79c1\uff0c\u4f7f\u7528duCBA\u7b97\u6cd5\u4f5c\u4e3a\u8054\u90a6\u805a\u5408\u65b9\u6cd5\uff0c\u7528\u968f\u673a\u54cd\u5e94\u6280\u672f\u5728\u6570\u636e\u4e0a\u5b9e\u73b0\u5dee\u5206\u9690\u79c1\uff0c\u5728\u4e0d\u540cepsilon\u503c\u4e0b\u7814\u7a76\u5b89\u5168\u4e0e\u6027\u80fd\u7684\u6743\u8861\u3002", "result": "\u968f\u7740epsilon\u503c\u964d\u4f4e\uff0c\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\uff0c\u51fa\u73b0\u7c7b\u9884\u6d4b\u4e0d\u5e73\u8861\u3002", "conclusion": "\u66f4\u9ad8\u7684\u9690\u79c1\u7ea7\u522b\u4e0d\u603b\u80fd\u5e26\u6765\u5b9e\u9645\u7ed3\u679c\uff0c\u5fc5\u987b\u4ed4\u7ec6\u8003\u8651\u5b89\u5168\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u5e73\u8861\u3002"}}
{"id": "2509.13878", "pdf": "https://arxiv.org/pdf/2509.13878", "abs": "https://arxiv.org/abs/2509.13878", "authors": ["Janne Laakkonen", "Ivan Kukanov", "Ville Hautam\u00e4ki"], "title": "Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "6 pages, 3 figures, 1 table", "summary": "Foundation models such as Wav2Vec2 excel at representation learning in speech\ntasks, including audio deepfake detection. However, after being fine-tuned on a\nfixed set of bonafide and spoofed audio clips, they often fail to generalize to\nnovel deepfake methods not represented in training. To address this, we propose\na mixture-of-LoRA-experts approach that integrates multiple low-rank adapters\n(LoRA) into the model's attention layers. A routing mechanism selectively\nactivates specialized experts, enhancing adaptability to evolving deepfake\nattacks. Experimental results show that our method outperforms standard\nfine-tuning in both in-domain and out-of-domain scenarios, reducing equal error\nrates relative to baseline models. Notably, our best MoE-LoRA model lowers the\naverage out-of-domain EER from 8.55\\% to 6.08\\%, demonstrating its\neffectiveness in achieving generalizable audio deepfake detection.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408LoRA\u4e13\u5bb6\u65b9\u6cd5\u7528\u4e8e\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u4e8e\u6807\u51c6\u5fae\u8c03\uff0c\u80fd\u6709\u6548\u5b9e\u73b0\u53ef\u6cdb\u5316\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u57fa\u7840\u6a21\u578b\u5728\u5fae\u8c03\u540e\u96be\u4ee5\u6cdb\u5316\u5230\u8bad\u7ec3\u96c6\u4e2d\u672a\u6db5\u76d6\u7684\u65b0\u578b\u6df1\u5ea6\u4f2a\u9020\u65b9\u6cd5\uff0c\u9700\u8981\u63d0\u5347\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u6df7\u5408LoRA\u4e13\u5bb6\u65b9\u6cd5\uff0c\u5c06\u591a\u4e2a\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\u96c6\u6210\u5230\u6a21\u578b\u7684\u6ce8\u610f\u529b\u5c42\uff0c\u5e76\u901a\u8fc7\u8def\u7531\u673a\u5236\u9009\u62e9\u6027\u6fc0\u6d3b\u4e13\u5bb6\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u57df\u5185\u548c\u57df\u5916\u573a\u666f\u5747\u4f18\u4e8e\u6807\u51c6\u5fae\u8c03\uff0c\u964d\u4f4e\u4e86\u76f8\u5bf9\u57fa\u7ebf\u6a21\u578b\u7684\u7b49\u9519\u8bef\u7387\uff0c\u6700\u4f73\u6a21\u578b\u5c06\u5e73\u5747\u57df\u5916EER\u4ece8.55%\u964d\u81f36.08%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0\u53ef\u6cdb\u5316\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u3002"}}
{"id": "2509.13990", "pdf": "https://arxiv.org/pdf/2509.13990", "abs": "https://arxiv.org/abs/2509.13990", "authors": ["Colin Hong", "Xu Guo", "Anand Chaanan Singh", "Esha Choukse", "Dmitrii Ustiugov"], "title": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": "Accepted by EMNLP 2025 (Oral), 9 pages", "summary": "Recently, Test-Time Scaling (TTS) has gained increasing attention for\nimproving LLM reasoning performance at test time without retraining the model.\nA notable TTS technique is Self-Consistency (SC), which generates multiple\nreasoning chains in parallel and selects the final answer via majority voting.\nWhile effective, the order-of-magnitude computational overhead limits its broad\ndeployment. Prior attempts to accelerate SC mainly rely on model-based\nconfidence scores or heuristics with limited empirical support. For the first\ntime, we theoretically and empirically analyze the inefficiencies of SC and\nreveal actionable opportunities for improvement. Building on these insights, we\npropose Slim-SC, a step-wise pruning strategy that identifies and removes\nredundant chains using inter-chain similarity at the thought level. Experiments\non three STEM reasoning datasets and two recent LLM architectures show that\nSlim-SC reduces inference latency and KVC usage by up to 45% and 26%,\nrespectively, with R1-Distill, while maintaining or improving accuracy, thus\noffering a simple yet efficient TTS alternative for SC.", "AI": {"tldr": "\u6587\u7ae0\u5206\u6790Self - Consistency (SC)\u7684\u4f4e\u6548\u6027\uff0c\u63d0\u51faSlim - SC\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u53ef\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u548cKVC\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709Self - Consistency (SC)\u6280\u672f\u867d\u80fd\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u5148\u524d\u52a0\u901f\u65b9\u6cd5\u7f3a\u4e4f\u5b9e\u8bc1\u652f\u6301\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790SC\u7684\u4f4e\u6548\u6027\uff0c\u63d0\u51faSlim - SC\uff0c\u5229\u7528\u601d\u60f3\u5c42\u9762\u7684\u94fe\u95f4\u76f8\u4f3c\u5ea6\u9010\u6b65\u4fee\u526a\u5197\u4f59\u63a8\u7406\u94fe\u3002", "result": "\u5728\u4e09\u4e2aSTEM\u63a8\u7406\u6570\u636e\u96c6\u548c\u4e24\u4e2aLLM\u67b6\u6784\u4e0a\u5b9e\u9a8c\uff0cSlim - SC\u7ed3\u5408R1 - Distill\u53ef\u5c06\u63a8\u7406\u5ef6\u8fdf\u548cKVC\u4f7f\u7528\u5206\u522b\u6700\u591a\u964d\u4f4e45%\u548c26%\uff0c\u5e76\u4fdd\u6301\u6216\u63d0\u5347\u51c6\u786e\u7387\u3002", "conclusion": "Slim - SC\u662f\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684TTS\u66ff\u4ee3\u65b9\u6848\uff0c\u53ef\u89e3\u51b3SC\u7684\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\u3002"}}
{"id": "2509.13934", "pdf": "https://arxiv.org/pdf/2509.13934", "abs": "https://arxiv.org/abs/2509.13934", "authors": ["Zhixion Chen", "Jiangzhou Wang", "and Hyundong Shin", "Arumugam Nallanathan"], "title": "Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "14pages, 8 figures", "summary": "The deployment of unmanned aerial vehicles (UAVs) for reliable and\nenergy-efficient data collection from spatially distributed devices holds great\npromise in supporting diverse Internet of Things (IoT) applications.\nNevertheless, the limited endurance and communication range of UAVs necessitate\nintelligent trajectory planning. While reinforcement learning (RL) has been\nextensively explored for UAV trajectory optimization, its interactive nature\nentails high costs and risks in real-world environments. Offline RL mitigates\nthese issues but remains susceptible to unstable training and heavily rely on\nexpert-quality datasets. To address these challenges, we formulate a joint UAV\ntrajectory planning and resource allocation problem to maximize energy\nefficiency of data collection. The resource allocation subproblem is first\ntransformed into an equivalent linear programming formulation and solved\noptimally with polynomial-time complexity. Then, we propose a large language\nmodel (LLM)-empowered critic-regularized decision transformer (DT) framework,\ntermed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we\nincorporate critic networks to regularize the DT model training, thereby\nintegrating the sequence modeling capabilities of DT with critic-based value\nguidance to enable learning effective policies from suboptimal datasets.\nFurthermore, to mitigate the data-hungry nature of transformer models, we\nemploy a pre-trained LLM as the transformer backbone of the DT model and adopt\na parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid\nadaptation to UAV control tasks with small-scale dataset and low computational\noverhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark\nonline and offline RL methods, achieving up to 36.7\\% higher energy efficiency\nthan the current state-of-the-art DT approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLLM - CRDT\u6846\u67b6\u89e3\u51b3\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u63d0\u5347\u6570\u636e\u6536\u96c6\u80fd\u6548\uff0c\u6a21\u62df\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u65e0\u4eba\u673a\u7eed\u822a\u548c\u901a\u4fe1\u8303\u56f4\u6709\u9650\u9700\u667a\u80fd\u8f68\u8ff9\u89c4\u5212\uff0c\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u6709\u6210\u672c\u548c\u98ce\u9669\uff0c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u4e14\u4f9d\u8d56\u4f18\u8d28\u6570\u636e\u96c6\u3002", "method": "\u5c06\u8d44\u6e90\u5206\u914d\u5b50\u95ee\u9898\u8f6c\u5316\u4e3a\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\uff0c\u63d0\u51faLLM - CRDT\u6846\u67b6\uff0c\u6574\u5408\u6279\u8bc4\u7f51\u7edc\u6b63\u5219\u5316\u8bad\u7ec3\uff0c\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u9aa8\u5e72\u5e76\u91c7\u7528LoRA\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u5e7f\u6cdb\u6a21\u62df\u8868\u660e\uff0cLLM - CRDT\u4f18\u4e8e\u57fa\u51c6\u5728\u7ebf\u548c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6bd4\u73b0\u6709DT\u65b9\u6cd5\u80fd\u6548\u6700\u9ad8\u63d0\u534736.7%\u3002", "conclusion": "LLM - CRDT\u80fd\u6709\u6548\u89e3\u51b3\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u63d0\u5347\u6570\u636e\u6536\u96c6\u80fd\u6548\u3002"}}
{"id": "2509.14001", "pdf": "https://arxiv.org/pdf/2509.14001", "abs": "https://arxiv.org/abs/2509.14001", "authors": ["Elena Camuffo", "Francesco Barbato", "Mete Ozay", "Simone Milani", "Umberto Michieli"], "title": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),\na knowledge distillation approach that transfers region-level multimodal\nsemantics from a large vision-language teacher (e.g., LLaVa) into a lightweight\nvision-only object detector student (e.g., YOLO). A translation module maps\nstudent features into a joint space, where the training of the student and\ntranslator is guided by a dual-objective loss that enforces both local\nalignment and global relational consistency. Unlike prior approaches focused on\ndense or global alignment, MOCHA operates at the object level, enabling\nefficient transfer of semantics without modifying the teacher or requiring\ntextual input at inference. We validate our method across four personalized\ndetection benchmarks under few-shot regimes. Results show consistent gains over\nbaselines, with a +10.1 average score improvement. Despite its compact\narchitecture, MOCHA reaches performance on par with larger multimodal models,\nproving its suitability for real-world deployment.", "AI": {"tldr": "\u4ecb\u7ecdMOCHA\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u5c06\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u8f6c\u79fb\u5230\u8f7b\u91cf\u7ea7\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5728\u5c11\u6837\u672c\u68c0\u6d4b\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u5c06\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u533a\u57df\u7ea7\u591a\u6a21\u6001\u8bed\u4e49\u8f6c\u79fb\u5230\u8f7b\u91cf\u7ea7\u89c6\u89c9\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u4e14\u907f\u514d\u4fee\u6539\u6559\u5e08\u6a21\u578b\u548c\u63a8\u7406\u65f6\u6587\u672c\u8f93\u5165\u3002", "method": "\u5f15\u5165MOCHA\u65b9\u6cd5\uff0c\u7528\u7ffb\u8bd1\u6a21\u5757\u5c06\u5b66\u751f\u7279\u5f81\u6620\u5c04\u5230\u8054\u5408\u7a7a\u95f4\uff0c\u901a\u8fc7\u53cc\u76ee\u6807\u635f\u5931\u6307\u5bfc\u5b66\u751f\u548c\u7ffb\u8bd1\u5668\u8bad\u7ec3\u3002", "result": "\u5728\u56db\u4e2a\u5c11\u6837\u672c\u4e2a\u6027\u5316\u68c0\u6d4b\u57fa\u51c6\u4e0a\u9a8c\u8bc1\uff0c\u5e73\u5747\u5f97\u5206\u6bd4\u57fa\u7ebf\u63d0\u9ad810.1\uff0c\u6027\u80fd\u4e0e\u66f4\u5927\u7684\u591a\u6a21\u6001\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "MOCHA\u67b6\u6784\u7d27\u51d1\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2509.14003", "pdf": "https://arxiv.org/pdf/2509.14003", "abs": "https://arxiv.org/abs/2509.14003", "authors": ["Liting Gao", "Yi Yuan", "Yaru Chen", "Yuelan Cheng", "Zhenbo Li", "Juan Wen", "Shubin Zhang", "Wenwu Wang"], "title": "RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Diffusion models have shown remarkable progress in text-to-audio generation.\nHowever, text-guided audio editing remains in its early stages. This task\nfocuses on modifying the target content within an audio signal while preserving\nthe rest, thus demanding precise localization and faithful editing according to\nthe text prompt. Existing training-based and zero-shot methods that rely on\nfull-caption or costly optimization often struggle with complex editing or lack\npracticality. In this work, we propose a novel end-to-end efficient rectified\nflow matching-based diffusion framework for audio editing, and construct a\ndataset featuring overlapping multi-event audio to support training and\nbenchmarking in complex scenarios. Experiments show that our model achieves\nfaithful semantic alignment without requiring auxiliary captions or masks,\nwhile maintaining competitive editing quality across metrics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6574\u6d41\u6d41\u5339\u914d\u7684\u6269\u6563\u6846\u67b6\u7528\u4e8e\u97f3\u9891\u7f16\u8f91\uff0c\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u6548\u679c\u597d\u3002", "motivation": "\u6587\u672c\u5f15\u5bfc\u7684\u97f3\u9891\u7f16\u8f91\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u7f16\u8f91\u4e0a\u6709\u56f0\u96be\u6216\u7f3a\u4e4f\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u9ad8\u6548\u7684\u57fa\u4e8e\u6574\u6d41\u6d41\u5339\u914d\u7684\u6269\u6563\u6846\u67b6\u8fdb\u884c\u97f3\u9891\u7f16\u8f91\uff0c\u6784\u5efa\u542b\u91cd\u53e0\u591a\u4e8b\u4ef6\u97f3\u9891\u7684\u6570\u636e\u96c6\u652f\u6301\u8bad\u7ec3\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u65e0\u9700\u8f85\u52a9\u5b57\u5e55\u6216\u63a9\u7801\u5c31\u80fd\u5b9e\u73b0\u5fe0\u5b9e\u7684\u8bed\u4e49\u5bf9\u9f50\uff0c\u5404\u9879\u6307\u6807\u7f16\u8f91\u8d28\u91cf\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u6587\u672c\u5f15\u5bfc\u97f3\u9891\u7f16\u8f91\u4efb\u52a1\u4e2d\u5177\u6709\u6709\u6548\u6027\u548c\u4f18\u52bf\u3002"}}
{"id": "2509.13975", "pdf": "https://arxiv.org/pdf/2509.13975", "abs": "https://arxiv.org/abs/2509.13975", "authors": ["Ilker Bayram"], "title": "Classification Filtering", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "We consider a streaming signal in which each sample is linked to a latent\nclass. We assume that multiple classifiers are available, each providing class\nprobabilities with varying degrees of accuracy. These classifiers are employed\nfollowing a straightforward and fixed policy. In this setting, we consider the\nproblem of fusing the output of the classifiers while incorporating the\ntemporal aspect to improve classification accuracy. We propose a state-space\nmodel and develop a filter tailored for realtime execution. We demonstrate the\neffectiveness of the proposed filter in an activity classification application\nbased on inertial measurement unit (IMU) data from a wearable device.", "AI": {"tldr": "\u8003\u8651\u542b\u6f5c\u5728\u7c7b\u522b\u7684\u6d41\u4fe1\u53f7\uff0c\u591a\u5206\u7c7b\u5668\u8f93\u51fa\u878d\u5408\u95ee\u9898\uff0c\u63d0\u51fa\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u5b9e\u65f6\u6ee4\u6ce2\u5668\uff0c\u5728\u6d3b\u52a8\u5206\u7c7b\u5e94\u7528\u9a8c\u8bc1\u6548\u679c\u3002", "motivation": "\u878d\u5408\u591a\u5206\u7c7b\u5668\u8f93\u51fa\u5e76\u7ed3\u5408\u65f6\u95f4\u56e0\u7d20\u4ee5\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5f00\u53d1\u9002\u7528\u4e8e\u5b9e\u65f6\u6267\u884c\u7684\u6ee4\u6ce2\u5668\u3002", "result": "\u5728\u57fa\u4e8e\u53ef\u7a7f\u6234\u8bbe\u5907IMU\u6570\u636e\u7684\u6d3b\u52a8\u5206\u7c7b\u5e94\u7528\u4e2d\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u6ee4\u6ce2\u5668\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u5b9e\u65f6\u6ee4\u6ce2\u5668\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u5206\u7c7b\u5668\u8f93\u51fa\u878d\u5408\u95ee\u9898\uff0c\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\u3002"}}
{"id": "2509.14008", "pdf": "https://arxiv.org/pdf/2509.14008", "abs": "https://arxiv.org/abs/2509.14008", "authors": ["Hasan Abed Al Kader Hammoud", "Mohammad Zbeeb", "Bernard Ghanem"], "title": "Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Technical Report", "summary": "We present Hala, a family of Arabic-centric instruction and translation\nmodels built with our translate-and-tune pipeline. We first compress a strong\nAR$\\leftrightarrow$EN teacher to FP8 (yielding $\\sim$2$\\times$ higher\nthroughput with no quality loss) and use it to create high-fidelity bilingual\nsupervision. A lightweight language model LFM2-1.2B is then fine-tuned on this\ndata and used to translate high-quality English instruction sets into Arabic,\nproducing a million-scale corpus tailored to instruction following. We train\nHala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to\nbalance Arabic specialization with base-model strengths. On Arabic-centric\nbenchmarks, Hala achieves state-of-the-art results within both the \"nano\"\n($\\leq$2B) and \"small\" (7-9B) categories, outperforming their bases. We release\nmodels, data, evaluation, and recipes to accelerate research in Arabic NLP.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4ee5\u963f\u62c9\u4f2f\u8bed\u4e3a\u4e2d\u5fc3\u7684\u6307\u4ee4\u548c\u7ffb\u8bd1\u6a21\u578bHala\uff0c\u901a\u8fc7\u7279\u5b9a\u6d41\u7a0b\u6784\u5efa\uff0c\u5728\u963f\u62c9\u4f2f\u8bed\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u6210\u679c\u5e76\u5f00\u6e90\u76f8\u5173\u8d44\u6e90\u3002", "motivation": "\u63a8\u52a8\u963f\u62c9\u4f2f\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\uff0c\u6784\u5efa\u4ee5\u963f\u62c9\u4f2f\u8bed\u4e3a\u4e2d\u5fc3\u7684\u6307\u4ee4\u548c\u7ffb\u8bd1\u6a21\u578b\u3002", "method": "\u4f7f\u7528translate - and - tune\u7ba1\u9053\uff0c\u5c06\u5f3aAR\u2194EN\u6559\u5e08\u6a21\u578b\u538b\u7f29\u5230FP8\u521b\u5efa\u53cc\u8bed\u76d1\u7763\uff0c\u5fae\u8c03\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578bLFM2 - 1.2B\u7ffb\u8bd1\u82f1\u8bed\u6307\u4ee4\u96c6\uff0c\u8bad\u7ec3\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u7684Hala\u6a21\u578b\u5e76\u5e94\u7528slerp\u5408\u5e76\u3002", "result": "Hala\u5728\u963f\u62c9\u4f2f\u8bed\u57fa\u51c6\u6d4b\u8bd5\u7684\u201cnano\u201d\uff08\u22642B\uff09\u548c\u201csmall\u201d\uff087 - 9B\uff09\u7c7b\u522b\u4e2d\u53d6\u5f97\u4e86SOTA\u6210\u679c\uff0c\u8d85\u8d8a\u4e86\u5176\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "\u53d1\u5e03\u6a21\u578b\u3001\u6570\u636e\u3001\u8bc4\u4f30\u548c\u914d\u65b9\u4ee5\u52a0\u901f\u963f\u62c9\u4f2f\u8bedNLP\u7814\u7a76\u3002"}}
{"id": "2509.13980", "pdf": "https://arxiv.org/pdf/2509.13980", "abs": "https://arxiv.org/abs/2509.13980", "authors": ["Sami Ul Haq", "Chinonso Cynthia Osuji", "Sheila Castilho", "Brian Davis"], "title": "Long-context Reference-based MT Quality Estimation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In this paper, we present our submission to the Tenth Conference on Machine\nTranslation (WMT25) Shared Task on Automated Translation Quality Evaluation.\n  Our systems are built upon the COMET framework and trained to predict\nsegment-level Error Span Annotation (ESA) scores using augmented long-context\ndata.\n  To construct long-context training data, we concatenate in-domain,\nhuman-annotated sentences and compute a weighted average of their scores.\n  We integrate multiple human judgment datasets (MQM, SQM, and DA) by\nnormalising their scales and train multilingual regression models to predict\nquality scores from the source, hypothesis, and reference translations.\n  Experimental results show that incorporating long-context information\nimproves correlations with human judgments compared to models trained only on\nshort segments.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdWMT25\u81ea\u52a8\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u5171\u4eab\u4efb\u52a1\u7684\u63d0\u4ea4\u7cfb\u7edf\uff0c\u57fa\u4e8eCOMET\u6846\u67b6\uff0c\u7528\u589e\u5f3a\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u8bad\u7ec3\u9884\u6d4bESA\u5206\u6570\uff0c\u5b9e\u9a8c\u8868\u660e\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u63d0\u5347\u4e0e\u4eba\u5de5\u5224\u65ad\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u53c2\u4e0eWMT25\u81ea\u52a8\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u5171\u4eab\u4efb\u52a1\uff0c\u63d0\u9ad8\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u6548\u679c\u3002", "method": "\u57fa\u4e8eCOMET\u6846\u67b6\uff0c\u7528\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u8bad\u7ec3\u9884\u6d4bESA\u5206\u6570\uff0c\u6784\u5efa\u8bad\u7ec3\u6570\u636e\u65f6\u62fc\u63a5\u53e5\u5e76\u8ba1\u7b97\u5206\u6570\u52a0\u6743\u5e73\u5747\uff0c\u6574\u5408\u591a\u4e2a\u4eba\u5de5\u5224\u65ad\u6570\u636e\u96c6\u5e76\u5f52\u4e00\u5316\u8bad\u7ec3\u591a\u8bed\u8a00\u56de\u5f52\u6a21\u578b\u3002", "result": "\u5305\u542b\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u6a21\u578b\u4e0e\u4eba\u5de5\u5224\u65ad\u7684\u76f8\u5173\u6027\u6bd4\u4ec5\u5728\u77ed\u7247\u6bb5\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u66f4\u9ad8\u3002", "conclusion": "\u4f7f\u7528\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u80fd\u6709\u6548\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u6a21\u578b\u4e0e\u4eba\u5de5\u5224\u65ad\u7684\u76f8\u5173\u6027\u3002"}}
{"id": "2509.14031", "pdf": "https://arxiv.org/pdf/2509.14031", "abs": "https://arxiv.org/abs/2509.14031", "authors": ["Pawe\u0142 M\u0105ka", "Yusuf Can Semerci", "Jan Scholtes", "Gerasimos Spanakis"], "title": "You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "EMNLP 2025 main conference", "summary": "Achieving human-level translations requires leveraging context to ensure\ncoherence and handle complex phenomena like pronoun disambiguation. Sparsity of\ncontextually rich examples in the standard training data has been hypothesized\nas the reason for the difficulty of context utilization. In this work, we\nsystematically validate this claim in both single- and multilingual settings by\nconstructing training datasets with a controlled proportions of contextually\nrelevant examples. We demonstrate a strong association between training data\nsparsity and model performance confirming sparsity as a key bottleneck.\nImportantly, we reveal that improvements in one contextual phenomenon do no\ngeneralize to others. While we observe some cross-lingual transfer, it is not\nsignificantly higher between languages within the same sub-family. Finally, we\npropose and empirically evaluate two training strategies designed to leverage\nthe available data. These strategies improve context utilization, resulting in\naccuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in\nsingle- and multilingual settings respectively.", "AI": {"tldr": "\u672c\u6587\u9a8c\u8bc1\u8bad\u7ec3\u6570\u636e\u7a00\u758f\u662f\u4e0a\u4e0b\u6587\u5229\u7528\u96be\u7684\u539f\u56e0\uff0c\u63ed\u793a\u4e0d\u540c\u4e0a\u4e0b\u6587\u73b0\u8c61\u6539\u8fdb\u96be\u6cdb\u5316\uff0c\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5b9e\u73b0\u4eba\u7c7b\u6c34\u5e73\u7ffb\u8bd1\u65f6\u5229\u7528\u4e0a\u4e0b\u6587\u96be\u7684\u95ee\u9898\uff0c\u63a2\u7a76\u6807\u51c6\u8bad\u7ec3\u6570\u636e\u4e2d\u4e0a\u4e0b\u6587\u4e30\u5bcc\u793a\u4f8b\u7a00\u758f\u662f\u5426\u4e3a\u539f\u56e0\u3002", "method": "\u6784\u5efa\u542b\u4e0d\u540c\u6bd4\u4f8b\u4e0a\u4e0b\u6587\u76f8\u5173\u793a\u4f8b\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u9a8c\u8bc1\u6570\u636e\u7a00\u758f\u4e0e\u6a21\u578b\u6027\u80fd\u5173\u8054\uff1b\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u8bc1\u5b9e\u8bad\u7ec3\u6570\u636e\u7a00\u758f\u662f\u5173\u952e\u74f6\u9888\uff0c\u4e0d\u540c\u4e0a\u4e0b\u6587\u73b0\u8c61\u6539\u8fdb\u96be\u6cdb\u5316\uff0c\u8de8\u8bed\u8a00\u8f6c\u79fb\u4e0d\u663e\u8457\uff1b\u4e24\u79cd\u7b56\u7565\u5206\u522b\u5728\u5355\u8bed\u548c\u591a\u8bed\u73af\u5883\u4e0b\u4f7fctxPro\u8bc4\u4f30\u51c6\u786e\u7387\u63d0\u53476\u548c8\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8bad\u7ec3\u6570\u636e\u7a00\u758f\u662f\u4e0a\u4e0b\u6587\u5229\u7528\u96be\u7684\u5173\u952e\u56e0\u7d20\uff0c\u63d0\u51fa\u7684\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u4e0a\u4e0b\u6587\u5229\u7528\u548c\u7ffb\u8bd1\u51c6\u786e\u6027\u3002"}}
{"id": "2509.14036", "pdf": "https://arxiv.org/pdf/2509.14036", "abs": "https://arxiv.org/abs/2509.14036", "authors": ["Zekang Liu", "Wei Feng", "Fanhua Shang", "Lianyu Hu", "Jichao Feng", "Liqing Gao"], "title": "SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sign Language Translation (SLT) bridges the communication gap between deaf\npeople and hearing people, where dialogue provides crucial contextual cues to\naid in translation. Building on this foundational concept, this paper proposes\nQuestion-based Sign Language Translation (QB-SLT), a novel task that explores\nthe efficient integration of dialogue. Unlike gloss (sign language\ntranscription) annotations, dialogue naturally occurs in communication and is\neasier to annotate. The key challenge lies in aligning multimodality features\nwhile leveraging the context of the question to improve translation. To address\nthis issue, we propose a cross-modality Self-supervised Learning with Sigmoid\nSelf-attention Weighting (SSL-SSAW) fusion method for sign language\ntranslation. Specifically, we employ contrastive learning to align\nmultimodality features in QB-SLT, then introduce a Sigmoid Self-attention\nWeighting (SSAW) module for adaptive feature extraction from question and sign\nlanguage sequences. Additionally, we leverage available question text through\nself-supervised learning to enhance representation and translation\ncapabilities. We evaluated our approach on newly constructed CSL-Daily-QA and\nPHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,\neasily accessible question assistance can achieve or even surpass the\nperformance of gloss assistance. Furthermore, visualization results demonstrate\nthe effectiveness of incorporating dialogue in improving translation quality.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u95ee\u9898\u7684\u624b\u8bed\u7ffb\u8bd1\uff08QB - SLT\uff09\u65b0\u4efb\u52a1\u53ca\u8de8\u6a21\u6001\u81ea\u76d1\u7763\u5b66\u4e60\u4e0eSigmoid\u81ea\u6ce8\u610f\u529b\u52a0\u6743\uff08SSL - SSAW\uff09\u878d\u5408\u65b9\u6cd5\uff0c\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u83b7SOTA\u6027\u80fd\uff0c\u8868\u660e\u5bf9\u8bdd\u5bf9\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u6709\u6548\u3002", "motivation": "\u624b\u8bed\u7ffb\u8bd1\u4e2d\u5bf9\u8bdd\u80fd\u63d0\u4f9b\u5173\u952e\u4e0a\u4e0b\u6587\u7ebf\u7d22\u8f85\u52a9\u7ffb\u8bd1\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u5bf9\u8bdd\u9ad8\u6548\u96c6\u6210\u7684\u63a2\u7d22\uff0c\u4e14\u5bf9\u8bdd\u6bd4\u624b\u8bed\u8f6c\u5f55\u6ce8\u91ca\u66f4\u6613\u6807\u6ce8\u3002", "method": "\u63d0\u51faSSL - SSAW\u878d\u5408\u65b9\u6cd5\uff0c\u7528\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u591a\u6a21\u6001\u7279\u5f81\uff0c\u5f15\u5165SSAW\u6a21\u5757\u81ea\u9002\u5e94\u63d0\u53d6\u7279\u5f81\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u5229\u7528\u95ee\u9898\u6587\u672c\u63d0\u5347\u80fd\u529b\u3002", "result": "\u5728CSL - Daily - QA\u548cPHOENIX - 2014T - QA\u6570\u636e\u96c6\u4e0a\uff0cSSL - SSAW\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u95ee\u9898\u8f85\u52a9\u6548\u679c\u53ef\u8d85\u624b\u8bed\u8f6c\u5f55\u6ce8\u91ca\u8f85\u52a9\u3002", "conclusion": "\u5bf9\u8bdd\u5bf9\u63d0\u5347\u624b\u8bed\u7ffb\u8bd1\u8d28\u91cf\u6709\u6548\uff0c\u6240\u63d0\u65b9\u6cd5\u53ef\u884c\u4e14\u6548\u679c\u597d\u3002"}}
{"id": "2509.14037", "pdf": "https://arxiv.org/pdf/2509.14037", "abs": "https://arxiv.org/abs/2509.14037", "authors": ["Ranga Baminiwatte", "Kazi Jewel Rana", "Aaron J. Masino"], "title": "PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding disease similarity is critical for advancing diagnostics, drug\ndiscovery, and personalized treatment strategies. We present PhenoGnet, a novel\ngraph-based contrastive learning framework designed to predict disease\nsimilarity by integrating gene functional interaction networks with the Human\nPhenotype Ontology (HPO). PhenoGnet comprises two key components: an intra-view\nmodel that separately encodes gene and phenotype graphs using Graph\nConvolutional Networks (GCNs) and Graph Attention Networks (GATs), and a cross\nview model implemented as a shared weight multilayer perceptron (MLP) that\naligns gene and phenotype embeddings through contrastive learning. The model is\ntrained using known gene phenotype associations as positive pairs and randomly\nsampled unrelated pairs as negatives. Diseases are represented by the mean\nembeddings of their associated genes and/or phenotypes, and pairwise similarity\nis computed via cosine similarity. Evaluation on a curated benchmark of 1,100\nsimilar and 866 dissimilar disease pairs demonstrates strong performance, with\ngene based embeddings achieving an AUCPR of 0.9012 and AUROC of 0.8764,\noutperforming existing state of the art methods. Notably, PhenoGnet captures\nlatent biological relationships beyond direct overlap, offering a scalable and\ninterpretable solution for disease similarity prediction. These results\nunderscore its potential for enabling downstream applications in rare disease\nresearch and precision medicine.", "AI": {"tldr": "\u63d0\u51faPhenoGnet\u6846\u67b6\u9884\u6d4b\u75be\u75c5\u76f8\u4f3c\u5ea6\uff0c\u6548\u679c\u8d85\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u4e0b\u6e38\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u7406\u89e3\u75be\u75c5\u76f8\u4f3c\u5ea6\u5bf9\u8bca\u65ad\u3001\u836f\u7269\u53d1\u73b0\u548c\u4e2a\u6027\u5316\u6cbb\u7597\u7b56\u7565\u81f3\u5173\u91cd\u8981\u3002", "method": "PhenoGnet\u6574\u5408\u57fa\u56e0\u529f\u80fd\u4ea4\u4e92\u7f51\u7edc\u548c\u4eba\u7c7b\u8868\u578b\u672c\u4f53\uff0c\u5305\u542b\u5185\u89c6\u56fe\u548c\u8de8\u89c6\u56fe\u6a21\u578b\uff0c\u7528\u5df2\u77e5\u57fa\u56e0\u8868\u578b\u5173\u8054\u4f5c\u6b63\u6837\u672c\uff0c\u968f\u673a\u65e0\u5173\u5bf9\u4f5c\u8d1f\u6837\u672c\u8bad\u7ec3\u3002", "result": "\u57281100\u5bf9\u76f8\u4f3c\u548c866\u5bf9\u4e0d\u76f8\u4f3c\u75be\u75c5\u5bf9\u57fa\u51c6\u4e0a\u8bc4\u4f30\uff0c\u57fa\u4e8e\u57fa\u56e0\u7684\u5d4c\u5165AUCPR\u8fbe0.9012\uff0cAUROC\u8fbe0.8764\uff0c\u8d85\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "PhenoGnet\u80fd\u6355\u6349\u6f5c\u5728\u751f\u7269\u5173\u7cfb\uff0c\u4e3a\u75be\u75c5\u76f8\u4f3c\u5ea6\u9884\u6d4b\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u65b9\u6848\uff0c\u6709\u4e0b\u6e38\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.14040", "pdf": "https://arxiv.org/pdf/2509.14040", "abs": "https://arxiv.org/abs/2509.14040", "authors": ["Zewen Yang", "Xiaobing Dai", "Dongfa Zhang", "Yu Li", "Ziyang Meng", "Bingkun Huang", "Hamid Sadeghian", "Sami Haddadin"], "title": "Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Learning from demonstration allows robots to acquire complex skills from\nhuman demonstrations, but conventional approaches often require large datasets\nand fail to generalize across coordinate transformations. In this paper, we\npropose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)\nlearning framework that enables robots to perform human-guided automated\ncontrol from a single motion prompt. A dataset-construction strategy based on\ncoordinate transformations is introduced that enforces invariance to\ntranslation, rotation, and scaling, while supporting multi-step predictions.\nMoreover, GeoGP is robust to variations in the user's motion prompt and\nsupports multi-skill autonomy. We validate the proposed approach through\nnumerical simulations with the designed user graphical interface and two\nreal-world robotic experiments, which demonstrate that the proposed method is\neffective, generalizes across tasks, and significantly reduces the\ndemonstration burden. Project page is available at:\nhttps://prompt2auto.github.io", "AI": {"tldr": "\u63d0\u51faPrompt2Auto\u51e0\u4f55\u4e0d\u53d8\u5355\u6837\u672c\u9ad8\u65af\u8fc7\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9\u673a\u5668\u4eba\u4ece\u5355\u8fd0\u52a8\u63d0\u793a\u4e2d\u6267\u884c\u81ea\u52a8\u63a7\u5236\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u4e14\u80fd\u51cf\u8f7b\u6f14\u793a\u8d1f\u62c5\u3002", "motivation": "\u4f20\u7edf\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\u7684\u65b9\u6cd5\u9700\u5927\u91cf\u6570\u636e\u96c6\uff0c\u4e14\u65e0\u6cd5\u8de8\u5750\u6807\u53d8\u6362\u6cdb\u5316\u3002", "method": "\u63d0\u51faPrompt2Auto\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u4e8e\u5750\u6807\u53d8\u6362\u7684\u6570\u636e\u96c6\u6784\u5efa\u7b56\u7565\uff0c\u5b9e\u73b0\u5e73\u79fb\u3001\u65cb\u8f6c\u548c\u7f29\u653e\u4e0d\u53d8\u6027\uff0c\u652f\u6301\u591a\u6b65\u9884\u6d4b\u3002", "result": "\u901a\u8fc7\u6570\u503c\u6a21\u62df\u548c\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u6709\u6548\u3001\u80fd\u8de8\u4efb\u52a1\u6cdb\u5316\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u8de8\u4efb\u52a1\u6cdb\u5316\uff0c\u663e\u8457\u51cf\u8f7b\u6f14\u793a\u8d1f\u62c5\u3002"}}
{"id": "2509.14016", "pdf": "https://arxiv.org/pdf/2509.14016", "abs": "https://arxiv.org/abs/2509.14016", "authors": ["Jonas Buchli", "Brendan Tracey", "Tomislav Andric", "Christopher Wipf", "Yu Him Justin Chiu", "Matthias Lochbrunner", "Craig Donner", "Rana X. Adhikari", "Jan Harms", "Iain Barr", "Roland Hafner", "Andrea Huber", "Abbas Abdolmaleki", "Charlie Beattie", "Joseph Betzwieser", "Serkan Cabi", "Jonas Degrave", "Yuzhu Dong", "Leslie Fritz", "Anchal Gupta", "Oliver Groth", "Sandy Huang", "Tamara Norman", "Hannah Openshaw", "Jameson Rollins", "Greg Thornton", "George Van Den Driessche", "Markus Wulfmeier", "Pushmeet Kohli", "Martin Riedmiller", "LIGO Instrument Team"], "title": "Improving cosmological reach of a gravitational wave observatory using Deep Loop Shaping", "categories": ["astro-ph.IM", "cs.LG", "cs.SY", "eess.SY", "gr-qc"], "comment": null, "summary": "Improved low-frequency sensitivity of gravitational wave observatories would\nunlock study of intermediate-mass black hole mergers, binary black hole\neccentricity, and provide early warnings for multi-messenger observations of\nbinary neutron star mergers. Today's mirror stabilization control injects\nharmful noise, constituting a major obstacle to sensitivity improvements. We\neliminated this noise through Deep Loop Shaping, a reinforcement learning\nmethod using frequency domain rewards. We proved our methodology on the LIGO\nLivingston Observatory (LLO). Our controller reduced control noise in the\n10--30Hz band by over 30x, and up to 100x in sub-bands surpassing the design\ngoal motivated by the quantum limit. These results highlight the potential of\nDeep Loop Shaping to improve current and future GW observatories, and more\nbroadly instrumentation and control systems.", "AI": {"tldr": "\u5229\u7528\u6df1\u5ea6\u56de\u8def\u6574\u5f62\u6cd5\u6d88\u9664\u5f15\u529b\u6ce2\u5929\u6587\u53f0\u955c\u7a33\u5b9a\u63a7\u5236\u566a\u58f0\uff0c\u5728LLO\u9a8c\u8bc1\uff0c\u5927\u5e45\u964d\u4f4e\u7279\u5b9a\u9891\u6bb5\u63a7\u5236\u566a\u58f0\uff0c\u51f8\u663e\u8be5\u65b9\u6cd5\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u955c\u7a33\u5b9a\u63a7\u5236\u6ce8\u5165\u6709\u5bb3\u566a\u58f0\u963b\u788d\u5f15\u529b\u6ce2\u5929\u6587\u53f0\u4f4e\u9891\u7075\u654f\u5ea6\u63d0\u5347\uff0c\u9700\u6d88\u9664\u566a\u58f0\u4ee5\u89e3\u9501\u66f4\u591a\u7814\u7a76\u53ca\u591a\u4fe1\u4f7f\u89c2\u6d4b\u9884\u8b66\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u9891\u57df\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5Deep Loop Shaping\u6d88\u9664\u566a\u58f0\u3002", "result": "\u63a7\u5236\u5668\u4f7f10 - 30Hz\u9891\u6bb5\u63a7\u5236\u566a\u58f0\u964d\u4f4e\u8d8530\u500d\uff0c\u5b50\u9891\u6bb5\u6700\u9ad8\u964d100\u500d\uff0c\u8d85\u91cf\u5b50\u6781\u9650\u8bbe\u8ba1\u76ee\u6807\u3002", "conclusion": "Deep Loop Shaping\u6709\u6f5c\u529b\u6539\u8fdb\u5f53\u524d\u53ca\u672a\u6765\u5f15\u529b\u6ce2\u5929\u6587\u53f0\u548c\u4eea\u5668\u63a7\u5236\u7cfb\u7edf\u3002"}}
{"id": "2509.14049", "pdf": "https://arxiv.org/pdf/2509.14049", "abs": "https://arxiv.org/abs/2509.14049", "authors": ["Jordi Grau-Haro", "Ruben Ribes-Serrano", "Javier Naranjo-Alcazar", "Marta Garcia-Ballesteros", "Pedro Zuccarello"], "title": "Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices", "categories": ["cs.SD", "cs.AI"], "comment": "Accepted at Computing Conference 2026, London, UK", "summary": "Convolutional Neural Networks (CNNs) have demonstrated exceptional\nperformance in audio tagging tasks. However, deploying these models on\nresource-constrained devices like the Raspberry Pi poses challenges related to\ncomputational efficiency and thermal management. In this paper, a comprehensive\nevaluation of multiple convolutional neural network (CNN) architectures for\naudio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D\nmodels from the Pretrained Audio Neural Networks (PANNs) framework, a\nConvNeXt-based model adapted for audio classification, as well as MobileNetV3\narchitectures. In addition, two PANNs-derived networks, CNN9 and CNN13,\nrecently proposed, are also evaluated. To enhance deployment efficiency and\nportability across diverse hardware platforms, all models are converted to the\nOpen Neural Network Exchange (ONNX) format. Unlike previous works that focus on\na single model, our analysis encompasses a broader range of architectures and\ninvolves continuous 24-hour inference sessions to assess performance stability.\nOur experiments reveal that, with appropriate model selection and optimization,\nit is possible to maintain consistent inference latency and manage thermal\nbehavior effectively over extended periods. These findings provide valuable\ninsights for deploying audio tagging models in real-world edge computing\nscenarios.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6811\u8393\u6d3e\u4e0a\u7528\u4e8e\u97f3\u9891\u6807\u7b7e\u7684\u591a\u79cdCNN\u67b6\u6784\u8fdb\u884c\u8bc4\u4f30\uff0c\u5c06\u6a21\u578b\u8f6c\u6362\u4e3aONNX\u683c\u5f0f\uff0c\u5b9e\u9a8c\u8868\u660e\u5408\u9002\u9009\u578b\u548c\u4f18\u5316\u53ef\u6709\u6548\u7ba1\u7406\u63a8\u7406\u5ef6\u8fdf\u548c\u70ed\u884c\u4e3a\u3002", "motivation": "CNN\u5728\u97f3\u9891\u6807\u7b7e\u4efb\u52a1\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u6811\u8393\u6d3e\u7b49\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u548c\u70ed\u7ba1\u7406\u6311\u6218\u3002", "method": "\u5bf9PANNs\u6846\u67b6\u76841D\u548c2D\u6a21\u578b\u3001\u57fa\u4e8eConvNeXt\u7684\u97f3\u9891\u5206\u7c7b\u6a21\u578b\u3001MobileNetV3\u67b6\u6784\uff0c\u4ee5\u53caCNN9\u548cCNN13\u8fdb\u884c\u8bc4\u4f30\uff0c\u5c06\u6a21\u578b\u8f6c\u6362\u4e3aONNX\u683c\u5f0f\uff0c\u8fdb\u884c24\u5c0f\u65f6\u8fde\u7eed\u63a8\u7406\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7\u5408\u9002\u7684\u6a21\u578b\u9009\u62e9\u548c\u4f18\u5316\uff0c\u53ef\u5728\u957f\u65f6\u95f4\u5185\u4fdd\u6301\u4e00\u81f4\u7684\u63a8\u7406\u5ef6\u8fdf\u5e76\u6709\u6548\u7ba1\u7406\u70ed\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5728\u73b0\u5b9e\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u4e2d\u90e8\u7f72\u97f3\u9891\u6807\u7b7e\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.14020", "pdf": "https://arxiv.org/pdf/2509.14020", "abs": "https://arxiv.org/abs/2509.14020", "authors": ["Felipe Crivellaro Minuzzi", "Leandro Farina"], "title": "Artificial neural networks ensemble methodology to predict significant wave height", "categories": ["physics.ao-ph", "cs.LG", "physics.data-an", "68T07, 86A05, 68T05", "I.2.6; J.2; G.3"], "comment": null, "summary": "The forecast of wave variables are important for several applications that\ndepend on a better description of the ocean state. Due to the chaotic behaviour\nof the differential equations which model this problem, a well know strategy to\novercome the difficulties is basically to run several simulations, by for\ninstance, varying the initial condition, and averaging the result of each of\nthese, creating an ensemble. Moreover, in the last few years, considering the\namount of available data and the computational power increase, machine learning\nalgorithms have been applied as surrogate to traditional numerical models,\nyielding comparative or better results. In this work, we present a methodology\nto create an ensemble of different artificial neural networks architectures,\nnamely, MLP, RNN, LSTM, CNN and a hybrid CNN-LSTM, which aims to predict\nsignificant wave height on six different locations in the Brazilian coast. The\nnetworks are trained using NOAA's numerical reforecast data and target the\nresidual between observational data and the numerical model output. A new\nstrategy to create the training and target datasets is demonstrated. Results\nshow that our framework is capable of producing high efficient forecast, with\nan average accuracy of $80\\%$, that can achieve up to $88\\%$ in the best case\nscenario, which means $5\\%$ reduction in error metrics if compared to NOAA's\nnumerical model, and a increasingly reduction of computational cost.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e0d\u540c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u521b\u5efa\u96c6\u6210\u6a21\u578b\u9884\u6d4b\u5df4\u897f\u6d77\u5cb8\u516d\u4e2a\u5730\u70b9\u7684\u6709\u6548\u6ce2\u9ad8\uff0c\u5c55\u793a\u65b0\u6570\u636e\u96c6\u521b\u5efa\u7b56\u7565\uff0c\u7ed3\u679c\u9ad8\u6548\u4e14\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u6ce2\u6d6a\u53d8\u91cf\u9884\u6d4b\u5bf9\u4f9d\u8d56\u6d77\u6d0b\u72b6\u6001\u63cf\u8ff0\u7684\u5e94\u7528\u5f88\u91cd\u8981\uff0c\u4f20\u7edf\u65b9\u6cd5\u6709\u56f0\u96be\uff0c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6709\u4f18\u52bf\uff0c\u56e0\u6b64\u7814\u7a76\u7528\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\u6a21\u578b\u9884\u6d4b\u6709\u6548\u6ce2\u9ad8\u3002", "method": "\u521b\u5efaMLP\u3001RNN\u3001LSTM\u3001CNN\u548c\u6df7\u5408CNN - LSTM\u7b49\u4e0d\u540c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u96c6\u6210\uff0c\u7528NOAA\u6570\u503c\u518d\u9884\u6d4b\u6570\u636e\u8bad\u7ec3\uff0c\u76ee\u6807\u662f\u89c2\u6d4b\u6570\u636e\u4e0e\u6570\u503c\u6a21\u578b\u8f93\u51fa\u7684\u6b8b\u5dee\uff0c\u5c55\u793a\u65b0\u7684\u8bad\u7ec3\u548c\u76ee\u6807\u6570\u636e\u96c6\u521b\u5efa\u7b56\u7565\u3002", "result": "\u6846\u67b6\u80fd\u9ad8\u6548\u9884\u6d4b\uff0c\u5e73\u5747\u51c6\u786e\u738780%\uff0c\u6700\u4f73\u53ef\u8fbe88%\uff0c\u6bd4NOAA\u6570\u503c\u6a21\u578b\u8bef\u5dee\u6307\u6807\u964d\u4f4e5%\uff0c\u4e14\u4e0d\u65ad\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\u6a21\u578b\u9884\u6d4b\u6709\u6548\u6ce2\u9ad8\u7684\u6846\u67b6\u9ad8\u6548\uff0c\u80fd\u63d0\u9ad8\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2509.14026", "pdf": "https://arxiv.org/pdf/2509.14026", "abs": "https://arxiv.org/abs/2509.14026", "authors": ["Jiun-Cheng Jiang", "Morris Yu-Chao Huang", "Tianlong Chen", "Hsi-Sheng Goan"], "title": "Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks", "categories": ["quant-ph", "cs.LG"], "comment": "45 pages", "summary": "Variational quantum circuits (VQCs) are central to quantum machine learning,\nwhile recent progress in Kolmogorov-Arnold networks (KANs) highlights the power\nof learnable activation functions. We unify these directions by introducing\nquantum variational activation functions (QVAFs), realized through single-qubit\ndata re-uploading circuits called DatA Re-Uploading ActivatioNs (DARUANs). We\nshow that DARUAN with trainable weights in data pre-processing possesses an\nexponentially growing frequency spectrum with data repetitions, enabling an\nexponential reduction in parameter size compared with Fourier-based activations\nwithout loss of expressivity. Embedding DARUAN into KANs yields\nquantum-inspired KANs (QKANs), which retain the interpretability of KANs while\nimproving their parameter efficiency, expressivity, and generalization. We\nfurther introduce two novel techniques to enhance scalability, feasibility and\ncomputational efficiency, such as layer extension and hybrid QKANs (HQKANs) as\ndrop-in replacements of multi-layer perceptrons (MLPs) for feed-forward\nnetworks in large-scale models. We provide theoretical analysis and extensive\nexperiments on function regression, image classification, and autoregressive\ngenerative language modeling, demonstrating the efficiency and scalability of\nQKANs. DARUANs and QKANs offer a promising direction for advancing quantum\nmachine learning on both noisy intermediate-scale quantum (NISQ) hardware and\nclassical quantum simulators.", "AI": {"tldr": "\u63d0\u51fa\u91cf\u5b50\u53d8\u5206\u6fc0\u6d3b\u51fd\u6570QVAFs\uff08\u901a\u8fc7DARUANs\u5b9e\u73b0\uff09\uff0c\u5d4c\u5165KANs\u5f97\u5230QKANs\uff0c\u5f15\u5165\u65b0\u6280\u672f\u589e\u5f3a\u53ef\u6269\u5c55\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u7ed3\u5408\u53d8\u5206\u91cf\u5b50\u7535\u8def\u548cKolmogorov - Arnold\u7f51\u7edc\u4e2d\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u7684\u4f18\u52bf\uff0c\u63a8\u52a8\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u53d1\u5c55\u3002", "method": "\u5f15\u5165QVAFs\u548cDARUANs\uff0c\u5c06DARUAN\u5d4c\u5165KANs\u5f97\u5230QKANs\uff0c\u8fd8\u91c7\u7528\u5c42\u6269\u5c55\u548c\u6df7\u5408QKANs\u6280\u672f\u3002", "result": "DARUAN\u9891\u7387\u8c31\u968f\u6570\u636e\u91cd\u590d\u6307\u6570\u589e\u957f\uff0c\u53ef\u6307\u6570\u7ea7\u51cf\u5c11\u53c2\u6570\u5927\u5c0f\uff1bQKANs\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u9ad8\u53c2\u6570\u6548\u7387\u3001\u8868\u8fbe\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\uff1b\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "DARUANs\u548cQKANs\u4e3a\u5728NISQ\u786c\u4ef6\u548c\u7ecf\u5178\u91cf\u5b50\u6a21\u62df\u5668\u4e0a\u63a8\u8fdb\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2509.14165", "pdf": "https://arxiv.org/pdf/2509.14165", "abs": "https://arxiv.org/abs/2509.14165", "authors": ["Michal Szczepanski", "Martyna Poreba", "Karim Haroun"], "title": "Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision Transformers (ViTs) achieve state-of-the-art performance in semantic\nsegmentation but are hindered by high computational and memory costs. To\naddress this, we propose STEP (SuperToken and Early-Pruning), a hybrid\ntoken-reduction framework that combines dynamic patch merging and token pruning\nto enhance efficiency without significantly compromising accuracy. At the core\nof STEP is dCTS, a lightweight CNN-based policy network that enables flexible\nmerging into superpatches. Encoder blocks integrate also early-exits to remove\nhigh-confident supertokens, lowering computational load. We evaluate our method\non high-resolution semantic segmentation benchmarks, including images up to\n1024 x 1024, and show that when dCTS is applied alone, the token count can be\nreduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching\nscheme. This yields a 2.6x reduction in computational cost and a 3.4x increase\nin throughput when using ViT-Large as the backbone. Applying the full STEP\nframework further improves efficiency, reaching up to a 4x reduction in\ncomputational complexity and a 1.7x gain in inference speed, with a maximum\naccuracy drop of no more than 2.0%. With the proposed STEP configurations, up\nto 40% of tokens can be confidently predicted and halted before reaching the\nfinal encoder layer.", "AI": {"tldr": "\u63d0\u51faSTEP\u6846\u67b6\u63d0\u5347\u89c6\u89c9Transformer\u8bed\u4e49\u5206\u5272\u6548\u7387\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u4e0b\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u63d0\u5347\u541e\u5410\u91cf\u3002", "motivation": "\u89c6\u89c9Transformer\u5728\u8bed\u4e49\u5206\u5272\u4e2d\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\uff0c\u9700\u63d0\u5347\u6548\u7387\u3002", "method": "\u63d0\u51faSTEP\u6df7\u5408\u6807\u8bb0\u51cf\u5c11\u6846\u67b6\uff0c\u7ed3\u5408\u52a8\u6001\u5757\u5408\u5e76\u548c\u6807\u8bb0\u4fee\u526a\uff0c\u6838\u5fc3\u662fdCTS\u7b56\u7565\u7f51\u7edc\uff0c\u7f16\u7801\u5668\u5757\u96c6\u6210\u63d0\u524d\u9000\u51fa\u673a\u5236\u3002", "result": "dCTS\u5355\u72ec\u5e94\u7528\u65f6\u6807\u8bb0\u6570\u91cf\u964d\u4f4e2.5\u500d\u3001\u8ba1\u7b97\u6210\u672c\u964d\u4f4e2.6\u500d\u3001\u541e\u5410\u91cf\u63d0\u53473.4\u500d\uff1b\u5b8c\u6574STEP\u6846\u67b6\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e4\u500d\u3001\u63a8\u7406\u901f\u5ea6\u63d0\u53471.7\u500d\uff0c\u7cbe\u5ea6\u4e0b\u964d\u4e0d\u8d852.0%\uff0c\u6700\u591a40%\u6807\u8bb0\u53ef\u63d0\u524d\u505c\u6b62\u3002", "conclusion": "STEP\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u89c6\u89c9Transformer\u8bed\u4e49\u5206\u5272\u6548\u7387\u3002"}}
{"id": "2509.14180", "pdf": "https://arxiv.org/pdf/2509.14180", "abs": "https://arxiv.org/abs/2509.14180", "authors": ["Akhil Theerthala"], "title": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; J.4"], "comment": "24 pages, 11 figures. The paper presents a novel framework for\n  generating a personal finance dataset. The resulting fine-tuned model and\n  dataset are publicly available", "summary": "Personalized financial advice requires consideration of user goals,\nconstraints, risk tolerance, and jurisdiction. Prior LLM work has focused on\nsupport systems for investors and financial planners. Simultaneously, numerous\nrecent studies examine broader personal finance tasks, including budgeting,\ndebt management, retirement, and estate planning, through agentic pipelines\nthat incur high maintenance costs, yielding less than 25% of their expected\nfinancial returns. In this study, we introduce a novel and reproducible\nframework that integrates relevant financial context with behavioral finance\nstudies to construct supervision data for end-to-end advisors. Using this\nframework, we create a 19k sample reasoning dataset and conduct a comprehensive\nfine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test\nsplit and a blind LLM-jury study, we demonstrate that through careful data\ncuration and behavioral integration, our 8B model achieves performance\ncomparable to significantly larger baselines (14-32B parameters) across factual\naccuracy, fluency, and personalization metrics while incurring 80% lower costs\nthan the larger counterparts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u6846\u67b6\u6784\u5efa\u76d1\u7763\u6570\u636e\u5fae\u8c03Qwen - 3 - 8B\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6210\u672c\u4f4e\u4e14\u6027\u80fd\u4e0e\u5927\u53c2\u6570\u6a21\u578b\u76f8\u5f53\u3002", "motivation": "\u8fc7\u5f80LLM\u5de5\u4f5c\u96c6\u4e2d\u5728\u6295\u8d44\u8005\u548c\u91d1\u878d\u89c4\u5212\u5e08\u652f\u6301\u7cfb\u7edf\uff0c\u73b0\u6709\u4e2a\u4eba\u7406\u8d22\u4efb\u52a1\u4ee3\u7406\u7ba1\u9053\u7ef4\u62a4\u6210\u672c\u9ad8\u3001\u6536\u76ca\u4f4e\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165\u6574\u5408\u91d1\u878d\u80cc\u666f\u548c\u884c\u4e3a\u91d1\u878d\u7814\u7a76\u7684\u6846\u67b6\u6784\u5efa\u76d1\u7763\u6570\u636e\uff0c\u521b\u5efa19k\u6837\u672c\u63a8\u7406\u6570\u636e\u96c6\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u5bf9Qwen - 3 - 8B\u6a21\u578b\u8fdb\u884c\u5168\u9762\u5fae\u8c03\u3002", "result": "\u901a\u8fc7\u4fdd\u7559\u6d4b\u8bd5\u548c\u76f2\u6d4b\uff0c8B\u6a21\u578b\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u6d41\u7545\u6027\u548c\u4e2a\u6027\u5316\u6307\u6807\u4e0a\u8868\u73b0\u4e0e14 - 32B\u53c2\u6570\u7684\u5927\u6a21\u578b\u76f8\u5f53\uff0c\u6210\u672c\u964d\u4f4e80%\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u5fc3\u7684\u6570\u636e\u7ba1\u7406\u548c\u884c\u4e3a\u6574\u5408\uff0c\u5c0f\u53c2\u6570\u6a21\u578b\u53ef\u5728\u4f4e\u5f97\u591a\u7684\u6210\u672c\u4e0b\u8fbe\u5230\u5927\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2509.14163", "pdf": "https://arxiv.org/pdf/2509.14163", "abs": "https://arxiv.org/abs/2509.14163", "authors": ["Chi-Sheng Chen", "En-Jui Kuo"], "title": "Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Diffusion models typically employ static or heuristic classifier-free\nguidance (CFG) schedules, which often fail to adapt across timesteps and noise\nconditions. In this work, we introduce a quantum reinforcement learning (QRL)\ncontroller that dynamically adjusts CFG at each denoising step. The controller\nadopts a hybrid quantum--classical actor--critic architecture: a shallow\nvariational quantum circuit (VQC) with ring entanglement generates policy\nfeatures, which are mapped by a compact multilayer perceptron (MLP) into\nGaussian actions over $\\Delta$CFG, while a classical critic estimates value\nfunctions. The policy is optimized using Proximal Policy Optimization (PPO)\nwith Generalized Advantage Estimation (GAE), guided by a reward that balances\nclassification confidence, perceptual improvement, and action regularization.\nExperiments on CIFAR-10 demonstrate that our QRL policy improves perceptual\nquality (LPIPS, PSNR, SSIM) while reducing parameter count compared to\nclassical RL actors and fixed schedules. Ablation studies on qubit number and\ncircuit depth reveal trade-offs between accuracy and efficiency, and extended\nevaluations confirm robust generation under long diffusion schedules.", "AI": {"tldr": "\u63d0\u51fa\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u52a8\u6001\u8c03\u6574\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\uff08CFG\uff09\uff0c\u5728CIFAR - 10\u5b9e\u9a8c\u4e2d\u63d0\u5347\u611f\u77e5\u8d28\u91cf\u5e76\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u4f7f\u7528\u7684\u9759\u6001\u6216\u542f\u53d1\u5f0fCFG\u8c03\u5ea6\u96be\u4ee5\u9002\u5e94\u4e0d\u540c\u65f6\u95f4\u6b65\u957f\u548c\u566a\u58f0\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u6df7\u5408\u91cf\u5b50 - \u7ecf\u5178\u6f14\u5458 - \u8bc4\u8bba\u5bb6\u67b6\u6784\uff0c\u7528\u53d8\u5206\u91cf\u5b50\u7535\u8def\u751f\u6210\u7b56\u7565\u7279\u5f81\uff0c\u591a\u5c42\u611f\u77e5\u673a\u6620\u5c04\u52a8\u4f5c\uff0c\u4f7f\u7528PPO\u548cGAE\u4f18\u5316\u7b56\u7565\uff0c\u7531\u5e73\u8861\u591a\u79cd\u56e0\u7d20\u7684\u5956\u52b1\u5f15\u5bfc\u3002", "result": "\u5728CIFAR - 10\u4e0a\u5b9e\u9a8c\u663e\u793a\u63d0\u5347\u4e86\u611f\u77e5\u8d28\u91cf\uff08LPIPS\u3001PSNR\u3001SSIM\uff09\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u6570\u91cf\uff0c\u6d88\u878d\u5b9e\u9a8c\u63ed\u793a\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u6743\u8861\uff0c\u6269\u5c55\u8bc4\u4f30\u8bc1\u5b9e\u957f\u6269\u6563\u8c03\u5ea6\u4e0b\u751f\u6210\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684QRL\u7b56\u7565\u6709\u6548\uff0c\u80fd\u52a8\u6001\u8c03\u6574CFG\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u6709\u4f18\u52bf\u3002"}}
{"id": "2509.14199", "pdf": "https://arxiv.org/pdf/2509.14199", "abs": "https://arxiv.org/abs/2509.14199", "authors": ["Haichao Zhang", "Wenhao Chai", "Shwai He", "Ang Li", "Yun Fu"], "title": "Dense Video Understanding with Gated Residual Tokenization", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "High temporal resolution is essential for capturing fine-grained details in\nvideo understanding. However, current video large language models (VLLMs) and\nbenchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or\nkeyframe selection, discarding dense temporal information. This compromise\navoids the high cost of tokenizing every frame, which otherwise leads to\nredundant computation and linear token growth as video length increases. While\nthis trade-off works for slowly changing content, it fails for tasks like\nlecture comprehension, where information appears in nearly every frame and\nrequires precise temporal alignment. To address this gap, we introduce Dense\nVideo Understanding (DVU), which enables high-FPS video comprehension by\nreducing both tokenization time and token overhead. Existing benchmarks are\nalso limited, as their QA pairs focus on coarse content changes. We therefore\npropose DIVE (Dense Information Video Evaluation), the first benchmark designed\nfor dense temporal reasoning. To make DVU practical, we present Gated Residual\nTokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated\nTokenization uses pixel-level motion estimation to skip static regions during\ntokenization, achieving sub-linear growth in token count and compute. (2)\nSemantic-Scene Intra-Tokenization Merging fuses tokens across static regions\nwithin a scene, further reducing redundancy while preserving dynamic semantics.\nExperiments on DIVE show that GRT outperforms larger VLLM baselines and scales\npositively with FPS. These results highlight the importance of dense temporal\ninformation and demonstrate that GRT enables efficient, scalable high-FPS video\nunderstanding.", "AI": {"tldr": "\u63d0\u51faDense Video Understanding (DVU)\u548cDIVE\u57fa\u51c6\uff0c\u91c7\u7528Gated Residual Tokenization (GRT)\u6846\u67b6\u5b9e\u73b0\u9ad8\u6548\u9ad8\u5e27\u7387\u89c6\u9891\u7406\u89e3\uff0c\u5b9e\u9a8c\u8868\u660eGRT\u8868\u73b0\u4f18\u4e14\u53ef\u6269\u5c55\u3002", "motivation": "\u5f53\u524dVLLMs\u548c\u57fa\u51c6\u591a\u91c7\u7528\u4f4e\u5e27\u7387\u91c7\u6837\uff0c\u4e22\u5f03\u5bc6\u96c6\u65f6\u95f4\u4fe1\u606f\uff0c\u73b0\u6709\u57fa\u51c6QA\u5bf9\u5173\u6ce8\u7c97\u7c92\u5ea6\u5185\u5bb9\u53d8\u5316\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5982\u8bb2\u5ea7\u7406\u89e3\u7b49\u4efb\u52a1\u9700\u6c42\u3002", "method": "\u5f15\u5165DVU\u51cf\u5c11\u5206\u8bcd\u65f6\u95f4\u548c\u4ee4\u724c\u5f00\u9500\uff1b\u63d0\u51faDIVE\u57fa\u51c6\u7528\u4e8e\u5bc6\u96c6\u65f6\u95f4\u63a8\u7406\uff1b\u63d0\u51faGRT\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ec\u8fd0\u52a8\u8865\u507f\u95e8\u63a7\u5206\u8bcd\u548c\u8bed\u4e49\u573a\u666f\u5185\u4ee4\u724c\u5408\u5e76\u3002", "result": "\u5728DIVE\u4e0a\u5b9e\u9a8c\u663e\u793aGRT\u4f18\u4e8e\u66f4\u5927\u7684VLLM\u57fa\u7ebf\uff0c\u4e14\u968fFPS\u63d0\u5347\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u5bc6\u96c6\u65f6\u95f4\u4fe1\u606f\u7684\u91cd\u8981\u6027\uff0c\u8bc1\u660eGRT\u80fd\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u9ad8\u5e27\u7387\u89c6\u9891\u7406\u89e3\u3002"}}
{"id": "2509.14233", "pdf": "https://arxiv.org/pdf/2509.14233", "abs": "https://arxiv.org/abs/2509.14233", "authors": ["Alejandro Hern\u00e1ndez-Cano", "Alexander H\u00e4gele", "Allen Hao Huang", "Angelika Romanou", "Antoni-Joan Solergibert", "Barna Pasztor", "Bettina Messmer", "Dhia Garbaya", "Eduard Frank \u010eurech", "Ido Hakimi", "Juan Garc\u00eda Giraldo", "Mete Ismayilzada", "Negar Foroutan", "Skander Moalla", "Tiancheng Chen", "Vinko Sabol\u010dec", "Yixuan Xu", "Michael Aerni", "Badr AlKhamissi", "Ines Altemir Marinas", "Mohammad Hossein Amani", "Matin Ansaripour", "Ilia Badanin", "Harold Benoit", "Emanuela Boros", "Nicholas Browning", "Fabian B\u00f6sch", "Maximilian B\u00f6ther", "Niklas Canova", "Camille Challier", "Clement Charmillot", "Jonathan Coles", "Jan Deriu", "Arnout Devos", "Lukas Drescher", "Daniil Dzenhaliou", "Maud Ehrmann", "Dongyang Fan", "Simin Fan", "Silin Gao", "Miguel Gila", "Mar\u00eda Grandury", "Diba Hashemi", "Alexander Hoyle", "Jiaming Jiang", "Mark Klein", "Andrei Kucharavy", "Anastasiia Kucherenko", "Frederike L\u00fcbeck", "Roman Machacek", "Theofilos Manitaras", "Andreas Marfurt", "Kyle Matoba", "Simon Matrenok", "Henrique Mendonc\u00e7a", "Fawzi Roberto Mohamed", "Syrielle Montariol", "Luca Mouchel", "Sven Najem-Meyer", "Jingwei Ni", "Gennaro Oliva", "Matteo Pagliardini", "Elia Palme", "Andrei Panferov", "L\u00e9o Paoletti", "Marco Passerini", "Ivan Pavlov", "Auguste Poiroux", "Kaustubh Ponkshe", "Nathan Ranchin", "Javi Rando", "Mathieu Sauser", "Jakhongir Saydaliev", "Muhammad Ali Sayfiddinov", "Marian Schneider", "Stefano Schuppli", "Marco Scialanga", "Andrei Semenov", "Kumar Shridhar", "Raghav Singhal", "Anna Sotnikova", "Alexander Sternfeld", "Ayush Kumar Tarun", "Paul Teiletche", "Jannis Vamvas", "Xiaozhe Yao", "Hao Zhao Alexander Ilic", "Ana Klimovic", "Andreas Krause", "Caglar Gulcehre", "David Rosenthal", "Elliott Ash", "Florian Tram\u00e8r", "Joost VandeVondele", "Livio Veraldi", "Martin Rajman", "Thomas Schulthess", "Torsten Hoefler", "Antoine Bosselut", "Martin Jaggi", "Imanol Schlag"], "title": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present Apertus, a fully open suite of large language models (LLMs)\ndesigned to address two systemic shortcomings in today's open model ecosystem:\ndata compliance and multilingual representation. Unlike many prior models that\nrelease weights without reproducible data pipelines or regard for content-owner\nrights, Apertus models are pretrained exclusively on openly available data,\nretroactively respecting robots.txt exclusions and filtering for\nnon-permissive, toxic, and personally identifiable content. To mitigate risks\nof memorization, we adopt the Goldfish objective during pretraining, strongly\nsuppressing verbatim recall of data while retaining downstream task\nperformance. The Apertus models also expand multilingual coverage, training on\n15T tokens from over 1800 languages, with ~40% of pretraining data allocated to\nnon-English content. Released at 8B and 70B scales, Apertus approaches\nstate-of-the-art results among fully open models on multilingual benchmarks,\nrivalling or surpassing open-weight counterparts. Beyond model weights, we\nrelease all scientific artifacts from our development cycle with a permissive\nlicense, including data preparation scripts, checkpoints, evaluation suites,\nand training code, enabling transparent audit and extension.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u5168\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5957\u4ef6Apertus\uff0c\u89e3\u51b3\u6570\u636e\u5408\u89c4\u548c\u591a\u8bed\u8a00\u8868\u793a\u95ee\u9898\uff0c\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63a5\u8fd1\u6700\u4f18\uff0c\u8fd8\u5f00\u6e90\u5f00\u53d1\u5468\u671f\u7684\u6240\u6709\u79d1\u5b66\u5236\u54c1\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u5f00\u6e90\u6a21\u578b\u751f\u6001\u7cfb\u7edf\u4e2d\u6570\u636e\u5408\u89c4\u548c\u591a\u8bed\u8a00\u8868\u793a\u7684\u4e24\u4e2a\u7cfb\u7edf\u6027\u7f3a\u9677\u3002", "method": "\u4ec5\u5728\u516c\u5f00\u53ef\u7528\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\uff0c\u8ffd\u6eaf\u5c0a\u91cdrobots.txt\u6392\u9664\u89c4\u5219\u5e76\u8fc7\u6ee4\u4e0d\u826f\u5185\u5bb9\uff1b\u9884\u8bad\u7ec3\u65f6\u91c7\u7528Goldfish\u76ee\u6807\u6291\u5236\u6570\u636e\u9010\u5b57\u56de\u5fc6\uff1b\u57281800\u591a\u79cd\u8bed\u8a00\u768415T\u4ee4\u724c\u4e0a\u8bad\u7ec3\uff0c\u7ea640%\u9884\u8bad\u7ec3\u6570\u636e\u4e3a\u975e\u82f1\u8bed\u5185\u5bb9\u3002", "result": "Apertus\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63a5\u8fd1\u5168\u5f00\u6e90\u6a21\u578b\u7684\u6700\u4f18\u7ed3\u679c\uff0c\u4e0e\u6216\u8d85\u8d8a\u5f00\u6e90\u6743\u91cd\u7684\u540c\u7c7b\u6a21\u578b\u3002", "conclusion": "\u53d1\u5e03Apertus\u6a21\u578b\u6743\u91cd\u53ca\u5f00\u53d1\u5468\u671f\u7684\u6240\u6709\u79d1\u5b66\u5236\u54c1\uff0c\u4fbf\u4e8e\u900f\u660e\u5ba1\u8ba1\u548c\u6269\u5c55\u3002"}}
{"id": "2509.14203", "pdf": "https://arxiv.org/pdf/2509.14203", "abs": "https://arxiv.org/abs/2509.14203", "authors": ["Shengbo Wang", "Nian Si"], "title": "Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Learning and optimal control under robust Markov decision processes (MDPs)\nhave received increasing attention, yet most existing theory, algorithms, and\napplications focus on finite-horizon or discounted models. The average-reward\nformulation, while natural in many operations research and management contexts,\nremains underexplored. This is primarily because the dynamic programming\nfoundations are technically challenging and only partially understood, with\nseveral fundamental questions remaining open. This paper steps toward a general\nframework for average-reward robust MDPs by analyzing the constant-gain\nsetting. We study the average-reward robust control problem with possible\ninformation asymmetries between the controller and an S-rectangular adversary.\nOur analysis centers on the constant-gain robust Bellman equation, examining\nboth the existence of solutions and their relationship to the optimal average\nreward. Specifically, we identify when solutions to the robust Bellman equation\ncharacterize the optimal average reward and stationary policies, and we provide\nsufficient conditions ensuring solutions' existence. These findings expand the\ndynamic programming theory for average-reward robust MDPs and lay a foundation\nfor robust dynamic decision making under long-run average criteria in\noperational environments.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u6052\u5b9a\u589e\u76ca\u8bbe\u7f6e\uff0c\u4e3a\u5e73\u5747\u56de\u62a5\u9c81\u68d2\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u6784\u5efa\u901a\u7528\u6846\u67b6\uff0c\u7814\u7a76\u542b\u4fe1\u606f\u4e0d\u5bf9\u79f0\u7684\u63a7\u5236\u95ee\u9898\uff0c\u5206\u6790\u9c81\u68d2\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff0c\u7ed9\u51fa\u89e3\u7684\u5b58\u5728\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u3001\u7b97\u6cd5\u548c\u5e94\u7528\u591a\u5173\u6ce8\u6709\u9650\u65f6\u57df\u6216\u6298\u6263\u6a21\u578b\uff0c\u5e73\u5747\u56de\u62a5\u516c\u5f0f\u5728\u8fd0\u7b79\u5b66\u548c\u7ba1\u7406\u73af\u5883\u4e2d\u867d\u81ea\u7136\u4f46\u7814\u7a76\u4e0d\u8db3\uff0c\u52a8\u6001\u89c4\u5212\u57fa\u7840\u6280\u672f\u6311\u6218\u5927\u4e14\u90e8\u5206\u672a\u88ab\u7406\u89e3\u3002", "method": "\u5206\u6790\u6052\u5b9a\u589e\u76ca\u8bbe\u7f6e\uff0c\u56f4\u7ed5\u6052\u5b9a\u589e\u76ca\u9c81\u68d2\u8d1d\u5c14\u66fc\u65b9\u7a0b\u5c55\u5f00\u7814\u7a76\uff0c\u8003\u5bdf\u89e3\u7684\u5b58\u5728\u6027\u53ca\u5176\u4e0e\u6700\u4f18\u5e73\u5747\u56de\u62a5\u7684\u5173\u7cfb\u3002", "result": "\u786e\u5b9a\u4e86\u9c81\u68d2\u8d1d\u5c14\u66fc\u65b9\u7a0b\u7684\u89e3\u4f55\u65f6\u80fd\u8868\u5f81\u6700\u4f18\u5e73\u5747\u56de\u62a5\u548c\u7a33\u6001\u7b56\u7565\uff0c\u5e76\u7ed9\u51fa\u89e3\u5b58\u5728\u7684\u5145\u5206\u6761\u4ef6\u3002", "conclusion": "\u6269\u5c55\u4e86\u5e73\u5747\u56de\u62a5\u9c81\u68d2\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u52a8\u6001\u89c4\u5212\u7406\u8bba\uff0c\u4e3a\u8fd0\u8425\u73af\u5883\u4e2d\u57fa\u4e8e\u957f\u671f\u5e73\u5747\u6807\u51c6\u7684\u9c81\u68d2\u52a8\u6001\u51b3\u7b56\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.14228", "pdf": "https://arxiv.org/pdf/2509.14228", "abs": "https://arxiv.org/abs/2509.14228", "authors": ["Benjamin Shaffer", "Victoria Edwards", "Brooks Kinch", "Nathaniel Trask", "M. Ani Hsieh"], "title": "Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Source localization in a complex flow poses a significant challenge for\nmulti-robot teams tasked with localizing the source of chemical leaks or\ntracking the dispersion of an oil spill. The flow dynamics can be time-varying\nand chaotic, resulting in sporadic and intermittent sensor readings, and\ncomplex environmental geometries further complicate a team's ability to model\nand predict the dispersion. To accurately account for the physical processes\nthat drive the dispersion dynamics, robots must have access to computationally\nintensive numerical models, which can be difficult when onboard computation is\nlimited. We present a distributed mobile sensing framework for source\nlocalization in which each robot carries a machine-learned, finite element\nmodel of its environment to guide information-based sampling. The models are\nused to evaluate an approximate mutual information criterion to drive an\ninfotaxis control strategy, which selects sensing regions that are expected to\nmaximize informativeness for the source localization objective. Our approach\nachieves faster error reduction compared to baseline sensing strategies and\nresults in more accurate source localization compared to baseline machine\nlearning approaches.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u5f0f\u79fb\u52a8\u4f20\u611f\u6846\u67b6\u7528\u4e8e\u590d\u6742\u6d41\u4e2d\u7684\u6e90\u5b9a\u4f4d\uff0c\u6bd4\u57fa\u7ebf\u7b56\u7565\u548c\u65b9\u6cd5\u66f4\u4f18\u3002", "motivation": "\u590d\u6742\u6d41\u4e2d\u7684\u6e90\u5b9a\u4f4d\u5bf9\u591a\u673a\u5668\u4eba\u56e2\u961f\u662f\u6311\u6218\uff0c\u6d41\u52a8\u529b\u5b66\u548c\u73af\u5883\u51e0\u4f55\u4f7f\u5efa\u6a21\u548c\u9884\u6d4b\u56f0\u96be\uff0c\u4e14\u673a\u5668\u4eba\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u5f0f\u79fb\u52a8\u4f20\u611f\u6846\u67b6\uff0c\u6bcf\u4e2a\u673a\u5668\u4eba\u643a\u5e26\u673a\u5668\u5b66\u4e60\u7684\u6709\u9650\u5143\u6a21\u578b\uff0c\u7528\u8fd1\u4f3c\u4e92\u4fe1\u606f\u51c6\u5219\u9a71\u52a8\u4fe1\u606f\u5bfb\u4f18\u63a7\u5236\u7b56\u7565\u3002", "result": "\u6bd4\u57fa\u7ebf\u4f20\u611f\u7b56\u7565\u66f4\u5feb\u51cf\u5c11\u8bef\u5dee\uff0c\u6bd4\u57fa\u7ebf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u6e90\u5b9a\u4f4d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u79fb\u52a8\u4f20\u611f\u6846\u67b6\u5728\u590d\u6742\u6d41\u6e90\u5b9a\u4f4d\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2509.14229", "pdf": "https://arxiv.org/pdf/2509.14229", "abs": "https://arxiv.org/abs/2509.14229", "authors": ["Rieko Tasaka", "Tatsuya Kimura", "Joe Suzuki"], "title": "Spacing Test for Fused Lasso", "categories": ["math.ST", "cs.LG", "stat.TH"], "comment": null, "summary": "This study addresses the unresolved problem of selecting the regularization\nparameter in the fused lasso. In particular, we extend the framework of the\nSpacing Test proposed by Tibshirani et al. to the fused lasso, providing a\ntheoretical foundation for post-selection inference by characterizing the\nselection event as a polyhedral constraint. Based on the analysis of the\nsolution path of the fused lasso using a LARS-type algorithm, we derive exact\nconditional $p$-values for the selected change-points. Our method broadens the\napplicability of the Spacing Test from the standard lasso to fused penalty\nstructures. Furthermore, through numerical experiments comparing the proposed\nmethod with sequential versions of AIC and BIC as well as cross-validation, we\ndemonstrate that the proposed approach properly controls the type I error while\nachieving high detection power. This work offers a theoretically sound and\ncomputationally practical solution for parameter selection and post-selection\ninference in structured signal estimation problems. Keywords: Fused Lasso,\nRegularization parameter selection, Spacing Test for Lasso, Selective\ninference, Change-point detection", "AI": {"tldr": "\u672c\u6587\u5c06\u95f4\u8ddd\u68c0\u9a8c\u6846\u67b6\u6269\u5c55\u5230\u878d\u5408\u5957\u7d22\uff0c\u63a8\u5bfc\u9009\u5b9a\u53d8\u5316\u70b9\u7684\u7cbe\u786e\u6761\u4ef6p\u503c\uff0c\u7ecf\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u63a7\u5236\u4e00\u7c7b\u9519\u8bef\u4e14\u6709\u9ad8\u68c0\u6d4b\u529b\uff0c\u4e3a\u7ed3\u6784\u5316\u4fe1\u53f7\u4f30\u8ba1\u95ee\u9898\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u878d\u5408\u5957\u7d22\u4e2d\u6b63\u5219\u5316\u53c2\u6570\u9009\u62e9\u7684\u672a\u51b3\u95ee\u9898\u3002", "method": "\u5c06Tibshirani\u7b49\u4eba\u63d0\u51fa\u7684\u95f4\u8ddd\u68c0\u9a8c\u6846\u67b6\u6269\u5c55\u5230\u878d\u5408\u5957\u7d22\uff0c\u7528LARS\u578b\u7b97\u6cd5\u5206\u6790\u878d\u5408\u5957\u7d22\u89e3\u8def\u5f84\u63a8\u5bfc\u7cbe\u786e\u6761\u4ef6p\u503c\uff0c\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u4e0eAIC\u3001BIC\u548c\u4ea4\u53c9\u9a8c\u8bc1\u7684\u987a\u5e8f\u7248\u672c\u5bf9\u6bd4\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u80fd\u9002\u5f53\u63a7\u5236\u4e00\u7c7b\u9519\u8bef\uff0c\u540c\u65f6\u5b9e\u73b0\u9ad8\u68c0\u6d4b\u529b\u3002", "conclusion": "\u4e3a\u7ed3\u6784\u5316\u4fe1\u53f7\u4f30\u8ba1\u95ee\u9898\u4e2d\u7684\u53c2\u6570\u9009\u62e9\u548c\u9009\u62e9\u540e\u63a8\u65ad\u63d0\u4f9b\u4e86\u7406\u8bba\u5408\u7406\u4e14\u8ba1\u7b97\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
